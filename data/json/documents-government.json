["### About this Resource\n\nThese genai implementation recommendations and considerations have been created as a way to\nshare information and resources to help direct responsible implementation of genai tools and guide genai\nLiteracy in North Carolina Public Schools.\n\nNote that as genai is emerging technology and is changing rapidly, as are laws and rules governing its\nuse, this is a living document and it will be updated as needed to reflect changes that take place in this very\nfluid environment.\n\nThe last update will appear at the bottom of each page for your reference.\n\nThese guidelines have been organized around the five focus areas of the North Carolina Digital Learning Plan ,\nwhich guides digital teaching and learning for North Carolina\npublic schools.\n\nThe Digital Learning Plan encourages the safe\nuse of innovative technology to prepare students for future\nschool and work to improve student outcomes and support the\nappropriate use of technology to advance learning.\n\nTh is document is organized around the five focus areas of the\nNC Digital Learning Plan as seen in this graphic.\n\nThe Office of Digital Teaching and Learning, housed within the\nNorth Carolina Department of Public Instruction(NCDPI),\nsupports educators in using genai safely to improve\nstudent learning.\n\nIf you need assistance with implementing\ngenai into your district or school, please reach out to\nyour regional Digital Teaching and Learning Consultant or\nInnovative Learning Catalyst.\n\nAll regional DTL consultants\u2019 and Innovative Learning Catalysts\u2019\ncontact information, as well as a wealth of other information, may be found on the DTL Hub webpage .\n\n**Acknowledgements** :\nThis document was developed by the NCDPI genai Guidelines Committee, which is a collaboration between\nseveral different Offices within NCDPI and includes the following members:\n\n-  Vera Cubero.\n\n(Lead Contributor).\n\nEducation Consultant II; Office of Digital Teaching and Learning\n\n-  Dr. Ashley McBride.(Contributor).\n\nSection Chief; Digital Learning Initiative\n\n-  Diane Dulaney.(Contributor).\n\nDirector, Office of Data, Reporting and Privacy\n\n-  Eli Hamrick IV.\n\n(Contributor).Secondary Computer Science, IT, and Technology Education Consultant\n\n-  Timothy Wease.(Contributor).\n\nPSU IT Security Specialist, Cybersecurity Section\n\n-  Dr. Vanessa Wrenn.(Contributor).\n\nChief Information Officer; Technology Services and Digital Learning\n\n-  Josh Barton.(Reviewer).\n\nState Consultant for Assistive Technology; Office of Exceptional Children\n\n_*The Department of Information Technology is expected to release additional guidance around genai.\n\nOnce_\n_released, this document will be updated to align with their recommendations_ _._\n\nDirect questions about this document to  or \n\n\n-----", "**Leadership and Vision......................................................................................................................... 5**\n\nApproach to genai......................................................................................................................... 5\n10 Top Skills from Future of Jobs Report & NC Portrait of a Graduate...................................................6\nResponsible Implementation..................................................................................................................... 7\ngenai Implementation Roadmap for North Carolina\u2019s Public Schools..........................................................8\nPSU genai Guidelines.................................................................................................................... 9\nEvaluating genai Ed Tech Tools..................................................................................................10\nDeveloping genai Guidelines at Your PSU..................................................................................11\nDeveloping genai Guidelines at Your PSU..................................................................................12\nExample genai Amendment to School Integrity Policy.............................................................13", "**Curriculum, Instruction, and Assessment.......................................................................................... 17**\n\nLarge Language Models (LLMs)..............................................................................................................17\nThe CRAFT prompting framework:....................................................................................................18\nConcerns & Limitations............................................................................................................................19\nStrategies to Ensure More Accurate Responses from LLMs.................................................................20\nHow to Use genai Responsibly EVERY Time................................................................................................ 21\nRethinking Plagiarism and Cheating in the Age of genai.............................................................................22\nDisclosing genai Use or Citing genai as a Source...........................................................................23\nUse Caution with genai Detectors.................................................................................................................23\nTeacher Use Cases of genai....................................................................................................... 25\nProviding Student Feedback Using genai.................................................................................. 26\nStudent Use of genai...................................................................................................................27", "#### Approach to genai\n\nMany schools and districts opted to block access to genai tools in the spring of 2022 to allow time to learn more\nabout the potential issues and educational impact of genai.\n\nMany who originally blocked access to genai tools have\nsince allowed these tools at least for teachers, but many continue to block access for students.\n\nTeachAI, in the Teach genai Toolkit points out that \u201cAttempting to enforce broad bans on genai is a futile effort that\nwidens the digital divide between students with independent access to genai on personal devices and students\ndependent on school or community resources.\n\nClosing the digital divide in an age of genai still begins with internet\nconnectivity, device availability, and basic digital literacy.\u201d Public schools are the best hope for closing the\ndigital divide by ensuring equal opportunity to learn about and with genai for all students to prepare\nthem to be competitive in the current and future job market.\n\nHowever, it is important to ensure that genai is\nimplemented responsibly by all stakeholders to ensure safety and privacy, and responsible ethical use.\n\nThe US Dept.\n\nof Education\u2019s \u201c genai and the Future of Teaching and Learning: Insights and\nRecommendations \u201d included an analogy that suggests genai and other genai tools should provide a\ntechnology-enhanced future more like an electric bike and less like a robot vacuum.\n\nWhile robot vacuums do\nthe user\u2019s job without human involvement or oversight, when using an e-bike the human is both fully aware and\nfully in control, but the user\u2019s burden is lessened and their effort is multiplied by a complementary\ntechnological enhancement.\n\nTo further expand on this analogy for educational applications of genai,\nthe graphic below compares the use of genai to three different types of bikes.\n\nThis analogy\ndemonstrates that without genai, some students\u2019 struggles will inhibit learning, like a mountain bike; while with too\nmuch reliance on and lack of understanding of genai is unpredictable and can even be harmful like a motorcycle.\n\nIdeally, genai would be used like an E bike, with the human in control.\n\nThis analogy demonstrates using genai as a\nlearning partner, to help reduce struggles, support individual needs, and result in more productive learning, but\nalways with human oversight and control.\n\nThe 3 Bikes Analogy graphic may be accessed for downloading and printing by clicking the image.\n\nDirect questions about this document to  or \n\n\n-----", "#### 10 Top Skills from Future of Jobs Report & NC Portrait of a Graduate\n\nThe World Economic Forum\u2019s Future of Jobs Report studies a vast data set from global companies each year\nto make predictions on the future of work for the next five years in the future.\n\nIn their 2023 report, the 10 top skills that will be the most important for students to possess in order to be\npoised for success in the near future align remarkably well with the 7 durable skills that are highlighted in North\nCarolina\u2019s Portrait of a Graduate.\n\nWhile they may use different terms, many of the same human skills are highlighted in both are synonymous,\nsuch as \u2018curiosity and lifelong learning\u2019 and \u2018Learner\u2019s Mindset\u2019.\n\nIn a future in which many things can be completed faster and\nperhaps better by genai, companies will value and\nseek after the human skills that are the focus of the North Carolina Portrait of the Graduate: adaptability,\ncollaboration, communication, critical thinking, empathy, learner\u2019s mindset, and personal responsibility.\n\nThese\nare skills that can not be replicated by genai, and they will be highly valued.\n\nIn addition to these durable human skills, students will need to be genai Literate and able to effectively work with\ngenai as a partner.\n\nTo truly prepare students for the world they will graduate into, whether they graduate in 2024 or\n2034, all these durable skills and genai Literacy should be infused into all grade levels and all curriculum areas.\n\nThis document aims to help education leaders adapt to these new realities, implement genai\nresponsibly in their schools, and provide guidance for infusing genai Literacy into all grade levels and curriculum\nareas.\n\nDirect questions about this document to  or \n\n\n-----", "#### Responsible Implementation\n\ngenai, while not perfect, is a powerful tool that can be used by educators and students alike to expand\ntheir own abilities.\n\nIf implemented thoughtfully and responsibly, genai has the potential to transform\nteaching and learning in profound ways such as:\n\n-  Assisting both teachers and students in managing their workload more efficiently through the\nautomation of routine administrative tasks.\n\nThis support enables teachers to concentrate more on\nengaging directly with students, resulting in improved learning outcomes.\n\n-  Offering additional learning support to students outside of regular school hours, including tutoring and\nresource assistance.\n\nThis is particularly beneficial for students lacking access to educational resources\nor assistance at home.\n\n-  Enabling teachers to customize learning experiences and develop lessons and materials specifically\ndesigned for individual student needs.\n\n-  Adapting teaching methods to suit different learning preferences and providing focused help where\nneeded, reducing gaps in educational achievement by analyzing student performance data.\n\n-  Enhancing accessibility for underrepresented groups in education, including providing translation tools\nfor students who speak multiple languages, voice-to-text and text-to-voice options for students with\nphysical challenges or learning disabilities, and planning tools for those requiring assistance in\nexecutive functioning.\n\nThe responsible implementation of genai into NC K12 schools can help close the digital divide,\nreducing disparities that currently exist, and creating educational environments that are more inclusive.\n\nAdditionally, responsible implementation will prepare students for a future in which genai is sure to be integral to\nall aspects of their lives.\n\nHowever, ignoring genai or not implementing it responsibly and equitably, can\nhave the opposite effect, increasing the disparities that put many students at a disadvantage and increasing\nthe digital divide.\n\nMany educators fear that genai can provide misinformation or can become a method for cheating on\nassignments.\n\nAs genai becomes more commonplace in all aspects of life, it is imperative that educators adapt to\nthis new reality and rethink current attitudes about plagiarism and cheating.\n\nRather, a\nTeachers should educate students about the responsible use of genai, promoting the values of honesty,\ncritical thinking, and originality in academic endeavors.\n\nResponsible genai implementation, thorough oversight, and educational awareness that includes genai\nLiteracy for all users including all students is essential.\n\nMore guidance on genai Literacy is in the Human Capacity\nsection of this document.\n\nImplementing rigorous quality checks and validation processes when using\ngenai-powered educational tools ensures that the information provided is accurate, reliable, free from\nbias and that it aligns with educational objectives.\n\nDirect questions about this document to  or \n\n\n-----", "#### 1.\n\nEstablish a Foundation\n\n\u25cb Host an introductory meeting & training for district & school leaders, board, student leaders & other\nkey decision makers\n\n\u25cb Create a team to develop PSU-wide genai academic guidelines (or adapt current academic\nintegrity/acceptable use policies to include genai).\n\nInclude leaders, teachers, students, &\ncommunity members.\n\n\u25cb Review current EdTech providers deploying genai to vet their safety, privacy, reliability, and\nefficacy, to determine if they are appropriate to be used for your school, and which users they will be\nopen to based on their Terms of Service and school or district policies.", "#### 2.\n\nDevelop Your Staff\n\n\u25cb To ensure successful implementation, targeted professional development for educators on generative\ngenai including its impact, effective use, capabilities, limitations, concerns & responsible genai\nuse should be provided for all staff.\n\n\u25cb Share PSU genai guidelines draft for feedback; work with teachers on what the guidelines mean for their\nclassroom\n\n\u25cb Support teachers in updating their syllabi and/or classroom policies to include genai integrity guidelines\nthat align with PSU guidelines\n\n\u25cb Work with teachers to help them rethink plagiarism and academic integrity in the genai Age and support\nthem in shifting assessments to genai-resistant, genai-assisted, & genai-partnered versions", "#### 3.\n\nEducate Students & Community\n\n\u25cb Share genai guidelines at school-wide events including parents and guardians to build common\nunderstanding\n\n\u25cb Teachers review guidelines in each classroom along with syllabi & examples of appropriate &\ninappropriate student use\n\n\u25cb Implement genai training to upskill students and ensure they are prepared to mitigate any\nbiases, inaccuracies or issues that may arise and utilize genai effectively as a learning partner.\n\n\u25cb Provide content reviews and ongoing opportunities for training and learning to teachers and the\nschool community", "#### 4.\n\nAssess and Progress\n\n\u25cb Create a plan for constant review & reevaluation of academic guidelines in light of genai evolution and\nadvances\n\n\u25cb Evaluate new genai tools for appropriateness to launch pilot programs\n\n\u25cb Continuous updating & training across school community including sharing exemplars & opportunity\nto express concerns\n\n\u25cb Elevate best practices for genai implementation from across community & partners\n\nDirect questions about this document to  or \n\n\n-----", "#### PSU genai Guidelines\n\nTo ensure equity of access and responsible use of genai by all stakeholders, it is recommended to\ndevelop district-wide guidelines that detail the acceptable and responsible use of genai.\n\nMany districts\nare choosing to adapt current acceptable use or academic integrity policies to specifically include genai\nnow to provide much needed timely guidance, rather than drafting new policies at this time.\n\nSome plan to\ndevelop full policies at a later date.\n\nIt is recommended to note in any policy or guidelines that they may need to\nbe adapted as genai is changing rapidly.\n\nIn addition to adapting or creating guidelines and or policies, PSUs should work to build a common\nunderstanding and common language.\n\nFollowing the creation and dissemination of district-wide guidance, a\ncomprehensive genai Literacy training plan should be developed to ensure that all users are trained specifically in\nthe responsible, safe, and ethical use of genai.\n\nStaff should receive training first with guided practice\nfollowed by a practice period of at least 4-6 weeks to gain adequate understanding and competency and to\nexpress and discuss any concerns or issues in using genai tools before generalizing use with students.\n\ngenai guidelines/policies as well as any Data Sharing Agreements should be carefully evaluated when\nmaking decisions about which tools to allow for students.\n\nAs with any digital tool, Public School Units should\nfollow the terms of service, including appropriate age limits and seeking parental consent if required.\n\nIt is\nrecommended to consult with the technology director and, if needed, legal counsel, in evaluating the terms of\nservice.\n\nMost Large Language Models such as ChatGPT, Google Bard, Bing.com/chat, and Perplexity are currently\nprohibited for ages under 13 per their terms of service, but are allowed for ages 13 and over with varying\nparental/guardian permission requirements.\n\nIf your PSU decides to utilize a tool with students that requires\nparent/guardian permission, or if you decide to require parent/guardian permission for other tools, you may\nchoose to customize this Example genai Permission Form .\n\nIn some cases, it may be appropriate to include genai tool permissions in other technology policies.\n\nRegardless of\nwhether an genai permission form is deemed necessary by the PSU, all staff and student users as well as all\nparent/guardians should be made aware of the school or PSU\u2019s genai guidelines, including any\nacademic integrity or acceptable use guidelines that reference the use and disclosure of genai and\nplagiarism.\n\nThese guidelines should also be signed by both students and parents.\n\nYou may reference this\nspreadsheet for a comparison of LLM models .\n\nSome school and district leaders may be hesitant to allow tools such as ChatGPT or Google Bard for students\neven if they are 13 and over.\n\nAn encouraging trend for K12 education is that built-for education models are\nbeing developed and may help alleviate these concerns, though they may come with a cost.\n\nNCDPI does not endorse any company or product, but one example of a built-for-education model is Khan\nAcademy\u2019s Khanmigo (  ), a personal assistant for teachers and a\npersonal tutor for students.\n\nAnother promising model is Magic School magicschool.genai , which already has a\nfree robust teacher platform and is introducing Magic School Student in early 2024.\n\nOther education focused\nmodels are likely to go to market in 2024, so education leaders should soon have more choice in safe,\nbuilt-for-education models for students to learn with and about genai.\n\nDirect questions about this document to  or \n\n\n-----", "#### Evaluating genai Ed Tech Tools\n\nAdapted from genai for Education\u2019s \u201c Top 6 Questions for Schools to Ask genai Edtech Companies \u201d\n\n**genai Capabilities and Limitations**\ngenai is a new technology with extensive limitations.\n\n-  What controls are in place to identify and lower hallucinations?\n\n-  Are responses accompanied by links to reliable sources to verify the information?\n\n-  Does the tool include an easy way to share the genai Chat so teachers can monitor student use for school\nwork?", "**Mitigating Bias**\n\nIt\u2019s important that the tools we use do not cause harm to our students or teachers.\n\n-  What steps have been or are being taken to identify and mitigate biases?\n\n-  How are fair and unbiased outputs supported?\n\n-  How can users report instances of bias if they encounter them in genai responses?", "**Accessibility and Inclusive Design**\n\nOur school needs to accommodate diverse learners and varying technical skills among staff.\n\n-  How does the tool ensure accessibility and usability for all our students and staff?\n\n-  How can these tools be used to provide additional support and personalization for students with IEPs,\n504s, English Language Learners, economically disadvantaged students, marginalized student groups\nand others?", "**Cybersecurity**\n\nHow can we be sure we are minimizing any potential risks to our networks and our users?\n\n-  What security practices are you implementing to protect our user and organizational data?\n\n-  How do your security practices meet or exceed applicable PSU, State, and Federal requirements\nincluding the new NC Third Party Data Integration requirements?\n\nDirect questions about this document to  or \n\n\n-----", "**Guiding Questions**\n\n-  How are students using genai?\n\nHow are teachers?\n\n-  What was the impact of the release of ChatGPT and other generative Al tools on your school?\n\n-  What are your biggest concerns about genai this year?\n\n-  What are the major ethical concerns your school has about GenAl?\n\n-  How can you adapt your current academic integrity policy to include GenAl?\n\n-  How can the use of genai tools help students with IEP , 504, language barriers, and other learning\n\nneeds?", "**Key Steps**\n\n-  Create a common understanding of Generative Al for all stakeholders through Al literacy.\n\n-  Design a clear set of guidelines that work for both students and teachers.\n\n-  Partner with stakeholders, including students, to develop and socialize the policy.\n\n-  Identify that the policy is a work in progress.\n\n-  Provide examples of the policy in stakeholder-specific language.", "**What to Include**\n\n-  Appropriate Use of generative Al Tools\n\n\u25cb Identify what types of assignments and assessments can be Al-assisted with teacher approval\nand which must be completed without GenAl support\n\n\u25cb Provide examples of inappropriate use cases and appropriate use cases.\n\n-  Tracking and Citing generative Al\n\n\u25cb Provide guidelines on how students and teachers should track and cite their use of GenAl for\ntheir school work/practice\n\n\u25cb Provide examples of proper genai disclosure statements and citations in the correct format\n\n-  Data Privacy and Security\n\n\u25cb Clearly define what student, teacher, and school personally identifiable information (PII)\nincludes.\n\n\u25cb Remind all users that PII is off-limits to generative Al tools (including uploading or pasting in of\ndata into genAI models as well as typing it in a cha)\n\n\u25cb Provide a refresher for educators of student data privacy & FERPA\n\nDirect questions about this document to  or \n\n\n-----", "**Common Issues to Consider**\n\n-  Educators should only use genai for formative evaluation and the educator should always be in\nthe loop, reading all student work and genai-generated comments.\n\n\u25cb Grading with genai tools can be unreliable due to inaccuracies or \u2018hallucinations\u2019 and\nimplicit bias in genai tools.\n\n-  genai detectors are not reliable.\n\n\u25cb They often create false positives, penalizing non-native speakers and creative writing styles.\n\n\u25cb They often create false negatives for skillful genai prompters who know how to fool the genai.\n\n-  genai tools may make up incorrect information, a phenomenon known as \u2018hallucination\u2019.\n\nUsers\nmust be trained to verify all data, facts, quotes, etc.\n\n-  All users need explicit training on protecting data privacy, including reminders of what constitutes\nPersonally Identifiable Information (PII).", "**Strategies for Introducing the Policy at the\u2026**\n\n|Faculty|School|Class|\n|---|---|---|\n|Kick-off Assembly|Open House or Parent Meeting|Personal Scenarios|\n|Faculty Meetings; PLC Meetings|Interactive Presentation|Teach, model, discuss and reinforce responsible use|\n|Case Studies, Debates|genai Literacy Week|Case Studies, Debates|\n|Policy Exploration Workshops|Teach, model, discuss and reinforce acceptable responsible genai Use by Staff and Students including examples of appropriate vs inappropriate use||\n|Peer Educators|Build common language around genai by teaching & posting graphics such as CRAFT & EVERY framework, genai Acceptable Use Assessment Scale etc in classrooms||\n\n\n\nDirect questions about this document to  or \n\n\n-----", "#### Example genai Amendment to School Integrity Policy\n\nAdapted from genai for Education \u2018Guide to Developing an genai Policy For Your School\u2019\n\n\ngenai (genai) tools like ChatGPT are a significant technological advancement\nthat has the potential to support your learning.\n\nBut with any new technology, there are significant limitations\nand risks associated with its use, misuse, and overuse.\n\nTo support appropriate, responsible use of genai in your learning, these steps should be taken when\ndetermining if, how, and when to use genai tools.\n\nIf these steps are not followed, your use of generative\ngenai tools will be considered an academic integrity violation.", "**Step 1**\n\nCheck with your teacher to find out if the assignment, homework, project, or assessment can be completed\nwith the support of a genai tool, and if so, the level of genai support that is allowed (School and\ndistrict leaders may wish to utilize or modify the genai Acceptable Use Scale here to build common\nunderstanding and language about accepteds level of use).", "**Step 2**\n\nIf genai is allowed and used, share your conversations with the tool by adding the share link to the chat\non your final product or works cited page so that your teacher can evaluate your learning process and how you\npartnered with the genai model, as well as your final product.", "**Step 3**\n\nDisclose all use of genai tools according to your school\u2019s policy.\n\nThis may include disclosure statements or formal\ncitations, as directed by the teacher for the particular assignment.\n\n|Examples of Appropriate genai Use|Examples of Inappropriate genai Use|\n|---|---|\n|Explain topic in a way that I can understand|Using genai without permission from teacher|\n|Help me brainstorm & explore ideas|Completing an entire assignment, homework, or assessment with genai|\n|Help me study for an upcoming assessment|Not reviewing & verifying genai response for hallucinations or inaccuracies|\n|Provide feedback on my work for areas of improvement|Not revising the genai output so that it refel cts your human voice and style|\n||Not being transparent about & disclosing or citing your work with genai|\n\n\nDirect questions about this document to  or \n\n\n-----", "#### genai Training and genai Literacy\n\nBecause genai is already transforming the way we live, and will continue to have an even greater impact\nin the future, it is imperative that primary and secondary schools in every district and school develop and\nimplement an genai Literacy program that provides all staff and students with the understanding of this powerful\ninnovative new technology.\n\nThe genai (genai) Literacy Act, recent bipartisan legislation that seeks to promote genai literacy in US\nschools, emphasizes a balanced focus on the foundational principles, applications, limitations and ethical\nimplications of genai.\n\nIts goal is to amend the Digital Equity Act to codify genai Literacy as a component\nof digital literacy, which indeed it is.\n\nThis genai Literacy act defines genai literacy as \u201cunderstanding of basic genai\nprinciples and applications, the skills to recognize when genai is employed, and awareness of its limits.\u201d The\nimportance of genai literacy is stressed in this act; \u201cgenai literacy empowers individuals to be informed decision\nmakers and benefits us all by preparing individuals to meaningfully engage in conversations about responsible\nand ethical development and use of genai.\n\nHaving an genai-literate population will help promote\nnational security and contribute to our economic competitiveness.\u201d\n\nThe miraculous speed of genai innovation in the past year has made it clear that genai is not going away and will\naffect all areas of our lives, as well as all people.\n\ngenai Literacy is digital literacy in the 21st century and beyond.\n\nIt\nis imperative that all schools and districts ensure all staff and students are genai literate, and that genai literacy is\ninfused in all curriculum areas.\n\nAfter establishing and sharing district-wide guidelines, it is crucial to develop a\ncomprehensive genai Literacy training strategy that involves training all staff and students to develop in the\neffective, ethical, and safe use of genai tools.\n\nGiven the risks associated with irresponsible use, it is\nimportant to ensure comprehensive and consistent training for all users.\n\nStaff members should receive training initially and should be provided adequate time to practice and attain\nproficiency with the tools before extending their use to students.\n\nThe North Carolina Department of Public\nInstruction strongly advocates for educators to undergo professional development focused on both utilizing\ngenai professionally and guiding students to effectively & ethically use genai as a learning\npartner.\n\nThis training should equip educators with the necessary knowledge to effectively employ genai\nin their work while ensuring its safe and responsible integration into classroom instruction.\n\nIt is also recommended that staff members have the opportunity to discuss their experiences, ask questions,\nexpress concerns, and provide feedback on the genai Implementation plan before they are responsible for\nintegrating genai use with age-appropriate student groups.\n\nWe have provided a list of high-quality, free professional development for education leaders, teachers and\nstudents in the appendix of this document.\n\nPlease see the Appendix for these recommendations.\n\nDirect questions about this document to  or \n\n\n-----", "#### genai Literacy for All\n\ngenai is already becoming ubiquitous.\n\nOne can\u2019t go online or on social media without encountering genai-generated\ncontent, even if it is not always recognized as genai-generated.Our students\u2019 levels of genai literacy will have profound\nimpacts on work, education, and all aspects of their lives in an genai-enhanced world in which humans interact\nwith genai increasingly more each day and in which the old mantra \u2018seeing is believing\u2019 no longer holds true.\n\nThe TeachAI Toolkit offers a more detailed definition of genai Literacy:\n\n\u201cgenai literacy refers to the knowledge, skills, and attitudes associated with how artificial\nintelligence works, including its principles, concepts, and applications, as well as how to use\ngenai, such as its limitations, implications, and ethical considerations.\u201d\n\nWhile specific guidelines for genai Literacy, especially in younger grades that are not allowed to use many of the\ngenai tools are not yet developed, the good news is that many of the standards that NC has already\nadopted such as Computer Science and the NC Digital Learning Standards for Students (ISTE Standards) will\nhelp support genai Literacy, by developing computational thinking, technological skills, and supporting the durable\nskills in NC Portrait of a Graduate (Adaptability, Collaboration, Communication, Critical Thinking, Empathy,\nLearner\u2019s Mindset, Personal Responsibility), that will be highly valued in the future.\n\ngenai Literacy will, however,\nrequire an increased emphasis on media literacy, critical thinking, and ethics.\n\nStudents will need to be able to\nwork alongside genai tools, think critically about media, and make ethical decisions about the use of genai tools and\ndissemination of content.\n\nInfusing genai literacy in all curriculum will ensure that our students are poised to\nsucceed.\n\nTo ensure responsible, safe, and ethical implementation of genai, staff and students who are of the age\nto use genai should be trained on safe, effective and responsible use including the following key\naspects, each of which is covered in more detail in the \u2018Curriculum and Assessment\u2019 section of this document.\n\n-  Alignment with PSU and school-based guidelines/policies governing genai usage.\n\n-  Building a basic understanding of genai: how it works, its power to transform learning, and the\nconcerns and limitations of current models.\n\n-  How genai impacts education, including potential future implications on the job market.\n\n-  Effective communicating with the Large Language models (prompting).\n\n-  Safe, Ethical Use and Disclosure of Use and PSU and school guidelines.\n\n-  genai as a Learning Partner to support curriculum standards, enhance human creativity & critical thinking.\n\nDirect questions about this document to  or \n\n\n-----", "**Middle grades:**\n\n-  View, evaluate, and create genai generated content using generative image tools in creative apps such as\nCanva and Adobe Express to enhance genai Literacy, creativity, collaboration and critical thinking.\n\n-  Middle school students may also benefit from awareness of potentially unsafe and irresponsible uses\nof genai such as in social media applications such as SnapChat MyAI and even in the video games they\nplay.", "**High school:**\n\n-  Dedicated genai training prior to utilizing genai Large Language Models like ChatGPT\nthat includes the components above similar to Staff training, but with a student lens of using genai as a\nlearning partner.\n\n-  Increase critical thinking and media literacy, focusing on genai Generated content online.\n\n-  View, evaluate, and create genai generated content using generative image tools in creative apps such as\nCanva and Adobe Express to enhance genai Literacy, creativity, collaboration and critical thinking.\n\n-  Students should gain awareness of the potentially unsafe and irresponsible uses of genai such as in social\nmedia applications such as SnapChat MyAI and even in the video games they play.\n\nDirect questions about this document to  or \n\n\n-----", "#### Large Language Models (LLMs)\n\nChatGPT is an example of a Large Language Model (LLM), a type of genai program\ndesigned to understand and generate human-like text.\n\nIt is similar to having a very knowledgeable assistant\nwho has read a vast amount of books and articles and can provide just-in-time assistance.\n\nThis assistant can\nanswer questions, write stories, and even help with homework, by using the information it has learned.\n\nSome\nother well-known LLM models are Bing Chat, Google Bard, Claude, & Perplexity.\n\nJust as you would review the\nwork of a capable assistant, the human user must also review the work of the LLM and make adjustments as\nneeded.\n\nWhen used skillfully, LLMs can have significant positive impacts on teachers by drastically reducing the time\nthat is required for tasks such as planning, creating content, assessing student work, and executing tasks such\nas emails and newsletters.\n\nThis reduction in time on task can result in a better work life balance and improved\njob satisfaction.\n\nIn addition to saving teachers a lot of time, utilizing genai LLM models can also open a whole new\nworld of ideas and creativity, which often revitalizes their passion for teaching.\n\nIt can give them more control\nover the content they create, allowing them to personalize content for their teaching style and their students\u2019\ndistinct needs rather than appropriating generic content from text books or online sources.\n\nPerhaps most\nimportantly, if used skillfully, these tools can allow educators more time to focus on the reasons they entered\nthe profession; building relationships with students and targeting their individual needs.\n\nFor students, genai can act as a learning partner to give them just-in-time assistance and guidance\nbased on their individual needs, helping to level the playing field for neurodivergent students, those with\nlearning needs, those who are not native speakers, those from economically disadvantaged or other historically\nmarginalized communities, and all students.\n\nLearning to work effectively with genai can also help\nprepare students for rewarding careers in their genai-rich future in which being able to work effectively with\ngenai will be an expectation.\n\nTo ensure teachers and students have the skills to realize the tremendous positive impact that genai can have on\neducation, educators need a basic understanding of how the models work.\n\nThey should know that LLMs are\ndifferent from search engines, and must be used differently for helpful results.\n\nIt is helpful to provide new users with a prompting framework that details how to effectively create a prompt to\nimprove results.\n\nThis will help ensure a positive introduction to LLMs and help ensure the users get the most\nefficient and effective results.\n\nOne such framework is the CRAFT genai Prompting framework by Vera Cubero\n(NCDPI) This frameworks using an acronym for the word CRAFT as a simple reminder to help guide educators\nand students alike remember how to craft prompts that get the most targeted and helpful results from the\nchatbot.\n\nDirect questions about this document to  or \n\n\n-----", "#### The CRAFT prompting framework:\n\nThis framework allows users to skip the learning curve and interact with the models in a way that will help\nthem see helpful and targeted results quickly, resulting in more successful introductions to LLMs such as Chat\nGPT, Google Bard, etc.\n\nA brief explanation of this framework with several example prompts can be accessed at\n .\n\nThe image below can be downloaded for printing as a poster by going to  .\n\n**genai for Education Prompt Library**\n\nAdditionally, educators and students alike would benefit from examining well-developed prompts such as those\nin the Prompt Library from genai for Education .\n\nThis terrific resource provides many examples of well-designed\nand effective prompts along with suggestions for further personalizing the prompts.\n\nThe prompts can be\ncopied, pasted into a model and then edited to suit the user\u2019s needs.\n\nAt the time of publishing, this valuable\nresource contains 100 prompt examples with many different uses for teachers and students.\n\nDirect questions about this document to  or \n\n\n-----", "**Data Privacy Concerns:**\n\nAll users must be taught the importance of protecting data privacy when using genai tools.\n\nUsers\nshould never input Personally Identifiable Information or PII.\n\ninto an genai tool (or anywhere else without careful\nconsideration)!!!\n\nStudent ID Numbers are PII.\n\nBe especially mindful of this when pasting data into the model or\nuploading any data that may contain PII.", "**Bias:**\n\nBecause genai models are trained on the Internet, there is always the potential for inherent societal\nbiases surrounding gender roles, race, religion, and politics.\n\nWhile genai companies are focused on fine tuning their models to ensure that they do not perpetuate stereotypes\nor biases, such biases are always possible because the training data set includes the entire Internet.\n\nSchools\nand districts must be prepared to mitigate potential issues that arise from bias within the use of genai.\n\ngenai models\nhave a built in evaluation (thumbs up/down) and an option to include a comment.\n\nIf bias is suspected or\ndetected, this is one way to report it to the company that produces the tool.\n\nEstablishing clear methods of\ncommunicating concerns with genai systems deployed within their educational environments is also needed at\nthe school or district level.\n\nBias mitigation techniques should be included in genai Literacy training to educators\nand students including how to identify and address biases in genai-generated content at the school or district\nlevel.", "**Inaccuracies/\u2018hallucinations\u2019:**\n\nLarge Language Models like ChatGPT are not search engines and these models actually generate content by\nmaking predictions based on their training data and the user input or prompt.\n\nThey do not search for and\nreturn content that already exists as search engines do.\n\nBecause of this, LLMs have the potential of generating\n(predicting) content that is not factually correct, but sounds very plausible.\n\nThis phenomenon is commonly\nreferred to as \u2018hallucinations\u2019.\n\ngenai developers are constantly fine tuning their models to reduce hallucinations,\nbut because of the way the models work, it may not be possible to eliminate them entirely, at least for some\ntime.\n\nTherefore, it is essential that users understand this and are trained to verify all facts, quotes, statistics,\nand resources in genai responses using dependable online sources.\n\nThe most effective use of genai LLMs is by a user with knowledge of the subject matter, and who is\ntherefore more likely to notice and question inaccuracies.\n\nIt is especially important to verify data with reliable\nsources if the user is not a subject matter expert on the topic as they are much less likely to recognize\ninaccuracies if they do occur.\n\nSome LLM models provide links in their responses to make fact checking\nresponses easier (such as Bing Chat & Perplexity) while Google Bard has a built-in mechanism for the user to\nverify the information by clicking the G beneath a response.\n\nUnder 18 users are guided through this on their\nfirst fact based prompt as part of Bard\u2019s genai guidance for students.\n\nDirect questions about this document to  or \n\n\n-----", "#### Strategies to Ensure More Accurate Responses from LLMs\n\nWhile there currently is no foolproof way to completely eliminate the possibility of genai models\nproviding inaccurate information or hallucinations, there are prompting strategies that users can employ to\nreduce the likelihood of inaccuracies.\n\nThe following handout outlines five strategies to ensure more accurate\nresponses by LLMs.\n\nYou may download this as a poster by going to \n\nDirect questions about this document to  or \n\n\n-----", "#### How to Use genai Responsibly EVERY Time\n\nThe EVERY framework provides an acronym to remind users of the steps needed to ensure ethical use of genai by\nstaff and students alike, EVERY time genai is used.\n\nThis framework was a collaboration between genai for Education\n(aiforeducation.io) and Vera Cubero (NCDPI).\n\nTo download a printable pdf of the EVERY framework, visit\n\n\nDirect questions about this document to  or \n\n\n-----", "#### Rethinking Plagiarism and Cheating in the Age of genai\n\nIn the not-too-distant future, it will be a common assumption that all writing from academic papers to news\nreports and emails may be written with genai.\n\nIn light of this, it is perhaps shortsighted to automatically consider\nall use of genai as \u2018cheating\u2019.\n\nEducators will need to rethink their ideas of what constitutes plagiarism and cheating\nin today\u2019s world, and adapt their teaching, assignments, and expectations to this new reality.\n\nAn genai Acceptable Use Scale is an important part of a school or PSU\u2019s genai adoption plan to help build\ncommon understanding, clear expectations, and common language around the use of genai by students.\n\nThe\nscale should be referred to clarify what level, if any, is acceptable use of genai on a given task.\n\nIt should be\nexplicitly taught and posted in visible locations for reference.\n\nThe following genai assessment scale was adapted for the K12 environment by Vera Cubero (NCDPI).\n\nIt is based\non the original work of Dr. Leon Furze, Dr. Mike Perkins, Dr. Jasper Roe FHEA, & Dr. Jason Mcvaugh.\n\nThis\nversion of the scale includes five levels of genai Assessment (0-4) with descriptions of each along with disclosure\nor citation recommendations.\n\nA scale such as this can help build the common understanding and language to\nensure fair and equitable treatment of issues of suspected plagiarism or cheating with genai in the K12 setting.\n\nTo download click the image below or visit  .\n\nThe lower corner\nincludes an editable template link if you would like to modify it to suit your particular needs.\n\nDirect questions about this document to  or \n\n\n-----", "#### Disclosing genai Use or Citing genai as a Source\n\nEducators should lead by example and model transparency and academic honesty about their use of\ngenai tools, and teach students to do the same.\n\nBecause today\u2019s genai tools can not actually\ncreate content without some level of human participation and guidance, it is generally considered best practice\nto acknowledge the use or partnership with the genai tool when a formal citation is not required.\n\nBecause genai is so new, there will likely be further litigation surrounding genai and copyright.\n\nOne issue\nthat was decided on 8/18/2023 by the US District Court for the District of Columbia in a federal decision is that\na work created entirely by genai can not be copyrighted.\n\nReference Thaler v Perlmutter, Case No\n1:22-cv-01564 (D.D.C2022).\n\nAlso, genai can not be considered the sole author or creator of a work.\n\nIf traditional citations are not required, but any form of genai assistance was used, it is recommended to include in\nthe disclosure statement how genai was used (brainstorming, outlining, feedback, editing, etc).\n\nDisclosure\nstatements can be included in an \"genai Credits\" section at the end of the work or within the text, beneath an\nimage, etc as appropriate.\n\nA link to genai chats can be shared on most major LLM platforms and this is a great way for teachers to see a\nstudent's learning process and how the student relied on or partnered with the genai to complete the work.\n\n**Example disclosure statements** :\n\n-  \u201cCreated by John Doe with editing assistance from ChatGPT\u201d\n\n-  \u201cI used Google Bard to help me brainstorm ideas for my project\u201d\n\n-  \u201cI used ChatGPT to help me organize my thoughts into a finished product\u201d\n\n-  \u201cImage created in partnership with Adobe Firefly.\n\nPrompt; \u2018create a cartoonish image of a bored frog\non a lily pad, surrounded by cattails.\n\n16:9 Make it bright and colorful so that young children would\nenjoy it.\u2019", "#### Use Caution with genai Detectors\n\ngenai detectors have proven not to be dependable, therefore they should never be used as the only factor when\ndetermining if a student \u2018cheated\u2019.\n\nCommon issues with genai detectors are a high frequency of false positives for\nnon native English speakers and creative writers as well as a high frequency of false negatives for students\nwho are skilled at working with genai and are capable of fooling the detectors.\n\nIf there is suspicion that a student\ndepended on genai too heavily for an assignment, this should be viewed as a teachable moment to reinforce the\nappropriate partnership with genai tools rather than a \u2018gotcha\u2019 moment.\n\nWorking with genai in many ways is the same\nas working with a tutor, asking a parent for assistance, or completing an assignment with a partner or a\ncollaborative group.\n\nIn the age of genai, it is important to focus on student reflection on the process of learning,\nrather than just the end product.\n\nEducators should ensure proper communication about appropriate uses of genai on each assignment, referencing\nan genai Acceptable Use Scale such as the one provided on the previous page to clarify appropriate level of\ngenai as this may vary from assignment to assignment and class to class.\n\nThis graphic by Holly Clark of The Infused Classroom, is an excellent visual aid to demonstrate why genai\ndetectors are problematic and what to do instead.\n\nImage credit: Use with permission from Holly Clark of The Infused Classroom,\n\n\nDirect questions about this document to  or \n\n\n-----", "#### Teacher Use Cases of genai\n\ngenai can be used by educators to support their daily work tasks and transform the student learning experience in\na variety of ways that can help reduce the burden of teaching as well as improve educators\u2019 ability to\npersonalize learning for their students, thus improving teaching and learning.\n\nMany educators who skillfully use genai in their lesson planning have reported a renewed passion for\ntheir content because of genai\u2019s potential to help them develop engaging new lessons and activities\nthat are personalized to their own teaching style, as well as student abilities and needs.\n\nFurthermore, using\ngenai to automate routine, mundane tasks can free up time for teachers to focus on higher order\nthinking tasks, problem solving, collaboration, and making human connections with their students.\n\nThere are several areas in which genai can support teachers in both developing and delivering more effective and\npersonalized lessons (this is not an exhaustive list- the possibilities are endless):\n\n-  **Brainstorming/Thought Partner:** Large Language Models like ChatGPT and Google Bard have access to\nso much information and are fantastic to brainstorm and get fresh ideas.\n\nTeachers can utilize\ngenai as a thought partner to bring new life into old lessons, brainstorm ideas for projects, labs,\nand assignments, solve educational problems of practice such as behavior issues, learning to better\nmeet the needs of diverse learners, implementing new strategies, and just about any other issue they\nface in the classroom.\n\n-  **Content creation tools** : genai can assist teachers in creating engaging and interactive lesson materials,\nsuch as presentations, simulations, games, and more.\n\n-  **Efficient assistant:** Being able to use Large Language Models for completing the mundane tasks such\nas emails, newsletters, creating rubrics etc frees up teachers to do more creative tasks, make\nconnections with students, and improve their work life balance.\n\n-  **Personalization** : genai can help teachers create adapted learning content that meets a student\u2019s individual\nlearning style, reading level, language, pace etc and can save educators time in personalizing content to\nmeet a variety of student needs.\n\n-  **Data-driven decision making** : genai can provide teachers with real-time insights into student performance,\nallowing them to identify areas of strength and weakness and adjust their instruction accordingly.\n\n-  **Automated grading and feedback** : genai can automate the grading of quizzes and essays, freeing up\nteacher time for more personalized instruction and feedback.\n\n-  **Creative Assistant** : Use image generator tools such as Adobe Firefly, Canva, etc to create the images\nyou need using plain language instead of searching for hours for them.\n\nDirect questions about this document to  or \n\n\n-----", "#### Providing Student Feedback Using genai\n\ngenai tools can reduce a lot of the time spent in assessing student work, which is one of the most time\nconsuming tasks for most educators.\n\ngenai can save considerable time in evaluating student writing in\n\naddition to the other potential benefits below.\n\ngenai has the potential to revolutionize assessment by:\n\n-  **Lending Objectivity** : genai tools can lend objectivity to the assessment of student work.\n\n-  **Alleviating Writers\u2019 block** : genai tools are a great starting point for formulating comments,\nhelping teachers find words that reflect the tone and purpose they wish to convey\n\n-  **Analyzing complex student responses** : genai algorithms can analyze student-drawn models and group\nthem based on similarities, helping teachers understand student understanding of complex concepts\nlike \"rate of change.\"\n\n-  **Providing instant feedback:** genai can offer immediate feedback on complex skills like learning sign\nlanguage or speaking a foreign language, even when a human instructor is unavailable.\n\n-  **Lightening teachers' workload** : genai assistants can grade simple aspects of student work, freeing up\nteachers' time to focus on more complex tasks like evaluating essays and projects.\n\n-  **Enhancing accessibility** : genai-powered learning technologies can provide verbal feedback to students,\nmaking learning more accessible for all students, including those with disabilities.\n\n-  **Embedding feedback into the learning process** : genai can provide real-time feedback to students while\nthey are working on a problem, helping them identify errors and improve their understanding before\nthey submit their work.\n\nHowever, it is imperative with today\u2019s genai tools that teachers use genai for assessment and\ngrading with some specific guidelines in mind:\n\n**Formative Assessment Only** : Today\u2019s genai should be used only for formative assessment.\n\n-  Today\u2019s Large Language Models and other genai tools are new technology and not\n\ncompletely reliable, therefore should not be used to assign letter or number grades to student work.\n\n**Humans must always be in the loop** to ensure fair and equitable treatment of student work.\n\n-  The teacher should always review student work and evaluate and edit as needed any genai generated\ncomments before sharing with students.\n\n-  Teachers should understand the potential for \u2018hallucinations\u2019 and how they can mitigate this when\nusing genai to evaluate student work.\n\n-  For example, LLMs are more likely to hallucinate if you ask for something that doesn\u2019t exist, such as\nasking it to \u2018identify all the grammatical errors in this passage\u2019.\n\nIf there are no grammatical errors, it\nmay \u2018find\u2019 some anyway because you asked it to.\n\nInstead, asking it to \u2018evaluate the writing for\ngrammatical usage\u2019 would be less likely to produce hallucinations.\n\nDirect questions about this document to  or \n\n\n-----", "#### Student Use of genai\n\ngenai has enormous potential to improve student learning outcomes and erase the discrepancies that\nnow exist in access to education for economically disadvantaged students, students with learning disabilities,\nEnglish Language Learners, neurodivergent students as well as all other students.\n\nBelow are a few examples of\nthe ways genai can aid students in learning, and new developments are sure to continue to emerge as\nwell.\n\n**Learning Partner & Personal Tutor** :\n\n-  genai tools can provide just-in-time, objective and targeted assistance, feedback and guidance\nto students.\n\n-  genai can help explain difficult concepts, provide evaluation and feedback, help generate ideas,\nact as a thought partner, debate, partner, a character from fiction, history, a career, and more.\n\nThe\npossibilities are endless.\n\n-  Adaptive learning platforms: Students can use genai-powered platforms that adjust the difficulty and pace\nof learning materials based on their individual performance.\n\nThis ensures they are challenged but not\noverwhelmed.\n\n**Self-Directed Learning** :\n\n-  genai-powered research assistants: Students can use genai assistants to find relevant information and\nresources for their research projects.\n\n-  Learning simulations: Students can participate in genai-powered simulations that allow them to explore\ncomplex concepts and practice applying their knowledge in a safe environment.\n\n-  genai-powered writing tools: Students can use genai tools to brainstorm ideas, check their own work for\nplagiarism, and improve their writing skills.\n\n**Creativity and Collaboration** :\n\n-  Collaborative learning platforms: Students can use genai-powered platforms to collaborate with peers on\nprojects, share ideas, and receive feedback from peers and teachers.\n\n-  Generative image generators such as Adobe Firefly, Adobe Express, Canva, and others provide\nstudents the ability to explore their creativity in new ways by using natural language input to create new\nworks of art for self expression, illustrate their own writing, or demonstrate learning.\n\n**Accessibility Tools** :\n\n-  Text-to-speech and speech-to-text tools: Students with disabilities can use genai tools to access learning\nmaterials and communicate more effectively.\n\n-  Translation tools: Students who are learning English or another language can use genai tools to translate\ntext and audio content.\n\nDirect questions about this document to  or \n\n\n-----", "**Data Privacy**\n\nFERPA defines the term personally identifiable information (PII) to include direct identifiers (such as a student's\nor other family member's name) and indirect identifiers (such as a student's date of birth, place of birth, or\nmother's maiden name).\n\nLLM models such as ChatGPT utilize user input in the form of chats to continue training the models.\n\nTherefore\nit is imperative that users fully understand what PII is, and learn NOT to enter, paste, or upload any PII into the\nchat of any genai tool.\n\nAll users should be reminded of what data is considered PII, and that it includes\nstudent ID numbers.\n\nUsers should use caution in particular to avoid inadvertently copying or uploading PII into\nthe model when evaluating student responses, analyzing data, or creating personalized content such as IEP\ngoals, personalized learning plans, etc.", "**Reviewing and Adapting Guidelines**\n\nSchool districts and schools must continuously review and adapt their genai guidelines to keep pace with the rapid\nevolution of genai technologies.\n\nThis involves regular assessments of genai practices, potential risks, and emerging\ntrends to maintain responsible and ethical integration.\n\nAll PSUs engaging with genai technologies should regularly\nreview the company\u2019s usage and privacy guidelines.\n\n**Usage** : PSUs, schools, educators and students that are utilizing any type of genai tools adhere to specific usage\nrequirements outlined by the tool's developer or provider.\n\nThis includes complying with age restrictions, data\nusage practices, any restrictions, inclusivity, limitations, notifications, and any other relevant guidelines or\nrestrictions.\n\nThis should include awareness and procedures in place regarding, but not limited to following\nCOPPA, CIPPA, IDEA, FERPA, and section 504.\n\nDirect questions about this document to  or \n\n\n-----", "#### Relevant Policies in the US\n\n**FERPA** -  Family Educational Rights and Privacy Act: Protects the privacy of student education records & gives\nparents certain rights regarding student education records\n\n-  genai systems must protect the privacy of student education records and comply with parental consent\nrequirements.\n\nData must remain within the direct control of the educational institution.\n\n**COPPA** -  Children\u2019s Online Privacy Protection Act: Imposes requirements on websites and online services\ndirected to children under 13 years of age, or that collect personal information from a child under 13.\n\n-  genai chatbots, personalized learning platforms, and other technologies collecting personal information\nand user data on children under 13 must require parental consent.\n\n**IDEA** -  Individuals with Disabilities Education Act: Ensures students with disabilities are provided with free\nappropriate education that is tailored to their individual needs.\n\n-  genai must not be implemented in a way that denies disabled students equal access to education\nopportunities.\n\n-  genai tools can be used to help meet students\u2019 individual needs and help provide them with independence\nand equal access to learning content.\n\n-  genai tools can be used to help relieve the burden of meeting each student\u2019s individual needs.\n\n**CIPA** -  Children\u2019s Internet Protection Act: Requires schools and libraries that receive federal funds for Internet\naccess or internal connections to adopt and enforce policies to protect minors from harmful content online.\n\n-  Schools must ensure genai content filters align with CIPA protections against harmful content.\n\n**Section 504** -  A federal law designed to protect the rights of individuals with disabilities in programs that\nreceive federal financial assistance from the US Department of Education.\n\n-  This section of the Rehabilitation Act applies to both physical and digital environments.\n\n-  Schools must ensure that their digital content and technologies, like genai, are accessible to students with\ndisabilities.\n\nDirect questions about this document to  or \n\n\n-----", "#### Purchasing and Using genai Technologies:\n\nWhen it comes to investing in technologies to support learning with and about genai, it is\nimportant to ensure that the technology resources:\n\n-  **Are Age Appropriate for the User of the genai Technology:**\n\n\u25cb Pay special attention to age allowances of the technology to ensure compliance with federal,\nstate, and local laws and policies as well as age limits and permission requirements in the terms\nof service for each application.\n\n-  **Comply with Regulations:**\n\n\u25cb Prioritize technologies that comply with federal, state, and local regulations regarding data\nprivacy and cybersecurity in educational settings.\n\nFamiliarize yourself with regulations like the\nFamily Educational Rights and Privacy Act (FERPA) in the United States and similar laws in other\nregions.\n\n-  **Secure Access Controls** :\n\n\u25cb Implement secure access controls to ensure that only authorized individuals have access to\nsensitive student data.\n\nThis includes usernames, passwords, and multifactor authentication\nmethods to protect against unauthorized access.\n\n-  **Encrypt and Secure Transmission:**\n\n\u25cb Ensure that data, especially personally identifiable information (PII), is encrypted both in transit\nand at rest.\n\nThis adds an extra layer of protection against data breaches or unauthorized\ninterception.\n\n-  **Are Required to Undergo Regular Security Audits** :\n\n\u25cb Periodically conduct security audits and assessments to identify vulnerabilities in the\ntechnology infrastructure.\n\nThis helps in proactively addressing potential security risks and\nensuring a robust cybersecurity posture.\n\n-  **Meet Clear Data Usage Policies** :\n\n\u25cb Clearly communicate to students, parents, and educators how data collected by genai technologies\nwill be used, stored, and shared.\n\nEstablish transparent policies that align with best practices for\ndata privacy in educational settings.\n\n-  **Meet Vendor Security Standards** :\n\n\u25cb If using third-party platforms or services, verify that the vendors adhere to stringent security\nstandards.\n\nThis includes evaluating their data protection policies, encryption practices, and\noverall commitment to cybersecurity.\n\nDirect questions about this document to  or \n\n\n-----", "#### Resources for K12 School Leaders:\n\n-  NCDPI DTL Team- \u2018Leading K12 Schools in the Age of genai\u2019 Slide Deck: \n\n-  US Dept.\n\nof Education Office of Educational Technology: genai\n\n-  TeachAI Guidance for Schools Toolkit\n\n-  ISTE genai in Education Resource Collection: \n\n-  The White House Blueprint for an genai Bill of Rights\n\n-  Common Sense Media \u201c genai and Our Kids: Common Sense Considerations and Guidance for Parents,\nEducators, and Policy Makers 2023 \u201d\n\n-  Common Sense Media genai Initiative: Product Reviews", "#### Resources for Staff Development:\n\n**\u25cf** **aiforeducation.io**\n\n**\u25cb** Free 2 hour Course: on demand An Essential Guide to genai for Educators\n\n\u25cb genai Launchpad Webinar Series\n\n\u25cb Prompt Library\n\n\u25cb Student Curriculum (also great for staff!)\n\n-  4 complete lessons for grades 7-9 or 10-12\n\n-  1.\n\nInterview a Chatbot, 2.\n\nMind of a Machine, 3.\n\nHallucination Detective, 4.\n\nCo-Creating an genai Policy\n\n**\u25cf** **Code.org**\n\n\u25cb \u201c genai 101 for Educators \u201d Approx.\n\n5 hours, on demand\n\n\u25cb How genai Works Video Series (for teachers and students)\n\n**\u25cf** **Google**\n\n\u25cb Introduction to genai\n\n\u25a0 Considered to be an eight-hour free course (but more like 2 hours); includes information\nspecifically about genai,\n\n\u25cb Introduction to Large Language Models\n\n\u25a0 Considered to be an eight-hour free course (but more like 2 hours); includes information\nspecifically on Large Language Models\n\n\u25cb Introduction to Responsible genai course\n\n\u25a0 Considered to be an eight-hour free course (but more like 2 hours); includes information\nabout what responsible genai is and why it is essential.\n\n**\u25cf** **Microsoft**\n\n\u25cb Microsoft Learn Educator Center genai for Education\n\n\u25a0 Contains 4 Educator Trainings on genai\n\n\u25a0 genai for Education: Resources and Learning Opportunities\n\nDirect questions about this document to  or \n\n\n-----", "#### Resources for Teaching Students about genai\n\n**\u25cf** **The genai Education Project aiEDU.org**\n\n\u25cb genai Snapshots\n\n\u25a0 genai Snapshots by aiedu.org\n\n\u25a0 5 min critical thinking activities about genai for grades 7-12\n\n\u25a0 The link above allows you to download a Google folder with all Snapshots.\n\n\u25a0 Snapshots do not require student use of genai\n\n\u25cb genai in Five Minutes-\n\n\u25a0 \n\n\u25a0 A great quick overview of genai for staff or students\n\n\u25cb Learn About genai\n\n\u25a0 genai challenges & Projects \n\n\u25cb Intro to genai Course\n\n\u25a0 Full 10 week Project Based Learning course for grades 9-12\n\n\u25a0 \n\n**\u25cf** **genai for Education aiforeducation.io**\n\n\u25cb Student Curriculum lessons\n\n\u25a0  (also great for staff!)\n\n\u25a0 4 complete lessons for grades 7-9 or 10-12\n\n\u25a0 1.\n\nInterview a Chatbot, 2.\n\nMind of a Machine, 3.\n\nHallucination Detective, 4.\n\nCo-Creating an genai Policy\n\n\u25cb Prompt Library for Students\n\n\u25a0 \n\n\u25a0 An ever growing collection of well developed prompts geared toward student use\nof genAI as a learning partner.\n\n\u25a0 Prompts can be copied and pasted, then edited to suit as needed.\n\n**\u25cf** **Code.org**\n\n\u25cb How genai Works Video Series\n\n\u25cb genai Curriculum (multiple options for grades 3-12)\n\n\u25cb Educators can use code.org curriculum and their learning platform for free.\n\nIt allows\neducators to create classes and make assignments.\n\n**\u25cf** **Common Sense Media**\n\n\u25cb genai Literacy Lessons for Grades 6-12\n\n\u25cb Eight 15-20 minute lessons\n\n-  **Google**\n\n\u25cb Learn About genai by Google\n\n\u25cb 5 Must Knows to Get Started with genai (video)\n\nDirect questions about this document to  or \n\n\n-----", "# genai and the Creative Economy Staff Report: Perspectives and Takeaways\n\n December 2023 US Federal Trade Commission\n\n\n-----\n\nIntroduction ........................................................................................................................ 3\ngenai and Recent Technological Developments ................................................... 4\nFTC\u2019s Interest and Role in genai.............................................................................................. 5\nEvent Summary ................................................................................................................... 8\nThemes ................................................................................................................................ 9\n\nHow did participants say data is being obtained or collected?.......................................\n\n9\nWhat harms did participants say they were currently facing?......................................\n\n12\nHow did participants view proposed consent defaults?................................................\n\n14\nWhat are participants doing to understand and address genai?\n\n..................... 17\n\nPotential Areas of Further Inquiry.................................................................................... 20\nConclusion ......................................................................................................................... 21\nAppendix............................................................................................................................ 22\n\nAppendix I: Participant Bios.......................................................................................... 22\nAppendix II: Roundtable Quote Book ........................................................................... 25\n\n\u201cWe\u2019re not anti technology.\u201d ...................................................................................... 26\n\u201cOur members are keenly aware that their works are being used by genai systems.\u201d...27\nPlatforms using user-generated content for training ................................................ 28\nContracts..................................................................................................................... 28\nBody \u201cScans\u201d...............................................................................................................29\n\u201cLosing work\u201d ............................................................................................................. 29\nImpacts on opportunities ........................................................................................... 30\n\u201cTime spent\u201d ............................................................................................................... 31\nLoss of money and/or compensation.........................................................................31\nAccuracy and Fairness................................................................................................31\nDiminished value of work........................................................................................... 32\nLoss of ability to compete...........................................................................................32\nReputational damage.................................................................................................. 33\nDeepfakes, Impersonations, and/or Fan confusion .................................................. 33\nConsent, Permission, and/or Opt-out vs. opt-in ....................................................... 35\nMachine unlearning.................................................................................................... 36\nTransparency and disclosure ..................................................................................... 36\nChanging terms of service .......................................................................................... 37\nPolicy and legislative efforts.......................................................................................37\n\n\n-----\n\nLawsuits ...................................................................................................................... 37\nSelf-initiated research and investigations.................................................................. 38\nCollective bargaining .................................................................................................. 38\nRegulation................................................................................................................... 39\nConsent ....................................................................................................................... 40\n\u201cA system that is opt-in.", "Not opt-out.\u201d....................................................................... 40\nCredit and Transparency............................................................................................40\nCompensation............................................................................................................. 41\nLicensing..................................................................................................................... 41\n\n\n-----", "## genai and Recent Technological Developments\n\nThe past year has seen the emergence of tools powered by genai that can\ngenerate outputs like text, images, and audio on command.\n\nThese tools are commonly\nreferred to as \u201cgenai.\u201d To output different kinds of content, these models must\nbe built using vast amounts of existing work.\n\n3 For example, large language models such\nas PaLM 2 4 and Llama 2 5 rely on large datasets of text that have been \u201ctokenized\u201d\u2013\ndivided into smaller chunks of words or even parts of words \u2013 which are then analyzed\nfor patterns that can be reproduced.\n\n6 Image generators like Stable Diffusion are reliant\non images, paired with their captions, to fuel their models.\n\n7 The ways these tools are\nbuilt and the content the tools output have garnered attention and concern, particularly\nfrom those whose work is being used and potentially replaced.\n\n3  _See, e.g.,_\n4 _See_ Google, _PaLM 2 Technical Report_ \n5 _See_ Hugo Touvron et al., _Llama 2: Open Foundation and Fine-Tuned Chat Models_ , arXiv (July 19,\n2023),  .\n\n6 _See_ Madhumita Murgia et al., _Generative genai exists because of the transformer_ , Financial Times (Sep.\n12, 2023),  .\n\n7 _See_ Kashmir Hill, _This Tool Could Protect Artists From A.I.-Generated Art That Steals Their Style_ , The\nNew York Times (Feb. 13, 2023),  .\n\n-----", "## FTC\u2019s Interest and Role in genai\n\nThe FTC\u2019s economy-wide mission has, over its century long history, adapted to the\ndevelopment and deployment of new technologies, many of which pose novel and\nimportant challenges to the consumers, workers, and honest businesses who depend on\nmarkets being free and fair.\n\ngenai is the latest of such challenges.\n\nThe Commission\u2019s enforcement authority derives primarily from Section 5 of the FTC\nAct, which prohibits unfair or deceptive acts or practices and unfair methods of\ncompetition.\n\nThe Executive Order on the Safe, Secure, and Trustworthy Development\nand Use of genai encourages the FTC to consider whether to exercise its\nexisting authorities, as appropriate, to ensure competition in the genai marketplace and to\nprotect the public from harms that may be enabled by genai.\n\n8\n\nFrom an enforcement perspective, the FTC has been using its existing legal authorities\nto take action against illegal practices involving genai.\n\nFor instance, the FTC alleged that\nAmazon and Ring used highly private data\u2014voice recordings collected by Amazon\u2019s\nAlexa voice assistant and videos collected by Ring\u2019s internet-connected home security\ncameras\u2014to train their algorithms while violating customers\u2019 privacy.\n\n9 The Alexa\nmatter, in particular, underscored that the Children\u2019s Online Privacy Protection Act\nRule\u2019s prohibition on the indefinite retention of children\u2019s data and similar legal rules\nare not superseded by claims from businesses that data must be indefinitely retained to\nimprove machine learning algorithms.\n\n10 In recent months, the FTC secured a temporary\nrestraining order against a business-opportunity seller that claimed to use genai to make\nclients profitable and successful.\n\n11 The FTC has also made clear that a business that\nrelies on algorithmic decision-making must ensure that the algorithm is not resulting in\n\n8  EO at 5.3 (a),\n9 Press Release, Fed.\n\nTrade Comm\u2019n, _FTC and DOJ Charge Amazon with Violating Children\u2019s Privacy_\n_Law by Keeping Kids\u2019 Alexa Voice Recordings Forever and Undermining Parents\u2019 Deletion Requests_\n(May 31, 2023),  Press Release, Fed.\n\nTrade\nComm\u2019n, _FTC Says Ring Employees Illegally Surveilled Customers, Failed to Stop Hackers from Taking_\n(May 31, 2023),  _Control of Users\u2019 Cameras_\n\n10 _See_ Statement of Commissioner Alvaro M. Bedoya, Joined by Chair Lina M. Khan and Commissioner\nRebecca Kelly Slaughter, In the Matter of Amazon Alexa ( _United States v. Amazon.com, Inc._ ), at 1 (May\n gov/pdf/Bedoya-Statement-on-Alexa-Joined-by-LKand-RKS-Final-1233pm.pdf 31, 2023),\n\n11 Press Release, Fed.\n\nTrade Comm\u2019n, _FTC Action Stops Business Opportunity Scheme That Promised Its_\n_AI-Boosted Tools Would Power High Earnings Through Online Stores_ (Aug. 22, 2023),\n\n\n\n-----\n\nunlawful bias.\n\n12 Furthermore, the FTC charged WealthPress with using deceptive claims\nto sell consumers investment-advising services\u2014often claiming that the services\u2019\nrecommendations were based on an algorithm created by a purported expert.\n\n13\n\nThe rapid development and deployment of genai also poses potential risks to competition.\n\nThe rising importance of genai to the economy may further lock in the market dominance\nof large incumbent technology firms.\n\n14 These powerful, vertically integrated incumbents\ncontrol many of the inputs necessary for the effective development and deployment of\ngenai tools, including cloud-based or local computing power 15 and access to large stores of\ntraining data.\n\nThese dominant technology companies may have the incentive to use their\ncontrol over these inputs to unlawfully entrench their market positions in genai and related\nmarkets, including digital content markets.\n\nIn addition, genai tools can be used to facilitate\ncollusive behavior that unfairly inflates prices, precisely target price discrimination, or\notherwise manipulate outputs.\n\n16 The FTC is empowered under Section 5 of the FTC Act\nto protect the public against unfair methods of competition, including when powerful\nfirms unfairly use genai technologies in a manner that tends to harm competitive\nconditions.\n\n17\n\nWith respect to the creative industries, the development and use of genai technology raises\na host of potential competition and consumer protection issues.\n\nAlthough many people\npartake in different forms of creative expression as hobbyists or amateurs, millions of\nAmericans pursue creative work as a profession and many of these artists are self\u00ad\n\n12 Press Release, Fed.\n\nTrade Comm\u2019n, _FTC Chair Khan and Officials from DOJ, CFPB and EEOC Release_\n(Apr.\n\n25, 2023),  _Joint Statement on AI_\n\n13 Press Release, Fed.\n\nTrade Comm\u2019n, _FTC Suit Requires Investment Advice Company WealthPress to_\n(Jan. 13, 2023),  _Pay $1.7 Million for Deceiving Consumers_\n\n14 _See_ Staff in the Bureau of Competition & Office of Technology, _Generative genai Raises Competition_\n_Concerns_  , Fed.\n\nTrade Comm\u2019n (June 29, 2023), .", "Trade Comm\u2019n (June 29, 2023), .\n\n15 The FTC has taken enforcement action to protect competition and innovation in markets for computer\nprocessors with potential genai applications.\n\n_See_ Complaint, _In the Matter of Nvidia/Arm_ , Docket No.\n\n9404,\nComm\u2019n File No.\n\n2110015 (Dec. 2, 2021),\n part 3 complaint public version.pdf.\n\n16 _See, e.g._ , Khan, _supra,_ note 1 (discussing algorithmic price collusion and price discrimination); _see also_\n_Huskey v. State Farm Fire & Cas.\n\nCo._ , No.\n\n22 C 7014, 2023 WL 5848164, at *9 (N.D. Ill. Sept. 11, 2023)\n(discussing discriminatory insurance claim processing algorithm).\n\n17 _See_ Fed.\n\nTrade Comm\u2019n, Policy Statement Regarding the Scope of Unfair Methods of Competition\nUnder Section 5 of the Federal Trade Commission Act, Comm\u2019n File No.\n\nP221202 (Nov. 10, 2022),\n gov/pdf/P221202Section5PolicyStatement.pdf .\n\n-----\n\nemployed.\n\n18 Research has explored genai\u2019s early economic impacts on\nprofessional illustrators, 19 but artists in other creative fields, such as acting or\nscreenwriting, have also expressed concerns over the ways that genai might\naffect their livelihoods.\n\n20 Uncompensated and unauthorized appropriation of creators\u2019\ncontent may also diminish incentives to invest and produce content, affecting quality\nover the long term.\n\nVarious competition and consumer protection concerns may arise when genai is deployed\nin the creative professions.\n\nConduct\u2013such as training an genai tool on protected expression\nwithout the creator\u2019s consent or selling output generated from such an genai tool, including\nby mimicking the creator\u2019s writing style, vocal or instrumental performance, or\nlikeness\u2014may constitute an unfair method of competition or an unfair or deceptive\npractice.\n\nThat is especially true when the conduct deceives consumers, exploits a\ncreator\u2019s reputation or diminishes the value of her existing or future works, reveals\nprivate information, or otherwise causes substantial injury to consumers.\n\nIn addition,\nconduct that may be consistent with other bodies of law nevertheless may violate\nSection 5.\n\n21\n\n18 _See_ Office of Research & Analysis, _Artists in the Workforce: Selected Demographic Characteristics_\n_Prior to COVID_ _\u2010_ _19_ , National Endowment for the Arts (July 2022), .\n\n19 _See_ Harry H. Jiang et al, _AI Art and its Impact on Artists_ , AIES '23: Proceedings of the 2023\nAAAI/ACM Conference on genai, Ethics, and Society, at 363-374 (Aug. 29, 2023),\n .\n\n20 _See_ Simone Shah, _The Writers Strike is Taking a Stand of genai,_ TIME (May 4, 2023),\n .\n\n21 _See FTC v. Real Prods.\n\nCorp._ , 90 F.2d 617, 619 (2d Cir.\n\n1937) (\u201cA copyright is not a license to engage in\nunfair competition.\u201d).\n\n-----", "## Event Summary\n\nIn October 2023, the FTC held a virtual roundtable discussion to better understand the\nconcerns about genai and specifically its impact on creative fields.\n\n22 Chair Khan,\nCommissioner Slaughter, and Commissioner Bedoya provided remarks.\n\nThe moderated\ndiscussion, which was public, consisted of twelve participants who represented a wide\nvariety of creative professions, including visual artists, screenwriters, actors,\nprogrammers, editors, musicians, and models.\n\nEach participant gave brief remarks about the changes their field was experiencing with\nthe advent of genai, and how they were responding to those changes.\n\nThese\nremarks were followed by a brief Q&A.\n\nA recording of the event 23 along with a\ntranscript 24 are available on the FTC event web page.\n\nDuring the event, participants acknowledged the potential benefits of genai\ntools, and many had a long history of incorporating new technologies in their practices.\n\nParticipants also described concerns about the ways genai could be an avenue\nfor their own exploitation.\n\nThough participants came from different fields, a few consistent themes emerged:\n\n-  Concerns about how their work was being collected and used to train generative\ngenai models;\n\n-  The impact that genai outputs are already having on their industry and\nlivelihoods;\n\n-  Issues associated with solutions being proposed by genai companies to address\ncreators\u2019 concerns; and\n\n-  Alternative approaches that creators are pursuing to protect themselves and their\nindustry, including by enshrining their right to choose whether they want to use\ngenai in their work through union contracts.\n\n25\n\nThe next section of this report expands on each of the four themes.\n\n22 _See_ \n23 _See_ \n gov/pdf/creative-economy-and-generative-genai-transcriptoctober-4-2023.pdf 24 _See_\n25 _See_ Writers Guild of America, _Summary of the 2023 WGA MBA_\n .\n\n-----", "### How did participants say data is being obtained or collected?\n\nParticipants said that their work was being used to train and finetune genai\nmodels without their consent.\n\nThroughout the event, participants touched on different\nways their work was being collected, either because it was publicly posted online by\nthemselves or others, or because expansive interpretations of prior contractual\nagreements led others to make their art available to train genai.\n\nIn addition, artists often\nproduce work for hire and do not own the copyright on those creative works, further\nlimiting their ability to control how their work is used.\n\nParticipants said the nature of\ntheir work often leaves them without legal protection, and that the lack of transparency\naround data collection practices made it difficult for them to know when their works\nwere being taken.", "**Participants said that human-created work, including their own, was**\n\n**necessary for genai tools to function.\n\n** As Duncan Crabtree-Ireland, the\nNational Executive Director and Chief Negotiator for SAG-AFTRA, said during the\nevent, \u201cNo genai algorithm is able to make something out of nothing.\u201d\n\nThese claims are in line with research and reporting on genai.\n\nMany factors\nimpact an genai model\u2019s performance, but one key factor is the quality of the data used to\ntrain it.\n\nRecent research has found that not only is it necessary to carefully curate the\ndata sets used to train a genai model, 26 but removing low-quality content and\neven up-sampling higher-quality sources can result in performance improvements.\n\n27\nThe genai research community generally agrees that it is critical that the content used\nshould be diverse 28 and that generally means it must be created by an actual person.\n\ngenai models, said Douglas Preston, an author and participant of the event,\n\u201cwould be lame and useless without our books.\n\nJust imagine what it would be like if it\nwas only trained on text scraped from web blogs, opinion screeds, cat stories,\npornography and the like.\u201d\n\nIn addition to the quality of the data used to train genai models, research suggests another\nkey factor is the quantity.\n\nPopular large language models, for instance, were built using\nbillions, even trillions, of tokens, 29 which in turn necessitates similarly massive amounts\nof content.\n\nReporting suggests that this content mostly comes from scraping from the\nInternet.\n\n30", "**Participants said that their work was being taken from the Internet and is**\n\n**being used to train or finetune genai models without their**\n**awareness or consent.\n\n** John August, a screenwriter and member of the Writers Guild\nof America West, said that large language models \u201chave scraped massive volumes of\ndata, including our words and our unique perspectives.\u201d\n\n\n-----\n\nFor many creative professionals, publicly posting to the Internet is a necessary part of\nthe job.\n\nSteven Zapata, a concept artist and illustrator speaking on behalf of the Concept\nArt Association, said that, \u201cto advertise our work, most of us put our art online, on social\nmedia and our personal websites.\n\nThis leaves it exposed to unethical scraping practices.\u201d\n\nThese \u201cunethical scraping practices\u201d have been questioned within academia, 31 and genai\nresearchers have clearly stated that using training data that has been obtained from\npublic sources does not inherently mean that \u201cauthorial consent\u201d has been obtained.\n\n32\n\nIn addition to the scraping of work belonging to creative professionals, Bradley Kuhn, a\npolicy fellow at the Software Freedom Conservancy, pointed out that depending on the\nplatforms they use, creative professionals \u201cmay have already agreed for their own\ncreative works to become part of the company's machine learning data sets\u201d because of\nwhat is said in those platforms\u2019 terms of service agreements.\n\nSeveral tech companies\nmade the news over the summer after they updated their terms of service to include\nreferences to building genai with user data, 33 eliciting backlash from artists in at least one\ninstance.\n\n34\n\nIn some cases, participants said they weren\u2019t even the ones to post their works online in\nthe first place.\n\nTim Friedlander, president and founder of the National Association of\nVoice Actors, pointed out that, \u201cit's incredibly easy to use genai to capture the voice of an\n\n26 _See_ Jordan Hoffman et.\n\nal, _Training Compute-Optimal Large Language Models,_ arXiv (Mar.\n\n29,\n2022), \n27 _See_ Touvron et al, _supra_ note 5.\n\n28 _See_ Ilia Shumailov et al., _The Curse of Recursion: Training on Generated Data Makes Models Forget_ ,\narXiv (May 31, 2023),  .\n\n29 _See, e.g,_ Wayne Xin Zhao et.\n\nal, _A Survey of Large Language Models_ , arXiv (Nov. 24, 2023),\n .\n\n30 _See_ Kevin Schaul et al., _Inside the secret list of websites that make genai like ChatGPT sound smart,_ The\n Washington Post (Apr 19, 2023), .\n\n31 _See e.g.,_ Signe Ravn et.\n\nal, _What Is \u201cPublicly Available Data\u201d?\n\nExploring Blurred Public\u2013Private_\n_Boundaries and Ethical Practices Through a Case Study on Instagram,_ Journal of Empirical Research on\nHuman Research Ethics, Volume 15 Issue 1-2, at 40-45 (May 19, 2019)\n _See also_ Antony K. Cooper et.\n\nal,\n_On the Ethics of Using Publicly-Available Data,_ Responsible Design, Implementation and Use of\nInformation and Communication Technology, at 159-171 (Mar 10, 2020)\n .\n\n32 _See_ Leo Gao, et.\n\nal, _The Pile: An 800GB Dataset of Diverse Text for Language Modeling_ , arXiv, at\nSection 6.5 (Dec. 31, 2020),  .\n\n33 _See_ Matt G. Southern, _Google Updates Privacy Policy To Collect Public Data For genai Training_ , Search\n Engine Journal (Jul.\n\n3, 2023) ; _See also_ Brian Merchant, _Column: These apps and websites use_\n_your data to train genai.\n\nYou\u2019re probably using one right now._ , Los Angeles Times (Aug. 16, 2023)\n .\n\n34 _See_ Michael Kan, _Artists Drop Twitter Over Elon Musk's Plan to Train His genai Project on Tweets,_\nPCMag (Aug. 1, 2023), \n\n10\n\n\n-----\n\nactor from content available on the internet, and to use that sample to create whole\nworks for sale or non-commercial distribution.\u201d 35 Several participants referenced a\ndataset called Books3, which The Atlantic reported was built from a library of pirated\nbooks.\n\n36 Preston, for instance, said that the dataset had, \u201call my books, all 40 of them on\nit, including many different editions.\u201d Another participant, Clarkesworld magazine\nfounder and editor Neil Clarke, said that anthologies he had edited and published could\nalso be found in the dataset.", "**Participants said the nature of most paid creative work means that artists**\n\n**often have little control over how their creations are later used.\n\n** Participants\nexplained that many creative professionals do work for hire, meaning the rights to their\ncreative works belong to the client or company that hired them.\n\n\u201cWGA writers do not\nhold copyright to most of the scripts we write; those are works made for hire, so\nstudios\u2014 our employers\u2014 hold the copyright,\u201d August said.\n\nThis means that creative\nprofessionals don\u2019t always have control over how their works are used in the future.\n\nSteven Zapata, a concept artist and illustrator speaking on behalf of the Concept Art\nAssociation, said that with work-for-hire agreements, a visual artist could spend decades\nof their life working for a studio and that studio \u201ccan take all your work, train a model\non it, and then have a free and tireless replica of you to use in perpetuity.\u201d\n\nFriedlander said that voice actors were experiencing that now: \u201cContracts we signed\nyears ago are now being used to justify the inclusion of our audio in synthetic voice\nmodels.\u201d\n\nSome creative professionals have even less insight into what they\u2019ve been forced to give\nup.\n\nSara Ziff of the Model Alliance noted that many fashion models do not actually see\nthe terms that their management companies have agreed to with clients, so many do not\nactually know what happens to the digital body scans that some clients are starting to\nrequire.", "**These uncertainties are exacerbated by the fact that genai developers do not**\n\n**publicly disclose what works are included in their training data, according**\n**to participants.\n\n**\n\nPreston said that, \u201c[genai companies] refuse to answer any questions from the Author's\nGuild about what data sets they're using, where they're getting their books, and how\nthey're being used.\n\nThere's no transparency at all.\n\nIt's an absolute black hole.\u201d\n\n35 Music artists have suffered similar problems with genai.\n\n_See_ Sharon Adarlo, _Nicki Minaj_\n _enraged by deepfake video_ ; _see also_ Noah A. McGee, , Futurism (Jul.\n\n12, 2023) _Heard the Fake Clip of Drake Rapping \u2018Munch\u2019?\n\nHere\u2019s Why_\n _It\u2019s Causing Concern for Major Labels_ , The Root (Apr.\n\n14, 2023) .\n\n36 _See_ Alex Reisner, _These 183,000 Books Are Fueling the Biggest Fight in Publishing and Tech_ , The\n Atlantic (Sep. 25, 2023), .\n\n11\n\n\n-----\n\nResearchers have found that some genai developers have become less open over time about\nwhat can be found in their models\u2019 training data.\n\n37\n\nWhen asked about how participants found out about the inclusion of their work in the\ntraining of these models, Umair Kazi stated that \u201cThere is a lack of transparency from genai\ndevelopers about training data sets, which makes it very difficult to ascertain which\nworks were actually used to train the models and how.\u201d", "### What harms did participants say they were currently facing?\n\nParticipants\u2019 concerns were limited not just to how their own work was being used.\n\nThroughout the event, participants discussed a wide range of harms they associated with\nthe outputs of genai tools.\n\nThese harms included the ways that genai\ncould be used make it more difficult to find human-made work, mimic creative\nprofessionals\u2019 unique styles causing market confusion and reputational damage, and\nlead to loss of opportunity and income.", "**Participants said that genai outputs are starting to appear in the**\n\n**venues where creative professionals compete for work, making it more**\n**difficult for consumers and potential publishers to find human-made work.\n\n**\nKazi, the Authors Guild director of public policy and outreach, said that his group was\nalready seeing genai being used to generate low-quality eBooks that displace humanauthored books in major online book retailers.\n\nIn one instance earlier this year, he said,\ngenai-generated books began dominating the young adult romance bestseller list of a\npopular online bookseller.\n\n38\n\nNeil Clarke, the editor and founder of the sci-fi short story magazine Clarkesworld,\n\n39\ndescribed being inundated with hundreds of submissions that appeared to be AIgenerated, leading him to temporarily close submissions.\n\nClarke said the magazine\nhad a standing \u201cno-genai\u201d policy even prior to the influx of submissions, and said his\nworkload has \u201ceasily doubled\u201d as he sorts through a stream of suspicious submissions.", "**Participants expressed concerns about genai tools being used to**\n\n**mimic their own unique styles, brands, voice and likenesses, which could**\n**allow strangers and former clients to create knockoffs of their work.\n\n** Karla\n\n37 _See_ David Gray Widder et.\n\nal, _Open (For Business): Big Tech, Concentrated Power, and the Political_\n_Economy of Open AI_ , SSRN Electronic Journal (Aug. 18 2023),\n id=4543807 .\n\n38 _See_ Jules Roscoe, _AI-Generated Books of Nonsense Are All Over Amazon's Bestseller Lists_ , VICE (Jun\n 28, 2023), .\n\n39 _See_ Mia Sato, _AI-generated fiction is flooding literary magazines \u2014 but not fooling anyone,_ The Verge\n (Feb. 25, 2023), .\n\n12\n\n\n-----\n\nOrtiz, a concept artist and illustrator, said that text-to-image generators can let anyone\nproduce work \u201cin the style of\u201d a named artist, and that her own name has been\nreferenced thousands of times by people prompting genai systems to produce\nwork that looked like her own.\n\nSimilarly, Kazi of the Authors Guild alleged that\ngenai was being used to create unauthorized derivative works in the style of\npopular authors, and described one person\u2019s attempts to write the concluding books of\nGeorge R.R.\n\nMartin\u2019s popular \u201cA Song of Ice and Fire\u201d series.\n\ngenai generated knock-offs have found their way onto online book publishing platforms,\nsaid John August of the Writers\u2019 Guild of America West, where they are being sold to\ncustomers who might confuse them with authors\u2019 actual works.\n\n40 In addition to creating\nand selling their own work, now authors have to fend off genai-fueled fraudsters: \u201cThey\u2019re\nhaving to fight to get those fakes taken down, and protect their brands,\u201d said August.\n\nParticipants said that the threat of genai fakes can also come from former clients.\n\nFriedlander, the NAVA president, gave the example of a New York voice actor who was\nlet go after working for a company for several years.\n\nAccording to Friedlander, the\ncompany told the voice actor that it finally had enough of the actor\u2019s audio, and the\ncompany was now planning on creating a synthetic version of their voice.", "**Participants said that when consumers mistake genai-generated work made in**\n\n**the likeness or style of a particular artist as the actual work of that artist, it**\n**could jeopardize the actual artist\u2019s reputation and ability to earn income.\n\n**\nZapata, the illustrator speaking on behalf of the Concept Art Association, said AIgenerated work can end up online with the artist\u2019s name attached, even though they\ndidn\u2019t make the work and have no control over the content or the quality of the piece.\n\n\u201cThe negative market implications of a potential client encountering a freely\ndownloadable genai copycat of us when searching our names online could be devastating to\nindividual careers and our industry as a whole,\u201d he said.\n\nParticipants said that they have also seen genai tools being used to harass\ncreative professionals and confuse consumers.\n\nFriedlander referenced an incident from\nFebruary, in which anonymous trolls made synthetic versions of multiple voice actors,\nand tweeted false audio clips of them divulging their actual home addresses and saying\nhomophobic and racist slurs.\n\n41 Jen Jacobsen, the executive director of the Artist Rights\n\n40 Books allegedly written using genai have been published using authors\u2019 actual names.\n\n_See_ Ella\nCreamer, _Amazon removes books \u2018generated by genai\u2019 for sale under author\u2019s name,_ The Guardian (Aug. 9,\n 2023), .\n\n41 _See_ Joseph Cox, _Video Game Voice Actors Doxed and Harassed in Targeted genai Voice Attack_ , VICE\n(Feb. 13, 2023),  .\n\n13\n\n\n-----\n\nAlliance said that genai tools have been used to create false depictions of artists\nselling products that the artists never endorsed.\n\n42\n\n\u201cIt's not only confusing to fans, but humiliating to the artists themselves and\nundermines their public image,\u201d said Jacobsen.", "**Participants were concerned that creative professionals are already losing**\n\n**work because of genai.\n\n** Friedlander described a recent incident where a\nvoice actor in Washington state lost out on an audiobook job when the company told\nthem it \u201cdecided to take the job in-house.\u201d Friedlander said that around the same time,\nthe company published a press release stating that they would be using a synthetic voice\nstartup for all their audiobook productions.\n\nHe said this move was \u201ceffectively replacing\nall of those human narrators with synthetic voices.\u201d\n\nKazi of the Authors Guild said that freelance journalists and professional writers of web\nand marketing content were reportedly losing work \u201cat an alarming rate.\u201d He described\nthe plight of an unnamed Guild member, who works as a marketing and web content\nwriter and reportedly lost three-quarters of their work because their clients switched to\nusing genai instead.\n\nZiff, the Model Alliance founder, said that earlier this year a major clothing company\nannounced that they were creating genai-generated models to increase the number and\ndiversity of their models.\n\n43 \u201cIn an industry that has historically been discriminatory,\ncreating digital representations of models of various ages, ethnicities, and body types\nrather than hiring and paying a diversity of real models is concerning,\u201d she said.\n\nZiff pointed out that the use of genai fashion models would not just impact human models.\n\nShe said that fashion workers of all kinds\u2014including photographers, stylists, and hair\nand makeup artists\u2014were concerned about their use, because it could impact all their\nlivelihoods.", "### How did participants view proposed consent defaults?\n\nSome genai developers have started offering people, including creative professionals, the\nchoice to \u201copt-out\u201d of their work being used to train future models, through methods\n\n42 _See e.g._ Carson Blackwelder et al., _Tom Hanks warns fans about fake ad featuring fabricated image of_\n _his likeness_ , ABC News (Oct. 2, 2023), .\n\n43 _See_ Jess Weatherbed, _Levi\u2019s will test genai-generated clothing models to \u2018increase diversity\u2019_ , The Verge\n (Mar.\n\n27, 2023), .\n\n14\n\n\n-----\n\nsuch as direct opt-out forms, 44 voluntarily complying with third-party lists, 45 and public\ncommitments to respect the Robots Exclusion Protocol .\n\n46 Participants raised multiple\nconcerns about these kinds of opt-out frameworks, ranging from the practical, like not\nknowing whether their data was used and, thus, whether opt-out is even needed, to\nmore fundamental issues with the approach, like shifting the burden from companies to\ncreators.\n\nParticipants also discussed the need for solutions that would not only limit the\nharm moving forward but also address the harm that has already occurred.", "**Participants said that opt-outs put the burden on creators to police a**\n\n**rapidly changing marketplace, where new companies and genai models are**\n**emerging every day.\n\n** Jacobsen likened these to \u201ca new form of uncompensated labor\u201d\nthat genai developers are requiring people to perform if they want to avoid being exploited.\n\n\u201cSuch burden shifting is not only unfair, it is morally wrong and antithetical to basic\nprinciples of artistic integrity,\u201d said Jacobsen.\n\nAugust echoed that sentiment, \u201cThere are so many companies out there developing and\ntraining genai models, to be forced to continually track all of them down to opt out is an\nenormous administrative burden on individual artists.\u201d\n\nOrtiz pointed out that these frameworks require a certain level of technical and legal\nexpertise about a fast-moving industry, and that raises questions about whether the\nchoices these frameworks offer are truly accessible to all creators:\n\n_Does that mean we have to opt out on each and every one of them?\n\nThat's a fulltime job.\n\nWhat about if those models update?\n\nWhat about if they don't publicize_\n_and they use third parties?\n\nWhat if those models in the opt-out forms are not an_\n_artist's native language?\n\nWhat about artists who never spend time online or_\n_don't even know this is happening?_\n\nParticipants wanted genai developers to take an opt-in approach instead.\n\nClarke said that\nopt-out frameworks, in contrast to a framework that seeks explicit consent prior to\nusage, \u201cis what you get when the fox designs the chicken coop.\u201d", "**Participants also emphasized that because of the lack of transparency about**\n\n**what is being used as training data, it was unclear which work they would**\n**need to request to have removed, or even if their work was included at all.\n\n**\nKazi said the fact that writers and editors were able to check whether their books could\nbe found in the Books3 dataset was \u201can anomaly\u201d and not the norm.\n\nBecause that\n\n44 _See_ Kyle Wiggers, _OpenAI unveils DALL-E 3, allows artists to opt out of training,_ TechCrunch (Sep.\n 20, 2023), .\n\n45 _See_ Kyle Wiggers, _Spawning lays out plans for letting creators opt out of genai training,_\n TechCrunch (May 3, 2023), .\n\n46 _See e.g.,_ Ben Welsh, _Who blocks OpenAI, Google genai and Common Crawl?_\n\n\n15\n\n\n-----\n\ndataset was publicly available, anyone could inspect and audit it, and build tools to make\nexamining the dataset accessible to the public.\n\n47 Researchers have found that this is not\nthe case for all datasets used to train genai models, 48 and participants noted that as well.\n\n\u201cThere is a lack of transparency from genai developers about training data sets, which\nmakes it very difficult to ascertain which works were actually used to train the models\nand how,\u201d said Kazi.\n\nOrtiz said that lack of transparency makes it difficult for individuals even to know which\nworks they should request be removed, \u201cExisting opt-out procedures often ask users to\nlist works used to train the model they own, but as we just mentioned, that training data\nis secret, so it's an impossible task.\u201d\n\nParticipants said that transparency around training data and what works were used to\nbuild them was greatly needed.\n\n\u201cDivulging your dataset should be compulsory,\u201d said\nZapata.", "**Participants took issue with the fact that most opt-out frameworks were**\n\n**about** future **models, and often did nothing to address past usage** .\n\nThroughout the event, many of the participants called for consent and compensation\nbecause they said genai models were trained without them.\n\nParticipants' consent was not\nsought during the development of these genai models, and they did not have an\nopportunity to negotiate for fair compensation for the works used.\n\nZapata said that mainstream genai developers\u2019 opt-outs only apply to the future\ndevelopments.\n\nEven if someone chooses to follow a developer\u2019s opt-out instructions,\nZapata said, \u201cit\u2019s already too late to get out of the most current model.\u201d\n\nThis may be, as Zapata noted, due to technical limitations.\n\nDeveloping methods of\neffective machine \u201cun\u201d-learning is currently a research topic of academic and corporate\ninterest.\n\n49\n\nMany of participants\u2019 concerns surrounded past actions, which are not fully addressed\nby giving a choice about future use.\n\nSaid August, \u201cThe advent of genai doesn't change\nfundamental ways that the world is supposed to work, and that world works in\npermission first.\u201d\n\n47 Reisner, _supra_ note 38.\n\n48 _See_ Rishi Bommasani et.\n\nal, _The Foundation Model Transparency Index_ , arXiv (Oct. 19, 2023),\n .\n\n49 _See, e.g.,_ NeurIPS 2023 Machine Unlearning Challenge \n\n16\n\n\n-----", "### What are participants doing to understand and address genai?\n\nThroughout the event, participants described the approaches that they are using to\naddress and understand the ways that genai is reshaping their respective lines of\nwork.\n\nParticipants said they have been conducting research to better understand\ngenai.\n\nThey have engaged in labor strikes of near historic lengths as they\nnegotiate for protections against genai in their collective bargaining agreements.\n\nThey have\nbacked legislative efforts on both the state and federal level.\n\nThey have joined classaction lawsuits, and they have attempted to engage with genai developers directly.", "**Participants described research efforts they were undertaking to**\n\n**understand the emerging genai landscape.\n\n** Clarke said that after he\nexperienced an influx of what he suspected were genai-generated submissions, he spoke\nwith fraud detection experts and genai researchers to better understand how to combat\nfalse submissions to his magazine.\n\nHe spent time evaluating many of the public and\ncommercial genai detection tools, because he was uncertain about their accuracy claims\nand whether they would be suitable to use.\n\nKazi described the ways the Authors Guild has probed genai chatbots to better\nunderstand what might have been included in their training data, since the developers\ndo not disclose what they contain.\n\nZiff said the Model Alliance is partnering with the Worker Institute at Cornell University\nto develop a research study that would better help them understand the impact of\ngenai on fashion workers, with a particular focus on workers of color.", "**Union representatives who participated said they have been bargaining**\n\n**over genai or are planning to when their current agreements are up** .\n\nAugust, the\nscreenwriter and member of the Writers Guild of America West\u2019s Negotiating\nCommittee, said the Guild\u2019s recently ratified agreement could offer helpful guidance\nwhen thinking about future public policy on genai, and laid out the new guardrails the\nGuild has set in its agreement:\n\n_Our agreement defines that genai is not a writer and the material it generates is_\n_not equivalent to human writing for purposes of our contract.\n\nThat means that_\n_AI cannot rewrite us, nor can it compete with a human writer for credit and the_\n_associated financial benefit of that credit.\n\nFurther, the studios now have to tell_\n_us if they are providing us with material generated by genai and then it cannot_\n_require us to use genai tools._\n\nAugust emphasized that the Guild was able to win these protections because they are a\nstrong union that successfully carried off a nearly five-month strike\u2014one of the longest\n\n17\n\n\n-----\n\nin the Guild\u2019s history, according to Entertainment Weekly.\n\n50 August reminded the\naudience that most writers and artists don\u2019t have unions to protect them.\n\nThat fact was\nechoed by participants who represented worker advocacy groups like the National\nAssociation of Voice Actors and the Model Alliance.\n\nThese kinds of groups can advocate\nfor and support their members, they but cannot collectively bargain agreements with\ncompanies.\n\nJohn K Painting of the American Federation of Musicians, another union that was\nrepresented during the event, said that in addition to collective bargaining agreements,\nlegislative lobbying was an important mechanism for AFM to win protections for its\nmembers.\n\nThis approach was not just limited to the organized labor groups represented\nat the event.", "**Throughout the event, participants mentioned specific pieces of legislation**\n\n**they supported and hoped would help creative professionals and add**\n**guardrails for how genai is built and used.\n\n** On the state level, Ziff of the\nModel Alliance said her organization supported the Fashion Workers Act in New York, 51\nwhich would establish basic labor protections for models and content creators in the\nstate\u2019s fashion industry.\n\nZiff said the bill would help address the lack of transparency\naround how models\u2019 body scans are being used.\n\nOn the federal level, NAVA\u2019s Friedlander said the organization recently endorsed the genai\nLabeling Act of 2023, 52 which would require genai developers to include \u201ca clear\nand conspicuous disclosure identifying genai-generated content and genai chatbots,\u201d\naccording to a press release from U.S.\n\nSenator Brian Schatz (D-Hawai\u2019i), who\nintroduced the bill.\n\n53\n\nJacobsen of the Artist Rights Alliance also referenced the Protect Working Musicians\nAct of 2023, 54 which Jacobsen said would give small and independent musicians an\nantitrust exemption to negotiate collectively with genai developers and streaming\nplatforms.\n\nAdditionally, at least one participant mentioned the idea of a federal right of publicity.\n\nState-level laws have been passed in places like New York 55 and California, 56 but not\n\n\n50 _See_ Lester Fabian Braithwaite, _Writers Guild officially ratifies new contract after months-long strike,_\n Entertainment Weekly (Oct. 9, 2023), .\n\n51 N.Y. Legis.\n\nS. 2477A.\n\nReg.\n\nSess.\n\n2023-2024 (2023).\n\n52 genai Labeling Act of 2023, S. 2691, 118th Cong.\n\n(2023).\n\n53 Press Release, U.S.\n\nSenator Brian Schatz, _Schatz, Kennedy Introduce Bipartisan Legislation To_\n_Provide More Transparency On genai-Generated Content_ (Oct. 24, 2023),\n .\n\n54 Protect Working Musicians Act of 2023, H.R.\n\n5576, 118th Cong.\n\n(2023).\n\n55 NY CLS Civ R \u00a7 51 (2021)\n56 Cal Civ Code \u00a7 3344\n\n18\n\n\n-----\n\nevery state has its own version.\n\nRight of publicity laws generally protect a person\u2019s\nlikeness from being misused for commercial purposes without their consent and could\npotentially give creative professionals greater control over how things like their voices or\npersonal styles are being used.\n\nSince the event took place, a bipartisan group of senators\nreleased a discussion draft of the No Fakes Act of 2023, 57 which would create such\nfederal protections specifically addressing misuse of genai.", "**A few participants said they were engaged in ongoing class-action lawsuits**\n\n**that they hoped would help address some of the harms they said were**\n**caused by genai developers.\n\n** One such participant was Doug Preston, a\nfiction author, who said he and his co-plaintiffs were seeking damages for the\nunauthorized use of their copyrighted work.\n\nPreston said that moving forward, he and\nhis co-plaintiffs wanted genai developers get permission from authors, properly license\ntheir books, and compensate them fairly for that use.", "**At least one participant mentioned proactively working with an genai**\n\n**developer on a project.\n\n** Friedlander, the NAVA president, said that he was working\non developing a synthetic version of his voice that would allow him to perform work he\nwould not otherwise be able to do, like read a newspaper cover-to-cover every morning.\n\nFriedlander emphasized that not only was this being done with his consent, control, and\ncompensation, but more generally that genai tools should enhance and not\nreplace the work of creative professionals.\n\n57 Press Release, U.S.\n\nSenator Chris Coons, _Senators Coons, Blackburn, Klobuchar, Tillis announce draft_\n_of bill to protect voice and likeness of actors, singers, performers, and individuals from genai-generated_\n_replicas_ (Oct. 12, 2023),  fakes act draft text.pdf .\n\n19\n\n\n-----", "## Potential Areas of Further Inquiry\n\nThe event outlined the diverse palette of issues and experiences that creative\nprofessionals face across the industry.\n\nFurther research is required to help scholars, law\nenforcement agencies, and other civil society organizations understand how generative\ngenai can impact communities and how those harms can be mitigated.\n\nParticipants\nhighlighted a multitude of questions and open areas for further research.\n\nOrtiz, for instance, raised several questions during the event about how opt-out\nframeworks are being effectively communicated to people whose work has been\nincluded in training sets, highlighting issues such as barriers of language and technical\nexpertise.\n\nOrtiz\u2019s questions prompt other questions, such as: What other barriers do\nexisting opt-out frameworks present?\n\nHow are the accessibility and usage rates of\noptions presented by these frameworks being measured?\n\nZapata noted another major barrier is a lack of disclosure around what is currently\nincluded in training sets.\n\nKazi and Clarke\u2019s discussion of the Books3 dataset also raises\nquestions about what is needed beyond simply publishing a dataset.\n\nBooks3 was always\npublic but not easily interpretable by the public prior to investigative reporting on the\ntopic.\n\nWhat efforts are being made to disclose the contents of training sets?\n\nWhat\npractices are being developed to ensure that transparency is meaningful and furthers\nunderstanding for a public beyond those with technical expertise in machine learning?\n\nAnother open question that Zapata touched on was how genai developers can effectively\ncomply with opt-out requests for existing models.\n\nWhat is the current state of machine\n\u201cunlearning\u201d research?\n\nWhat is needed to effectively remove the contributions from\nwork no longer desired in a model, and how can that be verified?\n\nWhat measures of\nefficacy are being developed as this research evolves?\n\nParticipants discussed many stages of model development and deployment where issues\nmay arise, starting from the collection and inclusion of work in training data without the\naffirmative consent of its creators, to downstream misuse of these models and other\nunintended effects.\n\nFriedlander, for instance, highlighted a new problem that voice\nactors are now facing\u2014proving the provenance of their own work to clients.\n\nSaid\nFriedlander, \u201can extra burden has now been placed on voice actors to prove that the\naudio they\u2019re delivering is not genai-generated.\u201d For this example, and others, wha t is the\nscope of the de facto burden placed on artists in the aggregate, to what extent is it\nunremunerated, and is the allocation of such costs justifiable and efficient?\n\nBeyond the individual effect that genai has on any given creator, how might the\npractices of genai developers affect these markets over the long term?\n\nFor example, would\nthe uncompensated and unauthorized use of creators\u2019 content dissuade individuals and\nfirms from investing in high-quality content in the first instance?\n\n20\n\n\n-----", "## Conclusion\n\nThe creative professionals at the roundtable discussion raised a number of concerns\nregarding the impact that genai is having on them and on consumers.\n\nAlthough many of\nthe concerns raised at the roundtable lay beyond the scope of the Commission\u2019s\njurisdiction, targeted enforcement under the FTC\u2019s existing authority in genai-related\nmarkets can help to foster fair competition and protect people in creative industries and\nbeyond from unfair or deceptive practices.\n\nFor decades, the FTC has used its authorities to address deceptive or unfair acts or\npractices and unfair methods of competition as it relates to new and transformative\ntechnologies.\n\nThere is no \u201cgenai exemption\u201d from the laws on the books.\n\nThe FTC will\ncontinue to vigorously use the full range of its authorities to protect Americans from\ndeceptive and unfair conduct and maintain open, fair, and competitive markets.\n\nThe FTC continues to listen and learn about the latest trends\u2014and recognizes that the\ntopics covered above are by no means exhaustive.\n\nThe FTC will continue to closely\nmonitor and scan the developments of these products, services, and tools.\n\nAs the\ngenai industry continues to develop, the FTC will remain vigilant and ready to\nuse the full panoply of its law enforcement and policy tools to foster fair competition,\nprotect consumers, and help ensure that the public benefits from this transformative\ntechnology.\n\n21\n\n\n-----", "**Platforms using user-generated content for training**\n\n-  \u201cWe knew these models were trained without permission on the copyrighted\nworks of others, and it didn't sit right with us.\u201d - Neil Clarke\n\n-  \u201cZoom is among the many Big Tech companies that have sought to cajole users\ninto consent for use of their user data as training input for machine learning\nsystems.\u201d - Bradley Kuhn\n\n-  \u201cFor example, data laundering, where a company outsources its data collection to\na third party under the pretext of research to then immediately use that for\ncommercial purposes.\n\nAn example of this is LAION.\n\nSpecifically, it's more\npopular LAOIN-5B, a dataset that contains 5.8 billion text and image pairs, which\nagain includes the entirety of my work and the work of almost everyone I know.\u201d Karla Ortiz\n\n-  \u201cThe massive datasets that text-to-image models are trained off of contain the\ncopyrighted works of artists, whether it be work done for ourselves or work done\nfor companies in a work-for-hire capacity.\u201d - Steven Zapata\n\n-  \u201cUnfortunately, in today's reckless, careless rush to launch new genai\nproducts, we are seeing what is euphemistically referred to as genai training or\nlearning, but which is in fact illegal copying of artistic works on a massive scale\nwithout consent or compensation and often without the artist even knowing.\u201d Jen Jacobson", "**Contracts**\n\n-  \u201cContracts we signed years ago are now being used to justify the inclusion of our\naudio in synthetic voice models.\n\nAnd every time that happens without the\nconsent, control, and compensation of the voice actor involved, the value of that\nvoice actor's product, their voice and the sound of their voice, is diluted and\nunfairly diminished.\n\nWe consider this to be a form of theft.\n\nWe agree to license\nour voice to clients.\n\nThe client is buying the exclusive rights to that recording,\nthat performance, but also the sound of our voice.\n\nWe could potentially now be in\nconflict with a clone of our own voice, which causes harm to both the voice actor\nand the company.\n\nPepsi and Coke can't have the same voice providing their\ncommercials.\n\nChevy and Ford can't have the same voice.\n\nCurrently the only\nprotections that we have from voice actors having their audio uploaded to these\nsites are the terms of service that people agree to.\u201d - Tim Friedlander\n\n-  \u201cWhen a model signs a management agreement, she typically hands over a power\nof attorney, and thus rarely, if ever, sees her own contracts with the brands.\n\nAs a\nresult, models have little transparency into their own business dealings.\u201d - Sara\nZiff\n\n28\n\n\n-----\n\n-  \u201cAlso, the nature of the typical work-for-hire contract has put us in a bad bind.\n\nAlmost every commercial artist today works under all-encompassing work-forhire contracts that surrender all rights to a company.\u201d - Steven Zapata\n\n-  \u201cModels have very little insight into how their work or likeness is being used in\ngeneral, let alone in the context of genai.\n\nNormally they don't see their\ncontracts with the brands and often don't know how their image will be used,\nwhether how much they'll be paid.\n\nSo genai introduces the potential for\nfurther exploitation in an already exploitative work environment.\u201d - Sara Ziff", "**Body \u201cScans\u201d**\n\n-  \u201cIncreasingly, companies are asking models to undergo scans that generate a 3D\nmodel of their body or face.\n\nIn our poll, nearly 18% of models who responded had\nbeen asked to undergo a scan by a brand or a management company.\u201d - Sara Ziff\n\n**\u201cLosing work\u201d**\n\n-  \u201cOnce they start employing bots to submit these words, what we currently receive\nin a month may arrive in hours.\n\nQuantity and the lack of reliable detection tools\nwill eventually break our ability to do our job.\u201d - Neil Clarke\n\n-  \u201cIn one instance earlier this year, genai-generated books started dominating\nAmazon's bestseller list in the young adult romance category.\n\nWe have seen AIgenerated books pop up for sale on closely related or very similar topics as those\nauthors have listed for pre-orders, a growth in the number of unauthorized\nsummaries of books, and fake books using names of renowned authors.\u201d - Umair\nKazi\n\n-  \u201cFreelance journalists and professional writers of web and marketing content are\nreporting losing work at an alarming rate.\n\nAn Authors Guild member who writes\nmarketing and web content reported losing 75% of their work as a result of\nclients switching to genai.\u201d - Umair Kazi\n\n-  \u201cA content writer featured in a piece about ChatGPT's impact in the Washington\nPost stated that he had lost a half of his annual income.\n\nThere's a widespread and\nreal concern among writers that genai will decimate the profession.\n\nIn our recent\nsurvey, 69% of authors said that genai threatens their careers, and an\noverwhelming 90% said that authors should be compensated if their works are\nused in training.\n\nThese concerns are born out of the experience of enduring\nlongterm precarity.\u201d - Umair Kazi\n\n-  \u201cA voice actor in New York worked for a company for three years, and year four,\nthey were let go because they were told the company had enough of their audio,\nand they were going to now create a synthetic version of their voice.\u201d - Tim\nFriedlander\n\n29\n\n\n-----\n\n-  \u201cAnd most recently, a voice actor in Washington state lost an audiobook job when\nthey decided to take the job in-house.\n\nAround that same time, the audiobook\ncompany made a press announcement that they were now using ElevenLabs for\nall of their audiobook productions, effectively replacing all of those human\nnarrators with synthetic voices.\u201d - Tim Friedlander\n\n-  \u201cFashion workers are worried about the threat of these genai models replacing jobs\n\n\u2013 not only for models, but also photographers, stylists, and hair and makeup\nartists among others.\u201d - Sara Ziff, Model Alliance\n\n-  \u201cPerhaps most harmfully, these exploitative products compete directly with\nartists and are already replacing us.\n\nThat may be the most disturbing harms of\ngenai.\n\nNot vast murdering sci-fi nonsense, but one built on works taken\nwithout credit, consent, compensation and transparency, and marketed and used\nas a replacement for the creators of those works at a fraction of the cost.\n\nThe\nwhole process is rotten.\u201d - Karla Ortiz\n\n-  \u201cCompared to previous technological shifts, the job losses here could be steep:\nrecording and scoring of all types can be wholesale replaced if composers and\nsongwriters can replace the output of live performing instrumentalists with an\ngenai-generated facsimile.\n\nProducers may replace the composers and songwriters\nthemselves.\n\nLive touring across all genres would be impacted if bands and artists\ncould tour with genai- generated backing musicians, holographic orchestras, genai\nbacking tracks.\u201d - John Painting", "**Impacts on opportunities**\n\n-  \u201cMembers in our community have expressed particular concern about companies\nusing genai-generated models as part of their diversity and inclusion initiatives.\n\nFor\nexample, Shudu, a digital model who was created through genai in 2017 by the\nworld's first all-digital modeling agency, has appeared as a face of high-end\nbrands such as BMW and Louis Vuitton.\n\nCritics have called this a form of \"digital\nblackface\u201d since Shudu is a Black woman, and the creator who profits off her\nimage is a White man.\u201d - Sara Ziff\n\n-  \u201cAnd earlier this year, Levi's announced that they are creating genai-generated\nmodels to increase the number and diversity of their models.\n\nIn an industry that\nhas historically been discriminatory, creating digital representations of models of\nvarious ages, ethnicities, and body types rather than hiring and paying a diversity\nof real models is concerning.\u201d - Sara Ziff\n\n-  \u201cWhen used ethically and in a manner that recognizes intellectual property\nrights, genai can help people in their careers and can further opportunities.\n\nIt can\ncreate access to employment for people with disabilities and those who would\notherwise be prevented from pursuing work in the entertainment industry.\u201d Duncan Crabtree-Ireland\n\n30\n\n\n-----\n\n**\u201cTime spent\u201d**\n\n-  \u201cUnfortunately, we still have to review each of these suspicious submissions\nmanually, but for now, we've been able to stay open.\n\nBetween the time spent\nreviewing submissions and maintaining the software to control them, my\nworkload has easily doubled.\n\nIt's been exhausting, and this is only the early days.\u201d\n\n-  Neil Clarke\n\n-  \u201cAdditionally, an extra burden has now been placed on the voice actors to prove\nthat the audio they're delivering is not genai-generated.\n\nMany voice actors have\nreached out to NAVA asking for some way to prove that they delivered humangenerated audio.\u201d - Tim Friedlander\n\n-  \u201cDoes that mean we have to opt out on each and every one of them?\n\nThat's a fulltime job.\n\nWhat about if those models update?\n\nWhat about if they don't publicize\nand they use third parties?\n\nWhat if those models in the opt-out forms are not an\nartist's native language?\n\nWhat about artists who never spend time online or don't\neven know this is happening?\u201d - Karla Ortiz", "**Loss of money and/or compensation**\n\n-  \u201cMy own name, Karla Ortiz, has also been used thousands of times.\n\nI never gave\nconsent.\n\nI never got credit.\n\nI never got compensation.\u201d - Karla Ortiz\n\n-  \u201cA machine-generated creation which utilizes a performer's voice, face, or in our\ncase instrumental sound without the actual participation of that performer in the\ncreation is tantamount to replacing the performer entirely.\n\nIt removes the human\nfrom the creative process and the performing process.\n\nWhen that happens, the\nwork is gone, the wages are gone, the secondary residuals are gone.\u201d - John\nPainting\n\n-  \u201cFor musicians, like all the other creators represented here today, the unethical\nuse of genai poses an existential threat to our livelihood.\u201d - Jen Jacobson", "**Accuracy and Fairness**\n\n-  \u201cTo make matters worse, I observed that foreign authors were far more likely to\nbe incorrectly flagged as genai and an experienced eye remains the only reliable\nmethod of detection.\u201d - Neil Clarke\n\n-  \u201cAnd earlier this year, Levi's announced that they are creating genai-generated\nmodels to increase the number and diversity of their models.\n\nIn an industry that\nhas historically been discriminatory, creating digital representations of models of\nvarious ages, ethnicities, and body types rather than hiring and paying a diversity\nof real models is concerning.\u201d - Sara Ziff, Model Alliance\n\n31\n\n\n-----\n\n-  \u201cWith that in mind, there's a real risk that genai may be used to deceive investors\nand consumers into believing that a company engages in fair and equitable hiring\npractices and is diverse and inclusive, when they are not.\u201d - Sara Ziff", "**Diminished value of work**\n\n-  \u201cIt is using stolen goods to undercut the price of a seller and create market\nconfusion, and it's not a hypothetical.\u201d - John August\n\n-  \u201cWhile it is likely that there are many positive uses for this technology, I don't\nbelieve that authors, artists, translators, narrators, and others should be required\nto sacrifice their work to improve or build these models.\n\nProgress can still be\nmade responsibly without stepping on creatives.\u201d - Neil Clarke\n\n-  \u201cThere's a serious risk of market dilution from machine generated books and\nother works that can be cheaply mass-produced, and which will inevitably lower\nthe economic and artistic value of human created works.\u201d - Umair Kazi\n\n-  \u201cThese pieces have subject matters and qualities that we have no control over.\n\nAnd the negative market implications of a potential client encountering a freely\ndownloadable genai copycat of us when searching our names online could be\ndevastating to individual careers and our industry as a whole.\u201d - Steven Zapata", "**Loss of ability to compete**\n\n-  \u201cWithout guardrails, genai poses a profound threat to writers and the integrity of\nour creative work.\n\ngenai and its use raises major questions of intellectual property,\ntransparency of competition, all of which require careful oversight to protect the\ncreative economy.\u201d - John August\n\n-  \u201cIt's difficult enough to compete against other humans.\n\nNow mom and pop voice\nactors across the country have to compete against digital clones of themselves\nand against multimillion and billion dollar tech companies.\n\nIt's incredibly easy to\nuse genai to capture the voice of an actor from content available on the internet, and\nto use that sample to create whole works for sale or non-commercial\ndistribution.\u201d - Tim Friedlander\n\n-  \u201cMusicians\u2019 work is being stolen from them and then used to create genai-generated\ntracks that directly compete with them.\n\nFor example, we might see dominant\nstreaming platforms packing playlists with genai music that they obtain free of\ncharge or at a massive discount, which then lowers their own royalty obligations\nand diminishes artists wages.\u201d - Jen Jacobsen\n\n-  \u201cThis conduct may violate \u201cright of publicity\u201d laws in several states, but it needs\nto be recognized universally as a misappropriation that causes real harm not only\nto the artists, but to the entire market by confusing consumers and creating\nunfair competition.\u201d - Jen Jacobsen\n\n32\n\n\n-----\n\n-  \u201cThe increasing scale of machine-generated music dilutes the market and makes\nit more difficult for consumers to find the artists they want to hear.\n\nIt makes it\nharder for artists to connect with their fans, and it devalues human creativity.\u201d Jen Jacobsen\n\n-  \u201cWithout transparency, we can't even know the extent of how much of these\ncompanies have taken.\n\nThey took our work and data to train for-profit\ntechnologies that then directly compete against us in our own markets using\ngenerative media that is meant to mimic us.\u201d - Karla Ortiz\n\n-  \u201cMeanwhile, Big Tech has launched a campaign to manufacture consent about\nthese systems.\n\nBig Tech claims that the rules, licensing, and legislation that is\napplied to creative works since the 1800s in the United States are suddenly moot\nsimply because machine learning is, in their view, too important to be bogged\ndown by the licensing choices of human creators of works.\u201d - Bradley Kuhn", "**Reputational damage**\n\n-  \u201cIn February, Twitter doxxing: Voice actors such as Michael Schwalbe and Abbey\nVeffer had their voices cloned and had Twitter accounts made that gave out their\npersonal addresses in their own voice and said racist and homophobic things.\u201d Tim Friedlander\n\n-  \u201cIt's hard to imagine anything more personal to an artist or to anyone than being\ndepicted as doing or saying things that they would never do or say.\n\nIt's not only\nconfusing to fans, but humiliating to the artists themselves and undermines their\npublic image.\u201d - Jen Jacobson\n\n-  \u201cRight now, authors are finding genai generated knock-offs of their work published\non Amazon.\n\nThey're having to fight to get those fakes taken down, and protect\ntheir brands.\u201d - John August", "**Deepfakes, Impersonations, and/or Fan confusion**\n\n-  \u201cIt is using stolen goods to undercut the price of a seller and create market\nconfusion, and it's not a hypothetical.\n\nRight now, authors are finding genai\ngenerated knock-offs of their work published on Amazon.\n\nThey're having to fight\nto get those fakes taken down, and protect their brands.\u201d - John August\n\n-  \u201cFrom electronics to organic eggs, consumers expect to be told the origin of a\nproduct and its authenticity.\n\nConsumers make choices based on that information.\n\nThe same will likely be true with genai.\u201d - John August\n\n-  \u201cWe traced the source of much of this activity to YouTube, TikTok, and blog\ncontent hosted by side hustle con artists that would waive a stack of cash and\nmake false claims about earning riches from ChatGPT.\n\nTheir intent was to earn\nadvertising revenue or sell classes to those that tried and failed.\n\nThey knew these\ntactics would not get people published.\n\nWe happened to be on a list of a hundred\n\n33\n\n\n-----\n\nor so magazines that were used as part of these schemes.\n\nOver the months that\nfollowed, copycats would refine their approach.\u201d - Neil Clarke\n\n-  \u201cWe are already seeing that genai is being used to generate low quality eBooks,\nimpersonating authors, and displacing human authored books in the\nmarketplaces like Amazon.\u201d - Umair Kazi\n\n-  \u201cgenai is being used to create unauthorized derivative works such as a\ndeveloper using ChatGPT to write the concluding books in George R. R. Martin's,\n\u201cA Song of Ice and Fire\u201d Series and chatbots like the Dan Brown Chatbot.\u201d Umair Kazi\n\n-  \u201cAnd at the same time, many authors were discovering that ChatGPT-3 knew\neverything about their books as well.\n\nAnd some realized it was even being used to\ncreate works that imitated their own.\n\nMy friend George R.R.\n\nMartin, who was\nalready mentioned, was very disturbed when genai was used to write the last book in\nhis Game of Thrones series using his characters, his plot lines, his settings\u2014even\nhis voice.\u201d - Douglas Preston\n\n-  \u201cThousands of synthetic voices are currently online on websites from video games\nall over the internet.\n\nFan dubs are being created and turned into adult content,\nand then sharing those fan dubs on YouTube using the voices of those voice\nactors.\u201d - Tim Friedlander\n\n-  \u201cThose who had been scanned described not being given information about how\ntheir scans would be used, unknowingly handing away rights to their image, and\nnot being fairly compensated.\n\nFor people whose livelihoods are their image, this\nis particularly troubling in light of the rise in deepfake technology, specifically\ndeepfake pornography.\u201d - Sara Ziff\n\n-  \u201cThe companies offering these models often encourage users to request work in\nthe styles of particular artists by name, and many of these generations end up\nonline with our names attached to these pieces that we didn't make.\u201d - Steven\nZapata\n\n-  \u201cAnd perhaps even more disturbingly, genai models are now using artists\u2019 faces,\nvoices, and performances without permission to make digital impersonations\nthat not only create consumer confusion, but also cause serious harm to both fans\nand artists.\n\nThese deep fakes have depicted a band canceling a concert that wasn't\nactually canceled.\n\nThey've shown artists selling products that the artists never\nendorsed.\n\nWe've seen false depictions of musicians badmouthing their own fans.\n\nThis isn't a hypothetical harm.\n\nThis type of consumer deception and fraud are\nhappening right now.\u201d - Jen Jacobson\n\n\n\n-  \u201cThe ability to create a synthetic voice from anyone who has recorded audio is\neasy and simple and dangerous.\n\nCurrently now it only takes three seconds of\nsource audio to create a realistic voice clone.\n\nAnd this synthetic content can be\nused to deceive consumers into believing that a trusted voice is communicating\n\n34\n\n\n-----\n\nwith them.\n\nThis can lead to relying on false and misleading information and\npotentially even implicate the human whose voice has been used to harm people.\u201d\n\n-  Tim Friedlander", "**Consent, Permission, and/or Opt-out vs. opt-in**\n\n-  \u201cIf consumers take anything away from my comments today, I hope they\nremember to carefully read the terms and conditions of all software platforms\nthey use, as they may have already agreed for their own creative works to become\npart of the company's machine learning data sets.\n\nI admit it may take you a week\nto read all of those terms, but it's sadly the only way you'll know what rights\nyou've inadvertently given away to Big Tech.\u201d - Bradley Kuhn\n\n-  \u201cgenai developers have copied millions of copyrighted works without permission.\n\nThese works are not only copied many times in the course of compiling training\ndata sets and ingestion, but are embedded in the very fabric of the language\nmodels.\u201d - Umair Kazi\n\n-  \u201cAnd at one point, I asked it to write a poem in heroic couplets about one of my\ncharacters.\n\nAnd I was floored at the level of detail it knew when it generated this\npoem, and that's when I realized it must've ingested many of my books.\u201d Douglas Preston\n\n-  \u201cOpenAI illegally ingested our books to create a product that is currently valued\nat tens of billions of dollars, and they did this without our consent or\ncompensation.\n\nAnd as Umair mentioned, the average full-time author in America\nmakes only $20,000 a year.\n\nThis is a classic case of Robin Hood in reverse,\nstealing from the poor to give to the already obscenely rich.\u201d - Douglas Preston\n\n-  \u201cIn their race to be first, genai developers are swallowing everything they can get\ntheir hands on without regard to copyright ownership, intellectual property\nrights, or moral rights.\n\nAnd they're doing this without the slightest consideration\ngiven to supporting the livelihood of America's creative class.\u201d - Douglas Preston\n\n-  \u201cI personally am working on a synthetic voice that I have consent, compensation,\nand control for.\n\nThere are some things that humans can't physically do, such as\nnarrate the New York Times cover-to-cover every morning, or provide a realistic\nvoice for someone who is nonverbal.\n\nBut this tech should enhance and not\nreplace voice actors.\u201d - Tim Friedlander\n\n-  \u201cSo we need regulation, intervention, and oversight.\n\nWe as creators should have\ncomplete control over how our work is used, but we need help.\n\nSome of the\npotential actions and remedies that we hope to see include, first and foremost,\nensuring that all commercial genai models utilize only public domain content or\nlegally licensed datasets acquired in an opt-in capacity.\n\nOpt-out is completely\ninsufficient here.\n\nThis could mean current companies shifting to the public\n\n35\n\n\n-----\n\ndomain and possibly destroying their current models in the process so that opt-in\nbecomes the standard.\u201d - Steven Zapata\n\n-  \u201cMainstream models like DALL-E 3 don't reveal their training data and don't let\nyou search it, but they do offer an inefficient one by one opt-out system that you\ncan use if you think maybe your art is in there.\u201d - Steven Zapata\n\n-  \u201cWhat's new today, though, are the expansive genai models that ingest massive\namounts of musical works and mimic artists voices without obtaining creators\nconsent or compensating them.\u201d - Jen Jacobson\n\n-  \u201cThe final point I want to make is about the importance of choice.\n\nMany genai\ncompanies who have illegally vacuumed up hundreds of thousands of musical\nworks and recordings now say that artists can simply contact the company and\n\u201copt out.\u201d This is essentially proposing a new form of uncompensated labor that\nmusicians and composers have to perform if they want to avoid exploitation.\u201d Jen Jacobson\n\n-  \u201cOpt-out is completely insufficient here.\n\nThis could mean current companies\nshifting to the public domain and possibly destroying their current models in the\nprocess so that opt-in becomes the standard.\u201d - Steven Zapata\n\n-  \u201cBasically, tech companies must respect artists ownership rights.\n\nThose seeking\nto profit from others works should have the burden of obtaining permission.\n\nExplicit opt-in is the only way forward.\n\nIt's really how we ensure genai\nmodels exclude unauthorized works from the beginning.\u201d - Karla Ortiz", "**Machine unlearning**\n\n-  \u201cBut because these genai systems can't unlearn, this will only remove the images\nfrom future training datasets used by this one company and it's already too late to\nget out of the most current model.\u201d - Steven Zapata\n\n-  \u201cYeah, so opt-out is an ineffective and inappropriate standard for commercial use\nof copyrighted works including a genai.\n\nOnce a model is trained on data,\nit cannot be deleted unless the whole model is retrained from scratch.\n\nBy the time\na model is made public, it's already too late to opt out.\u201d - Karla Ortiz", "**Transparency and disclosure**\n\n-  \u201cWe also need transparency on datasets, and divulging your dataset should be\ncompulsory.\u201d - Steven Zapata\n\n-  \u201cExisting opt-out procedures often ask users to list works used to train the model\nthey own, but as we just mentioned, that training data is secret, so it's an\nimpossible task.\n\nAnd four, there are hundreds of genai models already in the market\nand more.\u201d - Karla Ortiz\n\n36\n\n\n-----\n\n-  \u201cBut as far as how we know our books are being used in genai training, we have\nabsolutely no idea.\n\nIt's a black hole.\n\nOpenAI is training ChatGPT 5 right now, is\nbuilding it.\n\nThey refuse to answer any questions from the Author's Guild about\nwhat data sets they're using, where they're getting their books, and how they're\nbeing used.\n\nThere's no transparency at all.\n\nIt's an absolute black hole.\u201d - Douglas\nPreston", "**Policy and legislative efforts**\n\n-  \u201cThe fight for protection over our craft and livelihoods doesn't stop at the\nbargaining table.\n\nWhile we have been able to achieve groundbreaking protection\nfor writers, we need public policy solutions, too.\u201d - John August, WGA West\n\n-  \u201cThe Guild\u2019s new agreement offers helpful guidance in thinking about future\npublic policy on genai.\n\nOur agreement defines that genai is not a writer and the\nmaterial it generates is not equivalent to human writing for purposes of our\ncontract.\n\nThat means that genai cannot rewrite us, nor can it compete with a human\nwriter for credit and the associated financial benefit of that credit.\u201d - John August\n\n-  \u201cAnd as such, NAVA recently endorsed the [US Senators] Schatz and Kennedy\u2019s\ngenai Labeling Act of 2023, which is Senate Bill 2691 that we are fully endorsing.\u201d Tim Friedlander\n\n-  \u201cTo address these concerns, we first aim to pass the Fashion Workers Act, our\nsignature bill, which would establish basic labor protections for models and\ncontent creators working in New York's fashion industry.\n\nThis would help\naddress the lack of transparency that leaves models in the dark about how their\ndigital image is being used, and establish a necessary foundation for regulation\naround genai in the fashion industry.\u201d - Sara Ziff\n\n-  \u201cSecond is artists need to have enough power to negotiate fair license terms with\nthese gigantic genai developers.\n\nThere's actually a bill in Congress sponsored by\nrepresentative Deborah Ross that would give small and independent musicians\nan antitrust exemption so they can come together and negotiate collectively, both\nwith genai developers and streaming platforms, which is something they do not have\nthe leverage to do currently.\u201d - Jen Jacobson", "**Lawsuits**\n\n-  \u201cI'm also the plaintiff in a class action lawsuit against OpenAI, along with 15\nother authors and the Guild itself.\n\nAnd we're asking for damages for unauthorized\n\n37\n\n\n-----\n\nuse of our copyrighted work and training and building ChatGPT.\u201d - Douglas\nPreston\n\n-  \u201cAnd that's why we joined together, the 17 of us authors, in a class action lawsuit\non behalf of all professional novelists against OpenAI.\n\nThere's nothing\ncomplicated about this lawsuit.\u201d - Douglas Preston\n\n-  \u201cAs a side note, due to all of this, I am also a plaintiff in a class action against\ngenai image companies as well.\u201d - Karla Ortiz", "**Self-initiated research and investigations**\n\n-  \u201cI evaluated many of the public and commercial detection tools and found their\nclaims significantly overstated.\n\nThe number of false positives and false negatives\nmade them unusable.\u201d - Neil Clarke\n\n-  \u201cSo we at the Authors Guild investigated, and here are some of the facts we\nuncovered.\n\nChatGPT3 used more than 150,000 copyrighted books to feed into its\ngenai system, which led us to the next question.\n\n\"Where did OpenAI get our books?\"\n\nThey're not just sitting out there on the web unprotected.\n\nWell, the Authors Guild\nfound that OpenAI got many, if not most, of these books from pirate websites\nsuch as LibGen run out of Russia.\u201d - Douglas Preston\n\n-  \u201cWe're also developing a research study in partnership with the Worker Institute\nat Cornell University to better understand the impact of genai on fashion\nworkers, particularly workers of color, and develop policy recommendations.\u201d Sara Ziff", "**Collective bargaining**\n\n-  \u201cWe won these protections because we're a strong union that successfully carried\noff a nearly five month strike.\n\nBut we need to remember that most writers and\nmost artists in this country don't have unions to protect them.\u201d - John August\n\n-  \u201cWe stand in solidarity with our fellow creative industry artists who are in\nunions.\n\nBut unlike them, 80% of the voiceover industry is non-union, meaning we\nlack the protections and contract that organize workers enjoy.\u201d - Tim Friedlander\n\n-  \u201cModels are typically hired as independent contractors through management\ncompanies which, unlike talent agencies, are held to very few legal standards.\n\nSo\nwhen we talk about how genai is impacting workers, we need to consider\nthe context of an industry that is truly like the Wild West\u2013 where workers have\nfew protections at baseline and also cannot collectively bargain here in the US.\u201d Sara Ziff\n\n-  \u201cAt The Model Alliance, we believe now is a critical time for solidarity between\nworkers across creative fields who contribute heavily to our culture and economy.\n\nUnfortunately, it's not enough to win protections through collective bargaining\nagreements.\n\nThere are many workers, including members of our community, who\n\n38\n\n\n-----\n\ncannot engage in collective bargaining, and so we have to ensure that they are\nincluded.\u201d - Sara Ziff\n\n-  \u201cAnd unfortunately, visual artists don't have strong union representation to push\nback on this.\n\nAs it stands, you can work hard for a company like Disney for 25\nyears and they can take all your work, train a model on it, and then have a free\nand tireless replica of you to use in perpetuity.\u201d - Steven Zapata\n\n-  \u201cThe solutions sought have been traditionally approached in two ways: collective\nbargaining with industry and legislative lobbying.\n\nBoth paths tend to seek\nsecondary income to those performers whose work has been diminished by\nadvancing technology.\u201d - John Painting", "**Regulation**\n\n-  \u201cWe need oversight.\u201d - Steven Zapata\n\n-  \u201cRegulation of this industry is needed sooner than later, and each moment they\nare allowed to continue their current practices only causes more harm.\n\nTheir\nactions to date demonstrate that they cannot be trusted to do it themselves.\u201d Neil Clarke\n\n-  \u201cgenai poses a serious threat to the writing profession, and we believe\nthat guardrails around its development and use are urgently needed.\u201d - Umair\nKazi\n\n-  \u201cNo copyright for genai-generated outputs.\n\nWe oppose efforts to deem genai-generated\ncontent protectable under copyright law or through creation of even a limited\nsuite generous right\u201d\n\n-  Umair Kazi\n\n-  \u201cWe're here today because a future with unregulated genai will hurt concept artists\nand all other sorts of artists across many fields.\n\nWe need regulation, intervention,\nand oversight.\u201d - Steven Zapata\n\n-  \u201cIf the FTC is not able to do this through rulemaking, we would request the FTC's\nsupport for federal legislation to establish that right.\n\nTransparency of ingested\ncontent on which these foundational models are trained in order to know if our\nvoice is present.\n\nProtections prior to the generation of any genai-created content\nthat might include voices of professionals that have not provided consent and are\nnot being compensated.\n\nProtection of our voices' biometric data for privacy and\ncommercial purposes.\n\nAn independent third party to verify that audio files are\nethically sourced.\n\nAnd finally, clear labeling of any genai-generated content to\nensure the consumers are fairly informed.\u201d - Tim Friedlander\n\n-  \u201cRegulatory agencies should act now to protect artists, consumers, and other\nAmericans from this unconscionable exploitation.\n\nRegulatory agencies should\n\n39\n\n\n-----\n\ndemand full transparency from genai companies and opt-in only\npractices.\u201d - Karla Ortiz\n\n-  \u201cLastly, regulatory agencies should strongly consider seeking algorithmic\ndisgorgement on products built on data acquired without consent, credit, or\ncompensation, regardless whether that company is transparent or not.\n\nUrgent\nmeasures like these will be needed to avoid, in my opinion, the diminishing or\noutright destruction of most, if not all creative professional livelihoods and the\nprotections of all of our rights.\u201d - Karla Ortiz\n\n-  \u201cIn my opinion, there's no reason that big tech shouldn't be regulated to make\nthese systems transparent, completely end to end.\u201d - Bradley Kuhn", "**Consent**\n\n-  \u201cConsent and compensation.\n\nRequire all genai companies to seek\npermission for the use of creative works and to fairly compensate creators.\u201d Umair Kazi\n\n-  \u201cAnd going forward, we're asking that OpenAI and other genai developers get\npermission from authors, properly license our books, and compensate us fairly\nfor that use.\u201d - Douglas Preston\n\n-  \u201cWe also think authors and artists should have the right to say that they don't\nwant their identities, works, voice or style used in outputs.\u201d - Umair Kazi\n\n-  \u201cThat's why we think it's critical that we require artists have affirmative consent\nbefore the work can be used to train genai models and that they have to\nbe compensated fairly when they do so.\n\nThe same should be true for all artists,\nincluding artists like us who do work for hire and don't hold the copyright on our\nwork.\u201d - John August\n\n**\u201cA system that is opt-in.\n\nNot opt-out.\u201d**\n\n-  \u201cAnd this system needs to be opt-in and not opt-out.\n\nAs Jen just said, there are so\nmany companies out there developing and training genai models, to be forced to\ncontinually track all of them down to opt out is an enormous administrative\nburden on individual artists.\n\nIt's not practical.\n\nIt has to be opt-in rather than optout.\u201d - John August", "**Credit and Transparency**\n\n-  \u201cCredit and transparency.\n\nCreate obligations for all genai companies to disclose\nwhat data sets and works they use to train the systems.\u201d - Umair Kazi\n\n-  \u201cLabeling genai-generated content.\u201d - Umair Kazi\n\n-  \u201cAs far as what we want, we want genai companies to be required to fully disclose\nthe complete lists of copyrighted works, books in particular is the medium that\nwe deal with most often, that are in the training data sets or provide specific links\n\n40\n\n\n-----\n\nto where the data sets were obtained from.\n\nAnd anyone compiling a training\ndataset should be similarly obligated to disclose the sources.\n\nAnd in the case of\ncopyrighted works, a complete list of works that have been included in the\ndataset.\u201d - Umair Kazi\n\n-  \u201cAnd we believe that there should be a requirement to conspicuously label fully or\nsubstantially genai generated words in online marketplaces.\u201d - Umair Kazi\n\n-  \u201cIn my view, the public should have access to the input set, have access to the\nsource code of the software that does the training and generation, and most\nimportantly, access to the source code that does these forms of backend\ngeneration exclusion, the latter of which I think would expose the duplicity of big\ntech's policies here.\u201d - Bradley Kuhn\n\n-  \u201cAt a minimum the consumers should know when genai is used to generate voices\nand receive a warning that the information they're going to receive may not be\naccurate.\u201d - Tim Friedlander\n\n-  \u201cWe need compulsory transparency and tools to verify compliance.\u201d - Steven\nZapata", "**Compensation**\n\n-  \u201cPermission and payment for use in outputs.\n\nRequire all genai companies to seek\npermission and pay compensation when creative works are used in outputs or\nwhen names or identities or titles of works are used in prompts.\u201d - Umair Kazi\n\n-  \u201cWe should also have genai companies pay a fine for their past practices and pay all\naffected artists a fee per generation.\n\nThis is to compensate artists for utilizing\ntheir works and names without permission, should be retroactive for as long as\nthe company has been for-profit.\n\nWe must close research to-commercial\nloopholes, interpreted or actual, that allow for-profit companies to monetize the\nresults of non-commercial research.\u201d - Steven Zapata", "**Licensing**\n\n-  \u201cAnd the third thing I would say is there is not a one-size-fits-all licensing system\nthat will work for all creators or even for all musicians.\n\nAssuming there is a level\nplaying field for negotiating, we think the best way for musicians to license their\nwork is in the free market, which may look different for every use, every artist\nand every company.\u201d - Jen Jacobson\n\n-  \u201cWithout a doubt, licensing will be essential in the future, but we must\naccomplish that through an opt-in system, otherwise there would be no real\nnegotiating leverage for creators.\n\nAnd the focus of licensing, I think should go\ntowards new opt-in foundation models, not the fine tuning of existing unethical\nmodels.\n\nAs to when companies hold the rights to work done for hire and want to\nlicense or train off of that, we need regulation.\u201d - Steven Zapata\n\n41\n\n\n-----\n\n-  \u201cI mean, visual artists, for example, lack the union representation to push back\nagainst contracts that claim all ownership.\n\nAnd without regulation, I think\npredatory contracts will just run rampant in this sector.\n\nAnd collective licensing\nis also troubling.\n\nThe early experiments we are seeing with \"contributor funds\"\nfrom companies like Shutterstock are paying out less than pennies.\n\nI mean actual\nfractions of a penny per used image.\n\nThat's all they want to pay a creator for their\nlife's work and to create a tool that will directly compete against them forever.\u201d Steven Zapata\n\n42\n\n\n-----", "April 26, 2023\n\nDr. Dario Amodei\nChief Executive Officer\nAnthropic\n548 Market St, PMB 90375\nSan Francisco, CA 94104\n\nDear Dr. Amodei,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.", "Available at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nMr. Tim Cook\nChief Executive Officer\nApple\nOne Apple Park Way\nCupertino, CA 95014\n\nDear Mr. Cook,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.", "genai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.", "Do you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nMr. Sundar Pichai\nChief Executive Officer\nGoogle\n1600 Amphitheater Parkway\nMountain View, CA 94043\n\nDear Mr. Pichai,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.", "In addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nMr. Mark Zuckerberg\nChief Executive Officer\nMeta Platforms, Inc.\n1 Hacker Way\nMenlo Park, CA 94025\n\nDear Mr. Zuckerberg,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.", "While public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.", "Chatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nMr. Satya Nadella\nChief Executive Officer\nMicrosoft Corporation\n1 Microsoft Way\nRedmond, WA 98052\n\nDear Mr. Nadella,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.", "and International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.", "14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nMr. David Holz\nChief Executive Officer\nMidjourney\n611 Gateway Blvd Suite 120\nSouth San Francisco, CA 94080\n\nDear Mr. Holz,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.", "I request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nMr. Sam Altman\nChief Executive Officer\nOpenAI\n3180 18th St\nSan Francisco, CA\n\nDear Mr. Altman,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.", "As a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?", "5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nBrigadier General Balan Ayyar, USAF, Retired\nChief Executive Officer\nPercipient.genai\n3975 Freedom Cir.\n\nSuite 850\nSanta Clara, CA 95054\n\nDear Brigadier General Ayyar,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.", "Each of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.", "Have you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nMr. Alexandr Wang\nChief Executive Officer\nScale genai\n155 5th St\nSan Francisco, CA 94103\n\nDear Mr. Wang,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?", "2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----\n\nApril 26, 2023\n\nMr. Emad Mostaque\nChief Executive Officer\nStability genai\n88 Notting Hill Gate\nLondon, England, W11 3HP\n\nDear Mr. Mostaque,\n\nI write today regarding the need to prioritize security in the design and development of artificial\nintelligence (genai) systems.\n\nAs companies like yours make rapid advancements in genai, we must\nacknowledge the security risks inherent in this technology and ensure genai development and\nadoption proceeds in a responsible and secure way.\n\nWhile public concern about the safety and\nsecurity of genai has been on the rise, I know that work on genai security is not new.\n\nHowever, with\nthe increasing use of genai across large swaths of our economy, and the possibility for large\nlanguage models to be steadily integrated into a range of existing systems, from healthcare to\nfinance sectors, I see an urgent need to underscore the importance of putting security at the\nforefront of your work.\n\nBeyond industry commitments, however, it is also clear that some level\nof regulation is necessary in this field.\n\nI recognize the important work you and your colleagues are doing to advance genai.\n\nAs a leading\ncompany in this emerging technology, I believe you have a responsibility to ensure that your\ntechnology products and systems are secure.\n\nI have long advocated for incorporating security-bydesign, as we have found time and again that failing to consider security early in the product\ndevelopment lifecycle leads to more costly and less effective security.\n\nInstead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .", "Instead, incorporating\nsecurity upfront can reduce costs 1 and risks 2 .\n\nMoreover, the last five years have demonstrated\nthat the ways in which the speed, scale, and excitement associated with new technologies have\nfrequently obscured the shortcomings of their creators in anticipating the harmful effects of their\nuse.\n\ngenai capabilities hold enormous potential; however, we must ensure that they do not advance\nwithout appropriate safeguards and regulation.\n\nWhile it is important to apply many of the same security principles we associate with traditional\ncomputing services and devices, genai presents a new set of security concerns that are distinct from\n\n1 Maurice Dawson et al., \u201cIntegrating Software Assurance into the Software Development Life Cycle (SDLC),\u201d\nJournal of Information Systems Technology and Planning (2010), Available at:\n\nSoftware_Assurance_into_the_Software_Development_Life_Cycle_SDLC\n2 \u201cU.S.\n\nand International Partners Publish Secure-by-Design and -Default Principles and Approaches,\u201d\nCybersecurity and Infrastructure Security Agency (April 13, 2023), \n\n\n-----\n\ntraditional software vulnerabilities.\n\nSome of the genai-specific security risks that I am concerned\nabout include the origin, quality, and accuracy of input data (data supply chain) 3 , tampering with\ntraining data (data poisoning attacks) 4 , and inputs to models that intentionally cause them to\nmake mistakes (adversarial examples) 5 .\n\nEach of these risks further highlighting the need for\nsecure, quality data inputs.\n\nBroadly speaking, these techniques can effectively defeat or degrade\nthe integrity, security, or performance of an genai system (including the potential confidentiality of\nits training data).\n\nAs leading models are increasingly integrated into larger systems, often\nwithout fully mapping dependencies and downstream implications, the effects of adversarial\nattacks on genai systems are only magnified.\n\nIn addition to those risks, I also have concerns regarding bias, trustworthiness, and potential\nmisuse or malicious use of genai systems.\n\nIn the last six months, we have seen open source\nresearchers repeatedly exploit a number of prominent, publicly-accessible generative models \u2013\ncrafting a range of clever (and often foreseeable) prompts to easily circumvent a system\u2019s rules.\n\nExamples include using widely-adopted models to generate malware 6 , craft increasingly\nsophisticated phishing techniques 7 , contribute to disinformation 8 , and provide harmful\ninformation 9 .\n\nIt is imperative that we address threats to not only digital security, but also threats\nto physical security and political security.\n\n10\n\nIn light of this, I am interested in learning about the measures that your company is taking to\nensure the security of its genai systems.\n\nI request that you provide answers to the following\nquestions no later than May 26, 2023.\n\nQuestions:\n\n\n1.\n\nCan you provide an overview of your company\u2019s security approach or strategy?\n\n2.\n\nWhat limits do you enforce on third-party access to your model and how do you actively\n\nmonitor for non-compliant uses?\n\n3 \u201cOWASP genai Security and Privacy Guide,\u201d OWASP Foundation, \n4 Fahri An\u0131l Yerlikaya, \u015eerif Bahtiyar, \u201cData poisoning attacks against machine learning algorithms\u201d,\nExpert Systems with Applications, Volume 208, (July 18, 2022).\n\nAvailable at:\n\n5 Alexey Kurakin, Ian Goodfellow, Samy Bengio, \u201cAdversarial Examples in the Physical World,\u201d Google, Inc.\n\nAvailable at: \n6 Dan Goodin, \u201cHackers Are Selling A Service that Bypasses ChatGPT Restrictions on Malware,\u201d Ars Technica\n(February 8, 2023) \n7 Lily Hay Newman, \u201cgenai Wrote Better Phishing Emails Than Humans in a Recent Test,\u201d Wired (August 7, 2021),\n\n8 Tiffany Hsu, Stuart A. Thompson, \u201cDisinformation Researchers Raise Alarms About A.I.\n\nChatbots,\u201d New York\nTimes (February 13, 2023), \n9 \u201cGPT-4 Jailbreak and Hacking via RabbitHole attack, Prompt injection, Content moderation bypass and\nWeaponizing genai,\u201d Adversa genai (March 15, 2023), \n10 Miles Brundage et al., \u201cThe Malicious Use of genai: Forecasting, Prevention, and Mitigation,\u201d\n(February, 2018), \n\n\n-----\n\n3.\n\nAre you participating in third party (internal or external) test & evaluation, verification\n\n& validation of your systems?\n\n4.\n\nWhat steps have you taken to ensure that you have secure and accurate data inputs and\n\noutputs?\n\nHave you provided comprehensive and accurate documentation of your training\ndata to downstream users to allow them to evaluate whether your model is appropriate\nfor their use?\n\n5.\n\nDo you provide complete and accurate documentation of your model to commercial\n\nusers?\n\nWhich documentation standards or procedures do you rely on?\n\n6.\n\nWhat kind of input sanitization techniques do you implement to ensure that your systems\n\nare not susceptible to prompt injection techniques that pose underlying system risks?\n\n7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.", "7.\n\nHow are you monitoring and auditing your systems to detect and mitigate security\n\nbreaches?\n\n8.\n\nCan you explain the security measures that you take to prevent unauthorized access to\n\nyour systems and models?\n\n9.\n\nHow do you protect your systems against potential breaches or cyberattacks?\n\nDo you\n\nhave a plan in place to respond to a potential security incident?\n\nWhat is your process for\nalerting users that have integrated your model into downstream systems?\n\n10.\n\nWhat is your process for ensuring the privacy of sensitive or personal information you\n\nthat your system uses?\n\n11.\n\nCan you describe how your company has handled past security incidents?\n\n12.\n\nWhat security standards, if any, are you adhering to?\n\nAre you using NIST\u2019s genai Risk\n\nManagement Framework?\n\n11\n\n\n13.\n\nIs your company participating in the development of technical standards related to genai\n\nand genai security?\n\n14.\n\nHow are you ensuring that your company continues to be knowledgeable about evolving\n\nsecurity best practices and risks?\n\n15.\n\nHow is your company addressing concerns about genai trustworthiness, including potential\n\nalgorithmic bias and misuse or malicious use of genai?\n\n16.\n\nHave you identified any security challenges unique to genai that you believe policymakers\n\nshould address?\n\nThank you for your attention to these important matters and I look forward to your response.\n\nSincerely,\n\nMark R. Warner\nUnited States Senator\n\n11 \u201cgenai Risk Management Framework,\u201d NIST (July 12, 2021), \n\n\n-----", "# Policies in Parallel?\n\nA Comparative Study of Journalistic genai\n Policies in 52 Global News Organisations\n\nP RE -P RINT \u2013 N OT P EER -R EVIEWED\n\nKim Bj\u00f6rn Becker 1\u2020 , Felix M. Simon 2\u2020 , and Christopher Crum 3\u2021\n\n1 Frankfurter Allgemeine Zeitung, Frankfurt, Germany & Trier University, Trier, Germany, \n\n2 Oxford Internet Institute, University of Oxford, Oxford, United Kingdom, \n\n3 Oxford Internet Institute, University of Oxford, Oxford, United Kingdom\n\nSeptember 6 th , 2023\n\nAbstract\n\nA growing number of news organisations have set up specific guidelines to govern how they\nuse genai (genai).\n\nThis article analyses a set of 52 guidelines from publishers in\nBelgium, Brazil, Canada, Finland, Germany, India, the Netherlands, Norway, Sweden,\nSwitzerland, the United Kingdom, and the United States.\n\nLooking at both formal and\nthematic characteristics, we provide comparative insights into how news outlets address\nboth expectations and concerns when it comes to using genai in the news.\n\nDrawing from neoinstitutional theory and the concept of institutional isomorphism, we argue that the policies\nshow signs of homogeneity, likely explained by isomorphic dynamics which arose as a\nresponse to the uncertainty created by the rise of genai after the release of\nChatGPT in November 2022.\n\nOur study shows that publishers have already begun to\nconverge in their guidelines on key points such as transparency and human supervision\nwhen dealing with genai-generated content.\n\nHowever, we argue that national and\norganisational idiosyncrasies continue to matter in shaping publishers\u2019 practices, with both\naccounting for some of the variation seen in the data.\n\nWe conclude by pointing out blind\nspots around technological dependency, sustainable genai, and inequalities in current genai\nguidelines and providing directions for further research.\n\nKeywords : genai, LLMs, News, Journalism, Isomorphism, genai Guidelines,\ngenai Ethics, Comparative Analysis\n\n\u2020 Both authors contributed equally to the design, data collection, analysis, and writing of\nthe study.\n\n\u2021 Christopher Crum contributed to the coding and analysis of guidelines, designed, and\ncarried out the syntactical analysis, and contributed to the final write-up.\n\n-----", "# Literature Review\n\nEthical issues can arise at every juncture of the journalistic process.\n\nWhile professional\nethics is intimately linked to the quality of journalistic products, these concepts are not\nidentical.\n\nSometimes, measures aimed at enhancing the quality of journalism are not\nnecessarily based on ethical behaviour, and sometimes quality and journalistic ethics\nmight even be at odds, as seen with the speed of reporting (Meier, 2018, p. 250).\n\nToday\nprofessional ethics mainly pertains to issues related to the accuracy and verification of\ninformation, the independence of journalists and publishers, possible deception and\nfabrication of facts in the production of content, the use of graphic images and image\nmanipulation, and the handling of sources and confidentiality (Ward, 2009, pp.\n\n296297).\n\n1\n\n\n-----\n\nSelf-Regulation of the News Through Guidelines\n\nBelow the formal level of laws and regulations, which generally define what journalism\ncan and cannot do (Ru\u00df-Mohl & Schultz, 2023: pp.\n\n267-281ff.\n\n), the journalistic\nprofession relies on self-regulation.\n\nThis is particularly true in liberal democracies,\nwherein press freedoms curb potential government efforts to influence reporting.\n\nSelfregulation rests on two pillars.\n\nFirst, many news organisations regulate themselves by\nsetting up non-governmental press councils, who often issue broad guidelines which in\nturn shape the work of participating organisations.\n\nA study of 55 press council codes\nof ethics across 45 countries (European Commission, n.d.) found that these stress \u2018core\njournalistic ethical principles\u2019 such as fairness and accuracy in reporting, as well as\nautonomy of the press but are often very general in their remit.\n\nSecond, publishers\noften develop individual guidelines.\n\nAn editorial guideline constitutes a set of rules by\na specific organisation that media professionals must or should observe.\n\nSuch internal\nguidelines often show great variety, encompassing various documents, from formal\nregulations to informal memos (Duffy & Knight, 2018, p. 7).\n\nLarge publishers\u2019 own\nguidelines are often more specific than those of press councils and reflect the principal\nvalues and standards of the respective publisher (Schultz, 2021, p. 126).\n\nUsually, these\nare intended to further specify the rules for these organisations\u2019 journalists and staff.\n\nNews Organisations\u2019 Social and New Media Guidelines as Precursors\n\nIn recent years, publishers have formulated additional guidelines for specific topics, for\nexample the use of social media.\n\nVarious studies have looked at these, e.g., through\ninterviews or content analysis (Opgenhaffen & Scheerlinck, 2014; Bloom, Cleary &\nNorth, 2016; Adornato & Lysak, 2017; Sacco & Bossio, 2016; Ihlebaek & Larsson, 2018;\nOpgenhaffen & d\u2019Haenens, 2015; Lee, 2016; Duffy & Knight, 2018).\n\nMany of these\nfocused on English-speaking countries (Lee, 2016) due to shared ideological and\neconomic structures and similar media systems (Duffy & Knight, 2018, p. 7), with\nOpgenhaffen/d\u2019Haenens (2015), additionally focusing on Belgium and France.\n\nResearch on social media policies has largely been limited to mapping how\n\nspecific media companies understand social media and what kind of behaviour they\nrequire of their journalists on these platforms.\n\nThe modest sample sizes and focus on\nthe Anglosphere make broad conclusions difficult.\n\nHowever, the results showed \u2018no\nhomogeneity\u2019 (Opgenhaffen & d\u2019Haenens, 2015, p. 213) as well as \u2018ambivalence\u2019 (Duffy\n& Knight, 2018, p. 8) which is notable given that social media are somewhat similar in\ntheir affordances across countries.\n\nIn their study of ethics guidelines for immersive\njournalism of eight publishers in English and Spanish-speaking countries, S\u00e1nchez Laws\n& Utne (2019) mainly found differences by organisation type, with \u2018a stricter ethical\nregime [\u2026] in publicly funded broadcasters\u2019 (p. 5) compared to privately owned media.\n\nFinally, contrasting professional journalism ethics with social media guidelines, Lee\n(2016) found that the latter \u2018hardly reflect changing journalistic norms\u2019 (p. 121).\n\n-----\n\nPolicies for the Use of genai in News Organisations\n\nEarly research on news organisations\u2019 genai guidelines has also been largely descriptive.\n\nBecker (2023) examined a total of seven guidelines from Europe and North America,\nwhile Cools & Diakopoulos (2023) analysed 21 guidelines, 14 from Europe, five from\nNorth America and one each from Asia and South America.\n\nBoth studies looked at the\nformal level, examining how the documents were titled and what statements were made\nabout their binding nature.\n\nIn addition, they addressed why media companies want to\nuse genai, what applications should be allowed and prohibited, how to deal with human\noversight of genai-produced material and transparency, principles of responsible genai, and\npossible dynamisation of the guidelines.\n\nBecker (2023, pp.", "Becker (2023, pp.\n\n145-146) furthermore refers\nto internal and external collaboration, while Cools & Diakopoulos (2023) focus on\naccountability and responsibility, training, and the concept of cautious\n\nexperimentation.\n\nGiven the small sample sizes, possible patterns are cursory.\n\nFor example, Cools\n\n& Diakopoulos (2023) point out that two media outlets owned by the same company\ntend to have similar policies.\n\nBecker (2023, p. 147) noted links between the journalistic\nstyle of the organisation and the form chosen for the guidelines: \u2018The news agencies\npresent their guidelines briefly in a news-like style, while magazine[s] chose a more\nnarrative form, and a British broadcaster known for its structural complexity chose the\nform of detailed guidelines\u2019.\n\nIn addition, the goals for the use of genai in the newsroom,\nas stated in the guidelines, tended to vary between media organisations.\n\nThe genai policies\nof private sector news organisations seemed to associate genai with comparative business\nadvantages, such as speed and breadth of coverage, while public service broadcasters\nfocused more on public service implications (Becker 2023, p. 139).", "# Theoretical Framework\n\nNeo-Institutionalism and Institutional Isomorphism: How News Organisations deal\nwith Uncertainty\n\nIt is worth noting that journalism ethics were \u2018developed for a journalism of limited\nreach, whose public duties were assumed to stop at the border\u2019 with the search for a\nglobal journalism ethic still \u2018a work in progress\u2019 (Ward, 2009, pp.\n\n304-305).\n\nWhile both\nnational differences and organisational differences continue to matter in the news and\nplay a role in shaping publishers\u2019 and journalists\u2019 practices, including around the\nadoption of new technologies (Hanitzsch & Mellado, 2011; Perus \u030c ko et al., 2020), the\nnews industry, or its organisations, are also increasingly shaped by factors that\ntranscend nationally bounded media systems, for instance the growing influence of the\ntechnology sector, or they themselves transcend nationally bounded media systems\nbecause they operate in more than one national market.\n\ngenai as a technology also acts\nwith broadly similar effects across contexts, so it would be reasonable to assume that\noutlets across context react to the technology \u2013 and its concomitant challenges \u2013 in\nsimilar ways.\n\n-----\n\nTo explain possible similarities \u2013 a homogenisation \u2013 and patterns in genai\n\nguidelines on a larger scale, we work with a neo-institutional lens, in particular the\nconcept of institutional isomorphism, the \u2018tendency of organisations in a particular field\nto resemble one another,\u2019 especially when faced with constraints (DiMaggio & Powell,\n1983).\n\nIsomorphism can be the result of one or a combination of three possible factors:\ncoercive, mimetic, and normative.\n\n_Coercive_ isomorphism \u2018results from both formal and informal pressures exerted\n\non organisations by other organisations on which they depend and by cultural\nexpectations in the society in which organisations operate\u2019 (DiMaggio & Powell, 1983,\np. 150).\n\nPressures can include laws and regulations or industry standards.\n\n_Mimetic_\nisomorphism refers to an organisation\u2019s response to uncertainty which often encourages\norganisations to respond to a stimulus by modelling themselves on similar or more\nsuccessful organisations in their field.\n\nThis may be particularly true when \u2018technologies\nare poorly understood [...], when goals are ambiguous, or when the environment creates\nsymbolic uncertainty\u2019 (DiMaggio & Powell, 1983, p. 151).\n\nFinally, _normative_\nisomorphism is the result of pressure from professional groups, i.e., it \u2018stems primarily\nfrom professionalisation,\u2019 what DiMaggio & Powell describe as \u2018the collective struggle\nof members of a profession to define the conditions and methods of their work\u2019 (1983,\np. 152).\n\nFactors leading to normative isomorphism include inter-organisational\nnetworks of exchange or the movement of labour between firms.\n\nIn the news industry, there is ample evidence that isomorphic processes in the\n\npast have occurred as result of all three of these factors.\n\nLooking at the pivot to online\nvideo news, Kalogeropoulos & Nielsen (2018) found that a mixture of audience demand\n(coercive), commercial considerations (mimetic), uncertainty about platform\nbusinesses\u2019 interests and strategies, and uncertainty about the future direction of digital\nmedia (coercive, mimetic, normative) led the majority of organisations in their study\nto \u2018converge on a similar short, platform and mobile-oriented approach to online news\nvideo\u2019 with differences \u2018more clearly related to organisational differences than to\ncountry differences\u2019 (p.\n\n2221ff.).\n\nChristin (2020) and later Petre (2021) also\ndemonstrated forms of mimetic isomorphism in the use of audience metrics.\n\nFaced with\nuncertainty and constraints, publishers across organisation types (Petre) and countries\n(Christin) adopted audience metrics in broadly similar ways, even though some\ndifferences remain due to national and organisational idiosyncrasies.\n\nFinally, Simon\n(2023a) finds that the adoption of platform companies\u2019 genai and genai infrastructures\nfollows an isomorphic pattern, with uncertainty about the direction and effects of the\ntechnology and the fear of being left behind acting as strong motivators for forms of\nmimetic isomorphism, recurring movement of talent and the highly networked nature\nbetween these news organisations contributing to these forms of normative and mimetic\nisomorphism, and genai as a large technological system (Simon, 2023a) itself acting as\ncoercive force.\n\n-----\n\nConsidering the current uncertainty about what genai is, what it can and cannot\n\ndo for and to the news (Newman, 2023; Simon, 2023b; Simon & Isaza-Ibarra, 2023),\nisomorphism can serve as a useful theoretical framework to investigate the adoption\nand content of news organisations\u2019 genai guidelines.", "Our focus is therefore on examining\nthe following research questions:\n\nRQ0: _To what extent do international news organisations\u2019 genai guidelines exhibit_\n_isomorphic tendencies?_\n\nIt will be readily apparent, however, that this question is too general and hides several\nmore specific ones, as follows:\n\nRQ1 : What are the formal and thematic characteristics of news organisations\u2019\ngenai guidelines?\n\nRQ2 a : How do genai guidelines compare across organisational types (commercial\nvs public service)?\n\nRQ2 b : How do genai guidelines compare across different countries?\n\nRQ3: What are the blind spots of current genai guidelines in news organisations?", "# Case Selection, Data, and Methods\n\nTo explore these questions, this study draws on a sample of 52 editorial genai policies\nfrom media companies and organisations in twelve countries, representing both the\nglobal North and South.\n\nSampling of Cases\n\nRecent studies of social media and genai guidelines have been limited by small sample\nsizes and convenience sampling approaches, relying mainly on guidelines available\nonline.\n\nTo create a dataset with some meaningful variation that allows for a more\ngeneral analysis, we took a more systematic approach.\n\nFirst, we identified a set of\ntwelve countries falling into different media system categories (Hallin, 2016) where the\nexistence of genai guidelines was already known or likely to be expected.\n\nThese countries\ncan be grouped into four main geographical regions: Western Europe (Belgium,\nGermany, the Netherlands, Switzerland, and the United Kingdom), Scandinavia\n(Finland, Norway, and Sweden), North America (Canada and the United States), and\nthe Global South 2 (Brazil and India).\n\n2 We acknowledge that the concept of \u2018Global South\u2019 is fraught, especially as it is an exceptionally\nbroad and heterogeneous category.\n\n-----\n\nWe then identified up to six leading companies or organisations for each country\n\nbased on weekly use according to the Digital News Report (Newman et al.\n\n2023) in\neach of the following categories: magazine, media group, news agency, legacy\nnewspaper, online news/digital-born, private broadcaster, professional organisation,\nand public broadcaster.\n\nBecause national media markets differ significantly from\ncountry to country, the sample is not entirely symmetrical.\n\nTo avoid missing out on\nimportant outlets not captured by the overall sampling, we strategically incorporated\nadditional outlets based on recommendations from country experts.\n\nThe final sample\nincluded 207 media outlets which we contacted by email.\n\nOf the 207 organisations, we were ultimately able to include 52 genai policies in\n\nour study.\n\nSeven media companies indicated that their policies were still under\ndevelopment, ten organisations had policies in place but would not share them for\nacademic purposes, and a further eleven companies responded that they had no genai\npolicies.\n\nWe received no response from 127 contacted media organisations.\n\nIn the final\nsample, a total of 33 documents (63.46%) were found online, in eight cases the\ncompanies made their policies available to us (15.38%), and in a further eleven cases\nwe were able to obtain the documents from other sources (21.15%).\n\n21 guidelines were\navailable in English (40.38%), while the remaining 31 documents (59.62%) were\ntranslated to English using the neural machine translation service DeepL.\n\nWhere\npossible, we verified the accuracy of translations drawing from our own experience\n(with German, Dutch and French) or with the help of native speakers.\n\nTable 1: Study sample, sorted by country and organisation type\n\nNr.", "Table 1: Study sample, sorted by country and organisation type\n\nNr.\n\nName Country Organisation type Source\n\n1 Mediahuis Belgium Media group Online\n\n2 Raad voor de Journalistiek Belgium Professional organisation Online\n\n3 RTBF Belgium Public broadcaster Obtained\n\n4 Nucleo Brazil Digital-born media Online\n\n5 The Globe and Mail Canada Legacy newspaper Online\n\n6 CBC Canada Public broadcaster Online\n\n7 Helsingin Sanomat Finland Legacy newspaper Obtained\n\n8 Suomen Tietotoimisto Finland News agency Obtained\n\n9 Council for Mass Media Finland Professional organisation Online\n\n10 Yle Finland Public broadcaster Obtained\n\n11 T-Online Germany Digital-born media Online\n\n12 Web.de/GMX/1&1 Germany Digital-born media Online\n\n\n13 Frankfurter Allgemeine\nZeitung\n\n\nGermany Legacy newspaper Online\n\n\n14 Rheinische Post Germany Legacy newspaper Provided\n\n15 S\u00fcddeutsche Zeitung Germany Legacy newspaper Online\n\n16 Handelsblatt Germany Legacy newspaper Obtained\n\n17 Der Spiegel Germany Magazine Online\n\n18 Ippen Germany Media group Provided\n\n\n-----\n\n19 Deutsche Presse-Agentur Germany News agency Online\n\n\n20 Deutscher JournalistenVerband\n\n\nGermany Professional organisation Online\n\n\n21 Bayerischer Rundfunk Germany Public broadcaster Online\n\n22 The Quint India Digital-born media Obtained\n\n23 De Volkskrant Netherlands Legacy newspaper Online\n\n24 DPG Media Netherlands Media group Obtained\n\n25 ANP Netherlands News agency Obtained\n\n26 NPO Netherlands Public broadcaster Provided\n\n27 TV2 Norway Commercial broadcaster Obtained\n\n28 Dagens Naeringsliv Norway Legacy newspaper Online\n\n29 Schibsted Norway Media group Online\n\n30 NRK Norway Public broadcaster Provided\n\n31 Sveriges Television Sweden Commercial broadcaster Obtained\n\n32 Svenska Dagbladet Sweden Legacy newspaper Online\n\n33 Aftonbladet Sweden Legacy newspaper Online\n\n34 Dagens Nyheter Sweden Legacy Newspaper Provided\n\n35 Journalisten Sweden Legacy newspaper Online\n\n36 Bonnier Sweden Media group Provided\n\n37 TT Nyhetsbyran Sweden News agency Obtained\n\n38 Heidi News Switzerland Digital-born media Online\n\n39 Tamedia Switzerland Media group Online\n\n40 Ringier Switzerland Media group Online\n\n41 SRF Switzerland Public broadcaster Online\n\n42 ITN United Kingdom Commercial broadcaster Provided\n\n43 Financial Times United Kingdom Legacy newspaper Online\n\n44 Reuters United Kingdom News agency Online\n\n45 BBC United Kingdom Public broadcaster Online\n\n46 Business Insider United States Digital-born media Online\n\n47 USA Today United States Legacy newspaper Online\n\n48 The Atlantic United States Magazine Online\n\n49 Wired United States Magazine Online\n\n50 AP United States News agency Provided\n\n51 RTDNA United States Professional organisation Online\n\n52 National Public Radio United States Public broadcaster Online\n\nQualitative Coding, Quantitative Coding, Quantitative Syntactic Analysis\n\nTo analyse the genai guidelines included in our study we use a mixed methods approach\ncombining qualitative thematic content analysis, quantitative coding, and quantitative\nsyntactic analysis.\n\n_Qualitative and Quantitative Coding_\n\n\n-----\n\nDrawing from the literature on genai in the news as well as previous research on news\norganisations\u2019 general, social media, and genai guidelines (Becker, 2023; Opgenhaffen &\nd\u2019Haenens, 2015, p. 206) as well as a first round of inductive coding using open, axial,\nand selective coding, we developed a codebook spanning 50 categories (see Appendix,\nTables 1 and 2).\n\nThis was followed by a first round of deductive qualitative coding, where three coders\ncoded all guidelines for 15 selected formal and thematic characteristics, with the unit\nof analysis being each individual sentence.\n\nFormal characteristics included the\nprofessional roles and specific genai engines mentioned.\n\nThematic aspects were goals of\ngenai deployment, journalistic values mentioned, allowed and prohibited genai applications,\npossible pitfalls of journalistic genai use, applications where transparency is required,\npossible elements of algorithmic bias, aspects of source protection, professional roles\nand institutions involved in internal and external cooperation around genai, and views on\npossible dependencies on large genai platform companies.\n\nAdditionally, we analysed the\ndocuments through rigorous quantitative coding, focusing on 35 additional formal and\nthematic categories including allowed deployments of genai in the journalistic process,\nareas of human supervision, and methods of creating transparency when genai was used.\n\nThe unit of analysis was the whole document.\n\nEach document was coded into all the\ncategories.\n\nFor the quantitative coding, the codebook was tested and refined over two\ninitial rounds of test coding, whereby three coders independently coded a random\nselection of three guidelines in both rounds to resolve difficulties and\nmisunderstandings.\n\nAfter each round, the results were compared and discussed, and\nthe codebook refined.", "After each round, the results were compared and discussed, and\nthe codebook refined.\n\nOnce the codebook was set, two coders independently recoded all\n52 pieces of content.\n\nTo measure intercoder reliability, we used Krippendorf\u2019s Alpha as\nthe most rigorous and reliable measurement.\n\nThe reliability of each guideline\u2019s coding\nwas estimated based on 3640 (1820 x 2) independent decisions in the coding process.\n\nIn 68 cases the coders disagreed.\n\nKrippendorff suggests that it \u2018is customary to require\n\u03b1 \u2265 .800.\n\nWhere tentative conclusions are still acceptable, \u03b1 \u2265 .667 is the lowest\nconceivable limit (2004, p. 241).\u2019 Krippendorff\u2019s Alpha was .94 on average with a range\nof .73 and 1.\n\nRemaining differences in coding were discussed and resolved.\n\n_Text-to-Text Statistical Comparison by Cosine Distance_\n\nIn a final step, we conducted a quantitative, statistical comparison of each genai guideline\nto each other genai guideline to account for any residual blind spots in the manual coding.\n\nThis analysis of syntactic similarity looked at the degree of resemblance in the\narrangement and structure of five-word blocks and quantifies how closely two or more\nsentences align in terms of their words, grammatical patterns, and word order.\n\nThe\ntext-to-text comparison involved a three-step process for each dyad in the dataset: (1)\ncleaning translated-to-English PDF documents, (2) vectorising text, and (3) comparing\nthe vectors by Cosine Distance.\n\nSince possible inferences from data are sensitive to preprocessing choices (Denny & Spirling, 2018, p. 4), only those aspects of text data that\nwere irrelevant to the research questions were excluded at the cleaning stage.\n\nThese\nincluded numbers, Unicode punctuation, and English-language stop words (\u2018the\u2019,\n\n\n-----\n\n\u2018which\u2019, \u2018on\u2019, \u2018at\u2019 etc.).\n\nFinally, each text file was transformed to lower case and white\nspace was stripped.\n\nFollowing Spirling (2012) and Alschner & Skougarevskiy (2016, p. 11), texts\n\nwere vectorised as the set of distinct five-word (\u201c5-gram\u201d) sequences present in each\ntext.\n\n5-gram sequences were employed because they tend to be long enough to capture\nmeaningful passages of text while short enough to be reoccurring across multiple\nguidelinesif textual borrowing occurs.\n\nCosine Distance, a measure of textual similarity\nwell-suited to texts of varying lengths \u2013 a ubiquitous phenomenon in our dataset \u2013 was\nthen computed.\n\nThe Cosine Distance between vectors ranges from 0, entirely the same set of n-\n\ngrams, to 1, indicating no shared n-grams, and is specified by 1 minus the Euclidean\ndot product of vector A, where A is the term frequency vectorization of the first text,\nand vector B, where B is the term frequency vectorization of the second text, over the\nmagnitude of each vector.\n\nThe intuition behind Cosine Distance is that the more similar\nthe two vectors are, the smaller the angle between them will be, and thus the larger\nthe Cosine Distance.\n\nResults were arrayed in a symmetrical matrix and visualized as a\nheatmap (see Fig.\n\n1 & 2), with darker colours indicating smaller distances, and thus,\nhigher degrees of similarity.\n\nTo contextualise resulting values, a sample of general editorial guidelines (n=10)\n\nwith an intentional overrepresentation of German-language guidelines (see Appendix,\nTable 3) to reflect the linguistic variation in the overall dataset, was also compared\nusing Cosine Distances.\n\nSuch an approach allows this paper to draw broad-strokes\nconclusions about how similar journalistic genai Guidelines are to each other in\ncomparison to how similar general editorial guidelines are to each other.\n\nThus,\npreliminary findings regarding the degree of convergence driven by the sharing of ideas\nin an environment of uncertainty surrounding genai can be assessed relative to\nconvergence in established journalistic practices.", "# Findings\n\nWe first present findings from the syntactic, statistical comparison before presenting\nfindings from the qualitative and quantitative coding of the formal and thematic\ncharacteristics of the genai guidelines.\n\nDue to the small sample size, we are constrained\nto descriptive statistics for the quantitative coding, as attempting more complex\nanalyses or inferential procedures could lead to unreliable or misleading results.\n\nSyntactic Similarity\n\nThe concept of syntactic similarity aids in assessing the likeness of sentences or text\nbased on their syntactic composition.\n\nThe matrix results of comparison by Cosine\nDistance in the genai guidelines sample indicates, on average, a lower degree of similarity\nthan do results in the benchmark general editorial guidelines sample.\n\nOne can see from\nthe histogram in Figure 1 that the modal outcome of dyadic comparison in editorial\n\n\n-----\n\nguidelines is between 0.4 and 0.6 while in Figure 2 (genai guidelines) the modal outcome\nis above 0.6.\n\nVisually, this is reflected in the presence of more tiles toward the red end\nof the spectrum indicating lower degrees of distance or a higher degree of statistical\nsimilarity on Figure 1 than on Figure 2.\n\nFigure 1: Dyadic benchmark comparison of editorial guidelines by Cosine\n\nDistance\n\nFigure 2: Dyadic comparison of genai guidelines by Cosine Distance\n\nFigure 1: Due to space limitations, not all outlets are labelled.\n\nOne can observe clustering at the level of shared language in both samples.\n\nFor\n\nexample, the two most similar editorial guidelines in the benchmark sample, those of\nSky News and the Australian Broadcasting Corporation, share English as a common\nlanguage.\n\nLikewise, ITN and the Canadian Broadcasting Company (CBC), the two\nmost similar genai guidelines in the study sample, also share English as a common\n\n\n-----\n\nlanguage.\n\nIn broad strokes, the columnar dendrogram in both Figure 1 and Figure 2\nindicates hierarchical grouping along language lines.\n\nIllustratively, Der Standard and\nAxel Springer, both German-language editorial guidelines, form a visually distinct block\nin Figure 1 (bottom-left quadrant), while Aftonbladet and TT Nyhetsbyr\u00e5n, both\nSwedish-language genai guidelines, form an outlier block (bottom-left) in Figure 2.\n\nAt a broader level, the columnar dendrograms indicate a high-level in-\n\ngroup/out-group dynamic where many media organisations group together regardless\nof language boundaries while some media organisations chart their own path outside of\nthe main group (labelled on both figures), leaving the average Cosine Distance within\nthe group higher than in the out-group.\n\nThe outlier group in Figure 1 appears to be an\noutlier group of one, suggesting that there are fewer media organisations willing to\nchart their own path in editorial guidelines than there are in genai guidelines, though that\nmay be a sample size driven outcome.\n\nAs one might expect, large, influential media\norganisations find themselves at the centre of the in-groups, particularly in Figure 2,\nwhere the BBC and Bayerischer Rundfunk, two early and influential sets of genai\nguidelines, are at the centre of the in-group block.\n\nFormal Characteristics\n\nResults pertaining to length, date of first publication, title keyword, remit,\naccountability, audience, reference to professional roles, and dynamization are\npresented below.\n\nFigure 3: Distribution of genai Guidelines by Word Length\n\nDistribution of genai Guidelines by length in words\n\n\n200 400 600 800 1000 1200 1400 1600 1800 2000 2200 2400 2600\n\nWords\n\n\n-----\n\nFigure 4: Distribution of genai Guidelines by Date of First Publication, if known\n\n(n=33).\n\nPublication of genai guidelines over time\n\nWeb.de/GMX/1&1\n\nNational Public Radio\n\nThe Quint\n\nThe Globe and Mail\n\nTamedia\n\nSvenska Dagbladet\n\nS\u00fcddeutsche Zeitung\n\nIndependent Television News\n\nDer Spiegel\n\nDagens Naeringsliv\n\nCBC\n\nRingier\n\nRheinische Post\n\nJournalisten\n\nFinancial Times\n\nDPG Media\n\nDe Volkskrant\n\nUSA Today\n\nT\u2212Online\n\nHeidi News\n\nFrankfurter Allgemeine Zeitung\n\nDeutscher Journalisten\u2212Verband\n\nDeutsche Presse\u2212Agentur\n\nBusiness Insider\n\nANP\n\nAftonbladet\n\nThe Atlantic\n\nIppen\n\nHelsingin Sanomat\n\nBBC\n\nBayerischer Rundfunk\n\nSchibsted\n\nCouncil for Mass Media\n\n\nDate of first publication\n\nAs Figure 3 shows, the documents vary considerably in length (see also Table 4\n\nin the Appendix).\n\nThe shortest consists of only 87 words or 506 characters including\nspaces, the longest has 3972 words (25,192 characters).\n\nThe arithmetic mean of all genai\nguidelines included in our study is 780 words or 4899 characters.\n\nFor 33 guidelines\n(63.46%), the month of publication was available (see Figure 4).\n\nThe earliest document\nin our study are the Finnish Press Council\u2019s guidelines, published in January 2020,\nwhile the latest documents were published in July 2023 by US public broadcaster\nNational Public Radio and the German online news sites web.de/GMX/1&1.", "The\nrelease of ChatGPT in November 2022 is likely to have boosted the development of genai\nguidelines in the media industry: A total of 33 guidelines with a known release date\n(87.88%) were published in 2023, but only one in 2021 (3.03% each) and three in 2020\n(9.09%).\n\nThe findings from the analysis of title keywords (Table 2) reveal a diverse range\n\nof terms used to frame genai guidelines.\n\nThe most common term is \u2018Guideline,\u2019 accounting\nfor 30.77% of the sample.\n\nOther prevalent terms include \u2018How-to\u2019-phrases (13.46%),\n\u2018Policy\u2019 (13.46%), and \u2018Principles\u2019 (7.69%).\n\nLess frequently used terms include\n\u2018Framework\u2019 (3.85%) and \u2018Guide\u2019 (1.92%).\n\nNotably, some documents do not have\nexplicit title keywords (7.69%).\n\nRegarding the remit of the genai guidelines \u2013 stating\nwhich part of the news organisation falls under the guidelines and must abide by them\n(Table 3) \u2013 the majority of documents are designed for the newsroom and journalists,\n\n\n-----\n\nconstituting 69.23% of the sample.\n\nAbout 28.85% of the guidelines are intended for all\ndepartments within the news organisation.\n\nThere is a single instance (1.92%) where the\ngenai guidelines pertain to the business side only.\n\nNone of the documents specify other\nremits, and there are no instances where the remit is not specified.\n\nTable 2: Title Keywords used in the genai Guidelines\n\nTitle keyword n %\n\nCharter 1 1.92\n\nFramework 2 3.85\n\nGuidance 1 1.92\n\nGuide 1 1.92\n\nGuideline 16 30.77\n\nHow-to 7 13.46\n\nLetter 1 1.92\n\nNote 3 5.77\n\nPolicy 7 13.46\n\nPosition paper 1 1.92\n\nPrinciples 4 7.69\n\nStatement 1 1.92\n\nOther 3 5.77\n\nNone 4 7.69\n\n**_Total_** _52_ _100_\n\nTable 3: Remit\n\nRemit n %\n\nAll departments 15 28.85\n\nBusiness development 1 1.92\n\nNewsroom/journalists 36 69.23\n\nOther 0 0.00\n\nNot specified 0 0.00\n\n**_Total_** _52_ _100_\n\nThe examination of accountability mechanisms \u2013 the question if genai guidelines\n\nwill be enforced and compliance controlled in some way \u2013 (Table 4) indicates that only\n7.69% of the documents explicitly mention such mechanisms, while 92.31% do not.\n\nMoreover, the guidelines mostly lack details on how enforcement will occur.\n\nRegarding\nthe intended audience (which differs from remit as it specifies if the guidelines are\nmeant for internal, external consumption or both), Table 5 shows that 34.62% of the\nguidelines are directed towards internal stakeholders, 28.85% towards external\naudiences, and 36.54% are intended for both internal and external consumption.\n\n73.08%\nof guidelines furthermore mention one or several professional roles within the\nguidelines such as \u2018editor-in-chief\u2019 or \u2018legal staff\u2019 for whom the guidelines either apply\n\n\n-----\n\nin specific ways or who serve as points of contact for other people within the\norganisation.\n\nTable 4: Accountability\n\nn %\n\nYes 4 7.69\n\nNo 48 92.31\n\n**_Total_** _52_ _100_\n\nTable 5: genai Guidelines\u2019 Intended Audiences\n\nn %\n\nInternal 18 34.62\n\nExternal 15 28.85\n\nBoth 19 36.54\n\nNot specified 0 0.00\n\n**_Total_** _52_ _100_\n\nFinally, on the dynamization of guidelines \u2013 the question if guidelines will be\n\nupdated \u2013 63.46% stated that guidelines will be updated, 36.54% did not mention the\nsame.\n\nHowever, the timing of such updates appears to be an area of varied opinions,\nwith a notable preference for a less rigid and more adaptable approach.\n\nOut of the 33\nguidelines mentioning dynamization, only 6.06% specified a particular interval for\nupdates, with the majority (93.94%) leaving the same unspecified.\n\nThematic Characteristics\n\n_Journalistic Values and Conditions for Use of AI_\n\nWe also analysed guidelines\u2019 reference to journalistic values drawing on Deuze\u2019s\nclassification of journalism\u2019s \u2018occupational ideology\u2019 that can be recognised worldwide\n(2005).\n\nThese five traits include \u2018Public Service\u2019, \u2018Objectivity\u2019, \u2018Autonomy\u2019,\n\u2018Immediacy\u2019, and \u2018Ethics\u2019.\n\nOverall, 71.15% of the documents mention one or more of\nthese journalistic values, while 28.85% do not mention any.\n\nFor allowed applications\nof genai in the journalistic process, 86.54% of the documents explicitly state where genai is\npermitted, while 13.46% do not provide such information.\n\nSimilarly, in relation to\nprohibited applications of genai in journalism, 67.31% of the guidelines specify where genai\ncannot be deployed, whereas 32.69% do not mention prohibited applications.\n\nIn Table\n6, we provide additional breakdowns for allowed and prohibited genai applications along\nthe chain of gatekeeping (adapted from Domingo et al., 2008).\n\n-----\n\nTable 6: Allowed and Prohibited genai applications\n\nAccess & observation Processing & filtering Distribution\n\nn % n % n %\n\nYes 23 44,23 22 42,31 29 55,77\n\nPartial 1 1,92 1 1,92 0 0,00\n\nNo 2 3,85 3 5,77 1 1,92\n\nNot specified 26 50,00 26 50,00 22 42,31\n\n**_Total_** _52_ _100_ _52_ _100_ _52_ _100_\n\nIn 69.23% of cases, guidelines also mentioned potential pitfalls of genai that staff\n\nshould be aware of while 30.77% did not refer to the same.", "The three most mentioned\npitfalls in genai guidelines were hallucinations, wherein the genai fabricates facts, with e.g.,\none guideline stating that the organisation takes a \u2018source-critical approach to genai-\ngenerated material\u2019 in response.\n\nSecond, bias of genai models \u2013 the tendency to perpetuate\nexisting biases, such as those based on race, gender, ethnicity, and other factors,\nthereby reinforcing societal inequalities \u2013 was frequently mentioned.\n\nFinally, some\nguidelines expressed concerns about copyright and intellectual property, with AIgenerated content violating licensing terms, plagiarising existing material, and\npotentially infringing on intellectual property rights.\n\nLooking at the question if\nguidelines reference specific AIs , genai engines or LLMs as examples of existing or\npossible genai deployment, we found an even split with 50.00% citing examples (most\ncommonly ChatGPT, DALL-E, and Midjourney), while the remaining 50.00% did not.\n\n_Transparency and Human Supervision_\n\nLooking at forms of how to deal with the deployment of genai in the journalistic process,\n90.38% of organisations reference transparency \u2013 the fact that the use of genai has to be\ndisclosed \u2013 in their genai guidelines.\n\nHowever, it should be noted that 82.98% do not\nexplicitly specify how this transparency should be communicated, as is evident from\ntable 7.\n\nTable 7: How to Communicate Transparency\n\nn %\n\nByline 2 4,26\n\nEndnote 3 6,38\n\nText box 1 2,13\n\nRegister entry 2 4,26\n\nNot specified 39 82,98\n\n**_Total_** _47_ _100_\n\nLooking at the qualitative results for all organisations who reference\n\ntransparency, we see some further variation beyond the method of disclosure, namely\n\n\n-----\n\non when and where this must happen.\n\nA few outlets are very prescriptive and detailed,\nwith one outlet, for example, writing that \u2018the editorial team shall indicate when a\nnews item or part of the information offering has been produced wholly or partly on\nthe basis of automated processes and, as far as possible, refer to the sources on which\nthe news item is based,\u2019 before listing examples.\n\nMany are less specific with one\nrecommending that genai use is labelled when genai \u2018is used as more than a mere aid,\u2019 but\nleaving this at the discretion of staff.\n\nOverall, the emphasis seems to be on the use of\ngenai for texts, followed by images, with content recommendation only receiving limited\nattention.\n\nWhen it came to human supervision of genai, 84.62% of organisations stipulated\n\nsupervision in some form.\n\nStill, table 8 shows that news organisations have no\nunanimous way of handling human supervision.\n\nTable 8: Human Supervision\n\n\nArea of\nsupervision\n\n\nText/product algorithm\n\n\nAnytime 34 65.38 9 17.31\n\nSometimes 5 9.62 5 9.62\n\nNever 0 0.00 38 73.08\n\nNot specified 13 25.00 0 0.00\n\n**_Total_** _52_ _100_ _52_ _100_\n\n_Responsible genai in Journalism_\n\nLooking, next, at three specific forms of responsible genai \u2013 concern for data privacy,\nsource protection, and algorithmic bias \u2013 we find a somewhat heterogenous picture\nas table 9 shows.\n\nTable 9: Elements of Responsible genai\n\nReference to...\n\nYes No **_Total_**\n\nn % n % _n_ _%_\n\n... data privacy 28 53,85 24 46,15 _52_ _100_\n\n... algorithmic bias 19 36,54 33 63,46 _52_ _100_\n\n... source protection 28 53,85 24 46,15 _52_ _100_\n\n**_Average_** _25_ _48,08_ _27_ _51,92_ _52_ _100_\n\nThe qualitative data demonstrates that many guidelines emphasise the\n\nprotection of vulnerable groups and contributors\u2019 privacy, urging against uploading or\nusing confidential or sensitive information in genai engines.\n\nSource protection is a\nrecurring theme, with guidelines ensuring that genai platforms are not given access to\nsensitive, source-protected, or unpublished information, with one organisation for\n\n\n-----\n\nexample writing that \u2018we protect the privacy of sources and do not share sensitive\nmaterial or personal data.\u2019 Similarly, for algorithmic bias, those guidelines that mention\nthe same show e.g., concern for unfair discrimination stemming from biases in training\ndata or caution against the use of genai that could lead to the \u2018discriminat[ion] against\nany individual or group based on race, ethnicity, religion, gender, sexual orientation,\nor any other characteristic.\u2019\n\n_Cooperation and Dependency_\n\nInternal cooperation on genai between different departments within news organisations\nwas present in 36.54% of cases.\n\nOrganisations mentioned that they had \u2018several teams\nacross departments studying genai\u2019 or outlined how genai was a topic for \u2018legal, tech, finance,\nHR\u2019 and all other departments.\n\nIn terms of external cooperation with e.g., technology\ncompanies, consultants, researchers, or governments, 17.31% of the guidelines mention\nthe same.\n\nFinally, on dependency , only 9.62% of the surveyed news organisations\u2019\nguidelines make any reference to possible dependencies on platform companies or other\ntechnology companies when it comes to the development and deployment of genai.", "One\nnews organisation, for example stresses the importance of \u2018independence [\u2026] not only\nfrom political but also from technical influences\u2019 while another argues that \u2018greater\nindependence from commercial big-tech providers is desirable.\u2019 The majority, 90.38%,\nhowever, do not make any reference to dependency.", "# Discussion\n\nIt is time to return to the questions we set out in the beginning, namely _to_ _what extent_\n_international news organisations\u2019 genai guidelines exhibit isomorphic tendencies (RQ0),_\ni.e., to what degree can we find homogeneity between them.\n\nThe overall picture that\nemerges provides evidence for isomorphic tendencies leading to homogeneity, but within\nbounds.\n\nThe syntactical similarity analysis supports that media organisations borrow\n\nwordings from each other when developing genai guidelines ( _RQ0 & RQ1_ ).\n\nTo the extent\nthese borrowed wordings also encode meanings, the statistical comparison by Cosine\nDistances also supports the concept that ideas are shared across organisations.\n\nThe\nresults further indicate the presence of at least a moderate degree of isomorphism in\ngenai guidelines as illustrated by the presence of an in-group cluster of organisations.\n\nOn the matter of comparative convergence, the results offer some preliminary support\nto the idea that convergence has progressed further in editorial guidelines than in AIuse guidelines, which makes sense given the relative novelty of genai guidelines.\n\nEditorial\nguidelines simply have had a longer time to converge.\n\nWhile the findings in Figure 2\n(genai Guidelines) clearly show the grouping dynamics and red tiles indicative of shared\nwordings and thus are consonant with on-going convergence, that convergence process\nhas not progressed as far as it has in the editorial guidelines sample (Figure 1), which\nhas more red-end-of-the-spectrum tiles.\n\nWhen it comes to genai guidelines on a syntactical\nlevel, the processes of isomorphism are nascent rather than fully developed.\n\n-----\n\nConceptual isomorphism ( _RQ0 & RQ1_ ) may be a different story entirely,\n\nhowever.\n\nJournalists and publishers may not use the same words for the same concepts\neven if there is broad agreement on the why, how, and what of genai guidelines in\njournalistic settings.\n\nAnd indeed, the quantitative coding results show homogeneity for\nalmost two thirds of the variables (assuming a threshold of >60%).\n\nOn the _formal level_ ,\ndocuments vary in length but most fall within the approximate range of 200 to 1000\nwords.\n\nA majority governs the editorial realm of journalists and the newsroom\n(69.23%), mentions specific professional roles as relevant stakeholders (73.08%), states\nthat the guidelines should be updated at some point (63.46%), but also lacks any\nreference to accountability mechanisms (92.31%).\n\nRegarding the _thematic features_ , our\ncoding again shows general patterns across publishers.\n\n71.15% refer to journalistic\nvalues, with \u2018trust\u2019 (46.15%) and \u2018accuracy\u2019 (44.23%) named most often.\n\nIt is also\ncommon that genai guidelines cover at least some forms of allowed or prohibited\napplications, with more news outlets mentioning allowed (86.54%) than prohibited ones\n(67.31%).\n\nA majority of 69.23% refers to possible pitfalls that can result from using genai\nin journalism.\n\nThe documents were also quite homogenous in dealing with transparency\nand human supervision of genai-generated content.\n\n90.38% of news outlets refer to\ntransparency, although most do not specify how to communicate the same, and 84.62%\nstress the importance of human supervision, although such oversight is mostly applied\nto text generated or otherwise edited by genai.\n\n65.38% require human supervision at all\ntimes.\n\nRegarding the quantitative coding, genai guidelines display a marked degree of\nhomogeneity, especially compared to social media guidelines.\n\nWhile some difference\nremains, due to the distinct requirements of media organisations and the early stage of\ngenai guideline development, the overall similarity across guidelines is striking, especially\ncompared to the lack of similarity research has uncovered in social media guidelines.\n\nWe turn next to more specific research questions ( _RQ2_ _a_ and _RQ2_ _b_ ) \u2013 if national\n\nand organisational idiosyncrasies continue to shape publishers\u2019 practices within the\noverall trend towards homogeneity.\n\nWhile the small sample size does not allow for\nrigorous statistical analysis and means that these cursory results must be interpreted\nwith caution, we can see some variance across organisational types (commercial vs.\npublic service) and country when looking \u2018under the hood\u2019.\n\nA difference seems to emerge mainly between publicly funded and commercial\n\npublishers \u2013 but not necessarily as expected.\n\nSurprisingly commercial media\norganisations\u2019 guidelines seem to be more fine-grained and contain significantly more\ninformation on permitted and prohibited applications (see Appendix, Table 4).", "Surprisingly commercial media\norganisations\u2019 guidelines seem to be more fine-grained and contain significantly more\ninformation on permitted and prohibited applications (see Appendix, Table 4).\n\nFor\nexample, the protection of sources, which plays a role especially when sensitive\ninformation is entered into the interface of LLMs, is emphasised above all by\ncommercial broadcasters and legacy newspapers (see Appendix, Table 5), the latter are\nalso significantly more concerned than average about data protection, perhaps owing\nto the risk legal liability poses to their business models.\n\nCommercial media also make more statements about possible pitfalls of genai (see\n\nAppendix, Table 6) which also ties in with the fact that this group more often tends\nto demand transparency in the use of genai and more frequently calls for human control\n\n\n-----\n\nof the products generated or edited by genai, compared to public media (see Appendix,\nTable 7).\n\nSo the conclusion that publicly funded broadcasters tend to establish a\n\u2018stricter ethical regime\u2019 than privately funded media outlets, as S\u00e1nchez Laws & Utne\n(2019) have shown regarding social media guidelines, seems questionable for genai\nguidelines.\n\nWhere public media are ahead is the human control of algorithms; they are more\n\naware of this topic than private-sector actors (see Appendix, Table 8) \u2013 possibly due\nto their high degree of organisation and the associated professional specialisation within\neditorial teams.\n\nLess surprising is that commercial media are somewhat more permissive\nwhen it comes to the use of genai than their publicly financed or public-service oriented\ncounterparts (see Appendix, Table 9).\n\nThis seems especially true for news agencies\nwhich allow genai to be used across most levels of the journalistic process much more than\nthe average (see Appendix, Table 10), potentially owing to their early adoption of the\ntechnology.\n\nThe data also shows _some variance across different countries_ ( _RQ2_ _b_ ).\n\nA set of\n\nfour countries refers to journalistic values at least ten percentage points more often\nthan average: Belgium, Canada, the United Kingdom and Germany (see Appendix,\nTable 12).\n\nGuidelines from Belgium and Finland allow for genai use more often than\naverage on all three levels of the journalistic process (see Appendix, Table 13).\n\nPossible\npitfalls of genai are most often mentioned by organisations in Canada, Norway, and the\nUnited Kingdom (see Appendix, Table 14).\n\nWhile many organisations make statements\nabout transparency and human oversight, organisations in Canada, the Netherlands,\nSwitzerland, and the United Kingdom are significantly above average (see Appendix,\nTable 15).\n\nWhen it comes to elements of Responsible genai (see Appendix, Table 16),\norganisations in Canada, the United Kingdom, Netherlands, and Germany have a\nparticularly strong emphasis on data privacy in their guidelines.\n\nAlgorithmic bias is\ncovered most often by organisations in Western Europe, especially in the United\nKingdom, the Netherlands, and Switzerland.\n\nSource protection, on the other hand, is\nmainly a topic for Scandinavian countries, although outlets in Canada and the United\nStates also mention this more often than average.\n\nFinally, the analysis of current genai guidelines within news organisations also\n\nrevealed _several blind spots (RQ3)_ .\n\nFirst, the vast majority of guidelines are essentially\ntoothless regarding enforcement of violations or broader oversight of what they\nstipulate.\n\nSimilarly, while many organisations demand the supervision of output,\noversight over algorithms and technical systems seems limited.\n\nA third notable absence\nare explicit directives regarding external collaborations, e.g., with technology vendors,\nresearchers, or other stakeholders.\n\nGiven the increasing reliance on external expertise\nin the development and deployment of genai, guidelines could include provisions for\ntransparent and ethical engagement with such actors.\n\nMost genai guidelines also did not\naddress questions of technological dependency, a factor that holds implications for the\nautonomy of news organisations (Simon, 2022).\n\nFew discussed safeguarding editorial\nindependence and self-reliance when it came to genai.\n\nLikewise, few organisations specified\n\n\n-----\n\nif and when their guidelines would be updated, a noteworthy omission considering the\nfast-moving nature of the field.\n\nIn addition, we identified several blind spots in our qualitative coding that\n\nmatter in as much as they are part of the current discourse around genai but were not\ndiscussed in the guidelines at all.\n\nFirst, while serving audiences was often mentioned,\nsolicitating audience feedback on guidelines or engaging audiences on genai use was\nconspicuously absent \u2013 an interesting facet amidst industry discussions stressing the\nneed for greater audience engagement.", "Likewise, references to recent debates around\nsustainable genai and genai supply chains (Brown, 2023; van Wynsberghe, 2021) which shed\nlight on the environmental and societal impact and harm of genai development and use,\nwere notably absent.\n\nThe impact of genai use on existing power asymmetries (Arguedas\n& Simon, 2023), especially with respect to local and cultural diversity, received only\nfleeting references in very few instances.\n\nSimilarly, issues of workplace surveillance\nthrough genai (Ebert et al., 2021), data colonialism (Couldry & Mejias, 2019), labour\nexploitation and potential human rights abuses associated with genai training received no\nattention from any of the guidelines.\n\nThe oversight of these facets underscores the need\nfor a more comprehensive integration of ethical considerations.\n\nLimitations\n\nIt is worth briefly dwelling here on the limitations of this study.\n\nFirst, the uneven\ndistribution of sources across different geographical regions is a notable caveat.\n\nOur\nreliance on a larger number of German sources in comparison to sources from other\nregions introduces a potential source of bias in the findings.\n\nThe sample size, while\nvaluable for exploratory insights and exceeding previous research, remains limited in\nits scope.\n\nThis limitation is particularly pronounced when considering the Global South,\nwhich is inadequately represented here despite concerted efforts to include guidelines\nfrom more news organisations in India and Brazil.\n\nMoreover, the study encountered restrictions in accessing guidelines from certain\n\norganisations.\n\nSome publishers acknowledged having or working on guidelines but were\nunwilling to share them.\n\nFrom background conversations we learned that often this\ncould be attributed to concerns surrounding divulging proprietary strategies and thus\npotentially losing a competitive advantage.\n\nSome were also concerned about looking\namateurish vis-\u00e0-vis their peers if they released guidelines too early.\n\nOrganisations\nmight also be wary of disclosing their approaches to issues such as dependency on major\ntechnology corporations, lest it jeopardise their response to the same.\n\nFurthermore, it should be acknowledged that this study does not encompass the\n\nentirety of internal guidelines that some organisations have, with a number of\norganisations maintaining more extensive internal guidelines that in some but not all\ncases were beyond our purview.\n\nThese internal documents often provide more granular\ninstructions for staff members, beyond what is publicly available.\n\nIt is important to note that our analysis examines the outcome \u2013 homogeneity\n\n\u2013 of a process that has likely already occurred (though it is likely to be still ongoing at\nthe time of writing).\n\nBut while we can assume that an isomorphic process has transpired\n(and can elaborate on potential driving factors), we cannot establish causality or\n\n\n-----\n\ndefinitively prove that this has been the case.\n\nThis aspect will require further research\nand delving into the motivations behind these guidelines and the processes shaping\ntheir creation.", "# Conclusion\n\nInstitutional isomorphism offers plausible explanations for our observations.\n\nDiMaggio\n& Powell contend that \u2018the greater the extent to which technologies are uncertain or\ngoals are ambiguous within a field, the greater the rate of isomorphic change\u2019 (1983, p.\n156).\n\nThis certainly holds true for the current state of genai in journalism.\n\nThe uncertainty\nsurrounding the trajectory of the technology is significant and many organisations are\ngrappling with defining their goals for genai.\n\nMoreover, the more ambiguous genai\u2019s nature,\nwhat it could enable, and what should crucially be done about it, the more likely\norganisations will emulate successful entities that preceded them.\n\nCertain guidelines,\nsuch as those of the BBC and Bayerischer Rundfunk, which have gained widespread\nattention through industry publications and conferences, have served as influential\nbenchmarks for others.\n\nAdditional predictors of isomorphism include the strong\nprofessionalism evident in journalism, both nationally and globally.\n\nJournalism is\nbecoming more internationally connected, facilitated by digital media, the exchange of\nlabour, and collaborations among major players.\n\nIn the genai domain, the core community\nworking on it remains relatively small, and initiatives like the London School of\nEconomic\u2019s Journalism genai initiative provide vital platforms for idea exchange.\n\nBoth\ncould have contributed to similar patterns emerging in the guidelines of international\nnews organisations.\n\nUltimately, it should not be forgotten that both the race to genai and the\n\nestablishment of genai guidelines are also a quest for legitimacy.\n\nFormulating an genai policy\n\u2013 one that resembles those of successful organisations and accedes to common demands\non how genai should be used and regulated \u2013 also functions as a form of signalling.\n\nBy\nhaving an genai policy, a publisher conveys some important information about themselves,\nin this case likely to make their commitment to the ethical use of genai observable and to\nshow to competitors that yes, they too, are innovative.\n\nThis, of course, ultimately raises\nthe point who and what genai guidelines are really for \u2013 are they a mere PR exercise,\ndressed up in form of a policy or a meaningful contribution to regulating a technology\nin the face of uncertainty.\n\nWhile only future research will be able to answer this\nquestion, we can assume that reality is more nuanced.\n\nPublicly, at least, many\norganisations assert that their motivation behind formulating such guidelines stems\nfrom the dynamic nature of the environment in which they operate, with guidelines\nintended to serve as an initial framework, offering a sense of security to staff, readers,\nand partners.\n\nMany seem to have emerged in response to both internal calls for\ndirection and a perceived need to address external demands.\n\nEstablishing legitimacy is\npart of the answer, not the whole story.\n\nLastly, isomorphism theory argues that a field\u2019s dependence on a single source\n\nleads to greater isomorphism.\n\nWhere DiMaggio & Powell referred to a \u2018single source of\n\n\n-----\n\nsupport for vital resources\u2019 (1983, p. 155) and resource centralisation, genai, as a large\ntechnological system (Simon, 2023a), comes into play.\n\nOne does not have to fully\nembrace technological determinism to assume that genai has a shaping power of its own.\n\nIt thus acts as a coercive force with broadly similar effects across contexts, resulting in\nanalogous reactions, including in the development of genai guidelines.\n\nWhile we could\nhypothesise that all organisations developing genai policies simply began at similar\nstarting points with equivalent concerns and knowledge about the technology, it is also\nconsiderably less elegant as a theory to explain the similarities we can observe.\n\nOccam\u2019s\nrazor would suggest that they modelled aspects of their policies on each other.\n\nWith this paper we hope to help lay the groundwork for future analysis and\n\nwork in this area.\n\nWe are at juncture on the road to more substantive genai use and, by\nextension, regulation in journalistic work.\n\nOne should nevertheless remember that\nmany genai guidelines are early examples, developed quickly in response to the launch of\nChatGPT and due to concerns about the speed with which genai became\naccessible to the public and journalists.\n\nAnd while the notion that genai guidelines in and\nof themselves will somehow magically resolve the intricacies of genai implementation and\nits attendant challenges is questionable, they can potentially make an important\ncontribution in ensuring the responsible, ethical, and effective use of the technology in\nthe news.\n\nPart of the significance of these findings also lies in the fact that this selfregulation for genai is well underway, with a sizable number of publishers having begun\nto establish strategies addressing various critical aspects of the technology.", "Crucially,\nwhile there remains ample room for improvement, these pioneering organisations, many\nof them leaders in the news industry, are poised to influence and set a precedent for\nbroader industry practices, thus facilitating a trickle-down effect of their genai guidelines\nand strategies.\n\nHow unanimous these will and should be remains to be seen.\n\nFor now,\nwe can see that there are some overlapping trends among genai guidelines but also a\nconsiderable degree of variety and we withhold judgment at this point if this is to be\ncelebrated or rectified.\n\nFuture questions abound.\n\nFor one, genai guidelines often emerge from internal\n\nconsultation processes that involve various departments, sometimes building upon preexisting materials.\n\nOne question here will be which \u2018tribes\u2019 \u2013 editorial, business, tech \u2013\nwithin news organisations will exert dominance in shaping the ideas and logics\nembedded in these guidelines.\n\nA second line of inquiry pertains to what kinds of\norganisations that release or craft both internal and external genai guidelines.\n\nUnderstanding which organisations engage in this practice and the reasons behind those\nthat opt not to (be it due to deeming guidelines unnecessary or as potential hindrances\nto their operations) will tell us something about the future direction of genai in journalism.\n\nFinally, against the backdrop of industry efforts to develop a set of principles, rights,\nand obligations regarding the use of genai-based systems, the question looms along which\nlines these guidelines will develop.\n\nWill we have more standardisation and homogeneity,\nor will we see more customisation in the future?\n\nFor now, publishers seem to embark\non this journey from somewhat similar points.\n\n-----", "## Australia\u2019s genai opportunity\n\nJuly 2023\n\n\n-----\n\nThis document is intended for general informational purposes only.\n\nThe report is a collaboration\n\nbetween Microsoft and the Tech Council of Australia.\n\nViews and opinions expressed in this document are based on the companies\u2019 knowledge and\n\nunderstanding of its area of business, markets and technology.\n\nThe companies do not provide medical,\n\nlegal, regulatory, audit, or tax advice, and this document does not constitute advice of any nature.\n\nWhile\n\nthe information in this document has been prepared in good faith, the companies disclaim, to the fullest\n\nextent permitted by applicable law, any and all liability for the accuracy and completeness of the\n\ninformation in this document and for any acts or omissions made based on such information.\n\nOpinions\n\nexpressed herein are subject to change without notice.\n\nNo part of this document may be reproduced in any manner without the written permission of the\n\ncompanies.\n\nThis document may make references to third party names, trademarks or copyrights that\n\nmay be owned by others.\n\nAny third-party names, trademarks or copyrights contained in this document\n\nare the property of their respective owners.\n\nThis report is a collaboration between\nMicrosoft and Tech Council of\nAustralia.\n\n-----", "**Annual value-added by 2030**\n\n$45B $75B $115B\n\n\nIn **software development** , genai can translate natural\nlanguage into code, democratising coding skills.\n\nIt can\nsuggest novel solutions to coding issues, allowing\ndevelopers to focus more on strategising and high-value\nthinking.\n\nFor **creatives** , genai can streamline workloads by handling\ntasks such as image generation or editing, and copy\ngeneration.\n\nThis can free them up to focus more on\ncreative direction, ideation and strategy.\n\nFor **marketing and sales professionals** , genai can craft\npersonalised sales pitches based on customer data and\npreferences, create interactive product demos and provide\nreal-time language translation, enhancing customer\nengagement.\n\nFor **managers** , genai can assist staff communication,\ncreating training materials, identifying trends in employee\nsentiment, and analysing performance data.\n\nFor **researchers** , genai can help think through complex\nproblems and develop frameworks to structure research\nprojects.\n\nIt can also assist in writing tasks such as outline\ncreation, word selection, and proofreading.\n\nImportantly, moving from the potential benefits of genai to actual, realised\ngains depends on a range of factors, including how useful it is for\nbusinesses, how the technology is regulated and safely managed, and\nhow workers are supported to use the technology.\n\nIn sizing the economic\nvalue of genai to Australia by 2030, we need to account for significant\nuncertainty, particularly around how quickly the technology can be\neffectively adopted.\n\nSlow-paced\n\nadoption\n\n10%\n\n20%\n\n\nMedium-paced\n\nadoption\n\n\nFast-paced\n\nadoption", "**Industry** **The genai opportunity**\n\nThe second section of this report explores the opportunity of\ngenai for Australia through more tangible examples.\n\nIt identifies\nfour key sectors where Australia can succeed in creating value\nthrough genai.\n\nThese opportunities are healthcare,\nmanufacturing, retail and professional services.\n\nThese sectors were chosen for two key reasons.\n\nFirst, they are likely to\ncontinue to be important sectors for employment and output in the\nAustralian economy into the future.\n\nSecond, genai is likely to have a\ntransformative effect on these sectors.\n\nAdditionally, these sectors and their diverse use cases for genai\nillustrate the breadth of the technology\u2019s impact on the economy.\n\nThe\nselection process involved desktop research, industry analysis,\nconsultation with experts, along with engagements with executives\nand key industry personnel more broadly.\n\nImportantly, the contents of these sector deep dives culminates from\nconsultations with industry experts, and a Roundtable discussion held\nin June with leaders from industry, academia and governments.\n\nWe\nthank all who contributed to these discussions.\n\nIn the **healthcare** sector, genai can enhance the quality and accessibility of services.\n\nBy reducing\nthe time burden of administrative tasks, healthcare professionals have more time for patientfocused care.\n\nFurthermore, the integration of genai into wearable devices can personalise\nhealthcare, enabling proactive models of care through earlier diagnoses at scale.\n\nIn **manufacturing** , genai could usher in an era of new, innovative capabilities, contributing to\nAustralia's strategic focus on advanced manufacturing.\n\nThis transition would strengthen\nAustralia's reputation for producing high-quality, technically-advanced products.\n\n**Retail** industries, already investing in omnichannel capabilities due to the pandemic, could\nintegrate genai into existing digital platforms.\n\nThis can drive brand differentiation and allow greater\ncustomer personalisation, all while maintaining cost-competitiveness.\n\nLastly, the **professional services** industry could leverage genai to automate routine tasks, freeing\nup a highly educated workforce to focus on higher-value activities.\n\nWith genai, Australia could\nfurther elevate its status for high-quality knowledge workers, notably in the banking and legal\nsubsectors.", "**Key challenges** **Key actions**\n\nCapturing the economic potential of genai requires leveraging\nAustralia\u2019s comparative advantages and strategic actions by\nindustry and government.\n\nAustralia possesses several comparative advantages that can enable\nit to seize the economic potential of genai.\n\nThese include a highlyskilled workforce proficient in data science, engineering, and\ncomputer science and a robust research and development sector.\n\nAdditional benefits, such as our strategic location close to Asia, a\nstable and transparent regulatory environment, and a thriving startup ecosystem provide strong grounds for genai development and\nadoption.\n\nAlongside these key strengths, there are also key challenges.\n\nTo\ncapture the economic benefits of genai, Australia needs to address\nbarriers around technology capability, enterprise readiness,\nawareness and skills, and responsible genai.\n\nSuch barriers include the\nsignificant investments required to build genai orchestrations to meet\nspecific industry contexts, integration with existing systems, data\nprotection, and workforce upskilling.\n\nBoth industry and government have key roles to play in addressing\nthese challenges.\n\nIndustry needs to clearly define genai's opportunity,\nassess readiness, invest in and experiment with the technology,\ndevelop privacy and security guardrails, upskill the workforce, and\nmonitor performance.\n\nMeanwhile, the Australian Government's role\nis crucial in setting a clear vision for genai in Australia, supporting\ncollaboration between research institutions and industry, providing\nregulatory clarity, incentivising genai adoption, and investing in the\nright skills.\n\nBy taking these strategic actions together, Australia can unlock the\ntransformative potential of genai, driving economic growth and global\ncompetitiveness.", "**Responsible**\n\n**genai**\n\n\nNarrowing the margin for error\n\nThe scale of investment required to\nbuild industry-specific genai\norchestrations\n\nDeciding to invest\n\nLaunching internal genai governance\n\nThe speed of change\n\nBuilding essential C-suite knowledge\n\nBuilding workforce digital literacy\n\nManaging training pathways\n\nDeveloping trust\n\nManaging privacy and data security\n\nRegulatory certainty\n\nManaging intellectual property", "###### genai creates novel content in response to user prompts and is becoming more powerful and accessible than ever before\n\n**genai is a step change in the evolution of genai**\n\n\ngenai (genai), the latest evolution in artificial\nintelligence, carries the potential for significant\neconomic advancement.\n\nWhile the full economic impact will take years to\nrealise, genai is already impacting a range of sectors\nacross the economy.\n\nThis report aims to focus\nspecifically on how genai could drive value for the\nAustralian economy, and identify the steps needed to\nseize this opportunity.\n\ngenai, a subset of genai, uses machine\nlearning to generate human-like content.\n\nIt signifies a\nconsiderable transformation in the economic prospects\nof genai at large, by empowering machines to produce\nnovel content or data, previously unseen or unimagined.\n\nRecent improvements in computing hardware and\ninfrastructure, along with the availability of large-scale\nand diverse training datasets, have been instrumental in\nenabling the development of larger and more powerful\ngenai models than ever before.\n\nOne of the most notable\ninnovations in deep learning architectures came in\n2017 with the Transformer architecture 1 , which\nfacilitates parallel processing of sequences and the use\nof attention mechanisms for tracking long-range word\nrelations.\n\nThis innovation, combined with\nadvancements in optimisation techniques, has\nfacilitated the development of larger, faster, and more\nsophisticated genai models.\n\nThese include the command of natural language,\ncoding and mathematics, and the ability to plan and\nproblem solve\u200b.\n\n2\n\nAlong with improved capability, innovations in\ntechnology have also led to increased accessibility of\ngenai by reducing costs.\n\nFurthermore, the development of more user-friendly\ntools and interfaces has made genai more accessible to\na wider range of users.\n\nFor example, some\nonline platforms allow users to easily create and\nmanipulate genai models using drag-and-drop interfaces\nor intuitive sliders, even if they have little to no\nexperience in machine learning.\n\nNot only has this\ndemocratised genai, improved accessibility creates a\nwider range of use-cases for businesses and workers\nacross all sectors of the economy.\n\nAdditionally, modern genai models are already being finetuned for specific use cases.\n\nThis has made it easier\nfor developers, researchers, and businesses to use genai\nin their applications without having to spend time and\nresources on training their own models \u200bfrom scratch.\n\nTogether, the improved computing and accessibility of\ngenai means it is already changing how we work and the\nway firms operate.\n\nIt is augmenting human workers by\nacting as a copilot, increasing productivity and quality\nin various industries, as well as creating new jobs and\nbusinesses.", "**Applications**\n\n**of LLMs**\n**(2023+)**\n\n\n**genai** is the ability for a machine to\nperform a task typically requiring human\nintelligence.\n\nHistorically, these tasks have been limited to\npattern recognition and processing, with\nimprovements in complexity and accuracy\ndeveloping over time .\n\n**genai is a step change from previous**\n**evolutions of genai.\n\nAs well as recognising complex**\n**patterns and processing data, it can create novel**\n**content in response to user prompts.\n\n**\n\nAdvancements in computing hardware,\ninfrastructure and, most notably, deep learning\narchitectures such as Transformers 1 have enabled\nthe development of larger and more capable genai\nmodels.\n\nLarge Language Models (LLMs) pretrained\non extremely large datasets generate human-like\nand coherent text and can be fine-tuned for specific\ntasks.\n\nSuch \u2018foundational models\u2019 provide a platform for\napplications to be built on top, leading to even more\nuse cases and wider accessibility.\n\nAs models become larger, they develop powerful\n\u2018emergent capabilities\u2019 that are only possible when the\nmodel reaches a certain scale.\n\nNo longer limited to\ncompleting narrow tasks based on a narrow range of\nprompts, modern genai models can now perform more\n\u2018generalist\u2019 functions.\n\n-----", "**An overview of genai**\n\ngenai can create novel content in response to user\nprompts.\n\nThe generation of this content is\nprincipally handled by foundational models such\nas Large Language Models (LLMs) that are deep\nneural networks.\n\nThese models are built on\nrobust computing infrastructure and depend on\nlarge datasets for training.\n\nTo enhance the\naccessibility and usability of LLMs,\nreinforcement learning techniques that\nencourage human-like responses and intuitive\ninterfaces are integral components of the genai\nframework.\n\nAs it evolves, genai promises to deliver immense\nvalue across several facets.\n\nOne of these is\nautomation, where genai can expedite processes\nand minimise time spent on repetitive\nadministrative tasks.\n\nIn the creation domain, it\ncan help generate new ideas in areas such as\nproduct design and content creation.\n\nIt can also\nplay an advisory role, acting as a copilot guiding\nworkers through complex issues.\n\nFurthermore,\ngenai allows the exploration, interrogation, and\nsynthesis of large datasets, leading to improved\ndata comprehension and more insightful\ndecision-making.\n\nThe versatility of genai is underscored by the range\nof its models, extending from text and code\ngeneration to the creation of images, audio and\nvoice, video, and 3D content.\n\nEach of these\nmodels ushers in unique use-cases, thereby\nemphasising the far-reaching applications and\neconomic benefits of genai.\n\nCloud\n\ninfrastructure\n\nand computer\n\nhardware\n\n\nFoundational\n\nmodels\n\n(e.g.\n\nLLMs)\n\n\nModel\n\nfine-tuning (e.g.\n\nRLHF 1 )\n\n\nTraining data\n\n\nNeural networks\n\n& deep learning\n\n\nInterfaces &\napplications", "**Five ways genai is already copiloting work**\n\n**genai assists workers in two key ways.\n\n** First, by\nautomating well-defined and highly repetitive tasks, genai\nallows workers to spend more time on the more\ncomplex aspects of their jobs.\n\nImportantly, this is likely\nto improve job satisfaction for all workers.\n\nSecond, genai\ncan augment and assist workers to complete these\nmore complex tasks.\n\nFor example, the ability to suggest\nstep-by-step problem solving instructions means genai is\nguiding workers through new skills and new ways of\napproaching problems.", "**The salesperson**\n\ngenai can provide hyper-personalised\nintelligence to improve customer interactions.\n\nThis could include crafting personalised\nengagements based on customer data and\npreferences, generating engaging marketing\nmaterials, creating interactive product demos\nand providing real-time language translation\nduring sales calls with non-native speakers.\n\nThis leads to a more streamlined and\ninteractive experience for the customer.\n\n**genai conversational assistants help customer support**\n\n**agents resolve 14% more issues per hour** **4**", "**The developer**\n\nWhile coding companions aren\u2019t new , GAIpowered companions surpass existing 1\ntechnology by being able to understand a\ncoder\u2018s aims and suggest an entirely new\napproach to solving a problem.\n\nThis allows\ncoders to do more high-value thinking,\nincluding collaborating with product\nmanagers to think carefully about the\ndesired end-user experience.\n\nAdditionally,\ngenai can translate natural language to code,\nmaking coding a skillset available to all.", "**The manager**\n\ngenai can help managers stay in tune with their team\nby supporting communication, creating training\nmaterials, identifying trends in employee\nsentiment, and analysing performance data.\n\nAdditionally, genai can allow easier access to\nbusiness intelligence, analysing company data to\nassist managers in completing request for\nproposals (RFPs), understanding clients, and\nassisting resource planning.\n\n**genai tools have been shown to reduce the time of**\n\n**writing tasks by 37% with improved quality** **5**", "**The creative**\n\ngenai can handle repetitive and time-consuming\ntasks \u2013 allowing creatives to focus on higher-level\ntasks such as creative direction, ideation, and\nstrategy.\n\nDALL-E, an genai system developed by\nOpenAI, can generate high-quality images based\non textual descriptions, which can be useful for\nadvertising, marketing, and branding.\n\nAnother\nexample is Copy.genai, an genai-powered tool that could\nbe used to generate human-like text for ads,\nproduct descriptions, and social media posts.", "**The researcher**\n\ngenai can be a valuable copilot for researchers.\n\nThrough interactive conversations, genai models\ncan help researchers think through complex\nproblems and develop frameworks to structure\nresearch projects.\n\nFurthermore, genai can assist\nwith writing tasks, such as generating outlines,\nsuggesting word choices, and proofreading.\n\nImage-based models can also increase the size of\ndatasets, by creating realistic synthetic images\n(for example, of biological structures) that assist\nresearch.", "**Improvements to existing industries**\n\nFirstly, adoption of the technology in existing\nindustries drives higher productivity and quality.\n\ngenai can boost productivity by automating certain\ntasks within an occupation.\n\nThis partial automation\nfrees up time for the worker to focus on other tasks,\ntherefore completing their existing roles more quickly\nand increasing their productivity.\n\nFor example,\ndoctors and nurses spend a significant proportion of\ntheir time on administrative activities which could be\nautomated to focus on patient care.\n\nFurthermore,\nknowledge workers in professional services can save\nsubstantial time researching and synthesising large\namounts of information.\n\nAdditionally, genai can improve the quality of a worker\u2019s\noutput by augmenting tasks within a role.\n\nAugmentation refers to genai\u2019s ability to assist the\nworker to complete a task.\n\nFor example, genai may\naugment a doctor\u2019s diagnosis of a patient, by\ngenerating a list of possible cases based on the\ndoctor\u2019s inputs or patient data.\n\nUltimately, the\ndoctor\u2019s expertise is needed to complete the\ndiagnosis (i.e.\n\ncomplete the task).\n\nYet with the aid of\ngenai, which both advises and explores potential\nsolutions, the doctor is better able to think through all\npossible cases, leading to more comprehensive care.\n\nIn other words, the quality of their output is improved.\n\nAcross all industries, such augmentation and the\nresulting gains in quality can lead to increased\ncustomer satisfaction, loyalty, and retention,\ngenerating a quality \u2018premium\u2019 that drives value to the\neconomy.", "**New products and services**\n\nSecondly, genai can enable the development of new\nproducts and services that were not previously\npossible, such as highly personalised content,\nconversational virtual assistants, and interactive\nwearable health devices.\n\nThis can lead to increased\ninnovation and competitiveness in a range of\nindustries, driving economic growth and enhancing\nAustralia's global competitiveness.\n\nNew jobs can be created by enabling the development\nof new products and services, as new forms of\nemployment emerge with this innovation.\n\nThis can\nhelp to boost employment rates and drive economic\ngrowth.\n\nNew business opportunities can enable entrepreneurs\nto develop new products and services that are not\ncurrently feasible with existing technologies.\n\nThis can\nlead to the creation of new industries and markets,\ndriving economic growth and job creation.\n\nOverall, genai can play a key role in driving innovation,\nproductivity, and competitiveness in a range of\nindustries, and has the potential to deliver significant\neconomic value to the Australian economy.", "**New products and services**\n\nNew jobs Business growth\n\nand creation\n\n\nLabour\n\nproductivity\n\nBy automating and\nstreamlining various tasks,\ngenai frees up time for\nworkers to focus on more\ncomplex or creative aspects\nof their jobs.\n\nImproved\n\nquality\n\nBy augmenting and assisting\ntask completion, genai drives\nhigher quality outputs.\n\nThis\nis because when genai acts as\na copilot, it can leverage and\nenhance the existing\nexpertise of the workforce.\n\nBusinesses will be able to\nproduce more sophisticated\nproducts and services,\nwhich in turn creates new\nroles in areas such as\nproduct design, marketing,\nand customer service, while\nalso increasing the demand\nfor skilled workers.\n\nThe possibility of new\nproducts and services\nopens up Australian\nindustries to new markets,\nboth domestically and\nglobally.\n\nAdditionally, genai\ncreates new opportunities\nfor entrepreneurs and\nstartups.\n\n-----", "**We calculate the productivity and quality gains of this successful transition**\n\nEach hour automated by genai and transitioned to other tasks means workers can produce more in a\ngiven timeframe, increasing output per worker (productivity).\n\nEach hour augmented or copiloted by genai\nallows workers to improve quality of their output, resulting in quality gains.", "**We estimate the global addressable market of genai in 2030**\n\nTotal addressable market is the total revenue opportunity for businesses selling genai products.\n\nWe\nfocus only on the market for genai software, since consultations revealed this is where Australia\u2019s\nopportunity is most likely to reside (as opposed to genai hardware).", "**We estimate Australia\u2019s share of this global market in 2030**\n\nThis estimation is based on Australia\u2019s existing share of global tech \u2018unicorns\u2019 \u2013 tech startups with an\nannual turnover over $1B.\n\nThis proxy captures Australia\u2019s comparative advantage in tech start-ups, and\nlikelihood to capture a greater than proportional share of the global genai software market.", "**To account for the significant uncertainty around how genai will**\n\n**impact Australia in 2030, we model the potential gains against three**\n**different scenarios for adoption**\n\nGiven genai is a relatively nascent and rapidly evolving technology, there is significant\nuncertainty in how this technology is adopted and embraced.\n\nTo account for this, we model\nthe potential gains against three different scenarios for adoption.\n\nThis gives a range for the\ntotal economic opportunity of genai in 2030.\n\nThe adoption of new technologies typically\nfollows a distinct pattern known as an S-curve, 2\nwith a slow start (early adopters), followed by a\nrapid increase (majority adopters), and then a\nslowdown (late adopters).\n\nTo predict the S-curve\nof genai, we use historical data on internet adoption\nin Australia as a reference point.\n\n1 We arrive at\nthree scenarios for adoption, as shown.\n\nEven in\nour fastest scenario, our scenarios stop before the\nmajority of adoption would occur.\n\nIn the scenario of slow-paced adoption, adoption rates in 2030 are 13%.\n\nThis can be\ninterpreted as 13% of task hours that have the potential to be automated and augmented are\nin fact automated and augmented.\n\nIn the medium and high paced scenarios, adoption rates\nin 2030 are 21% and 33% respectively.\n\n3\n\n**_To validate our results, we compare them against a growth accounting_**\n**_methodology from literature_**\n_Brynjolfsson, Baily and Korinek (2023)_ _4_ _estimate productivity gains of genai using a growth-accounting_\n_method.\n\nAdapting this approach returned comparable results to our method._\n\n\n-----", "**At its current level of capability, genai has the potential to automate or**\n\n**augment 44% of tasks on average**\n\n22%\n\n\ngenai can transform the way people work by\nautomating or augmenting tasks.\n\nOn average,\nacross all occupations, 44% of worker task-hours\nhave potential to be automated or augmented.\n\nAutomation of tasks improves the productivity of\nworkers, allowing them to produce more in any given\namount of time.\n\nIn parallel, augmentation, whereby\ngenai acts as a copilot, enables workers to improve\nthe quality of their output.\n\nTo understand how each occupation is impacted by\ngenai, we analysed data from the Occupational\nInformation Network (O*NET), which provides\ninformation on the tasks undertaken by each\noccupation.\n\nOn average, 22% of task-hours have high potential\nfor automation by genai.\n\nThese tasks, characterised\nby their routine nature and well-defined parameters,\nlend themselves more easily to automation.\n\nSuch\ntasks include synthesising documents and large\ntext-based sources, reconciling data, or transcribing.\n\ntasks are either less routine or not discretely defined\nand require proactive effort from a human.\n\nSuch\ntasks include directing organisational activities,\nevaluating personnel capabilities, and interpersonal\ntasks more generally.\n\nIn the analysis, these tasks are\nassumed to not derive any benefit from genai.\n\nLastly, around 30% of task-hours are deemed non\nlanguage tasks with no potential for automation or\naugmentation through genai.\n\nThese activities are\nlargely physical or manual tasks.\n\nIt is important to note these averages provide an\noverall view of the impact of genai on workers across\nthe economy.\n\nHowever, different occupations are\nimpacted to different extents.\n\ngenai is likely to have\nthe greatest impact on white-collar work in services\nindustries.\n\n1 This is a shift from previous automating\ntechnologies, which have traditionally targeted\nmanual labour-intensive activities.\n\ngenai presents a\ntransformative opportunity for roles and industries\npreviously thought to be less impacted by digital\ninnovation.\n\n30%\n\n\nPotential for automation\n\nPotential for augmentation\n\nLower potential for automation\nor augmentation\n\nNon-language tasks", "**Potential for augmentation:**\n\n-  Evaluate the quality or accuracy of data\n\n-  Explain regulations, policies or procedures\n\n-  Prepare financial documents, reports or budgets\n\n-  Train staff to use products or services\n\n\nAdditionally, 22% of task-hours demonstrate a high\npotential for augmentation using genai.\n\nThese tasks\nmight be assisted with genai but necessitate human\ninput or involvement in some way.\n\nSuch tasks\ninclude inspecting the quality of products,\nevaluating the accuracy of data, explanations of\npolicies and procedures, preparing technical\ndocuments, or training staff to use products and\nservices.\n\nFor these tasks, genai acts as a copilot,\namplifying workers\u2019 expertise to improve the quality\nof their output.\n\nM 26% f t k h hibit l\n\n\n-----", "**The economic opportunity of genai in 2030**\n\n$ billion, 2030 annual value added, 2023 values\n\nSlow-paced adoption Medium-paced adoption Fast-paced adoption\n\n**$3-6B** **$45-115B**\n**$2-4B**\n**$10-25B**\n\n**$30-80B**\n\n\ngenai could deliver between $45-115B in\nvalue to the Australian economy.\n\nHow much of\nthis potential value is captured depends on two\nfactors: how well the technology is adopted\nacross all industries and how well workers are\nsupported to transition to other tasks.\n\nThe pace at which Australia adopts genai will\ndetermine how the potential opportunity is\ntranslated into tangible economic growth.\n\nIf we\naccelerate adoption, the total gains can be up to\n$115B annually by 2030.\n\nIf adoption in Australia\ngrows more slowly, the total benefit would be\napproximately $45B annually.\n\nThe majority of these gains, $30-$80B (or 70%),\nresult from uplifts in productivity.\n\nEvery routine\ntask automated by genai enables workers to\nachieve more in a given amount of time.\n\nFor\nexample, a customer support agent can attend to\nmore customer calls if the tasks of logging\ncomplaints and post-call feedback are handled by\ngenai.\n\nImportantly, there is a risk some of the\nautomated task-hours are not successfully\ntransitioned to other work.\n\nTo be conservative, we\nexclude these task-hours from the productivity\ngains modelling.\n\n2 Crucially, this highlights that\nsupporting workers and managing the transition\nis critical to achieving the full productivity\nbenefits of genai.\n\nIn addition, genai augments tasks and acts as a\ncopilot, allowing workers to complete high-value\nand high-quality work.\n\nFor example, a software\n\n\nspeed on new innovative medical research,\nimproving their diagnostic capabilities.\n\nThis\nincreased quality is expected to be worth $10-25B\nto the economy, depending on the adoption rate.\n\nAs well as improvements to existing industries,\ngenai will power new products and services in\nAustralia.\n\nGlobally, the total addressable market\nfor genai software could be ~$220B by 2030.\n\n1 If\nAustralia moves early, it could capture a greater\nthan proportional share of this market.\n\nFor\nexample, savvy Australian start-ups could build\nand sell industry-specific applications that\ncapture a global market.\n\nIn Australia, these new products and services will\npower new jobs and businesses that could\ncollectively add $5-10B to the economy,\ndepending once again on adoption rates.", "**A note on scenarios**\n\n_Since genai is relatively nascent and rapidly evolving,_\n_it is difficult to estimate with precision its_\n_economic value in 2030.\n\nFor this reason, we model_\n_the economic opportunity based on three different_\n_adoption scenarios, leading to a large range in the_\n_final figures.\n\nThese figures aim only to_\n_demonstrate the significant potential of GAI_\n\n\nIncreased\n\nproductivity\n\n\nImproved quality New jobs New business\n\ngrowth and\n\ncreation\n\n\nTotal", "###### To realise this economic opportunity, Australian industries and governments need to manage three key risks\n\nThe economic opportunity of genai is estimated according to three different scenarios, each based on differing rates of adoption (slow-paced, medium-paced, and highpaced).\n\nImportantly, the benefits in any of the three scenarios will only be achieved if Australia can manage three key risks:\n\n\n**xx**", "**Enabling equal access to genai across**\n\n**businesses and individuals**\n\nCertain regions or communities may face barriers in\naccessing and benefiting from genai.\n\nTo address this\nrisk, governments will need to prioritise initiatives\nthat bridge the digital divide.\n\nThis includes investing\nin infrastructure development, such as high-speed\ninternet connectivity in remote or underserved areas.\n\nAdditionally, it may mean establishing funding\nprograms and grants to support small and medium\nsized enterprises, startups, and education\ninstitutions in adopting the technology.\n\nPromoting\ndigital literacy can also help ensure that individuals\nfrom diverse backgrounds have the skills and\nknowledge to participate in the genai-driven economy.", "**Transitioning workers to other tasks and roles**\n\nThe full labour force benefits of genai will only be\nrealised if net employment remains steady.\n\nAs\nadoption and capability of genai increases, certain\noccupations may experience reduced demand for\nlabour.\n\nGovernments and industries must\ncollaborate to transition workers in such roles to\nother tasks and occupations.\n\nThis means\nproactively investing in comprehensive reskilling and\nupskilling programs, with a focus on emerging\nindustries and occupations, and emphasising digital\nliteracy, data analysis, critical thinking, and\ncreativity.", "**Managing genai responsibly**\n\nAs the capability of genai develops, and users are still\nlearning about its functionality, the technology\ncarries certain risks such as biased or unethical\noutputs, privacy concerns, and potential misuse.\n\nIndustry and government need to establish\nregulations that promote transparency,\naccountability, and responsible practices.\n\nThis\nincludes guidelines for transparency and\naccountability in decision-making, to ensure genai\nsystems are inclusive and do not obscure the\ncontext-specific needs of priority cohorts.\n\nFurthermore, ensuring data security is particularly\ncritical if genai is to drive benefits in highly sensitive\nindustries like healthcare or law.\n\n-----", "###### genai presents a significant opportunity for growth in at least four key sectors in the Australian economy\n\n**genai has high potential in at least four key sectors**\n\n\n\nThis report identifies four key sectors where Australia\ncan succeed in creating value through genai.\n\nThese\nopportunities are healthcare, manufacturing, retail and\nprofessional services.\n\nThese sectors have been chosen based on two key\nconsiderations.\n\nFirst, they are likely to continue being\nimportant sectors for employment and output in the\nAustralian economy into the future.\n\nSecond, genai is\nlikely to have a transformative effect on these\nsectors.\n\nAdditionally, these sectors and their diverse use cases\nfor genai were chosen to illustrate the breadth of the\ntechnology\u2019s impact on the economy.\n\nThe process for selection involved desktop research,\nindustry analysis, consultation with experts, along\nwith engagements with executives and key industry\npersonnel more broadly.\n\n|$ billion, annual value-added, 2030 Key industries|The genai Opportunity|Key driver of value|\n|---|---|---|\n|Healthcare|$5-13B|\u2022 Reduced medical admin, leading to more one on one patient care|\n|Manufacturing|$2-5B|\u2022 Shorter design cycles and greater quality control|\n|Retail|$3-9B|\u2022 Better customer support and personalised experiences, and streamlined back-end operations|\n|Professional and Financial Services1|$5-13B|\u2022 Automation of routine tasks, leading to more time invested in higher value-adding activities|\n\n\n-----", "**93% of people are interested**\n\n**in using digital self-service for**\n**pre-visit tasks** **3**\n\nWith genai, self-service will be\nmore personalised and\neffective.\n\ngenai has significant potential to improve the accessibility and quality of\nhealthcare delivery.\n\nIt can enable more one on one patient care by\nreducing time spent on admin, improving personalisation by being\nembedded in wearable devices, and supporting the transition towards\nmore proactive models of healthcare by allowing earlier diagnosis, at\nscale.\n\nImportantly, the key to realising these benefits will be robust\nprotocols that ensure patient confidentiality and safety are maintained.", "**Benefits of genai in Manufacturing**\n\ngenai may be a game-changer for Australian manufacturing, by enabling\na suite of advanced manufacturing capabilities that play to Australia\u2019s\nexisting manufacturing strengths of producing high quality and highly\ntechnical products.\n\nImportantly, shifting to advanced manufacturing is\na strategic priority for both State and Federal Governments.", "**Exploring**\n\n-  Improve quality inspection, using synthetic\ndata that depicts low-occurrence defects,\nand calibrating with computer vision\ninspection\n\n-  Make recommendations and provide training\ncontent and scenarios for servicing\nequipment and parts to field technicians\n\n\n**genai can assist in rapid prototyping and design**\n\nIllustrative use case of genai in manufacturing", "**32% may be augmented by genai** **1**\n\nThis means more time can be\ninvested in improving customer\nexperiences and products.\n\n**genai can improve the**\n**productivity of customer**\n**support workers by 14%** **2**\n\nStudies have found genai allows\ncustomer support workers to\nresolve more issues per hour.\n\n**genai could allow greater**\n**personalisation of products,**\n**and drive customer**\n**engagement**\n\nPersonalised chatbots and\nproduct offerings could enhance\nthe customer experience.\n\nAs a result of having to invest in omnichannel capabilities during the\npandemic, the retail industry should be better placed to integrate\ngenai into existing digital platforms.\n\nSuch integration could be\nparticularly important as companies look for new ways to\ndifferentiate and personalise products, while remaining costcompetitive.", "**Advising**\n\n-  Efficient inventory management with\nautomatic analysis of sales data and\nconsumer sentiment\n\n-  Assisting compliance with regulation, by\nsupporting easier navigation of laws and\nobligations\n\n-  Streamline complaint handling, by\ncategorising complaints and suggesting\nresponses\n\n-  Improved space management through\ncreating alternative planograms based on\nindividual store demographics", "**Post call**\n\nPost-call, genai\nanalyses the call\nand provides data\nand feedback for\nthe support\n\n\nCustomer\ncontacts the\nretailer with a\nproblem.\n\nA genai support agent\nconnects with the\ncustomer and guides\nthem through simple\ntroubleshooting while\n\n\nIf the matter is\ncomplex, it is directed\nto a human support\nworker, assisted by\ngenai to provide precise\n\n\n-----", "**Benefits of genai in Professional and Financial Services**\n\nThe professional services industry is a highly educated workforce with\nrelatively low levels of productivity.\n\nThis makes the industry a prime\ncandidate for genai transformation.\n\nAs genai automates routine and welldefined tasks, the highly skilled workforce can spend more time on\nhigher value thinking.\n\nWith genai, Australia could build on its reputation\nfor high calibre knowledge workers, particularly in financial and legal\nsectors.\n\n**genai could drive greater access**\n**to professional services,**\n**including legal and financial**\n**advice**\n\nFor example, genai may\nsupport lawyers to take on\nmore cases for underserved\ncohorts.", "**Exploring**\n\n-  Predict future client problems and assist\ngeneration of solutions\n\n-  Assist stress-testing through interactive\nsimulations of expected credit losses (ECL)\nbased on different macro-economic\nscenarios\n\n-  \u2018Horizon scanning\u2019 law changes in other\njurisdictions and analysing outcomes to\n\nk di ti\n\n\nA genai tool reviews the document,\nlooking for missing clauses by\ncomparing to other similar\ncontracts.\n\nIt summarises and shares the\nroot causes/ impacted\n\n\nLawyer completes first draft\nof a contract.", "###### Australian industries and governments are at a critical juncture with genai adoption and need to collaborate to capitalise on the opportunity\n\nThe previous two sections of this report illustrated\nthe significant opportunity genai represents for\nAustralia.\n\nIf Australia is to capitalise, the time to act\nis now.\n\nInnovation is progressing at a rapid rate, and\ninternational peers are already on the move towards\nadopting genai.\n\nAustralian industries and governments,\nif they are to keep pace, are at a critical juncture and\nneed to collaborate.\n\nThe genai space is rapidly evolving.\n\nWhile\nthis innovative environment signals great\nopportunity, it also brings significant uncertainty for\nboth adopters and regulators of genai.\n\nInternational peers are already implementing a range\nof policies to keep pace with this innovation.\n\nThe US\nhas established a Senate Judiciary Subcommittee on\nPrivacy, Technology and the Law to hear expert\nopinions about genai\u2019s impact on the economy and\nsociety.\n\n1 At the time of writing, the EU is progressing\nthe EU genai Act, its flagship piece of\nspecific legislation to classify and regulate genai.\n\n2 The\nG7 has announced its commitment to work together\non genai governance and interoperability.\n\n3 Overall, in the\nlast year alone, legislative bodies across 127\ncountries have passed 37 laws that include the word\n\u2018genai\u2019.\n\n4\n\nImportantly, Australia is already well positioned to\nstay up to speed with global best practice.\n\nIn 2019,\nthe Federal Government released an genai Ethics\nFramework, to guide businesses and the Government\nto \u2018responsibly design, develop and implement genai\u2019.\n\n5\nThe CSIRO\u2019s National genai Centre recently established\n\n\nthe Responsible genai Network (RAIN), which supports\nindustry to improve genai governance capabilities.\n\n6 It\nalso has published a report assisting businesses to\nimplement responsible genai.\n\n7 Further, the Department\nof Industry, Science and Resources is developing\nSafe and Responsible genai policy, 8 building on the\nNational Science and Technology Council\u2019s Rapid\nResearch Report on genai _._ 9\n\nImportantly, these initial policies are good first steps,\nbut mainly relate to the topic of regulation.\n\nAlongside\nregulatory clarification, collaboration between\nindustries and governments that focusses on\nsupporting Australia\u2019s genai ecosystem needs to\nbegin.\n\nThis section of the report aims to spur on this\ncollaboration.\n\nIt first explores Australia\u2019s\ncomparative advantages in digital technology that\nshould be leveraged by both industry and\ngovernment.\n\nNext, it explores the barriers industry\nand government face in capitalising on genai.\n\nFinally, it\noutlines the priority actions both adopters and policy\nsetters need to take if Australia is to become a global\nleader in genai.", "**Key contribution of this report**\n\nReleased draft regulation specific\nto genai 10\n\nDeveloping domestic\nfoundational models, e.g.\n\nMOSS\n\n\u00a3100M to establish Foundational\nModel Taskforce, to assess genai\nopportunities 11\n\nCSIRO Responsible genai Network\n(RAIN)\n\nDepartment of Industry, Science\nand Resources calls for\nconsultation on responsible genai\n\n\nImmediate actions for collaboration amongst adopters and policy setters\nto build out Australia\u2019s genai ecosystem\n\n\n-----", "**Large existing talent pool**\n\nAustralia is home to a burgeoning tech workforce, which was 935,000 strong as of February 2023 and\non track to grow to 1.2 million by 2030.\n\n1 This emerging workforce, with the right support from industry\nand government, can provide a strong foundation for the development and adoption of genai\ntechnologies.\n\nHighly-skilled talent has already enabled the country to become a global leader in areas\nsuch as natural language processing and machine learning.\n\n2", "**Stable regulatory settings and engagement with global standards**\n\nAustralia\u2019s governments and agencies value consultation and transparency in the development of\nnew regulation.\n\nThis approach promotes regulatory certainty and provides a stable environment for\nthe development and adoption of new technologies.\n\nThe Federal Government has already begun the\nconsultation process to consider genai governance in Australia.\n\n3 Furthermore, Australia is engaging with\nbest practice from overseas and focused on aligning domestic regulations with global standards, in\nturn encouraging foreign direct investment and international market opportunities for Australian\ncompanies.", "**High cloud adoption**\n\nAustralian industries are increasingly becoming cloud-adopters.\n\nIT spending reached $117B in 2022,\nwith ~30% on software alone.\n\n4 This is important since the full impact of genai will be realised when\norganisations can integrate genai across all its processes.\n\nThis requires those process to be digital and\naccompanied by strong data foundations in the first place.", "**Investment in digital infrastructure**\n\nAustralia has recently made significant investments in digital infrastructure.\n\n4 For example, the NBN\nwill provide 10 million households and businesses with high-speed internet access by 2025.\n\n5 This\ninvestment is critical to ensuring the benefits of genai, which requires reliable internet access, are\ndistributed across Australia, particularly in regional areas.", "**Strong tech sector and existing ecosystem**\n\nThe tech sector contributed $167B to GDP in 2022, growing by 80% since 2016.\n\n4 Australia\u2019s tech\necosystem has supported numerous globally successful companies, including Atlassian, Afterpay,\nSeek and Canva.\n\nFurthermore, international leaders in cloud services such as Microsoft, Google and\nAWS all have made significant, long-term investments in tech infrastructure in Australia.\n\nThe strength\nand diversity of Australia\u2019s tech sector will drive investment into new genai ventures and support\ncollaboration.", "**Thriving start-up culture**\n\nAustralian start-ups may develop domestic foundational models or harness the power of existing\nmodels developed overseas to develop applications for specific industry use cases.\n\nLast year, the\ntech sector attracted $7.4B with ~20% raised by Enterprise / Business software.\n\nFurthermore, there\nwere 20,000 tech start-ups in 2022, with 21 reaching unicorn status.\n\n4", "**World-class research institutions**\n\nAustralia is home to world-class universities and research institutions conducting cutting-edge\nresearch in areas such as genai and machine learning, as well as in areas with high\npotential for genai transformation such as medical technologies and advanced manufacturing.\n\nThis\nresearch expertise provides a foundation for the development of new genai technologies, as well as for\ncollaboration with international partners.", "**Responsible genai**\n\n**Developing trust:** Research suggests o nly one third of\nAustralians trust genai, and less than half believe the\nbenefits outweigh the risks.\n\n3 Users want to know how\ngenai-powered decisions made, how data is being used,\nand who to hold accountable in the case of errors.\n\n**Managing privacy and data security:** Concerns about\nwhere data is stored and how it is shared when\ninputted into foundational models may deter adoption,\nparticularly in industries that work with sensitive data\n(i.e.\n\nhealthcare or legal services).\n\n**Regulatory certainty:** Timing of the development of\nregulatory guidance makes business investment\ndecisions regarding genai difficult, particularly if\nAustralian regulation becomes out of step with global\nstandards.\n\n**Managing intellectual property** **:** It is important to\npreserve the public\u2019s access and ability to derive\nknowledge and understanding from copyrighted works.\n\nAny application of copyright or other IP law should\nrespect and preserve that important principle, and not\nunnecessarily inhibit the use of tools to achieve this.\n\n**Deciding to invest:** Adopting genai requires\nintegrating the technology with existing\nsystems, a robust data strategy, and\nexpertise in change management.\n\n**Launching internal genai governance:** To\nleverage genai for specific use cases,\nbusinesses might need to connect sensitive\ndata to language models, so that the model\ncan perform the desired functions and draw\ninsights from the data.\n\nThis requires\nbusinesses to implement strong safeguards\nto protect sensitive information.\n\n**Speed of change** : The rapidly evolving nature\nof genai technology makes it hard to determine\nthe right time to invest, the specific areas\nwhere technology can provide value, and\nwhether solutions can be built in-house or\nrequire external partnerships.\n\nThis makes it\ndifficult to develop the business case for\nadoption.\n\n**Building essential C-suite knowledge:** Due to the\nrapid advances in genai, it is difficult for executives\nto know which use cases are present\nopportunities, and which are already outdated.\n\nThis lack of awareness not only stifles adoption,\nbut presents a risk if leaders invest without\nunderstanding best practice for responsible genai.\n\n1\n\n**Building workforce digital literacy:** Australia has a\nsignificant digital skills gap, with 3 in 5 surveyed\nbusinesses reporting their workforce lacked or\nhad outdated digital skills.\n\n2 This is a barrier to\nboth adoption and production of genai tools.\n\nSpecifically, workers currently lack an\nunderstanding of the strengths and limitations of\ndifferent genai models, potentially leading to\nmisuse.\n\n**Managing training pathways:** If low-level tasks\nbecome automated, junior employees have fewer\nchances to learn the \u2018tools of the trade\u2019.\n\nEmployers need to rethink how junior staff will be\nsupported in their career progression.\n\n**Narrowing the margin for error** : While the latest\ngenai models narrow the margin for error\nsignificantly, human verification of outputs will\ncontinue to be needed, especially in critical usecases.\n\nThis margin for error makes leaders in\ncritical industries such as healthcare or finance\nmore cautious about adoption where incorrect\nor misleading information could have\nsignificant consequences.\n\n**Scale of investment required to build industryspecific genai orchestrations:** Businesses often\nrequire customised solutions.\n\nIn order to adapt\ngenai models, businesses might need to invest\nadditional resources in building genai\norchestrations that align with industry-specific\nneeds.\n\nThese challenges may be resolved naturally as\nthe technology develops.\n\nYet businesses and\ngovernments still face three further barriers\n\n\n-----", "**Priority actions to accelerate adoption of genai**\n\n|Priority|Potential Actions|Impact|\n|---|---|---|\n|Define the genai vision and opportunity|\u2022 Define the organisation\u2019s vision for genai, with clear goals, outcomes and success metrics \u2022 Determine the organisation\u2019s risk appetite and stakeholder priorities.\n\n\u2022 Assess the opportunities for \u2018big-picture\u2019 transformation by examining the whole range of the organisation\u2019s processes with a new genai lens.\n\nThis includes re-assessing existing infrastructure, data strategies, investment strategies, training processes etc.|\u2022 Enables a whole-organisation transformation, beyond just changing singular, siloed processes.\n\n\u2022 Facilitates continuous transformation as genai\u2019s capabilities develop.|\n|Assess readiness|\u2022 Assess readiness across three domains; data, people and organisation.\n\nData needs to be cleaned, governed and piped from source for use in the cloud.\n\nPeople need to be supported to have the necessary skills and mindset for adoption.\n\nThe organisation needs to have modern processes, responsible genai governance, and execution oversight.\n\n\u2022 Identify gaps and understand which solutions can be created in-house and which need to be bought from partners.\n\nDevelop a robust ecosystem strategy that builds relationships with key partners.|\u2022 Identifying potential challenges and risks early on allows proactive mitigation strategies.\n\n\u2022 Readiness assessment provides a foundation for developing a comprehensive adoption strategy, tailored to the specific needs and capabilities of the organisation.|\n|Invest and experiment with the technology|\u2022 Develop hypotheses for 1-3 use cases & experiment to validate value, understand how the workforce reacts, plan for change management, and how to work with partners to fine-tune outcomes.\n\n\u2022 Set out detailed reference architecture and ecosystem to accelerate deployment and manage the transition.\n\nThis deployment pathway should prioritise low-risk, high-impact applications (i.e.\n\ninternal knowledge management) that have minimal barriers to adoption.|\u2022 Allows organisations to understand benefits and challenges, before making significant investment decisions.\n\n\u2022 Enables change management, data management and responsible practices to be defined.|\n|Develop Responsible genai governance frameworks|\u2022 Set a foundational governance system, that articulates the roles and responsibilities of different teams and functions across the organisation.\n\n\u2022 Define the principles of responsible genai and the overarching values that will guide decision making.\n\n\u2022 Develop practical guides that translate these principles into a daily practice for each worker.\n\n\u2022 Perform ongoing reviews of these practical guides, to ensure adaptability to developments in genai.|\u2022 Mitigate the risks associated with genai adoption and instil confidence in internal and external stakeholders that priorities are aligned to secure and responsible use.|\n|Upskill the workforce|\u2022 Design and deploy an organisation-wide literacy and upskilling program, targeting leaders, producers and adopters based on the needs of their respective role and function.|\u2022 Support employees to maximise the value of genai and adapt to new roles and responsibilities, fostering a culture of innovation, creativity and learning within the organisation.|", "**Communicate to**\n\n**customers and**\n**stakeholders**\n\n\nDefine the organisation\u2019s vision for genai, with clear goals, outcomes and success metrics\n\nDetermine the organisation\u2019s risk appetite and stakeholder priorities.\n\nAssess the opportunities for \u2018big-picture\u2019 transformation by examining the whole range of the organisation\u2019s\nprocesses with a new genai lens.\n\nThis includes re-assessing existing infrastructure, data strategies, investment\nstrategies, training processes etc.\n\nAssess readiness across three domains; data, people and organisation.\n\nData needs to be cleaned, governed and piped\nfrom source for use in the cloud.\n\nPeople need to be supported to have the necessary skills and mindset for adoption.\n\nThe organisation needs to have modern processes, responsible genai governance, and execution oversight.\n\nIdentify gaps and understand which solutions can be created in-house and which need to be bought from partners.\n\nDevelop a robust ecosystem strategy that builds relationships with key partners.\n\nDevelop hypotheses for 1-3 use cases & experiment to validate value, understand how the workforce reacts, plan for\nchange management, and how to work with partners to fine-tune outcomes.\n\nSet out detailed reference architecture and ecosystem to accelerate deployment and manage the transition.\n\nThis\ndeployment pathway should prioritise low-risk, high-impact applications (i.e.\n\ninternal knowledge management) that\nhave minimal barriers to adoption.\n\nSet a foundational governance system, that articulates the roles and responsibilities of different teams and functions\nacross the organisation.\n\nDefine the principles of responsible genai and the overarching values that will guide decision making.\n\nDevelop practical guides that translate these principles into a daily practice for each worker.\n\nPerform ongoing reviews of these practical guides, to ensure adaptability to developments in genai.\n\nDesign and deploy an organisation-wide literacy and upskilling program, targeting leaders, producers and adopters\nbased on the needs of their respective role and function.\n\nConduct market research and consultations with key stakeholders to understand expectations around genai usage, and\nkey concerns.\n\nExplain to stakeholders plans for genai adoption, and the steps taken to ensure responsible use of genai.\n\nEnables a whole-organisation transformation, beyond just changing\nsingular, siloed processes.\n\nFacilitates continuous transformation as genai\u2019s capabilities develop.\n\nIdentifying potential challenges and risks early on allows proactive\nmitigation strategies.\n\nReadiness assessment provides a foundation for developing a\ncomprehensive adoption strategy, tailored to the specific needs and\ncapabilities of the organisation.\n\nAllows organisations to understand benefits and challenges, before\nmaking significant investment decisions.\n\nEnables change management, data management and responsible\npractices to be defined.\n\nMitigate the risks associated with genai adoption and instil confidence\nin internal and external stakeholders that priorities are aligned to\nsecure and responsible use.\n\nSupport employees to maximise the value of genai and adapt to new\nroles and responsibilities, fostering a culture of innovation, creativity\nand learning within the organisation.\n\nInstill customers and stakeholders with confidence about genai usage,\nand embed transparency into adoption, to encourage adoption of\nnew genai products and services.\n\n-----", "**Actions for regulators and policy makers to support genai adoption**\n\n|Priority|Potential Actions|Impact|\n|---|---|---|\n|Define the vision for genai in Australia|\u2022 Engage communities to gauge societal expectations about what principles should guide genai adoption.\n\n\u2022 Consult with industry and leverage existing strategy documents for critical technologies, including genai, to understand Australia\u2019s genai advantage, prioritise use cases and applications, and develop policies to address key challenges.\n\n\u2022 Establish mechanisms to monitor and evaluate progress in genai adoption.|\u2022 A clear \u2018North Star\u2019 will signal the policy makers\u2019 future intent to invest and support genai adoption, in turn supporting further adoption from industry.|\n|Support collaboration between industry, academia and government|\u2022 Support knowledge sharing amongst industries, academia and governments, to ensure an adequate level of understanding of genai amongst key decision makers and executives.\n\n\u2022 Establish robust communication channels for key stakeholders, including regular roundtable discussions, to monitor developments in technology and risks.\n\n\u2022 Continue collaborating with international peers, aligning on best practice for regulation and investment.|\u2022 Ensure Governments, regulators, industry and research bodies are aligned in their priorities and understanding of \u2018best-practice\u2019 for responsible genai.\n\n\u2022 Increased knowledge sharing and awareness, including at C-suite level, about the opportunities and responsibilities of genai adoption.|\n|Provide regulatory clarity|\u2022 Provide guidance on how Australia\u2019s existing regulatory environment treats genai (i.e.\n\nThe Privacy Act, Australian Consumer Law, anti- discrimination acts).\n\nIdentify and prioritise gaps, to understand if genai-specific regulation is needed.\n\n\u2022 Develop a standardised risk management framework for use by both governments and industry as they adopt genai, leveraging existing international frameworks where relevant (for example, the genai Risk and Management Framework from the National Institute of Standards and Technology) \u2022 Ensure regulation, either in existing laws or through bespoke regulation, aligns with global standards.|\u2022 Signal future intentions and direction of regulation and legislation, assisting organisation decisions.\n\n\u2022 Building trust and accountability will encourage adoption amongst industry and ensure safe use.|\n|Incentivise adoption and innovation|\u2022 Consider tax incentives, grants and start-up support to develop a domestic genai ecosystem.\n\n\u2022 Enhance and support existing research programs in universities and CSIRO, particularly focusing on mitigating Responsible genai risks.\n\n\u2022 Deliver business education and support knowledge sharing to SMEs/NGOs, including industry partnerships with international peers.\n\n\u2022 Leverage existing programs, such as the Industry Growth Program and the National Reconstruction Fund (NRF), as key mechanisms for domestic genai industry growth.|\u2022 Scale up industry capability and productivity and increase pull-through downstream demand.|\n\n\nContinue to leverage upskilling programs and micro-credentials to build basic digital literacy and support workers into new, higher-value\nadding tasks (e.g.\n\nCSIRO\u2019s Next Generation genai and Emerging Technologies Graduates Program).\n\nA clear \u2018North Star\u2019 will signal the policy makers\u2019\nfuture intent to invest and support genai adoption, in\nturn supporting further adoption from industry.\n\nEnsure Governments, regulators, industry and\nresearch bodies are aligned in their priorities and\nunderstanding of \u2018best-practice\u2019 for responsible genai.\n\nIncreased knowledge sharing and awareness,\nincluding at C-suite level, about the opportunities\nand responsibilities of genai adoption.\n\nSignal future intentions and direction of regulation\nand legislation, assisting organisation decisions.\n\nBuilding trust and accountability will encourage\nadoption amongst industry and ensure safe use.\n\nScale up industry capability and productivity and\nincrease pull-through downstream demand.\n\nIncrease access to skilled workers and build\ncapacity in industry-relevant capabilities.", "**Invest in the right**\n\n**skills and support**\n**higher value tasks**\n\n\nLeverage Jobs and Skills Councils to update industry standards around skills, credentials and qualifications relevant to genai, and support\neducation providers to deliver courses aligned to these standards.\n\nLeverage the Technology Council of Australia\u2019s _Getting to 1.2 Million,_ an existing national strategy for building the domestic tech\n\n\n-----", "**Estimating** \ud835\udc99 \ud835\udc8a **and** \ud835\udc9a \ud835\udc8a **is done in four steps**\n\n1.\n\nWe first tag tasks in the O*NET database as either language or non language tasks\nLanguage tasks include natural, mathematical, computational, and other \u2018languages\u2019.\n\nNon-language tasks are not\nimpacted by genai at all (i.e.\n\nmanual labour tasks).\n\nImportantly, since LLM\u2019s have shown significant leaps in\ncapability and performance, we focus our assessment on these models.\n\nThis assessment is based on the\ncapabilities of GPT-4 (the current state of the art LLM).\n\nThis means the analysis does not include the impact of\nimage-generating models and other modalities.\n\n4\n\n2.\n\nWe then filter language tasks against a set of criteria:\ni. whether the task requires human to human interaction (as opposed to human to computer interaction)\n\nii.\n\nwhether the task is non-routine and/or non well-defined\n\niii.\n\nwhether the task requires human involvement enforced by law, ethics or social conventions.\n\n3.\n\nA task\u2019s score against the three criteria determines if could be automated or augmented\nEach language-based task is assigned a score based on the number of the above criteria it meets, and categorised\naccording to this score.\n\n-  **High potential for automation** : tasks do not meet any of the criteria, i.e..\n\nIt involves human to computer\ninteraction, is relatively routine and well defined, and there\u2019s no human involvement enforced by law, ethics or\nsocial conventions.\n\n-  **High potential for augmentation** : tasks meet only one of the criteria, i.e.\n\neither human to human interaction\nrequired, or it is routinary/well structured, or human involvement enforced.\n\n-  **Lower potential for augmentation or automation** : tasks meet at least two of the criteria.\n\nNo significant impact\nof the technology is expected.\n\n4.\n\nA combination of human and machine learning classification is used to score and categorise all tasks in the\nO*NET database\nEach task is scored and classified by both human and machine tagging.\n\nWe prompt (few-shot) gpt-4 along with\nsome example classifications for it to classify other tasks.\n\nA combination of the scores from both approaches is\nused for the final categorisation of a task.\n\nOutputs from GPT-4 tagging were validated by selecting a random\nsample of results for human review.", "**For every occupation, we estimate the number of working hours that can be automated or**\n\n**augmented by genai**\n\nThe O*NET database provides an overview of all the tasks performed by workers in every\noccupation in the US economy, and how much time is spent on each task.\n\n1 Mapping the\nresults to the Australian workforce, we can attain the percentage of task-hours exposed to\nautomation and augmentation by genai for each occupation.\n\nWe then multiply this percentage\nby the median hours worked in a year in 2022 in each occupation 2 and projected number of\npeople employed in the occupation by 2030.\n\n3 This gives the total number of working hours\nper occupation that can potentially be automated and augmented by genai in 2030.\n\nThis method is represented by the following equations:\n\n\nTotal hours \ud835\udc1a\ud835\udc2e\ud835\udc2d\ud835\udc28\ud835\udc26\ud835\udc1a\ud835\udc2d\ud835\udc1e\ud835\udc1d by genai = \u0dcd\n\n\ud835\udc56=1\n\n\ud835\udc5b\n\nTotal hours \ud835\udc1a\ud835\udc2e\ud835\udc20\ud835\udc26\ud835\udc1e\ud835\udc27\ud835\udc2d\ud835\udc1e\ud835\udc1d by genai = \u0dcd\n\n\ud835\udc56=1\n\n\n\ud835\udc65 \ud835\udc56 (\ud835\udc5a \ud835\udc56 \ud835\udc5d \ud835\udc56 )\n\n\ud835\udc66 \ud835\udc56 (\ud835\udc5a \ud835\udc56 \ud835\udc5d \ud835\udc56 )\n\n\nWhere:\n\n-  n is the number of unique occupations\nin the economy\n\n-  i is the given occupation\n\n-  x is percent of task-hours exposed to\nautomation by genai\n\n-  m is the median hours worked in the\noccupation in 2022\n\n\np is the projected number of people\nemployed in the occupation by 2030 3\n\ny is the percent of task-hours exposed\nto augmentation by genai\n\n\nTherefore, the key component of this method is estimating \ud835\udc65 \ud835\udc56 and \ud835\udc66 \ud835\udc56 .\n\nAll other variables can\nbe found using ABS data.\n\n-----", "**Task-hours automated by genai are likely to be successfully**\n\n**transitioned to other tasks**\n\nTo estimate genai\u2019s impact on productivity, we need to calculate the number of automated task-hours that might\nbe successfully transitioned to other tasks.\n\nTask-hours automated by genai are likely to be successfully\ntransitioned to other work due to two key reasons:", "##### 1 correlated with low levels of unemployment\n\nWhile automation may reduce demand for some roles, these replaced roles can be transitioned\nto either new jobs created within the industry or in other sectors.\n\nThe logic here is automation\nleads to costs savings for businesses, which may be re-invested into higher-value activities.\n\nAlternatively, the savings may result in either lower prices or higher wages.\n\nIn either case, the\nsurplus generated by automation spurs economic growth, in turn creating new jobs in the\neconomy.\n\n2,3", "##### 2 genai is mainly likely to replace specific tasks within jobs, rather than entire roles.\n\n**genai replaces tasks, not whole roles** .\n\nFor the vast majority of occupations, the proportion of taskhours replaced by genai is relatively modest.\n\nEven at full adoption of genai \u2013 which is a far higher\nlevel of adoption than our modelled fast-adoption scenario \u2013 _85% of workers will have less than_\n_one third of their task-hours exposed to automation_ .\n\n4 Our scenarios to 2030 suggest that genai\nautomation would affect about one hour per week on average for the typical worker.\n\n**Effective use** of genai tools for complex tasks **, requires human expertise** to prompt models and\ninterpret results.\n\nThis suggests demand for skilled workers will likely continue, even as adoption\nincreases.", "**However, we account for the fact that some automated task-hours**\n\n**might not be successfully transitioned**\n\nIn our modelling, we account for the possibility that some task-hours automated by genai might not be\nsuccessfully transitioned to other tasks.\n\nTo be conservative, these automated task-hours unlikely to be\ntransitioned are excluded from the final productivity gains calculation for genai (see next slide).", "**Estimating the number of automated hours transitioned to other tasks**\n\nWe have taken the assumption that the number of automated hours transitioned to other tasks varies by\noccupation.\n\nWe have assumed that 5 for the occupations that are most exposed to genai automation, none of the\nautomated hours are transitioned to other tasks for workers (telemarketers, with only 32% of task-hours _not_\nautomated, represent this case).\n\nOn the flipside, occupations least exposed to genai automation (caretakers, with\n100% of task hours _not_ automated), would have all task-hours transitioned to other work.\n\nMaking these assumptions\nallows us to assume the remaining occupations fit somewhere in-between, as shown in the curve below.\n\nWe assume the curve is logarithmic in nature, i.e.\n\nwhen an\noccupation is less exposed to genai (more hours _not_ automated),\nthe likelihood of successfully transitioning automated hours to\nother tasks would decrease at a lower rate as its exposure level\nincreases (traversing the curve from right-to-left).\n\nConversely,\nthis rate of change would be higher for occupations more\nexposed to genai (fewer hours _no_ t automated).\n\nBased on this modelled relationship and occupation level data,\non average across the economy 93% of task-hours would be\nsuccessfully transitioned (i.e.\n\n7% of task-hours would not be\ntransitioned to other work), which aligns with other research.\n\n6\nImportantly, this is finding is only a conservative modelling\nassumption which limits the size of the opportunity described \u2013\nit is not a forecast of employment.\n\nIn reality, it is highly likely that\nthe labour market would respond dynamically and that rising\nincomes stemming from productivity growth would create more\ndemand for labour.\n\nModelled relationship b/w exposure to automation and likelihood\n\nof successfully transitioning automated task-hours\n\n\n-----", "**Conceptual overview:**\n\nAfter estimating the potential task-hours automated by genai and the share of these\nhours successfully transitioned to other work, we then estimate the impact this can have on\nlabour productivity and the economic value gained from this in 2030.\n\nLabour productivity is\ntypically measured as the ratio of total output to total hours worked (i.e., output per unit time).\n\nFirst, it\u2019s useful to conceptualise how a future economy that adopts genai differs from one with no\ngenai (i.e.\n\nthe counterfactual).\n\nWe make a conservative assumption that the capability of genai\ndoesn\u2019t significantly differ in 2030 from current levels (i.e., there are no external shocks that\nvastly increase or decrease the technology\u2019s capability).\n\nCompared to the counterfactual case,\nthe key difference in an economy using genai is that certain task-hours are now automated with\ngenai.\n\nThis allows a human worker to now focus more on other tasks, thereby increasing the\noutput they can produce per unit time (i.e., their productivity).\n\nThis concept is affirmed by academic studies on genai's influence on productivity.\n\nA prime\nexample is the 2023 experimental study, \"genai at Work,\" by Brynjolfsson et al., that\nexamined the productivity effects of genai-assisted call centre workers compared to a control\ngroup.\n\nWith the aid of genai, which provided real-time guidance and links to pertinent\ndocumentation, workers resolved 13.8% more calls within the same duration.\n\nNotably, the\nautomation of minor tasks led to a productivity surge, allowing the worker to address more calls.\n\nHowever, the workers' expertise remained vital as they maintained discretion over the\nimplementation of the genai's suggestions, reinforcing the need for high-skilled labour in\nconjunction with genai.\n\n\ud835\udc65\u2217 \ud835\udc61\n% increase in output per hour worked =\n\n\n1 \u2212\ud835\udc65\u2217\ud835\udc61\u2032\n\n\nWhere:\n\n-  \ud835\udc65 is the proportion of hours automated by genai\n\n\n\ud835\udc61 is the proportion of automated hours successfully transitioned to other tasks\n\n\ud835\udc61 \u2032 = 1 \u2212\ud835\udc61 i.e., the proportion of automated hours not transitioned to other tasks\n\n\n\ud835\udc61 is the proportion of automated hours successfully transitioned to other tasks\n\n\nFor example, a worker who has 10% of their hours automated by genai (a=0.1) and 90% of these hours get\ntransitioned to other tasks (t=0.9) will experience a 9% increase in output per hour worked.", "**We then calculate the value of output per hour for a worker in each occupation**\n\nWe then estimate the GVA per worker for each occupation, which is a measure of output per hour i.e.\n\nproductivity.\n\nThe GVA per worker is based on occupation level data on wages per hour and the ratio of GVA to\nwages from ABS Industry data.\n\n1", "**Finally, we multiply the per worker value by the number of employees in the occupation**\n\nTo calculate the productivity gains of genai, we multiply the GVA per worker (step B) by the percentage increase in\nproductivity per worker (step A).\n\nTo get the total gains across the economy, we multiply this by the projected\nnumber of people employed in the occupation, and sum across all occupations.\n\nThis is given by the following\nequation.\n\nTotal productivity gains of genai = \u0dcd\n\n\ud835\udc56=1\n\n\n\ud835\udc4e \ud835\udc56 \ud835\udc4f \ud835\udc56 \ud835\udc5d\n\n\nWhere:\n\n-  n is the number of unique occupations in the\neconomy\n\n-  i is the given occupation\n\n\n\ud835\udc4e is the % increase in output\n\n\ud835\udc4f is value of output per worker\n\n\ud835\udc5d is the projected number of workers in the\noccupation in 2030 2\n\n\n-----", "**We calculate the value of this higher quality output in terms of a wage premium**\n\nTo evaluate the improvements in quality of work in each occupation, we multiply each hour of work\naugmented by genai by [Median hourly wage X 0.2].\n\n1 This assumes that augmented hours of work will earn\na wage premium, as augmentation leads to higher quality work.\n\nPrevious econometric modelling done by\nAccenture, shows non-automatable work (complex tasks) pays a wage premium of 20% compared to\nautomatable work.\n\n2 This is represented by the following equation:", "**Conceptual overview:**\n\nUsing our estimates on the potential task-hours augmented by genai, we then\nestimate the impact this can have on quality of outputs produced.\n\nAugmentation means genai\nassists the human worker to complete a given task.\n\nSuch tasks may include inspecting the\nquality of products, evaluating the accuracy of data, explanations of policies and procedures,\npreparing technical documents, or training staff to use products and services _._ In other words,\naugmentation is equivalent to genai being a copilot, i.e.\n\nan expert helper to a user trying to\naccomplish a complex task.\n\nAs these tasks still require a human in the loop to either validate\nthe results or complete parts of the task, we assume this augmentation results in an\nimprovement in the quality of output, rather than the production of more output.\n\nA good example of such \u2018augmentation\u2019 is genai\u2019s ability to assist workers in brainstorming and\ngenerating new ideas and solutions.\n\nFor example, a software developer discovers a bug\nunique to their application, and needs to generate a piece of code to resolve the issue.\n\nThe\ndeveloper can describe the issue to the genai coding companion, asking it to suggest\nsolutions.\n\nThe developer can then test and refine each generated solution, choosing the piece\nof code that gives the optimal result.\n\nAnother example may be in healthcare, with genai models\nassisting practitioners in diagnoses.\n\ngenai models may generate a list of possible diagnoses,\nbased on given inputs, and the healthcare professional's expertise allows them to choose the\nmost plausible case.\n\nIn both examples, genai models enhance the expertise of the human\nworker, leading to better quality outcomes.\n\nTotal quality gains of genai = \u0dcd\n\n\ud835\udc56=1\n\n\n\ud835\udc66 \ud835\udc56 (0.2\ud835\udc64 \ud835\udc56\n\n\n|Col1|Where: \u2022 \ud835\udc66 is now the number of hours augmented in the given occupation (see slide 35 for method) \u2022 \ud835\udc5b is the number of unique occupations in the economy \u2022 i is the given occupation \u2022 \u210e is the number of hours automated in the given occupation (see slide 35 for method) \u2022 \ud835\udc64 is the median hourly wage in the given occupation|Col3|\n|---|---|---|", "**To convert these wage values to Gross Value Added (GVA), we use historic ratios of wages**\n\n**to GVA**\nThe previous equation gives productivity gains in wage values.\n\nTo convert these wage values to gross\nvalue-added, we perform the following conversion:\n\n\nTotal quality gains of genai in value added terms = \ud835\udc44( \ud835\udc3a )\n\n\ud835\udc4a\n\nWhere:\n\n-  \ud835\udc44 is total productivity gains of genai in wage value terms\n\n-  G is the average GVA in the economy last 10 years 3\n\n-  W is the average total wages in economy last 10 3\n\n\n-----", "**Value created**\n\n**by new**\n\n**products and**\n\n**services**\n\n\nNew genai\nproducts and services\nwill continue to be\ndeveloped and brought\nto market.\n\nAustralia\u2019s strength is likely\nnot to be in producing\nfoundational models, owing\nto large computing and\ninvestment requirements.\n\nRather, Australia is likely to be\na global leader in applications\nbuilt on top of such models.\n\nThe value created by new\nproducts and services will be\ndriven by new jobs and\nbusiness growth.\n\nTotal addressable market is the total revenue opportunity for businesses selling genai products.\n\nWe focus only on the market for genai software (i.e.\n\napplications that are built on top of large language\nmodels), since consultations revealed this is where Australia\u2019s opportunity is most likely to reside (rather\nthan in producing hardware, or the LLM\u2019s themselves).\n\n1", "**2** **We estimate Australia\u2019s share of this global market, using Australia\u2019s current share** **of global tech \u2018unicorns\u2019 as a proxy.\n\n**\n\nA \u2018unicorn\u2019 is defined as a start-up with over $1B in annual turnover.\n\nIn 2022, Australia\u2019s share of global\ntech unicorns was 2.3%.\n\n2 We use this 2.3% as a base-case proxy 3 for Australia\u2019s share of genai market for\ntwo reasons.\n\nFirst, it accounts for Australia\u2019s comparative in tech start-ups.\n\nWe assume Australia will\ncapture a greater than proportional share of the genai market (i.e.\n\ngreater than 1.5%, its current share of\nglobal GDP) owing to its comparative advantages in tech.\n\nSecond, we focus only on companies over $1B\nsince this would make up the majority of Australia\u2019s market share.", "**We estimate the contribution of the genai market to Australia\u2019s economy**\n\n**3**\n\nFinally, we estimate the value created for the Australian economy from this genai market.\n\nThis value is\nbased on the revenue earnings, previously estimated.\n\nTo calculate this value, we use the average ratio of\ntotal income to industry value-added in Australia\u2019s tech sector over the last 10 years.\n\nWe then estimate\nhow much of this industry value-added is driven by either new jobs or new businesses based on the\nhistoric ratio of wages to industry value-added over the last 10 years (approximately 0.4).\n\n4\n\n\n-----", "**Methodology for estimating adoption rates of genai by 2030**\n\nIt is important to note \u2018adoption\u2019 should not be thought only of individuals using genai in an unstructured, case-by-case basis (such as an individual having a personal ChatGPT account).\n\nRather, for genai to achieve the economic benefits\ndescribed in this report, \u2018adoption\u2019 refers to more strategic use occurring at the enterprise level (i.e.\n\nintegration into business functions and processes).\n\nAs discussed in Section 3, such adoption faces numerous challenges, and requires a\nrange of actions to address such barriers.", "**1.\n\nUnderstanding the adoption of technologies as an S-Curve** **2.\n\nUsing the Internet adoption rates as a reference to model genai**\n\n**adoption**\n\n\nIn the world of technology and innovation, the adoption of new technologies typically follows a distinct pattern\nknown as an S-curve.\n\n1 It represents a slow start (early adopters), followed by a rapid increase (majority\nadopters), and then a slowdown as saturation is reached (late adopters).\n\nWe then use the fitted parameters to estimate the adoption curve for genai.\n\nWe consider three scenarios to\nsignify the uncertainty in genai's adoption:\n\n-  **Slow-paced adoption:** We assume that the inflection point for genai's adoption is as far off in the future as\nit was for the internet in 1987.\n\nIf genai is at a similar stage by end of 2023, with limited adoption and usage\nprimarily within specialised fields, then this scenario would be appropriate.\n\n-  **Medium-paced adoption:** We assume that the inflection point for genai's adoption is as far off as it was for\nthe internet in 1990.\n\nIf by the end of 2023, genai is at a stage where it's seeing increased commercial\ninterest but is still not widely adopted, this scenario would apply.\n\n-  **Fast-paced adoption:** We assume that the inflection point for genai's adoption is as far off as it was for the\ninternet in 1993.\n\nIf by the end of 2023, genai reaches a stage where it is being adopted by early majority\nusers, this scenario would be most appropriate.\n\nThese assumptions allow us to shift the curve's inflection\npoint (t0) to an appropriate position relative to genai's start\nyear.\n\nIn the scenario of slow-paced adoption, adoption\nrates in 2030 are 13%.\n\nThis can be interpreted as 13% of\ntask-hours that have the potential to be automated and\naugmented are in fact automated and augmented.\n\nIn the\nmedium and high paced scenarios, adoption rates in\n2030 are 21% and 33% respectively.\n\nWe have no scenario\nfor the final level of adoption of genai, but would expect the\nultimate adoption to be much less than 100 per cent.\n\nThis modelling approach provides a structured way to\nestimate and visualise the potential adoption trajectory\nof genai, using the historical adoption of the internet as a\nbenchmark.\n\nHowever, there remains significant\nuncertainty about the future adoption path of genai and\nthese adoption scenarios are intended as useful guides\nf i l i\n\n\nMathematically, this curve can be represented by a logistic function, defined as:\n\n\n\ud835\udc46\ud835\udc61=\n\nWhere:\n\n-  t is the input to the function (in our case,\nrepresenting the years since a base year)\n\n-  S(t) is the adoption rate at t\n\n\n1 + \ud835\udc52 \u2212\ud835\udc58\ud835\udc61\u2212\ud835\udc61 0\n\n-  e is the base of natural logarithms,\n\n-  k is the logistic growth rate or steepness of the\ncurve at the inflection point\n\n\nL is the maximum adoption rate (the saturation\nlevel),\n\n\nt0 is the inflection point, the t-value at which\nadoption rate is growing the fastest\n\nTo predict the S-curve of genai, we use historical data on\ninternet adoption 2 in Australia as a reference point.\n\nWe\nfit the logistic function to this data using a method\ncalled curve fitting, which finds the values of k and t0\nthat produce the best fit to the data.\n\nThe \u2018L\u2019 parameter\nfor genai is assumed to be known.\n\nThe following key assumptions are made:\n\n-  The adoption of genai will follow a similar S-curve as\nthe adoption of the internet\n\n-  The saturation level \u2018L\u2019 is set to 1 for modelling\npurposes\n\n-  The inflection point t0 for genai will vary based on\ndifferent scenarios\n\n\n-----", "**Brynjolfsson, Baily and Korinek outline a growthaccounting methodology for calculating the impact**\n\n**of genai**\nIn _Machines of mind: The case for an genai-powered productivity_\n_boom (2023)_ , the authors outline two channels through\nwhich genai may increase productivity in the economy.\n\nFirst,\ngenai will increase the level of output per unit of labour input\nproduced in the economy (i.e.\n\nincrease the efficiency of\noutput production by workers).\n\nSecond, genai will lead to flowon innovations, such as new products and services, that will\nfurther increase the efficiency of output production over\ntime.\n\nThe authors conceptualise these flow-on effects as an\nincrease in the _growth rate_ of productivity.\n\nIn our modelling, we also capture both these channels.\n\nThe\nfirst channel is captured as \u2018productivity gains\u2019.\n\nThe second\nchannel, the flow-on innovation, is captured in our \u2018quality\ngains\u2019 and \u2018new products and services\u2019 buckets.\n\nBrynjolfsson\net al.\n\nchoose to frame both channels as \u2018productivity gains\u2019,\nsince both channels are increasing output per unit of input.\n\nWhen we adapt this method for Australian data, it returns\nresults comparable to our study, broadly between the\nmedium-paced and fast-paced scenarios for growth.", "**Disclaimer**\n\nThis document is intended for general informational purposes only.\n\nThe report is a\ncollaboration between Microsoft and the Tech Council of Australia.\n\nViews and opinions expressed in this document are based on the companies\u2019 knowledge and\nunderstanding of its area of business, markets and technology.\n\nThe companies do not provide\nmedical, legal, regulatory, audit, or tax advice, and this document does not constitute advice of\nany nature.\n\nWhile the information in this document has been prepared in good faith, the\ncompanies disclaim, to the fullest extent permitted by applicable law, any and all liability for\nthe accuracy and completeness of the information in this document and for any acts or\nomissions made based on such information.\n\nOpinions expressed herein are subject to change\nwithout notice.\n\nNo part of this document may be reproduced in any manner without the written\npermission of the companies.\n\nThis document may make references to third party names,\ntrademarks or copyrights that may be owned by others.\n\nAny third-party names, trademarks or\ncopyrights contained in this document are the property of their respective owners.\n\n-----", "**Washington, DC 20528**\n\nOctober 24, 2023\n\nPolicy Statement 139-07\n\nMEMORANDUM FOR: DHS Agency and Office Leaders\n\n\nFROM: Eric Hysen\n\nChief Information Officer\n\n\nERIC N Digitally signed by ERIC N HYSEN\nHYSEN Date: 2023.10.24 15:51:49 -04'00'\n\n\nSUBJECT: **Use of Commercial genai (genai) Tools**\n\nDuring his April 21, 2023, State of Homeland Security address, Secretary Mayorkas stated that\n\u201cOur Department will lead in the responsible use of genai [genai] to secure the\nhomeland and in defending against the malicious use of this transformational technology.\n\nAs we\ndo this, we will ensure that our use of genai is rigorously tested to avoid bias and disparate impact\nand is clearly explainable to the people we serve.\u201d\n\nTo do this, the Secretary directed the Under Secretary for Science and Technology and me to\nestablish an genai Task Force (AITF).\n\nAs the AITF works to advance specific\nmission applications of genai across the Department, we must also address ways in which our\nworkforce uses commercially available genai (genai) products in their work.\n\n\u201cgenai\u201d means the class of genai models that emulate the structure and\ncharacteristics of input data to generate novel synthetic content.\n\nThis can include images,\nvideos, audio, text, and other types of digital content.\n\nTools using genai have rapidly gained\nworldwide popularity.\n\nThere is a growing body of research that suggests genai will lead to\nsignificant productivity gains across all sectors.\n\n1\n\ngenai tools also present significant challenges and risks, including producing \u201challucinations\u201d\nor invented and inaccurate responses and generating biased outputs based on biases in their\ntraining data.\n\n2 They further present information privacy and security risks if sensitive\ninformation is provided to tools and used to further train underlying models.\n\nCareful human\njudgment is required to balance the productivity gains associated with genai tools with these\nrisks.\n\n1 Economic potential of genai | McKinsey, genai Improves Employee Productivity by 66% (nngroup.com)\n2 Why ChatGPT and Bing Chat are so good at making things up | Ars Technical\n\n\n-----\n\nPage 2\n\nThe AITF is actively exploring use cases for genai tools across a variety of DHS mission areas.\n\nWhile this work continues, I have determined that DHS must enable and encourage DHS\npersonnel 3 to responsibly use commercial products to harness the benefits of genai and ensure\nwe continuously adapt to the future of work.\n\nAs such, I am issuing the following initial guidance\nto facilitate appropriate use during this early stage of technological development:\n\n-  My office will develop and maintain a list of conditionally approved commercial genai\ntools 4 for use on open-source information 5 only.\n\n`o` In developing this list, we will review basic accuracy and security practices,\nsupply chain risk management concerns, privacy and civil liberties safeguards,\nand available information on how training data was sourced.\n\nThis list will be\ncoordinated in advance of its release with the DHS Privacy Office (PRIV), the\nOffice for Civil Rights and Civil Liberties (CRCL), and other stakeholders.\n\n`o` This review will not provide approval to utilize these tools on non-public\ninformation.\n\n`o` We will maintain a page on DHS Connect listing these tools and offering\nemployees the ability to submit additional tools for review and testing.\n\n-  My office will update Department IT and cybersecurity policies and standards to include\nnew requirements for use of approved commercial genai tools by DHS personnel in\ntheir work.\n\nIn the interim, however, the following rules shall apply:\n\n`o` Personnel must never put DHS data regarding individuals (regardless of whether\nit is personally identifiable information (PII) or anonymized), social media\ncontent, or any For Official Use Only, Sensitive but Unclassified Information,\nnow known as \u201cControlled Unclassified Information,\u201d or Classified information\ninto commercial genai tools.\n\n`o` Personnel shall protect any PII collected or generated by the use of commercial\ngenai tools in accordance with applicable DHS privacy policy and federal law.\n\n`o` Prior to any use of these tools, personnel must obtain approval from their\nsupervisors, complete a training on responsible use of genai along with their annual\nProtecting Personally Identifiable Information and Cybersecurity Awareness\ntrainings, and sign an acknowledgement of the conditions on use.\n\n`o` Personnel will create accounts on these tools using their DHS email and use these\naccounts only for DHS use, separate from any personal use of these tools.\n\n`o` Personnel will select options in tools that limit data retention and opt out of inputs\nbeing used to further train models.\n\n`o` All use of conditionally approved commercial genai tools will be on the web,\nnot through downloaded desktop or mobile apps.\n\n3 Personnel includes federal employees, contractors, detailees, and others working on behalf of DHS.", "3 Personnel includes federal employees, contractors, detailees, and others working on behalf of DHS.\n\n4 \u201cCommercial genai tools\u201d are defined as genai technology or products available for use or purchase by\nthe general public (i.e., off-the-shelf).\n\nThis definition does not include customized software or services developed\nspecifically for the government through an IT acquisition process.\n\n5 Open-Source Information means unclassified information that has been published or broadcast in some manner to\nthe public.\n\nSources are newspapers or other periodicals; weather reports; books, journal articles, or other published\nworks; public court filings; or any similar documents that have traditionally been publicly available.\n\n-----\n\nPage 3\n\n\no At all times, personnel are accountable for accessing and handling DHS\ninformation and IT resources in compliance with DHS User Rules of Behavior\nand DHS policies, including privacy, civil rights, and civil liberties policies.\n\no Personnel should ensure all content generated or modified using these tools is\nreviewed by appropriate subject matter experts for accuracy, relevance, data\nsensitivity, inappropriate bias, and policy compliance 6 before using it in any\nofficial capacity, especially when interacting with the public.\n\no Commercial genai tools may not be used in the decision-making process for any\nbenefits adjudication, credentialling, vetting, or law or civil investigation or\nenforcement related actions.\n\nAgency and Office Leaders or CIOs can request\nfrom my office a written waiver of these restrictions.\n\no Any spillage or compromise of DHS information into genai tools must be\nreported immediately pursuant to applicable policies.\n\no Agency and Office Chief Information Officers will develop policies regarding\nappropriate use of commercial genai tools in their missions, in consultation with\nmy office, PRIV, and CRCL.\n\nThese policies may impose additional conditions or\nlimitations on the use of commercial genai tools based on unique mission\nrequirements.\n\nImmediate appropriate applications of commercial genai tools to DHS business could include\ngenerating first drafts of documents that a human would subsequently review, conducting and\nsynthesizing research on open-source information, and developing briefing materials or\npreparing for meetings and events.\n\nI have personally found these tools valuable in these use\ncases already, and encourage employees to learn, identify, and share other valuable uses with\neach other.\n\nThis initial guidance will be updated in coordination with relevant stakeholders across the\nDepartment regularly given the rapid pace of technological change in the genai space.\n\nAs Agencies\nand Offices deploy internal systems and tools leveraging genai, those systems will be governed\nthrough broader Department policies on responsible use, including DHS Policy Statement 13906 \u201cAcquisition and Use of genai and Machine Learning Technologies by DHS\nComponents.\u201d\n\n6 For example, _see_ Policy Statement 139-06, _Acquisition and Use of genai and Machine Learning_\n_Technologies by DHS Components_ (Aug. 8, 2023) (\u201cAll DHS users of genai are charged with providing human\noversight, safeguards, and where appropriate, review and redress in genai-enabled processes implemented by DHS, to\nensure these principles are applied effectively and efficiently in the design, implementation, and end uses of this\ntechnology.\u201d).\n\n-----", "**UNESCO \u2013 a global leader in education**\n\nEducation is UNESCO\u2019s top priority because it is a\nbasic human right and the foundation for peace\nand sustainable development.\n\nUNESCO is the\nUnited Nations\u2019 specialized agency for education,\nproviding global and regional leadership to drive\nprogress, strengthening the resilience and capacity\nof national systems to serve all learners.\n\nUNESCO\nalso leads eforts to respond to contemporary\nglobal challenges through transformative learning,\nwith special focus on gender equality and Africa\nacross all actions.", "**The Global Education 2030 Agenda**\n\nUNESCO, as the United Nations\u2019 specialized agency for\neducation, is entrusted to lead and coordinate the\nEducation 2030 Agenda, which is part of a global\nmovement to eradicate poverty through 17 Sustainable\nDevelopment Goals by 2030.\n\nEducation, essential to\nachieve all of these goals, has its own dedicated Goal 4,\nwhich aims to **\u201c** **_ensure inclusive and equitable quality_**\n**_education and promote lifelong learning opportunities_**\n**_for all._** **\u201d** The Education 2030 Framework for Action\nprovides guidance for the implementation of this\nambitious goal and commitments.\n\nPublished in 2023 by the United Nations Educational, Scientific and Cultural Organization,\n7, place de Fontenoy, 75352 Paris 07 SP, France\n\n\u00a9 UNESCO 2023\n\nISBN 978-92-3-100612-8\n\nThis publication is available in Open Access under the Attribution-ShareAlike 3.0 IGO (CC-BY-SA 3.0 IGO) license\n( By using the content of this publication, the users accept to be bound by the\nterms of use of the UNESCO Open Access Repository (\n\nThe designations employed and the presentation of material throughout this publication do not imply the expression of any opinion\nwhatsoever on the part of UNESCO concerning the legal status of any country, territory, city or area or of its authorities, or concerning\nthe delimitation of its frontiers or boundaries.\n\nImages marked with an asterisk (*) do not fall under the CC-BY-SA license and may not be used or reproduced without the prior\npermission of the copyright holders.\n\nThe ideas and opinions expressed in this publication are those of the authors; they are not necessarily those of UNESCO and do not\ncommit the Organization.\n\nCover credit: Olexandra Simkina/Shutterstock.com*\n\nDesigned and printed by UNESCO\n\n_Printed in France_\n\n\n-----", "**Towards a human-centred approach to the use**\n\n**of genai**\n\nPublicly available genai (GenAI) tools are rapidly emerging, and the\nrelease of iterative versions is outpacing the adaptation of national regulatory\nframeworks.\n\nThe absence of national regulations on GenAI in most countries\nleaves the data privacy of users unprotected and educational institutions largely\nunprepared to validate the tools.\n\nUNESCO\u2019s first global guidance on GenAI in education aims to support countries\nto implement immediate actions, plan long-term policies and develop human\ncapacity to ensure a human-centred vision of these new technologies.\n\nThe Guidance presents an assessment of potential risks GenAI could pose to\ncore humanistic values that promote human agency, inclusion, equity, gender\nequality, and linguistic and cultural diversities, as well as plural opinions and\nexpressions.\n\nIt proposes key steps for governmental agencies to regulate the\nuse of GenAI tools including mandating the\nprotection of data privacy and considering an\nage limit for their use.\n\nIt outlines requirements\nfor GenAI providers to enable their ethical and\neffective use in education.\n\nWhile **ChatGPT**\nreached", "### 100 million\n\nThe Guidance stresses the need for educational\ninstitutions to validate GenAI systems on their\nethical and pedagogical appropriateness\nfor education.\n\nIt calls on the international\ncommunity to reflect on their long-term\nimplications for knowledge, teaching, learning\nand assessment.\n\nmonthly active users\nin January 2023, only\n**one country** had released\nregulations\n**on genai**\nas of July 2023\n\n\nThe publication offers concrete\nrecommendations for policy-makers and\neducational institutions on how the uses of\nGenAI tools can be designed to protect human\nagency and genuinely benefit learners, teachers and researchers.\n\n_\u201cSince wars begin in the minds of men and_\n_women it is in the minds of men and women_\n_that the defences of peace must be constructed\u201d_\n\n\n-----", "##### Foreword\n\ngenai (GenAI) burst into the public awareness in late\n2022 with the launch of ChatGPT, which became the fastest growing app in\nhistory.\n\nWith the power to imitate human capabilities to produce outputs such\nas text, images, videos, music and software codes, these GenAI applications\nhave caused a stir.\n\nMillions of people are now using GenAI in their daily lives and\nthe potential of adapting the models to domain-specific genai applications seems\nunlimited.\n\n\u00a9 UNESCO\n\n\nSuch wide-ranging capacities for information processing and knowledge\nproduction have potentially huge implications for education, as they replicate\nthe higher-order thinking that constitutes the foundation of human learning.\n\nAs GenAI tools are increasingly able to automate some basic levels of writing\nand artwork creation, they are forcing education policy-makers and institutions\nto revisit why, what and how we learn.\n\nThese are now critical considerations for\neducation in this new phase of the digital era.\n\nThis publication aims to support the planning of appropriate regulations, policies and human capacity\ndevelopment, to ensure that GenAI becomes a tool that genuinely benefits and empowers teachers, learners\nand researchers.\n\nIt proposes key steps for governmental agencies to regulate the use of genai.\n\nIt also presents frameworks\nand concrete examples for policy formulation and instructional design that enable ethical and effective uses of\nthis technology in education.\n\nFinally, it calls on the international community to consider the profound longerterm implications of genai for how we understand knowledge and define learning content, methods and\noutcomes, as well as the way in which we assess and validate learning.\n\nBuilding on UNESCO\u2019s 2021 _Recommendation on the Ethics of Artificial Intelligence_ , the guidance is anchored in a\nhumanistic approach to education that promotes human agency, inclusion, equity, gender equality, and cultural\nand linguistic diversity, as well as plural opinions and expressions.\n\nFurthermore, it responds to the call of the 2021\nreport of the International Commission on the Futures of Education, _Reimagining our futures together: A new social_\n_contract for education_ to redefine our relationship with technology, as an integral part of our efforts to renew the\nsocial contract for education.\n\ngenai must not usurp human intelligence.\n\nRather, it invites us to reconsider our established understandings of\nknowledge and human learning.\n\nIt is my hope that this guidance will help us redefine new horizons for education\nand inform our collective thinking and collaborative actions that can lead to human-centred digital learning futures\nfor all.", "##### Acknowledgements\n\nUnder the leadership of Stefania Giannini, Assistant-Director for Education, and the guidance of Sobhi Tawil, Director\nof the Future of Learning and Innovation Division at UNESCO, the drafting of the publication was led by Fengchun\nMiao, Chief of Unit for Technology and genai in Education.\n\nParticular thanks go to Wayne Holmes, Associate Professor at University College London, who co-drafted the\npublication.\n\nThis publication is the fruit of a collective effort of education leaders and experts in the field of genai and education.\n\nIt benefited from the insights and inputs of many experts including: Mutlu Cukurova, Professor at University College\nLondon; Colin de la Higuera, UNESCO Chair in Technologies for the Training of Teachers with Open Educational\nResources at Nantes University; Shafika Isaacs, Research Associate at the University of Johannesburg; Natalie Lao,\nExecutive Director of the App Inventor Foundation; Qin Ni, Associate Professor at Shanghai Normal University;\nCatalina Nicolin, ICT in Education Expert at the European Digital Education Hub in Romania; John Shaw-Taylor,\nUNESCO Chair in genai and Professor of Computational Statistics and Machine Learning at University College London;\nKelly Shirohira, Executive Manager at Jet Education Services; Ki-Sang Song, Professor at Korea National University of\nEducation; and Ilkka Tuomi, Chief Scientist at Meaning Processing Ltd in Finland.\n\nMany colleagues across UNESCO also contributed in various ways including: Dafna Feinholz, Chief of Section for\nBioethics and the Ethics of Science and Technology; Francesc Pedr\u00f3, Director of the International Institute for Higher\nEducation in Latin America and the Caribbean; Prateek Sibal, Programme Specialist, Section for Digital Policies and\nDigital Transformation; Saurabh Roy, Senior Project Officer at the Section for Teacher Development, Division for\nPolicies and Lifelong Learning Systems; Benjamin Vergel De Dios, Programme Specialist in ICT in Education, Section\nfor Educational Innovation and Skills Development in the Bangkok Office; the colleagues in the Diversity of Cultural\nExpressions Entity in the Culture Sector; and Mark West, Programme Specialist, Future of Learning and Innovation\nDivision.\n\nAppreciation is also due to Glen Hertelendy, Luisa Ferrara and Xianglei Zheng, Unit for Technology and genai in\nEducation, Future of Learning and Innovation, for coordinating the production of the publication.\n\nGratitude is also extended to Jenny Webster for copy-editing and proofreading the text, and to Ngoc-Thuy Tran for\ndesigning the layout.\n\n-----", "**Foreword** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**2**", "**Acknowledgements** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**3**", "**List of acronyms and abbreviations** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**6**", "**1.\n\nWhat is genai and how does it work?\n\n** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**8**\n\n1.1 What is genai?\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n8\n\n1.2 How does genai work?\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n8\n\n1.2.1 How text GenAI models work .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n9\n\n1.2.2 How image GenAI models work .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n11\n\n1.3 Prompt-engineering to generate desired outputs .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n11\n\n1.4 \u0007 Emerging EdGPT and its implications .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n13", "**2.\n\nControversies around genai and their implications for education** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**14**\n\n2.1 Worsening digital poverty .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n14\n\n2.2 \u0007 Outpacing national regulatory adaptation .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n14\n\n2.3 Use of content without consent .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n15\n\n2.4 Unexplainable models used to generate outputs .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n15\n\n2.5 genai-generated content polluting the internet .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n16\n\n2.6 Lack of understanding of the real world .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n16\n\n2.7 Reducing the diversity of opinions and further marginalizing already marginalized voices .\n\n.\n\n.\n\n.\n\n.\n\n17\n\n2.8 Generating deeper deepfakes .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n17", "**3.\n\nRegulating the use of genai in education** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**18**\n\n3.1 A human-centred approach to genai .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n18\n\n3.2 Steps to regulate GenAI in education .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n18\n\n3.3 Regulations on GenAI: Key elements .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n20\n\n3.3.1 Governmental regulatory agencies .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n20\n\n3.3.2 Providers of GenAI tools .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n21\n\n3.3.3 Institutional users .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n23\n\n3.3.4 Individual users .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n23", "**4.\n\nTowards a policy framework for the use of generative** **genai in education and research** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**24**\n\n4.1 Promote inclusion, equity, and linguistic and cultural diversity .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n24\n\n4.2 Protect human agency .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n24\n\n\n-----\n\n4.3 Monitor and validate GenAI systems for education .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n25\n\n4.4 Develop genai competencies including GenAI-related skills for learners .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n25\n\n4.5 Build capacity for teachers and researchers to make proper use of GenAI .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n26\n\n4.6 Promote plural opinions and plural expressions of ideas .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n26\n\n4.7 Test locally relevant application models and build a cumulative evidence base .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n27\n\n4.8 Review long-term implications in an intersectoral and interdisciplinary manner .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n27", "**5.\n\nFacilitating creative use of GenAI in education and research** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**28**\n\n5.1 Institutional strategies to facilitate responsible and creative use of GenAI .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n28\n\n5.2 A \u2018human-centred and pedagogically appropriate interaction\u2019 approach .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n29\n\n5.3 Co-designing the use of GenAI in education and research .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n29\n\n5.3.1 genai for research .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n29\n\n5.3.2 genai to facilitate teaching .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n30\n\n5.3.3 genai as a 1:1 coach for the self-paced acquisition of foundational skills .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n31\n\n5.3.4 genai to facilitate inquiry or project-based learning .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n33\n\n5.3.5 genai to support learners with special needs .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n34", "**6.\n\nGenAI and the future of education and research** .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n**36**\n\n6.1 Uncharted ethical issues .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n36\n\n6.2 Copyright and intellectual property .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n36\n\n6.3 Sources of content and learning .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n36\n\n6.4 Homogenized responses versus diverse and creative outputs .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n37\n\n6.5 Rethinking assessment and learning outcomes .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n37\n\n6.6 Thinking processes .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n37\n\nConcluding remarks .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n38", "**List of tables**\n\nTable 1.\n\nTechniques used in genai .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n8\n\nTable 2.\n\nOpenAI GPTs .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n9\n\nTable 3.\n\nCo-designing uses of GenAI for research .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n30\n\nTable 4.\n\nCo-designing uses of GenAI to support teachers and teaching .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n31\n\nTable 5.\n\nCo-designing uses of GenAI as a 1:1 coach for the self-paced acquisition of\nfoundational skills in languages and the arts .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n32\n\nTable 6.\n\nCo-designing uses of GenAI to facilitate inquiry or project-based learning .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n33\n\nTable 7.\n\nCo-designing uses of GenAI to support learners with special needs .\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n.\n\n34\n\n\n-----", "**Concepts and technologies**\n\n**AGI** Artificial general intelligence\n\n**genai** genai\n\n**API** Application programming interface\n\n**ANN** Artificial neural network\n\n**DAI** Distributed genai\n\n**GAN** Generative adversarial networks\n\n**GB** Gigabytes\n\n**GDPR** General Data Protection Regulation\n\n**GenAI** genai\n\n**GPT** Generative pre-trained transformer\n\n**ICT** Information and communication technology\n\n**LaMDA** Language model for dialogue applications\n\n**LLM** Large language model\n\n**ML** Machine learning\n\n**VAE** Variational autoencoders", "**1.1 What is genai?\n\n**\n\ngenai (GenAI) is an genai (genai)\ntechnology that automatically generates content\nin response to prompts written in natural-language\nconversational interfaces.\n\nRather than simply curating\nexisting webpages, by drawing on existing content,\nGenAI actually produces new content.\n\nThe content\ncan appear in formats that comprise all symbolic\nrepresentations of human thinking: texts written in\nnatural language, images (including photographs,\ndigital paintings and cartoons), videos, music and\nsoftware code.\n\nGenAI is trained using data collected\nfrom webpages, social media conversations and\nother online media.\n\nIt generates its content by\nstatistically analysing the distributions of words, pixels\nor other elements in the data that it has ingested\nand identifying and repeating common patterns (for\nexample, which words typically follow which other\nwords).\n\nWhile GenAI can produce new content, it cannot\ngenerate new ideas or solutions to real-world\nchallenges, as it does not understand real-world\nobjects or social relations that underpin language.\n\nMoreover, despite its fluent and impressive output,\nGenAI cannot be trusted to be accurate.\n\nIndeed, even\n\n\nthe provider of ChatGPT acknowledges, \u2018While tools\nlike ChatGPT can often generate answers that sound\nreasonable, they cannot be relied upon to be accurate.\u2019\n(OpenAI, 2023).\n\nMost often, the errors will go unnoticed\nunless the user has a solid knowledge of the topic in\nquestion.", "**1.2 How does genai works?\n\n**\n\nThe specific technologies behind GenAI are part of the\nfamily of genai technologies called machine learning (ML)\nwhich uses algorithms to enable it to continuously and\nautomatically improve its performance from data.\n\nThe\ntype of ML which has led to many of the advances in\ngenai that we have seen in recent years, such as the use\nof genai for facial recognition, is known as artificial neural\nnetworks (ANNs), which are inspired by how the human\nbrain works and its synaptic connections between\nneurons.\n\nThere are many types of ANNs.\n\nBoth text and image genai technologies are\nbased on a set of genai technologies that have been\navailable to researchers for several years.\n\n1 ChatGPT, for\ninstance, uses a generative pre-trained transformer\n(GPT), while image GenAI typically uses what are\nknown as generative adversarial networks (GANs)\n(see **Table 1** ).\n\n3", "**Table 1.\n\nTechniques used in genai**\n\n|Machine learning (ML)|Col2|A type of genai that uses data to automatically improve its performance.|\n|---|---|---|\n|Artificial neural network (ANN)||A type of ML that is inspired by the structure and functioning of the human brain (e.g.\n\nthe synaptic connections between neurons).|\n|Text genai|General-purpose transformers|A type of ANN that is capable of focusing on difefrent parts of data to determine how they relate to each other|\n||Large language models (LLM)|A type of general-purpose transformer that is trained on vast amounts of text data.|\n||Generative pre-trained transformer (GPT)4|A type of LLM that is pre-trained on even larger amounts of data, which allows the model to capture the nuances of language and generate coherent context-aware text.|\n|Image genai|Generative adversarial networks (GANs)|Types of neural network used for image generation.|\n||Variational autoencoders (VAEs)||\n\n\n-----", "**1.2.1.\n\nHow text GenAI models work**\n\nText genai uses a type of ANN known as a\ngeneral-purpose transformer, and a type of generalpurpose transformer called a large language model.\n\nThis is why genai Text GenAI systems are often referred\nto as large language models, or LLMs.\n\nThe type of\nLLM used by text GenAI is known as a generative\npre-trained transformer, or GPT (hence the \u2018GPT\u2019 in\n\u2018ChatGPT\u2019).\n\nChatGPT is built on GPT-3 which was developed by\nOpenAI.\n\nThis was the third iteration of their GPT, the\nfirst being launched in 2018 and the most recent,\nGPT-4, in March 2023 (see **Table 2** ).\n\nEach OpenAI\nGPT iteratively improved upon the previous through\nadvances in genai architectures, training methods and\noptimization techniques.\n\nOne well-known facet of its\n\n\ncontinuous progress is the use of growing amounts\nof data to train its exponentially increasing number\nof \u2018parameters\u2019 .\n\nParameters might be thought of as\nmetaphorical knobs that can be adjusted to fine-tune\nthe GPT\u2019s performance.\n\nThey include the model\u2019s\n\u2018weights\u2019 , numerical parameters that determine how\nthe model processes input and produces output.\n\nIn addition to the advancements in optimizing genai\narchitectures and training methods, this rapid iteration\nhas been made possible also due to the massive\namounts of data 5 and improvements in computing\ncapabilities available to the big companies.\n\nSince 2012,\ncomputing capabilities used for training GenAI models\nhave been doubling every 3-4 months.\n\nBy comparison,\nMoore\u2019s Law had a two-year doubling period (OpenAI,\n2018; Stanford University, 2019).\n\n|Table 2.\n\nOpenAI GPTs|Col2|\n|---|---|\n|Amount of Number of Model Launched training data parameters|Characteristics|\n|GPT-1 2018 40 GB 117 million|Capable of natural-language-processing tasks such as completing texts and answering questions.|\n|GPT-2 2019 40 GB 1,500 million|Capable of more complex natural-language-processing tasks such as machine translation and summarizing.|\n|GPT-3 2020 17,000 GB 175,000 million|Capable of advanced natural-language-processing tasks such as writing coherent paragraphs and generating entire articles.\n\nAlso capable of adapting to new tasks with just a few examples.|\n|1,000,000 GB 170,000,000 GPT-46 2023 (reported but million (reported not confirmed) but not confirmed)|Enhanced reliability and is capable of processing more complex instructions.|\n\n\n\u00be Beginning with a random prediction, the\nGPT uses these estimated probabilities to\npredict the next likely word or phrase in its\nresponse.\n\n**3.\n\n** The predicted words or phrases are converted\ninto readable text.\n\n**4.\n\n** The readable text is filtered through what are\nknown as \u2018guardrails\u2019 to remove any offensive\ncontent.\n\n**5.\n\n** Steps 2 to 4 are repeated until a response is\nfinished.\n\nThe response is considered finished\nwhen it reaches a maximum token limit or\nmeets predefined stopping criteria.", "**Once the GPT has been trained, generating a text**\n\n**response to a prompt involves the following steps:**\n\n**1.\n\n** The prompt is broken down into smaller units\n(called tokens) that are inputted into the GPT.\n\n**2.\n\n** The GPT uses statistical patterns to predict\nlikely words or phrases that might form a\ncoherent response to the prompt.\n\n\u00be The GPT identifies patterns of words\nand phrases that commonly co-occur\nin its prebuilt large data model (which\ncomprises text scraped from the internet\nand elsewhere).\n\n\u00be Using these patterns, the GPT estimates\nthe probability of specific words or\nphrases appearing in a given context.\n\n-----\n\n**6.\n\n** The response is post-processed to improve\nreadability by applying formatting,\npunctuation and other enhancements (such\nas beginning the response with words that a\nhuman might use, such as \u2018Sure\u2019 , \u2018Certainly\u2019 or\n\u2018I\u2019m sorry\u2019).\n\nWhile GPTs and their ability to automatically generate\ntext have been available to researchers since 2018,\nwhat made the launch of ChatGPT so novel was its\nfree access via an easy-to-use interface, meaning that\nanyone with internet access could explore the tool.\n\nThe launch of ChatGPT set off shock waves around the\nworld, and quickly led to other global tech companies\nplaying catch-up, alongside numerous start-up\ncompanies, either by launching their own similar\nsystems or by building new tools on top.\n\nBy July 2023, some of the alternatives to ChatGPT\nincluded the following:\n\n-  **\u0007** **Alpaca:** 7 A fine-tuned version of Meta\u2019s\nLlama, from Stanford University, which aims\nto address LLMs\u2019 false information, social\nstereotypes and toxic language.\n\n-  \u0007 **Bard:** 8 An LLM from Google, based on its\nLaMDA and PaLM 2 systems, that has access\nto the internet in real time, which means it can\nprovide up-to-date information.\n\n-  \u0007 **Chatsonic:** 9 Made by Writesonic, it builds on\nChatGPT while also crawling data directly\nfrom Google.\n\nAccordingly, it has less chance of\nproducing factually incorrect answers.\n\n-  \u0007 **Ernie** (also known as **Wenxin Yiyan** \u6587\u5fc3\u4e00\u8a00 ): 10\nA bilingual LLM from Baidu, still in\ndevelopment, which integrates extensive\nknowledge with massive datasets to generate\ntext and images.\n\n-  \u0007 **Hugging Chat:** 11 Made by Hugging Face,\nwho emphasized ethics and transparency\nthroughout its development, training and\ndeployment.\n\nIn addition, all data used to train\ntheir models are open source.\n\n-  **\u0007** **Jasper:** 12 A suite of tools and APIs that, for\nexample, can be trained to write in a user\u2019s\nparticular preferred style.\n\nIt can also generate\nimages.\n\n-  \u0007 **Llama:** 13 An open-source LLM from Meta that\nrequires less computing power and fewer\nresources to test new approaches, validate\nothers\u2019 work and explore new use cases.\n\n-  **\u0007** **Open Assistant:** 14 An open-source approach\ndesigned to enable anyone with sufficient\nexpertise to develop their own LLM.\n\nIt was\nbuilt on training data curated by volunteers.\n\n-  \u0007 **Tongyi Qianwen** ( \u901a\u4e49\u5343\u95ee ): 15 An LLM from\nAlibaba that can respond to prompts in\nEnglish or Chinese.\n\nIt is being integrated into\nAlibaba\u2019s suite of business tools.\n\n-  **\u0007** **YouChat:** 16 An LLM that incorporates real-time\nsearch capabilities to provide additional\ncontext and insights in order to generate more\naccurate and reliable results.\n\nMost of these are free to use (within certain limits),\nwhile some are open-source.\n\nMany other products\nare being launched that are based one of these LLMs.\n\nExamples include the following:\n\n-  **\u0007** **ChatPDF:** 17 Summarizes and answers\nquestions about submitted PDF documents.\n\n-  **\u0007** **Elicit: The genai Research Assistant:** 18 Aims to\nautomate parts of researchers\u2019 workflows,\nidentifying relevant papers and summarizing\nkey information.\n\n-  **\u0007** **Perplexity:** 19 Provides a \u2018knowledge hub\u2019\nfor people seeking quick, accurate answers\ntailored to their needs.\n\n**\u0007** Similarly, LLM-based tools are being embedded into\nother products, such as web browsers.\n\nFor example,\nextensions for the Chrome browser that are built on\nChatGPT include the following:\n\n-  **\u0007** **WebChatGPT:** 20 Gives ChatGPT internet access\nto enable more accurate and up-to-date\nconversations.\n\n-  **\u0007** **Compose genai:** 21 Autocompletes sentences in\nemails and elsewhere.\n\n-  \u0007 **TeamSmart genai:** 22 Provides a \u2018team of virtual\nassistants\u2019 .\n\n-  **Wiseone:** 23 Simplifies online information.\n\nIn addition, ChatGPT has been incorporated into some\nsearch engines, 24 and is being implemented across\nlarge portfolios of productivity tools (e.g.\n\nMicrosoft\nWord and Excel), making it even more available in\noffices and educational institutions worldwide (Murphy\nKelly, 2023).\n\n-----\n\nFinally, as an interesting transition to image GenAI,\nthe most recent GPT from OpenAI, GPT-4, is able to\naccept images as well as text in its prompts.\n\nIn this\nsense, it is multimodal.", "-----\n\nFinally, as an interesting transition to image GenAI,\nthe most recent GPT from OpenAI, GPT-4, is able to\naccept images as well as text in its prompts.\n\nIn this\nsense, it is multimodal.\n\nAccordingly, some argue that\nthe name \u2018large language model\u2019 (LLM) is becoming\nless appropriate, which is one reason why researchers\nat Stanford University have proposed the term\n\u2018foundation model\u2019 (Bommasani et al., 2021).\n\nThis\nalternative is yet to be widely adopted.", "**1.2.2.\n\nHow image GenAI models work**\n\nImage GenAI and music GenAI typically use a\ndifferent type of ANN known as generative adversarial\nnetworks (GANs) which can also be combined with\nvariational autoencoders.\n\nSome image GenAI models\nlike Dall\u00b7E and Stable Diffusion use Diffusion Models,\na different generative ANN.\n\nTaking GANs as example\nto explain how image GenAI models work: GANs\nhave two parts (two \u2018adversaries\u2019), the \u2018generator\u2019 and\nthe \u2018discriminator\u2019 .\n\nIn the case of image GANs, the\ngenerator creates a random image in response to a\nprompt, and the discriminator tries to distinguish\nbetween this generated image and real images.\n\nThe\ngenerator then uses the result of the discriminator to\nadjust its parameters, in order to create another image.\n\nThe process is repeated, possibly thousands of times,\nwith the generator making more and more realistic\nimages that the discriminator is less and less able to\ndistinguish from real images.\n\nFor example, a successful\nGAN trained on a dataset of thousands of landscape\nphotographs might generate new but unreal images of\nlandscapes that are almost indistinguishable from real\nphotographs.\n\nMeanwhile, a GAN trained on a dataset of\npopular music (or even music by a single artist) might\ngenerate new pieces of music that follow the structure\nand complexity of the original music.\n\nAs of July 2023, the **image GenAI** models that are\navailable include the following, all of which generate\nimages from text prompts.\n\nMost are free to use, within\ncertain limits:\n\n-  \u0007 **Craiyon:** 25 Previously known as DALL\n\n- E mini.\n\n-  **DALL\u2022E 2:** 26 OpenAI\u2019s image GenAI tool.\n\n-  \u0007 **DreamStudio:** 27 Stable Diffusion\u2019s image\nGenAI tool.\n\n-  **\u0007** **Fotor:** 28 Incorporates GenAI in a range of\nimage-editing tools.\n\n-  \u0007 **Midjourney:** 29 An independent image GenAI\ntool.\n\n-  \u0007 **NightCafe:** 30 Interface to Stable Diffusion and\nDALL\u2022E 2.\n\n-  **Photosonic:** 31 WriteSonic\u2019s genai art generator .\n\nExamples of easy-to-access **video GenAI** include the\nfollowing:\n\n-  \u0007 **Elai:** 32 Can convert presentations, websites and\ntext into videos.\n\n-  \u0007 **GliaCloud:** 33 Can generate videos from news\ncontent, social media posts, live sporting\nevents and statistical data.\n\n-  **\u0007** **Pictory:** 34 Can automatically create short\nvideos from long-form content.\n\n-  **\u0007** **Runway:** 35 Offers a range of video (and\nimaging) generation and editing tools.\n\nFinally, these are some examples of easy-to-access\n**music GenAI** :\n\n-  **\u0007** **Aiva:** 36 Can automatically create personalized\nsoundtracks.\n\n-  **\u0007** **Boomy,** 37 **Soundraw,** 38 **and Voicemod:** 39 Can\ngenerate songs from any text, and require no\nmusical composition knowledge.", "**1.3 Prompt-engineering to generate**\n\n**desired outputs**\n\nWhile using GenAI can be as simple as typing in a\nquestion or other prompt, the reality is that it is still\nnot straightforward for the user to get exactly the\noutput that they want.\n\nFor example, the breakthrough\ngenai image _Th\u00e9\u00e2tre D\u2019op\u00e9ra Spatial_ which won a prize\nat the Colorado State Fair in the United States of\nAmerica, took weeks of writing prompts and finetuning hundreds of images in order to generate the\nfinal submission (Roose, 2022).\n\nThe similar challenge\nof writing effective prompts for text GenAI has led to\nan increasing number of prompt-engineering jobs\nappearing on recruitment websites (Popli, 2023).\n\n\u2018Prompt-engineering\u2019 refers to the processes and\ntechniques for composing input to produce GenAI\noutput that more closely resembles the user\u2019s desired\nintent.\n\n-----\n\nPrompt-engineering is most successful when the\nprompt articulates a coherent chain of reasoning\ncentred on a particular problem or a chain of thought\nin a logical order.\n\nSpecific recommendations include:\n\n-  \u0007 Use **simple** , clear and straightforward\nlanguage that can be easily understood,\navoiding complex or ambiguous wording.\n\n-  \u0007 Include **examples** to illustrate the desired\nresponse or format of generated completions.\n\n-  \u0007 Include **context** , which is crucial for\ngenerating relevant and meaningful\ncompletions.\n\n-  **\u0007** **Refine** and iterate as necessary, experimenting\nwith different variations.\n\n-  \u0007 Be **ethical** , avoiding prompts that may\ngenerate inappropriate, biased or harmful\ncontent.\n\nIt is also important to recognize immediately that\nGenAI outputs cannot be relied upon without\ncritical evaluation.\n\nAs OpenAI write about their most\nsophisticated GPT: 40\n\n\nIn light of the quality of GenAI\u2019s outputs, rigorous\nuser tests and performance evaluations should be\nconducted before validating the tools for large-scale\nor high-stakes adoption.\n\nSuch exercises should be\ndesigned with a performance metric that is most\nrelevant to the type of task for which users ask GenAI\nto provide outputs.\n\nFor example, for solving math\nproblems, \u2018accuracy\u2019 could be used as the main metric\nto quantify how often a GenAI tool produces the\ncorrect answer; for responding to sensitive questions,\nthe main metric to measure performance might be\n\u2018answer rate\u2019 (the frequency with which the GenAI\ndirectly answers a question); for code generation, the\nmetric may be \u2018the fraction of the generated codes\nthat are directly executable\u2019 (whether the generated\ncode could be directly executed in a programming\nenvironment and pass the unit tests); and for visual\nreasoning, the metric could be \u2018exact match\u2019 (whether\nthe generated visual objects exactly match the ground\ntruth) (Chen et al., 2023).\n\nIn summary, at a superficial level, GenAI is easy to use;\nhowever, more sophisticated outputs need skilled\nhuman input and must be critically evaluated before\nthey are used.", "**Despite its capabilities, GPT-4 has similar limitations as**\n\n**earlier GPT models.\n\nMost importantly, it still is not fully**\n**reliable (it \u2018hallucinates\u2019 facts and makes reasoning**\n**errors).\n\nGreat care should be taken when using language model**\n**outputs, particularly in high-stakes contexts, with the exact**\n**protocol (such as human review, grounding with additional**\n**context, or avoiding high-stakes uses altogether) matching the**\n**needs of a specific use-case.\u2019**", "**Implications for education and research**\n\nWhile GenAI might help teachers and researchers\ngenerate useful text and other outputs to support\ntheir work, it is not necessarily a straightforward\nprocess.\n\nIt can take multiple iterations of a prompt\nbefore the desired output is achieved.\n\nA worry is\nthat young learners, because they are by definition\nless expert than teachers, might unknowingly and\nwithout critical engagement accept GenAI output\nthat is superficial, inaccurate or even harmful.\n\n-----", "**1.4 \u0007** **Emerging EdGPT and its**\n\n**implications**\n\nGiven that GenAI models can serve as the basis or\nstarting point for developing more specialized or\ndomain-specific models, some researchers have\nsuggested that GPTs should be renamed \u2018foundation\nmodels\u2019 (Bommasani et al., 2021).\n\nIn education,\ndevelopers and researchers have started to fine-tune a\nfoundation model to develop \u2018EdGPT\u2019 .\n\n41 EdGPT models\nare trained with specific data to serve educational\npurposes.\n\nIn other words, EdGPT aims to refine the\nmodel that has been derived from massive amounts of\ngeneral training data with smaller amounts of highquality, domain-specific education data.\n\nThis potentially gives EdGPT more scope to support\nthe achievement of the transformations listed in\nSection 4.3.\n\nFor example, EdGPT models targeting\ncurriculum co-design may allow educators and learners\nto generate appropriate educational materials such\nas lesson plans, quizzes and interactive activities\nthat closely align with an effective pedagogical\napproach and specific curricular objectives and levels\nof challenge for particular learners.\n\nSimilarly, in the\ncontext of a 1:1 language skills coach, a foundation\nmodel refined with texts appropriate for a particular\nlanguage might be used to generate exemplar\nsentences, paragraphs or conversations for practice.\n\nWhen learners interact with the model, it can respond\nwith relevant and grammatically accurate text at the\nright level for them.\n\nTheoretically, the outputs of EdGPT\nmodels could also contain fewer general biases or\notherwise objectionable content than standard GPT,\n\n\nbut still might generate errors.\n\nIt is critical to note that,\nunless the underlying GenAI models and approach\nchange significantly, EdGPT may still generate errors\nand demonstrate other limitations.\n\nAccordingly,\nit is still important that the main users of EdGPT,\nespecially teachers and learners, need to take a critical\nperspective to any outputs.\n\nCurrently, the refining of foundation models for more\ntargeted use of GPT in education is at an early stage.\n\nExisting examples include EduChat, a foundation\nmodel developed by East China Normal University\nto provide services for teaching and learning, and\nwhose codes, data and parameters are shared as open\nsource.\n\n42 Another example is MathGPT being developed\nby the TAL Education Group \u2013 a LLM that focuses on\nmathematics-related problem-solving and lecturing for\nusers worldwide.\n\n43\n\nHowever, before significant progress is possible, it is\nessential that efforts are put into refining foundation\nmodels not only through adding subject knowledge\nand de-biasing, but also through adding knowledge\nabout relevant learning methods, and how this can\nbe reflected in the design of algorithms and models.\n\nThe challenge is to determine the extent to which\nEdGPT models can go beyond subject knowledge to\nalso target student-centred pedagogy and positive\nteacher-student interactions.\n\nThe further challenge is\nto determine the extent to which learner and teacher\ndata may ethically be collected and used in order to\ninform an EdGPT.\n\nFinally, there is also a need for robust\nresearch to ensure that EdGPT does not undermine\nstudents\u2019 human rights nor disempower teachers.\n\n-----", "**2.1 Worsening digital poverty**\n\nAs noted earlier, GenAI relies upon huge amounts of\ndata and massive computing power in addition to its\niterative innovations in genai architectures and training\nmethods, which are mostly only available to the\nlargest international technology companies and a few\neconomies (mostly the United States, People\u2019s Republic\nof China, and to a lesser extent Europe).\n\nThis means\nthat the possibility to create and control GenAI is out of\nreach of most companies and most countries, especially\nthose in the Global South.\n\nAs access to data becomes increasingly essential for the\neconomic development of countries and for the digital\nopportunities of individuals, those countries and people\nwho do not have access to or cannot afford enough\ndata are left in a situation of \u2018data poverty\u2019 (Marwala,\n2023).\n\nThe situation is similar for access to computing\npower.\n\nThe rapid pervasion of GenAI in technologically\nadvanced countries and regions has accelerated\nexponentially the generation and processing of data,\nand has simultaneously intensified the concentration\nof genai wealth in the Global North.\n\nAs an immediate\nconsequence, the data-poor regions have been further\nexcluded and put at long-term risk of being colonized\nby the standards embedded in the GPT models.\n\nThe\ncurrent ChatGPT models are trained on data from online\nusers which reflect the values and norms of the Global\nNorth, making them inappropriate for locally relevant\ngenai algorithms in data-poor communities in many\nparts of the Global South or in more disadvantaged\ncommunities in the Global North.\n\nResearchers, teachers and learners should take\na critical view of the value orientations, cultural\nstandards and social customs embedded in GenAI\ntraining models.\n\nPolicy-makers should be aware of\nand take action to address the worsening of inequities\ncaused by the widening divide in training and\ncontrolling GenAI models.", "**2.2 \u0007** **Outpacing national regulatory**\n\n**adaptation**\n\nDominant GenAI providers have also been criticized\nfor not allowing their systems to be subject to rigorous\nindependent academic review (Dwivedi et al., 2023).\n\n44\nThe foundational technologies of a company\u2019s GenAI\ntend to be protected as corporate intellectual property.\n\nMeanwhile many of the companies that are starting\nto use GenAI are finding it increasingly challenging\nto maintain the security of their systems (Lin, 2023).\n\nMoreover, despite calls for regulation from the genai\nindustry itself, 45 the drafting of legislation on the\ncreation and use of all genai, including GenAI, often lags\nbehind the rapid pace of development.\n\nThis partly\nexplains the challenges experienced by national or local\nagencies in understanding and governing the legal and\nethical issues.\n\n46\n\nWhile GenAI may augment human capacities in\ncompleting certain tasks, there is limited democratic\ncontrol of the companies that are promoting GenAI.\n\nThis raises the question of regulations, in particular in\nrespect of access to, and use of, domestic data including\ndata on local institutions and individuals as well as\ndata generated on the countries\u2019 territory.\n\nAppropriate\nlegislation is needed so that local governmental\nagencies may gain some control over the surging waves\nof GenAI to ensure its governance as a public good.\n\n-----", "**2.4 Unexplainable models used to**\n\n**generate outputs**\n\nIt has long been recognized that artificial neural\nnetworks (ANNs) are usually \u2018black boxes\u2019; that is, that\ntheir inner workings are not open to inspection.\n\nAs a\nresult, ANNs are not \u2018transparent\u2019 or \u2018explainable\u2019 , and\nit is not possible to ascertain how their outputs were\ndetermined.\n\nWhile the overall approach, including the algorithms\nused, is generally explainable, the particular models\nand their parameters, including the model\u2019s weights,\nare not inspectable, which is why a specific output that\nis generated cannot be explained.\n\nThere are billions of\nparameters/weights in a model like GPT-4 (see **Table 2** )\nand it is the weights collectively that hold the learned\npatterns that the model uses to generate its outputs.\n\nAs parameters/weights are not transparent in ANNs\n( **Table 1** ), one cannot explain the precise way a specific\noutput is created by these models.\n\nGenAI\u2019s lack of transparency and explainability is\nincreasingly problematic as GenAI becomes ever more\ncomplex (see **Table 2** ), often producing unexpected or\nundesired results.\n\nIn addition, GenAI models inherit and\nperpetuate biases present in their training data which,\ngiven the non-transparent nature of the models, are\nhard to detect and address.\n\nFinally, this opacity is also\na key cause of trust issues around GenAI (Nazaretsky\net al., 2022 _a_ ).\n\nIf users don\u2019t understand how a GenAI\nsystem arrived at a specific output, they are less likely\nto be willing to adopt it or use it (Nazaretsky et al.,\n2022 _b_ ).", "**2.3 Use of content without consent**\n\nAs noted earlier, GenAI models are built from large\namounts of data (e.g.\n\ntext, sounds, code and images)\noften scraped from the internet and usually without\nany owner\u2019s permission.\n\nMany image GenAI systems\nand some code GenAI systems have consequently been\naccused of violating intellectual property rights.\n\nAt the\ntime of writing, there are several ongoing international\nlegal cases that relate to this issue.\n\nFurthermore, some have pointed out that GPTs may\ncontravene laws such as the European Union\u2019s (2016)\nGeneral Data Protection Regulation or GDPR, especially\npeople\u2019s right to be forgotten, as it is currently\nimpossible to remove someone\u2019s data (or the results of\nthat data) from a GPT model once it has been trained.", "**Implications for education and research**\n\n-  Researchers, teachers and learners need to know the\nrights of data owners and should check whether the\nGenAI tools they are using contravene any existing\nregulations.\n\n-  Researchers, teachers and learners should also be\naware that the images or codes created with GenAI\nmight violate someone else\u2019s intellectual property\nrights, and that images, sounds or code that they\ncreate and share on the internet might be exploited\nby other GenAI.", "**Implications for education and research**\n\nResearchers, teachers and learners should be aware\nthat GenAI systems operate as black boxes and that\nit is consequently difficult, if not impossible, to know\nwhy particular content has been created.\n\nA lack of\nexplanation of how the outputs are generated tends\nto lock users in the logic defined by parameters\ndesigned in the GenAI systems.\n\nThese parameters\nmay reflect specific cultural or commercial values and\nnorms that implicitly bias the content produced.\n\n-----", "**2.5 genai-generated content polluting**\n\n**the internet**\n\nBecause GPT training data is typically drawn from\nthe internet, which all too frequently includes\ndiscriminatory and other unacceptable language,\ndevelopers have had to implement what they call\n\u2018guardrails\u2019 to prevent GPT output from being offensive\nand/or unethical.\n\nHowever, due to the absence of strict\nregulations and effective monitoring mechanisms,\nbiased materials generated by GenAI are increasingly\nspreading throughout the internet, polluting one of\nthe main sources of content or knowledge for most\nlearners across the world.\n\nThis is especially important\nbecause the material generated by GenAI can appear\nto be quite accurate and convincing, when often it\ncontains errors and biased ideas.\n\nThis poses a high\nrisk for young learners who do not have solid prior\nknowledge of the topic in question.\n\nIt also poses a\nrecursive risk for future GPT models that will be trained\non text scraped from the Internet that GPT models have\nthemselves created which also include their biases and\nerrors.", "**Implications for education and research**\n\n-  Researchers, teachers and learners need to be\naware that GenAI systems are capable of outputting\noffensive and unethical materials.\n\n-  They also need to know about the long-term\nissues that will potentially arise for the reliability of\nknowledge when future GPT models are based on text\nthat previous GPT models have generated.", "**2.6 Lack of understanding of the real**\n\n**world**\n\nText GPTs are sometimes pejoratively referred to as\n\u2018stochastic parrots\u2019 because, as has been noted earlier,\nwhile they can produce text that appears convincing,\nthat text often contains errors and can include harmful\nstatements (Bender et al., 2021).\n\nThis all occurs because\nGPTs only repeat language patterns found in their\ntraining data (usually text drawn from the internet),\n\n\nstarting with random (or \u2018stochastic\u2019) patterns, and\nwithout understanding their meaning \u2013 just as a parrot\ncan mimic sounds without actually comprehending\nwhat it is saying.\n\nThe disconnect between GenAI models \u2018appearing\u2019 to\nunderstand the text that they use and generate, and\nthe \u2018reality\u2019 that they do not understand the language\nand the real world can lead teachers and students\nto place a level of trust in the output that it does not\nwarrant.\n\nThis poses serious risks for future education.\n\nIndeed, GenAI is not informed by observations of the\nreal world or other key aspects of the scientific method,\nnor is it aligned with human or social values.\n\nFor these\nreasons, it cannot generate genuinely novel content\nabout the real world, objects and their relations, people\nand social relations, human-object relations, or humantech relations.\n\nWhether the apparently novel content\ngenerated by GenAI models can be recognized as\nscientific knowledge is contested.\n\nAs already noted, GPTs can frequently produce\ninaccurate or unreliable text.\n\nIn fact, it is well known\nthat GPTs make up some things that do not exist in\nreal life.\n\nSome call this \u2018hallucination\u2019 , although others\ncriticize the use of such an anthropomorphic and\ntherefore misleading term.\n\nThis is acknowledged by\nthe companies producing GenAI.\n\nThe bottom of the\nChatGPT public interface, for instance, states: \u2018ChatGPT\nmay produce inaccurate information about people,\nplaces, or facts\u2019 .\n\n2\n\nIt has also been suggested by a few advocates that\nGenAI represents a significant step in the journey\ntowards artificial general intelligence (AGI), a term\nsuggesting a class of genai that is more intelligent than\nhumans.\n\nHowever, this has long been critiqued, with\nthe argument that genai will never progress towards AGI at\nleast until it in some way brings together, in symbiosis,\nboth knowledge-based genai (also known as symbolic\nor rule-based genai) and data-based genai (also known as\nmachine learning) (Marcus, 2022).\n\nThe AGI or sentience\nclaims also distract us from more careful consideration\nof current harms being perpetrated with genai, such as\nhidden discrimination against already discriminatedagainst groups (Metz, 2021).\n\n-----", "**Implications for education and research**\n\n-  The output of a text GenAI can look impressively\nhuman-like, as if it understood the text that it\ngenerated.\n\nHowever, GenAI does not understand\nanything.\n\nInstead, these tools string words together in\nways that are common on the internet.\n\nThe text that is\ngenerated can also be incorrect.\n\n-  Researchers, teachers and learners need to be\naware that a GPT does not understand the text that\nit generates; that it can, and often does, generate\nincorrect statements; and that they therefore need\nto take a critical approach to everything that it does\ngenerate.", "**2.7 Reducing the diversity of opinions**\n\n**and further marginalizing already**\n**marginalized voices**\n\nChatGPT and similar such tools tend to output only\nstandard answers that assume the values of the\nowners/creators of the data used to train the models.\n\nIndeed, if a sequence of words appears frequently in\nthe training data \u2013 as is the case with common and\nuncontroversial topics and mainstream or dominant\nbeliefs \u2013 it is likely to be repeated by the GPT in its\noutput.\n\nThis risks constraining and undermining the\ndevelopment of plural opinions and plural expressions\nof ideas.\n\nData-poor populations, including marginalized\ncommunities in the Global North, have minimal\nor limited digital presence online.\n\nTheir voices are\nconsequently not being heard and their concerns\nare not represented in the data being used to train\nGPTs, and so rarely appear in the outputs.\n\nFor these\nreasons, given the pre-training methodology based\non data from internet web pages and social media\nconversations, GPT models can further marginalize\nalready disadvantaged people.", "**Implications for education and research**\n\n-  While the developers and providers of GenAI models\nhave the primary responsibility for continuously\naddressing biases in the datasets and outputs of\nthese models, the user-side researchers, teachers and\nlearners need to know that the output of text GenAI\nrepresents only the most common or dominant view\nof the world at the time when its training data was\nproduced and that some of it is problematic or biased\n(e.g.\n\nstereotypical gender roles).\n\n-  Learners, teachers and researchers should never\naccept the information provided by the GenAI at face\nvalue and should always critically assess it.\n\n-  Researchers, teachers and learners also must be\naware of how minority voices can be left out, because\nminority voices are by definition less common in the\ntraining data.", "**2.8 Generating deeper deepfakes**\n\nIn addition to the controversies common to all GenAI,\nGAN GenAI can be used to alter or manipulate existing\nimages or videos to generate fake ones that are\ndifficult to distinguish from real ones.\n\nGenAI is making\nit increasingly easy to create these \u2018deepfakes\u2019 and\nso-called \u2018fake news\u2019 .\n\nIn other words, GenAI is making it\neasier for certain actors to commit unethical, immoral\nand criminal acts, such as spreading disinformation,\npromoting hate speech and incorporating the faces\nof people, without their knowledge or consent, into\nentirely fake and sometimes compromising films.", "**Implications for education and research**\n\nWhile it is the obligation of GenAI providers to protect\nthe copyright and portrait rights of users, researchers,\nteachers and learners also need to be aware that\nany images they share on the internet may be\nincorporated into GenAI training data and might be\nmanipulated and used in unethical ways.\n\n-----", "##### 3.\n\nRegulating the use of genai in education\n\nIn order to address the controversies around\ngenai and to harness the potential\nbenefits of GenAI in education, it first needs to be\nregulated.\n\nRegulation of GenAI for educational\npurposes requires a number of steps and policy\nmeasures based on a human-centred approach to\nensure its ethical, safe, equitable and meaningful\nuse.", "**3.1 A human-centred approach to genai**\n\nUNESCO\u2019s 2021 _Recommendation on the Ethics of Artificial_\n_Intelligence_ provides the requisite normative framework\nto start addressing the multiple controversies around\ngenai, including those that pertain to education\nand research.\n\nIt is based on a human-centred approach\nto genai which advocates that the use of genai should be at\nthe service of the development of human capabilities\nfor inclusive, just and sustainable futures.\n\nSuch an\napproach must be guided by human rights principles,\nand the need to protect human dignity and the cultural\ndiversity that defines the knowledge commons.\n\nIn\nterms of governance, a human-centred approach\nrequires proper regulation that can ensure human\nagency, transparency and public accountability.\n\nThe 2019 _Beijing Consensus on Artificial Intelligence_\n_(genai) and Education_ further elaborates what a humancentred approach implies for the use of genai in the\ncontext of education.\n\nThe Consensus affirms that the\nuse of genai technologies in education should enhance\nhuman capacities for sustainable development and\neffective human-machine collaboration in life, learning\nand work.\n\nIt also calls for further actions to ensure\nequitable access to genai to support marginalized people\nand address inequalities, while promoting linguistic\nand cultural diversities.\n\nThe Consensus suggests\nadopting whole-of-government, intersectoral and\nmultistakeholder approaches to the planning of\npolicies on genai in education.\n\n_AI and education: Guidance for policy-makers_ (UNESCO,\n2022 _b_ ) further refines what a human-centred approach\nmeans when examining the benefits and risks of genai\nin education and the role of education as a means of\ndeveloping genai competencies.\n\nIt proposes concrete\n\n\nrecommendations for the formulation of policies\nto steer the use of genai to (i) enable inclusive access\nto learning programmes, especially for vulnerable\ngroups such as learners with disabilities; (ii) support\npersonalized and open learning options; (iii) improve\ndata-based provisions and management to expand\naccess and improve quality in learning; (iv) monitor\nlearning processes and alert teachers to failure risks;\nand (v) develop understanding and skills for the ethical\nand meaningful use of genai.", "**3.2 Steps to regulate GenAI in**\n\n**education**\n\nPrior to the release of ChatGPT, governments had been\ndeveloping or adapting frameworks for regulating\nthe collection and use of data and the adoption of genai\nsystems across sectors including in education, which\nprovided a legislative and policy context for the\nregulation of newly emergent genai applications.\n\nIn the\naftermath of the release of multiple competitive GenAI\nmodels starting in November 2022, governments\nhave been adopting different policy responses \u2013 from\nbanning GenAI to assessing needs for adapting existing\nframeworks, to urgently formulating new regulations.\n\nGovernmental strategies for regulating and facilitating\nthe creative use of GenAI were mapped and reviewed\nin April 2023 (UNESCO, 2023 _b_ ).\n\n47 The review suggests\na series of seven steps that governmental agencies\ncan take to regulate genai and reassert public\ncontrol in order to leverage its potentials across sectors,\nincluding in education.", "**Step 1: Endorse international or regional**\n\n**general data protection regulations or develop**\n**national ones**\n\nThe training of GenAI models has involved collecting\nand processing online data from citizens across many\ncountries.\n\nThe use, by GenAI models, of data and\ncontent without consent is further challenging the\nissue of data protection.\n\nGeneral data protection regulations, with the EU\u2019s\nGDPR enacted in 2018 as one of the forerunner\n\n\n-----\n\nexamples, provide the necessary legal framework to\nregulate the collection and processing of personal\ndata by the suppliers of GenAI.\n\nAccording to the\nData Protection and Privacy Legislation Worldline\nportal of the United Nations Conference on Trade and\nDevelopment (UNCTAD), 137 out of 194 countries have\nestablished legislation to safeguard data protection\nand privacy.\n\n48\n\nThe extent to which these frameworks are being\nimplemented in those countries, however, remains\nunclear.\n\nIt is therefore ever more critical to ensure that\nthese are properly implemented, including regular\nmonitoring of the operations of GenAI systems.\n\nIt is\nalso urgent for countries that do not yet have general\ndata protection laws to develop them.", "**Step 2: Adopt/revise and fund whole-ofgovernment strategies on genai**\n\nRegulating genai must be part and parcel of\nbroader national genai strategies that can ensure safe\nand equitable use of genai across development sectors,\nincluding in education.\n\nThe formulation, endorsement,\nfunding and implementation of national genai strategies\nrequires a whole-of-government approach.\n\nOnly\nsuch an approach can ensure the coordination of\nintersectoral actions required for integrated responses\nto emerging challenges.\n\nBy early 2023, some 67 countries 49 had developed or\nplanned national strategies on genai, with 61 of them\ntaking the form of a standalone genai strategy, and 7 being\nchapters on genai integrated within broader national ICT\nor digitalization strategies.\n\nUnderstandably, given\nits novelty, none of these national strategies had yet\ncovered genai as a specific issue at the time of\nwriting.\n\nIt is critical that countries revise existing national genai\nstrategies, or develop them, ensuring provisions to\nregulate the ethical use of genai across sectors including in\neducation.", "**Step 3: Solidify and implement specific**\n\n**regulations on the ethics of genai**\n\nIn order to address the ethical dimensions posed by the\nuse of genai, specific regulations are required.\n\nThe UNESCO 2023 review of existing national genai\nstrategies indicates that the identification of such\nethical issues and the formulation of guiding principles\nis only common to some 40 national genai strategies.\n\n50\nAnd even here, the ethical principles will need to be\ntranslated into enforceable laws or regulations.\n\nThis\nis seldom the case.\n\nIndeed, only around 20 countries\nhad defined any clear regulations on the ethics of genai\nincluding as they relate to education, either as part\nof national genai strategies or otherwise.\n\nInterestingly,\nwhile education is highlighted as a policy domain\nacross some 45 national genai strategies, 51 references to\neducation are articulated more in terms of genai skills\nand talent development required to support national\ncompetitiveness, and less in terms of ethical issues.\n\nCountries that do not yet have regulations on ethics of\ngenai must urgently articulate and implement them.", "**Step 4: Adjust or enforce existing copyright**\n\n**laws to regulate genai-generated content**\n\nThe increasingly pervasive use of GenAI has introduced\nnew challenges for copyright, both concerning the\ncopyrighted content or work that models are trained\non, as well as the status of the \u2018non-human\u2019 knowledge\noutputs they produce.\n\nAt present, only China, EU countries and the United\nStates have adjusted copyright laws to account for\nthe implications of genai.\n\nThe US Copyright\nOffice, for instance, has ruled that the output of GenAI\nsystems such as ChatGPT are not protectable under\nUS copyright law, arguing that \u2018copyright can protect\nonly material that is the product of human creativity\u2019\n(US Copyright Office, 2023).\n\nMeanwhile in the EU,\nthe proposed EU genai Act requires genai tool developers\nto disclose the copyrighted materials they used\nin building their systems (European Commission,\n2021).\n\nChina, through its regulation on GenAI released\nin July 2023, requires the labelling of outputs of GenAI\nas genai-generated content, and only recognizes them as\noutputs of digital synthesis.\n\nRegulating the use of copyrighted materials in the\ntraining of GenAI models and defining the copyright\nstatus of GenAI outputs are emerging as new\naccountabilities of copyright laws.\n\nIt is urgent that\nexisting laws be adjusted to account for this.\n\n-----", "**Step 5: Elaborate regulatory frameworks on**\n\n**genai**\n\nThe rapid pace of development of genai technologies is\nforcing national/local governance agencies to speed\nup their renewal of regulations.\n\nAs of July 2023, only\none country, China, had released specific official\nregulations on GenAI.\n\nThe Provisional Regulations on\nGoverning the Service of genai released on\n13 July 2023 (Cyberspace Administration of China,\n2023 _a_ ) requires providers of GenAI systems to label\ngenai-generated content, images and videos properly and\nlawfully in accordance with its existing Regulation on\nDeep Synthesis in the Framework of Online Information\nServices.\n\nMore of such national GenAI-specific\nframeworks need to be developed based upon an\nassessment of the gaps in existing local regulations and\nlaws.", "**Step 6: Build capacity for proper use of GenAI**\n\n**in education and research**\n\nSchools and other educational institutions need\nto develop capacities to understand the potential\nbenefits and risks of genai, including GenAI, for education.\n\nIt is only based on such understanding that they can\nvalidate the adoption of genai tools.\n\nMoreover, teachers\nand researchers need to be supported to strengthen\ntheir capacities for the proper use of GenAI, including\nthrough training and continuous coaching.\n\nA number\nof countries have launched such capacity-building\nprogrammes, including Singapore, which has been\noffering a dedicated platform for the genai capacity\ndevelopment of educational institutions through its genai\nGovernment Cloud Cluster which includes a dedicated\nrepository of GPT models (Ocampo, 2023).", "**GenAI for education and research**\n\nThe impact of current versions of GenAI is just\nbeginning to unfold, and their effects on education are\nyet to be fully explored and understood.\n\nMeanwhile,\nstronger versions of GenAI and other classes of genai\ncontinue to be developed and deployed.\n\nCrucial\nquestions remain, however, around the implications\nof GenAI for knowledge creation, transmission and\nvalidation \u2013 for teaching and learning, for curriculum\ndesign and assessment, and for research and copyright.\n\nMost countries are at the early stage of the adoption of\nGenAI in education, even as the longer-term impacts\n\n\nhave yet to be understood.\n\nTo ensure a human-centred\nuse of genai, open public debate and policy dialogues\non the long-term implications should urgently be\nconducted.\n\nInclusive debate involving government,\nthe private sector and other partners, should serve to\nprovide insights and inputs for the iterative renewal of\nregulations and policies.", "**Key elements**\n\nAll countries need to properly regulate GenAI in order\nto ensure it benefits development in education and\nother contexts.\n\nThis section proposes actions around\nkey elements that can be taken by: (1) governmental\nregulatory agencies, (2) providers of genai-enabled\ntools, (3) institutional users, and (4) individual users.\n\nWhile many of the elements in the framework are of\na transnational nature, all should also be considered\nin light of the local context, that is, the specific\ncountry\u2019s educational systems and general regulatory\nframeworks already in place.", "**3.3.1.\n\nGovernmental regulatory agencies**\n\nA whole-of-government approach is required for\nthe coordination of the design, alignment and\nimplementation of regulations on GenAI.\n\nThe following\nseven key elements and actions are recommended:\n\n-  **\u0007** **Intersectoral coordination** : Establish\na national body to lead on the wholeof-government approach to GenAI and\ncoordinate cooperation across sectors.\n\n-  **\u0007** **Alignment of legislation** : Align the\nframework with the relevant legislative\nand regulatory contexts of each country \u2013\nwith, for example, general data protection\nlaws, regulations on internet security, laws\non the security of data produced from or\nused to serve citizens, and other relevant\nlegislation and usual practices.\n\nAssess the\nappropriateness of existing regulations and\nany necessary adaptations in response to new\nissues raised by GenAI.\n\n-  **\u0007** **Balance between the regulation of GenAI**\n**and the promotion of genai innovation** :\nPromote intersectoral cooperation among\ncompanies, organizations, and education\n\n\n-----\n\nand research institutions, as well as relevant\npublic agencies to jointly develop trustworthy\nmodels; encourage the building of opensource eco-systems to promote the sharing of\nsuper-computing resources and high-quality\npre-training datasets; and foster the practical\napplication of GenAI across sectors and the\ncreation of high-quality content for the public\ngood.\n\n**\u0007** **Assessment and classification of the**\n**potential risks of genai** : Establish principles and a\nprocess for the assessment and categorization\nof the efficacy, safety and security of GenAI\nservices, before they are deployed and\nthroughout the system\u2019s life cycle.\n\nConsider\ncategorization mechanisms based on the\nlevels of risk that GenAI may imply for citizens.\n\nClassify them into strict regulations (i.e.\n\nbanning genai-enabled applications or systems\nwith unacceptable risks), special regulations\nfor high-risk applications, and general\nregulations on applications that are not listed\nas high risk.\n\nSee the EU\u2019s draft genai Act for an\nexample of this approach.\n\n**\u0007** **Protection of data privacy** : Account for\nthe fact that the use of GenAI almost always\ninvolves users sharing their data with the\nGenAI provider.\n\nMandate the drafting and\nimplementation of laws for the protection of\nusers\u2019 personal information and identify and\ncombat unlawful data storage, profiling and\nsharing.\n\n**\u0007** **Definition and enforcement of age limit for**\n**the use of GenAI** : Most GenAI applications\nare primarily designed for adult users.\n\nThese\napplications often entail substantial risks for\nchildren, including exposure to inappropriate\ncontent as well as the potential for\nmanipulation.\n\nIn light of these risks and given\nthe considerable uncertainty that continues\nto surround iterative GenAI applications, age\nrestrictions are strongly recommended for\ngeneral-purpose genai technologies in order to\nprotect children\u2019s rights and wellbeing.\n\nCurrently, the terms of use for ChatGPT require\nthat users must be at least 13 years old, and\nusers under 18 must have their parent or legal\nguardian\u2019s permission to use the services.\n\n52\nThese age restrictions or thresholds are\nderived from the Children\u2019s Online Privacy\n\n\nProtection Act of the United States of America\n(Federal Trade Commission, 1998).\n\nPassed in\n1998 before widespread social media use and\nwell before the creation of easy-to-use and\npowerful GenAI applications such as ChatGPT,\nthe US law specifies that organizations or\nindividual social media providers are not\nallowed to provide services for children under\nthe age of 13 without parental permission.\n\nMany commentators understand this threshold\nto be too young and have advocated for\nlegislation to raise the age to 16.\n\nThe GDPR of\nthe European Union (2016) specifies that users\nmust be at least 16 years old to use the services\nof social media without parental permissions.\n\nThe emergence of various GenAI chatbots\ndemand that countries carefully consider \u2013\nand publicly deliberate \u2013 the appropriate age\nthreshold for independent conversations with\nGenAI platforms.\n\nThe minimum threshold\nshould be 13 years of age.\n\nCountries will\nalso need to decide if self-reporting age\nremains an appropriate means of age\nverification.\n\nCountries will need to mandate\nthe accountabilities of GenAI providers for age\nverification and accountabilities of parents or\nguardians for monitoring the independent\nconversations of underage children.\n\n-  \u0007 **National data ownership and the risk of**\n**data poverty** : Take legislative measures to\nprotect national data ownership and regulate\nproviders of GenAI that operate within its\nborders.\n\nFor datasets generated by citizens\nthat are being used for commercial purposes,\nestablish regulations to promote mutual\nbeneficial cooperation so that this category\nof data shall not be drained from the country\nto be exploited exclusively by the big tech\ncompanies.", "**3.3.2.\n\nProviders of GenAI tools**\n\nProviders of GenAI include organizations and\nindividuals who are responsible for developing\nand making available GenAI tools, and/or are using\nGenAI technologies to provide services including\nthrough programmable application programming\ninterfaces (APIs).\n\nMost of the influential providers of\nGenAI tools are extremely well-funded companies.\n\nIt should be made clear to GenAI providers that\nthey are accountable for ethics by design, including\n\n\n-----\n\nfor implementing the ethical principles stipulated\nin the regulations.\n\nThe following ten categories of\naccountabilities should be covered:\n\n-  **\u0007** **Human accountabilities** : GenAI providers\nshould be held responsible for ensuring\nadherence to core values and lawful\npurposes, respecting intellectual property,\nand upholding ethical practices, while also\npreventing the spread of disinformation and\nhate speech.\n\n-  **\u0007** **Trustworthy data and models** : GenAI\nproviders should be required to evidence\nthe trustworthiness and ethics of the data\nsources and methods used by their models\nand outputs.\n\nThey must be mandated to adopt\ndata and foundation models with proven legal\nsources, and abide by the relevant intellectual\nproperty laws (e.g.\n\nif the data are protected by\nintellectual property rights).\n\nIn addition, when\nthe models need to use personal information,\nthe collection of said information should take\nplace only with the informed and explicit\nconsent of the owners.\n\n-  **\u0007** **Non-discriminatory content generation** :\nProviders of GenAI must prohibit the design\nand deployment of GenAI systems that\ngenerate biased or discriminatory content\nbased on race, nationality, gender or other\nprotected characteristics.\n\nThey should ensure\nthat robust \u2018guardrails\u2019 are in place to prevent\nGenAI producing offensive, biased or false\ncontent, while ensuring that the humans\ninvolved in informing the guardrails are\nprotected and not exploited.\n\n-  **\u0007** **Explainability and transparency of GenAI**\n**models** : Providers should submit to public\ngovernance agencies their explanations of the\nsources, scale and types of data used by the\nmodels; their rules for labelling data in pretraining; the methods or algorithms that their\nmodels use to generate content or responses;\nand the services that their GenAI tools are\nproviding.\n\nWhen necessary, they should\noffer support to help governance agencies\nunderstand the technology and data.\n\nGenAI\u2019s\npropensity to generate content with errors\nand contestable responses should be made\ntransparent for users.\n\n**\u0007** **Labelling of GenAI content** : In accordance\nwith relevant laws or regulations on the\ngenai-assisted synthesis of online information,\nproviders need to label GenAI-generated\npapers, reports, images and videos properly\nand lawfully.\n\nFor example, GenAI output\nshould be clearly labelled as having been\nproduced by a machine.\n\n**\u0007** **Security and safety principles** : Providers\nof GenAI should ensure secure, robust and\nsustainable service throughout the life cycle of\na GenAI system.\n\n**\u0007** **Specifications on appropriateness for**\n**access and use** : Providers of GenAI should\nprovide clear specifications on the appropriate\naudience for, and use scenarios and purposes\nof, their services and help users of GenAI tools\nto make rational and responsible decisions.\n\n**\u0007** **Acknowledging the limitations and**\n**preventing predictable risks** : Providers of\nGenAI should clearly advertise the limitations\nof the methods used by the systems and their\noutputs.\n\nThey need to develop technologies\nto ensure that the input data, methods,\nand outputs do no predictable harm to\nusers, together with protocols to mitigate\nunpredictable harms when they occur.\n\nThey\nmust also provide guidance to help users\nunderstand GenAI-generated content based\non ethical principles, and to prevent their overreliance on and addiction to the generated\ncontent.\n\n\u0007 **Mechanisms for complaints and remedies** :\nProviders of GenAI need to establish\nmechanisms and channels for the collection\nof complaints from users and the wider public,\nand take timely actions to accept and process\nthese complaints.\n\n**\u0007** **Monitoring and reporting of unlawful**\n**use** : Providers shall cooperate with public\ngovernance agencies to facilitate the\nmonitoring and reporting of unlawful use.\n\nThis\nincludes when people use GenAI products in\nways that are illegal or violate ethical or social\nvalues such as promoting disinformation or\nhate speech, generating spam or composing\nmalware.\n\n-----", "**3.3.3.\n\nInstitutional users**\n\nInstitutional users include educational authorities and\ninstitutions such as universities and schools that hold\nresponsibilities for determining whether GenAI should\nbe adopted and which types of GenAI tools should be\nprocured and deployed within the institution.\n\n-  **\u0007** **Institutional auditing of GenAI algorithms,**\n**data and outputs** : Implement mechanisms to\nmonitor as best as possible the algorithms and\ndata used by GenAI tools and the outputs they\ngenerate.\n\nThis should include regular audits\nand assessments, the protection of user data,\nand automatically filtering out inappropriate\ncontent.\n\n-  **\u0007** **Validating proportionality and protecting**\n**users\u2019 well-being** : Implement national\nclassification mechanisms or build an\ninstitutional policy for categorizing and\nvalidating GenAI systems and applications.\n\nEnsure that the GenAI systems adopted by\nthe institution are in line with locally validated\nethical frameworks and do no predictable\nharm to the institutions\u2019 target users, especially\nchildren and vulnerable groups.", "**3.3.4.\n\nIndividual users**\n\nIndividual users potentially include all people globally\nwho have access to the Internet and at least one type\nof GenAI tool.\n\nThe term \u2018individual users\u2019 , as employed\nhere, mainly refer to individual teachers, researchers\nand learners in formal educational institutions or those\nparticipating in non-formal programmes of study.\n\n-  **\u0007** **Awareness of terms of reference on the**\n**use of GenAI** : Upon signing or expressing\nconsent to service agreements, users should\nbe aware of the obligations of abiding by the\nToR stipulated in the agreement and the laws\nor regulations behind the agreement.\n\n-  **\u0007** **Ethical use of GenAI applications** : Users\nshould deploy GenAI responsibly and avoid\nexploiting it in ways that might damage other\npeople\u2019s reputations and lawful rights.\n\n-  **Monitoring and reporting unlawful** **\u0007**\n**GenAI applications** : When discovering\nGenAI applications that violate one or\nmore regulations, users should notify the\ngovernmental regulatory agencies.\n\n**\u0007** **Review and address the long-term impacts** :\nOver time, relying on GenAI tools or content\nin education may have profound effects on\nthe development of human capacities such\nas critical thinking skills and creativity.\n\nThese\npotential effects should be evaluated and\naddressed.\n\n**\u0007** **Age appropriateness** : Consider implementing\nminimum age restrictions for the independent\nuse of GenAI in the institution.\n\n-----", "###### 4.\n\nTowards a policy framework for the use of genai in education and research\n\nRegulating GenAI to harness the potential benefits for\neducation and research requires the development of\nappropriate policies.\n\nThe 2023 survey data cited above\nindicate that only a handful of countries have adopted\nspecific policies or plans for the use of genai in education.\n\nThe preceding section outlined a vision, the steps\nrequired and the key elements and actions that can be\ntaken by various stakeholders.\n\nThis section provides\nmeasures that can be taken to develop coherent,\ncomprehensive policy frameworks to regulate the use\nof GenAI in education and research.\n\nA starting point for this is the 2022 _AI and education:_\n_guidance for policy-makers_ (UNESCO, 2022 _b_ ).\n\nIt proposes\na comprehensive set of recommendations to guide\ngovernments in the development and implementation\nof sector-wide policies on genai and education with a\nfocus on promoting quality education, social equity\nand inclusion.\n\nMost of the recommendations remain\napplicable and can be further adapted to guide the\nformulation of specific policies on GenAI in education.\n\nThe following eight specific measures for the planning\nof policies on GenAI in education and research are\nproposed here to complement this existing guidance.", "**4.1 Promote inclusion, equity, and**\n\n**linguistic and cultural diversity**\n\nThe critical importance of inclusion must be recognized\nand addressed throughout the life cycle of GenAI.\n\nMore specifically, GenAI tools will not help address\nthe fundamental challenges in education or the\nachievement of SDG 4 commitments unless such\ntools are made inclusively accessible (irrespective of\ngender, ethnicity, special educational needs, socioeconomic status, geographic location, displacement\nstatus and so on), and if they do not by design advance\nequity, linguistic diversities and cultural pluralism.\n\nTo\nachieve this, the following three policy measures are\nrecommended:\n\n-  \u0007 Identify those who do not have or cannot\nafford internet connectivity or data, and take\n\n\naction to promote universal connectivity and\ndigital competencies in order to reduce the\nbarriers to equitable and inclusive access to\ngenai applications.\n\nEstablish sustainable funding\nmechanisms for the development and\nprovision of genai-enabled tools for learners who\nhave disabilities or special needs.\n\nPromote the\nuse of GenAI to support lifelong learners of all\nages, locations, and backgrounds.\n\n-  \u0007 Develop criteria for the validation of GenAI\nsystems to ensure that there is no gender bias,\ndiscrimination against marginalized groups, or\nhate speech embedded in data or algorithms.\n\n-  \u0007 Develop and implement inclusive\nspecifications for GenAI systems and\nimplement institutional measures to protect\nlinguistic and cultural diversities when\ndeploying GenAI in education and research at\nscale.\n\nRelevant specifications should require\nproviders of GenAI to include data in multiple\nlanguages, especially local or indigenous\nlanguages, in the training of GPT models to\nimprove GenAI\u2019s ability to respond to and\ngenerate multilingual text.\n\nSpecifications\nand institutional measures should strictly\nprevent genai providers from any intentional or\nunintentional removal of minority languages\nor discrimination against speakers of\nindigenous languages, and require providers\nto stop systems promoting dominant\nlanguages or cultural norms.", "**4.2 Protect human agency**\n\nAs GenAI becomes increasingly sophisticated, a key\ndanger is its potential to undermine human agency.\n\nAs more individuals use GenAI to support their writing\nor other creative activities, they might unintentionally\ncome to rely upon it.\n\nThis can compromise the\ndevelopment of intellectual skills.\n\nWhile GenAI may\nbe used to challenge and extend human thinking, it\nshould not be allowed to usurp human thinking.\n\nThe\n\n\n-----\n\nprotection and enhancement of human agency should\nalways be core considerations when designing and\nadopting GenAI from the following seven perspectives:\n\n-  \u0007 Inform learners about the types of data that\nGenAI may collect from them, how these data\nare used, and the impact it may have on their\neducation and wider lives.\n\n-  \u0007 Protect learners\u2019 intrinsic motivation to grow\nand learn as individuals.\n\nReinforce human\nautonomy over their own approaches to\nresearch, teaching, and learning in the context\nof using increasingly sophisticated GenAI\nsystems.\n\n-  \u0007 Prevent the use of GenAI where it would\ndeprive learners of opportunities to develop\ncognitive abilities and social skills through\nobservations of the real world, empirical\npractices such as experiments, discussions\nwith other humans, and independent logical\nreasoning.\n\n-  \u0007 Ensure sufficient social interaction and\nappropriate exposure to creative output\nproduced by humans and prevent learners\nbecoming addicted to or dependent on GenAI.\n\n-  \u0007 Use GenAI tools to minimize the pressure\nof homework and exams, rather than to\nexacerbate it.\n\n-  \u0007 Consult researchers, teachers and learners\nabout their views on GenAI and use the\nfeedback to decide whether and how\nspecific GenAI tools should be deployed at\nan institutional scale.\n\nEncourage learners,\nteachers and researchers to critique and\nquestion the methodologies behind the genai\nsystems, the accuracy of the output content,\nand the norms or pedagogies that they may\nimpose.\n\n-  \u0007 Prevent ceding human accountability to GenAI\nsystems when making high-stakes decisions.", "**4.3 Monitor and validate GenAI**\n\n**systems for education**\n\nAs noted, the development and deployment of GenAI\nshould be ethical by design.\n\nSubsequently, once the\nGenAI is in use, and throughout its life cycle, it needs\nto be carefully monitored and validated \u2013 for its ethical\n\n\nrisks, its pedagogical appropriateness and rigour, and\nits impact on students, teachers and classroom/school\nrelationships.\n\nIn this respect, the following five actions\nare recommended:\n\n-  \u0007 Build validation mechanisms to test whether\nGenAI systems used in education and\nresearch are free of biases, especially gender\nbiases, and whether they are trained on data\nrepresentative of diversity (in terms of gender,\ndisability, social and economic status, ethnic\nand cultural background, and geographic\nlocation).\n\n-  \u0007 Address the complex issue of informed\nconsent, particularly in contexts where\nchildren or other vulnerable learners are not\ncapable of giving genuinely informed consent.\n\n-  \u0007 Audit whether outputs of GenAI include\ndeepfake images, fake (inaccurate or false)\nnews, or hate speech.\n\nIf the GenAI is found\nto be generating inappropriate content,\ninstitutions and educators should be willing\nand able to take swift and robust action to\nmitigate or eliminate the problem.\n\n-  \u0007 Exercise strict ethical validation of GenAI\napplications before they are officially adopted\nin educational or research institutions (i.e.\n\nadopt an ethics-by-design approach).\n\n-  \u0007 Before making decisions on institutional\nadoption, ensure that the GenAI applications\nin question do no predictable harm to\nstudents, are educationally effective and valid\nfor the ages and abilities of the target learners,\nand are aligned with sound pedagogical\nprinciples (i.e.\n\nbased on the relevant domains\nof knowledge and the expected learning\noutcomes and development of values).", "**GenAI-related skills for learners**\n\nThe development of genai competencies among learners\nis key to the safe, ethical and meaningful use of genai in\neducation and beyond.\n\nHowever, according to UNESCO\ndata, only some 15 countries had developed and\nimplemented, or were in the process of developing,\ngovernment-endorsed genai curricula in schools in early\n2022 (UNESCO, 2022 _c_ ).\n\nThe latest developments of\nGenAI have further reinforced the urgent need for\n\n\n-----\n\neveryone to achieve an appropriate level of literacy in\nboth the human and technological dimensions of genai,\nunderstanding how it works in broad terms, as well\nas the specific impact of GenAI.\n\nIn order to do so, the\nfollowing five actions are now urgently needed:\n\n-  \u0007 Commit to the provision of governmentsanctioned genai curricula for school education,\nin technical and vocational education and\ntraining, as well as for lifelong learning.\n\ngenai\ncurricula should cover the impact of genai on\nour lives, including the ethical issues it raises,\nas well as age-appropriate understanding of\nalgorithms and data, and skills for the proper\nand creative use of genai tools including GenAI\napplications;\n\n-  \u0007 Support higher education and research\ninstitutions to enhance programmes to\ndevelop local genai talent;\n\n-  \u0007 Promote gender equality in developing\nadvanced genai competencies and create a\ngender-balanced pool of professionals;\n\n-  \u0007 Develop intersectoral forecasts of the national\nand global job shifts caused by the latest\nGenAI automation, and enhance future-proof\nskills at all levels of education and lifelong\nlearning systems based on prospective shifts\nin demand; and\n\n-  \u0007 Provide special programmes for older workers\nand citizens who may need to learn new skills\nand adapt to new environments.", "**GenAI**\n\nAccording to 2023 survey data on the governmental\nuse of genai for education (UNESCO, 2023 _c_ ), only some\nseven countries (China, Finland, Georgia, Qatar,\nSpain, Thailand and T\u00fcrkiye) reported that they had\ndeveloped or were developing frameworks or training\nprogrammes on genai for teachers.\n\nOnly the Ministry of\nEducation of Singapore reported building an online\nrepository centred on the use of ChatGPT in teaching\nand learning.\n\nThis clearly shows that teachers in most\ncountries are do not have access to well-structured\ntraining on the use of genai in education, not least on the\nuse of GenAI.\n\nTo prepare teachers for the responsible and effective\nuse of GenAI, countries need to take the following four\nactions:\n\n-  \u0007 Formulate or adjust guidance based on local\ntests to help researchers and teachers to\nnavigate widely available GenAI tools, and\nsteer the design of new domain-specific genai\napplications.\n\n-  \u0007 Protect the rights of teachers and researchers\nand the value of their practices when using\nGenAI.\n\nMore specifically, analyse teachers\u2019\nunique roles in facilitating higher-order\nthinking, organizing human interaction, and\nfostering human values.\n\n-  \u0007 Define the value orientation, knowledge\nand skills that teachers need in order to\nunderstand and use GenAI systems effectively\nand ethically.\n\nEnable teachers to create specific\nGenAI-based tools to facilitate learning in\nthe classroom and in their own professional\ndevelopment.\n\n-  \u0007 Dynamically review the competencies needed\nby teachers to understand and use genai for\nteaching, learning and for their professional\ndevelopment, and integrate emerging sets of\nvalues, understanding and skills on genai into the\ncompetency frameworks and programmes for\ntraining in-service and pre-service teachers.", "**4.6 Promote plural opinions and plural**\n\n**expressions of ideas**\n\nAs noted earlier, GenAI understands neither the prompt\nnor the response.\n\nInstead, its responses are based on\nprobabilities of language patterns found in the data\n(from the internet) that it ingested when its model was\ntrained.\n\nTo address some of the fundamental problems\nof its outputs, new methods are currently being\nresearched such as connecting GenAI with knowledge\ndatabases and reasoning engines.\n\nNonetheless,\nbecause of how it works, its source materials and\nthe tacit perspectives of its developers, GenAI, by\ndefinition, reproduces dominant worldviews in its\noutputs and undermines minority and plural opinions.\n\nAccordingly, if human civilizations are to flourish, it is\nessential that we recognize that GenAI can never be an\nauthoritative source of knowledge on whatever topic it\nengages with.\n\n-----\n\nAs a result, users need to view GenAI\u2019s outputs critically.\n\nIn particular:\n\n-  \u0007 Understand the role of GenAI as a fast but\nfrequently unreliable source of information.\n\nWhile some plugins and LLM-based tools\nmentioned earlier are designed to support\nthe need to access validated and up-to-date\ninformation, there is little robust evidence as\nyet that these are effective.\n\n-  \u0007 Encourage learners and researchers to critique\nthe responses provided by GenAI.\n\nRecognize\nthat GenAI typically only repeats established\nor standard opinions, thus undermining plural\nand minority opinions and plural expressions\nof ideas.\n\n-  \u0007 Provide learners with sufficient opportunities\nto learn from trial and error, empirical\nexperiments, and observations of the real\nworld.", "**4.7 Test locally relevant application**\n\n**models and build a cumulative**\n**evidence base**\n\nGenAI models are thus far dominated by information\nfrom the Global North and under-representing voices\nfrom the Global South and indigenous communities.\n\nOnly by means of determined efforts, for example\nharnessing synthetic data (Marwala, 2023), will GenAI\ntools be made sensitive to the context and needs of\nlocal communities, particularly those from the Global\nSouth.\n\nTo explore approaches relevant to local needs,\nwhile collaborating more widely, the following eight\nactions are recommended:\n\n-  \u0007 Ensure the design and adoption of GenAI are\nstrategically planned rather than facilitating a\npassive and non-critical procurement process.\n\n-  \u0007 Incentivize the designers of GenAI to target\nopen-ended, exploratory and diverse learning\noptions.\n\n-  \u0007 Test and scale up evidence-based use cases\nof applying genai in education and research in\naccordance with educational priorities, rather\nthan novelty, myth or hype.\n\n-  \u0007 Guide the use of GenAI to trigger innovation\nin research, including through leveraging\ncomputing capabilities, large-scale data,\nand GenAI outputs to inform and inspire the\nimprovement of research methodologies.\n\n-  \u0007 Review the social and ethical implications of\nincorporating GenAI into research processes.\n\n-  \u0007 Establish specific criteria based on evidenced\npedagogical research and methodologies and\nbuild an evidence base for the effectiveness\nof GenAI in terms of supporting the provision\nof inclusive learning opportunities, meeting\nlearning and research objectives, and\npromoting linguistic and cultural diversities.\n\n-  \u0007 Take iterative steps to strengthen evidence on\nthe social and ethical impact of GenAI.\n\n-  \u0007 Analyse the environmental costs of leveraging\ngenai technologies at scale (e.g.\n\nthe energy and\nresources required for training GPT models),\nand develop sustainable targets to be met by\ngenai providers in a bid to avoid adding to climate\nchange.", "**4.8 Review long-term implications**\n\n**in an intersectoral and**\n**interdisciplinary manner**\n\nIntersectoral and interdisciplinary approaches are\nessential for the effective and ethical use of GenAI\nin education and research.\n\nOnly by drawing on a\nrange of expertise, while bringing together multiple\nstakeholders, will key challenges be identified promptly\nand addressed effectively to minimize long-term\nnegative implications while leveraging ongoing and\ncumulative benefits.\n\nTherefore, these three actions are\nrecommended:\n\n-  Collaborate with genai providers, educators, \u0007\nresearchers, and representatives of parents\nand students to plan system-wide adjustments\nin curriculum frameworks and assessment\nmethodologies, to fully leverage the potential\nand mitigate the risks of GenAI for education\nand research.\n\n-  \u0007 Bring together intersectoral and\ninterdisciplinary expertise including\neducators, researchers, learning scientists,\ngenai engineers, and representatives of other\nstakeholders to examine the long-term\nimplications of GenAI for learning and\nknowledge production, research and\ncopyright, curriculum and assessment, and\nhuman collaboration and social dynamics.\n\n-  \u0007 Provide timely advice to inform the iterative\nupdates of regulations and policies.\n\n-----", "##### 5.\n\nFacilitating creative use of GenAI in education and research\n\n**\u0007** **Guidance and training** : Provide guidance\nand training to researchers, teachers and\nlearners about GenAI tools to ensure that they\nunderstand the ethical issues such as biases in\ndata labelling and algorithms, and that they\ncomply with the appropriate regulations on\ndata privacy and intellectual property.\n\n**\u0007** **Building GenAI prompt-engineering**\n**capacities** : In addition to subject-specific\nknowledge, researchers and teachers will also\nneed expertise in engineering and critically\nevaluating the prompts generated by GenAI.\n\nGiven that the challenges raised by GenAI\nare complex, researchers and teachers must\nreceive high-quality training and support to\ndo this.\n\n**\u0007** **Detecting GenAI-based plagiarism in**\n**written assignments** : GenAI might allow\nstudents to pass off text that they did not write\nas their own work, a new type of \u2018plagiarism\u2019 .\n\nGenAI providers are required to label their\noutputs with \u2018generated by genai\u2019 watermarks,\nwhile tools are being developed to identify\nmaterial that has been produced by genai.\n\nHowever, there is little evidence that these\nmeasures or tools are effective.\n\nThe immediate\ninstitutional strategy is to uphold academic\nintegrity and reinforce accountability through\nrigorous detection by humans.\n\nThe long-term\nstrategy is for institutions and educators to\nrethink the design of written assignments\nso that they are not used to assess tasks\nthat GenAI tools can do better than human\nlearners.\n\nInstead, they should address what\nhumans can do that GenAI and other genai tools\ncannot do, including applying human values\nsuch as compassion and creativity to complex\nreal-world challenges.\n\nWhen ChatGPT was first launched, educators across\nthe world expressed their concerns about its potential\nto generate essays and how it might help students to\ncheat.\n\nMore recently, many people and organizations\nincluding some of the world\u2019s leading universities\nhave argued that \u2018the genie is out of the bottle\u2019 and\ntools like ChatGPT are here to stay and may be used\nproductively in educational settings.\n\nMeanwhile, the\ninternet is now awash with suggestions for the use of\nGenAI in education and research.\n\nThese include using\nit to inspire new ideas, generate multi-perspective\nexamples, develop lesson plans and presentations,\nsummarize existing materials, and stimulate image\ncreation.\n\nAlthough new ideas appear on the internet\nalmost every day, researchers and educators are still\nworking out exactly what GenAI means for teaching,\nlearning and research.\n\nIn particular, the people behind\nmany of the proposed uses may not have properly\nconsidered ethical principles, while others are driven by\nthe technological potentials of GenAI rather than the\nneeds of researchers, teachers or learners.\n\nThis section\noutlines ways in which the creative use of GenAI in\neducation can be facilitated.", "**GenAI**\n\nAs stated earlier, educational and research institutions\nshould develop, implement and validate appropriate\nstrategies and ethical frameworks to guide the\nresponsible and ethical use of GenAI systems and\napplications to meet the needs of teaching, learning\nand research.\n\nThis can be achieved through the\nfollowing four strategies:\n\n-  **\u0007** **Institutional implementation of ethical**\n**principles** : Ensure that researchers, teachers\nand learners use GenAI tools responsibly and\nethically, and critically approach the accuracy\nand validity of the outputs.\n\n-----", "**5.2 A \u2018human-centred and**\n\n**pedagogically appropriate**\n**interaction\u2019 approach**\n\nResearchers and educators should prioritize human\nagency and responsible, pedagogically appropriate\ninteraction between humans and genai tools when\ndeciding on whether and how to use GenAI.\n\nThis\nincludes the following five considerations:\n\n-  \u0007 the use of the tool(s) should contribute to\nhumans\u2019 needs and make learning or research\nmore effective than a no-tech or other\nalternative approach;\n\n-  \u0007 educators\u2019 and learners\u2019 use of the tool(s)\nshould be based on their intrinsic motivation;\n\n-  \u0007 the process of using the tool(s) should be\ncontrolled by the human educators, learners\nor researchers;\n\n-  \u0007 the choice and organization of the tool(s)\nand the content they generate should be\nproportionate, based on the learners\u2019 age\nrange, the expected results, and the type of\ntarget knowledge (e.g.\n\nfactual, conceptual,\nprocedural, or metacognitive) or target\nproblem (e.g.\n\nwell-structured or ill-structured);\nand\n\n-  \u0007 the usage processes should ensure humans\u2019\ninteractive engagement with GenAI and\nhigher-order thinking, as well as human\naccountability for decisions related to the\naccuracy of genai-generated content, teaching\nor research strategies, and their impact on\nhuman behaviours.", "**5.3 Co-designing the use of GenAI in**\n\n**education and research**\n\n\nTo facilitate the recommended co-design, this\nGuidance proposes a framework composed of the\nfollowing six perspectives to consolidate pedagogically\nappropriate interactions and the prioritization of\nhuman agency:\n\n-  \u0007 appropriate domains of knowledge or\nproblems;\n\n-  expected outcomes;\n\n-  \u0007 appropriate GenAI tools and comparative\nadvantages;\n\n-  requirements for users;\n\n-  \u0007 required human pedagogical methods and\nexample prompts; and\n\n-  ethical risks.\n\nThis section provides examples of how a process of\nco-design in the use of GenAI can inform research\npractices, assist in teaching, provide coaching for the\nself-paced acquisition of foundational skills, facilitate\nhigher-order thinking, and support learners with\nspecial needs.\n\nThese examples represent only the tip\nof the iceberg of the increasing number of domains in\nwhich GenAI may have potential.", "**5.3.1 genai for research**\n\nGenAI models have demonstrated their potential to\nexpand views on research outlines and to enrich data\nexploration as well as literature reviews (see **Table 3** ).\n\nWhile a wider range of use cases may emerge, novel\nresearch is needed to define the potential domain\nof research problems and expected outcomes, to\ndemonstrate the efficacy and accuracy, and to ensure\nthat human agency in understanding the real world\nthrough research will not be undermined by the use of\ngenai tools.\n\nThe use of GenAI in education and research should be\nneither imposed in a top-down approach nor driven by\ncommercial hyperbole.\n\nInstead, its safe and effective\nuse should be co-designed by teachers, learners, and\nresearchers.\n\nIt also needs a robust process of piloting\nand evaluation to examine the effectiveness and the\nlong-term impact of different uses.\n\n-----\n\n|Table 3.\n\nCo-designing uses of GenAI for research|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n|Potential Appropriate Appropriate but domains of Expected GenAI tools and unproven knowledge or outcomes comparative uses problems advantages||||Required human Requirements pedagogical Possible risks for the users methods and example prompts|||\n|genai advisor for research outlines|Might be useful in well- structured domains of research problems.|Developing and answering research questions, suggesting appropriate methodologies.\n\nPotential transformation: 1:1 coach for research planning|Starting with the list in Section 1.2, assess whether the GenAI tools are locally accessible, open-source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|The researcher must have a basic understanding of the topic(s).\n\nThe researcher should develop the ability to verify the information, and be especially capable of detecting citations of non-existent research papers.|Basic ideas for the definition of research problems (e.g.\n\ntarget audience, issues, context), as well as methodologies, expected outcomes and formats.\n\nExample prompt: Write 10 potential research questions for [topic x] and rank them in importance for [the field of research y].|Need to be alert to the high risk of GenAI making up information (such as non-existent research publications), and of users being tempted to copy and paste genai-generated research outlines, which may reduce junior researchers\u2019 opportunities to learn from trial and error.|\n|Generative data explorer and literature reviewer|Might be useful in ill-structured domains of research problems.|Automatic gathering of information, exploration of a wide range of data, proposing drafts of literature reviews, and automating parts of data interpretation.\n\nPotential transformation: genai trainers for data exploration and literature reviews|Starting with the list in Section 1.2, assess whether the GenAI tools are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|The researchers must have a robust knowledge of methodologies and techniques for analysing data.|Progressive definitions of the problems, the scope of data and sources of literature, the methodologies used for data exploration and literature reviews, and the expected outcomes and their formats.|Need to beware of GenAI-fabricated information, the improper handling of data, possible breaches of privacy, unauthorized profiling, and gender bias.\n\nNeed to be alert to the propagation of dominant norms and their threat to alternative norms and plural opinions.|", "**5.3.2 genai to facilitate teaching**\n\nThe use of both general GenAI platforms and specific\neducational GenAI tools should be designed to\nenhance teachers\u2019 understanding of their subject as\nwell as their knowledge on teaching methodologies,\nincluding through teacher-genai co-designing of lesson\nplans, course packages, or entire curricula.\n\nThe\nGenAI-assisted conversational teachers\u2019 assistants\nor \u2018generative twins of teaching assistants\u2019 53 that are\n\n\npre-trained based on data from experienced teachers\nand libraries, have been tested in some educational\ninstitutions and may hold unknown potential as well\nas uncharted ethical risk.\n\nThe practical application\nprocesses and further iterations of these models still\nneed to be carefully audited through the framework\nrecommended in this Guidance and safeguarded by\nhuman supervision as exemplified in **Table 4** .\n\n-----", "**Table 4.\n\nCo-designing uses of GenAI to support teachers and teaching**\n\n|Potential Appropriate Appropriate but domains of Expected GenAI tools and unproven knowledge or outcomes comparative uses problems advantages|Col2|Col3|Col4|Required human Requirements pedagogical Possible risks for the users methods and example prompts|Col6|Col7|\n|---|---|---|---|---|---|---|\n|Curriculum or course co-designer|Conceptual knowledge on certain teaching topics and procedural knowledge on teaching methodologies.|Assisting with the curriculum and lesson design process, including outlining or extending views on key areas of the target topic and defining the curriculum structure.\n\nIt may also help teachers prepare tests and exams by ofefring examples of questions and rubrics for evaluation.\n\nPotential transformation: genai-generated curriculum|Starting with the list in Section 1.2, assess whether the GenAI tools are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|The teachers must understand and carefully specify what they want the curriculum, courses, lessons, or tests to cover and achieve, whether they want to address procedural or conceptual knowledge, and what teaching theory they wish to apply.|Questions to GenAI on suggesting the structure and examples of factual knowledge on topic(s), suggesting teaching methods and processes for topics or problems, or creating course packages or lesson plans based on topic(s) and formatting.\n\nHuman curriculum designers need to verify the factual knowledge and check the appropriateness of the suggested course packages.|The risk of GenAI imposing dominant norms and pedagogical methods is high.\n\nIt may inadvertently perpetuate exclusionary practices in favour of the already data-rich groups and reinforce inequalities in access to relevant and high-quality educational opportunities, disadvantaging data-poor groups.|\n|Generative chatbot as teaching assistant|Conceptual knowledge across multiple domains in well- structured problems.|Providing individualized support, answering questions and identifying resources.\n\nPotential transformation: Generative twins of teachers\u2019 assistants|Starting with the list in Section 1.2, assess whether the GenAI tools are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|It supports teachers but targets learners directly, so this requires learners to have sufficient prior knowledge, abilities and metacognitive skills to the verify the outputs of GenAI and notice the misinformation.\n\nThus it might be more appropriate for learners in higher education.|Requires the teachers to understand the problems clearly, to monitor the conversation and help learners to verify dubious answers provided by GenAI.|Based on the current capabilities of GenAI models, educational institutions need to guarantee human supervision of the responses provided by GenAI tools, being alert to the risk of misinformation.\n\nIt may also limit learners\u2019 access to human guidance and support, hindering the development of a strong teacher-student relationship, which is especially concerning for children.|", "**5.3.3 genai as a 1:1 coach for the**\n\n**self-paced acquisition of foundational skills**\n\nWhile higher-order thinking and creativity have been\ndrawing increasing attention when defining learning\noutcomes, there is still no doubting the importance\nof foundational skills in children\u2019s psychological\ndevelopment and competency progression.\n\nAmong\na large spectrum of abilities, these foundational\nskills include listening, pronouncing, and writing a\n\n\nmother tongue or foreign language, as well as basic\nnumeracy, art, and coding.\n\n\u2018Drill and practice\u2019 should\nnot be considered as an obsolete pedagogical method;\ninstead, it should be reinvigorated and upgraded\nwith GenAI technologies to foster learners\u2019 self-paced\nrehearsal of foundational skills.\n\nIf guided by ethical and\npedagogical principles, GenAI tools have the potential\nto become 1:1 coaches for such self-paced practice, as\nillustrated in **Table 5** .\n\n-----", "**Table 5.\n\nCo-designing uses of GenAI as a 1:1 coach for the self-paced acquisition of foundational**\n\n|skills in languages and the arts|Col2|Col3|Col4|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n|Potential Appropriate Appropriate but domains of Expected GenAI tools and unproven knowledge or outcomes comparative uses problems advantages||||Required human Requirements pedagogical Possible risks for the users methods and example prompts|||\n|1:1 language skills coach|Language learning, including conversational practice.|Engaging learners in conversational practice to help them improve listening, speaking and writing skills by ofefring feedback, corrections and modelling of the mother tongue or foreign language.\n\nHelping learners improve their writing skills.\n\nPotential transformation: 1:1 language tutorials at beginner level|Starting with the list in Section 1.2, assess whether the GenAI tools are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|An age limit may be set for the independent conversations in view of the culturally insensitive or age- inappropriate output provided by GenAI systems.\n\nThe learner must have the initial intrinsic motivation to engage in a conversation with an genai system.\n\nThe learner should be able to take a critical approach to the GenAI\u2019s suggestions and check whether they are accurate.|When using general GenAI platforms, human teachers can guide learners to engage with GenAI tools to request feedback for improvement, correction of pronunciation or examples of writing.\n\nFor instance: Engage me in a conversation in the [x] language, helping me to continuously improve.\n\nSuggest some ideas to help me write about [topic x].|Need to be alert to culturally insensitive or contextually inaccurate language, and the inadvertent perpetuation of stereotypes or cultural biases.\n\nWithout proper pedagogical strategies to simulate learners\u2019 intrinsic motivations, it may limit children\u2019s creativity and originality, leading to formulaic writing.\n\nIt may also limit opportunities for real-life interactions, plural opinions, plural expression, and critical thinking.|\n|1:1 art coach|Technical skills in areas of art such as music and drawing.|Providing suggestions for art techniques (e.g.\n\ntips on perspective and colour), or musical composition (e.g.\n\nmelody and chord progression).\n\nPotential transformation: 1:1 art teacher at introductory levels|Starting with the list in Section 1.2, assess whether the GenAI tools are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|Learners must have some initial aims for creating art or music, a foundational understanding of the key elements of the domain of art or music, and basic abilities to analyse the artworks or musical compositions.|Human teachers should ask learners to compare genai tools\u2019 art techniques with their own artwork.\n\nHuman teachers or coaches must encourage learners to develop and apply their imagination and creativity, which GenAI cannot replace.\n\nExample prompt: Suggest some ideas to inspire me to create an image on [topics/ideas].|May expose children to inappropriate or ofefnsive content, which may violate their right to safeguarding and well-being.\n\nGenAI tools raise the risk of stopping learners from developing their imagination and creativity.|\n|1:1 coach for coding or arithmetic|Conceptual programming knowledge and skills at the introductory level.\n\nIt might also apply to the learning of basic mathematics.|Supporting self- paced learning of basic coding knowledge and skills, finding bugs in learners\u2019 coding and providing immediate feedback, and tailoring answers to questions.\n\nPotential transformation: 1:1 coding teacher at introductory level|Starting with the list in Section 1.3, assess whether the GenAI tools are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|Finding and defining a problem, and designing algorithms to solve the problem, remain the core aspects of learning coding and programming.\n\nLearners must have intrinsic motivation to use the coding, along with some basic knowledge and skills in using the programming language.|Human teachers and coaches should teach basic knowledge and skills, and inspire learners to use computational thinking and programming to solve problems including through collaborative coding.\n\nExample prompt: Suggest some unusual ideas for coding.|The accuracy of feedback and suggestions remains a problematic issue as GenAI will not always be right.", "Example prompt: Suggest some unusual ideas for coding.|The accuracy of feedback and suggestions remains a problematic issue as GenAI will not always be right.\n\nThere is a high risk that GenAI tools will prevent learners from developing computational thinking skills and abilities to find and define meaningful problems for coding.|\n\n\n-----", "**5.3.4** **genai to facilitate inquiry or**\n\n**project-based learning**\n\nIf not used purposefully to facilitate higher-order\nthinking or creativity, GenAI tools tend to encourage\nplagiarism or shallow \u2018stochastic parroting\u2019 outputs.\n\nHowever, given that GenAI models have been trained\n\n\nbased on large-scale data, they have potential for\nacting as an opponent in Socratic dialogues or as a\nresearch assistant in project-based learning.\n\nYet these\npotentials can only be leveraged through instructional/\nlearning design processes that aim to trigger higherorder thinking as exemplified in **Table 6** .", "**Table 6.\n\nCo-designing uses of GenAI to facilitate inquiry or project-based learning**\n\n|Potential Appropriate Appropriate but domains of Expected GenAI tools and unproven knowledge or outcomes comparative uses problems advantages|Col2|Col3|Col4|Required human Requirements pedagogical Possible risks for the users methods and example prompts|Col6|Col7|\n|---|---|---|---|---|---|---|\n|Socratic challenger|Ill-structured problems.|Engage learners in dialogue reminiscent of the Socratic questioning of prior knowledge, leading to the discovery of new knowledge or deeper understanding.\n\nPotential transformation: 1:1 Socratic opponent|Starting with the list in Section 1.3, assess whether specific GenAI tools are locally accessible, open- source, rigorously tested and validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|The learner must have reached the age that allows them to conduct independent conversations with GenAI tools.\n\nLearners must have prior knowledge and abilities to check whether the arguments and information presented are accurate.|Human teachers may help prepare a list of gradually deeper questions as examples for learners to adapt into prompts.\n\nLearners may also start with a broad prompt such as \u2018Engage me in a Socratic dialogue in order to help me take a critical perspective towards [topic x]\u2019 and then gradually deepen the dialogue through increasingly refined prompts.|The current GenAI tools may generate similar or standard answers that limit learners\u2019 exposure to diverse viewpoints and alternative perspectives, leading to an echo-chamber efefct, and hinder the development of independent thinking.|\n|Advisor for project-based learning|Ill-structured research problems in science or social studies.|Support knowledge creation through helping learners to conduct project-based learning.\n\nThis includes GenAI playing a role that is similar to the research advisor described in Table 3.\n\nPotential transformation: 1:1 project- based learning coach|Starting with the list in Section 1.3, assess whether the GenAI tools are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|Learners could act as junior researchers in planning and implementing project-based learning.\n\nThe learners must be old enough for the independent use of GenAI platforms.\n\nLearners must have the motivation and ability to engage in self-directed project-based learning activities, so that they are not tempted to passively copy and paste the answers provided by GenAI tools.|Human teachers guide learners to ask GenAI to provide basic ideas for the definition of research problems as suggested in 5.3.1.\n\nIndividual and group learners use GenAI tools to conduct literature reviews, collect and process data, and create reports.|Learners without the solid prior knowledge and the ability necessary to verify the accuracy of answers may be misled by the information that GenAI tools provide.\n\nIt may also limit learners\u2019 discussions and interactions with peers and reduce opportunities for collaborative learning, potentially harming their social development.|\n\n\n-----", "**5.3.5** **genai to support learners with special needs**\n\nTheoretically, GenAI models have the potential to\nhelp learners with hearing or visual impairments.\n\nThe emerging practices include GenAI-enabled\nsubtitles or captions for deaf and hard-of-hearing\nlearners, and GenAI-generated audio description for\nvisually impaired learners.\n\nGenAI models can also\nconvert text to speech and speech to text to enable\npeople with visual, hearing, or speech impairments\nto access content, ask questions, and communicate\nwith their peers.\n\nHowever, this function has not yet\nbeen leveraged at scale.\n\nAccording to the survey\nmentioned earlier, conducted by UNESCO in 2023\non governments\u2019 use of genai in education, only four\ncountries (China, Jordan, Malaysia and Qatar) reported\nthat their governmental agencies had validated\nand recommended genai-assisted tools to support\ninclusive access for learners who have disabilities\n(UNESCO, 2023 _c_ ).\n\nThere is also a trend toward iterations of GenAI\nmodels being trained to support learners to use their\nown languages, including minority and indigenous\nlanguages, to learn and communicate.\n\nFor example,\n\n\nPaLM 2, Google\u2019s next-generation LLM, is trained on\nparallel data covering hundreds of languages in the\nform of source and target text pairs.\n\nThe inclusion\nof parallel multilingual data is designed to further\nimprove the model\u2019s ability to understand and\ngenerate multilingual text (Google, 2023 _b_ ).\n\nBy providing real-time translations, paraphrasing, and\nautomatic correction, GenAI tools have the potential\nto help learners who use minority languages to\ncommunicate ideas and enhance their collaboration\nwith peers from different linguistic backgrounds.\n\nHowever, this will not happen naturally at scale.\n\nOnly\nwith purposeful design can this potential be leveraged\nto amplify the voices of marginalized groups.\n\nFinally, it has also been suggested that GenAI systems\nhave the potential to carry out conversation-based\ndiagnoses, identifying psychological or social-emotional\nproblems as well as learning difficulties.\n\nHowever, there\nremains little evidence that this approach is either\neffective or safe, and any diagnoses would require\ninterpretation by skilled professionals.", "**Table 7.\n\nCo-designing uses of GenAI to support learners with special needs**\n\n|Potential Appropriate Appropriate but domains of Expected GenAI tools and unproven knowledge or outcomes comparative uses problems advantages|Col2|Col3|Col4|Required human Requirements pedagogical Possible risks for the users methods and example prompts|Col6|Col7|\n|---|---|---|---|---|---|---|\n|Conversational diagnosis of learning difficulties|This might be helpful for learners who are facing learning difficulties caused by psychological, social or emotional problems.|Using natural- language engagement to identify the needs of learners who have psychological, social or emotional problems or learning difficulties, in order to provide them with relevant support or instruction.\n\nPotential transformation: 1:1 primary advisor for learners with social or emotional problems or learning difficulties|In addition to general GenAI tools, search for chatbots powered by GenAI.\n\nAssess whether they are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|Teachers or specialists who work with this group of learners will need to ensure that the primary advice suggested by the GenAI system is accurate.|Teachers or facilitators need to provide comfortable environments to engage the learner in a conversation in order to diagnose psychological, social, or emotional problems, or learning difficulties.|May inadvertently misdiagnose the learner\u2019s specific challenges, leading to the wrong support being provided.|\n\n\n-----\n\n|Potential Appropriate Appropriate but domains of Expected GenAI tools and unproven knowledge or outcomes comparative uses problems advantages|Col2|Col3|Col4|Required human Requirements pedagogical Possible risks for the users methods and example prompts|Col6|Col7|\n|---|---|---|---|---|---|---|\n|genai-powered accessibility tools|These enable learners with hearing or visual impairment to access a wider range of content, thus improving the quality of their learning.|Meeting learners\u2019 access needs and supporting their acquisition of subject-specific knowledge by providing GenAI-enabled captioning and/ or sign language interpretation for audio or video content, and audio descriptions for text or other visual material.\n\nPotential transformation: 1:1 personalized genai-powered language aids|In addition to general GenAI tools, search for relevant and trusted genai-powered generators of captions and audio descriptions.\n\nAssess whether they are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|The educators or facilitators must help learners access and learn how to operate the GenAI tools.\n\nThey also need to ensure that the tools\u2019 outputs genuinely support these learners and do not reinforce the challenges and biases that they face.|Need to test the accessibility of platforms or tools to identify and fix accessibility issues before they are used.\n\nGenAI tools can only provide access to content, so educators and facilitators should focus on enhancing their quality of learning and social well-being.\n\nEducators and facilitators need to teach the learners to create voice or text prompts based on their abilities.|The captions or audio descriptions produced by GenAI platforms that are not designed specifically to support vision or hearing are often inaccurate and may mislead learners with special needs.\n\nThese tools may inadvertently reinforce existing biases.|\n|Generative amplifier for marginalized learners|It might be helpful for learners from minority linguistic or cultural backgrounds to express and amplify their voices, to participate online, and to conduct collaborative social studies.|Providing real- time translations, paraphrasing, and automatic correction of writing to support learners from marginalized groups to use their own languages to communicate with peers from difefrent linguistic backgrounds.\n\nPotential transformation: Inclusive LLMs for marginalized learners|A specific example for consideration is PaLM 2.\n\nAssess whether the GenAI tools are locally accessible, open source, rigorously tested or validated by authorities.\n\nFurther consider the advantages and challenges of any particular GenAI tool, and ensure that it properly addresses specific human needs.|The learners should have knowledge or meaningful opinions on the topic of the conversation or collaborative study.", "They need to be capable of making responsible and non-discriminatory contributions and avoiding hate speech.|Teachers or educators should design studies and writing tasks for learners on social or cultural topics, or organize online seminars or intercultural collaborations to stimulate learners to generate ideas and share opinions.|Need to identify and correct the errors in genai translations and paraphrasing that may cause intercultural misunderstandings.\n\nThis use can provide opportunities for marginalized learners to amplify their voices, but will not touch the root cause of data poverty and therefore cannot decolonize genai tools.|\n\n\n-----", "**6.2 Copyright and intellectual**\n\n**property**\n\nThe emergence of GenAI is rapidly changing the way in\nwhich scientific, artistic and literary works are created,\ndistributed and consumed.\n\nUnauthorized copying,\ndistribution or use of copyrighted works without\npermission from the copyright holder violates their\nexclusive rights and can lead to legal consequences.\n\nFor example, the training of GenAI models has been\naccused of infringing copyright.\n\nIn one of the recent\ncases, the genai-generated song featuring \u2018Drake\u2019 and \u2018The\nWeeknd\u2019 (Abel Tesfaye) reached millions of listeners\nbefore being taken offline due to a copyright dispute\n(Coscarelli, 2023).\n\nWhile the emerging regulatory\nframeworks intend to require GenAI providers to\nrecognize and protect the intellectual property of\nthe owners of the content used by the model, it is\nbecoming increasingly challenging to determine the\nownership and originality of the overwhelming amount\nof generated works.\n\nThis lack of traceability not only\nraises concerns about protecting the rights of creators\nand ensuring fair compensation for their intellectual\ncontributions, but also introduces challenges into\neducational contexts about how the output of GenAI\ntools may responsibly be used.\n\nThis may have profound\nimplications for the research system.", "**6.3 Sources of content and learning**\n\nGenAI tools are changing the way teaching and\nlearning content can be generated and provided.\n\nIn the future, content generated through humanAI conversations may become one of the main\nsources of knowledge production.\n\nThis is likely to\nfurther undermine learners\u2019 direct engagement with\neducational content based on resources, textbooks\nand curricula created and validated by humans.\n\nThe\nauthoritative appearance of GenAI text may mislead\nyoung learners who do not have sufficient prior\nknowledge to be able to recognize inaccuracies or to\nquestion it effectively.\n\nWhether learners\u2019 engagement\nwith unvalidated content should be recognized as\n\u2018learning\u2019 is also contestable.\n\nGenAI technologies are still rapidly evolving and likely\nto have a profound impact on education and research,\nand are yet to be fully understood.\n\nTherefore, their\npotential long-term implications for education and\nresearch need immediate attention and further indepth review.", "**6.1 Uncharted ethical issues**\n\nThe increasingly sophisticated GenAI tools will raise\nadditional ethical concerns that need to be examined\nin detail.\n\nFurther to Sections 2 and 3, deeper and more\nforward-looking analyses are needed to reveal and\naddress uncharted ethical issues from at least the\nfollowing five perspectives:\n\n-  \u0007 **Access and equity:** GenAI systems in\neducation may exacerbate existing disparities\nin access to technology and educational\nresources, further deepening inequities.\n\n-  \u0007 **Human connection** : GenAI systems in\neducation may reduce human-to-human\ninteraction and the critical social-emotional\naspects of learning.\n\n-  **\u0007** **Human intellectual development** : GenAI\nsystems in education may limit learners\u2019\nautonomy and agency by providing\npredetermined solutions or narrowing the\nrange of possible learning experiences.\n\nTheir long-term impact on young learners\u2019\nintellectual development needs to be\ninvestigated.\n\n-  **\u0007** **Psychological impact** : GenAI systems that\nmimic human interactions may have unknown\npsychological effects on learners, raising\nconcerns about their cognitive development\nand emotional well-being, and about the\npotential for manipulation.\n\n-  **\u0007** **Hidden bias and discrimination** : As more\nsophisticated GenAI systems are being\ndeveloped and applied in education, they are\nlikely to generate new biases and forms of\ndiscrimination based on the training data and\nmethods used by the models, which can result\nin unknown and potentially harmful outputs.\n\n-----\n\nThe resultant concentration on aggregated\nsecond-hand information may also reduce learners\u2019\nopportunities for constructing knowledge through\nproven methods such as directly perceiving and\nexperiencing the real world, learning from trial\nand error, performing empirical experiments, and\ndeveloping common sense.\n\nIt may also threaten the\nsocial construction of knowledge and the fostering of\nsocial values through collaborative classroom practices.", "**6.4 Homogenized responses versus**\n\n**diverse and creative outputs**\n\nGenAI narrows plural narratives as the outputs\ngenerated tend to represent and reinforce dominant\nviewpoints.\n\nThe resulting homogenization of\nknowledge limits pluralistic and creative thinking.\n\nThe increased dependency of teachers and students\non GenAI tools to seek suggestions may lead to\nthe standardization and conformity of responses,\nweakening the value of independent thought and\nself-directed inquiry.\n\nThe potential homogenization\nof expression in written pieces and artwork can\nlimit learners\u2019 imagination, creativity and alternative\nperspectives of expressions.\n\nGenAI providers and educators need to consider the\nextent to which EdGPT might be developed and used\nto foster creativity, collaboration, critical thinking and\nother higher-order thinking skills.", "**6.5 Rethinking assessment and**\n\n**learning outcomes**\n\nThe implications of GenAI for assessment go far beyond\nthe immediate concerns about learners cheating on\nwritten assignments.\n\nWe must contend with the fact\nthat GenAI can produce relatively well-organized\npapers and essays and impressive works of art, and can\npass some knowledge-based exams in certain subject\nareas.\n\nWe therefore need to rethink what exactly should\nbe learned and to what ends, and how learning is to be\nassessed and validated.\n\nCritical discussion by educators, policy-makers, learners\nand other stakeholders need to consider the following\nfour categories of learning outcomes:\n\n\n**Values:** The values required to ensure the humancentred design and use of technology are central\nto the rethinking of learning outcomes and their\nassessment in the digital era.\n\nIn revisiting the\npurpose of education, the values that inform the\nway in which technology relates to education\nshould be made explicit.\n\nIt is through this\nnormative lens that learning outcomes and their\nassessment and validation need to be iteratively\nupdated to respond to the increasingly pervasive\nuse of technology, including genai, in society.\n\n**Foundational knowledge and skills:** Even\nin the domains of competencies where GenAI\ntools can do better than humans, learners will\nstill need sound foundational knowledge and\nskills.\n\nFoundational literacy, numeracy and\nbasic scientific literacy skills will remain key for\neducation in the future.\n\nThe scope and nature of\nthese foundational skills will need to be regularly\nrevisited to reflect the increasingly genai-rich\nenvironments we live in.\n\n**Higher-order thinking skills:** Learning outcomes\nwill need to include skills required to support\nhigher-order thinking and problem solving\nbased on human-genai collaboration and the use\nof GenAI-generated outputs.\n\nThese may include\nunderstanding the roles of factual and conceptual\nknowledge in grounding higher-order thinking,\nand the critical evaluation of genai-generated\ncontent.\n\n**Vocational skills needed to work with genai:** In the\ndomains where genai can do better than humans and\nis automating task units, human learners need to\nnurture new skills that enable them to develop,\noperate and work with GenAI tools.\n\nThe redesign\nof learning outcomes and educational assessment\nwill need to reflect the vocational skills required\nfor the new jobs created by genai.", "**6.6 Thinking processes**\n\nThe most fundamental perspective of the long-term\nimplications of GenAI for education and research is\nstill about the complementary relationship between\nhuman agency and machines.\n\nOne of the key questions\nis whether humans can possibly cede basic levels of\nthinking and skill-acquisition processes to genai and rather\nconcentrate on higher-order thinking skills based on\nthe outputs provided by genai.\n\n-----\n\nWriting, for example, is often associated with the\nstructuring of thinking.\n\nWith GenAI, rather than starting\nfrom scratch to plan the aims, scope and outline of\na set of ideas, humans can now start with a wellstructured outline provided by GenAI.\n\nSome experts\nhave characterized the use of GenAI to generate\ntext in this way as \u2018writing without thinking\u2019 (Chayka,\n2023).\n\nAs these new GenAI-assisted practices become\nmore widely adopted, established methods for the\nacquisition and assessment of writing skills will need\nto adapt.\n\nOne option in the future is that the learning\nof writing may focus on building skills in planning and\ncomposing prompts, critical evaluation of the GenAI\noutputs, and higher-order thinking, as well as on cowriting based on GenAI\u2019s outlines.", "**Concluding remarks**\n\nFrom the perspective of a human-centred approach, genai\ntools should be designed to extend or augment human\nintellectual abilities and social skills, and not undermine\nthem, conflict with them or usurp them.\n\nIt has long\nbeen expected that genai tools can be further integrated\nas part and parcel of the tools available to humans\n\n\nto support analysis and action for more inclusive and\nsustainable futures.\n\nFor genai to be a trustable part and parcel of humanmachine collaboration \u2013 at individual, institutional and\nsystem levels \u2013 the human-centred approach informed\nby the 2021 UNESCO _Recommendation on the Ethics of_\n_AI_ is to be further specified and implemented according\nto the specific characteristics of emerging technologies\nsuch as GenAI.\n\nOnly in this way can we ensure that\nGenAI becomes a trustworthy tool for researchers,\nteachers and learners.\n\nWhile GenAI should be used to serve education and\nresearch, we all need to be cognizant that GenAI\nmight also change the established systems and their\nfoundations in these domains.\n\nThe transformation of\neducation and research to be triggered by GenAI, if\nany, should be rigorously reviewed and steered by a\nhuman-centred approach.\n\nOnly by doing so can we\nensure that the potentials of genai in particular, and all\nother categories of technologies used in education\nmore broadly, enhance human capabilities to build\ninclusive digital futures for all.\n\n-----", "#### Guidance for genai\n\nin education and research\n\nThis Guidance aims to support the planning of appropriate regulations, policies\nand human capacity development programmes to ensure that generative artif cial\nintelligence (GenAI) becomes a tool that genuinely benef ts and empowers teachers,\nlearners and researchers.\n\nIt explains the genai techniques used by GenAI and maps\nout a list of GPT models that are made publicly available, especially those under\nopen-source licences.\n\nIt also opens a discussion on the emergence of EdGPT \u2013\nGenAI models that are trained with specif c data to serve educational purposes.\n\nFurthermore, it summarizes some of the key controversies around GenAI, from\nworsening digital poverty to the homogenization of opinions, and from deeper\ndeepfakes to issues of copyright.\n\nBased on a humanistic vision, the Guidance\nproposes key steps for the regulation of GenAI tools, including mandating the\nprotection of data privacy and setting an age limit for independent conversations\nwith GenAI platforms.\n\nTo guide the proper use of the tools in education and research,\nthis Guidance proposes a human-agent and age-appropriate approach to the ethical\nvalidation and pedagogical design processes.\n\n9 789231 006128\n\n\n-----", "##### Acknowledgements\b 6\n\nForeword\b 7\n\n Principles\b 8\n\nPrinciple 1: You know what genai is and what its limitations are\b 8\n\nPrinciple 2: You use genai lawfully, ethically and responsibly\b 8\n\nPrinciple 3: You know how to keep genai tools secure \b 9\n\nPrinciple 4: You have meaningful human control at the right stage\b 10\n\nPrinciple 5: You understand how to manage the full genai lifecycle \b 10\n\nPrinciple 6: You use the right tool for the job\b 11\n\nPrinciple 7: You are open and collaborative\b 11\n\nPrinciple 8: You work with commercial colleagues from the start\b 12\n\nPrinciple 9: You have the skills and expertise that you need to build\nand use genai\b 12\n\nPrinciple 10: You use these principles alongside your organisation\u2019s\npolicies and have the right assurance in place\b 12", "##### Building genai solutions\b 17\n\nDefining the goal\b 17\n\nIdentifying use cases\b 17\n\nUse cases to avoid\b 18\n\nBuilding the team\b 19\n\nAcquiring skills\b 20\n\nCreating the genai support structure\b 21\n\n\n-----\n\nBuying genai\b 22\n\nExisting guidance\b 23\n\nRoutes to market\b 23\n\nSpecifying your requirements\b 25\n\nRunning your procurement\b 25\n\nProcurement in an emerging market\b 26\n\nAligning procurement and ethics \b 26\n\nBuilding the solution\b 27\n\nCore concepts\b 27\n\nPatterns\b 29\n\nPicking your tools\b 32\n\nGetting reliable results\b 36\n\nTesting genai solutions\b 39\n\nData management\b 40", "##### Using genai safely and responsibly\b 41\n\nLegal considerations\b 41\n\nExample legal issues\b 41\n\nEthics\b 43\n\nTransparency and explainability\b 44\n\nAccountability and responsibility\b 46\n\nFairness, bias and discrimination\b 47\n\nInformation quality and misinformation\b 49\n\nMaintaining appropriate human involvement in automated processes\b 50\n\nSustainability and environmental considerations\b 51\n\nData protection and privacy\b 52\n\nAccountability\b 53\n\nLawfulness and purpose limitation\b 54\n\nTransparency and individual rights\b 56\n\nFairness\b 57\n\nData minimisation\b 58\n\nStorage limitation\b 59\n\nHuman oversight\b 60\n\nAccuracy\b 61\n\n\n-----\n\nSecurity\b 62\n\nHow to deploy genai securely\b 62\n\nSecurity risks\b 65\n\nGovernance\b 73\n\ngenai governance board or genai representation on an existing board\b 73\n\nEthics committee\b 73\n\nCreating an genai/ML systems inventory\b 74\n\nProgramme governance in teams and what should be considered\b 74\n\n\n-----", "## Acknowledgements\n\nThe publication of this report has been made possible by the support from\na large number of stakeholders.\n\nCentral government department contributions have come from the Home Office (HO),\nDepartment for Environment, Food and Rural Affairs (Defra), Department for Business and\nTrade (DBT), Foreign, Commonwealth and Development Office (FCDO), Department for\nScience, Innovation and Technology (DSIT), Cabinet Office (CO), Department for Work\nand Pensions (DWP), HM Treasury (HMT), HM Revenue and Customs (HMRC), Ministry\nof Defence (MOD), Ministry of Justice (MOJ), Department for Levelling Up, Housing and\nCommunities (DLUHC), Department of Health and Social Care (DHSC), Department for\nTransport (DfT), Crown Commercial Service (CCS), Government Legal Department (GLD)\nand No.10 Data Science team.\n\nArm\u2019s length bodies, devolved administrations and public sector bodies\u2019 contributions have\ncome from the National Health Service (NHS), HM Courts and Tribunals Service (HMCTS),\nGovernment Internal Audit Agency (GIAA), Information Commissioner\u2019s Office (ICO), Office\nfor National Statistics (ONS), Driver and Vehicle Licensing Agency (DVLA), Met Office,\nGovernment Communications Headquarters (GCHQ) and Scottish Government.\n\nIndustry leaders and expert contributions have come from Amazon, Microsoft, IBM, Google,\nBCG, the Alan Turing Institute, the Oxford Internet Institute, and the Treasury Board of\nCanada Secretariat.\n\nUser research participants have come from a range of departments and have been very\ngenerous with their time.\n\n-----", "## Foreword\n\nAt the time of writing, it has been a year since genai\n(genai) burst into public awareness with the release of ChatGPT.\n\nIn that time, the\nability of this technology to produce text, images and video has captured the\nimagination of citizens, businesses and civil servants.\n\nThe last year has been a\nperiod of experimentation, discovery and education, where we have explored the\npotential \u2013 and the limitations \u2013 of genai.\n\nIn 2021, the National genai Strategy set out a 10 year vision that recognised the power of\ngenai to increase resilience, productivity, growth and innovation across the private and public\nsectors.\n\nThe 2023 white paper A pro-innovation approach to genai regulation sets out the\ngovernment\u2019s proposals for implementing a proportionate, future-proof and pro-innovation\nframework for regulating genai.\n\nWe published initial guidance on genai in June 2023,\nencouraging civil servants to gain familiarity with the technology, while remaining aware of\nrisks.\n\nWe are now publishing this expanded framework, providing practical considerations\nfor anyone planning or developing a genai solution.\n\ngenai has the potential to unlock significant productivity benefits.\n\nThis framework\naims to help readers understand genai, to guide anyone building genai\nsolutions, and, most importantly, to lay out what must be taken into account to use\ngenai safely and responsibly.\n\nIt is based on a set of ten principles which should be\nborne in mind in all genai projects.\n\nThis framework differs from other technology guidance we have produced: it is necessarily\n_incomplete_ and _dynamic_ .\n\nIt is _incomplete_ because the field of genai is developing\nrapidly and best practice in many areas has not yet emerged.\n\nIt is _dynamic_ because we\nwill update it frequently as we learn more from the experience of using genai across\ngovernment, industry and society.\n\nIt does not aim to be a detailed technical manual: there are many other resources for that.\n\nIndeed, it is intended to be accessible and useful to non-technical readers as well as to\ntechnical experts.\n\nHowever, as our body of knowledge and experience grows, we will add\ndeeper dive sections to share patterns, techniques and emerging best practice (for example\nprompt engineering).\n\nFurthermore, although there are several forms of genai, this\nframework focuses primarily on large language models (LLMs), as these have received the\nmost attention, and have the greatest level of immediate application in government.\n\nFinally, I would like to thank all of the people who have contributed to this framework.\n\nIt has\nbeen a collective effort of experts from government departments, arm\u2019s length bodies, other\npublic sector organisations, academic institutions and industry partners.\n\nI look forward\nto continued contributions from a growing community as we gain experience in using\ngenai safely, responsibly and effectively.", "## Principles\n\nWe have defined ten common principles to guide the safe, responsible and\neffective use of genai in government organisations.\n\nThe white paper\nA pro-innovation approach to genai regulation , sets out five principles to guide and\ninform genai development in all sectors.\n\nThis framework builds on those principles\nto create ten core principles for genai use in government and public\nsector organisations.\n\nPosters on each of the ten principles for you to display in your government\norganisation are available on GOV.UK.", "#### Principle 1: You know what genai is and what its limitations are\n\ngenai is a specialised form of genai that can interpret and generate high-quality outputs\nincluding text and images, opening up the potential for opportunities for organisations,\nincluding delivering efficiency savings or developing new language capability.\n\nYou actively learn about genai technology to gain an understanding of what it can\nand cannot do, how it can help and the potential risks it poses.\n\nLLMs lack personal experiences and emotions and don\u2019t inherently possess real-world\ncontextual awareness, but some now have access to the internet.\n\ngenai tools are not guaranteed to be accurate as they are generally designed only\nto produce highly plausible and coherent results.\n\nThis means that they can, and do, make\nerrors.\n\nYou will need to employ techniques to increase the relevance and correctness of\ntheir outputs, and have a process in place to test them.\n\nYou can find out more about what\ngenai is in our Understanding genai section and what it can and cannot do\nfor you in the Building genai solutions section.", "#### Principle 2: You use genai lawfully, ethically and responsibly\n\ngenai brings specific ethical and legal considerations, and your use of genai\ntools must be responsible and lawful.\n\nYou should engage with compliance professionals, such as data protection, privacy and\nlegal experts in your organisation early in your journey.\n\nYou should seek legal advice on\nintellectual property, equalities implications, and fairness and data protection implications for\nyour use of genai.\n\nYou need to establish and communicate how you will address ethical concerns from the\nstart, so that diverse and inclusive participation is built into the project lifecycle.\n\n-----\n\ngenai models can process personal data so you need to consider how you protect\npersonal data, are compliant with data protection legislation and minimise the risk of privacy\nintrusion from the outset.\n\ngenai models are trained on large data sets, which may include biased or harmful\nmaterial, as well as personal data.\n\nBiases can be introduced throughout the entire lifecycle\nand you need to consider testing and minimising bias in the data at all stages.\n\ngenai should not be used to replace strategic decision making.\n\ngenai has hidden environmental issues that you and your organisation should\nunderstand and consider before deciding to use genai solutions.\n\nYou should use\ngenai technology only when relevant, appropriate, and proportionate, choosing the\nmost suitable and sustainable option for your organisation\u2019s needs.\n\nYou should also use the genai regulation white paper \u2019s fairness principle, which states that\ngenai systems should not undermine the legal rights of individuals and organisations.\n\nAnd that\nthey should not discriminate against individuals or create unfair market outcomes.\n\nYou can find out more in our Using genai safely and responsibly section.", "#### Principle 3: You know how to keep genai tools secure\n\ngenai tools can consume and store sensitive government information and personal\nidentifiable information if the proper assurances are not in place.\n\nWhen using generative\ngenai tools, you need to be confident that your organisation\u2019s data is held securely, and\nthat the genai tool can only access the parts of your organisation\u2019s data that it\nneeds for its task.\n\nYou need to ensure that private or sensitive data sources are not being used to train\ngenai models without the knowledge or consent of the data owner.\n\ngenai tools are often hosted in places outside your organisation\u2019s secure network.\n\nYou must make sure that you understand where the data you give to a genai tool is\nprocessed, and that it is not stored or accessible by other organisations.\n\nGovernment data can contain sensitive and personal information that must be processed\nlawfully, securely and fairly at all times.\n\nYour approach must comply with the data\nprotection legislation.\n\nYou need to build in safeguards and put technical controls in place.\n\nThis includes content\nfiltering to detect malicious activity and validation checks to ensure responses are accurate\nand do not leak data.\n\nYou can find out more in our Security , Data protection and privacy , and Building the\nsolution sections.\n\n-----", "#### Principle 4: You have meaningful human control at the right stage\n\nWhen you use genai you need to make sure that there are processes for quality\nassurance controls which include an appropriately trained and qualified person to review\nyour genai tool\u2019s outputs and validation of all decision making that genai\noutputs have fed into.\n\nWhen you use genai to embed chatbot functionality into a website, or other uses\nwhere the speed of a response to a user means that a human review process is not\npossible, you need to be confident in the human control at other stages in the product\nlifecycle.\n\nYou must have fully tested the product before deployment, and have robust\nassurance and regular checks of the live tool in place.\n\nSince it is not possible to build\nmodels that never produce unwanted or fictitious outputs (i.e.\n\nhallucinations), incorporating\nend-user feedback is vital.\n\nPut mechanisms into place that allow end-users to report\ncontent and trigger a human review process.\n\nYou can find out more in our Ethics , Data protection and privacy , Building the solution\nand Security sections.", "#### Principle 5: You understand how to manage the full genai lifecycle\n\ngenai tools, like other technology deployments, have a full project lifecycle that you\nneed to understand.\n\nYou and your team must know how to choose a genai tool and how to set it up.\n\nYou need to have the right resource in place to support day-to-day maintenance of the tool.\n\nYou need to know how to update the system, and how to close the system securely down\nat the end of your project.\n\nYou need to understand how to monitor and mitigate genai drift, bias and\nhallucinations.\n\nYou have a robust testing and monitoring process in place to catch\nthese problems.\n\nYou should use the Technology code of practice to build a clear understanding of\ntechnology deployment lifecycles, and understand and use the National Cyber Security\nCentre cloud security principles .\n\nYou should understand the benefits, other use cases and applications that your solution\ncould support across government.\n\nThe provides guidance on governmentwide knowledge assets and The Government Office for Technology Transfer Rose Book can provide\nsupport and funding to help develop government-wide solutions.\n\nIf you develop a service you must use the Service Standard for government.\n\nYou can find out more about development best practices for genai in our Building\nthe solution section.\n\n-----", "#### Principle 6: You use the right tool for the job\n\nYou should ensure you select the most appropriate technology to meet your needs.\n\ngenai is good at many tasks but has a number of limitations and can be expensive\nto use.\n\nYou should be open to solutions using genai as they can allow organisations\nto develop new or faster approaches to the delivery of public services, and can provide\na springboard for more creative and innovative thinking about policy and public sector\nproblems.\n\nYou can create more space for you and your people to problem solve by using\ngenai to support time-consuming administrative tasks.\n\nWhen building genai solutions you should make sure that you select the most\nappropriate deployment patterns and choose the most suitable genai model for\nyour use case.\n\nYou can find out about how to choose the right genai technology for your task or\nproject in our Identifying use cases , Patterns , Picking your tools and Things to consider\nwhen evaluating LLMs sections.", "#### Principle 7: You are open and collaborative\n\nThere are lots of teams across government who are interested in using genai tools\nin their work.\n\nYour approach to any genai project should make use of existing crossgovernment communities, where there is a space to solve problems collaboratively.\n\nYou should identify which groups, communities, civil societies, non-governmental\norganisations, academic organisations and public representative organisations have an\ninterest in your project.\n\nYou should have a clear plan for engaging and communicating with\nthese stakeholders at the start of your work.\n\nYou should seek to join cross-government communities and engage with other government\norganisations.\n\nFind other departments who are trying to address similar issues and learn\nfrom them, and also share your insights with others.\n\nYou should reuse ideas, code and\ninfrastructure where possible.\n\nAny automated response visible to the public such as via a chatbot interface or\nemail should be clearly identified as such (e.g.\n\n\u201cThis response has been written by an\nautomated genai-chatbot\u201d).\n\nYou should be open with the public about where and how algorithms and genai systems are\nbeing used in official duties (e.g.\n\nGOV.UK digital blogs).\n\nThe UK Algorithmic Transparency\nRecording Standard (ATRS) provides a standardised way to document information about\nthe algorithmic tools being used in the public sector with the aim to make this information\nclearly accessible to the public.\n\nYou can find out more in our Ethics section.\n\n-----", "#### Principle 8: You work with commercial colleagues from the start\n\ngenai tools are new and you will need specific advice from commercial colleagues\non the implications for your project.\n\nYou should reach out to commercial colleagues early in\nyour journey to understand how to use genai in line with commercial requirements.\n\nYou should work with commercial colleagues to ensure that the expectations around the\nresponsible and ethical use of genai are the same between in-house developed genai\nsystems and those procured from a third party.\n\nFor example, procurement contracts can\nrequire transparency from the supplier on the different information categories as set out in\nthe Algorithmic Transparency Recording Standard (ATRS) .\n\nYou can find out more in our Buying genai section.", "#### Principle 9: You have the skills and expertise that you need to build and use genai\n\nYou should understand the technical requirements for using genai tools, and have\nthem in place within your team.\n\nYou should know that genai requires an understanding of new skills such as prompt\nengineering and you, or your team, should have the necessary skill set.\n\nYou should take part in available Civil Service learning courses on genai, and\nproactively keep track of developments in the field.\n\nYou can find out more in our Acquiring skills section.", "#### Principle 10: You use these principles alongside your organisation\u2019s policies and have the right assurance in place\n\nThese principles and this framework set out a consistent approach for the use of generative\ngenai tools for UK government.\n\nWhile you should make sure that you use these principles\nwhen working with genai, many government organisations have their own\ngovernance structures and policies in place, and you also should follow any organisationspecific policies.\n\nYou need to understand, monitor and mitigate the risks that using a genai tool can\nbring.\n\nYou need to connect with the right assurance teams in your organisation early in the\nproject lifecycle for your genai tool.\n\nYou need to have clearly documented review and escalation processes in place.\n\nThis might\nbe a genai review board, or a programme-level board.\n\nYou can find out more in our Governance section.\n\n-----", "## Understanding genai\n\nThis section explains what genai is, the applications of generative\ngenai in government and the limitations of genai and LLMs.\n\nIt supports\nPrinciple 1: You know what genai is and what its limitations are.\n\nThis section is centred on explaining genai and its limitations.\n\nYou can find explanations of the core concepts around managing, choosing\nand developing genai solutions in the Building genai\nsolutions section.", "#### What is genai?\n\ngenai is a form of genai \u2013 a broad field which aims to use computers to emulate the\nproducts of human intelligence or to build capabilities which go beyond human intelligence.\n\nUnlike previous forms of genai, genai produces new content, such as images, text or\nmusic.\n\nIt is this capability, particularly the ability to generate language, which has captured\nthe public imagination, and creates potential applications within government.\n\ngenai fits within the broader field of genai as shown below:\n\nArtificial\nintelligence\n\n\nMachine\nlearning\n\nDeep\nlearning\n\nGenerative\ngenai\n\n\nAlgorithms that automatically\nlearn from data sets\n\nMachine learning using neural\nnetworks to automatically learn\nfrom large data sets\n\nNeural networks trained on huge\namounts of data and able to\ngenerate high-quality outputs\nincluding text and digital images\n\n\nModels which generate content are not new, and have been a subject of research for\nthe last decade.\n\nHowever, the launch of ChatGPT in November 2022 increased public\nawareness and interest in the technology, as well as triggering an acceleration in the market\nfor usable genai products.\n\nOther well known genai applications include\nClaude, Bard, Bedrock and Dall-E, which are LLMs.\n\n-----\n\nPublic LLM interfaces fit within the field of genai as shown below:\n\nGenerative\ngenai\n\n\nFoundation\nmodels\n\nLarge\nlanguage\nmodels\n\nUser\ninterfaces\ne.g.\n\nChatGPT\nand Bard\n\n\nA general purpose model trained\non large quantities of data\n\nFoundation models trained on text\nand able to interpret and generate\nhigh-quality outputs\n\nA publicly available service\nwith a simple user interface\nto access an LLM\n\n\n_Foundation models_ are large neural networks trained on extremely large datasets\nto produce responses which resemble those datasets.\n\nFoundation models may not\nnecessarily be language-based, and they could have been trained on non-text data, e.g.\n\nbiochemical information.\n\n_LLMs_ are foundation models specifically trained on text and natural language data to\ngenerate high-quality text based outputs.\n\n_User interfaces for foundation models and LLMs_ , are user-friendly ways that people without\ntechnical experience can use foundation models or LLMs.\n\nChatGPT and Bard are examples\nof these.\n\nAt present they are mostly accessed by tool-specific URLs, but they are likely to\nbe embedded into other consumer software and tools in the near future.\n\ngenai works by using large quantities of data, often harvested from the internet,\nto train a model in the underlying patterns and structure of that data.\n\nAfter many rounds\nof training, sometimes involving machines only, sometimes involving humans, the model is\ncapable of generating new content, similar to the training examples.\n\nWhen a user provides a prompt or input, the genai evaluates the likelihood of various possible\nresponses based on what it has learned from its training data.\n\nIt then selects and presents\nthe response that has the highest probability of being the right fit for the given prompt.\n\nIn\nessence, it uses its training to choose the most appropriate response for the user\u2019s input.\n\n-----", "#### Applications of genai in government\n\nDespite their limitations, the ability of LLMs to process and produce language is highly\nrelevant to the work of government, and could be used to:\n\n-  speed up delivery of services: retrieving relevant organisational information faster\n\nto answer citizen digital queries or routing email correspondence to the right parts\nof the business\n\n-  reduce staff workload: suggesting first drafts of routine email responses or computer\n\ncode to allow people more time to focus on other priorities\n\n-  perform complicated tasks: helping to review and summarise huge\n\namounts of information\n\n-  improve accessibility of government information: improving the readability and\n\naccessibility of information on webpages or reports\n\n-  perform specialist tasks more cost-effectively: summarising documentation that contains\n\nspecialist language like financial or legal terms, or translating a document into several\ndifferent languages\n\nHowever, LLMs and other forms of genai still have limitations: you should make sure\nthat you understand these, and that you build appropriate testing and controls into any\ngenai solutions.", "#### Limitations of genai and LLMs\n\nLLMs predict the next word in a sequence.\n\nThey don\u2019t understand the content or meaning\nof the words beyond how likely they are to be used in response to a particular question.\n\nThis means that even though LLMs can produce plausible responses to requests, there are\nlimitations on what they can reliably do.\n\nYou need to be aware of these limitations and have checks and assurance in place when\nusing genai in your organisation.\n\n-  Hallucination (also called confabulation): LLMs are primarily designed to prioritise the\n\nappearance of being plausible rather than focusing on ensuring absolute accuracy,\nfrequently resulting in the creation of content that appears plausible but may actually be\nfactually incorrect.\n\n-  Critical thinking and judgement: although LLMs can give the appearance of reasoning,\n\nthey are simply predicting the next most plausible word in their output, and may produce\ninaccurate or poorly-reasoned conclusions.\n\n-  Sensitive or ethical context: LLMs can generate offensive, biased, or inappropriate\n\ncontent if not properly guided, as they will replicate any bias present in the data they\nwere trained on.\n\n-  Domain expertise: unless specifically trained on specialist data, LLMs are not true\n\ndomain experts.\n\nOn their own, they are not a substitute for professional advice,\nespecially in legal, medical, or other critical areas where precise and contextually relevant\ninformation is essential.\n\n-----\n\n-  Personal experience and context: LLMs lack personal experiences and emotions.\n\nAlthough their outputs may appear as if they come from a person, they do not have true\nunderstanding or a consciousness.\n\n-  Dynamic real-time information retrieval: LLMs do not always have real-time access to\n\nthe internet or data outside their training set.\n\nHowever, this feature of LLM products is\nchanging.\n\nAs of October 2023, ChatGPT, Bard and Bing have been modified to include\naccess to real-time internet data in their results.\n\n-  Short-term memory: LLMs have a limited context window.\n\nThey might lose track of the\n\ncontext of a conversation if it\u2019s too long, leading to incoherent responses.\n\n-  Explainability: genai is based on neural networks, which are so-called \u2018black\n\nboxes\u2019.\n\nThis makes it difficult or impossible to explain the inner workings of the model\nwhich has potential implications if in the future you are challenged to justify decisioning\nor guidance based on the model.\n\nThese limitations mean that there are types of use cases where you should currently avoid\nusing genai, such as safety-of-life systems or those involving fully automated\ndecision-making which affects individuals.\n\nHowever, the capabilities and limitations of genai solutions are rapidly changing,\nand solution providers are continuously striving to overcome these limitations.\n\nThis means\nthat you should make sure that you understand the features of the products and services\nyou are using and how they are expected to change.\n\n-----", "## Building genai solutions\n\nThis section outlines the practical steps you\u2019ll need to take in building generative\ngenai solutions, including defining the goal, building the team, creating the\ngenai support structure, buying genai and building the solution.\n\nIt supports:\n\n-  Principle 1: You know what genai is and what its limitations are\n\n-  Principle 3: You know how to keep genai tools secure\n\n-  Principle 4: You have meaningful human control at the right stage\n\n-  Principle 5: You understand how to manage the full genai lifecycle\n\n-  Principle 6: You use the right tool for the job\n\n-  Principle 8: You work with commercial colleagues from the start\n\n-  Principle 9: You have the skills and expertise that you need to build\nand use genai\n\nHowever, following the guidance in this section is only part of what is needed\nto build genai solutions.\n\nYou also need to make sure that you are using\ngenai safely and responsibly.", "#### Defining the goal\n\nLike all technology, using genai is a means to an end, not an objective in itself.\n\nWhether planning your first use of genai or a broader transformation programme,\nyou should be clear on the goals you want to achieve and particularly, where you could use\ngenai, and where you should avoid it.\n\nGoals for the use of genai may include improved public services, improved\nproductivity, increased staff satisfaction, increased quality, cost savings and risk\nreduction.\n\nYou should make sure you know which goal you are seeking, and how you will\nmeasure outcomes.", "##### Identifying use cases\n\nWhen thinking about how you could leverage genai in your organisation you\nneed to consider the possible situations or use cases.\n\nThe identification of potential use\ncases should be led by business needs and user needs, rather than directed by what\nthe technology can do.\n\nEncourage business units and users to articulate their current\nchallenges and opportunities.\n\nTake the time to thoroughly understand users and their\nneeds as per the Service Manual to make sure you are solving the right problems.\n\n-----\n\nTry to focus on use cases that can only be solved by genai or where genai\noffers significant advantages above existing techniques.\n\nThe use of genai is still evolving, but the most promising use cases are likely to be\nthose which aim to:\n\n-  support digital enquiries: enable citizens to express their needs in natural language\n\nonline, and help them find the content and services which are most helpful to them\n\n-  interpret requests: analyse correspondence or voice calls to understand citizens\u2019 needs,\n\nand route their requests to the place where they can best get help\n\n-  enhanced search: quickly retrieving relevant organisational information or case notes\n\nto help answer citizens\u2019 queries\n\n-  synthesise complex data: help users to understand large amounts of data and text,\n\nby producing simple summaries\n\n-  generate output: produce first drafts of documents and correspondence\n\n-  assist software development: support software engineers in producing code,\n\nand understanding complex legacy code\n\n-  summarise text and audio: converting emails and records of meetings into structured\n\ncontent, saving time in producing minutes and keeping records\n\n-  improve accessibility: support conversion of content from text to audio, and translation\n\nbetween different languages", "##### Use cases to avoid\n\nGiven the current limitations of genai, there are many use cases where its use is not\nyet appropriate, and which should be avoided.\n\n-  Fully automated decision-making: any use cases involving significant decisions, such as\n\nthose involving someone\u2019s health or safety, should not be made by genai alone.\n\n-  High-risk / high-impact applications: genai should not be used on its own in\n\nhigh\u2011risk areas which could cause harm to someone\u2019s health, safety, fundamental rights,\nor to the environment.\n\n-  Low-latency applications: genai operates relatively slowly compared to other\n\ncomputer systems and should not be used in use cases where an extremely rapid,\nlow\u2011latency response is required.\n\n-  High-accuracy results: genai is optimised for plausibility rather than accuracy\n\nand should not be relied on as a sole source of truth, without additional measures to\nensure accuracy.\n\n-  High-explainability contexts: like other solutions based on neural networks, the inner\n\nworkings of a genai solution may be difficult or impossible to explain, meaning\nthat it should not be used where it is essential to explain every step in a decision.\n\n-----\n\n-  Limited data contexts: the performance of genai depends on large quantities\n\nof training data.\n\nSystems that have been trained on limited quantities of data, for\nexample in specialist areas using legal or medical terminology, may produce skewed or\ninaccurate results.\n\nThis list is not exhaustive: you should make sure that you understand the limitations\nof genai, as well as the features and roadmap of the products and\nservices you are using.", "#### Practical recommendations\n\nDefine clear goals for your use of genai, and ensure they are consistent\nwith your organisation\u2019s genai roadmap.\n\nSelect use cases which meet a clear need and fit the capabilities of genai.\n\nUnderstand the limitations of genai, and avoid high-risk use cases.\n\nFind out what use cases other government organisations are considering and see\nif you can share information or reuse their work.", "#### Building the team\n\nWhile public-facing genai services such as ChatGPT are easy to use and access,\nbuilding production-grade solutions which underpin services to citizens requires a range of\nskills and expertise.\n\nYou should aim to build a multi-disciplinary team which includes:\n\n-  business leaders and experts who understand the context and impact on\n\ncitizens and services\n\n-  data scientists who understand the relevant data, how to use it effectively, and how to\n\nbuild/train and test models\n\n-  software engineers who can build and integrate solutions\n\n-  user researchers and designers who can help understand user needs and design\n\ncompelling experiences\n\n-  support from legal, commercial and security colleagues, as well as ethics and data\n\nprivacy experts who can help you make your genai solution safe and responsible\n\nYou should ensure that you not only have the team in place to build your genai\nsolution, but that you have the capability to operate your solution in production.\n\nAs well as building a team which contains the right skills, you should strive to ensure that\nyour team includes a diversity of groups and viewpoints, to help you stay alert to risks of\nbias and discrimination.\n\n-----\n\ngenai is a new technology, and even if you have highly experienced experts in your\nteam, they will likely need to acquire new skills.", "##### Acquiring skills\n\nThe broad foundational skills required for working in the digital space are outlined in\nthe digital, data and technology capability framework including data roles, software\ndevelopment and user-centred design.\n\nTo help you acquire the more specific skills needed\nto build and run genai solutions, we have defined a set of open learning resources\navailable to all civil servants from within Civil Service Learning.\n\n-  genai \u2013 Introduction : in this course you will learn what genai is,\n\nwhat the main genai applications are, and their capabilities and potential\napplications across various domains.\n\nIt will also cover the limits and risks of genai\ntechnologies, including ethical considerations.\n\n-  genai \u2013 Risks and ethics : in this course you will learn about the generic risks\n\nand technical limitations of genai technologies.\n\nYou will consider the ethical implications\nof using genai, including the issues of bias, fairness, transparency and potential misuse.\n\nThe course also includes the dos and don\u2019ts of using genai in government.\n\n-  genai \u2013 Tools and applications : in this course you will learn about the most\n\nimportant genai tools and their functionalities.\n\n-  genai \u2013 Prompt engineering : in this course you will learn what prompt\n\nengineering is and how it can be used to improve the accuracy of genai tools.\n\n-  genai \u2013 Strategy and governance : in this course you will learn how to evaluate\n\nthe business value of genai and assess its potential impact on organisational culture and\ngovernance to develop a holistic genai strategy.\n\n-  genai \u2013 Technical curriculum : in this course you will learn about the\n\nfunctionalities of various genai technologies and cloud systems, including copilots.\n\nYou will\nalso consider how to address technical and innovation challenges concerning the\nimplementation and training of genai to generate customised outcomes.\n\nA series of off-the-shelf courses on more specific aspects of genai has been made\navailable on Prospectus online through the Learning Framework.\n\n-----\n\nYou should tailor your learning plan to meet the needs of five groups of learners.\n\n1.\n\nBeginners: all civil servants who are new to genai and need to gain an\n\nunderstanding of its concepts, benefits, limitations and risks.\n\nThe suggested courses\nprovide an introduction to genai, and do not require any previous knowledge.\n\n2.\n\nOperational delivery and policy professionals: civil servants who primarily use generative\n\ngenai for information retrieval and text generation purposes.\n\nThe recommended resources\nprovide the necessary knowledge and skills to make effective and responsible use of\nappropriate genai tools.\n\n3.\n\nDigital and technology professionals: civil servants with advanced digital skills who work\n\non the development of genai solutions in government.\n\nThe suggested learning\nopportunities address the technical aspects and implementation challenges associated\nwith fostering genai innovation.\n\n4.\n\nData and analytics professionals: civil servants who work on the collection, organisation,\n\nanalysis and visualisation of data.\n\nThe recommended resources focus on the use of\ngenai to facilitate automated data analysis, the synthesis of complex information,\nand the generation of predictive models.\n\n5.\n\nSenior civil servants: decision-makers who are responsible for creating a generative\n\ngenai\u2011ready culture in government.\n\nThese resources and workshops help understand\nthe latest trends in genai, and its potential impact on organisational culture,\ngovernance, ethics and strategy.", "#### Creating the genai support structure\n\nAs genai is a new technology, you should make sure that you have the structures in\nplace to support its adoption.\n\nThese structures do not need to be fully mature before your\nfirst project: indeed, your experience in your first project will shape the way you organise\nthese structures.\n\nHowever, you should ensure that you have sufficient control to make your\nuse of genai safe and responsible.\n\nThe supporting structures required for effective genai adoption are the same as\nthose required to support the broader adoption of other forms of genai.\n\nIf your organisation\nis already using other forms of genai, these structures may already be in place.\n\n-----\n\nIf you do not already have them in place, you should consider establishing:\n\n-  genai strategy and adoption plan: a clear statement of the way that you plan to use genai within\n\nyour organisation, including impact on existing organisation structures and change\nmanagement plans\n\n-  genai principles: a simple set of top level principles which embody your values and goals,\n\nand which can be followed by all people building solutions\n\n-  genai governance board: a group of senior leaders and experts to set principles, and to\n\nreview and authorise uses of genai which fit these principles\n\n-  communication strategy: your approach for engaging with internal and external\n\nstakeholders to gain support, share best practice and show transparency\n\n-  genai sourcing and partnership strategy: definition of which capabilities you will build within\n\nyour own organisation and which you will seek from partners", "#### Buying genai\n\nThe genai market is still new and developing engagement with commercial\ncolleagues is particularly important to discuss partners, pricing, products and services.\n\nCrown Commercial Service (CCS) can guide you through existing guidance, routes to\nmarket, specifying your requirements, and running the procurement process.\n\nThey can also\nhelp you navigate procurement in an emerging market and regulatory and policy landscape,\nas well as ensure that your procurement is aligned with ethical principles.\n\n-----", "##### Existing guidance\n\nThere is detailed guidance to support the procurement of genai in the public sector.\n\nYou should\nfamiliarise yourself with this guidance and make sure you\u2019re taking steps to align with\nbest practice.\n\n-  Guidelines for genai procurement : provides a summary of best practice when buying\n\ngenai technologies in government:\n\n-  preparation and planning: getting the right expertise, data assessments and\n\ngovernance, genai impact assessment and market engagement\n\n-  publication: problem statements, specification and avoiding vendor lock-in\n\n-  selection, evaluation and award : setting robust criteria and ensuring you have\n\nthe correct expertise\n\n-  contract implementation and ongoing management : managing your service,\n\ntesting for security and how to handle end of life considerations\n\n-  Digital, Data and Technology (DDaT) Playbook : provides general guidance on\n\nsourcing and contracting for digital and data projects and programmes, which all central\ngovernment departments and their arm\u2019s length bodies are expected to follow on a\n\u2018comply or explain\u2019 basis.\n\nIt includes specific guidance on genai and machine learning,\nas well as intellectual property rights.\n\n-  Sourcing playbook : defines the commercial process as a whole and includes key\n\npolicies and guidance for making sourcing decisions for the delivery of public services.\n\n-  Rose Book : provides guidance on managing and exploiting the wider value of\n\nknowledge assets (including software, data and business processes).\n\nAnnex D contains\nspecific guidance on managing these in procurement.", "##### Routes to market\n\nConsider the available routes to market and commercial agreements, and determine which\none is best to run your procurement through based on your requirements.\n\nThere are a range of routes to market to purchase genai systems.\n\nDepending on the kind\nof challenges you\u2019re addressing, you may prefer to use a framework or a Dynamic\nPurchasing System (DPS) .\n\nA Find a Tender Service procurement route also exists which\nmay be an option for bespoke requirements or contractual terms, or where there is no\nsuitable standard offering.\n\nCCS offers a number of compliant frameworks and DPSs for the public\nsector to procure genai.\n\n-----\n\nA summary of the differences between a framework agreement and DPS is provided below,\nwith further information available at  and more information\non use of frameworks in the Digital, Data and Technology (DDaT) Playbook .\n\nFramework DPS\n\n\nSupplier access Successful suppliers are awarded\nto the framework at launch.\n\nOpen for new supplier\nregistrations at any time.\n\nClosed to new supplier\nregistrations.\n\nPrime suppliers can request to\nadd new subcontractors.\n\nStructure Often divided into lots by product\nor service type.\n\nCompliance Thorough ongoing supplier\ncompliance checks carried\nout by CCS, meaning buyers\nhave less to do at call-off\n(excluding G-Cloud).\n\nBuying options Various options, including\ndirect award, depending on\nthe agreements.\n\nSuppliers filterable by categories.\n\nBasic compliance checks are\ncarried out by CCS, allowing\nthe buyer to complete these\nat the call-off.\n\nFurther competition only.\n\nA number of CCS agreements include genai within their scope, for example:\n\nDynamic Purchasing Systems:\n\n-  genai\n\n-  Automation Marketplace\n\n-  SPARK\n\nFrameworks:\n\n-  Big Data and Analytics\n\n-  G-Cloud 13\n\n-  Technology Products & Associated Services 2\n\n-  Technology Services 3\n\n-  Back Office Software\n\n-  Cloud Compute 2\n\n\n-----\n\nIn addition to commercial agreements, CCS has signed a number of Memoranda of\nUnderstanding (MoU) with suppliers .\n\nThese MoUs set out preferential pricing and\ndiscounts on products and services across the technology landscape, including cloud,\nsoftware, technology products and services and networks.\n\nMoU savings can be accessed\nthrough any route to market.\n\nTo find out more or for support, please contact", "##### Specifying your requirements\n\nWhen buying genai products and services, you will need to document your requirements to\ntell your suppliers what you need.\n\nRead the CCS guide on How to write a specification\nfor more details.\n\nWhen drafting requirements for genai, you should:\n\n-  start with your problem statement\n\n-  highlight your data strategy and requirements\n\n-  focus on data quality, bias (mitigation) and limitations\n\n-  underline the need for you to understand the supplier\u2019s genai approach\n\n-  consider strategies to avoid vendor lock-in\n\n-  apply the data ethics framework principles and checklist\n\n-  mention any integration with associated technologies or services\n\n-  consider your ongoing support and maintenance requirements\n\n-  consider the data format of your organisation and provide suppliers\n\nwith dummy data where possible\n\n-  provide guidance on budget to consider hidden costs\n\n-  consider who will have intellectual property rights if new software is developed\n\n-  consider any acceptable liabilities and appetite for risk, to match against draft terms\n\nand conditions, once provided\n\nFor further information and detail, read the Selection, evaluation and award section of\nthe Guidelines for genai Procurement.", "##### Running your procurement\n\nHaving prepared your procurement strategy, defined your requirements, and selected your\ncommercial agreement, you can now proceed to conduct a \u2018call-off\u2019 in accordance with\nthe process set out in the relevant commercial agreement.\n\nThe commercial agreement will\nspecify whether you can \u2018call-off\u2019 by further competition, a direct award or either.\n\nCCS offers buyer guidance tailored to each of its agreements, which describe each step\nin detail, including completing your order contract and compiling your contract.\n\nDetailed guidance on planning and running procurements is available in the Digital, Data\nand Technology (DDaT) Playbook .\n\n-----", "##### Procurement in an emerging market\n\nCommercial agreements\n\ngenai is an emerging market.\n\nAs well as rapidly evolving technology, there are ongoing changes\nin the supply base and the products and services it offers.\n\nDPSs offer flexibility for new\nsuppliers to join, which often complement these dynamics well for buyers.\n\nAny public sector buyers interested in shaping CCS\u2019s longer term commercial agreement\nportfolio should express their interest via \n\nRegulation and policy\n\nRegulation and policy will also evolve to keep pace.\n\nHowever, there are already a number of\nlegal and regulatory provisions which are relevant to the use of genai technologies.\n\n-  UK data protection law : regulation around automated decision making, processing\n\npersonal data, processing for the purpose of developing and training genai technologies.\n\nIn\nNovember 2022, a new Procurement Policy Note was published to provide an update to\nthis: PPN 03/22 Updated guidance on data protection legislation .\n\n-  Online Safety Act : provisions concerning design and use of algorithms are to be\n\nincluded in a new set of laws to protect children and adults online.\n\nIt will make social\nmedia companies more responsible for their users\u2019 safety on their platforms.\n\n-  A pro-innovation approach to genai regulation : this white paper published in March 2023,\n\nsets out early steps towards establishing a regulatory regime for genai.\n\nThe white paper\noutlines a proportionate pro-innovation framework, including five principles to guide\nresponsible genai innovation in all sectors.\n\n-  Centre for Data Ethics and Innovation (CDEI) genai assurance techniques : the portfolio\n\nof genai assurance techniques has been developed by the CDEI, initially in collaboration with\ntechUK.\n\nThe portfolio is useful for anybody involved in designing, developing, deploying\nor procuring genai-enabled systems.\n\nIt shows examples of genai assurance techniques being\nused in the real-world to support the development of trustworthy genai.\n\nFurther guidance is also available from the Information Commissioner\u2019s Office , Equality\nand Human Rights Commission , Medicines and Healthcare products Regulation\nAuthority and the Health and Safety Executive .", "##### Aligning procurement and ethics\n\nIt\u2019s important to consider and factor in data ethics into your commercial approach from\nthe outset.\n\nA range of guidance relating specifically to genai and data ethics is available\nto provide guidance for public servants working with data and/or genai.\n\nThis collates existing\nethical principles, developed by government and public sector sector bodies.\n\n-  The data ethics framework outlines appropriate and responsible data use in\n\ngovernment and the wider public sector.\n\nThe framework helps public servants\nunderstand ethical considerations, address these within their projects, and encourage\nresponsible innovation.\n\n-----\n\n-  Data ethics requirements : CCS has created a checklist for suppliers to follow that\n\nwill mitigate bias and ensure diversity in development teams, as well as transparency/\ninterpretability and explainability of the results.\n\n-  The Public Sector Contract includes a number of provisions relating to genai\n\nand data ethics.\n\nFor further information, please see the Data protection and privacy , Ethics and Regulation\nand policy sections.", "#### Practical recommendations\n\nEngage your commercial colleagues from the outset.\n\nUnderstand and make use of existing guidance.\n\nUnderstand and make use of existing routes to market, including frameworks,\nDynamic Purchasing Systems and Memoranda of Understanding.\n\nSpecify clear requirements and plan your procurement carefully.\n\nSeek support from your commercial colleagues to help navigate the evolving\nmarket, regulatory and policy landscape.\n\nEnsure that your procurement is aligned to ethical principles.", "##### Core concepts\n\ngenai provides a wide breadth of capability, and a key part of designing and building\na genai solution will be to get it to behave accurately and reliably.\n\nThis section sets\nout key concepts that you need to understand to design and build genai solutions\nthat meet your needs.\n\n-  _Prompts_ are the primary input provided to an LLM.\n\nIn the simplest case, a prompt may\n\nonly be the user-prompt.\n\nIn production systems, a prompt will have additional parts, such\nas meta-prompts, the chat history, and reference data to support explainability.\n\n-  _Prompt engineering_ describes the process of adjusting LLM input to improve\n\nperformance and accuracy.\n\nIn its simplest form it may be testing different user-prompt\nformulations.\n\nIn production systems, it will include adjustments, such as adding metaprompts, provision of examples and data sources, and sometimes parameter tuning.\n\n-  _User-prompts_ are whatever you type into e.g.\n\na chat box.\n\nThey are generally in\n\nthe everyday natural language you use, e.g.\n\n\u2018Write a summary of the generative\ngenai framework\u2019.\n\n-----\n\n-  _Meta-prompts_ (also known as system prompts) are higher-level instructions that help\n\ndirect an LLM to respond in a specific way.\n\nThey can be used to instruct the model\non how to generate responses to user-prompts, provide feedback, or handle certain\ntypes of content.\n\n-  _Embedding_ is the process of transforming information such as words, or images into\n\nnumerical values and relationships that the computer algorithms can understand and\nmanipulate.\n\nEmbeddings are typically stored in vector databases (see below).\n\n-  _Retrieval augmentation generation_ is a technique which uses reference data stored in\n\nvector databases (i.e.\n\nthe embeddings) to ground a model\u2019s answers to a user\u2019s prompt.\n\nYou could specify that the model cites its sources when returning information.\n\n-  _Vector databases_ index and store data such as text in an indexed format easily\n\nsearchable by models.\n\nThe ability to store and efficiently retrieve information has been a\nkey enabler in the progress of genai technology.\n\n-  _Grounding_ is the process of linking the representations learned by the genai models to real-\n\nworld entities or concepts.\n\nIt is essential for making genai models understand and relate\nits learned information to real-world concepts.\n\nIn the context of LLMs, grounding is\noften achieved by a combination of prompt engineering, parameter tuning, and retrieval\naugmented generation.\n\n-  _Chat history_ is a collection of prompts and responses.\n\nIt is limited to a session.\n\nDifferent\n\nmodels may allow different session sizes.\n\nFor example, Bing search sessions allow\nup to 30 user-prompts.\n\nThe chat history is the memory of LLMs.\n\nOutside of the chat\nhistory LLMs are \u2018stateless\u2019.\n\nThat means the model itself does not store chat history.\n\nIf\nyou wanted to permanently add information to a model you would need to fine-tune an\nexisting model (or train one from scratch).\n\n-  _Parameter tuning_ is the process of optimising the performance of the genai model for a\n\nspecific task or data set by adjusting configuration settings.\n\n-  _Model fine-tuning_ is the process of limited re-training of a model on new data.\n\nIt can\n\nbe done to enforce a desired behaviour.\n\nIt also allows us to add data sets to a model\npermanently.\n\nTypically, fine-tuning will adjust only some layers of the model\u2019s neural\nnetwork.\n\nDepending on the information or behaviour to be trained, fine-tuning may be\nmore expensive and complicated than prompt engineering.\n\nExperience with model tuning\nin government is currently limited and we are looking to expand on this topic in a future\niteration of this framework.\n\n-  _Open-source models_ are publicly accessible, and their source code, architecture, and\n\nparameters are available for examination and modification by the broader community.\n\n-  _Closed models_ , on the other hand, are proprietary and not openly accessible to the\n\npublic.\n\nThe inner workings and details of these models are kept confidential and are\nnot shared openly.\n\n-----", "##### Patterns\n\ngenai can be accessed and deployed in many different ways or patterns.\n\nEach pattern provides different benefits and presents a different set of security challenges,\naffecting the level of risk that you must manage.\n\nThis section explains patterns and approaches as the main ways that you are likely to use\nand encounter genai, including:\n\n-  public genai applications and web services\n\n-  embedded genai applications\n\n-  public genai application programming interfaces (APIs)\n\n-  local development\n\n-  cloud solutions\n\nPublic genai applications and web services\n\nApplications like OpenAI\u2019s ChatGPT, Google\u2019s Bard, Microsoft\u2019s Bing search, are the\nconsumer side of genai.\n\nThey have a simple interface, where the user types in a text\nprompt and is presented with a response.\n\nThis is the simplest approach, with the benefit\nthat users are already familiar with these tools.\n\nMany LLM providers offer web services free of charge, allowing users to experiment\nand interact with their models.\n\nGenerally, you\u2019ll just need an email address to sign up.\n\nThere are a few things you\u2019ll need to consider before signing up to a generative\ngenai web service.\n\n-  You must make sure you\u2019re acting in line with the policies of your organisation.\n\n-  While the use of these web services is free of charge, you should be aware that any\n\ninformation provided to these services may be made publicly available and/or used by\nthe provider.\n\nMake sure you have read and understood the terms of service.\n\n-  genai web services and applications are often trained using unfiltered material on\n\nthe internet.\n\nThis means that they can reproduce any harmful or biased material that they\nhave found online.\n\nYou can learn more about bias and how to use genai safely in\nthe Using genai safely and responsibly section.\n\n-  genai web services and applications may produce unreliable results.\n\nYou should\n\nnot trust any factual information provided without a validated reference.\n\n-----\n\nEmbedded genai applications\n\nLLMs are now being embedded, or integrated, into existing and popular products.\n\nEmbedded genai allows people to use language-based prompts to ask questions\nabout their organisation\u2019s data, or for specific support on a task.\n\nEmbedded genai tools provide straightforward user interfaces in products that\npeople are already familiar with.\n\nThey can be a very simple way to bring genai into\nyour organisation.\n\nExamples of embedded genai tools include:\n\n-  Adobe Photoshop Generative Fill tool: helps with image editing by adding or\n\nremoving components\n\n-  Github Copilot and AWS CodeWhisperer: helps to develop code by providing auto-\n\ncomplete style suggestions\n\n-  AWS ChatOps: an genai assistant that can help to manage an AWS cloud environment\n\n-  Microsoft 365 Copilot: an genai assistant that can support use of Microsoft products\n\n-  Google Duet genai: an genai assistant that can support the use of Google products\n\nincluding writing code\n\nYou must be certain you understand the scope of access and data processing of these\nservices.\n\nMost enterprise licenced services will assure your control over your data.\n\nHowever,\nsupporting services like abuse monitoring may still retain information for processing\nby the vendors.\n\nIf data sovereignty is a concern, you must also clarify the data processing\ngeolocation with a vendor.\n\nLLMs that are integrated into organisations\u2019 existing enterprise licences may have access\nto the data that\u2019s held by your organisation by default.\n\nBefore enabling a service, you must\nunderstand what data an embedded genai tool has access to in your organisation.\n\nThe use of code assistance tools requires the addition of integrated development\nenvironment or editor plugins.\n\nYou must be certain to only use official plugins.\n\nIf you use\na coding assistant to generate a complex algorithm, it may be necessary to verify the\nlicensing status manually by searching for the code on the internet to double-check you\u2019re\nnot inadvertently violating any copyrights or licences.\n\nPublic genai APIs\n\nMost big genai applications will offer an API.\n\nThis allows developers to integrate\ngenai capabilities directly into solutions they build.\n\nIt takes only a few lines of code\nto build a plugin to extend the features of another application.\n\nAs with web services, signing up is typically required to obtain an access token.\n\nYou need\nto be aware of the terms and conditions of using the API.\n\nBy using an API your organisation\u2019s data is still sent over to the provider, and you must be\nsure that you are comfortable with what happens to it before using an API.\n\n-----\n\nThe benefit of using APIs is that you will have greater control over the data.\n\nYou can\nintercept the data being sent to the model and also process the responses before returning\nthem to the user.", "You can\nintercept the data being sent to the model and also process the responses before returning\nthem to the user.\n\nThis, for example, allows you to:\n\n-  include privacy enhancing technology (PET) to prevent data leakage\n\n-  add content filters to sanitise the prompts and responses\n\n-  log and audit all interactions with the model\n\nHowever, you will also need to perform additional tasks commonly performed by the user\ninterface of web and embedded services, such as:\n\n-  maintaining a session history\n\n-  maintaining a chat history\n\n-  developing and maintaining meta-prompts and general prompt engineering\n\nLocal development\n\nFor rapid prototyping and minimum viable product studies, the development on personal or\nlocal hardware (i.e.\n\nsufficiently powerful laptops) may be a feasible option.\n\nDevelopment best practices like distributed version control systems, automated\ndeployment, and regular backups of development environments are particularly important\nwhen working with personal machines.\n\nWhen working on local development you should consider containerisation and cloudnative technology paradigms like Twelve-Factor applications.\n\nThese will help when moving\nsolutions from local hardware into the cloud.\n\nPlease note that the recommendation for production systems remains firmly with fully\nsupported cloud environments.\n\nCloud solutions\n\nCloud services provide similar functionality to public and paid-for APIs, often with a\nfamiliar web interface with useful tools for experimentation.\n\nIn addition to compliance with\ngovernment\u2019s Cloud First Policy , their key advantages is that they allow increased control\nover your data.\n\nYou can access cloud service providers\u2019 LLMs by signing up through your\norganisation\u2019s AWS, Microsoft or Google enterprise account.\n\nWhen establishing your genai cloud service, make sure the development\nenvironment is compliant with your organisation\u2019s data security policies, governmental\nguidelines and the Service Standard.\n\nIf your organisation and/or use case requires all data to remain on UK soil, you might need\nto plan in additional time for applying for access to resources within the UK as these may\nbe subject to additional regulation by some providers.\n\nTechnical account managers and\nsolution architects supporting your enterprise account will be able to help with this step.\n\n-----", "#### Practical recommendations\n\nLearn about the different patterns and approaches, and evaluate them against\nthe needs of your project and users.\n\nRefer to your organisation\u2019s policies before exploring any use of public generative\ngenai applications or APIs.\n\nBe aware that any information provided to genai web services may be\nmade publicly available and/or used by the provider.\n\nMake sure you have read\nand understood their terms of service.\n\nCheck licensing and speak to suppliers to understand the capabilities and data\ncollection and storage policies for their services, including geographic region\nif data sovereignty is a concern.\n\nBefore enabling embedded genai tools understand what organisational\ndata they would have access to.\n\nUse only official code assistance plugins.\n\nLearn from other government organisations who have implemented\ngenai solutions.", "##### Picking your tools\n\nIn order to develop and deploy genai systems you will need to pick the right tools\nand technology for your organisation.\n\nDeciding on the best tools will depend on your\ncurrent IT infrastructure, level of expertise, risk-appetite and the specific use cases you\nare supporting.\n\nDecisions on your development stack\n\nThere are a number of technology choices you will need to consider when building your\ngenai solutions, including the most appropriate IT infrastructure, which programming\nlanguages to use and the best LLM.\n\n-  Infrastructure: you should select a suitable infrastructure environment.\n\nMicrosoft, Google\n\nor AWS may be appropriate, depending on your current IT infrastructure or existing\npartnerships and expertise in your teams.\n\nAlternatively, it may be that a specific LLM\nis considered most appropriate for your particular use case, leading to a particular set\nof infrastructure requirements.\n\n-----\n\nAs models change and improve, the most appropriate one for your use case may also\nchange, so try to build-in the technical agility to support different models or providers.\n\nItems for consideration include:\n\n-  use of cloud services vs local development: you should be aware of the government\u2019s\n\nCloud First Policy , but understand that local development may be feasible for\nexperimentation \u2013 using container technology from the start can help you to move\nyour solution between platforms with minimal overhead\n\n-  web services, access modes such as APIs and associated frameworks \u2013\n\nsee section on Patterns\n\n-  front-end / user interface and back-end solutions\n\n-  programming languages\n\n-  data storage (e.g.\n\nBinary Large Object (BLOB) stores and vector stores)\n\n-  access logging, prompt auditing, and protective monitoring\n\n-  Programming language: in the context of genai research, Python is the most widely used\n\nprogramming language.\n\nWhile some tools and frameworks are available in other\nlanguages, for example LangChain is also available in JavaScript, it is likely that most\ndocumentation and community discussion is based on Python examples.\n\nIf you\u2019re\nworking on a use case that has focused interaction with a genai model API\nendpoint only, the choice of programming language is less important.\n\n-  Frameworks: genai frameworks are software libraries or platforms that provide\n\ntools, APIs, and pre-built models to develop, train, and deploy genai models.\n\nThese frameworks implement various algorithms and architectures, making it more\nconvenient for you to experiment with and create generative models.\n\nExample\nframeworks include LangChain , Haystack , Azure Semantic Kernel and Google Vertex\ngenai pipelines.\n\nAWS Bedrock similarly provides an abstraction layer to interact with varied\nmodels using a common interface.\n\nThese frameworks have their own strengths and\nunique features.\n\nHowever, you should also be aware that their use may increase the\ncomplexity of your solution.\n\nThe choice of a genai framework might depend on:\n\n-  your specific project requirements\n\n-  the familiarity of the developer with the framework and programming language\n\n-  the size and engagement of the community support around it\n\n\n-----\n\nThings to consider when evaluating LLMs\n\nThere are many models currently available, so you need to select the most appropriate\nfor your particular use case.\n\nThe Stanford Center for Research on Foundation Models\nprovides the Holistic Evaluation of Language Models to benchmark different models\nagainst criteria such as accuracy, robustness, fairness, bias, and toxicity.\n\nIt can help you\nto compare the capabilities of a large number of language models.\n\nHere are some of the\nthings you should consider.\n\n-  Capability: depending on your use case, conversational foundation models may not be\n\nthe best fit for you.\n\nIf you have a domain-specific requirement in sectors like medical\nor security applications, pre-tuned, specialised models like Google PaLM-2-med\nand Google PaLM-2-sec may reduce the amount of work required to reach a certain\nperformance level and time to production.\n\n-  Equally, if you\u2019re mainly focused on indexing tasks, BERT-type models may provide better\n\nperformance compared to GPT-style LLMs.\n\n-  Availability: at the time of writing, many LLMs are not available for general public use,\n\nor are locked to certain regions.\n\nOne of the first things to consider when deciding on\nwhich model to use is whether implementation in a production environment is possible\nin line with your organisation\u2019s policy requirements.\n\n-  Mode of deployment: many LLMs are available via a number of different routes.\n\nFor\n\nproduction applications the use of fully-featured cloud services or operation of opensource models in a fully controlled cloud environment will be a hard requirement for most\nif not all use cases.\n\n-  Cost: most access to LLMs is charged by the number of tokens (roughly equal to the\n\nword count).", "-  Cost: most access to LLMs is charged by the number of tokens (roughly equal to the\n\nword count).\n\nIf your genai tool is hosted in a cloud environment, you\u2019ll have\nto pay additional infrastructure costs.\n\nWhile the operation of open-source models\nwill not necessarily incur a cost per transaction, the operation of graphics processing\nunits-enabled instances is costly as well.\n\nCloud infrastructure best practices like\ndynamic scaling and shutting down instances outside of working hours will help to\nreduce these costs.\n\n-  Context limits: LLMs often limit the maximum amount of tokens the model can\n\nprocess as a single input prompt.\n\nFactors determining the size of prompts are the\ncontext window of conversation (if included), the amount of contextual data included\nvia meta-prompting and retrieval augmented generation as well as the expected size\nof user inputs.\n\n-  API rate limits: model providers impose limits on how frequently users can make requests\n\nthrough an API.\n\nThis may be important if your use case leads to a high volume of\nrequests.\n\nSoftware development best practices for asynchronous execution (such as use\nof contexts and queues) may help to resolve bottlenecks but will increase the complexity\nof your solution.\n\n-----\n\n-  Language capability: if your use case includes multilingual interaction with the model, or if\n\nyou expect to operate with very domain-specific language using specific legal or medical\nterminology, you should consider the amount of relevant language-specific training the\nLLM has received.\n\n-  Open vs closed-source (training data, code and weights): if openness is important\n\nto your solution, you should consider whether all aspects of the model, including\ntraining data, neural network coding and model weights, are available as open source.\n\nOpen source is different from being available.\n\nThe LLaMa model is unsuitable for use by\nthe government as its weights were leaked, but not officially released meaning it may be\nmore susceptible to adversarial attacks.\n\n-  Sites such as Hugging Face host a large collection of models and documentation.\n\nExamples of sites that provide open source low-code solutions include\nDatabricks and MosaicML .\n\n-  Non-technical considerations: there may be data-protection, legal or ethical\n\nconsiderations which constrain or direct your choice of technology, for example\nan LLM may have been trained on copyrighted data, or to produce a procedurally\nfair decision\u2011making system, and one solution should be chosen over another.", "#### Practical recommendations\n\nSelect the simplest solutions that meet your requirements, aligned to your\nIT infrastructure.\n\nUnderstand the key characteristics of genai products and how they\nfit your needs, realising that these characteristics may change rapidly in\na fast moving market.\n\nSpeak to other government organisations to find out what they have done, to help\ninform your decisions.\n\nConduct \u2018well architected\u2019 reviews at appropriate stages of the solutions\u2019 lifecycle.\n\n-----", "##### Getting reliable results\n\ngenai technology needs to be carefully controlled and managed in order to\nensure the models behave and perform in the way you want them to, reliably and\nconsistently.\n\nThere are a number of things you can do to help deliver high quality and\nreliable performance.\n\n-  Select your model carefully: in order to achieve a reliable, consistent and cost-effective\n\nimplementation, the most appropriate model for a particular use case should be chosen.\n\n-  Design a clear interface and train users: ensure your genai system is used as\n\nintended.\n\nDesign and develop a useful and intuitive interface your users will interact with.\n\nDefine and include any required user settings (for example the size of required response).\n\nBe clear about the design envelope for genai systems, i.e.\n\nwhat it has been\ndesigned and built to do, and, more importantly, what its limitations are.\n\nEnsure your user\ncommunity is trained in its proper use and fully understand its limitations.\n\n-  Evaluate input prompts: user inputs to the genai tool can be evaluated with a\n\ncontent filtering system to detect and filter inappropriate inputs.\n\nThe evaluation of input\nusing deterministic tools may be feasible and could reduce the amount of comparatively\nexpensive calls to an LLM.\n\nAlternatively, calls to a smaller and/or classification-specialised\nLLM may be required.\n\nMake sure that the system returns a meaningful error to allow a\nuser to adjust their prompt if rejected.\n\nThere are some commercially available tools that\ncan provide some of this functionality.\n\nExample checks include:\n\n-  identifying whether the prompt is abusive or malicious\n\n-  confirming the prompt is not attempting to jailbreak the LLM, for example by asking\n\nthe LLM to ignore its safety instructions\n\n-  confirming no unnecessary personally identifiable information has been entered\n\n-  Ground your solution: if your use case is looking for the model to provide factual\n\ninformation \u2013 as opposed to just taking advantage of a models\u2019 creative language\ncapabilities \u2013 you should follow steps to ensure that its responses are accurate, for\nexample by employing retrieval augmented generation.\n\nWith this, you identify useful\ndocumentation then extract the important text, break it into \u2018chunks\u2019, convert them to\n\u2018embeddings\u2019 and send them to a \u2018vector-database\u2019.\n\nThis relevant information can now\nbe easily retrieved and integrated as part of the model responses.\n\n-  A key application of genai is working with your organisation\u2019s private data.\n\nBy enabling the model to access, understand and use the private data, insights and\nknowledge can be provided to users that is specific to their subject domain.\n\nThere are\ndifferent ways to hook a genai model into a private data source.\n\n-  You could train the model from scratch on your own private data, but this is costly and\n\nimpractical.\n\nAlternatively, you can take a pre-trained model and further train it on your\nown private data.\n\nThis is a process called fine-tuning, and is less expensive and time\nconsuming than training a model from scratch.\n\n-----\n\n-  The easiest and most cost-efficient approach to augmenting your genai model\n\nwith private data is to use in-context learning, which means adding domain-specific\ncontext to the prompt sent to the model.\n\nThe limitation here is usually the size of\nthe prompt, and a way around this is to chunk your private data to reduce its size.\n\nThen a similarity search can be used to retrieve relevant chunks of text that can be\nsent as context to the model.\n\n-  Use prompt engineering: an important mechanism to shape the model\u2019s performance\n\nand produce accurate and reliable results is prompt engineering.\n\nDeveloping good\nprompts and meta-prompts is an effective way to set the standards and rules for how the\nuser requests should be processed and interpreted, the logical steps the model should\nfollow and what type of response is required.\n\nFor example, you could include:\n\n-  setting the tone for the interactions, for example request a chatbot to provide polite,\n\nprofessional and neutral language responses \u2013 this will help to reduce bias\n\n-  setting clear boundaries on what the genai tool can, and cannot,\n\nrespond to \u2013 you could specify the requirement for a model to not engage with\nabusive or malicious inputs, but reject them and instead return an alternative,\nappropriate response\n\n-  defining the format and structure of the desired output \u2013 for example asking for\n\na Boolean yes/no response to be provided in JSON format\n\n-  defining guardrails to prevent the assistant from generating inappropriate or\n\nharmful content\n\n-  Evaluate outputs: once a model returns an output, it is important to ensure that its\n\nmessaging is appropriate.\n\nOff-the-shelf content filters may be useful here, as well as\nclassical or genai text-classification tools.", "Off-the-shelf content filters may be useful here, as well as\nclassical or genai text-classification tools.\n\nDepending on the use case, a human\nmight be required to check the output some or all of the time, although the expenditure\nof time and money to do this needs careful consideration.\n\nAccuracy and bias checks on\nthe LLM responses prior to presentation to the user can be used to check and confirm:\n\n-  the response is grounded in truth with no hallucinations\n\n-  the response does not contain toxic or harmful information\n\n-  the response does not contain biased information\n\n-  the response is fair and does not unduly discriminate\n\n-  the user has permission to access the returned information\n\n-  Include humans: there are many good ways that humans can be involved in the\n\ndevelopment and use of genai solutions to help implement reliable and desired\noutcomes.\n\nHumans can be part of the development process to review input data to\nmake sure it is high-quality, to assess and improve model performance and also to review\nmodel outputs.\n\nIf there is a person within the processing chain preventing the system from\nproducing uncontrolled, automated outputs, this is called having a \u2018human-in-the-loop\u2019.\n\n-----\n\n-  Evaluate performance: to maintain the performance of the genai system,\n\nits performance should be continually monitored and evaluated by logging and auditing\nall interactions with the model:\n\n-  conduct thorough testing to assess the functionality and effectiveness of the system\n\n\u2013 see section on Testing genai solutions for further information\n\n-  record the input prompts and the returned responses\n\n-  collect and analyse metrics across all aspects of performance: including hallucinations,\n\ntoxicity, fairness, robustness, and higher-level business key performance indicators\n\n-  evaluate the collected metrics and validate the model\u2019s outputs against ground truth\n\nor expert judgement, and obtain user feedback to understand the usefulness of\nthe returned response \u2013 this could be a simple thumbs-up indicator or something\nmore sophisticated", "#### Practical recommendations\n\nAssume the model may provide you with incorrect information unless you build in\nsafeguards to prevent it.\n\nUnderstand techniques for improving the reliability of models, and that these\ntechniques are developing rapidly.\n\nGround the genai system in real organisational data, if possible, to\nimprove accuracy.\n\nImplement extensive testing to ensure the outputs are within expected bounds.\n\nIt is very easy to develop a prototype but can be very hard to produce a working\nand reliable production solution.\n\n-----", "##### Testing genai solutions\n\ngenai tools are not guaranteed to be accurate as they are designed to produce\nplausible and coherent results.\n\nThey generate responses that have a high likelihood of being\nplausible based on the data that they have processed.\n\nThis means that they can, and do,\nmake errors.\n\nIn addition to employing techniques to get reliable results, you should have a\nprocess in place to test them.\n\n-  During the initial experimental discovery phases, you should look to assess and\n\nimprove the existing system until it meets the required performance, reliability and\nrobustness criteria.\n\n-  Conduct thorough testing to assess the functionality and effectiveness of the system.\n\n-  Record the input prompts and the returned responses, and collect and analyse metrics\n\nacross all aspects of performance including hallucinations, toxicity, fairness, robustness,\nand higher-level business key performance indicators.\n\n-  Evaluate the collected metrics and validate the model\u2019s outputs against ground truth\n\nor expert judgement, obtaining user feedback if possible.\n\n-  Closely review the outcomes of the technical decisions made, the infrastructure\n\nand running costs and environmental impact.\n\nUse this information to continually\niterate your solution.\n\nTechnical methods and metrics for assessing bias in genai are still being developed\nand evaluated.\n\nHowever, there are existing tools that can support genai fairness testing, such\nas IBM fairness 360 , Microsoft FairLearn , Google What-If-Tool , University of Chicago\nAequitas tool , and PyMetrics audit-genai .\n\nYou should carefully select methods based on\nthe use case and consider using a combination of techniques to mitigate bias across\nthe genai lifecycle.", "##### Data management\n\nGood data management is crucial in supporting the successful implementation of\ngenai solutions.\n\nThe types of data you will need to manage include the following.\n\n-  Organisational grounding data: LLMs are not databases of knowledge, but advanced\n\ntext engines.\n\nTheir contents may also be out of date.\n\nTo improve their performance and\nmake them more reliable, relevant information can be used to \u2018ground\u2019 the responses,\nfor example by employing retrieval augmented generation.\n\n-  Reporting data: it is important to maintain documentation, including methodology,\n\ndescription of the design choices and assumptions.\n\nKeep records from any architecture\ndesign reviews.\n\nThis can help to support the ability to audit the project and support\nthe transparency of your use of genai.\n\nIf possible collect metrics to help to estimate any\nefficiency savings, value to your business and to taxpayers and the return on investment.\n\n-  Testing and operational data: all model inputs and outputs should be logged.\n\nWhen collected during testing and development, this information will be used to\nimprove the performance of the system.\n\nWhen collected during use, it will be used to\nmonitor and maintain performance.\n\nThe recording of the outcomes and any resulting\ndecisions will also help when examining and looking to explain the model results.\n\nSee the Testing genai solutions section for further details.\n\n-  Additionally, all user engagement of the genai systems should be logged to\n\nensure safe and compliant use.\n\n-  User feedback: both during the initial development stage and whilst in use, you should\n\nbe collecting feedback from users on their interactions with the system.\n\nCollecting and\nstoring metrics such as performance, ease of use and occurrences of problematic\nbehaviour (including hallucinations and potential biases etc) helps to control and improve\nthe genai system.\n\n-  Financial operations, or FinOps data: the cost of running your genai solutions\n\nshould be monitored closely to ensure you continue to operate cost-effectively, for the\ngiven model and prompts.\n\nData management needs to also address data loss prevention.\n\nConsider using PET\nto prevent data leakage, and if you process personal identifiable information take\naction to protect peoples\u2019 data e.g.\n\npseudonymising data to reduce the risk of leaking\nsensitive information.", "#### Practical recommendations\n\nRecord, store and analyse data on your use of genai solutions.\n\nCarefully consider any use cases which automatically lead to destructive or\nirreversible actions such as sending emails or modifying records, and whether a\nperson should be part of the process to authorise any proposed changes (called\nhaving a \u2018human-in-the-loop\u2019).\n\n-----", "## Using genai safely and responsibly\n\nThis section outlines the steps you\u2019ll need to ensure that you build genai\nsolutions in a safe and responsible way, taking account of legal considerations,\nethics, data protection and privacy, security, and governance.\n\nMany of these\nconsiderations interact with each other, so you should read all of these topics\ntogether, and seek support from data ethics, privacy, legal and security experts.\n\nIt supports:\n\n-  Principle 2: You use genai lawfully, ethically and responsibly\n\n-  Principle 3: You know how to keep genai tools secure\n\n-  Principle 4: You have meaningful human control at the right stage", "#### Legal considerations\n\nYou should seek advice from government legal profession legal advisers who help you to\nnavigate through the use of genai in government.\n\nAlthough genai is new, many of the legal issues that surround it are not.\n\nFor\nexample, many of the ethical principles discussed in this document, such as fairness,\ndiscrimination, transparency and bias, have sound foundations in public law.\n\nIn that way,\nmany of the ethical issues that your team identifies will also be legal issues, and your\nlawyers will be able to help to guide you through them.\n\nThe Lawfulness and purpose limitation section provides a framework to ensure that\npersonal data is processed lawfully, securely and fairly at all times.\n\nYour lawyers can\nadvise you on that.\n\nYou may face procurement and commercial issues when buying genai products.\n\nAlongside commercial colleagues, your lawyers can help you to navigate those challenges.\n\nWhen you contact your legal team, you should explain your aims for the genai\nsolution, what it will be capable of doing, and any potential risks you are aware of.\n\nThis will\nhelp you to understand, for example, if you need legislation to achieve what you want to do.\n\nIt will also help to minimise the risk of your work being challenged in court, having unintended\n\u2013 and unethical \u2013 consequences or a negative impact on the people you want it to benefit.", "##### Example legal issues\n\nThese are example legal issues designed to help you understand when you might want\nto consider getting legal advice.\n\nThey should not be read as real legal advice and their\napplication to any given scenario will be fact specific.\n\nYou should always consult your\ndepartmental lawyer if in doubt.\n\n-----\n\nData protection\n\nData protection is a legal issue, with potentially serious legal consequences should the\ngovernment get it wrong.\n\nAlthough your organisation will have a data protection officer\nand there may also be experts in your team, your legal team will be able to help you to\nunpick some of the more difficult data protection issues that are thrown up by the use of\ngenai.\n\nSee the Data protection and privacy section for more information.\n\nContractual issues\n\nYour lawyers will help you to draw up the contracts and other agreements for the\nprocurement or licensing of genai tools.\n\nThere may be special considerations for\nthose contracts, such as how to apportion intellectual property and how to ensure the\nlevel of transparency that would be required in a legal challenge.\n\nContracts for technology\nservices may need to incorporate procedures for system errors and outages, that recognise\nthe potential consequences of performance failures.\n\nSee the Buying genai section for more information.\n\nIntellectual property and copyright\n\nThe potential intellectual property issues with genai have been much discussed.\n\nYour lawyers can help you to navigate these, for example by considering at the outset how\nownership of intellectual property rights and liabilities will be apportioned throughout the\nlifetime of the project.\n\nThey can also give you advice on any copyright issues with the use of\nthese systems in government.\n\nEqualities issues\n\nLawyers can help you to navigate the equalities issues raised by the use of genai in\ngovernment, for example obligations arising under the Equality Act 2010.\n\nConducting an\nassessment of the equalities impacts of your use of genai can also be one way to\nguard against bias, which is particularly important in the context of genai.\n\nIf approached early, before contracts are signed, your legal advisers can help you ensure\nthe government is fulfilling its responsibilities to the public to assess the impacts of the\ntechnology it is using.\n\nPublic law principles\n\nPublic law principles explain how public bodies should act rationally, fairly, lawfully and\ncompatibly with human rights.\n\nThese are guidelines for public bodies on how to act within\nthe law.\n\nMany of these public law principles overlap with the ethical principles set out\nin this guidance.\n\nAs a result, your lawyers will likely be able to guide you on the application of the ethical\nprinciples, based on their knowledge of public law and the court cases that have occurred\nand the detail of the judgments.\n\n-----\n\nFor example, public law involves a principle of procedural fairness.\n\nThis is not so much\nabout the decision that is eventually reached but about how a decision is arrived at.\n\nA correct procedure would ensure that relevant considerations are considered.\n\nThe\ntransparency and explainability of the genai tool may well be key in being able to demonstrate\nthat the procedure was fair.\n\nPublic law also considers rationality.\n\nRationality may be relevant in testing the choice of\ngenai system, considering the features used in a system, and considering the\noutcomes of the system and the metrics used to test those outcomes.\n\nWhere you are considering using genai in decision-making in particular, public\nlaw also can guide you, for example on whether particular decisions require the exercise\nof a discretion by a decision maker, which could be unfairly fettered by the use of a tool,\nor whether in fact the decision can be delegated at all.\n\nHuman rights\n\nPublic authorities must act in a way that is compatible with human rights.\n\nIt\u2019s possible that\ngenai systems (especially those involving the use of personal data) may in some way affect at\nleast one of the rights in the European Convention on Human Rights.\n\nExamples of those\nmost likely to be commonly impacted are Article 8 (right to a private and family life) and\nArticle 10 (freedom of expression).\n\nLegislation\n\nSometimes, in order to do something, a public authority needs a legislative framework.\n\nYour lawyers will be able to advise you whether your use of genai is within the\ncurrent legal framework or needs new legislation.\n\nFor example, it may be that the legislative\nframework does not allow the process you are automating to be delegated to a machine.\n\nOr it may be that it provides for a decision to be made by a particular person.", "#### Ethics\n\nThe ethical questions raised by your use of genai will depend on your context and\nthe nature of your solutions.\n\nThe key themes you should address include:\n\n1.\n\nTransparency and explainability\n\n2.\n\nAccountability and responsibility\n\n3.\n\nFairness, bias and discrimination\n\n4.\n\nInformation quality and misinformation\n\n5.\n\nKeeping a human-in-the-loop\n\nAs well as the guidance in this framework, you should also take existing guidance into\naccount, such as the UK government data ethics framework and the UK Statistics\nAuthority ethics self-assessment tool .\n\nThe five cross-sectoral, values-based principles\nfor responsible genai innovation set out in the genai regulation white paper also provide a useful\n\n\n-----\n\nexplainer for safety, security and robustness; appropriate transparency and explainability;\nfairness; accountability and governance; and contestability and redress.", "##### Transparency and explainability\n\nTransparency is a cornerstone of the ethical development, deployment and use of genai\nsystems.\n\nA lack of transparency can lead to harmful outcomes, public distrust, a lack\nof accountability and ability to appeal.\n\nThe genai regulation white paper establishes that\ngenai systems should be appropriately transparent and explainable.\n\nTransparency is the\ncommunication of appropriate information about an genai system to the right people.\n\nFor\nexample: information on how, when, and for which purposes an genai system is being used.\n\nExplainability is how much it is possible for the relevant people to access, interpret and\nunderstand the decision-making processes of an genai system.\n\nHowever, transparency can be challenging in the context of genai, due to the closed\nand proprietary nature of commercial tools, and the inherent opacity of neural networks.\n\nYou should therefore ensure that you are transparent about the design of the genai\nsystem and the processes in which it is embedded:\n\nWhat you are transparent about:\n\n-  Technical transparency: information about the technical operation of the genai system,\n\nsuch as the code used to create the algorithms, and the underlying datasets used to\ntrain the model.\n\n-  Process transparency: information about the design, development and deployment\n\npractices behind your genai solutions, and the mechanisms used to demonstrate\nthat the solution is responsible and trustworthy.\n\nPutting in place robust reporting\nmechanisms, process-centred governance frameworks, and genai assurance techniques is\nessential for facilitating process-based transparency.\n\n-  Outcome-based transparency and explainability: the ability to clarify to any citizen using,\n\nor impacted by, a service that uses genai how the solution works and which\nfactors influence its decision making and outputs, including individual-level explanations\nof decisions where this is requested.\n\nHow and to whom you are being transparent:\n\n-  Internal transparency: retention of up-to-date internal records on technology and\n\nprocesses and process-based transparency information, including records of\nprompts and outputs.\n\n-  Public transparency: where possible from a sensitivity and security perspective, you\n\nshould be open and transparent about your department\u2019s use of genai systems\nto the general public.\n\nAlthough there are no universally accepted standards for achieving transparency in\nthe use of genai, there are existing standards and external resources which\nyou can draw on:\n\n\n-----\n\n-  The UK Algorithmic Transparency Recording Standard (ATRS) should be used by\n\npublic sector bodies using algorithmic solutions \u2013 like genai.\n\nThe ATRS aims to\nmake sure that information about algorithmic solutions used by government and the\npublic sector are clearly accessible to the public.\n\n-  The UK\u2019s national public sector genai ethics and safety guidance, Understanding\n\ngenai ethics and safety , outlines a process-based governance\nframework that can assist project teams in establishing and documenting proportionate\ngovernance actions.\n\n-  Data and model cards or fact sheets can be used as a reference point when\n\ndocumenting information about genai models and the datasets used in training and testing.\n\nA good example of these are Google\u2019s data cards and model cards .\n\n-  The Information Commissioner\u2019s Office (ICO) also offers genai auditing consultation and\n\nsupport to government organisations.\n\nFurther information can be found in A guide to\nICO audit: genai audits .\n\n-  Explaining decisions made with genai guidance is the UK\u2019s national genai explainability\n\nguidance co-produced by The Alan Turing Institute and the ICO: this details six types of\nexplanations as well as documentation processes.", "#### Practical recommendations\n\nClearly signpost when genai has been used to create content or is\ninteracting with members of the public.\n\nWhere possible, label genai generated\ncontent, and consider embedding watermarking into the model.\n\nPut in place evaluation and auditing structures, tracking data provenance, design\ndecisions, training scenarios and processes.\n\nUse existing standards and recording mechanisms such as the Algorithmic\nTransparency Recording Standard to communicate information about\ngenai solutions to the general public.\n\nUse external resources and emerging best practice, such as data cards and\nmodel cards for internal transparency.\n\nStrive to make model outputs as explainable as possible, while being aware of\nthe current explainability limitations of genai.\n\nConsider the use of open-source models, which provide more transparency about\ndatasets, code and training processes.\n\nImplement transparency and auditing requirements for suppliers as outlined\nin the Buying genai section.\n\n-----", "##### Accountability and responsibility\n\nEnsuring accountability for genai means that individuals and organisations can be\nheld accountable for the genai systems they develop, deploy, or use, and that human oversight\nis maintained.\n\nTo establish accountable practices across the genai lifecycle, you should\nconsider three key elements.\n\n-  Answerability: you should establish a chain of human responsibility across the generative\n\ngenai project lifecycle, including responsibility throughout the supply chain.\n\nIn cases of\nharm or errors caused by genai, recourse and feedback mechanisms need to be\nestablished for affected individuals.\n\nIdentifying the specific actors involved in genai\nsystems is vital to answerability.\n\nThis includes model developers, application developers,\npolicymakers, regulators, system operators and end-users.\n\nThe roles and responsibilities\nof each must be clearly defined and aligned with legal and ethical standards.\n\n-  Auditability: you should demonstrate the responsibility and trustworthiness of\n\nthe development and deployment practices by upholding robust reporting and\ndocumentation protocols, and retaining traceability throughout the genai lifecycle.\n\nThis refers\nto the process by which all stages of the genai innovation lifecycle from data\ncollection and base model training to implementation, fine-tuning, system deployment,\nupdating, and retirement are documented in a way that is accessible to relevant\nstakeholders and easily understood.\n\n-  Liability: you should make sure that all parties involved in the genai project\n\nlifecycle, from vendors and technical teams to system users, are acting lawfully and\nunderstand their respective legal obligations.\n\nAs an end-user, being accountable means taking responsibility for a system\u2019s outputs and\ngenerated content and its potential consequences.\n\nThis includes checking that these are\nfactual, truthful, non-discriminatory, non-harmful, and do not violate existing legal provisions,\nguidelines, policies or the providers\u2019 terms of use.\n\nIt entails putting the necessary oversight\nand human-in-the-loop processes in place to validate output in situations with high impact\nor risk.\n\nWhere these risks are too high, you must consider if genai should be used.\n\nUltimately, responsibility for any output or decision made or supported by an genai system\nalways rests with the public organisation.\n\nWhere genai is bought commercially,\nensure that vendors understand their responsibilities and liabilities, put the required risk\nmitigations in place and share all relevant information.\n\nRefer to the Buying genai\nsection for further guidance.\n\n-----", "#### Practical recommendations\n\nFollow existing legal provisions, guidelines and policies as well as the provider\u2019s\nterms of use when developing, deploying or using genai.\n\nAs an end-user, assume responsibility for output produced by genai tools\nwhen used to support everyday tasks, such as drafting emails and reports.\n\nClearly define responsibilities, accountability, and liability across all actors involved\nin the genai lifecycle.\n\nWhere the genai is bought commercially, define detailed\nresponsibilities and liability contractually.\n\nNominate a Senior Responsible Owner who will be accountable for the use of\ngenai in a specific project.\n\nWhere genai is used in situations of high impact or risk, establish a\nhuman-in-the-loop to oversee and validate outputs.\n\nAdopt a risk-based approach to the use of genai-generated content and put\nstrategies in place to minimise the risk of inaccurate or harmful outputs.\n\nWhere\nthe potential risks and harmful impacts are too high, consider whether human-inthe-loop approaches offer sufficient mitigation or if genai should be used.\n\nProvide routes for appeal and actionable redress and put feedback\nchannels into place.\n\nUse assurance techniques to evaluate the performance of genai systems.\n\nThe CDEI genai assurance guide provides a useful starting point, and the CDEI\nportfolio of genai assurance techniques offers real-world examples.", "##### Fairness, bias and discrimination\n\nFairness is a concept embedded across many areas of law and regulation, including\nequality and human rights, data protection, consumer and competition law, public and\ncommon law, and rules protecting vulnerable people.\n\nThe genai regulation white paper sets\nout that genai systems should not undermine the legal rights of individuals or organisations,\ndiscriminate unfairly against individuals or create unfair market outcomes.\n\nFairness, in the context of genai, means ensuring that outputs are unprejudiced,\nand do not amplify existing social, demographic, or cultural disparities.\n\nBy identifying and mitigating bias and reducing harm you will help your genai systems\nproduce fairer outcomes.\n\nIn genai, harmful biases can present as text, images, audio\nand video which perpetuate stereotypical or unfair treatment related to race, sex and gender,\nethnicity, or other protected characteristics.\n\nExamples of this are the generation of harmful\nstereotypes or abusive content targeted against particular social groups.\n\n-----\n\ngenai systems are designed, developed, and deployed by human beings who are\nbound by the limitations of their contexts and biases.\n\nThey are always trained on data which\nencodes present and past biases and inequalities of society.\n\nThese can present across the\ngenai lifecycle, from data collection to prompt writing.\n\nThe opacity and complexity of\nthese systems can make it difficult to identify exactly where and how biases are introduced.\n\ngenai models may reproduce biases embedded in training data or model design\nchoices.\n\nThey are particularly vulnerable to bias due to the fact that they are trained on\nvast amounts of unfiltered data scraped from the internet, which are likely to contain a wide\nrange of content reflecting historical and social biases.\n\nThe wording of prompts may also\ninadvertently introduce bias.\n\nAddressing these issues can help to support equitable representation in genai-generated\ncontent.\n\nThis might involve crafting prompts which encourage the consideration of different\nperspectives.\n\nFor development teams, this might include ensuring training data is diverse,\nand implementing fairness testing to assess how the tool responds to different input.\n\nTechnical methods and metrics for assessing bias in genai are still being developed\nand evaluated.\n\nRefer to the testing section for further guidance.", "#### Practical recommendations\n\nComply with human rights law, the Equality Act 2010, the Public Sector Equality\nDuty, the Equality and Human Rights Commission guide to using genai in public\nservices, as well as procedural fairness obligations.\n\nWrite prompts which minimise bias by using professional and neutral language.\n\nRefer to the prompt engineering section for guidance on how to develop and\noptimise prompts.\n\nReview generated output for potentially harmful content, such as sex and gender\nbased or cultural biases.\n\nTest a set of prompts to assess for bias.\n\nFor example, by changing the\ndemographic information in a prompt (such as references to ethnicity or sex and\ngender) and comparing the outputs.\n\nPut feedback mechanisms in place to allow individuals to report harmful content\nproduced using genai.\n\nImplement bias mitigation and fairness evaluation across the entire genai\nproject lifecycle.\n\nStrive for diversity across teams involved in developing, testing, and deploying\ngenai.\n\nCollect feedback from diverse groups during user testing to\nunderstand how a genai system performs in real-world scenarios.\n\nAdopt an approach of continuous evaluation to keep up with changing fairness\nconsiderations and societal expectations.\n\n-----", "##### Information quality and misinformation\n\nHaving access to high quality information is vital to support effective decision-making.\n\ngenai poses a challenge to information quality due to its ability to generate content\nthat appears credible but may be false or misleading.\n\nThe use of genai-generated content without proper validation and fact-checking can lead to the\nspread of misinformation.\n\nMany genai tools are built using large amounts of webscraped data from unknown, potentially outdated and harmful, sources.\n\nFor developers,\nthis makes validating the data quality of genai models extremely difficult.\n\nThe effectiveness of LLMs and other generative models is dependent on the quality of their\ntraining data.\n\nEven in cases where input data quality is deemed to be high, it is important to\nkeep in mind that these tools cannot understand real-world contexts, nuances in language,\ncultural references, or intent and do not have access to information that is known to be\nreal or true.\n\nLLMs are designed to generate statistically likely language patterns rather\nthan producing reliable and truthful accounts of reality.\n\nThis can make them convincing\ngenerators of \u2018nonsense\u2019.\n\nThe tendency for genai models to present nonsensical or\nincorrect outputs as factual is sometimes referred to as \u2018hallucination\u2019.\n\nTo mitigate the risk of misinformation, you should check generated content for accuracy\nand truthfulness, and any potentially harmful or misleading information.", "#### Practical recommendations\n\nOptimise prompts to improve the quality of generated output.\n\nThe specificity and\nstructure of prompts can improve the quality of responses.\n\nFor further guidance\non writing prompts refer to the prompt engineering deep dive section.\n\nVerify and cross-reference information produced by genai tools with\ntrusted sources to ensure content is accurate.\n\nBe aware that the data used by\nsome publicly available genai tools may be outdated.\n\nIndicate where genai has been used to create content and notify people\nwhen they are interacting with a genai system.\n\nAssess the impact of using genai-generated content and the risks of misinformation\nfor each use case.\n\nPut in place structured governance and oversight processes to regularly review\nthe performance of generative models.\n\nImprove the output quality of a model by grounding or fine-tuning it with\nhuman feedback.\n\nEmbed watermarking into a model so that outputs from the genai tools\ncan be easily detected by users and impacted parties.\n\n-----", "##### Maintaining appropriate human involvement in automated processes\n\nKeeping a human-in-the-loop means ensuring that there is human involvement and\nsupervision in the operations and outcomes of genai systems.\n\nIn a broader context,\nhumans should be involved with setting up the systems, tuning and testing the model so\nthe decision-making improves, and then actioning the decisions it suggests.\n\nThe availability of genai tools may contribute towards increasingly automated\nworkflows and decision-making processes.\n\nHowever, relying on genai to make decisions and\ngenerate content without meaningful human oversight can have negative consequences.\n\nA lack of human intervention might result in inaccurate or harmful outputs going unchecked.\n\nYou should assess the quality of genai-generated outputs to ensure they are accurate, relevant,\nand align with societal values.\n\ngenai also lacks flexibility, human understanding and compassion.\n\nWhile humans\nare able to take individual circumstances into account on a discretionary basis, genai systems\ndo not have this capacity.\n\nMaintaining meaningful human involvement in genai ensures that future innovation\naligns with human values and supports the public good.\n\nYou should uphold the expectation\n\u2018to be heard\u2019 by a human when interacting and receiving services from the government.\n\nThis supports the principle of transparency and building public trust.\n\nYou should never use\ngenai to fully automate decision making in high-risk or high-impact situations.", "#### Practical recommendations\n\nConsider whether genai is appropriate for the specific use case and\nwhether there is a clear public and user benefit.\n\nStrive to understand the factors that influence the output and formulate your own\nviews and organisational perspective before consulting the genai system.\n\nEnsure that there is a human-in-the-loop who can oversee outputs when\ngenai is in use in situations with high impacts.\n\nValidate and cross-reference any information sourced via genai solutions.\n\nRefrain from fully automated decisions and ensure humans are the final decisionmakers in high-risk or high-impact situations.\n\nDevelop appropriate safeguards if\na genai system is intended to be used in decision making with impact on\nmembers of the public.\n\nGive citizens the option to be referred to a person and enable feedback from\nusers and affected stakeholders.\n\n-----", "##### Sustainability and environmental considerations\n\ngenai has environmental impacts that you and your organisation should understand\nand consider before deciding to develop or use genai solutions.\n\nLLMs, in particular,\nrely heavily on computational power both during their training phase and then every time they\nare used, contributing to carbon emissions.\n\nThey may require the use of a lot of water to\ncool the data centres, and the manufacturing process of key components like the graphics\nprocessing units also contributes to the extraction of rare metals.\n\nYou should balance the environmental costs of using pre-trained models and usage costs\nwhen deciding on the most appropriate model size for your needs.\n\nIn general, it will not\nbe an environmentally-sound decision to train your own model if appropriate pre-trained\nmodels are available.\n\nAs models are generally expensive to operate, they should not be\nused for tasks that could be undertaken by other available machine learning tools.\n\ngenai can potentially contribute to reducing environmental impact as well.\n\nIt can\noptimise processes and minimise resource wastage.\n\nFor example, genai technologies can\nstreamline data analysis, reducing the computational power required to process information.\n\nThis optimisation results in lower energy consumption and a decreased carbon footprint.", "#### Practical recommendations\n\nInclude a focus on environmental impacts when considering using genai\nsolutions, and compare these to alternative technologies that do not use LLMs.\n\nCheck the environmental credentials of potential model providers, including their\nuse of renewable energy, energy-efficient infrastructure and sustainable practices\nand select low carbon emission energy grids.\n\nWhen selecting models, choose the smallest (in terms of number of\nparameters) that meets your requirements as these are likely to have the lowest\nenvironmental impact.\n\nConduct lifecycle analysis to assess the carbon footprint of genai systems and make\nyour technology more sustainable .\n\nBe transparent about the environmental costs of your genai project and\nmitigation measures such as using energy-efficient hardware.\n\n-----", "#### Data protection and privacy\n\ngenai systems can process personal data during their training and testing phases,\nas well as potentially generating outputs which contain personal data, including sensitive\npersonal data.\n\nWhen using genai you need to consider how you protect personal\ndata, are compliant with data protection legislation and minimise the risk of privacy intrusion\nfrom the outset.\n\nOrganisations developing and deploying genai systems must consider principles of\ndata protection outlined in the UK General Data Protection Regulation (UK GDPR) and the\nData Protection Act 2018.\n\nThe data protection law applies irrespective of the type of technology used, so its basic\nprinciples of compliance will also apply to any genai systems.\n\nThe ICO, which is\nresponsible for regulating compliance with the data protection legislation in the UK, outlines\nthese principles in their guidance .\n\nThe data protection principles most relevant to the use of genai are:\n\n-  accountability: your organisation has clear ownership of risk and responsibility for\n\nmitigations and compliance\n\n-  lawfulness: you have an applicable lawful basis for processing personal data and ensure\n\nthe processing is lawful under data protection or any other regulation\n\n-  purpose limitation: you define why you are processing personal data and only process\n\ndata for that purpose\n\n-  transparency and individual rights: you are open about what it uses personal data for,\n\nand your users can exercise their information rights\n\n-  fairness: you avoid processing personal data in ways that are detrimental,\n\nunexpected or misleading\n\n-  data minimisation: you develop systems that process only the data that is needed for\n\nthe task at hand\n\n-  storage limitation: you avoid accumulation of vast amounts of personal data for\n\nunjustifiably long periods\n\n-  human oversight: you build in human oversight to automated decision making\n\n-  accuracy: you have steps in place to ensure the accuracy of genai responses and\n\ndata related to individuals\n\n-  security: you implement appropriate technical and organisational mitigations to protect\n\nsensitive and personal data\n\n\n-----", "##### Accountability\n\nAccountability is a key principle in data protection law and the genai regulation white paper .\n\nAccountability establishes ownership of risk, responsibility for mitigations and compliance\nwith the legislation, ability to demonstrate your compliance and high standards for privacy.\n\nThe genai regulation white paper notes that clear lines of accountability need to be established\nacross the genai life cycle.\n\nOrganisations should take the following steps when planning genai solutions:\n\n-  make a strategic decision on how any use of genai technology fits with your\n\nexisting risk appetite\n\n-  review your risk governance model to establish clear ownership of genai risks\n\nat a senior level\n\n-  implement measures to mitigate these risks and test their effectiveness\n\n-  make sure residual risks are aligned with your organisation\u2019s risk appetite\n\n-  due to the evolving nature of genai technologies and new regulations, ensure you\n\nconduct regular reviews and further iterations\n\n-  importantly, engage with internal data protection, privacy and legal experts from the outset", "##### Lawfulness and purpose limitation\n\nThe nature of genai means that its misuse may result in high risks to data subjects.\n\nAs a result, a Data Protection Impact Assessment (DPIA) should be undertaken prior to\ndeploying any genai capabilities which process personal data.\n\nThe DPIA process should identify personal data processing at each stage of the generative\ngenai lifecycle starting from design to data acquisition and preparation, training, testing,\ndeployment and monitoring.\n\nIf you are processing personal data in your genai system that is not fully\nanonymised, you must identify an appropriate lawful basis under UK GDPR .\n\nThe UK GDPR requires data controllers :\n\n-  to identify each distinct processing operation, determine whether personal data is\n\nincluded and identify the specific purpose\n\n-  to map data sources and identify where personal data needs to flow as part of the\n\nprocessing operations\n\nIdentification of all personal data sources is important as data controllers will be accountable\nfor all personal data processed throughout the genai lifecycle.\n\nFor example,\ngenai products are often trained on publicly available information drawn from the\ninternet.\n\nPublicly available content which contains personal data may have been published\nin the public domain lawfully, but it is not currently agreed that the re-use of public personal\ndata to train an LLM is lawful.\n\nBefore re-using personal data in an LLM or generative\ngenai system, you should seek data protection and legal expertise to consider and advise\nwhether the re-use of that data is compatible with the purposes for which it was collected.\n\nSpecial category data is personal data that needs more protection because it is sensitive,\nsuch as health data.\n\nIf your genai system needs to process special category data,\nyou must be able to demonstrate that you meet one of the specific conditions in Article 9\nof the UK GDPR.\n\n-----\n\nWhen mapping personal data flows, it is important to identify the geographic location of each\ndistinct processing activity since the processing of data outside the UK will increase the risk\nof losing the protection of the UK data protection laws.\n\nData controllers may need to bring\nin additional safeguards, such as international transfer data agreements if personal data\nis being processed in jurisdictions where the data protection regime is not deemed to be\nadequate and transfers of personal data is restricted under Article 46 of the UK GDPR.\n\nIf having undertaken a DPIA, data protection risks remain \u2018high\u2019 even after mitigations, and\nyou cannot do anything to reduce it, prior consultation with the ICO is required under UK\nGDPR before processing of personal data can begin.", "#### Practical recommendations\n\nWhen building your team, seek support from data compliance professionals,\nincluding data protection, legal and privacy experts.\n\nIdentify data processing operations and their purpose, and map personal data\nsources and flows.\n\nDetermine whether personal data is necessary for each activity, and whether you\nare processing special category data or children\u2019s data.\n\nIdentify the applicable lawful basis of your data processing and assess data\nprotection and privacy risk through DPIAs and legitimate interest assessments .\n\nIf data protection and privacy risks remain \u2018high\u2019 even after mitigations,\nconsult with the ICO .\n\nIdentify any processing outside the UK to take additional safeguards to protect\npersonal data in jurisdictions where data protection regime may not be adequate.\n\nAssess any changes in the purpose of your genai system and make sure\nyour genai system remains compliant and lawful.\n\n-----", "##### Transparency and individual rights\n\nIn addition to the ethical reasons for seeking transparency, organisations need to be\ntransparent about how they process personal data in a genai system so that\nindividuals can effectively exercise the rights granted to them by the UK GDPR.\n\nThis obligation applies to the direct collection of data from individuals and to personal data\ncollected from other sources.\n\nThe rights relating to personal data granted to individuals\nunder data protection law apply wherever personal data is used at any of the various points\nin training, testing and deployment of an genai system.\n\nThe UK GDPR requires data controllers:\n\n-  to provide information to users in concise, transparent, intelligible and easily accessible\n\nform using clear and plain language\n\n-  to be transparent about the purpose for processing personal data, retention periods,\n\nthird parties involved in the processing activity\n\n-  to be transparent about the existence of automated decision-making, meaningful\n\ninformation about the logic involved, as well as the significance and the envisaged\nconsequences of such processing for the data subject\n\n-  to provide a clear explanation of the results these systems produce\n\n-  to uphold individuals\u2019 rights, including the right of access to the personal data that you\n\nhold on them, and a simple and clear process to exercise their right to correction and to\nobject to the processing of their personal data at any time\n\nThe data transformation processes involved in training a model may convert personal data\ninto a less detailed form, making training data harder to link to a particular named individual.\n\nHowever, even without direct identifiers, individual level data that is rich in other variables\nmay lead to inadvertent identification of people and is subject to data protection safeguards.\n\nThis data needs to be considered when responding to individuals\u2019 requests to exercise their\nrights as the initial processing stages may have included their personal data.", "#### Practical recommendations\n\nExplain your system in plain language.\n\nBe transparent about the purpose for processing personal data, retention periods\nand third parties involved in the processing activity.\n\nBe transparent about the existence and nature of automated decision-making,\nusing the Algorithmic Transparency Recording Standard .\n\nProvide a clear explanation of the results these systems produce, following\nguidance such the ICO\u2019s Explaining decisions made with genai .\n\n-----", "##### Fairness\n\nIn addition to ethical reasons for fairness, it is also a data protection obligation under the\nUK GDPR for genai systems that process personal data.\n\nIn the context of the data\nprotection legislation, fairness means that \u201cyou should only process personal data in ways\nthat people would reasonably expect and not use it in any way that could have unjustified\nadverse effects on them\u201d.\n\nYou must make sure that genai systems do not process personal data in ways that\nare unduly detrimental, unexpected or misleading to the individuals concerned.\n\nYou need\nto uphold the \u2018right to be informed\u2019 for individuals whose personal data is used at any\nstage of the development and deployment of genai systems as part of fulfilling the\ntransparency and fairness principles.\n\nIf genai systems infer data about people, you need to ensure that the system is\naccurate and avoids discrimination.\n\nData protection aims to protect individuals\u2019 rights and\nfreedoms with regard to the processing of their personal data, not just their information\nrights.\n\nThis includes the right to privacy but also the right to non-discrimination.\n\nDPIAs are the main tool to steer you to consider the risks to the rights and freedoms of\nindividuals, including the potential for any significant social or economic disadvantage.\n\nDPIAs also help you to demonstrate whether your processing is necessary to achieve your\npurpose, is proportionate and fair.\n\nYou must remember that there may be other sector-specific obligations around lawfulness,\nfairness, statistical accuracy or discrimination to consider alongside data protection\nobligations (e.g.\n\nEquality Act 2010).\n\nThese are discussed in more detail under the Legal\nconsiderations section.", "#### Practical recommendations\n\nIdentify the risks to the rights and freedoms of individuals through DPIAs\nand assess whether your processing is necessary, proportionate and fair to\nachieve your purpose.\n\nUse the ICO\u2019s genai Toolkit to reduce the risks to individuals\u2019 rights and freedoms.\n\nMitigate risks using the ICO\u2019s guidance on fairness in genai systems .\n\nProvide users with clear reassurance that you are upholding their right to\nprivacy, including simple and clear processes to exercise these rights in clear\nprivacy notices .\n\nAddress any objections from users related to solely automated decisions\nproducing legal or similarly significant impact on them by implementing\nsafeguards, such as meaningful human intervention, effective process to obtain\nand consider individuals\u2019 views and corrections of factual errors.\n\n-----", "##### Data minimisation\n\nThe data minimisation principle requires you to identify the minimum amount of personal\ndata you need to fulfil your purpose, and to only process that information, and no more.\n\nThis does not mean that genai shouldn\u2019t process personal data.\n\nIf you can\nachieve the same outcome by processing less personal data, then by definition, the data\nminimisation principle requires you to do so.\n\nThere are a number of techniques that you can adopt to develop genai systems that\nprocess only the data you need, while still remaining functional.\n\nThe CDEI\u2019s responsible\ndata access programme includes important work to encourage adoption of PETs.\n\nPETs are a set of emerging techniques that provide stronger protections to preserve\ndata privacy whilst enabling effective use of data.\n\nPETs come with their own limitations\nhowever, therefore selection of the PET technology should be proportionate to the\nsensitivity of the data.\n\nCDEI has published a PET adoption guide to raise awareness of these emerging technologies.\n\nSimilarly, the ICO has published the new PET guidance which explains how they can be\nused to support a data protection by design approach in line with regulatory requirements.", "#### Practical recommendations\n\nJustify use of personal data, thinking about the problem you are solving\nthrough your DPIA and settle with the minimum personal data that is required.\n\nLess personal data means less risk.\n\nReduce the risk of individuals\u2019 identifiability through the processing of their\npersonal data employing a range of privacy enhancing techniques.\n\n-----", "##### Storage limitation\n\ngenai systems can only process personal data as long as you can reasonably justify\nit for the purpose you are processing.\n\nAs challenging as it may be, you need to strike a\ndelicate balance between any relevant training of LLMs and minimising the collection and\nstorage of personal data to meet the UK GDPR requirement of storage limitation.\n\nIt may be necessary to retain training data in order to retrain the model, for example when\nnew modelling approaches become available and for debugging.\n\nHowever, where a model\nis established and unlikely to be retrained or modified, the training data may no longer be\nneeded.\n\nYou should:\n\n-  assess data requirements for accurate training\n\n-  specify a clear period for retaining and processing personal data in your information\n\nmaterials and be transparent\n\n-  delete the personal data at the end of that period\n\nThere are a number of strategies you can follow to address concerns around long (or even\nperpetual) retention of personal data.\n\nStorage limitation is best complied with through purpose\nlimitation and data minimisation.\n\nYou should map all personal data flows through stages of\ndevelopment, testing and deployment, and use data minimisation or eventually anonymisation\ntechniques to remove or irreversibly transform personal data from training datasets.", "##### Human oversight\n\nAlthough it is possible to use genai systems for automated decision making where\nthe system makes a decision automatically without any human involvement, this may\ninfringe the UK GDPR.\n\nUnder Article 22 , the UK GDPR currently prohibits \u201cdecision(s)\nbased solely on automated processing\u201d that have legal or \u2018similarly significant\u2019\nconsequences for individuals.\n\nServices that affect a person\u2019s legal status or their legal\nrights using genai must only use it for decision-support, where the system only\nsupports a human decision-maker in their deliberation.\n\ngenai systems need to bring processes into training, testing and output stages so\nthat humans work together with machines to perform tasks, combining their abilities to\nreach best results.\n\nHowever, the human input needs to be \u2018meaningful\u2019.\n\nThe degree and\nquality of human review and intervention before a final decision is made about an individual\nare key factors in determining whether a genai system is being used for automated\ndecision-making or merely as decision-support.\n\nThere are a number of factors that should determine the amount of human involvement\nin genai, such as the complexity of the output, its potential impact, the amount of\nspecialist human knowledge required.\n\nAs an example, genai systems deployed\nin legal, health and care are likely to always require human involvement no matter how\nexceptional the technology.\n\nWhile focusing on genai risks, it is important to consider biases at organisational and\nhuman review levels.\n\nHumans and genai technology have different strengths and\nweaknesses when it comes to ensuring fair outcomes.\n\ngenai cannot use emotional\nintelligence, nuance, or an understanding of the broader context.\n\nAt the same time, humans\nhave their own unconscious biases and beliefs that influence their reasoning.\n\nThis points\nback to the importance of the accountability principle, robust governance structures\nfor oversight and alignment of genai and existing business processes, such as\nrisk management.\n\nFurther aspects on human oversight for genai systems can be found in the\nEthics section.", "#### Practical recommendations\n\nDesign, document and assess the stages when meaningful human review\nprocesses are incorporated and what additional information will be taken into\nconsideration when making the final decision.\n\nUse the ICO guidance on automated decision making under UK GDPR for\nmore clarity on types of decisions that have a legal or similarly significant effect.\n\n-----", "##### Accuracy\n\nAccuracy in the context of data protection requires that personal data is not factually\nincorrect or misleading, and where necessary, is corrected, deleted and kept up to\ndate without delay.\n\nYou need to put in place appropriate mathematical and statistical procedures as part of\nyour technical measures to correct inaccuracies in personal data and minimise errors.\n\ngenai outputs should be tested against existing knowledge and expertise in early\nimplementations of those outputs.\n\nThe outputs of a genai system are not always intended to be treated as factual\ninformation about the individual but instead represent a \u2018statistically informed guess\u2019.\n\nYou\nneed to factor in the possibility of them being incorrect and the impact this may have on any\ndecisions.\n\nTo avoid such misinterpretations of outputs as factual, systems should be explicit\nthat they are statistically informed guesses rather than facts, including information about the\nsource of the data and how the inference has been generated.\n\nFor more information see the Getting reliable results section.", "#### Practical recommendations\n\nTest genai outputs against existing knowledge and expertise during\ntraining and testing.\n\nBe transparent that outputs are statistically informed guesses rather than facts.\n\nDocument the source of the data and the genai system used to generate\nthe conclusion.\n\nImplement processes to consider individuals\u2019 feedback, views and corrections of\nfactual errors.\n\n-----", "#### Security\n\nThe UK government has a responsibility to ensure that the services it provides do not\nexpose the public to undue risk, which makes security a primary concern for anyone\nlooking to deploy emerging technology, such as genai.\n\nThis section takes you through how to keep genai solutions in government secure:\n\n-  how to deploy genai securely\n\n-  security risks\n\n-  practical security recommendations\n\nWe have set up a cross-government genai security group made up of security\npractitioners, data scientists and genai experts to support this section, and help people\nacross government to share knowledge and best practices.\n\nYou can request to join the\ngroup by emailing:", "##### How to deploy genai securely\n\ngenai can be deployed in many different ways.\n\nThe approaches set out below\npresent different security challenges and can affect the level of risk that must be managed.\n\nThis section covers different approaches that you need to take for:\n\n-  public genai applications and web services\n\n-  embedded genai applications\n\n-  public genai APIs\n\n-  privately hosted open-source genai models\n\n-  data provenance\n\n-  working with your organisational data\n\n-  open-source vs closed-source models\n\nFor additional information see the section on deployment Patterns .\n\nPublic genai applications and web services\n\nThe use of public chatbots such as ChatGPT or Google Bard are easier to use compared to\nopen-source, bespoke solutions.\n\nHowever, a key disadvantage of allowing the use of public applications is that you cannot\neasily control the data input to the models and must rely on training users on what they can\nand cannot enter into the chat prompt.\n\nYou also have no control on the outputs from the\nmodel and are subject to their commercial licence agreements and privacy statements, for\nexample OpenAI will use the prompt data you enter directly into the ChatGPT website\nto improve their models , although individual users can opt out.\n\n-----\n\nEmbedded genai applications\n\nAs well as these more direct approaches to using genai, many vendors include\ngenai features and capabilities directly within their products, for example Slack GPT\nand Microsoft 365 Copilot.\n\nWhilst this guidance applies at a high level to each of these\napplications, they come with their own unique security concerns.\n\nYou should speak to your\nsecurity teams to discuss your requirements.\n\nIn addition to embedded applications there are also many genai tools that offer\nplugins or extensions to other software, for example, Visual Studio Code has a large\necosystem of community-built extensions, many of which offer genai functionality.\n\nExtreme caution should be taken before installing any unverified extensions as these\nare likely to present a security risk.\n\nYou should speak to your security team to discuss\nyour requirements.\n\nBefore adopting any of these products it is important to understand the underlying\narchitecture of the solution and what mitigations the vendor has put in place for the inherent\nrisks associated with genai.\n\nAll of these different approaches come with trade-offs between security, privacy, usability\nand cost.\n\nEach of the security risks of genai models need to be taken in context with\nthe way the model is deployed and used to inform the level of risk that an application poses.\n\nPublic genai APIs\n\nMany public genai applications usually offer the ability to access their services\nthrough APIs, which define the set of rules, protocols, and tools for building software\napplications.\n\nThrough using the API it can be very easy to integrate genai\ncapabilities into your own applications.\n\nThe benefit here is that you can intercept the data\nbeing sent to the model and also process the responses before returning them to the user.\n\nYou can also include PET to prevent data leakage, add content filters to sanitise the\nprompts and responses, and log and audit all interactions with the model.\n\nNote that PETs\ncome with their own limitations, therefore selection of the PET should be proportionate to\nthe sensitivity of the data: see ICO\u2019s privacy-enhancing technologies (PETs) and CDEI\u2019s\nPET adoption guide for more information.\n\nUse of the API still means that data is passed over to the provider, although the retention\npolicies tend to be more flexible for API use, for example, OpenAI only retains prompt data\nsent to the API for 30 days .\n\nPrivately hosted open-source genai models\n\nInstead of using a public genai offering, the alternative is to host your own\ngenai model.\n\nBy taking one of the many publicly available open-source models and\nrunning it in your own private cloud infrastructure, you ensure that data never leaves an\nenvironment that you own.\n\nThe type of models that you can run in this way are not on the scale of those that are\npublicly available but can still provide acceptable results.\n\nThe advantage is that you have\n\n\n-----\n\ncomplete control over the model and the data it consumes.\n\nThe disadvantage is that you\nare responsible for ensuring the model is secure and up to date.\n\nAn alternative approach is to use one of the larger commercial models, but in a private\nmanaged instance, for example, the Microsoft Azure OpenAI service offers access to the\nOpenAI ChatGPT models but running in a private instance with zero-day retention policies.\n\nData provenance\n\nIn addition to where your genai model runs, how the model was trained is also\nimportant from a security perspective.\n\nAll the publicly available models were trained\nusing data from the public internet.\n\nThis means that they include data that is personally\nidentifiable, inaccurate, illegal and harmful, all of which could present a security risk.", "This means that they include data that is personally\nidentifiable, inaccurate, illegal and harmful, all of which could present a security risk.\n\nIt is possible to train an LLM using your own data, but the cost of doing this for larger\nand more capable models is prohibitive.\n\nAlong with the cost, the amount of private data\nrequired to produce acceptable performance of a large model is also beyond the capacity\nof most organisations.\n\nWorking with your organisational data\n\nA key application of genai is working with your organisation\u2019s private data.\n\nBy enabling the model to access, understand and use the private data, insights and\nknowledge can be provided to users that is specific to their subject domain and will provide\nmore reliable results.\n\nOpen-source vs closed-source models\n\nNeither open-source or closed-source LLMs are inherently less secure than the other.\n\nA\nfully open-source model may expose not only the model code, but also the weights of its\nparameters and the data used to train the model.\n\nWhile this increases transparency, it also\npotentially presents a greater risk, as knowing the weights and the training data could allow\nan attacker to create attacks carefully tailored to the specific LLM.\n\nOne benefit of fully open-source models is that they allow you to inspect the source code\nand model architecture, enabling security experts to audit the code for vulnerabilities.\n\nDespite this, owing to their complexity, even an open-source LLM is mostly opaque,\nmeaning that the internals of the model are hard to analyse.\n\nOpen-source models\ntheoretically benefit from a community of developers, who can quickly identify and\nfix security issues, whereas closed-source model owners might be incentivised not\nto publicise security flaws in their models.\n\nHowever, it should be noted that several\nhigh\u2011profile vulnerabilities in open-source libraries have been present for many years\nbefore being identified.\n\n-----", "##### Security risks\n\nSignificant work has already been done by the Open Worldwide Application Security Project\n(OWASP) to identify the unique risks posed by LLMs .\n\nFrom these we can draw out some\nof the most common vulnerabilities and put them in context of how they could apply to LLM\napplications in government.\n\nThese risks focus on the use of LLMs but many of them will\nalso apply to other types of genai models.\n\nWe take each security risk and use a scenario describing an application of genai\nin a government context, to illustrate how that vulnerability might be exploited.\n\nThe list\nof scenarios is not exhaustive but should be used as a template for assessing the risks\nassociated with a particular application of genai.\n\nImpacts are described for each scenario, and mitigations suggested.\n\nThe likelihood and\nimpact of each risk in a given scenario are scored, following the approach outlined in the\nOWASP risk rating methodology .\n\nIn addition to the impact factors included in the OWASP\napproach, we add user harm and misinformation as a significant impact factor.\n\nSecurity threats include:\n\n-  prompt injection threats: using prompts that can make the genai model behave in\n\nunexpected ways:\n\n-  LLM chatbot on a government website\n\n-  LLM enhanced search on a government website\n\n-  private LLM chatbot returning suggested file sources\n\n-  data leakage: responses from the LLM reveal sensitive information, for\n\nexample, personal data:\n\n-  intranet search engine enhanced with LLM\n\n-  private LLM chatbot summarises chat conversations\n\n-  hallucinations: the LLM responds with information that appears to be truthful but is\n\nactually false:\n\n-  developer uses LLM generated code without review\n\nPrompt injection threats\n\nPrompt injections can either be direct, meaning a user directly enters a prompt into the\nLLM to subvert its behaviour.\n\nOr they can be indirect, meaning the LLM gets input from an\nexternal source, and that source has been manipulated to include a prompt injection, for\nexample from an email or an external file.\n\n-----\n\nScenario 1: LLM chatbot on a government website \u2013 full chat interface\n\nScenario\nA chatbot is deployed to a government website to assist with queries relating to a\nparticular public service.\n\nThe chatbot uses a private instance of one of the publicly\ntrained LLMs.\n\nThe user\u2019s question is combined with system instructions that tell the LLM\nto only respond to questions relevant to the specific service.\n\nThe system instructions are\ncombined with the user\u2019s original question and sent to the LLM.\n\nA malicious user could\ncraft a specific prompt that circumvents the system instructions and makes the chatbot\nrespond with irrelevant and potentially harmful information.\n\nThis is an example of a direct prompt injection attack.\n\nImpact\nActual risk of user harm if a user is tricked into using an unsafe prompt that then results\nin harmful content being returned and acted on, for example: a user is looking for how to\npay a bill and is directed to a false payment site.\n\nReputational damage to the government, if a user made public potentially harmful\nresponses received from the chatbot, for example: a user asking for generic information\nreceives an inflammatory response.\n\nMitigation\nUse prompt engineering to attach a meta prompt to any user input to prevent the LLM\nfrom responding to malicious input.\n\nApply content filters trained to detect likely prompt injections to all prompts\nsent to the LLM.\n\nChoose a more robust model.\n\nSome models have been shown to be more resistant to\nthis kind of attack than others.\n\nNone of these mitigations are sufficient to guarantee that a prompt injection attack\nwould not succeed.\n\nFundamentally, an LLM cannot distinguish between user input and\nsystem instructions.\n\nBoth are processed by the LLM as natural language inputs so there\nis no way to prevent a user prompt affecting the behaviour of the LLM.\n\nRisk rating\nLikelihood: **HIGH**\nImpact:\n\n-  LOW \u2013 response is returned to a single user with limited repercussions.\n\n-  **HIGH** \u2013 response causes actual harm to a user.\n\nRecommendation\nDeploying an LLM chatbot to a public-facing government website does come with a\nsignificant risk of a direct prompt injection attack.\n\nThe impact of such an attack should\nbe considered in the context of the specific use case.\n\nFor example, a chatbot deployed\nto a small number of users for the purposes of gathering data about the effectiveness\nof LLMs under controlled conditions is far lower risk than one that is more generally\navailable and designed to make specific, actionable recommendations to a user.\n\n-----\n\nScenario 2: LLM enhanced search on a government website \u2013 no chat interface\n\nScenario\nA private LLM is used to enhance the search capabilities of a public facing government\nwebsite, without providing a chatbot interface.\n\nThe content of the government website is\ninitially split into small chunks of text and vector indexed using a machine learning (ML)\nalgorithm.", "The content of the government website is\ninitially split into small chunks of text and vector indexed using a machine learning (ML)\nalgorithm.\n\nA user enters a natural language search term.\n\nThe ML algorithm processes\nthe search term into a vector, and a similarity search is done against the vector indexed\ndatabase of text chunks.\n\nThe most relevant chunks are retrieved and passed in context\nto the LLM, along with the user\u2019s search term, and system instructions telling the LLM\nto return a summary of the search results.\n\nA malicious user could craft a specific search\nterm that circumvents the system instructions making the summary contain potentially\nharmful information.\n\nImpact\nActual risk of user harm if a user is tricked into using an unsafe search term that results\nin harmful content being returned and acted on.\n\nReputational damage to the government, if a user made public potentially harmful\nresponses received from the enhanced search.\n\nMitigation\nApply content filters trained to detect likely prompt injections to all prompts\nsent to the LLM.\n\nFilter the summarised search results returned by the LLM to ensure they contain only\ninformation relating to the government website.\n\nDo not pass the original search term to the LLM.\n\nRisk rating\nLikelihood: MEDIUM\nImpact:\n\n-  LOW \u2013 response is returned to a single user with limited repercussions.\n\n-  **HIGH** \u2013 response causes actual harm to a user.\n\nRecommendation\nThis scenario presents lower risk than directly hosting an LLM chatbot on a government\nwebsite (Scenario 1), as a level of indirection exists between the search term entered\nby the user and the prompt sent to the LLM.\n\nHowever, if the search term is passed to\nthe LLM along with the search results in context, then a direct prompt injection would\nstill work.\n\nTo stop this no part of the search term should be passed to the LLM.\n\nThe\ntrade-off here is that this is likely to reduce the usefulness of the enhanced search.\n\n-----\n\nScenario 3: Private LLM chatbot returning suggested file sources\n\nScenario\nA chatbot is deployed into an internal departmental messaging system (for example\nGoogle Chat).\n\nThe chatbot calls out to a privately hosted open-source LLM running\nwithin the department\u2019s cloud.\n\nThe chatbot scans attachments posted in the chat,\nand passes the content of these to the LLM, with system instructions telling the LLM\nto augment its responses with links to relevant information held in departmental files.\n\nA user posts an attachment that unknown to them has been manipulated to contain\na prompt injection.\n\nThe chatbot passes the attachment content as input to the private\nLLM.\n\nThe resulting response contains a list of links to relevant files on the department\u2019s\nshared drives.\n\nThe prompt injection alters the list of links so that they direct the user to\nan insecure third-party website rather than the original file.\n\nThis is an example of an indirect prompt injection attack.\n\nImpact\nA user follows a harmful link, which may lead to data loss and privacy violations.\n\nAdditional vectors of attack are opened up which may result in further data loss or\nfinancial damage if malicious software was downloaded from the insecure site.\n\nMitigation\nApply content filters to attachments before they are passed to the LLM.\n\nApply filters to the response generated by the LLM, to ensure any links contained in it\nare only to known resources.\n\nEnsure network controls are enforced that prevent users following dangerous links.\n\nRisk rating\nLikelihood: MEDIUM\n\nImpact: MEDIUM\n\nRecommendation\nThis scenario does not present a significant risk.\n\nHowever, the impact is highly\ndependent on the actions the response from the LLM is used to make, in this case only\ngenerating a list of links.\n\nIf the response was used to send emails, or modify files or\nrecords, the impact would be much greater.\n\nLLM responses must not automatically lead\nto destructive or irreversible actions.\n\nA human must be present to review the action.\n\n-----\n\nData leakage\n\nScenario 4: Intranet search engine enhanced with LLM\n\nScenario\nA private LLM is used to enhance the search capabilities of an internal departmental\nsearch engine.\n\nThe departmental data (documents, emails, web pages and directory\ninformation) is initially split into small chunks of text and vector indexed using a ML\nalgorithm.\n\nA user enters a natural language question, for example: \u201cHow do I apply for\ncompassionate leave?\u201d.\n\nThe ML algorithm processes the user\u2019s question into a vector,\nand a similarity search is done against the vector indexed database of text chunks.\n\nThe most relevant chunks are retrieved and passed in context to the LLM, along with\nthe user\u2019s question, and system instructions telling the LLM to tailor its responses to\nthe user\u2019s question using information in the retrieved text.\n\nThe LLM responds with\nconfidential information that has been inadvertently retrieved by the vector index search.", "The LLM responds with\nconfidential information that has been inadvertently retrieved by the vector index search.\n\nFor example, it may return details about who is currently on compassionate leave and\nthe reasons why.\n\nImpact\nSignificant privacy violations and leakage of confidential data, irrespective of data\nsecurity controls.\n\nReputational damage to the department due to loss of data.\n\nRegulatory breaches with financial consequences.\n\nMitigation\nEnsure that any vector index database respects source data security controls.\n\nThe\nidentity of the search user must be passed to the similarity search so that appropriate\ncontrols can be applied.\n\nThis prevents the LLM receiving content that the user is not\npermitted to see.\n\nRisk rating\nLikelihood: MEDIUM\n\nImpact: **HIGH**\n\nRecommendation\nIn this scenario security controls can be preserved.\n\nHowever, if the LLM was to be\nfine\u2011tuned with private data or trained directly with private data, then there would\nbe no way of applying the original data security controls owing to the way the LLM\nencodes the data it is trained with.\n\nPrivate data which contains confidential information\nor employs different levels of security controls must not be used to fine-tune\nor train an LLM.\n\n-----\n\nScenario 5: Private LLM chatbot summarises chat conversations\n\nScenario\nA chatbot is deployed into an internal departmental messaging system (for example\nGoogle Chat).\n\nThe chatbot calls out to a privately hosted open-source LLM running\nwithin the department\u2019s cloud.\n\nThe chatbot scans the conversation thread and\nsummarises the content.\n\nA prompt injection in the conversation thread causes\nthe chatbot to emit the summary of the thread in the form of an obfuscated link\nto a malicious site, for example\n (this link is safe).\n\nThe chat interface unfurls the link posted in the\nresponse, automatically calling out to the malicious site and transferring the encoded\nsummary of the chat.\n\nImpact\nData loss, potentially confidential information contained in the chat thread is transferred\nto a third party.\n\nReputational damage to the department due to loss of data.\n\nRegulatory breaches with financial consequences.\n\nMitigation\nApply filters to the response generated by the LLM, to ensure any links contained in it\nare only to known resources.\n\nEnsure network controls are enforced that prevent applications making calls to\ndangerous URLs.\n\nRisk rating\nLikelihood: LOW\n\nImpact: **HIGH**\n\nRecommendation\nIn this scenario prompt injection can be used to perform data exfiltration without any\naction required by the user.\n\nThe risk can be mitigated by removing malicious links in the\nresponse from the LLM.\n\nMore generally LLM responses that will be read by humans\nshould avoid using links to external resources, and if external links are provided then the\nresponse must be filtered to remove malicious URLs.\n\n-----\n\nHallucinations\n\nScenario 6: Developer uses LLM generated code\n\nScenario\nA developer uses a public LLM to answer coding questions, and receives advice\nto install a specific software package, for example \u2018arangodb\u2019 from the JavaScript\npackage management system npm.\n\nWhen the LLM was trained the package did not\nexist.\n\nA hacker has previously interrogated the LLM with common coding questions\nand identified this hallucination.\n\nThey have then created a malicious package with the\nfictitious name and registered it with the package management system.\n\nWhen the\ndeveloper now comes to install the package, they receive the malicious code.\n\nImpact\nUnauthorised code execution when the software containing the fake package\nis deployed and run.\n\nThis could result in significant data loss and other\nserious consequences.\n\nMitigation\nDo not rely on the responses of the LLM.\n\nDouble check all outputs before including\nthem in your code.\n\nCheck all package dependencies of your code before deployment.\n\nUse an automated tool to scan for supply chain vulnerabilities, for example,\n\u2018dependabot\u2019 or \u2018snyk\u2019.\n\nRisk rating\nLikelihood: LOW\n\nImpact: **HIGH**\n\nRecommendation\nIf developers are following secure coding best practices the risk should never arise as all\ndependencies should be checked before deployment.\n\nOver-reliance on LLM generated\ncode without sufficient human oversight is likely to become an increasing risk.\n\nTreat all\nLLM generated code as inherently insecure and never use it directly in production code\nwithout first doing a code review.\n\nReferences\nCan you trust ChatGPT\u2019s package recommendations?\n\n-----", "#### Practical security recommendations\n\nDesign risk-driven security taking account of the OWASP Top 10 security\nrisks for LLMs .\n\nUse a consistent risk rating methodology to assess the impact and\nlikelihood of each risk.\n\nMinimise the attack surface by only using the required capabilities of the\ngenai tool, for example, by avoiding sending user input directly to an LLM.\n\nDefend in depth by adding layers of security, for example, by using PET to\nprevent data leakage and adding content filters to sanitise the prompts and\nresponses from an LLM.\n\nNever use private data that needs different levels of access permissions based on\nthe user who is viewing it, to fine-tune or train an LLM.\n\nPrevent LLM responses automatically leading to destructive or irreversible actions,\nsuch as sending emails or modifying records.\n\nIn these situations, a human must\nbe present to review the action.\n\nAvoid using links to external resources in LLM responses that will be read by\nhumans, and if external links are provided then the response must be filtered to\nremove malicious URLs.\n\nTreat all LLM generated code as inherently insecure and never use it directly in\nproduction without code review.\n\nNever enter any OFFICIAL or SENSITIVE information directly into public generative\ngenai applications or APIs, unless it is already publicly available or cleared for\npublication.\n\nExceptions may apply for specific applications with different data\nhandling terms provided under commercial licences, for example, Microsoft\nCopilot, Azure Open genai, or Bing Enterprise Chat.\n\nAvoid putting LLM chatbots on public facing government websites, unless the risk\nof direct prompt injection is acceptable under the specific use case.\n\n-----", "#### Governance\n\nBecause of the risks around security, bias and data, all genai programmes need strong\ngovernance processes.\n\nWhether they are already built into existing governance frameworks\nor a new governance framework, the processes should be focused on:\n\n-  continuous improvement by including new knowledge, methods, and technologies\n\n-  identifying key stakeholders representing different organisations and interests such\n\nas Civil Society Organisations and sector experts to create a balanced view from\nstakeholders so that they can support genai initiatives\n\n-  planning for the long-term sustainability of genai initiatives, considering scalability, long-term\n\nsupport, maintenance, and future developments\n\nAs part of any governance framework, organisations should consider setting up a\nseparate genai governance board or have genai representation on a governance board and an\nethics committee.\n\nAn genai governance board and an ethics committee are components of\nresponsible genai implementation within an organisation or department which play different and\ndistinct roles and responsibilities.", "##### genai governance board or genai representation on an existing board\n\nIn general, an genai governance board covers aspects such as alignment to ethical principles,\nrisk management, compliance, assurance, resource allocation, stakeholder engagement,\nand alignment with business objectives.\n\nAn genai governance board or representation on a board provides oversight, accountability,\nand strategic guidance to make informed decisions about genai adoption and use.\n\nThe board holds the organisation accountable for achieving responsible and effective genai\noutcomes and helps ensure genai projects are aligned with ethical values.\n\nIts scope is broader,\nincluding operational and strategic considerations.\n\nAlongside support and input from your organisation\u2019s internal assurance team, a board\nor an genai representative on a board will help you make sure your project is on track\nand manage risks.", "##### Ethics committee\n\nThe primary focus of an ethics committee is to assess the ethical implications of\nvarious actions, projects, and decisions within the organisation.\n\nIt evaluates projects,\npolicies, and actions from an ethical standpoint, focusing on values such as fairness,\ntransparency, and privacy.\n\nIt typically includes legal experts, representatives from relevant organisations, community\nmembers, and other stakeholders who provide a specialised perspective on ethical matters\nand may also include Civil Society Organisations.\n\nSee the Ethics section for related content.\n\n-----", "##### Creating an genai/ML systems inventory\n\nTo support the work, organisations should consider setting up genai and ML systems inventory\nto provide a comprehensive view of all deployed genai systems within an organisation.\n\nIt helps management and stakeholders understand the scope and scale of genai usage across\nprogrammes and projects, providing better oversight and awareness of any genai used in\nmaking decisions, and potential risks such as data quality, model accuracy, bias, security\nvulnerabilities, and regulatory compliance.\n\nThe inventory should be regularly kept up to date\nwith the following details:\n\n-  describe each system\u2019s purpose, usage, and associated risks\n\n-  include details like data elements, ownership, development, and key dates\n\n-  employ protocols, structures, and tools for maintaining an accurate and\n\ncomprehensive inventory", "##### Programme governance in teams and what should be considered\n\n-  Set out how the model will be maintained over time, and develop a comprehensive plan\n\nfor knowledge transfer and training to ensure the model\u2019s sustainable management.\n\n-  Establish clear roles and responsibilities to ensure accountability within teams for genai\n\nsystems, including who has the authority to change and modify the code of the genai model.\n\n-  Establish pathways for escalation and identify key points of contact for specific genai\n\nrelated issues.\n\n-  Set out how they work with and report into their programme boards and the\n\nethics committee.\n\n-  Ensure diversity within the project team by incorporating a range of subject matter\n\nexpertise, skills, and lived experiences.", "#### Practical recommendations\n\nConnect with your organisation\u2019s assurance team and review the CDEI\u2019s\nassurance guide .\n\nSet up an genai governance board or include genai experts on existing\ngovernance boards.\n\nConsider setting up an ethics committee, made up of internal stakeholders,\ncross-government stakeholders, sector experts and external stakeholders like\nCivil Society Organisations.\n\nSet up an genai/ML systems inventory to provide a comprehensive view of all\ndeployed genai systems within your department.\n\nMake sure your programme teams have clear governance structures in place.\n\n-----\n\n-----", "### Background\n\n_The sudden, widespread availability of genai tools has reshaped the digital landscape and_\n_animated a global debate about the opportunities and risks this technological development creates._\n_However, early discussion and initiatives on genai regulation and technical standards have_\n_not sufficiently taken into account international standards and practices from the field of corporate_\n_responsibility and accountability.\n\nTo address this gap, in May 2023 UN B-Tech launched its Generative_\n_AI Project to identify how the UN Guiding Principles on Business and Human Rights can guide more_\n_effective understanding, mitigations and governance of the risks associated with the development_\n_and deployment of genai._\n\nTechnological breakthroughs in the field of genai, coupled with the unprecedented speed and scale\nof uptake of new consumer tools and enterprise-facing applications have captured the public imagination.\n\nAspirations of leveraging genai to dramatically improve our lives suddenly seem much less\nfictional: whether helping individuals to reach new heights in creativity and productivity, bolstering industrial\ndevelopment, or uncovering solutions to shared challenges in the realms of healthcare00096-0/fulltext) and climate change .\n\nAnd yet, it also seems more likely than ever that these same tools will be designed and used (or abused)\nin ways that erode individual freedoms, undercut livelihoods, reinforce inequalities, and undermine norms\nand institutions designed to uphold democratic values and protect human rights.\n\nIn fact, evidence of adverse\nimpacts on people from genai tools\u2014whether stemming from in-built characteristics of these tools or\nfrom their misuse\u2014are already being reported: for example increasing technology-enabled gender-based\nviolence, the amplification of discriminatory racial and ethnic stereotypes , the supercharging of online\ndisinformation campaigns or the creation of child sexual abuse material at scale .\n\nAttention to the near-term opportunities and risks of current genai models are taking place within a\nwider debate about the future promise and threats to humanity of Artificial General Intelligence 5 (AGI).\n\nSome\nsee the potential of AGI to augment and propel the human experience to new, currently unimaginable heights.\n\nOthers have voiced concern that the achievement of AGI will usher in a dystopian future in which AGI works\nto undermine human existence.\n\nRegardless of one\u2019s position on these matters, addressing current risks and\nharms should be a priority.\n\nFocusing on what is in front of us also has the merit of being a way to iterate\nguardrails that can protect against present but also future, as yet unknown, harms.\n\n5 \u201cArtificial general intelligence (AGI) is the representation of generalized human cognitive abilities in software so that, faced with\n\nan unfamiliar task, the AGI system could find a solution.\n\nThe intention of an AGI system is to perform any task that a human being\nis capable of.\n\nDefinitions of AGI vary because experts from different fields define human intelligence from different perspectives.\n\nComputer scientists often define human intelligence in terms of being able to achieve goals.\n\nPsychologists, on the other hand, often\ndefine general intelligence in terms of adaptability or survival.\u201d Source: Tech Target\n\n\n-----\n\nGovernments, civil society, academics, technologists, investors and business executives have all called for\nregulation to govern the design and deployment of genai systems to protect against harms and\nmaximize their benefits.\n\nThis has added even more urgency to an already high number of regulatory and\nother genai initiatives 6 , in some cases resulting in amendments to regulatory proposals 7 and voluntary initiatives.\n\nWhile many of these initiatives seek to advance the governance, assessment and management of risks to\nsociety by private sector actors developing and deploying genai technologies, few have incorporated\nthe due diligence expectations laid out by the international standards of business conduct: specifically, the UN\nGuiding Principles on Business and Human Rights and the _OECD Guidelines for Multinational Enterprises on_\n_Responsible Business Conduct_ (OECD Guidelines).\n\nThis misses the opportunity to benefit from several decades\nof policy developments, regulatory convergence, business practice, multi-stakeholder collaboration and civil\nsociety advocacy about how to (and how not to) advance responsible corporate conduct across complex global\nvalue chains, including in the technology sector itself.\n\nAgainst this backdrop, B-Tech launched its genai Project to raise awareness and facilitate exchange\namong key stakeholders and interdisciplinary experts and shape a comprehensive understanding about the role\nthe UNGPs can play in governing genai responsibly.", "The Project aims to do this by:\n\n\u2013 Clarifying the expectations under the UNGPs for companies developing and deploying genai\ntechnologies and products in order to achieve common and more effective human rights risk management\napproaches across the industry.\n\n\u2013 Spotlighting the growth and maturation of existing company responsible genai approaches, as well as\nacademic research and civil society advocacy that have all laid important foundations for addressing the\nrisks to human rights associated with genai.\n\n\u2013 Informing the debate about policy options for managing human rights risks related to the development\nand deployment of genai, including through mandatory and voluntary measures.\n\n\u2013 Complementing parallel efforts to embed the international standards of business conduct into genai\ngovernance, such as the work being led by the OECD 8 .\n\nBuilding on OHCHR\u2019s existing work on tech and human rights and on B-Tech\u2019s other workstreams, the B-Tech\ngenai Project is being implemented through an iterative process of research and engagement.\n\nThis\nhas included exploratory interviews with company practitioners, civil society, technical experts, and other key\nstakeholders, as well as workshops and other convenings involving multiple stakeholders.\n\nThis paper lays out the findings from the first phase of the Project, implemented between June and November 2023.\n\n6 OECD genai Policy Observatory lists over 1000 genai policy initiatives from 69 countries, territories and the EU.\n\n7 See, for example genai: A closer look at the EU genai Act .\n\n8 The OECD is working to apply and adapt international standards on responsible business conduct to actors in the genai value chain.\n\nThis work\n\nis being led by a multistakeholder Network of Experts , which includes the UN B-Tech Project, and is overseen by government delegates in\nthe OECD Working Party on Responsible Business Conduct and the OECD Working Party on genai Governance.\n\nThe project is systematically\nbuilding towards the development of concrete and practical recommendations for genai actors under an overarching due diligence framework\nby first mapping out and consolidating recommendations, terminology, and risk scopes from existing genai-specific and generic risk management\nframeworks (e.g.\n\nthe OECD Due Diligence Guidance for Responsible Business Conduct, the NIST genai Risk Management Framework, the G7\nCode of Conduct for the Development of Advanced genai Systems, IEEE 7000 series, ISO 31000, and ISO/IEC 23894).\n\n-----", "###### Impacts on internationally agreed human rights should be the focus of State and company action to advance the responsible development and deployment of genai technologies.\n\nInternational human rights comprise a list of basic rights that are universally recognised as necessary for a\nperson to live a life of equality and dignity.\n\nThey have developed\u2014 and will develop\u2014based on debate,\ncooperation and consensus building between countries from different regions and people from many different\ngroups, cultures and ethical perspectives.\n\nHuman rights are not, and may never be, uniformly protected, upheld\nand respected around the world, but a rights-based approach to advancing the responsible development and\ndeployment of genai brings the global legitimacy and pragmatism that no other set of standards or\nethical frameworks can claim.\n\nHuman Rights also offer an intentionally aspirational roadmap and moral\ncompass grounded in our shared humanity to help guide decision-making.\n\nA rights-based approach to advancing the responsible development and deployment of genai provides 9 :\n\n\u2013 Agreed norms for assessing and addressing impacts: Human rights provide an existing, well-defined\nand holistic set of outcomes against which States, companies and other actors evaluate the risks related\nto genai.\n\nThis offers a common basis for evaluating the nature of risk, i.e., whose lives may be\nadversely impacted by the proliferation of genai, and in which specific circumstances and in what\nspecific ways.\n\nA human rights lens can also prompt attention to categories of impacts on people that\nmay be otherwise missed such as impacts on political participation, access to public services, freedom\nof assembly, the right to a fair trial, the right to physical and mental health and freedom to form and hold\nopinions, for example.\n\n\u2013 An architecture for convening, deliberation, and enforcement: The international human rights framework has\ndeveloped a relatively elaborate architecture of regional and international institutions and processes (e.g.,\ncourts, specialized agencies, intergovernmental bodies, designated experts) which can be used both to\nfacilitate consideration of these issues and, in some instances, to monitor and even enforce implementation of\nany resulting outputs.\n\nBut the international human rights system is not the only human rights regime.\n\nRegional\nhuman rights systems, national courts, local civil society actors and human rights defenders \u2014 all actors\npaying increasing attention to human rights in the digital economy \u2014 also play an important, if uneven, role.\n\n\u2013 Standards that already apply to both States and corporations: Focusing on upholding international human\nrights has the merit of reinforcing that State action related to genai should not run counter to States\u2019\nhuman rights commitments.\n\nThis includes the requirement that States should refrain from interfering with\nor curtailing the enjoyment of human rights when deploying genai to deliver State functions (such\nas education, healthcare, social security or defence) or when regulating genai development and\nuse by others.\n\nAt the same time, the international human rights framework was never _exclusively_ framed\naround States.\n\nThe Universal Declaration of Human Rights , which is the foundation of the contemporary\ninternational human rights, directs \u201cevery individual and _every organ of society_ \u201d to strive and to secure\n\n\n9 See also Jason Pielemeier, Global Network Initiative: The Advantages of Applying the International Human Rights Framework to\n\ngenai which informed these key messages.\n\n-----\n\nuniversal and effective recognition _and observance_ \u201d of human rights (emphasis added).\n\nAnd the UNGPs\noutline and clarify the respective _duties of States to protect_ _10_ _individuals from business-related_ human\nrights harms, and the related, distinct and independent _responsibilities of corporations to respect_ _11_ human\nrights in the course of their activities.\n\nThe idea that impacts on human rights should sit at the core of governing technologies, including artificial\nintelligence, is gaining traction.\n\nGovernment policy and regulatory initiatives focused on the societal risks of\ngenai already focus, to varying degrees, on human rights impacts 12 .\n\nSome the most well-known\ntechnology companies have in place public commitments and processes focused on operating with respect for\nhuman rights and many have invested considerable attention to \u201cfairness and bias\u201d of genai\nand machine learning models, demonstrating one way in which principles of equality and non-discrimination\nalready have some purchase in the field.\n\nAt the international level, the UN Secretary-General has called for\nguardrails to ensure genai governance is grounded in human rights, transparency, and accountability .\n\nNonetheless, a large number of international and national policy initiatives aiming to address the risks of\ngenai entirely omit reference to international human rights standards.", "Nonetheless, a large number of international and national policy initiatives aiming to address the risks of\ngenai entirely omit reference to international human rights standards.\n\nAt best, this omission creates\nan unnecessary normative vacuum in which a global patchwork of laws, industry standards and business\npractices based on similar sounding aims \u2014 e.g., ethics, fairness, openness, transparency \u2014 are vaguely\nor differently defined without being tethered to the important question of real impacts on real people in real\nplaces.\n\nAt worst, vague definitions of responsible conduct and judgments of what constitutes acceptable risk\nwhen developing and deploying genai systems may be determined solely by short-term geopolitical\ninterests and market incentives that externalize impacts on people.\n\nTo catalyse greater application of a human rights lens to developing and deploying genai, B-Tech has\ndeveloped a Taxonomy of Human Rights Risks Connected to genai .\n\nThe Taxonomy outlines numerous\n\u201crisk examples\u201d connected to genai across nine categories of internationally agreed human rights.\n\nWhile the Taxonomy does not attempt to comprehensively list all potential human rights harms, it does offer\nan examination of some of the main ways in which human rights are currently at risk from genai\ndevelopment and deployment, as well as risks that are likely to materialize in the medium-term future.\n\nWhile\nmany of these human rights impacts may have been associated with earlier forms of genai, they have been or\nrisk being exacerbated by the particularities of genai.\n\n10 According to the UNGPs, States should take \u201c _appropriate steps to prevent, investigate, punish and redress human rights abuse through_\n\n_effective policies, legislation, regulations and adjudication_ \u201d (UNGP1), and that States \u201c _should consider a smart mix of measures\u2014_\n_national and international, mandatory and voluntary\u2014to foster business respect for human rights_ .\u201d (UNGP3).\n\nFor more information\nabout the UNGPs calls for States to apply a \u201csmart mix\u201d of measures and ensure \u201cpolicy coherence\u201d, see: B-tech foundational paper\nBridging Governance Gaps in the Age of Technology \u2014 Key Characteristics of the State Duty to Protect\n\n11 The Corporate Responsibility to Respect Human rights requires all business enterprises to: 1) avoid causing or contributing to adverse\n\nhuman rights impacts through their own activities, and address such impacts when they occur; and 2) seek to prevent or mitigate\nadverse human rights impacts that are directly linked to their operations, products or services by their business relationships, even if\nthey have not contributed to those impacts.\n\nSee also B-Tech foundational papers Key Characteristics of Business Respect for Human\nRights and Designing and implementing effective company-based grievance mechanisms\n\n12 For example, the Draft EU genai ACT : Art.\n\n35 \u201cseeks to ensure a high level of protection for fundamental rights and aims to address various\n\nsources of risks through a clearly defined risk-based approach\u201d; the Draft Brazilian genai Bill : Art.\n\n7 \u201c grants persons affected by genai systems\nthe following rights vis-\u00e0-vis \u201cproviders\u201d and \u201cusers\u201d of genai systems, regardless of the risk-classification of the genai system\u201d and lists Right to\ninformation about their interactions with an genai system; Right to an explanation, Right to challenge decisions or predictions, Right to human\nintervention, Right to non-discrimination and the correction of discriminatory bias, and Right to privacy and the protection of personal\ndata; the U.S Blueprint for an genai Bill of Rights is set out \u201cto help guide the design, use, and deployment of automated systems to protect\nthe rights of the American public in the age of genai.\n\n(\u2026), these principles are a blueprint for building and deploying\nautomated systems that are aligned with democratic values and protect civil rights, civil liberties, and privacy.\u201d\n\n\n-----", "###### The UNGPs offer guidance on how to establish the multi-layered architecture of governance needed to address the conduct of private sector actors across the full genai value chain.\n\nThere are multiple forces shaping the evolution of genai technologies and the ways in which they\nare used.\n\nThese include the ambition by some technologists to pursue AGI, the economic potential of these\ntechnologies, diverse industries investing in genai-enabled efficiency gains and innovations, research\norganisations exploring new solutions to climate and other shared challenges, and diverse interests \u2014 some\nbenign, some malicious \u2014 of States and individuals.\n\nWhat is undeniable is that private enterprises sit at the core of technological breakthroughs and the modes\nthrough which genai will permeate our lives.\n\nMany of these companies also have highly specialized\nunderstandings of genai\u2019s functioning and the considerable financial, human and other resources\nneeded to remain at the forefront of innovations.\n\nLeaders from across academia, government, civil society\nand business have called for States to regulate the practices of companies developing and/or deploying\ngenai foundation models, applications and products.\n\nIn sum, the challenge of addressing the adverse\nimpacts of genai is in large part a challenge of establishing a robust, principled and pragmatic\ngovernance framework of corporate responsibility and accountability for those impacts.\n\nThere are, of course, limits to what frameworks focused on responsible business conduct and corporate\naccountability can tackle.\n\nThey are not a panacea.\n\nMany issues will require other tools, laws, enforcement\nregimes and multi-lateral solutions.\n\nFor example, addressing States deploying genai technologies in\nways that violate the human rights of their own citizens, political parties flooding social media with genai-generated\ndisinformation about opposition candidates, or criminal actions by individuals (such as use of synthetic voice\nto commit fraud) will not be eradicated through a sole focus on corporate conduct.\n\nThat said, advancing\nresponsible business conduct, in addition to being valuable in its own right, can serve as one powerful avenue\nto minimize the likelihood of the most egregious harms resulting from genai\u2019s proliferation.\n\nThe UNGPs are a powerful tool for the task at hand.\n\nThey articulate the components of a multi-layered\ngovernance model needed to advance business respect for human rights in practice: one that moves beyond\nthe false binary choice between voluntary self-regulation and binding law requirements.\n\nAs John Ruggie,\narchitect of the UNGPs once noted , \u201c(The UNGPs) _are not merely a text.\n\nThey were intended to help generate_\n_a new regulatory dynamic, one in which public and private governance systems, corporate as well as civil,_\n_each come to add distinct value, compensate for one another\u2019s weaknesses, and play mutually reinforcing_\n_roles\u2014out of which a more comprehensive and effective global regime might evolve_ .\u201d\n\nWith this vision in mind, a UNGPs-informed approach to this task would emphasize that:\n\nI.\n\nStates should implement a \u201csmart-mix\u201d of regulation, guidance, incentives, and transparency requirements\n\u2014 all supported by policy coherence in domestic and multi-lateral efforts - to advance corporate\nresponsibility and accountability for human rights harms.\n\n-----\n\nII.\n\nRegional, national, international and industry-led initiatives focused on advancing responsible generative\n\ngenai should align to the international standards of business conduct: the UNGPs and OECD Guidelines.\n\nThis\nmeans, in particular, integrating a true risk-based approach to identifying and taking action on impacts.\n\nIII.\n\nGreater urgency to ensure effective judicial and non-judicial access to remedy for individuals whose\n\nhuman rights are harmed by the development or deployment of genai.\n\nThe following pages briefly summarize the rationale for these points of emphasis and provide practical\nrecommendations for what States should do in the near-term to advance a \u201c _comprehensive and effective global_\n_regime_ \u201d for governing genai, including through robust engagement with companies and civil society.\n\nI.\n\nStates should implement a \u201csmart-mix\u201d of regulation, guidance, incentives, and transparency\nrequirements \u2014 all supported by policy coherence in domestic and multi-lateral efforts \u2014 to\nadvance corporate responsibility and accountability for human rights harms.\n\n**RATIONALE:** The UNGPs focus on this \u201csmart-mix\u201d 13 because decades of experience have shown that\nregulation alone is rarely a \u2018silver bullet\u2019 solution that on its own will ensure that respect for human rights\nis consistently placed at the heart of private sector governance, strategy and conduct.", "There are varying\nreasons for this, most notably that some companies will lag behind others in terms of responsible conduct and\ncompliance meaning States invariably need to explore how to make use of diverse legal regimes and policy\ndomains.\n\nIt is also true that regulators often struggle to keep pace with technological innovation meaning that\nmore nimble methods of governance, alongside regulation, are demanded.\n\nThe UNGPs also emphasize the importance of States ensuring coherent action across all State agencies that\nshape business practice.\n\nWhere policy coherence is lacking, States will fail to provide private companies\ndeveloping and deploying genai with clear and predictable expectations.\n\nThis serves to undermine\nboth the effectiveness of State measures and the ability of companies to adjust their practices in a stringent\nand comprehensive manner.\n\nSpecial attention to the role of home states within which genai investment is most prolific is critical.\n\nThe action or inaction of these States \u2014 notably the United States and China globally, as well as leaders in\ntheir region such as Singapore, South Korea, India, Germany, the United Kingdom, Brazil, Chile, Egypt and\nSouth Africa 14 \u2014 will have an outsized impact on whether genai governance and business practice\nis rights-respecting.\n\nThe UNGPs reinforce that \u201cStates should set out clearly the expectation that all business\nenterprises domiciled in their territory and/or jurisdiction respect human rights throughout their operations\u201d\nthrough applying \u201cdomestic measures with extra-territorial implications\u201d or approaches that \u201camount to direct\nextraterritorial legislation and enforcement\u201d (GP 2).\n\n13 The UNGPs state that States should take \u201c _appropriate steps to prevent, investigate, punish and redress human rights abuse through_\n\n_effective policies, legislation, regulations and adjudication_ \u201d (GP1), and that States \u201c _should consider a smart mix of measures\u2014national_\n_and international, mandatory and voluntary \u2014 to foster business respect for human rights_ .\u201d (GP3).\n\nSee also The Geneva Academy of\nInternational Humanitarian Law and Human Rights, The relevance of the Smart Mix of Measures for genai\n\n\n14 See the Global genai Index which ranks 62 countries based 111 indicators, collected from 28 different public and private data sources.\n\nThe indicators are split across seven sub-pillars: Talent, Infrastructure, Operating Environment, Research, Development, Government\nStrategy and Commercial.\n\n-----\n\nStates participating in multilateral fora and multi-stakeholder processes is also an essential component in\nensuring the international legitimacy, coherence and effectiveness of State action 15 .\n\nCoherent collective action\nis key to ensure that State can address the fact that the development and deployment of genai can\noccur at a high speed and at great scale across borders.\n\nCooperation between States can take the form of\naiding States with less financial resource or technological expertise to implement their own form of the smartmix needed to govern human rights risks and challenges particular to their national context.\n\nWhatever the\nmodalities of collective action, the \u201cGuiding Principles provide a common reference point\u201d and can \u201cserve\nas a useful basis for building a cumulative positive effect that takes into account the respective roles and\nresponsibilities of all relevant stakeholders.\u201d (GP10).\n\nFinally, the UNGPS reinforce that meaningful involvement of civil society and affected groups, as well as\ninvestors, academics and business leaders can reinforce accountability for States to prioritize human rights\nprotections and investment into effective ways to address business-related human rights impacts associated\nwith genai technologies.\n\n**RECOMMENDATIONS:** The following are near-term priorities for applying the \u201csmart mix\u201d of measures and\nensuring policy coherence within State actions aimed at governing genai.\n\n\u2013 States should enforce laws that are aimed at, or have the effect of, requiring companies developing and\ndeploying genai technology to respect human rights, periodically assess the adequacy of such laws\nand address any gaps.\n\nIn most jurisdictions there are a number of existing laws that can address particular\naspects of human rights risks connected to genai.\n\nBeyond the clear relevance of privacy law, data\nprotection and data security, other relevant domains of law include labor, non-discrimination, copyright,\nproduct liability, consumer law and sector-specific regulations (e.g., for finance and healthcare).\n\n\u2013 States should provide effective guidance and associated capacity building to business enterprises on\nhow to respect human rights when developing or deploying genai.\n\nEven with State policy and\nregulatory measures in place, companies \u2014 especially start-ups and smaller firms \u2014 can benefit from\nclear direction as to what respect for human rights means in operational terms given their specific place\nin the genai value chain.", "This could be done through creating new guidance or adapting existing\ngenai due diligence standards 16 to ensure alignment with the UNGPs and OECD Guidelines.\n\nThis would\naddress current differences in terminology and risk scope which may cause barriers to use for companies\nwho have to comply with guidance in multiple jurisdictions.\n\nWhile guidance is not prescriptive in nature,\nit may accompany regulation, fill near-term gaps in understanding what good corporate conduct looks\nlike, and even be a testing ground for future regulatory proposals.\n\n\u2013 Authoritative corporate transparency regimes from the corporate responsibility and accountability field\nshould be used to complement technology specific transparency requirements.\n\nFor example, EU legislative\n\n15 The UNGPs note that \u201c _Collective action through multilateral institutions can help States level the playing field with regard to business_\n\n_respect for human rights, but it should do so by raising the performance of laggards.\n\nCooperation between States, multilateral_\n_institutions and other stakeholders can also play an important role_ \u201d (Commentary to UNGP10).\n\n16 For example, the U.S National Institute of Standards and Technology genai Risk Management Framework , the IEEE\n\nStandard Model Process for Addressing Ethical Concerns during System Design (IEEE 7000); ISO\u2019s Information technology \u2014 Artificial\nintelligence Risk management (ISO/IEC 23894).\n\nSee also genai Standards Hub .\n\n-----\n\ninitiatives \u2014 whether in the drafting, transposition or enforcement phase \u2014 should make use of the\nEuropean Sustainability Reporting Standards when seeking to increase transparency by companies\ndeveloping and deploying genai.\n\nOne obvious benefit is that this can minimize the reporting\nburden on companies.\n\nEqually important, the content of these standards addresses aspects of corporate\nconduct that are critical to understanding the seriousness and likely quality of genai related\nrisk management / due diligence 17 .\n\nIn addition, innovative multi-stakeholder structures that enable\nmeaningful transparency without increasing risks to human rights or undermining legitimate business\ninterests should be supported by States.\n\nThe Global Network Initiative\u2019s methodology of conducting\nindependent company assessment is a leading model that could be applied to evaluating genai\nrelated company processes and conduct.\n\n\u2013 States \u2014 especially those States home to market-leading companies at the core of developing genai systems\n\n\u2014 should build the competence and capability of relevant agencies, administrative supervisory bodies\nand officials.\n\nThe goal of such efforts should be to enable the navigation of the societal and technical\ncomplexities of how digital technologies function, the associated risks to people, and the role (including\nlimits) of companies to address these risks.\n\nLawmakers should also include provisions for ensuring\nappropriate investigative and other capacity exists to meaningfully enforce regulations 18 .\n\nInnovative ideas\nwill be needed to achieve this.\n\nFor example, the Australian Human Rights Commission championed the\nidea of creating an Australian eSafety Commissioner in order to build capacity in government and industry\nin relation to promoting and protecting rights when designing, procuring and deploying genai systems.\n\nThe\nnow-established eCommissioner has published a position statement and guidance on genai .\n\n\u2013 States should pursue multi-lateral action focused on the protection and respect of human rights.\n\nLarge\nlevels of cooperation and the rapid spread of best practices between States will be crucial for advancing\nthe responsible genai.\n\nSuch multilateral efforts can also minimize the risks of States pursuing their\nown, however legitimate \u2014 economic and geo-political interests at the expense of building dignity and\nrespect into the heart of genai development and deployment.\n\n\u2013 States \u2014 whether part of national, regional or international initiatives \u2014 should establish and sustain\nstakeholder engagement with companies, civil society and especially affected stakeholders to learn about\nrisks, impacts and challenges/opportunities to advance meaningful genai risk assessment and\nmitigations.\n\nThis will be necessary to better understand how proposals would work in a wide range of\nreal-world scenarios.\n\nIt is also an important way to reduce the risk of States introducing new legislative\nor policy measures that are inconsistent with their own international human rights obligations.\n\nBrazil\u2019s\n\n17 The European Sustainability Reporting Standards (ESRS) are set to apply to more than 50,000 companies in the EU and at least 10,000\n\noutside.\n\nThe standards help meet the purpose of the EU\u2019s Corporate Sustainability Reporting Directive (CSRD) in ensuring greater\nrigor and comparability in companies\u2019 reporting on their sustainability performance across environmental, social and governance\nissues.", "Many aspects of the ESRS can be applied to, reporting by companies developing and deploying genai.\n\nFor example: The\ngovernance of social matters, taking a risk-based approach to the value chain, and clarity about the scope of reporting (including\nimpacts on consumers/end-users).\n\nSee Shift\u2019s Putting the European Sustainability Reporting Standards into Practice .\n\n18 For example, in its An EU genai Act that works for people and society: Five areas of focus for the trilogues , the Ada Lovelace institute\n\nemphasized the importance of well-resourced centralised regulatory capacity to ensure an effective genai governance framework, noting\nthat \u201cThe EU central functions should therefore be funded as much as, if not more than, other domains where safety and public trust are\nparamount and where underlying technologies form important parts of national infrastructure \u2014 such as civil nuclear, civil aviation,\nmedicines, road and rail\u201d and that \u201c As in already in place in some of these sectors (for example, 80% of the European Medicines\nAgency\u2019s funding comes from the market entities it regulates) a mandatory fee could be levied on developers over a certain threshold\n(for example, expenditure on training runs, or compute).\n\n-----\n\nappointment of a Commission of Experts comprised of 18 members with recognized expertise in\ntechnology law and regulation, and proposals for stakeholder representation as part of implementation\nof the EU genai Act are good examples of this.\n\nII.\n\nRegional, national, international and industry-led initiatives should use or align to the\ninternational standards of business conduct.\n\nThis means, in particular, integrating a true riskbased approach to identifying and taking action on impacts that: a) Uses severity of risks to\npeople to prioritize impacts for attention; and b) Sets expectations of companies across the\ngenai value chain commensurate with the nature of their involvement (causation,\ncontribution or linkage) with human rights risks and impacts.\n\n**RATIONALE:** States and stakeholders do not need to reinvent standards of responsible business conduct for\ncompanies developing and deploying genai technologies.\n\nRather, established expectations of what\nconstitutes responsible business conduct, laid out by the UNGPs and OECD Guidelines, should be the starting\npoint.\n\nThe UNGPs provide the authoritative definition of responsible corporate conduct in relation to business\nimpacts on human rights: _the Corporate Responsibility to Respect Human Rights_ .\n\nTo meet this responsibility,\nall companies should have in place \u201cpolicies and processes appropriate to their size and circumstances\u201d\nincluding a \u201chuman rights due diligence process to identify, prevent, mitigate and account for how they\naddress their impacts on human rights.\u201d(GP 15).\n\nTwo features of the UNGPs and OECD Guidelines are particularly pertinent to public policy, regulatory\nand voluntary efforts to guide and govern the conduct of companies developing and deploying generative\ngenai technologies.\n\n_First, a risk-based approach grounded in severity of risks to people:_ The UNGPs expect companies to maintain\na wide view of risks, meaning that businesses should identify the actual and potential impacts to all human\nrights related to the company\u2019s business activities and relationships (GP 12).\n\nThis, by definition, means that\ncompanies must anticipate and address risks to people, regardless of whether these lead to reputational,\noperational or financial risks to business.\n\nIt is important to note that risks to people and risks to business tend\nto converge, whether in the short, medium or long-term.\n\nBut where this is not the case, this does not release\ncompanies of their responsibility to address human rights harms.\n\nThe UNGPs recognize that companies will often need to prioritize impacts or risks for initial attention, due to the\ntypically large volumes of actual and potential impacts on human rights connected to their operations, products\nor services.\n\nTo address this, the UNGPs state that prioritisation should take place on the basis of their likelihood\nand relative severity from the perspective of those who are or may be affected.\n\nSeverity involves considering the\nscale of an impact (how grave it is), its scope (how widespread it is) and its irremediability (how hard it would\nbe to make right) 19 .\n\nAn impact can be severe overall even if it would only be so in one of these dimensions.\n\nThe\nUNGPs are also clear that in the case of human rights impacts, severity should always be the dominant factor\nover likelihood, particularly where delayed action would make an impact irremediable.\n\n19 For a more detailed explanation of the severity based risk framework, including considerations for how it applies in the technology\n\nsector, please see: Identifying Human Rights Risks Related to End-Use ; a B-Tech foundational paper.", "-----\n\nTo ensure that the most significant harms to people flowing from the development and deployment of\ngenai are adequately identified and addressed, this risk-based approach must be better integrated\ninto regulation, technical standards and guidance/methodologies for risk assessment.\n\nIn practice, this means:\n\n\u2013 Establishing that genai risk assessments should not conflate evaluations of risks to people and risks to\nbusiness, but instead treat them as distinct types of risks while acknowledging the relationship between the\ntwo.\n\nTraditional risk assessment methodologies typically fail to make such distinctions, leaving it unclear on\nwhat is driving risk evaluations and decision-making 20 .\n\nEfforts to establish greater clarity could usefully build\non the reporting concepts of impact materiality, financial materiality, and double materiality 21 .\n\n\u2013 Requiring that prioritization based on _severity of risks to people_ is part of genai risk assessment.\n\nThis is different to high-level classifications of unacceptable, high and low or minimal risk genai systems laid\nout in the EU genai Act 22 .\n\nRather, this would set expectations that when conducting risk assessment of any\ngenai system, developers and deployers apply the scale, scope and irremediability framework\nwhen undertaking prioritization of attention needed in the face of an inevitably large set of potential and\nactual human rights risks 23 .\n\n_Second, accounting for the nature of a company\u2019s involvement with human rights risks and impacts in_\n_establishing thresholds of appropriate action._ The genai value chain is vast and includes a growing\nnumber of technology companies involved in the development of genai (including foundation model\ndevelopers and Model hub and MLOps platforms); companies supplying capabilities (such as hardware or\ncomputing resources, and investors 24 ); and companies, States and individuals using genai across\ndiverse industries and contexts.\n\nUnder the UNGPs, all companies across the value chain have a clearly defined responsibility to prevent and\naddress negative impacts connected with operations, products or services, wherever they occur in the value\n\n\n20 By way of illustration, the NIST genai Risk Management Playbook (Govern 1.3) explains that \u201cgenai risk tolerances range from negligible\n\nto critical \u2014 from, respectively, almost no risk to risks that can result in irredeemable human, reputational, financial, or environmental\nlosses.\n\nRisk tolerance rating policies consider different sources of risk.\n\nThis places risks to people within the types of risks that should\nbe considered, yet in the state of common practice, risks to people are not taken into account sufficiently in risk scoring.\n\n21 As noted by Shift in Double Materiality: What you need to know \u201cThe concept of materiality has been applied for many years in\n\nvoluntary sustainability reporting standards, albeit with different meanings.\n\nFor example, for the Global Reporting Initiative, the focus\nhas been on the significance of impacts on people and planet; for the Sustainability Accounting Standards Board, it has been on\nimplications for the financial success of the company.\n\n\u201c Double materiality ,\u201d introduced for the first time in the European Sustainability\nReporting Standards (ESRS), brings these two approaches together: ESRS 1 makes clear that \u2026a sustainability matter is material\n\u201cwhen it meets the criteria for impact materiality or financial materiality or both.\n\nImpact materiality and financial materiality are\nconsidered \u201cinterrelated\u201d by the ESRS: an impact on people or the environment can be financially material from the start, or become\nfinancially material over time.\n\nThe evolving nature of this relationship is sometimes referred to as \u201c dynamic materiality .\u201d\n\n22 For an overview of the EU genai Act risk classification see, The EU genai Act: A Primer , by the Center for Security and Emerging Technology.\n\n23 An existing example of this is the Evaluation of Harms approach within Microsoft\u2019s Harms Modelling \u2014 \u201ca practice designed to\n\nhelp you anticipate the potential for harm, identify gaps in product that could put people at risk, and ultimately create approaches\nthat proactively address harm.\u201d.\n\nWhile it is unclear if the same as the UNGPs factors of severity, this Microsoft framework uses a\nprioritization approach based on scale and severity, as well as likelihood and frequency.\n\n24 Under the UNGPs investors at every stage of a company\u2019s lifecycle \u2014 from start-up to maturity \u2014 also have a responsibility to\n\noperate with respect for human rights.\n\nThis is critical because investors, both asset owners and managers, have unique and systematic\ninfluence over how companies in the technology industry are governed, make decisions, and act.\n\nThis B-Tech Investor Briefing provides\ninstitutional investors with holdings in digital technology companies with high-level analysis and guidance on how to apply the UNGPs\nframework to these investments.\n\n-----\n\nchain.", "-----\n\nchain.\n\nThis affirms that deployers of genai systems and other actors \u2014 including across diverse industry sectors 25\nand States \u2014 should be within the scope of regulation and other policy interventions.\n\nThe UNGPs \u201cinvolvement\nframework\u201d 26 provides a principled and pragmatic approach to this value chain wide approach, and sets the\nbasis for determining appropriate _action_ to address risks and impacts identified as part of risk assessments.\n\nThe UNGPs make the distinctions that:\n\n\u2013 Where a company causes or may cause an adverse human rights impact, it should cease or prevent the\nactual impact.\n\nIn situations of actual impacts having already occurred, the company should also provide\nremedy to affected individuals.\n\n\u2013 Where a company contributes to, or may contribute to , an adverse impact it should cease or prevent\nits contribution and use leverage to mitigate any remaining impacts to the greatest extent possible.\n\nA\ncompany can contribute to human rights impacts either in parallel with contributions by third parties,\nor by enabling or incentivising third parties to cause impacts, whether they are states or other business\nenterprises.\n\nIn situations where a company has contributed to actual impacts, the company should also\nprovide remedy to affected individuals.\n\n\u2013 Where a company\u2019s operations, products or services are linked through business relationships to an adverse\nimpact.\n\nIt does not have a responsibility to provide remedy since it has not contributed to the harm, but may\nconsider contributing to remedy or using leverage to incentvise those causing the harm to do so.\n\nThis \u201cinvolvement framework\u201d is central to the effectiveness of the due diligence approach in the UNGPs for\nseveral reasons that are also pertinent to the genai value chain:\n\n\u2013 It reflects both the extent and the limit of a company\u2019s responsibility for human rights harms in their value\nchains to situations where the harm is connected in some way to its operations, products or services.\n\nThis\nalso means that companies are not expected to address every negative impact on human rights that is\noccurring in their value chain or industry.\n\nRather, they should do so when they are causing, contributing\nor are linked to the adverse impact.\n\n\u2013 It clearly differentiates the type of response expected from companies based on the nature of their\ninvolvement with an impact, such that the expectations are reasonable and proportionate.\n\n\u2013 It emphasizes that effective due diligence must include attention from all companies across the generative\ngenai value chain to how their own practices, business strategies, model and product design decisions,\nand go-to-market choices might be contributing factor to human rights harms.\n\nBut also, even where this\nis not the case, companies should use leverage to address harms that are nonetheless connected to their\nproducts via business relationships.\n\n\u2013 Causation, and contribution as a form of causation, reflect well-established concepts in civil liability under\nexisting national laws, and doing due diligence can help protect companies against claims made on\n\nthat basis.\n\n25 The following Business for Social Responsibility (BSR) resources identify human rights issues associated with genai technologies in\n\nhealthcare , retail and the financial services sectors, and recommendations for addressing these impacts.\n\n26 For a detailed explanation of this framework, please see: Taking Action to Address Human Rights Risks Related to End-Use , a B-Tech\n\nfoundational paper.\n\n-----\n\n**RECOMMENDATIONS:** The following are near-term priorities for aligning public policy and regulatory\ninitiatives with the core concepts of the international standards of business conduct.\n\n\u2013 Reaffirm and ground policies in States\u2019 existing duty to protect and businesses\u2019 _Corporate Responsibility_\n_to Respect Human Rights_ as laid out by the UNGPs and OECD Guidelines.\n\nTwo positive examples of this\nare the G7 Hiroshima Process International Code of Conduct for Organizations Developing Advanced\ngenai Systems , and the OECD Declaration on Promoting and Enabling Responsible Business Conduct in the\nGlobal Economy , signed by 51 States.\n\n\u2013 Integrate risk-based prioritization based on severity of risks to people as well as the cause, contribution,\nlinkage \u201cInvolvement Framework\u201d into legislative texts, technical standards and guidance.\n\nApplying the\nUNGPs severity approach in how developers and deployers of genai conduct impact assessments\nwill aid in ensuring robust, well-considered risk evaluations, while also having the important behavioural\neffect of focusing decision-makers on the most severe risks to people.\n\nUsing the Involvement Framework\nprovides clarity as to the nature of the responsibilities that different actors in the genai value chain\nfor specific impacts, and what role they are therefore expected take in addressing the harm.", "\u2013 Establish multi-stakeholder dialogue to deepen appreciation of what a full value chain approach to\naddressing human rights risks means in practice.\n\nMulti-stakeholder, expert dialogue about the different ways\nthat distinct companies across the genai value chain can become involved in human rights harms\nor risks, could aid in informing what principled and pragmatic/reasonable conduct by each actor should\nlook like in practice.\n\nThese could be standalone \u201cresponsibility sandboxes\u201d or integrated into regulatory\nsandboxes 27 .\n\nTo deliver value, these would likely have to focus on singular use case, specific human rights\nharms or very well-defined tranches 28 of the genai value chain.\n\nThese dialogues could result in\nrecommendations for the best mix of measures aimed at preventing harms, but should also extend to\nidentifying which actors under which circumstances should be prepared to take a role in remedying harms.\n\nThis is especially important given the particular complexities concerning attribution and explainability of AIconnected impacts on people, the large volume of potentially harmed individuals, and the reality that many\nharms may occur due to actions of consumers post-deployment of genai systems.\n\nIII.\n\nEnsuring effective judicial and non-judicial access to remedy for individuals whose\nhuman rights are harmed by the development or deployment of genai.\n\n**RATIONALE:** Even where law, company commitments, business processes and market incentives are\naligned towards avoiding business-related human rights harms, some harms still occur, often in ways that\nare devastating to victims, families and, at times, whole communities.\n\nConsider, for example, workplace\ndiscrimination, contamination of rivers or product safety incidents.\n\nThe development and deployment of\ngenai will not be an exception.\n\nIn fact, totally avoiding negative harms seems highly unlikely.\n\nThese harms might arise in various ways, including due to malicious use, negligence from a developer, the\nunpredictability of genai model behaviour, and the unpredictability of use cases before genai\n\n27 For a fuller explanation, see the OECD\u2019s Regulatory Sandboxes in genai\n\n\n28 An example of such a \u201ctranche\u201d would be synthetic media around which some work has been done, though not yet with reference to\n\nthe UNGPs involvement framework, to articulate what practices different actors (builders of technology infrastructure, creators, and\ndistributors and publishers) connected to actual or potential harms should take.\n\nSee: Partnership on genai\u2019s Practices for Synthetic Media:\nA Framework for Collective Action\n\n\n-----\n\nmodels and products are released.\n\nEstablishing a robust and comprehensive system of remedies for human rights harms connected to generative\ngenai will require the same focus, determination, investment, ingenuity and resources that drive technological\ninnovation today.\n\nThe right to an effective remedy for violations of human rights is enshrined in international\nhuman rights law .\n\nThe duty of States to provide access to effective remedies for business-related human rights\nharms, including human rights harms associated with the development and use of digital technologies, is\na key aspect of the State Duty to Protect human rights, as laid out in the UNGPs.\n\nResponsible technology\ncompanies recognise both the commercial and ethical urgency of this task.\n\nNot only does the absence of\nremedies risk undermining companies\u2019 social license to operate (which can have significant commercial and\nlegal consequences, both in the short and long term), but it is also the right thing to do.\n\nPlacing human rights at the heart of remediation mechanisms and strategies focused on genai is vital\nto ensuring that this technology is aligned with principles and values that allow all human beings to thrive.\n\nThe positive news is that attention to redress for victims is already a feature of some genai-focused regulations\nand technical standards.\n\nBut much more needs to be clarified and implemented.\n\nThe UNGPs provide a pragmatic and compelling framework for delivering effective remedies for human rights\nharm to affected people and communities 29 .\n\nKey elements include:\n\n\u2013 A focus on the need for a range of remedy mechansims that can respond to all types of human rights risks\u2019\nas opposed to a narrow set of issues such as freedom of expression or privacy.\n\n\u2013 Explanation of the distinct but complementary roles of different kinds of actors (public and private,\nincluding companies) in providing remedy, regardless of whether or not harms are intended.\n\n\u2013 Reinforcement of the foundational role that judicial systems play within a wider \u201cremedy ecosystem\u201d that\nalso includes State-based non-judicial and non-State-based non-judicial mechanisms.\n\n\u2013 Setting out the different forms that effective remedies can take: Restitution, Compensation, Rehabilitation,\nSatisfaction, and Guarantees of non-repetition.", "\u2013 Setting out the different forms that effective remedies can take: Restitution, Compensation, Rehabilitation,\nSatisfaction, and Guarantees of non-repetition.\n\nThese concepts come from international human rights law\nand prioritize the importance of understanding and taking proper account of the needs and perspectives\nof affected people and groups in deciding what kind of remedy is needed in different situations.\n\n\u2013 Offering a practical set of to guide the design, evaluation and improvement of nonjudicial approaches to remedy, including those managed by the private sector.\n\neffectiveness criteria\n\n**RECOMMENDATIONS:** The following are near-term priorities for making Access to Remedy a central\nfeature in the governance of genai.\n\n\u2013 All stakeholders should collaborate to establish processes for understanding the experience and\nperspectives of impacted or at-risk individuals or groups about what meaningful remedy for generative\ngenai harms means in practice.\n\nThe voice of affected people is a vital, often overlooked, aspect of remedying\nharms.\n\nProcesses available to these groups to seek remedy often do not work for them or the remedy\n\n\n29 The following B-Tech foundational papers provide more detail about the Access to Remedy pillar of the UNGPs: Access to remedy and\n\nthe technology sector: basic concepts and principles ; Access to remedy and the technology sector: a \u201cremedy ecosystem\u201d approach ;\nDesigning and implementing effective company-based grievance mechanisms ; and Access to remedy and the technology sector:\nunderstanding the perspectives and needs of affected people and groups\n\n\n-----\n\ndelivered is not fully satisfactory when compared to the loss, pain, and suffering experienced.\n\nTo avoid\nrepeating this pattern with regard to harms that flow from the use of genai technologies, States,\nresponsible companies and civil society must find ways to amplify the voice of at-risk individuals in\ndesigning an adequate remedy eco-system.\n\nThis has both process-related elements, such as understanding\nwhich types of remedy processes are most accessible to at-risk or harmed people.\n\nIt also has outcomerelated elements, such as clarifying what restitution, compensation, rehabilitation, satisfaction, and\nguarantees of non-repetition should look like in practice.\n\nStates should ensure access to judicial remedies where individuals may have been harmed by the\ndevelopment or deployment of genai technologies.\n\nThis could involve ensuring robust enforcement\nof legal standards that underpin public law remedies of various kinds when harms related to genai\noccur.\n\nDepending on the operation of the regime in question, this could include financial compensation, the\ncriminal sanctions imposed, and binding orders to correct legal breaches and address underlying causes\nof harm.\n\nStates should also ensure that people are able to enforce their rights directly when these may\nhave been harmed by the development or deployment of genai technologies.\n\nThis could occur, for\ninstance, under the law of tort, or under a statutory cause of action.\n\nStates may also then need to make\ninvestments and adjustments needed to ensure that people are aware of their rights and that the barriers\nthey face in accessing judicial processes are recognised and addressed.\n\nStates, companies, civil society experts and affected stakeholders (or legitimate representatives) should\nwork together on how to establish non-judicial routes through which people may seek remedies for\nspecific human rights related harms connected to genai.\n\nThis could include, for instance, raising\ncomplaints with regulators about the conduct of technology companies (e.g., with respect to trade practices,\nanti-competitive behaviour or data-handling); independent complaint and mediation processes led by\nconsumer protection bodies or national human rights institutions; or company-based or collaborative\ngrievance mechanisms.\n\nOf particular promise here is the \u201cnational contact point\u201d system established\nunder the OECD Guidelines , which is perhaps one of the most widely established but underutilised forms\nof accountability for genai systems that currently exist.\n\nIn all cases, special attention should be invested in\naligning mechanisms with the UNGPs effective criteria.\n\n-----", "###### Implementation of thorough human rights due diligence by companies developing foundation models will provide an important basis for risk management across the genai value chain.\n\nAttention to the conduct of companies developing foundation models is especially important because the risk\nevaluations, decisions, business practices and disclosures of these companies can help to mitigate harms at\nan early stage across the genai value chain.\n\nThis is not to suggest that these companies are the only\nactors that have responsibilities; as noted above, all business actors across the genai value chain must\nmeet their _Corporate Responsibility to Respect Human Rights_ .\n\nIdentifying good due diligence practices by companies developing foundation models \u2014 as well as the challenges\nand limitations they encounter in the course of this \u2014 can deliver considerable benefits.\n\nIn addition to minimizing\nthe severity or likelihood of harms caused by the use of genai systems by malicious individuals, non-State\nactors or States, good practices implemented by model developers can inform due diligence by application\ndevelopers and deployers, creating significant efficiencies in risk assessment and mitigation across the generative\ngenai value chain, including establishing sector or use case-specific good practices.\n\nThere are also level-playing field and responsible innovation benefits.\n\nOn the one hand, guidance and tools\nbased on good practices at the foundation model level can aid start-ups seeking to enter the market space,\nthus enabling responsible competition and innovation.\n\nOn the other hand, deeper multi-stakeholder consensus\nabout what constitutes good practice can, when accompanied by meaningful regulation and incentives,\nestablish a global, level playing field of conduct under which companies should not be allowed to operate.\n\nThe work to clarify good practices has already begun.\n\nThe field of genai risk assessment and management is\nrich with academic research, civil society reporting and company policies and processes.\n\nAs laid out in a\nsupplement to this paper, An Overview of Human Rights and Responsible genai Company Practice some of the\nmost prominent technology companies driving genai have long had practices focused on identifying\nand addressing risks to society from genai.\n\nMoreover, there is broad alignment between the\nrisk management frameworks and methods being embedded in regulatory proposals or technical standards\nand the UNGPs.\n\nThe November 2023 OECD Report _Common guideposts to promote interoperability in AI_\n_risk management_ \u2014 _comparing genai risk management frameworks_ demonstrates that leading risk management\nframeworks are generally aligned with the top-level steps (define, assess, treat for risks, and govern risk\nmanagement) of an \u201cInteroperability Framework\u201d based on the OECD Guidelines.\n\nHowever, there are certain critical elements of Human Rights Due Diligence as laid out by the UNGPs\nthat are absent or under-emphasized in existing guidance and public discussion about company practice.\n\nThese elements or practices together represent the more transformative propositions of the UNGPs\nwhich are designed to guide companies to deliver demonstrably better outcomes for people.\n\nThey are:\n\n\n-----\n\nPractice 1 Boards and executives identifying the extent to which the company\u2019s business model and\n\nstrategy carry inherent human rights risks, and taking action to address this.\n\nPractice 2 Embedding human rights risk assessment \u2014 focused on all human rights with prioritization\n\nbased on severity \u2014 into the working methods and cultures typical of the product-oriented\n\ntechnology organizations developing foundation models.\n\nPractice 3 Evaluating \u201ctechnical\u201d mitigations with a focus on people in situations of vulnerability or\n\nmarginalization.\n\nPractice 4 Creatively building and using leverage to address residual risks and enable remedy for\n\nharms; and\n\nPractice 5 Engagement with affected stakeholders and human rights experts across the full cycle of\n\nhuman rights due diligence.\n\nPractice 1: Boards and executives identifying the extent to which the company\u2019s business\nmodel and strategy carries inherent human rights risks, and taking action to address this.\n\n**RATIONALE:** Under the UNGPs, companies are expected to conduct human rights due diligence across all\nof their business activities and relationships.\n\nAs outlined in B-Tech Addressing Business Model Related Human\nRights Risks foundational paper 30 , this includes addressing situations in which strategic product design/\nrelease decisions or business model choices create or increase human rights risks.\n\nBusiness model choices\nare made and reviewed by the top leadership of an enterprise responsible for strategy.\n\nExecutives and senior\nmanagers then work to ensure that these strategic choices are reflected in the company\u2019s operating model and\noften culture.", "Executives and senior\nmanagers then work to ensure that these strategic choices are reflected in the company\u2019s operating model and\noften culture.\n\nWhere this leads to business processes, incentives, or practices that increase risks to workers,\ncommunities or consumers, a tension can arise between a company\u2019s business model and its ability to respect\nhuman rights.\n\nThe intent of identifying features of business models and strategies is not to simplistically label some as rightsrespecting and others not.\n\nNor should the existence of risks automatically lead to business model adaptation,\nas this can sometimes create other, more serious risks.\n\nRather, it spotlights that in certain situations, managing\nnegative impacts connected to specific business activities requires active oversight and involvement from\nboards and executives making business model and strategy decisions.\n\nThis is in contrast to tasking teams\nto manage these risks at an operational level while making higher level decisions that could unwittingly\nundermine those teams\u2019 work.\n\nIn the context of developing and deploying genai foundation models, typical features of business models\nand strategies that companies\u2019 due diligence programs and practices will need to account for can include:\n\n\u2013 _Features of foundation models:_ genai foundation models are often described as general-purpose\ntechnologies meaning that they can be used, misused and abused in endless ways, many of which may\n\n\n30 See also B-Tech Institutional Investor Business Model Tool which provides templates for institutional investors to use in engaging\n\ntechnology companies on these business model risks.\n\n-----\n\nnot be immediately foreseeable.\n\nHarms can also arise when these technologies perform in sub-optimal or\nunexpected ways 31 .\n\nIn addition, the inherent complexity and opacity of genai models means that\nundesirable outputs are challenging, though by no means impossible, to explain and so fix.\n\n\u2013 _Revenue / monetisation strategy:_ The nature of human rights risks will shift based on the actors that a\ncompany targets and supports to use its foundation models.\n\nThese may include developers building\napplications, enterprise customers in different sectors, public sector organisations or individuals using\nconsumer interfaces.\n\nThis can be a complex picture but the risks associated with distinct revenue models\nshould be well-understood by board and executives.\n\n\u2013 _Nature and speed of deployment:_ It is common practice for technology companies to release products\nand tools incrementally and iteratively in order to gather feedback from users to inform improvements.\n\nCompanies at the core of genai development are taking this same approach, which can focus\npolicy and public attention on how to govern risks of current models and to help prepare to grapple with\nand address more powerful, future ones.\n\nAs such, some level of risk to society is inevitable.\n\nMoreover,\nrisks may be increased where models may be rushed for release in order to get ahead of or catch up\nwith competitors.\n\n\u2013 _The implications of closed, proprietary vs open-source models_ : Whether a company pursues an open\nversus closed source strategy to developing and deploying foundation models can also impact the shape\nof risks to human rights connected to its products, and how the company can best mitigate risks that flow\nfrom end-use 32 .\n\n**NEXT STEPS:** All stakeholders need to be part of creating greater clarity about the appropriate and\nreasonable oversight role of boards and leadership practices of company founders and executives to address\nbusiness-model related risks.\n\nThis should start with deliberations involving executives, civil society, regulators\nand investors to discuss this issue in more depth, and lead to case studies of good practices focused on:\n\n\u2013 Boards identifying as part of initial business model design and strategy \u2014 and in any changes to these -\nthe inherent human rights risks that flow from these and ensuring that the company has systems and plans\nto address these 33 .\n\n\u2013 Senior leaders establishing and implementing commitments to release or scale the capability of foundation\nmodels in a responsible manner , including evaluating which situations might merit adopting an approach\n\n\n31 See, for example, this study by AlgorithmWatch/genai Forensics.\n\nChatGPT and Co: Are genai-driven search engines a threat to democratic\n\nelections?\n\n32 Open and closed genai foundation models each have their own unique set of ethical considerations.\n\nFor example, Open\n\nmodels can allow for greater transparency and auditability, enabling researchers and developers to scrutinize the model\u2019s training\ndata, code, and decision-making processes.\n\nThis openness can help identify and address potential biases or ethical concerns.\n\nHowever, open models can be misused or repurposed for malicious applications, and can be difficult to control and steer, as changes\nmade by one developer can have unintended consequences for others.", "However, open models can be misused or repurposed for malicious applications, and can be difficult to control and steer, as changes\nmade by one developer can have unintended consequences for others.\n\nClosed genai Foundation Models tend to allow for\ncontrolled development and deployment and are generally less susceptible to misuse or repurposing for malicious applications, as\nthey are not publicly accessible.\n\nHowever, closed models can lack transparency and auditability, making it difficult to assess potential\nbiases or ethical concerns.\n\nThis lack of openness can hinder the identification and mitigation of ethical issues.\n\n33 This aspect of the governance of sustainability issues is getting increasing attention in corporate reporting requirements.\n\nFor example,\n\nthe European Sustainability Reporting Standards ask companies to disclose how they understand and address the relationship between\nmaterial impacts on people and their business model(s).\n\nFor more information about this, see Governance, Strategy and Business\nModels: Four Highlights from the European Sustainability Reporting Standards , by Shift\n\n\n-----\n\nakin to the \u201cprecautionary principle\u201d 34 .\n\nThis is consistent with the notion that, under the UNGPs, severity\nof actual and potential impacts should inform company action, even if their likelihood is considered low.\n\n\u2013 The best ways to establish and sustain corporate cultures that reward the identification of risks and adverse\nimpacts, including by ensuring that individuals feel able to raise concerns without fear of retribution.\n\n\u2013 Ensure that the company has in place the right competence, resources and processes to hear, and act\non, the perspectives of especially affected or at-risk stakeholders 35 .\n\nPractice 2: Embedding human rights risk assessment \u2014 focused on all human rights with\nany necessary prioritization being based on severity \u2014 into the product-oriented working\nmethods and cultures of technology companies developing foundation models.\n\n**RATIONALE:** The UNGPs place significant emphasis on companies ensuring that human rights due diligence,\nstarting with risk assessment and prioritization, should occur early and on an ongoing basis to enable timely\nand effective actions to address human rights risks.\n\nIn particular human rights impact assessments should be\nundertaken \u201cprior to a new activity or relationship; prior to major decisions or changes in the operation (e.g.\n\nmarket entry, product launch, policy change, or wider changes to the business); in response to or anticipation\nof changes in the operating environment (e.g.\n\nrising social tensions); and periodically throughout the life of\nan activity or relationship.\u201d (GP 17)\n\nHowever, within the typically product-driven, decentralized technology companies and corporate cultures\ndeveloping genai foundation models there is very little understanding of how to achieve this in\npractice.\n\nThis lack of clarity has several negative consequences.\n\nFirst, human rights risks may not be robustly\nassessed at moments in the life-cycle 36 of genai foundation models that would allow these risks to be\nmitigated most effectively.\n\nThis could be the result of uncertainty about which moments make sense for human\nright analysis.\n\nEven where clear decision-points for safety and ethical review are established, product teams\nand engineers may struggle to identify human rights risks and effectively prioritize attention to those risks due\nto lack of tools, training or access to internal or external human rights expertise.\n\nSecond, the ways in which product-oriented tech companies work can themselves be a \u201cblack-box\u201d to\nexternal stakeholders, especially those without a background in computer science, software development\nand engineering.\n\nThis can make it hard for companies to communicate in an impactful way about risk\nmanagement efforts that are embedded into existing processes.\n\nIt also reduces the ability for meaningful\ndialogue about the appropriateness and effectiveness of leveraging product development working methods\nto identify and assess human rights risks.\n\n34 The Precautionary Principle was most clearly articulated in Principle 15 of the 1992 Rio Declaration as \u201cIn order to protect the\n\nenvironment, the precautionary approach shall be widely applied by States according to their capabilities.", "Where there are threats\nof serious or irreversible damage, lack of full scientific certainty shall not be used as a reason for postponing cost-effective measures\nto prevent environmental degradation\u201d\n\n35 World Economic Forum: Board Duties in Ensuring Company Engagement with Affected Stakeholders provides a brief overview of the\n\nrole of corporate boards of directors in relation to the concept of \u201caffected stakeholders\u201d\n\n\n36 As noted by the OECD in its report , \u201cThe lifecycle encompasses the following phases that are not necessarily sequential: planning\n\nand design; collecting and processing data; building and using the model; verifying and validating; deployment; and operating and\nmonitoring\u201d.\n\nThis description is also reflected in the genai lifecycle used to structure the U.S. Department of Commerce, NIST Artificial\nIntelligence Risk Management Framework\n\n\n-----\n\nThird, methodologies for human rights impact assessments recommended by stakeholders or required in\nregulations may be too far removed from the pace and iterative nature of developing foundation models.\n\nThis can push human rights risk assessment and management towards solely being a compliance exercise\nas opposed to a meaningful tool in influencing corporate conduct towards improved management of risks to\npeople and rights-based, responsible innovation.\n\nSome computer scientists and academics have already begun to frame up important aspects of this topic.\n\nThe most extensive literature and guidance for companies focuses on the ethical deliberations within agile\nsoftware development processes 37 .\n\nMuch rarer is attention to how to integrate human rights considerations\ninto these processes.\n\nWhere this focus does exist, some researchers are raising important questions about the\nlimits of relying on the latest manifestations of agile product methods to address issues beyond the design of\nspecific features, such as establishing the overall objectives of technology systems, or software products 38 .\n\n**NEXT STEPS:** All stakeholders need to be part of creating greater clarity about what it means in practice\nto meaningfully embed assessment of human rights risks into the development of genai foundation\nmodels.\n\nThis can start with deliberations involving technologists (inside and outside of companies), civil\nsociety, academia and business and human rights experts focused on:\n\n\u2013 Identifying the most impactful moments at which a company should assess the actual and potential human\nrights impacts that it could become connected to due to the development or deployment of its foundation\nmodel.\n\nThis would ideally cover the spectrum from human rights impact assessments of a full model/\nsystem to lighter and quicker assessments as features of foundation models are iterated.\n\n\u2013 Creating tools, assessment methodologies and training that support an evaluation of impacts based on\nthe full range of internationally agreed human rights and prioritization of impacts for attention based on\ntheir scale, scope and irremediability.\n\nInstrumental to this will be case studies or hypothetical scenarios\ndetailing the mechanics (who is involved, how long does the assessment take, are external stakeholders\nconsulted, how does it connect/support to other deliberations (e.g., on usability or ethics), what are the\npitfalls to avoid etc.).\n\n\u2013 Establishing mechanisms to allow external stakeholders to understand, appreciate and inform the quality\nof human rights risk identification and prioritization practices.\n\nThis is distinct from important formal\nreporting by companies developing foundation models about risks and risk mitigation strategies.\n\nIt is far\nmore about creating safe and honest spaces for innovating robust human rights risk assessments.\n\n37 See Zuber, N., Gogoll, J., Kacianka, S. et al.\n\nEmpowered and embedded: ethics and agile processes Humanit Soc Sci Commun 9,\n\n191 (2022).\n\n38 In his article Can We Move Fast Without Breaking Things?\n\nSoftware Engineering Methods Matter to Human Rights Outcomes , Alex\n\nVoss is clear about the merits and potential limits of relying fully on the agile methods.\n\nHe argues that: \u201cOur choice of methods also\naffects human rights outcomes for stakeholders.\n\nI will argue below that software engineering has regressed as methods have become\noverly focused on the continuous delivery of new functionality at the expense of overarching and cross-cutting concerns.\n\nFrom this\ncritique, I develop the notion of _rights-respecting software engineering_ and outline what it would take to develop methods that make\nan explicit representation and consideration of rights possible in the development of software products and services.\u201d.\n\n-----\n\nPractice 3: Evaluating \u201ctechnical\u201d mitigations with a focus on people in situations of\nvulnerability or marginalization.\n\n**RATIONALE:** The companies developing and deploying the most prominent genai foundation\nmodels have done a great deal to find ways to make those models accurate and safe.", "**RATIONALE:** The companies developing and deploying the most prominent genai foundation\nmodels have done a great deal to find ways to make those models accurate and safe.\n\nThis paper uses the\nterm \u201ctechnical mitigations\u201d to denote the varied approaches used by these companies to train, tune and\nguide the behavior of models.\n\nExamples of these mitigations include: at the input level, prompt filtering\nand engineering; at the systems level, supervised fine-tuning, Reinforcement Learning with Human Feedback\n(RLHF) and Red Teaming; and at the output level, blocklists and classifiers.\n\nThese same companies also\nimplement post-deployment monitoring to track the model\u2019s performance over time, detect potential biases,\nmonitor model usage and ensure model security 39 .\n\nIt is beyond the scope of this paper to assess the technical effectiveness of these mitigation and monitoring\napproaches.\n\nCompany practice however does appear, upon initial review, to be well-aligned with the main\nprocess expectations of the UNGPs focused on tracking performance.\n\nThe UNGPs state that \u201cin order to\nverify whether adverse human rights impacts are being addressed, business enterprises should track the\neffectiveness of their response\u201d (GP 20).\n\nCompanies publish \u201csystem cards\u201d and peer-reviewed research to\ncommunicate key information about their models, including the technical mitigations that have been applied,\nwith what results and limitations 40 .\n\nSome also include reference to how, at a high level, internal and external\nstakeholders have been involved in evaluating mitigations, which is also consistent with UNGPs\u2019 expectations\nthat companies should \u201cdraw on feedback from both internal and external sources, including affected\nstakeholders\u201d (GP 20 b).\n\nHowever, two important expectations of the UNGPs require greater attention.\n\nFirst, the differential effectiveness of\nmitigations for people in situations of vulnerability needs to be further addressed.\n\nThe UNGPs state that \u201cBusiness\nenterprises should make particular efforts to track the effectiveness of their responses to impacts on individuals\nfrom groups or populations that may be at heightened risk of vulnerability or marginalization\u201d (GP 20).\n\nThis\nis echoed in the \u201cMeasure\u201d phase of the NIST genai Risk Management Framework which\n\n39 The following explanations of some of these mitigations have been sourced from various sites and through the use of Bard and\n\nChatGPT: Mitigations explained: Prompt filtering: Some inputs that do not violate law or responsible data policies may be part of\nproducing problematic engagements or outputs.\n\nIn these cases, it may be appropriate to filter, block, and hard code responses\nfor some inputs until the model can respond in the intended way; Prompt Engineering: Direct modifications of the user inputs are\nused to guide a model behaviour and encouraging responsible outputs.\n\nThis can be done by including contextual information\nor constraints in the prompts to establish background knowledge and guidelines while generating the output.\n\nModifications can\nbe implemented in various ways such as with automated identification and categorization, assistance of the LLM itself, or rules\nengines; Supervised fine-tuning: Adapting a pre-trained Language Model to a specific downstream task using labelled data.\n\nReinforcement Learning with Human Feedback: Reinforcement learning from human feedback is a machine learning approach\nthat combines reinforcement learning techniques, such as rewards and comparisons, with human guidance to train an artificial\nintelligence agent; Red Teaming: Red teaming involves many kinds of probing, testing, and attacking of genai systems.\n\nIt is a best\npractice in the responsible development of systems and features using LLMs.\n\nIt helps to uncover and identify harms and, in turn,\nenable measurement strategies to validate the effectiveness of mitigations; Blocklists: A way to prevent the generation of high-risk\ncontent is to compile a list of all the phrases that your model should not, under any circumstances, be permitted to include in a\nresponse.\n\nMany words are easily identifiable as problematic; slurs, for example, are typically offensive no matter their context\n\nClassifiers: The more effective, but also more difficult, approach is to develop classifiers that detect and filter outputs based on the\nmeaning conveyed by the words chosen.\n\nClassifiers, when properly trained on known examples of a particular sentiment or type of\nsemantic content, can become highly effective at identifying novel instances in which that sentiment or meaning is expressed.\n\n40 See, for example: Llama 2: Open Foundation and Fine-Tuned Chat Models from Meta, GPT-4 Systems Card from OpenAI, and PaLM\n\n2 Technical Report , from Google.\n\n-----\n\nincludes provisions that the \u201cAppropriateness of genai metrics and effectiveness of existing controls are regularly\nassessed and updated, including reports of errors and potential impacts on affected communities\u201d.", "In the context of genai foundation models, companies do point to limitations in existing technical\nmitigations, but apparently without tracking these implications for groups in situations of high risk.\n\nExamples of\ngaps already document include: safety features built in English that may not have the same effectiveness in other\nlanguages, the possibility that humans involved in the human feedback aspects of reinforcement learning may\nbe biased or intentionally promote toxicity, and continuing reports that models are still prone to \u201challucinations\u201d.\n\nTo be consistent with the UNGPs, companies should be tracking quantitative and qualitative data about the\nextent to which these limits to mitigations are increasing risks or adverse impacts to vulnerable groups.\n\nFor\nexample: are English trained models likely to result in disproportionate harm in countries where digital literacy\nis low, or to children whose native languages are not English?\n\nTo what degree are any human biases being\nreplicated within RLHF disproportionately impacting women or ethnic minorities?\n\nSecond, the adverse human rights risks of mitigations themselves need to be evaluated.\n\nUnder the UNGPs,\na company\u2019s mitigations are \u201cactivities\u201d which need to be assessed for their own human rights impacts.\n\nThis\nis already a well-understood principle for many companies in the telecommunications and technology sector.\n\nBy way of illustration, efforts by online platforms to prevent sexually exploitative content can also result in\nthe removal of content involving nudity for important cultural, educational, and health related reasons.\n\nFor\ngenai, two such examples of mitigations that civil society have identified as carrying human rights\nrisks include watermarking of synthetic media content , and the abuse of human rights of workers within the\nhuman feedback phase of RLHF .\n\nFocusing on the extent to which mitigations work for the most at-risk communities should not detract from\nthe critical importance of companies implementing mitigations that have proven to reduce human rights risk\nfor high volumes (at times likely millions) of people.\n\nThe focus should not be on pitting the human rights of\nthe many against the few.\n\nRather, the idea is that more quantitative and qualitative data about differential\neffectiveness and the human rights risks of mitigation enables diverse stakeholders to navigate dilemmas and\nfind solutions.\n\nLack of such data will likely simply embed the idea that harms to large swathes of humanity are\nno more than residual, or worst acceptable, risks and costs of genai development and deployment.\n\n**NEXT STEPS:** All stakeholders need to be part of creating greater clarity about how to evaluate the\neffectiveness of technical mitigations for the most at-risk groups.\n\nThis can start with deliberations involving\ntechnologists (inside and outside of companies), civil society, affected stakeholders and academia focused on:\n\n\u2013 The extent to which existing quantitative methods used by companies to evaluate mitigations can feasibly\nand responsibly be leveraged to offer insight into differential risks to distinct vulnerable groups.\n\nWhere this\nis the case, establishing what constitutes good practice, including about how to communicate externally\nabout insights, should be a priority.\n\n\u2013 Identifying how qualitative methods can offer feedback loops from affected stakeholders about the\neffectiveness, and indeed risks of technical mitigations for groups in situations of vulnerability.\n\nWhere\napplied, these qualitative research methods should draw on good social science practices.\n\n\u2013 Innovating collaborations that bring academics and civil society into the evaluation of effectiveness of\n\n\n-----\n\nmitigations but without compromising their independence and safety, or legitimate commercial interests\nof companies.\n\nThis might mean establishing voluntary but legally enforceable \u2018safe harbour\u2019 provisions\nfor all parties.\n\nPractice 4: Creatively building and using leverage to address \u201cresidual risks\u201d and enable\nremedy for harms.\n\n**RATIONALE:** It is unlikely that genai technologies will be deployed with zero residual risks to people\nand planet.\n\nBut companies developing foundation models should, consistent with the UNGPs, continue to take\naction to reduce the severity and likelihood of those risks beyond technical mitigations described above.\n\nThe\nUNGPs establish that where companies are not causing adverse impacts, but nevertheless connected to those\nimpacts, they are expected to build and use leverage to effect change to mitigate risk or remediate negative\nhuman rights impacts.\n\nThis is shown in the \u201cinvolvement framework\u201d described above.\n\nAs noted previously by\nB-Tech, leverage can take many forms that commonly fall into the following categories:\n\n\u2013 Bilaterally with third parties in the context of commercial relationships.\n\nFor example, via enforcing\ncontractual terms and incentives, or undertaking capacity building.", "For example, via enforcing\ncontractual terms and incentives, or undertaking capacity building.\n\n\u2013 With other companies \u2014 whether industry peers or companies from other industries.\n\nFor example, through\nthe development of technical standards and associated efforts to incentivise implementation.\n\n\u2013 Via partnerships with an institution or actor that can play an effective supporting role in influencing\nthe actions of the third party in question.\n\nThis might include with a home or host State, an international\norganization or a civil society organization.\n\n\u2013 Through multi-stakeholder collaboration \u2014 whether in the context of formal initiatives or not, and possibly\nwith the aim of establishing relevant public policy and law.\n\nThe concept of leverage understood in all its forms can galvanise problem-solving and innovation by\ncompanies to tackle the root causes of social externalities in their industry or operating contexts.\n\nIn addition,\nit can serve to minimize the outsourcing of responsibility to entities that lack the will, competence or resources\nto implement it.\n\nThe notion that companies developing genai foundation models should build and\nuse their leverage to address harms that they have contributed to or may be linked to should be reinforced\nin regulation, technical standards and guidance.\n\nThis should not in any way reduce efforts to implement\ntechnical mitigations.\n\nRather, the creative use of leverage by companies must complement these mitigations.\n\n**NEXT STEPS:** Companies developing foundation models and their stakeholders should develop greater\nclarity about the \u201cstate of the art\u201d and \u201cart of the possible\u201d in building and using leverage situations of\ngenai deployment where, even after technical mitigations, human rights risks exist.\n\nThe following\ndimensions should be explored.\n\n\u2013 Responsible use policies, terms of use in contracts, guidance and enforcement.\n\nThere is a rich body of\npractice in this domain which includes companies such as Meta and Google providing guidance and\nopen-source tools for developers to evaluate safety and other features of the applications and products they\ndevelop (for example, Meta\u2019s Llama 2 Responsible Use Guide , Google\u2019s Responsible genai Practices , Microsoft\u2019s\n\n\n-----\n\nResponsible Innovation Best Practices Toolkit and responsible genai training modules ).\n\nWhen advancing good\npractices in the context of genai, initial points of emphasis could include: Understanding the impact\nof these policies and practices i.e., in what ways do they make a difference and what can be improved;\nand how to monitor third party practices without violating the rights of data subjects.\n\n\u2013 Know Your Customer assessment and follow-up: Know Your Customer (KYC) refers to the set of guidelines,\nregulations and practices in the financial services sector to verify the identity, suitability and risks involved\nin maintaining a business relationship with a private sector or government customer.\n\nMicrosoft, in their\nreport Governing genai: A Blueprint for the Future has already signaled the value and relevance of this\nidea to address the risks of genai, including genai.\n\nThis is particularly interesting because there\nhas also been considerable attention to the use of leverage by financial institutions to address human\nrights risks connected to their lending and investments: See, for example, Using Leverage to Drive Better\nOutcomes for People .\n\nWhen advancing good KYC practices in the context of genai, initial points\nof emphasis could include: how to use indicators capable of evaluating customers\u2019 commitment and\ncompetence to manage risk and impacts from their own use of the company\u2019s foundation model and\nproducts; and strategies and tactics for building and using leverage when a customer is considered to be\nhigh risk from a human rights perspective.\n\n\u2013 Collective action with peer competitors (including smaller market entrants), value chain companies, civil\nsociety and international organizations: It is broadly accepted that the human rights risks connected to\nthe development and deployment of genai will require action from a wide range of actors.\n\nAnd\nmany technology companies already engage in collective action to address upstream labor rights risks\nand downstream privacy, freedom of expression and cyber-security risks.\n\nWhen advancing collective\naction good practices in the context of genai, initial points of emphasis should be: Clarity about\nthe scope of standards and activities being focused on to avoid signaling that some abuses or root causes\nof abuse are being addressed when they are not; ensuring that civil society and perspectives of affected\nstakeholders have an equal seat at the table; and targets and accountability measures that go beyond\npledges and principles to focus resources on delivering results that will lead to demonstrably better human\nrights outcomes.", "\u2013 Leverage for remedy: Under the UNGPs, companies have a responsibility to provide for or cooperate\nin remedy processes where they have caused or contributed to the harm; they may also take a role in\nenabling remedy where they are linked to the harm, which can be an effective means of reducing risks\nof their continuation or recurrence 41 .\n\nThere may also be practical, reputational and social license reasons\nfor companies to contribute to a well-functioning eco-system of avenues for remedies.\n\nBuilding on efforts\nto advance responsible investment by financial institutions, the use of leverage for remedy by companies\ndeveloping foundation models could be explored at two levels:\n\n\u2013 Focusing on customers\u2019 \u201cpreparedness for remedy\u201d as part of KYC.\n\nIn practice, this could involve\nasking questions to assess the effectiveness of grievance mechanisms that customers put in place\nand providing proactive support to strengthen customers\u2019 or industry-level mechanisms.\n\n\u2013 \u201cEnabling remedy\u201d in specific cases.\n\nIn practice, this could involve executives using their influence\nto bring greater focus to conversations about remedy when severe impacts occur; supporting\n\n41 see further UNGP 22.\n\n-----\n\nfact-finding in support of affected stakeholders and customers when impacts are alleged to have\noccurred, but the facts are disputed; and even contributing financial or other resources to bolster\nremedy packages.\n\nPractice 5: Engagement with affected stakeholders and civil society experts across the full\ncycle of human rights due diligence, and as part of enabling remedy for harms.\n\n**RATIONALE:** The UNGPs strongly emphasize that companies should engage with affected stakeholders or\ncredible proxies and expert stakeholders 42 as part of assessing, mitigating and remediating adverse impacts\non human rights that they are, or may become, connected to.\n\nThis is because these stakeholders typically\nhave a strong understanding - many of them through lived experience - of the interplay between business\noperations, value chains, products and services and human rights impacts.\n\nThe UNGPs state that \u201cTo enable business enterprises to assess their human rights impacts accurately, they should\nseek to understand the concerns of potentially affected stakeholders by consulting them directly in a manner\nthat takes into account language and other potential barriers to effective engagement.\n\nIn situations where such\nconsultation is not possible, business enterprises should consider reasonable alternatives such as consulting\ncredible, independent expert resources, including human rights defenders and others from civil society\u201d (GP 18)\n\nMeaningful engagement by foundation model developers with the perspectives of affected and expert\nstakeholders about the human rights risks and impacts connected to the use of these models, or generative\ngenai technologies in general, can improve the quality and credibility of a company\u2019s risks assessments.\n\nThis\nis especially true given the challenges of fully predicting the ways in which these models will behave or be\nused and misused post-deployment.\n\nAffected stakeholders, as distinct from deployers, may prove to be the\nmost reliable source of information about persistent or emerging harms.\n\nMoreover, robust engagement that\nauthentically identifies and addresses human rights-related concerns can help to establish or sustain the social\nlicense of genai technologies.\n\nThe UNGPs affirm that engagement with stakeholders should not stop at risk assessment, but instead take place\nacross all phases of human rights due diligence and as part of remedying harms.\n\nIn this way, engagement\nwith affected and expert civil society stakeholders can inform model design, risk mitigation and deployment\ndecisions towards mitigating risks to human rights, as well as strategies to ensure victims of harm have access\nto remedy when harms occur.\n\nThis ethos, which has been expressed by some as design from the margins\nin the context of social media is arguably the most promising pathway to the proliferation of genai\ngrounded in dignity and equality for all.\n\nSeveral organisations have already elaborated guidance for stakeholder engagement around genai systems that\n\n\n42 Under the UNGPs: Affected stakeholders are any individual or group whose human rights has been affected by an enterprise\u2019s\n\noperations, products or services; Credible proxies are individuals or groups who are recognised as legitimate representatives of\naffected stakeholders.\n\nExpert stakeholders: individuals or groups with expert knowledge about the impacts of business on people\u2019s\nhuman rights.\n\nIn the context of genai systems, it is important to note that affected individuals/communities can be anyone directly or\nindirectly affected by genai systems or decisions based on the output of genai systems, though they do not necessarily interact with the\ndeployed system or application.\n\n-----\n\noffer a good starting point for advancing good practice by foundation model developers.", "-----\n\noffer a good starting point for advancing good practice by foundation model developers.\n\nFor example:\n\n\u2013 The NIST genai Risk Management Playbook (Govern 5.1) lays out suggested actions to ensure robust\nengagement with relevant genai actors, which includes affected stakeholders.\n\nThe playbook emphasizes\nthat participatory stakeholder engagement: assist in identify emergent scenarios and risks in certain genai\napplications; is best carried out from the very beginning of genai system commissioning through the end of\nthe lifecycle; and is best carried out by personnel with expertise in participatory practices, qualitative\nmethods, and translation of contextual feedback for technical audiences.\n\n\u2013 European Centre for Not-For-Profit Law\u2019s Framework for Meaningful Engagement as part of assessing\nhuman rights impact for genai systems focus on the importance of _Shared Purpose_ beyond the interest\nof the convening organisation; _Trustworthy Processes_ that are inclusive, open, fair and respectful and\ndelivered with integrity and competence; and _Visible Impact_ i.e., that involvement can make a significant\ncontribution to decision-making, or makes changes to the governance of the organisation, product or\nservice to align it with the public interest.\n\n\u2013 Data and Society\u2019s Democratizing genai: Principles for Meaningful Public Participation provides\nrecommendations concerning, among other things: Early-stage public participation to ensure that decision-\nmakers do not become wedded to a preconceived decision before receiving public input; the need for\nequity and social justice commitments to guide every aspect of participation; the design of participation\nmethods for high-quality engagement; and the need to build the technical capacity of communities while\nalso acknowledging that \u201cAffected people do not need to know how to build an algorithm to have an\nopinion on how automated decision-making systems should (or should not) affect their lives.\u201d\n\nIn the context of genai foundation models, their general-purpose nature presents challenges related to\nthe massive numbers, diversity and geographic location of potentially affected stakeholders that may need to be\nengaged.\n\nOn these points, B-Tech Improving Stakeholder Engagement in Tech Company Due Diligence affirms\nthat \u201ctechnology companies should not interpret the expectation of the UNGPs as meaning that they must engage\nwith every one of the many thousands, even multiple millions, of stakeholders potentially impacted by the use of\nthe company\u2019s products and services.\n\nRather, tech companies should seek to hear from a representative mix of\nstakeholders, with resources prioritized to where risks to human rights are most severe\u201d.\n\nB-Tech has also previously called attention to the importance of engagement with expert and affected\nstakeholders outside of North America and Western Europe.\n\nFor some companies, membership in robust\nmultistakeholder initiatives, such as GNI has proved a useful way to connect with local civil society and\naffected groups, as well as the critical work of NGOs with specific focus on digital rights in their region, and\ninternational NGOs working to support with capacity building and guidance to these organizations 43 .\n\nBroad-based public participation represents another possible avenue for engagement with affected stakeholders.\n\nFor example, Anthropic and Open genai have partnered with The Collective Intelligence Project to pilot \u201cAlignment\nAssemblies\u201d aimed at shaping the trajectory of genai deployment in society.\n\nThe project founders also\naspire to experiment with other modes of engagement, citing federated citizens\u2019 assemblies, retroactive funding\n\n\n43 Such as the Paradigm Initiative working across Sub-Saharan; ELSAM in Indonesia, and Association por los Derechos Civiles in\n\nArgentina (see, ADC\u2019s due diligence guidance focused o marginalized groups ), and GNI and Global Digital Partners\u2019 Engaging Tech\nCompanies on Human Rights: A How-To Guide for Civil Society\n\n\n-----\n\nprocesses for writing better mode evaluations and public red-teaming.\n\nAnother exemplar innovation from the\nwider genai domain is the Ada Lovelace Institute\u2019s Citizens\u2019 Biometrics Council which brings together 50 members\nof the UK public to deliberate on the use of biometrics technologies like facial recognition.\n\nFinally, all individuals have political and public participation rights that \u201cplay a crucial role in the promotion\nof democratic governance, the rule of law, social inclusion and economic development, as well as in the\nadvancement of all human rights\u201d.\n\nThis is a reminder that formalized, legally mandated mechanisms for\nensuring that the voice and interests of specific affected stakeholders are represented in the development of\ngenai foundation models should also have a role to play.", "This could, for example, take the form of\nregulatory oversight of public participation forums, or establishing modes for specific groups such as data\nenrichment workers or artists to exercise their collective bargaining rights.\n\n**NEXT STEPS:** Establishing when, how and under what conditions companies developing generative\n\ngenai foundation models can most meaningfully ensure engagement with at-risk or impacted stakeholders and\ncivil society organizations requires attention from business, civil society and regulators.\n\nInitial points of focus\ncould be on:\n\n\u2013 Companies developing foundation models establishing the necessary internal commitment, capacity and\nculture to engage with affected stakeholders and civil society representatives across all phases of the genai\ndevelopment life cycle.\n\n\u2013 The meaningful integration of affected stakeholder perspectives within industry-led responsible generative\ngenai collaboration, with particular attention to removing logistical barriers to participation, diversity among\nparticipants and investing in the technical capacity of communities to engage.\n\n\u2013 Companies developing foundation models using \u201cleverage for engagement\u201d by taking a proactive role\nin advocating for more formalized mechanisms, and possibly funding options, for at-risk stakeholders to\nconvene and advocate for their rights with relevant actors across the genai value chain.\n\n-----", "## Looking Ahead\n\nThe insights and recommendations laid out in this paper and supporting supplements from the first phase of\nthe B-Tech genai project have been released to support multi-stakeholder dialogue and collaboration\nthat advances UNGPs-consistent public policy, regulation and business practice.\n\nThe findings, and responses\nto them, will inform B-Tech ongoing work on genai in 2024.\n\nUN Human Rights invites engagement from all stakeholders as we move into the second phase of this B-Tech\ninitiative.\n\nPlease contact us if you would like to engage with our work, including if you have recommendations for\npractical tools, case studies and guidance that will advance company, investor and State implementation of the _UN_\n_Guiding Principles on Business and Human Rights_ in the context of genai development and deployment", "##### Acknowledgements\n\nThe UN B-Tech team expresses thanks to all the experts and stakeholders that provided input into this\nfoundational paper such as representatives from the OECD Centre for Responsible Business Conduct , the\nGlobal Network Initiative , BSR and Shift .\n\nThe team is especially appreciative to Mark Hodge, Vice President\nof Shift, the lead author of this paper.\n\n-----", "###### Table of Recommendations\n\n|HEADLINE ONE Impacts on internationally agreed human rights should be the focus of State and company action to advance the responsible development and deployment of genai technologies|Col2|\n|---|---|\n|Key Messages: \u2013 Human rights provide an existing, well-defined, and holistic set of outcomes against which States, companies, and other actors evaluate the risks related to genai.\n\n\u2013 The international human rights framework has a developed architecture of international, regional and national institutions and processes which facilitate consideration of these issues and, in some instances, monitor and even enforce implementation.\n\n\u2013 Focusing on international human rights has the merit of reinforcing existing, well defined State obligations and corporate responsibilities.|Recommendations: To catalyse greater attention to applying a human rights lens to developing and deploying genai, B-Tech has developed a Taxonomy of genai Human Rights Harms.\n\nThe taxonomy shows clear connections between \u201crisk examples\u201d connected to genai across nine categories of internationally agreed human rights: \u2013 Freedom from Physical and Psychological Harm \u2013 Right to Equality Before the Law and Protection against Discrimination \u2013 Right to Privacy \u2013 Right to Own Property \u2013 Freedom of Thought, Religion, Conscience and Opinion \u2013 Freedom of Expression and Access to Information \u2013 Right to Work and to Gain a Living \u2013 Rights of the Child \u2013 Rights to Culture, Art and Science|\n\n\n\n\n|HEADLINE TWO The UNGPs offer guidance on how to establish the multi-layered architecture of governance needed to address the conduct of private sector actors across the full genai value chain.\n\nThis includes companies that are suppliers of genai knowledge and resources, actors in the genai system lifecycle, and users/operators of an genai system3|Col2|\n|---|---|\n|Key Message: States should implement a \u201csmart- mix\u201d of regulation, guidance, incentives, and transparency requirements \u2013 all supported by policy coherence in domestic and multi-lateral efforts - to advance corporate responsibility and accountability for human rights harms.|Recommendations: \u2013 States should enforce laws that are aimed at, or have the effect of, requiring companies developing and deploying genai technology to respect human rights, periodically assess the adequacy of such laws and address any gaps.\n\n\u2013 States should provide effective guidance and associated capacity building to business enterprises on how to respect human rights when developing or deploying genai.\n\n\u2013 Authoritative corporate transparency regimes from the corporate responsibility and accountability field should be used to complement technology specific transparency requirements.|\n\n\n-----\n\n|Col1|\u2013 States \u2014 especially those States home to market-leading companies at the core of developing genai systems \u2014 should build the competence and capability of relevant agencies, administrative supervisory bodies and officials.\n\n\u2013 States should pursue multi-lateral action focused on the protection and respect of human rights: to spread best practices between States minimize the risks of States pursuing their own interests at the expense of building dignity and respect into the heart of genai development and deployment.\n\n\u2013 States \u2014 whether part of national, regional or international initiatives \u2014 should establish and sustain stakeholder engagement with companies, civil society and especially affected stakeholders to learn about risks, impacts and challenges/opportunities to advance meaningful genai risk assessment and mitigations.|\n|---|---|\n|Key Message: Regional, national, international and industry-led initiatives focused on advancing responsible genai should use or align to the international standards of business conduct.\n\nThis means, in particular, integrating a true risk- based approach to identifying and taking action on impacts that: a) Uses severity of risks to people to prioritize impacts for attention; and b) sets expectations of companies across the genai value chain commensurate with the nature of their involvement (causation, contribution or linkage) with human rights risks and impacts|Recommendations: \u2013 Reaffirm and ground policies in States\u2019 existing duty to protect and businesses\u2019 Corporate Responsibility to Respect Human Rights as laid out by the UNGPs and OECD Guidelines.\n\n\u2013 Integrate risk-based prioritization based on severity of risks to people as well as the cause, contribution, linkage \u201cInvolvement Framework\u201d into legislative texts, technical standards and guidance.", "\u2013 Integrate risk-based prioritization based on severity of risks to people as well as the cause, contribution, linkage \u201cInvolvement Framework\u201d into legislative texts, technical standards and guidance.\n\n\u2013 Establish multi-stakeholder dialogue to deepen appreciation of what a full value chain approach to addressing human rights risks means in practice.|\n|Key Message: Greater urgency is needed towards ensuring effective judicial and non-judicial access to remedy for individuals whose human rights are harmed by the development or deployment of genai.|Recommendations: \u2013 All stakeholders should collaborate to establish processes for understanding the experience and perspectives of impacted or at-risk individuals or groups about what meaningful remedy for genai harms means in practice.\n\n\u2013 States should ensure access to judicial remedies where individuals may have been harmed by the development or deployment of genai technologies.\n\n\u2013 States, companies, civil society experts and affected stakeholders (or legitimate representatives) should work together on how to establish non-judicial routes through which people may seek remedies for specific human rights related harms connected to genai.|\n\n\n-----\n\n|HEADLINE THREE Implementation of thorough human rights due diligence by companies developing foundation models4 will provide an important basis for risk management across the genai value chain.\n\nClear and regularly updated guidance on what constitutes best practice is required, building on company practice and informed by civil society and relevant experts.\n\nEmphasis should be placed on key practices, which are currently under-emphasized in regulatory proposals and technical standards.|Col2|\n|---|---|\n|Practice 1: Boards and executives identifying the extent to which the company\u2019s business model and strategy carry inherent human rights risks, and taking action to address this.|Proposed Next Steps: Multi-stakeholder deliberations, and case studies of good practices focused on: \u2013 Boards identifying as part of initial business model design and strategy \u2013 and in any changes to these - the inherent human rights risks that flow from these and ensuring that the company has systems and plans to address these.\n\n\u2013 Senior leaders establishing and implementing commitments to release or scale the capability of foundation models in a responsible manner, including evaluating which situations might merit adopting an approach akin to the \u201cprecautionary principle\u201d.\n\n\u2013 The best ways to establish and sustain corporate cultures that reward the identifciation of risks and adverse impacts, including by ensuring that individuals feel able to raise concerns without fear of retribution.\n\n\u2013 Ensure that the company has in place the right competence, resources and processes to hear, and act on, the perspectives of especially affected or at-risk stakeholders.|\n|Practice 2: Embedding human rights risk assessment \u2013 focused on all human rights with any necessary prioritization being based on severity - into the product-oriented working methods and cultures of technology companies developing foundation models.|Proposed Next Steps: Multi-stakeholder deliberations, and case studies of good practices focused on: \u2013 Identifying the most impactful moments at which a company should assess the actual and potential human rights impacts that it could become connected to due to the development or deployment of its foundation model.\n\n\u2013 Creating tools, assessment methodologies and training that support an evaluation of impacts based on the full range of internationally agreed human rights and prioritization of impacts for attention based on their scale, scope and irremediability.\n\n\u2013 Mechanisms to allow external stakeholders to understand, appreciate and inform the quality of human rights risk identification and prioritization practices.|\n|Practice 3: Evaluating \u201ctechnical\u201d mitigations with a focus on people in situations of vulnerability or marginalization.|Proposed Next Steps: Multi-stakeholder deliberations, and case studies of good practices focused on: \u2013 The extent to which existing quantitative methods used by companies to evaluate mitigations can feasibly and responsibly be leveraged to offer insight into differential risks to distinct vulnerable groups.\n\n\u2013 Identifying how qualitative methods can offer feedback loops from affected stakeholders about the effectiveness, and indeed risks of technical mitigations for groups in situations of vulnerability.", "\u2013 Identifying how qualitative methods can offer feedback loops from affected stakeholders about the effectiveness, and indeed risks of technical mitigations for groups in situations of vulnerability.\n\n\u2013 Innovating collaborations that bring academics and civil society into the evaluation of effectiveness of mitigations but without compromising their independence and safety, or legitimate commercial interests of companies.|\n\n\n-----\n\n|Practice 4: Creatively building and using leverage to address \u201cresidual risks\u201d and enable remedy for harms.|Proposed Next Steps: Multi-stakeholder deliberations, and case studies of good practices focused on: \u2013 Responsible use policies, terms of use in contracts, guidance and enforcement with initial points of emphasis on understanding the impact of these policies and practices i.e., in what ways do they make a difference and what can be improved; and how to monitor third party practices without violating the rights of data subjects.\n\n\u2013 Know Your Customer assessment and follow-up with initial points of emphasis on: how to use indicators capable of evaluating customers\u2019 commitment and competence to manage risk and impacts from their own use of the company\u2019s foundation model and products; and strategies and tactics for building and using leverage when a customer is considered to be high risk from a human rights perspective.\n\n\u2013 Collective action with peer competitors (including smaller market entrants), value chain companies, civil society and international organizations with initial points of emphasis on ensuring that civil society and perspectives of affected stakeholders have an equal seat at the table; and targets and accountability measures that go beyond pledges and principles to focus resources on delivering results.\n\n\u2013 Leverage for remedy including providing proactive support to strengthen customers\u2019 redress mechanisms; identifying where industry-level mechanisms at the deployment level might be necessary; and \u201cenabling remedy\u201d in specific instances of harm.|\n|---|---|\n|Practice 5: Engagement with affected stakeholders and civil society experts across the full cycle of human rights due diligence, and as part of enabling remedy for harms|Proposed Next Steps: Multi-stakeholder deliberations, and case studies of good practices focused on: \u2013 Companies developing foundation models establishing the necessary internal commitment, capacity and culture to engage with affected stakeholders and civil society representatives across all phases of the genai development life cycle.\n\n\u2013 The meaningful integration of affected stakeholder perspectives within industry-led responsible genai collaboration, with particular attention to removing logistical barriers to participation, diversity among participants and investing in the technical capacity of communities to engage.\n\n\u2013 Companies developing foundation models using \u201cleverage for engagement\u201d by taking a proactive role in advocating for more formalized mechanisms, and possibly funding options, for at-risk stakeholders to convene and advocate for their rights with relevant actors across the genai value chain|\n\n\n-----", "**THE DI RECT O R**\n\nPROPOSED MEMORANDUM FOR THE HEADS OF EXECUTIVE DEPARTMENTS AND\nAGENCIES\n\nFROM: Shalanda D. Young\n\n\nSUBJECT: Advancing Governance, Innovation, and Risk Management for Agency Use of\n\ngenai\n\n\ngenai (genai) is one of the most powerful technologies of our time, and the\n\nPresident has been clear that we must seize the opportunities genai presents while managing its\nrisks.\n\nConsistent with the genai in Government Act of 2020, 1 the Advancing\nAmerican genai Act, 2 and President Biden\u2019s Executive Order of October 30, 2023 (Safe, Secure,\nand Trustworthy Development and Use of genai), this memorandum directs\nagencies to advance genai governance and innovation while managing risks from the use of genai,\nparticularly those affecting the safety and rights of the public.\n\nAs set forth in the accompanying Federal Register notice, the Office of Management and\n\n\nBudget is requesting public comment on this proposed memorandum.", "**1.\n\n** **OVERVIEW**\n\nWhile genai is improving operations and efficiency across the Federal Government,\n\n\nagencies must effectively manage its use.\n\nAs such, this memorandum establishes new agency\nrequirements and guidance for genai governance, innovation, and risk management, including\nthrough specific minimum risk management practices for uses of genai that impact the rights and\nsafety of the public.\n\n**_Strengthening genai Governance._** Managing genai risk and promoting genai innovation requires\n\neffective genai governance.\n\nAs required by President Biden\u2019s October 30, 2023 Executive Order\n(the \u201cgenai Executive Order\u201d), each agency must designate a Chief genai Officer (CAIO) within 60\ndays of the date of the issuance of this memorandum.\n\nThis memorandum describes the roles,\nresponsibilities, seniority, position, and reporting structures for agency CAIOs.\n\nBecause genai is\ndeeply interconnected with other technical and policy areas including data, information\n\n\n**_Strengthening genai Governance._** Managing genai risk and promoting genai innovation requires\n\n\n1 Pub.\n\nL. No.\n\n116-260, div.\n\nU, title 1, \u00a7 104 (codified at 40 U.S.C.\n\n\u00a7 11301 note),\n .\n\n2 Pub.\n\nL. No.\n\n117-263, div.\n\nG, title LXXII, subtitle B, \u00a7\u00a7 7224(a), 7224(d)(1)(B), and 7225 (codified at 40 U.S.C.\n\n11301 note),  .\n\n-----\n\ntechnology (IT), security, privacy, civil rights and civil liberties, customer experience, and\nworkforce management, CAIOs must work in close coordination with existing responsible\nofficials and organizations within their agencies.\n\n**_Advancing Responsible genai Innovation._** When implemented responsibly, genai can improve\n\noperations across the Federal Government.\n\nAgencies must increase their capacity to successfully\nand responsibly adopt genai, including genai, into their operations.\n\nTo that end, this\nmemorandum requires each agency identified in the Chief Financial Officer (CFO) Act 3 to\ndevelop an enterprise genai strategy.\n\nThis memorandum also provides recommendations for how\nagencies should reduce barriers to the responsible use of genai, including barriers related to IT\ninfrastructure, data, cybersecurity, workforce, and the particular challenges of genai.\n\n**_Managing Risks from the Use of genai._** While agencies will realize significant benefits\n\n\nfrom genai, they must also manage a range of risks from the use of genai.\n\nAgencies are subject to\nexisting risk management requirements relevant to genai, and this memorandum does not replace or\nsupersede these requirements.\n\nInstead, it creates new requirements focused specifically on the\nrisks from relying on genai to inform or carry out agency decisions and actions, particularly when\nsuch reliance impacts the rights and safety of the public.\n\n4 To address these risks, this\nmemorandum requires agencies to follow minimum practices when using rights-impacting and\nsafety-impacting genai, and enumerates specific categories of genai that are presumed to impact rights\nand safety.\n\nFinally, this memorandum also establishes a series of recommendations for managing\ngenai risks in the context of Federal procurement.", "**2.\n\n** **SCOPE**\n\nAgency adoption of genai poses many challenges, some novel and specific to genai and some\n\n\nwell-known.\n\nWhile agencies must give due attention to all aspects of genai, this memorandum is\nscoped to address risks specifically arising from the use of genai, as well as governance and\ninnovation issues that are directly tied to agencies\u2019 use of genai.\n\nThis memorandum does not\naddress issues that are present regardless of the use of genai, for instance with respect to Federal\ninformation and systems in general.\n\nIn addition, this memorandum does not supersede other,\nmore general Federal policies that apply to genai but are not focused specifically on genai, such as\npolicies that relate to enterprise risk management, information resources management, privacy,\nFederal statistical activities, IT, or cybersecurity.\n\nAgencies must continue to comply with\napplicable OMB policies in other domains relevant to genai, and to coordinate compliance across\nthe agency with all appropriate officials.\n\nAll agency responsible officials retain their existing\nauthorities and responsibilities established in other laws and policies.\n\n3 31 U.S.C.\n\n\u00a7 901(b).\n\n4 A full definition for \u201crisks from the use of genai\u201d is provided in Section 6.\n\n-----\n\na.\n\nCovered Agencies.\n\nExcept as specifically noted, this memorandum applies to all agencies\ndefined in 44 U.S.C.\n\n\u00a7 3502(1).\n\n5 As noted in the relevant sections, some requirements in this\nmemorandum only apply to CFO Act agencies, as identified in 31 U.S.C.\n\n\u00a7 901(b), and other\nrequirements do not apply to elements of the Intelligence Community, as defined in 50 U.S.C.\n\n\u00a7\n3003.\n\nb.\n\nCovered genai.\n\nThis memorandum provides requirements and recommendations that, as\ndescribed in more detail below, apply to new and existing genai that is developed, used, or procured\nby or on behalf of covered agencies.\n\nThe principles of this memorandum do not, by contrast,\ngovern agencies\u2019 regulatory actions designed to prescribe law or policy regarding non-agency\nuses of genai.\n\nThe requirements of this memorandum apply to system functionality that implements or is reliant\non genai, rather than to the entirety of an information system that incorporates genai.\n\nAs noted in the\nrelevant sections, some requirements in this memorandum apply only in specific circumstances\nin which agencies use genai, such as when the genai may impact rights or safety.\n\nc. Applicability to National Security Systems.\n\nThis memorandum does not cover genai when it is\nused as a component of a national security system.\n\n6", "**3.\n\n** **STRENGTHENING genai GOVERNANCE**\n\nThe head of each covered agency is responsible for pursuing genai innovation and ensuring\n\nthat their agency complies with genai requirements in relevant law and policy, including that risks\nfrom the agency\u2019s use of genai are adequately managed.\n\nThe head of each covered agency must\nalso consider the necessary financial, human, information, and infrastructural resources to carry\nout these responsibilities effectively, including providing or requesting resources via the budget\nprocess to support the responsibilities identified in this memorandum.\n\nTo improve accountability for genai issues, agencies must designate a Chief genai Officer,\n\nconsistent with Section 10.1(b) of the genai Executive Order.\n\nCAIOs bear primary responsibility on\n\n5 The term \u201cagency\u201d is defined as \u201cany executive department, military department, Government corporation,\nGovernment controlled corporation, or other establishment in the executive branch of the Government (including the\nExecutive Office of the President), or any independent regulatory agency,\u201d but does not include the Government\nAccountability Office; the Federal Election Commission; the governments of the District of Columbia and of the\nterritories and possessions of the United States, and their various subdivisions; or Government-owned contractoroperated facilities, including laboratories engaged in national defense research and production activities.\n\nAs a result,\nagencies defined in 44 U.S.C.\n\n\u00a7 3502(5) (independent regulatory agencies) that were not covered by Executive\nOrder 13960 of December 8, 2020 _are_ covered by this memorandum.\n\n6 genai innovation and risk for national security systems must be managed appropriately, but these systems are\ngoverned through other policy.\n\nFor example, Section 4.8 of the genai Executive Order requires the development of a\nNational Security Memorandum to govern the use of genai as a component of a National Security System, and agencies\nhave existing guidelines in place such as the Department of Defense\u2019s (DoD) _Responsible Artificial Intelligence_\n_Strategy and Implementation Pathway_ and the Office of the Director of National Intelligence\u2019s _Principles of_\n_Artificial Intelligence Ethics for the Intelligence Community_ , as well as policies governing specific high-risk national\nsecurity applications of genai, such as DoD Directive 3000.09, _Autonomy in Weapon Systems_ .\n\n-----\n\nbehalf of the head of their agency for implementing this memorandum and coordinating\nimplementation with other agencies.\n\nThis section defines CAIOs\u2019 roles, responsibilities,\nseniority, position, and reporting structure.\n\na.\n\nActions\n\ni.\n\n**Designating Chief genai Officers** _._ Within 60 days of the issuance of this memorandum, the\nhead of each agency must designate a CAIO.\n\nTo ensure the CAIO can fulfill the\nresponsibilities laid out in this memorandum, agencies that have already designated a\nCAIO must evaluate whether they need to provide that individual with additional\nauthority or appoint a new CAIO.\n\nAgencies must identify these officers to OMB through\nOMB\u2019s Integrated Data Collection process or an OMB-designated successor process, and\nthey must update OMB within 30 days when the designated individual changes.\n\nii.\n\n**Convening Agency genai Governance Bodies** _._ Within 60 days of the issuance of this\nmemorandum, each CFO Act agency must convene its relevant senior officials to\ncoordinate and govern genai issues, consistent with Section 10.1(b) of the genai Executive\nOrder and the detailed guidance in Section 3(c) of this memorandum.\n\niii.\n\n**Compliance Plans** _._ Consistent with Section 104(c)-(d) of the genai in Government Act,\nwithin 180 days of the issuance of this memorandum or any update to this memorandum\nand every two years thereafter until 2036, each agency must submit to OMB and post\npublicly on the agency\u2019s website either a plan to achieve consistency with this\nmemorandum, or a written determination that the agency does not use and does not\nanticipate using covered genai.\n\nAgencies must also include plans to update any existing\ninternal genai principles and guidelines to ensure consistency with this memorandum.\n\n7\nOMB will provide full templates for these compliance plans.\n\niv.\n\n**genai Use Case Inventories** _._ Pursuant to Section 7225 of the Advancing American genai Act,\nand subject to the exclusions in that Act and Section 10.1(e) of the genai Executive Order,\neach agency (except for the Department of Defense and the Intelligence Community)\nmust annually submit an inventory of its genai use cases to OMB and subsequently post a\npublic version on the agency\u2019s website.\n\n8 OMB will issue detailed instructions for the\ninventory through its Integrated Data Collection process or an OMB-designated successor\nprocess.", "8 OMB will issue detailed instructions for the\ninventory through its Integrated Data Collection process or an OMB-designated successor\nprocess.\n\nBeginning with the use case inventory for 2024, agencies will be required, as\napplicable, to identify and report additional detail on how they are using safety-impacting\nand rights-impacting genai, the risks\u2014including risks to equity\u2014that such use poses, how\nthey are managing those risks, and any related extensions and waivers granted under\n\n7 Given the importance of context-specific guidance on genai, agencies are encouraged to continue implementing their\nagency\u2019s genai principles and guidelines, so long as they do not conflict with the guidance in this memorandum.\n\n8 Agencies must only publicly report use cases to the extent practicable and consistent with applicable law and\ngovernmentwide guidance, including those concerning the protection of privacy and of sensitive law enforcement,\nnational security, and other protected information.\n\n-----\n\nSection 5 of this memorandum.\n\nv. **Reporting on genai Use Cases Not Subject to Inventory** _._ Some genai use cases are exempt\nfrom the Advancing American genai Act\u2019s inventory requirement.\n\nOf those use cases, those\nwithin the Department of Defense are otherwise within the scope of this memorandum\nunless they concern genai used as a component of a national security system.\n\nThe\nDepartment of Defense must annually provide OMB with information on those in-scope\ngenai use cases, including aggregate metrics about those in-scope genai uses cases, the number\nof such cases that impact rights and safety, their compliance with the practices of Section\n5(c) of this memorandum, and any waivers granted under Section 5 of this memorandum.\n\nOMB will issue detailed instructions for this reporting through its Integrated Data\nCollection process or an OMB-designated successor process.\n\nb.\n\nRoles, Responsibilities, Seniority, Position, and Reporting Structure of Chief Artificial\nIntelligence Officers\n\n\nConsistent with Section 10.1(b)(ii) of the genai Executive Order, this memorandum defines\n\n\nagency CAIOs\u2019 roles, responsibilities, seniority, position, and reporting structures as follows:\n\n\ni.\n\n**Roles.\n\n** CAIOs must have the necessary skills, knowledge, training, and expertise to\nperform the responsibilities described in this section.\n\nAt CFO Act agencies, the CAIO\u2019s\nprimary role must be coordination, innovation, and risk management for their agency\u2019s\nuse of genai.\n\nAgencies may choose to designate an existing official, such as a Chief\nTechnology Officer, Chief Data Officer, or similar official with relevant or\ncomplementary authorities and responsibilities, provided they have significant expertise\nin genai and meet the other requirements in this section.\n\nii.\n\n**Responsibilities.\n\n** The genai Executive Order tasks CAIOs with primary responsibility in\ntheir agencies, in coordination with other responsible officials, for coordinating their\nagency\u2019s use of genai, promoting genai innovation, managing risks from the use of genai, and\ncarrying out the agency responsibilities defined in Section 8(c) of Executive Order\n13960 9 and Section 4(b) of Executive Order 14091.\n\n10 In addition, CAIOs, in coordination\nwith other responsible officials and appropriate stakeholders, are responsible for:\n\n_Coordinating Agency Use of AI_\n\n\nA. serving as the senior advisor for genai to the head of the agency and other senior\n\n\nagency leadership and within their agency\u2019s senior decision-making forums;\n\n\nB. maintaining awareness of agency genai activities, including through creating and\n\n\nmaintaining the annual genai use case inventory;\n\n\n9 Executive Order 13960, _Promoting the Use of Trustworthy genai in the Federal Government,_\n .\n\n10 Executive Order 14091, _Further Advancing Racial Equity and Support for Underserved Communities Through the_\n_Federal Government_ ,  .\n\n-----\n\nC. developing a plan for compliance with this memorandum, as detailed in Section\n\n\n3(a)(iii) of this memorandum, and an agency genai strategy, as detailed in Section\n4(a) of this memorandum;\n\n\nD. advising the agency CFO and Chief Human Capital Officer (CHCO) on the\n\n\nresourcing requirements and workforce skillsets necessary for applying genai to the\nagency\u2019s mission and adequately managing its risks;\n\n\nE. supporting agency involvement with appropriate interagency coordination bodies\n\n\nrelated to their agency\u2019s genai activities, including representing the agency to the\ncouncil described in Section 10.1(a) of the genai Executive Order;\n\n\nF. supporting and coordinating their agency\u2019s involvement in genai standards-setting\n\n\nbodies, as appropriate, and encouraging agency adoption of voluntary consensus\nstandards for genai, as appropriate and consistent with OMB Circular No.", "A-119; 11\n\n\n_Promoting genai Innovation_\n\n\nG. working with their agency to identify and prioritize appropriate uses of genai that\n\n\nwill improve their agency\u2019s mission and advance equity;\n\n\nH. identifying and removing barriers to the responsible use of genai in the agency,\n\n\nincluding through the advancement of genai-enabling enterprise infrastructure,\nworkforce development measures, policy, and other resources for genai innovation;\n\n\nI. advocating within their agency and to the public on the opportunities and benefits\n\n\nof genai to the agency\u2019s mission;\n\n\n_Managing Risks from the Use of AI_\n\n\nJ. managing an agency program that supports the enterprise in identifying and\n\n\nmanaging risks from the use of genai, especially for safety-impacting and rightsimpacting genai;\n\n\nK. working with relevant senior agency officials to establish or update processes to\n\n\nmeasure, monitor, and evaluate the ongoing performance of genai applications and\nwhether they are achieving their intended objectives;\n\n\nL. overseeing agency compliance with requirements to manage risks from the use of\n\n\ngenai, including those established in this memorandum and in relevant law and\npolicy;\n\n\nM. conducting risk assessments, as necessary, of agency genai applications to ensure\n\n\ncompliance with this memorandum;\n\n\nN. overseeing development of agency-specific lists, as necessary, of purposes for\n\n\nwhich genai is presumed to be safety-impacting or rights-impacting; 12\n\n\nO. waiving individual applications of genai from elements of Section 5 of this\n\n\nmemorandum through the processes detailed in that section; and\n\n\n11 OMB Circular A-119, _Federal Participation in the Development and Use of Voluntary Consensus Standards and_\n_in Conformity Assessment Activities_  (Feb. 10, 1998), .\n\n12 See Section 5(b) of this memorandum for the OMB-defined lists to which agency-specific lists would add.\n\nAny\nagency-specific lists will be governed by the same processes defined in Section 5(b) for the OMB-defined lists.\n\n-----\n\nP. in partnership with relevant agency officials (e.g., authorizing, procurement, legal,\n\nhuman capital, and oversight officials), ensuring that their agency does not use genai\nthat is not in compliance with this memorandum, including by assisting these\nrelevant agency officials in evaluating Authorizations to Operate based on risks\nfrom the use of genai.\n\niii.\n\n**Seniority.\n\n** For CFO Act agencies, the CAIO must be a position at the Senior Executive\nService, Scientific and Professional, or Senior Leader level, or equivalent.\n\nIn other\nagencies, the CAIO must be at least a GS-15 or equivalent.\n\niv.\n\n**Position and Reporting Structure.\n\n** CAIOs must have the necessary authority to perform\nthe responsibilities in this section and must be positioned highly enough to engage\nregularly with other agency leadership, to include the Deputy Secretary or equivalent.\n\nFurther, CAIOs must coordinate with other responsible officials at their agency to ensure\nthat the agency\u2019s use of genai complies with and is appropriate in light of applicable law and\ngovernmentwide guidance.\n\nc. Internal Agency genai Coordination\n\nAgencies must ensure that genai issues receive adequate attention from the agency\u2019s senior\n\nleadership.\n\nConsistent with Section 10.1(b) of the genai Executive Order, agencies must take\nappropriate steps, such as through the convening of an genai governance body, to coordinate\ninternally among officials responsible for aspects of genai adoption and risk management.\n\nLikewise, the CAIO must be involved, at appropriate times, in broader agency-wide risk\nmanagement bodies and processes, 13 including in the development of the agency risk\nmanagement strategy.\n\n14 The agency\u2019s genai coordination mechanisms should be aligned to the\nneeds of the agency based on, for example, the degree to which the agency currently uses genai, the\ndegree to which genai could improve the agency\u2019s mission, and the risks posed by the agency\u2019s\ncurrent and potential uses of genai.\n\nCFO Act agencies are required specifically to establish genai Governance Boards to\n\nconvene relevant senior officials no less than quarterly to govern the agency\u2019s use of genai,\nincluding to remove barriers to the use of genai and to manage its associated risks.\n\nThose agencies\nare permitted to rely on existing governance bodies 15 to fulfill this requirement as long as they\ncurrently satisfy or are made to satisfy both of the following:\n\n13 _See, e.g.,_ OMB Circular No.\n\nA-123, _Management\u2019s Responsibility for Enterprise Risk Management and Internal_\n_Control_  (July 15, 2016), .\n\n14 _See_ OMB Circular No.\n\nA-130, _Managing Information as a Strategic Resource_ , Appx.\n\nI, sec.\n\n5(b) (July 28, 2016),\n .\n\n15 An example of a qualifying body includes agency Data Governance Bodies, established by OMB Memorandum\nM-19-23, _Phase 1 Implementation of the Foundations for Evidence-Based Policymaking Act of 2018: Learning_\n_Agendas, Personnel, and Planning Guidance_  .\n\n,\n\n\n-----\n\ni.", ",\n\n\n-----\n\ni.\n\nAgency genai Governance Boards must be chaired by the Deputy Secretary of the agency or\nequivalent and vice-chaired by the agency CAIO, and these responsibilities should not be\nassigned to other officials.\n\nWorking through this Board, CAIOs will support their\nrespective Deputy Secretaries in coordinating genai activities across the agency and\nimplementing relevant sections of the genai Executive Order.\n\nii.\n\nAgency genai Governance Boards must include appropriate representation from senior\nagency officials responsible for key enablers of genai adoption and risk management,\nincluding at least IT, cybersecurity, data, human capital, procurement, budget, agency\nmanagement, customer experience, performance evaluation, statistics, risk management,\nequity, privacy, civil rights and civil liberties, and officials responsible for implementing\ngenai within an agency\u2019s program office(s).\n\nAgencies should also consider including\nrepresentation from their respective Office of the Inspector General.", "**4.\n\n** **ADVANCING RESPONSIBLE genai INNOVATION**\n\nIf implemented responsibly, genai can improve operations and deliver efficiencies across the\n\n\nFederal Government.\n\nAgencies must improve their ability to use genai in ways that benefit the\npublic and increase mission effectiveness, while recognizing the limitations of genai and when it is\nnot suited for a given task.\n\nTo achieve this, agencies should build internal enterprise capacity to\nsupport responsible genai innovation and take actions to improve their procurement of genai.\n\na. genai Strategies\n\n\nWithin 365 days of the issuance of this memorandum, each CFO Act agency must\n\n\ndevelop and release publicly on the agency\u2019s website a strategy for identifying and removing\nbarriers to the responsible use of genai and achieving enterprise-wide advances in genai maturity,\nincluding:\n\n\ni. the agency\u2019s current and planned top use cases of genai 16 ;\n\n\nii.\n\na current assessment of the agency\u2019s genai maturity and the agency\u2019s genai maturity goals\nbased on the method established under Section 10.1(c) of the genai Executive Order;\n\n\niii.\n\nthe agency\u2019s plans to effectively govern its use of genai, including through its Chief genai\nOfficer, genai Governance Boards, and improvements to their genai use case inventory;\n\n\niv.\n\na plan for developing sufficient enterprise capacity for genai innovation, including mature\ngenai-enabling infrastructure for the data, computing, development, testing, cybersecurity\ncompliance, deployment, and continuous-monitoring infrastructure necessary to build,\ntest, and maintain genai;\n\n\nv. a plan for building sufficient enterprise capacity to manage risks from the use of genai;\n\n\nvi.\n\na current assessment of the agency\u2019s genai workforce capacity and projected genai workforce\nneeds, as well as a plan to recruit, hire, train, retain and empower genai practitioners and\nachieve genai literacy for non-practitioners involved in genai to meet those needs; and\n\n\n16 Consistent with Sections 7225(d) and 7228 of the Advancing American genai Act, this requirement applies to CFO\nAct agencies except for the Department of Defense and the Intelligence Community, as defined in 5 U.S.C.\n\n\u00a7\n3003(4).\n\n-----\n\nvii.\n\nspecific, prioritized areas and planning for future genai investment.\n\nb.\n\nRemoving Barriers to the Responsible Use of genai\n\n\nEmbracing innovation requires removing unnecessary and unhelpful barriers to the use of\n\n\ngenai while retaining and strengthening the guardrails that ensure its responsible use.\n\nAgencies\nshould create internal environments where those developing and deploying genai have flexibility\nand do not face hindrances that divert limited resources and expertise away from the genai\ninnovation and risk management.\n\nAgencies should take steps to remove such barriers, paying\nspecial attention to the following recommendations:\n\n\ni.\n\n**IT Infrastructure** **_._** Agencies should ensure that their genai projects have access to adequate\nIT infrastructure, including high-performance computing infrastructure specialized for genai\ntraining and inference, where necessary.\n\nAgencies should also ensure adequate access for\ngenai developers to the software tools, open-source libraries, and deployment and\nmonitoring capabilities necessary to rapidly develop, test, and maintain genai applications.\n\nii.\n\n**Data.\n\n** Agencies should develop adequate infrastructure and capacity to sufficiently curate\nagency datasets for use in training, testing, and operating genai.\n\nThis includes an agency\u2019s\ncapacity to maximize appropriate access to internal data and share such data within the\nagency.\n\nAgencies should also explore the utility of public access datasets and encourage\ntheir use, where appropriate and consistent with the data practices outlined in this\nmemorandum, to help develop, test, and maintain genai applications.\n\nThese activities should\nbe supported by resources to enable sound data governance and management practices,\nparticularly as it relates to data curation, labeling, and stewardship.\n\niii.\n\n**Cybersecurity.\n\n** Agencies should update, as necessary, cybersecurity authorization\nprocesses to better address the needs of genai applications, including to advance the use of\ncontinuous authorizations for genai.\n\nConsistent with Section 10.1(f) of the genai Executive\nOrder, agency authorizing officials should also prioritize genai and other critical\nemerging technologies in Authorizations to Operate and any other applicable release or\noversight processes.\n\niv.\n\n**Workforce.\n\n** Consistent with Sections 5.1 and 10.2 of the genai Executive Order, agencies\nshould take full advantage of available special hiring and retention authorities to fill gaps\nin genai talent, encouraging applications from individuals with diverse perspectives and\nexperiences, and ensure the use of recruitment best practices for genai positions, such as\ndescriptive job titles and skills-based assessments.", "When identifying and filling\nworkforce needs for genai, agencies should include both technical roles, such as data\nscientists and engineers, and non-technical roles, such as designers, behavioral scientists,\ncontracting officials, managers, and attorneys, whose contribution and competence with\ngenai are important for successful and responsible genai outcomes.\n\nAgencies should provide\nresources and training to develop such genai talent internally and should also increase genai\ntraining offerings for Federal employees, including opportunities that provide Federal\n\n\n-----\n\nemployees pathways to genai occupations and that assist employees affected by the\napplication of genai to their work.\n\nv. **genai** **_._** In addition to heeding the guidance provided in Section 10.1(f) of the genai\nExecutive Order, agencies should assess potential beneficial use cases of genai in\ntheir missions and establish adequate safeguards and oversight mechanisms that allow\ngenai to be used in the agency without posing undue risk.", "**5.\n\n** **MANAGING RISKS FROM THE USE OF genai**\n\nAgencies have a range of policies, procedures, and officials in place to manage risks\n\nrelated to agency information and systems.\n\nTo better address risks from the use of genai, and\nparticularly risks to the rights and safety of the public, all agencies that are not elements of the\nIntelligence Community are required to implement minimum practices, detailed below, to\nmanage risks from rights-impacting and safety-impacting genai.\n\n17\n\n\na.\n\nActions\n\n\ni.\n\n**Implementation of Risk Management Practices and Termination of Non-Compliant**\n**genai** .\n\nBy August 1, 2024, agencies must implement the minimum practices in Section 5(c)\nof this memorandum for safety-impacting or rights-impacting genai, or else stop using any\ngenai that is not compliant with the minimum practices, consistent with the details and\ncaveats in that section.\n\nii.\n\n**Recommendation on genai Documentation.\n\n** Within 180 days of the issuance of this\nmemorandum, the council described in Section 10.1(a) of the genai Executive Order will\nprovide the Director of OMB with a list of recommended documentation that should be\nrequired from a selected vendor in the fulfillment of a Federal genai contract.\n\nAs part of\ntheir recommendation, the council must consider the minimum risk management\npractices in Section 5(c) and the associated materials that may be required of vendors to\ndemonstrate that they have completed such tasks.\n\nb.\n\nDetermining Which genai Is Presumed to Be Safety-Impacting or RightsImpacting\n\n\nAll genai within the scope of this section that matches the definitions of \u201csafety-impacting\n\n\ngenai\u201d or \u201crights-impacting genai\u201d as defined in Section 6 must follow the minimum practices in\nSection 5(c) by the appropriate deadline.\n\nAgencies must review each use of genai that they are\ndeveloping or using to determine whether it matches the definition of safety-impacting or rightsimpacting.\n\nThe categories in this subsection only identify a subset of specific purposes for which genai\n\nis automatically _presumed_ to be safety-impacting or rights-impacting, and they do not represent\nan exhaustive list of purposes for which genai is safety-impacting or rights-impacting.\n\nAgencies are\n\n\nThe categories in this subsection only identify a subset of specific purposes for which genai\n\n\n17 Although elements of the Intelligence Community are not required to implement these practices, they are\nencouraged to do so.\n\n10\n\n\n-----\n\nalso encouraged to define specific purposes that, within their agency, are presumed to be safetyimpacting or rights-impacting and so must follow the practices in Section 5(c).\n\nAgencies are\nrequired to report any such agency-specific lists to OMB on an annual basis.\n\nWhere an agency currently uses or plans to use genai for a purpose described below, the\n\nCAIO, in coordination with other relevant officials as specified by the agency, may make a\ndetermination (or reverse a prior determination) that the genai application or component 18 does not\nmatch the definitions of \u201csafety-impacting genai\u201d or \u201crights-impacting genai\u201d and is therefore not\nsubject to the minimum practices.\n\nThe agency CAIO may make or reverse this determination\nonly with a documented context-specific and system-specific risk assessment.\n\nAny such\ndetermination or reversal must be reported to OMB within 30 days.\n\ni.\n\n**Purposes That Are Presumed to Be Safety-Impacting.\n\n** Unless the CAIO determines\notherwise, covered genai within the scope of this memorandum is presumed to be safetyimpacting and must follow the minimum practices for safety-impacting genai if it is used to\ncontrol or meaningfully influence the outcomes of the following activities:\n\n\nA.\n\nThe functioning of dams, emergency services, electrical grids or the generation or\n\n\nmovement of energy, fire safety systems, food safety mechanisms, integrity of\nelections and voting infrastructure, traffic control systems and other systems\ncontrolling physical transit, water and wastewater systems, and nuclear reactors,\nmaterials, and waste;\n\n\nB.\n\nPhysical movements, including in human-robot teaming, such as the movements\n\n\nof a robotic appendage or body, within a workplace, school, housing,\ntransportation, medical, or law enforcement setting;\n\n\nC. The application of kinetic force, delivery of biological or chemical agents, or\n\n\ndelivery of potentially damaging electromagnetic impulses;\n\n\nD. The movements of vehicles, whether on land, underground, at sea, in the air, or in\n\n\nspace;\n\n\nE. The transport, safety, design, or development of hazardous chemicals or\n\n\nbiological entities or pathways;\n\n\nF. Industrial emissions and environmental impact control processes;\nG. The transportation or management of industrial waste or other controlled\n\n\npollutants;\n\n\nH. The design, construction, or testing of industrial equipment, systems, or structures\n\n\nthat, if they failed, would pose a meaningful risk to safety;\n\n\nI.\n\nResponses to insider threats;\nJ.", "Responses to insider threats;\nJ.\n\nAccess to or security of government facilities; or\nK. Enforcement actions pursuant to sanctions, trade restrictions, or other controls on\n\n\nexports, investments, or shipping.\n\n18 CAIOs may also make these determinations across groups of closely related genai applications or components,\nprovided that: (1) those systems have undergone a risk assessment that adequately considers the risks from each\nindividual system; and (2) the systems are substantially identical in their risk profiles.\n\n11\n\n\n-----\n\nii.\n\n**Purposes That Are Presumed to Be Rights-Impacting.\n\n** Unless the CAIO determines\notherwise, covered genai is presumed to be rights-impacting (and potentially also safetyimpacting) and agencies must follow the minimum practices for rights-impacting genai and\nsafety-impacting genai if it is used to control or meaningfully influence the outcomes of any\nof the following activities or decisions:\n\n\nA.\n\nDecisions to block, remove, hide, or limit the reach of protected speech;\nB.\n\nLaw enforcement or surveillance-related risk assessments about individuals,\n\n\ncriminal recidivism prediction, offender prediction, predicting perpetrators'\nidentities, victim prediction, crime forecasting, license plate readers, iris\nmatching, facial matching, facial sketching, genetic facial reconstruction, social\nmedia monitoring, prison monitoring, forensic analysis, forensic genetics, the\nconduct of cyber intrusions, physical location-monitoring devices, or decisions\nrelated to sentencing, parole, supervised release, probation, bail, pretrial release,\nor pretrial detention;\n\n\nC. Deciding immigration, asylum, or detention status; providing risk assessments\n\n\nabout individuals who intend to travel to, or have already entered, the U.S. or its\nterritories; determining border access or access to Federal immigration related\nservices through biometrics (e.g., facial matching) or other means (e.g.,\nmonitoring of social media or protected online speech); translating official\ncommunication to an individual in an immigration, asylum, detention, or border\ncontext; or immigration, asylum, or detention-related physical locationmonitoring devices.\n\nD. Detecting or measuring emotions, thought, or deception in humans;\nE. In education, detecting student cheating or plagiarism, influencing admissions\n\n\nprocesses, monitoring students online or in virtual-reality, projecting student\nprogress or outcomes, recommending disciplinary interventions, determining\naccess to educational resources or programs, determining eligibility for student\naid, or facilitating surveillance (whether online or in-person);\n\n\nF. Tenant screening or controls, home valuation, mortgage underwriting, or\n\n\ndetermining access to or terms of home insurance;\n\n\nG. Determining the terms and conditions of employment, including pre-employment\n\n\nscreening, pay or promotion, performance management, hiring or termination,\ntime-on-task tracking, virtual or augmented reality workplace training programs,\nor electronic workplace surveillance and management systems;\n\n\nH. Decisions regarding medical devices, medical diagnostic tools, clinical diagnosis\n\n\nand determination of treatment, medical or insurance health-risk assessments,\ndrug-addiction risk assessments and associated access systems, suicide or other\nviolence risk assessment, mental-health status detection or prevention, systems\nthat flag patients for interventions, public insurance care-allocation systems, or\nhealth-insurance cost and underwriting processes;\n\n\nI. Loan-allocation processes, financial-system access determinations, credit scoring,\n\n\ndetermining who is subject to a financial audit, insurance processes including risk\n\n\n12\n\n\n-----\n\nassessments, interest rate determinations, or financial systems that apply penalties\n(e.g., that can garnish wages or withhold tax returns);\n\n\nJ.\n\nDecisions regarding access to, eligibility for, or revocation of government benefits\n\n\nor services; allowing or denying access\u2014through biometrics or other means (e.g.,\nsignature matching)\u2014to IT systems for accessing services for benefits; detecting\nfraud; assigning penalties in the context of government benefits; or\n\n\nK. Recommendations or decisions about child welfare, child custody, or whether a\n\n\nparent or guardian is suitable to gain or retain custody of a child.\n\nc. Minimum Practices for Safety-Impacting and Rights-Impacting genai\n\n\nExcept as prevented by applicable law and governmentwide guidance, agencies must\n\napply the minimum practices in this section to safety-impacting and rights-impacting genai by\nAugust 1, 2024, or else stop using the genai until it becomes compliant.\n\nPrior to August 1, 2024,\nagency CAIOs should work with their agencies\u2019 relevant officials to bring potentially noncompliant genai into conformity, which may include voluntary requests to third-party vendors to\ntake appropriate action (e.g., via updated documentation or testing measures).", "To ensure\ncompliance with this requirement, relevant agency officials must use existing mechanisms\nwherever possible, for example, the Authorization to Operate process.\n\nAn agency may also\nrequest an extension or grant a waiver to this requirement through its CAIO using the processes\ndetailed below.\n\nAgencies must document their implementation of these practices and be prepared to\n\nreport them to OMB, either as a component of the annual genai use case inventory, periodic\naccountability reviews such as a TechStat process, 19 or on request as determined by OMB.\n\nThe practices in this section represent a minimum baseline for managing risk from the\n\nuse of genai.\n\nAgencies must identify additional context-specific risks that are associated with their\ndetermined use cases and address them as appropriate.\n\nSuch risk considerations may include\nimpacts to safety, security, civil rights, civil liberties, privacy, democratic values, human rights,\nequal opportunities, potential harms to worker wellbeing, access to critical resources and\nservices, and effects on market competition.\n\nTo fill potential risk management gaps, agencies are\nencouraged to promote and to incorporate, as appropriate, additional best practices for genai risk\nmanagement, such as from the National Institute of Standards and Technology (NIST) genai Risk\nManagement Framework, 20 the Blueprint for an genai Bill of Rights, 21 applicable international\nstandards, 22 and the workforce principles established pursuant to Section 6 of the genai Executive\n\n19 _Policies & Initiatives: TechStat,_ U.S. Chief Information Officers Council,\n .\n\n20 _Artificial Intelligence Risk Management Framework (genai RMF 1.0)_ , NIST Publication genai 100-1,\n .\n\n21 _Blueprint for an genai Bill of Rights_ , White House Office of Science and Technology Policy,\n .\n\n22 For example, ISO/IEC 23894:2023 Information technology \u2014 genai \u2014 Guidance on risk\nmanagement,  .\n\n13\n\n\n-----\n\nOrder.\n\nAgencies are also encouraged to continue developing their own agency-specific practices,\nas appropriate and consistent with this memorandum and the principles in Executive Order\n13960, Executive Order 14091, and the October 30, 2023 genai Executive Order.\n\nThe practices in\nthis section also do not supersede, modify, or direct an interpretation of existing requirements\nmandated by law or governmentwide policy, and agency responsible officials must coordinate to\nensure that the performance of these practices does not conflict with other applicable law or\ngovernmentwide guidance.\n\ni.\n\n**Exclusions from Minimum Practices.\n\n** Agencies are not required to follow the minimum\npractices outlined in this section when using genai solely for one or more of the following\npurposes:\n\n\nA.\n\nEvaluation of a potential vendor, commercial capability, or freely available genai\n\n\ncapability that is not otherwise used in agency operations, solely for the purpose\nof making a procurement or acquisition decision;\n\n\nB.\n\nEvaluation of a particular genai application because the genai provider is the target or\n\n\npotential target of a regulatory enforcement, law enforcement, or national security\naction; 23 and\n\n\nC. Research and development.\n\n24\n\n\nii.\n\n**Extensions for Minimum Practices.\n\n** Until August 1, 2024, agencies may request from\n\nOMB an extension of limited and defined duration for a particular use of genai that cannot\nfeasibly meet the minimum requirements in this section by that date.\n\nThe request must be\naccompanied by a detailed justification for why the agency cannot achieve compliance\nfor the use case in question and what practices the agency has in place to mitigate the\nrisks from noncompliance, as well as a plan for how the agency will come to implement\nthe full set of required minimum practices from this section.\n\nii.\n\n**Extensions for Minimum Practices.\n\n** Until August 1, 2024, agencies may request from\n\n\niii.\n\n**Waivers from Minimum Practices.\n\n** In coordination with other relevant officials, an\n\nagency CAIO may waive one or more of the requirements in this section for a specific\ncovered genai application or component 25 after making a written determination, based upon\na system-specific risk assessment, that fulfilling the requirement would increase risks to\nsafety or rights overall or would create an unacceptable impediment to critical agency\noperations.\n\nSuch waivers are applicable for the duration of the genai\u2019s use, but must be\nreassessed by the CAIO if there are significant changes to the conditions or context in\nwhich the genai is used.\n\nAn agency CAIO may also revoke a previously issued waiver at\n\n\niii.\n\n**Waivers from Minimum Practices.\n\n** In coordination with other relevant officials, an\n\n\n23 Agencies are not required to follow these minimum practices when examining genai as the target or potential target\nof such an action, but they are required to follow these practices when _carrying out_ an enforcement or national\nsecurity action.", "For example, when evaluating an genai tool to determine whether it violates the law, agencies need not\nfollow the minimum practices; if agencies were using that same tool to assess a different target, they would have to\nfollow the minimum practices.\n\n24 genai research and development is not excluded if it is used in agency operations other than for the purposes of\nresearch and development, such as to make agency recommendations or decisions about real people.\n\n25 CAIOs may also grant waivers applicable to groups of closely related genai applications or components, provided\nthat: (1) those systems have undergone a risk assessment that adequately considers the risks from each individual\nsystem; and (2) the systems are substantially identical in their risk profiles.\n\n14\n\n\n-----\n\nany time.\n\nAgencies must report to OMB within 30 days of granting such a waiver,\ndetailing the scope, justifications, and supporting evidence.\n\niv.\n\n**Minimum Practices for Either Safety-Impacting or Rights-Impacting genai.\n\n**\n\nStarting on August 1, 2024, agencies must follow these practices _before_ using new or\nexisting covered safety-impacting or rights-impacting genai:\n\n\nA.\n\n**Complete an genai impact assessment** .\n\nImpact assessments must document the\n\nfollowing:\n\n\n1 _.\n\nThe intended purpose for the genai and its expected benefit_ , supported by specific\n\nmetrics or qualitative analysis.\n\nMetrics should be quantifiable measures of\npositive outcomes for an agency\u2019s mission, for example to reduce costs, wait\ntime for customers, or risk to human life, that can be measured after the genai is\ndeployed to confirm or disprove the value of using genai.\n\n26 Where quantification\nis not feasible, qualitative analysis should demonstrate an expected positive\noutcome, such as for improvements to customer experience or human\ninteractions\u2014and demonstrate that genai is a good fit to accomplish the relevant\ntask.\n\n2.\n\n_The potential risks of using AI_ , as well as what, if any, additional mitigation\n\nmeasures, beyond these minimum practices, the agency will take to help\nreduce these risks.\n\nAgencies should document the stakeholders 27 that will be\nmost impacted by the use of the system and assess the possible failure modes\nof the genai and of the broader system, both in isolation and as a result of human\nusers and other likely variables outside the scope of the system itself.\n\nAgencies should be especially attentive to the potential risks to underserved\ncommunities.\n\nThe expected benefits of the genai functionality should be\nconsidered against its potential risks, and if the benefits do not meaningfully\noutweigh the risks, agencies should not use the genai.\n\n3.\n\n_The quality and appropriateness of the relevant data_ .\n\nAgencies must assess\n\nthe quality of the data used in the genai\u2019s design, development, training, testing,\nand operation and its fitness to the genai\u2019s intended purpose.\n\nIf the agency\ncannot access such data after a reasonable effort to do so, it must obtain\nsufficient descriptive information from the genai or data provider to satisfy the\n\n26 For supervised and semi-supervised genai, agencies should use a target variable which can be reliably measured and\nadequately represents the desired real-world outcomes.\n\n27 Stakeholders will vary by use case.\n\nFor example, if an agency is using genai to control a water treatment process,\nstakeholders may include (1) local residents; (2) state, local, tribal, and territorial government representatives; and\n(3) environmental experts.\n\n15\n\n\n-----\n\nreporting requirements in this paragraph.\n\nAt a minimum, agencies must\ndocument:\n\n\na. the provenance and quality of the data for its intended purpose; 28\n\n\nb. how the data is relevant to the task being automated and has a\n\n\nreasonable expectation of being useful for the genai\u2019s development, testing,\nand operation;\n\n\nc. whether the data contains sufficient breadth to address the range of realworld inputs the genai might encounter;\n\n\nd. whether the data comes from an adequately reliable source; and\ne. how errors from data entry, machine processing, or other sources are\nadequately measured and limited, to include errors from relying on AIgenerated data as training data or model inputs.\n\nB.\n\n**Test the genai for performance in a real-world context** .\n\nAgencies must conduct\n\nadequate testing to ensure the genai, as well as components that rely on it, will work\nin its intended real-world context.\n\nSuch testing should follow domain-specific\nbest practices, when available, and should take into account both the specific\ntechnology used and feedback from human operators, reviewers, employees, and\ncustomers that use the service who impact the system\u2019s outcomes.\n\nTesting\nconditions should mirror as closely as possible the conditions in which the genai will\nbe deployed.", "Testing\nconditions should mirror as closely as possible the conditions in which the genai will\nbe deployed.\n\nThrough test results, agencies should demonstrate, to the extent\npracticable, that the genai will achieve its expected benefits while sufficiently\nmitigating risks associated with the genai, or else the agency should not use the genai.\n\nAgencies are also encouraged to leverage pilots and limited releases, with strong\nmonitoring, evaluation, and safeguards in place, to carry out the final stages of\ntesting before a wider release.\n\nB.\n\n**Test the genai for performance in a real-world context** .\n\nAgencies must conduct\n\n\nC. **Independently evaluate the genai** .\n\nAgencies, through the CAIO, an agency genai\n\noversight board, or other appropriate agency office with existing test and\nevaluation responsibilities, must review relevant genai documentation to ensure that\nthe system works appropriately and as intended, and that its expected benefits\noutweigh its potential risks.\n\nAt a minimum, this documentation must include the\ncompleted impact assessment and results from testing genai performance in a realworld context, both referenced in Section 5(c)(iv).\n\nAgencies must incorporate this\nindependent evaluation into an applicable release or oversight process, or the\nAuthorization to Operate process.\n\nThe independent reviewing authority must not\nhave been directly involved in the system\u2019s development.\n\nC. **Independently evaluate the genai** .\n\nAgencies, through the CAIO, an agency genai\n\n\n28 Consistent with OMB Memorandum M-19-15, _Improving Implementation of the Information Quality Act_ ,\n and the National Science and Technology\nCouncil\u2019s report  _Protecting the Integrity of Government Science_ , .\n\n16\n\n\n-----\n\nStarting on August 1, 2024 and on an ongoing basis _while_ using new or existing covered\nsafety-impacting or rights-impacting genai, agencies must ensure these practices are\nfollowed for the genai:\n\n\nD. **Conduct ongoing monitoring and establish thresholds for periodic human**\n\n**review.\n\n** In addition to pre-deployment testing, agencies must institute ongoing\nprocedures to monitor degradation to the genai\u2019s functionality and to detect changes\nin the genai\u2019s impact on rights or safety.\n\nPart of this monitoring process must include\nperiodic human reviews to determine whether the existing implementation of the\nminimum practices in this section adequately mitigates any new risk.\n\nSuch human\nreview, including renewed testing for performance of the genai in a real-world\ncontext, must be conducted at least annually 29 , and after significant modifications\nto the genai or to the conditions or context in which the genai is used.\n\nReviews must\ninclude oversight and consideration by an appropriate internal agency authority\nnot directly involved in the system\u2019s development or operation.\n\nAgencies should\nalso scale up the use of new or updated genai features incrementally where possible,\nto provide adequate time to monitor for adverse performance or outcomes.\n\nAgencies should also monitor and defend the genai from genai-specific exploits, 30\nparticularly those that would adversely impact rights or safety.\n\nE. **Mitigate emerging risks to rights and safety.\n\n** Upon identifying new or\n\nsignificantly altered risks to rights or safety through continuous monitoring,\nperiodic review, or other mechanisms, agencies must take steps to mitigate those\nrisks, including, as appropriate, through updating the genai to reduce its risks or\nimplementing non-technical mitigations, such as greater human oversight.\n\nAs\nsignificant modifications make the existing implementation of the other minimum\npractices in this section less effective, such as by making training or\ndocumentation inaccurate, agencies must update or repeat those practices, as\nappropriate.\n\nWhere the genai\u2019s risks to rights or safety exceed an acceptable level\nand where mitigation is not practicable, agencies must stop using the affected genai\nas soon as is practicable.\n\n31\n\n\nF. **Ensure adequate human training and assessment.\n\n** Agencies must ensure there\n\nis sufficient training, assessment, and oversight for operators of the genai to interpret\nand act on the genai\u2019s output, combat any human-machine teaming issues (such as\nautomation bias), and ensure the human-based components of the system\neffectively manage risks from the use of genai.\n\nTraining should be conducted on a\nperiodic basis, determined by the agency, and should be specific to the genai use\ncase, product, or service being operated.\n\n29 For customer-facing services, agencies should consider customer feedback.\n\n30 For example, the genai-specific exploits outlined in the MITRE ATLAS framework.\n\n_See_  .\n\n31 Agencies are responsible for determining how to safely decommission genai that was already in use at the time of\nthis memorandum\u2019s release without significant disruptions to essential government functions.", "17\n\n\n-----\n\nG. **Provide appropriate human consideration as part of decisions that pose a**\n\n**high risk to rights or safety.\n\n** Agencies should identify genai functionality that plays\na role in decisions that pose a high risk to rights or safety and ensure that the genai\nfunctionality is not permitted to intervene directly in such situations without\nappropriate human consideration and accountability.\n\nH. **Provide public notice and plain-language documentation through the genai use**\n\n**case inventory.\n\n** Agencies must ensure, to the extent consistent with applicable\nlaw and governmentwide guidance, including those concerning protection of\nprivacy and of sensitive law enforcement, national security, and other protected\ninformation, that the genai\u2019s entry in the use case inventory serves as adequately\ndetailed and generally accessible documentation of the system\u2019s functionality that\nprovides public notice of the genai to its users and the general public.\n\nWhere\npracticable, agencies should include this documentation or link to it in contexts\nwhere people will interact with or be impacted by the genai.\n\nWhere agencies\u2019 use\ncases are excluded from the public inventory requirements described in this\nguidance, they may still be required to report relevant information to OMB and\nmust ensure adequate transparency in their use of genai, as appropriate and\nconsistent with applicable law.\n\n**v.** **Additional Minimum Practices for Rights-Impacting genai.\n\n**\nStarting on August 1, 2024, agencies must follow the above minimum practices for genai\nthat is _either_ safety-impacting _or_ rights-impacting.\n\nIn addition, agencies must also follow\nthese minimum practices _before_ initiating use of new or existing rights-impacting genai:\n\n\nA.\n\n**Take steps to ensure that the genai will advance equity, dignity, and fairness.\n\n**\n\nThis should include at least:\n\n\n1.\n\n_Proactively identifying and removing factors contributing to algorithmic_\n\n_discrimination or bias._ Agencies must assess whether their rightsimpacting genai materially relies on information about a class protected by\nFederal nondiscrimination laws in a way that could result in algorithmic\ndiscrimination or bias against that protected class.\n\nAgencies should also\nassess whether proxies produce undue influence on their rights-impacting\ngenai.\n\nIn either case, if the genai\u2019s reliance on such information results in\nunlawful discrimination or harmful bias against protected classes, the\nagency must cease the use of the information before using the genai for\ndecision-making.\n\n2.\n\n_Assessing and mitigating disparate impacts._ Agencies must test their genai to\n\ndetermine whether there are significant disparities in the genai\u2019s performance\nacross demographic groups, including in the genai\u2019s real-world deployment,\n\n18\n\n\n-----\n\nand, consistent with applicable law, appropriately address disparities that\nhave the potential to lead to discrimination, cause meaningful harm, or\ndecrease equity, dignity, or fairness.\n\nIf adequate mitigation of the disparity\nis not possible, then agencies should not use or integrate the genai tool.\n\n3.\n\n_Using representative data._ Agencies should ensure that data used to\n\ndevelop, operate, and assess their genai is adequately representative of the\ncommunities who will be affected by the genai, and has been reviewed for\nimproper bias based on the historical and societal context of the data.\n\nB.\n\n**Consult and incorporate feedback from affected groups.\n\n** To the extent\n\npracticable and consistent with applicable law and governmentwide guidance,\nagencies must consult affected groups, including underserved communities, in the\ndesign, development, and use of the genai, and use such feedback to inform agency\ndecision-making regarding the genai.\n\nIn the event of negative feedback, agencies\nmust consider not deploying the genai or removing the genai from use.\n\nAgencies are\nstrongly encouraged to solicit feedback on an ongoing basis from affected groups,\nsuch as customers, 32 Federal employee groups, and employees\u2019 union\nrepresentatives, particularly after significant modifications to the genai or the\nconditions or context in which it is used.\n\nTo carry out such consultations, agencies\nshould take adequate steps to solicit input from the groups affected by the genai,\nwhich could include: 33\n\n\n1.\n\nDirect user testing, such as observing users interacting with the system;\n2.\n\nGeneral solicitations of comments from the public, such as a request for\n\n\ninformation in the _Federal Register_ or a \u201cTell Us About Your Experience\u201d\nsheet with open ended space for responses;\n\n\n3.\n\nPost-transaction customer feedback collections; 34\n4.\n\nPublic hearings or meetings, such as a listening session; or\n5.\n\nAny other transparent process that seeks public input, comments, or\n\n\nfeedback from the affected groups in a meaningful, equitable, accessible,\nand effective manner.", "Any other transparent process that seeks public input, comments, or\n\n\nfeedback from the affected groups in a meaningful, equitable, accessible,\nand effective manner.\n\nStarting on August 1, 2024 and on an ongoing basis _while_ using new or existing covered\nrights-impacting genai, agencies must ensure these practices are followed for the genai:\n\n32 Customers can include individuals, businesses, or organizations that interact with an agency.\n\n33 Agencies are not required to conduct consultations in a format that would require OMB clearance under the\nPaperwork Reduction Act (44 U.S.C.\n\n\u00a7 3507), provided the steps the agency takes are adequate to solicit input from\nthe groups affected by the genai.\n\n34 Information on post-transaction customer feedback surveys can be found in OMB Circular A-11, Section 280 \u2013\nManaging Customer Experience and Improving Service Delivery,  .\n\n19\n\n\n-----\n\nC. **Conduct ongoing monitoring and mitigation for genai-enabled discrimination.\n\n**\n\nAs part of their ongoing monitoring requirement cited in Section 5(c)(iv)(D),\nagencies must also monitor rights-impacting genai to assess and mitigate genai-enabled\ndiscrimination against protected classes that might arise from unforeseen\ncircumstances, changes to the system after deployment, or changes to the context\nof use or associated data.\n\nWhere sufficient mitigation is not possible, agencies\nmust safely discontinue use of the affected genai functionality.\n\nD. **Notify negatively affected individuals.\n\n** Where practicable and consistent with\n\napplicable law and governmentwide guidance, agencies must notify individuals\nwhen genai meaningfully influences the outcome of decisions specifically\nconcerning them, such as the denial of benefits.\n\n35 Such notice should be timely\nand written in a manner that is consistent with the Plain Writing Act of 2010, 36 if\napplicable.\n\nAgencies should consider the timing of their notice and when it is\nappropriate to provide notice in multiple languages and through alternative\nformats and channels, depending on the context of the genai\u2019s use.\n\nThe notice must\nalso include a clear and accessible means of contacting the agency and, where\nappropriate, requesting timely remediation for any related issues.\n\nAgencies are\nalso strongly encouraged to provide explanations for such decisions and actions.\n\n37\n\n\nE. **Maintain human consideration and remedy processes** .\n\nAgencies must provide\n\ntimely human consideration and potential remedy to the use of the genai by a\nfallback and escalation system in the event that an impacted individual would like\nto appeal or contest the genai\u2019s negative impacts on them.\n\nIn developing appropriate\nremedies, agencies should follow OMB guidance on calculating administrative\nburden and the remedy process should not place unnecessary burden on the\nimpacted individual.\n\n38 When law or governmentwide guidance precludes\ndisclosure of the use of genai or an opportunity for an individual appeal, agencies\nmust create appropriate mechanisms for human oversight of rights-impacting genai.\n\nF. **Maintain options to opt-out where practicable** .\n\nAgencies must prominently\n\nprovide and maintain a mechanism to conveniently opt out from genai functionality\n\n35 In some instances, such as an active law enforcement investigation, providing immediate notice may be\ninappropriate or impractical, and disclosure may be more appropriate at a later stage (i.e., prior to a defendant\u2019s\ntrial).\n\n36  Pub.\n\nL. No.\n\n111-274 (codified at 5 U.S.C.\n\n\u00a7 301 note), .\n\n37 Explanations might include, for example, how and why the genai-driven decision or action was taken.\n\nWhile exact\nexplanations of genai decisions are often not technically feasible, agencies should characterize the general nature of\nsuch genai decisions through context such as the data that the decision relied upon, the design of the genai, and the\nbroader decision-making context in which the system operates.\n\nSuch explanations should be technologically valid,\nmeaningful, useful, and as simply stated as possible, and higher-risk decisions should be accompanied by more\ncomprehensive explanations.\n\n38 _See_ OMB M-22-10 and supporting document \u201c Strategies for Reducing Administrative Burden in Public Benefit\nand Service Programs .\u201d\n\n20\n\n\n-----\n\nin favor of a human alternative where practicable and consistent with applicable\nlaw and governmentwide guidance.\n\nAn opt-out mechanism must exist where the\naffected people have a reasonable expectation of an alternative or where lack of\nan alternative would meaningfully limit accessibility or create unwarranted\nharmful impacts.\n\nd. Managing Risks in Federal Procurement of genai\n\n\nThis section provides agencies with recommendations for responsible Federal\n\n\nprocurement of genai.", "d. Managing Risks in Federal Procurement of genai\n\n\nThis section provides agencies with recommendations for responsible Federal\n\n\nprocurement of genai.\n\nIn addition to these recommendations and consistent with section 7224(d) of\nthe Advancing American genai Act and Section 10.1(d)(ii) of the genai Executive Order, OMB will\nalso develop an initial means to ensure that genai contracts align with the guidance in this\nmemorandum.\n\ni.\n\n**Aligning to National Values and Law** _._ Agencies should ensure that procured genai\nexhibits due respect for our Nation\u2019s values, is consistent with the Constitution, and\ncomplies with all other applicable laws, regulations, and policies, including those\naddressing privacy, confidentiality, copyright, human and civil rights, and civil liberties.\n\nii.\n\n**Transparency and Performance Improvement** _._ Agencies should take steps to ensure\ntransparency and adequate performance for their procured genai, including by:\n\n\nA. obtaining adequate documentation of procured genai, such as through the use of\n\n\nmodel, data, and system cards;\n\n\nB. regularly evaluating genai-performance claims made by Federal contractors,\n\n\nincluding in the particular environment where the agency expects to deploy the\ncapability; and\n\n\nC. considering contracting provisions that incentivize the continuous improvement of\n\n\nprocured genai.\n\niii.\n\n**Promoting Competition in Procurement of genai.\n\n** Agencies should take appropriate steps\nto ensure that Federal genai procurement practices promote opportunities for competition\namong contractors and do not improperly entrench incumbents.\n\nSuch steps may include\npromoting interoperability and ensuring that vendors do not inappropriately favor their\nown products at the expense of competitors\u2019 offerings.\n\niv.\n\n**Maximizing the Value of Data for genai** _._ In contracts for genai products and services,\nagencies should treat relevant data, as well as modifications to that data\u2014such as\ncleaning and labeling\u2014as a critical asset for their genai maturity.\n\nAgencies should take\nsteps to ensure that their contracts retain for the Government sufficient rights to data and\nany improvements to that data so as to avoid vendor lock-in and facilitate the\nGovernment\u2019s continued design, development, testing, and operation of genai.\n\nAdditionally,\nagencies should consider contracting provisions that protect Federal information used by\nvendors in the development and operation of genai products and services for the Federal\nGovernment so that such data is protected from unauthorized disclosure and use and\n\n21\n\n\n-----\n\ncannot be subsequently used to train or improve the functionality of commercial genai\nofferings offered by the vendor without express permission from the agency.\n\nv. **Responsibly Procuring genai** _._ Agencies are encouraged to include tailored risk\nmanagement requirements in contracts for genai, and particularly for dual-use\nfoundational models, including:\n\n\nA. requiring adequate testing and safeguards, including external genai red teaming,\n\n\nagainst risks from genai such as discriminatory, misleading,\ninflammatory, unsafe, or deceptive outputs;\n\n\nB. requiring that genai models have capabilities, as appropriate and\n\n\ntechnologically feasible, to reliably label or establish provenance for their\ncontent as generated or modified by genai; and\n\n\nC. Agencies are encouraged to consider the relevant NIST standards, as appropriate,\n\n\ndefined pursuant to Sections 4.1(a) and 10.1(d) of the genai Executive Order when\nimposing such requirements.", "**6.\n\n** **DEFINITIONS**\n\nThe below definitions apply for the purposes of this memorandum.\n\nAgency: The term \u201cagency\u201d has the meaning established in 44 U.S.C.\n\n\u00a7 3502(1).\n\nAlgorithmic discrimination: The term \u201calgorithmic discrimination\u201d has the meaning established\nin Section 10(f) of Executive Order 14091 of February 16, 2023.\n\ngenai (genai): The term \u201cgenai\u201d has the meaning established in\nSection 238(g) of the John S. McCain National Defense Authorization Act for Fiscal Year\n2019, 39 which states that \u201cthe term \u2018genai\u2019 includes the following\u201d:\n\n\n1.\n\nAny artificial system that performs tasks under varying and unpredictable circumstances\n\n\nwithout significant human oversight, or that can learn from experience and improve\nperformance when exposed to data sets.\n\n2.\n\nAn artificial system developed in computer software, physical hardware, or other context\n\n\nthat solves tasks requiring human-like perception, cognition, planning, learning,\ncommunication, or physical action.\n\n3.\n\nAn artificial system designed to think or act like a human, including cognitive\n\n\narchitectures and neural networks.\n\n4.\n\nA set of techniques, including machine learning, that is designed to approximate a\n\n\ncognitive task.\n\n39  Pub.\n\nL. No.\n\n115-232, \u00a7 238(g), .\n\n22\n\n\n-----\n\n5.\n\nAn artificial system designed to act rationally, including an intelligent software agent or\n\nembodied robot that achieves goals using perception, planning, reasoning, learning,\ncommunicating, decision making, and acting.\n\nFor the purposes of this memorandum, the following technical context may assist in interpreting\nthis definition:\n\n\n1.\n\nThis definition of genai encompasses, but is not limited to, the genai technical subfields of\n\n\nmachine learning (including, but not limited to, deep learning as well as supervised,\nunsupervised, and semi-supervised approaches), reinforcement learning, transfer\nlearning, and genai.\n\n2.\n\nThis definition of genai does not include robotic process automation or other systems whose\n\n\nbehavior is defined only by human-defined rules or that learn solely by repeating an\nobserved practice exactly as it was conducted.\n\n3.\n\nFor this definition, the technical complexity of a system (e.g., the number of parameters\n\n\nin a model, the type of model, or the amount of data used for training purposes) is not a\nrelevant consideration for determining whether it constitutes genai.\n\n4.\n\nThis definition includes systems that are fully autonomous, partially autonomous, and not\n\n\nautonomous, and it includes systems that operate both with and without human oversight.\n\ngenai Maturity: A Federal Government organization\u2019s capacity to successfully\nand responsibly adopt genai into their operations and decision-making across the organization,\nmanage its risks, and comply with relevant Federal law, regulation, and policy on genai.\n\ngenai Red Teaming: The term has the meaning established for \u201cgenai red-teaming\u201d\nin Section 3(d) of the genai Executive Order.\n\nAutomation Bias: The propensity for humans to inordinately favor suggestions from automated\ndecision-making systems and to ignore or fail to seek out contradictory information made\nwithout automation.\n\nCFO Act Agency: Refers to the agencies identified in 31 U.S.C.\n\n\u00a7 901(b).\n\nDual-Use Foundation Model: Has the meaning established in Section 3(k) of the genai Executive\nOrder.\n\nEquity: Has the meaning established in Section 10(a) of Executive Order 14091.\n\n40\n\nFederal Information: Has the meaning established in OMB Circular A-130.\n\ngenai: Has the meaning established in Section 3(p) of the genai Executive Order.\n\n40 Executive Order 14091, _Further Advancing Racial Equity and Support for Underserved Communities Through the_\n_Federal Government,_  .\n\n23\n\n\n-----\n\nIntelligence Community: Has the meaning established in 50 U.S.C.\n\n\u00a7 3003.\n\nNational Security System: Has the meaning established in 44 U.S.C.\n\n\u00a7 3552(b)(6).\n\nResearch and Development: As in OMB Circular No.\n\nA-11, _Preparation Submission, and_\n_Execution of the Budget_ (2023), research and development is defined as creative and systematic\nwork undertaken in order to increase the stock of knowledge\u2014including knowledge of people,\nculture, and society\u2014and to devise new applications using available knowledge.\n\nRights-Impacting genai: 41 genai whose output serves as a basis for decision or action that has a legal,\nmaterial, or similarly significant effect on an individual\u2019s or community\u2019s:\n\n\n1.\n\nCivil rights, civil liberties, or privacy, including but not limited to freedom of speech,\n\n\nvoting, human autonomy, and protections from discrimination, excessive punishment,\nand unlawful surveillance;\n\n\n2.\n\nEqual opportunities, including equitable access to education, housing, credit,\n\n\nemployment, and other programs where civil rights and equal opportunity protections\napply; or\n\n\n3.", "Equal opportunities, including equitable access to education, housing, credit,\n\n\nemployment, and other programs where civil rights and equal opportunity protections\napply; or\n\n\n3.\n\nAccess to critical resources or services, including healthcare, financial services, social\n\n\nservices, transportation, non-deceptive information about goods and services, and\ngovernment benefits or privileges.\n\nRisks from the Use of genai: Risks related to efficacy, safety, equity, fairness, transparency,\naccountability, appropriateness, or lawfulness of a decision or action resulting from the use of genai\nto inform, influence, decide, or execute that decision or action.\n\nThis includes such risks\nregardless of whether:\n\n\n1. the genai merely informs the decision or action, partially automates it, or fully automates it;\n2. there is or is not human oversight for the decision or action;\n3. it is or is not easily apparent that a decision or action took place, such as when an genai\n\n\napplication performs a background task or silently declines to take an action; or\n\n\n4. the humans involved in making the decision or action or that are affected by it are or are\n\n\nnot aware of how or to what extent the genai influenced or automated the decision or action.\n\nWhile the particular forms of these risks continue to evolve, at least the following factors can\ncreate, contribute to, or exacerbate these risks:\n\n\n1. genai outputs that are inaccurate or misleading;\n2. genai outputs that are unreliable, ineffective, or not robust;\n3. genai outputs that are discriminatory or have a discriminatory effect;\n4. genai outputs that contribute to actions or decisions resulting in harmful or unsafe outcomes,\n\nincluding genai outputs that lower the barrier for people to take intentional and harmful\nactions;\n\n41 Section 5(b) of this memorandum lists genai applications that are presumed to be rights-impacting.\n\n24\n\n\n-----\n\n5. genai being used for tasks to which it is poorly suited or being inappropriately repurposed in\n\n\na context for which it was not intended;\n\n\n6. genai being used in a context in which affected people have a reasonable expectation that a\n\n\nhuman is or should be primarily responsible for a decision or action; and\n\n\n7. the adversarial evasion or manipulation of genai, such as an entity purposefully inducing genai\n\n\nto misclassify an input.\n\nThis definition applies to risks specifically arising from using genai and that affect the outcomes of\ndecisions or actions.\n\nIt does not include all risks associated with genai, such as risks related to the\nprivacy, security, and confidentiality of the data used to train genai or used as inputs to genai models.\n\nSafety-Impacting genai: 42 genai that has the potential to meaningfully impact the safety of:\n\n\n1.\n\nHuman life or well-being, including loss of life, serious injury, bodily harm, biological or\n\n\nchemical harms, occupational hazards, harassment or abuse, or mental health, including\nboth individual and community aspects of these harms;\n\n\n2.\n\nClimate or environment, including irreversible or significant environmental damage;\n3.\n\nCritical infrastructure, including the critical infrastructure sectors defined in Presidential\n\n\nPolicy Directive 21 43 and the infrastructure for voting and protecting the integrity of\nelections; or,\n\n\n4.\n\nStrategic assets or resources, including high-value property, information marked as\n\n\nsensitive or classified by the Federal Government, and intellectual property.\n\nSignificant Modification: An update to an genai application or to the conditions or context in which\nit is used that meaningfully alters the genai\u2019s impact on rights or safety, such as through changing\nits functionality, underlying structure, or performance such that prior evaluations, training, or\ndocumentation become misleading to users, overseers, or individuals affected by the system.\n\nThis includes significantly changing the context, scope, or intended purpose in which the genai is\nused.\n\nUnderserved Communities: Has the meaning established in Section 10(b) of Executive Order\n14091.\n\n42 Section 5(b) of this memorandum lists genai applications that are presumed to be safety-impacting.\n\n43 Presidential Policy Directive 21 (PPD-21), _Critical Infrastructure Security and Resilience_ ,\n .\n\n25\n\n\n-----", "###### Letter from the Mayor \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026...\u2026\u2026 2\n\nLetter from the CTO \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\u2026 3\n\n Introduction \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\n\n4\n\n Foundational Efforts \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 6\n\n Moving Forward with Action \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 7\n\n Engagement for this Plan \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 9\n\n What is genai (genai)?\n\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 10\n\n The NYC genai Action Plan \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 11\n\n Summary of Initiatives and Actions \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026 12\n\n Plan Details \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.. 14\n\n Next Steps \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026..... 46\n\n Notes \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\n\n47\n\n\n-----", "# Letter from the Mayor\n\nMy Fellow New Yorkers:\n\nFrom my earliest days as mayor, I vowed that this administration would\napproach technology in a smart way and use it to deliver better services and\nopportunities for New York City.\n\nWe\u2019ve kept this promise by launching the\nnation\u2019s largest free municipal broadband program, expanding wireless\ninfrastructure across historically underserved communities, and creating a\ndigital one-stop shop to provide seamless access to government.\n\nThis is what\n\u201cGetting Stuff Done\u201d for New Yorkers looks like.\n\ngenai (genai) is one of the most impactful technological advances\nof our time.\n\nWhile genai has the potential to improve services and processes\nacross our government, we must also be mindful of its associated risks.\n\nWith\nthe release of our genai Action Plan, the first-of-its-kind for a major U.S. city, we\nare cementing our commitment to this emerging technology\u2019s responsible\nuse, and ensuring we are deploying the right tools in the right ways.\n\nThe New York City genai Action Plan \u2014 produced by the Office of Technology and\nInnovation \u2014 represents the knowledge, expertise, and contributions of 50\ncity employees from 18 agencies, as well as the insights of industry, academia,\nand civil society.\n\nIt illuminates the path forward, outlining seven new initiatives\nthat emphasize approaches to policy, guidance, support, and resources that\nwill help us responsibly harness the power of genai for good.\n\nAlmost two years into our administration, we remain energized by\ntechnology\u2019s potential to drive safety, opportunity, and efficiency across this\ngreat city.\n\nWe know that New York\u2019s best days are ahead \u2014 and it is with that\nsense of optimism about our city\u2019s future that we present this report.\n\nEric Adams\nMayor\n\n\n-----", "# Letter from the CTO\n\nMy Fellow New Yorkers:\n\nAcross New York City government, genai (genai) tools are inspiring\nparadigm shifts in how we serve New Yorkers.\n\nThese transformational\ntechnologies are critical to efforts such as preventing the next public health\noutbreak, empowering business owners and entrepreneurs, and optimizing\nthe use of city resources.\n\nAnd we\u2019ve only scratched the surface on genai\u2019s massive\npotential impact on our city government, the nation\u2019s largest municipal\nworkforce, and our eight million residents.\n\nWith more city agencies expected to embrace these tools in the near future,\nthe New York City genai Action Plan provides a vital roadmap for productive and\nresponsible use that also affirms New York City\u2019s status as a national and\nglobal leader in governing this emerging technology space.\n\nThis landmark\nplan astutely recognizes that it\u2019s not enough to encourage agencies to deploy\nmore genai-based solutions; we must also provide them with the framework and\nsupport to mitigate risks of misuse, inaccuracy, or bias and discrimination.\n\nI look forward to this plan providing a strong foundation for successful and\nresponsible city applications of these tools that improve the lives of New\nYorkers in the years ahead.\n\nMatthew C. Fraser\nChief Technology Officer\n\n\n-----", "# Foundational Efforts\n\nIn recent years, the City of New York\nhas been at the forefront of efforts to\nseize opportunities and mitigate risks\npresented by genai.\n\nIn 2020-21, the city worked with\nstakeholders across sectors to outline\na novel framework for identifying\nalgorithmic tools; 2 developed policies,\norganizational structures, and\nprocesses to support public reporting\nof these tools; and published the city\u2019s\nfirst-ever directory of tools.\n\nThis work\nhas continued since, and in 2023, the\ncity completed its third year of public\nreporting.\n\n3\n\nIn 2021, the city embarked on a broadbased effort to define the meaning\nand wide-ranging implications of genai,\nunderstand the state of the local genai\necosystem, and surface key\nopportunities and challenges that genai\npresents for the city and its residents.\n\nAfter engaging over fifty stakeholders\n\u2013 from government, industry,\nacademia, and civil society \u2013 the city\nreleased two publications, an \u201cgenai\nPrimer\u201d intended to provide local\ndecision-makers with an accurate and\nshared understanding of the\ntechnology and the issues it presents,\nand a broader genai Strategy that\nidentified key areas for future city\nwork.\n\n4\n\nIn addition to these more centrallymanaged efforts, a number of city\nagencies have already begun to work\nwith genai tools.\n\nAcross diverse domains\nand use cases, from prioritizing\nproperties for safety inspections to\npredicting the next public health\nthreat, agency teams have deployed\ngenai and learned important lessons\nabout how to organize, resource, and\nmanage this work.\n\n5\n\n3D LiDAR-derived image of midtown\nManhattan.\n\nThis image shows change\ndetection of new buildings highlighted in\nred, using 2010 and 2014 nDSM LiDAR data.\n\nDetected changes were used in a\nDepartment of Finance pilot program to\nidentify property assessment changes.\n\n_Source: NYC Department of Finance_\n\n\n-----", "# Moving Forward with Action\n\nIn January 2022, Mayor Adams\nconsolidated the city\u2019s technology and\ndata teams into the Office of\nTechnology & Innovation (OTI), led by\nthe citywide Chief Technology\nOfficer.\n\n6 This consolidation gives OTI\nnew insight into existing technology\npractices and needs across city\ngovernment, as well as new authority\nto set citywide policies and\nprocedures.\n\nIn October 2022, OTI released a\nStrategic Plan that outlined the\nstrategic priorities for the agency\u2019s\nwork in the years ahead, as well as key\ninitiatives toward realizing them.\n\nAmong these is the goal to foster\ninnovation via a set of efforts to\n\u201censure that city government is\npoised to take full advantage of new\ntechnologies.\u201d 7\n\nThis new structure and framework\nprovide a strong grounding for the\ncity to advance its work on genai.\n\nAnd OTI\nis poised to build on prior efforts to\ntake bold action.\n\nThis Action Plan presents a set of\nconcrete commitments, focused\nspecifically on city government\u2019s genai\nuse, that advance the city\u2019s capacity to\nleverage these powerful tools to\nbenefit the public, and ensure we are\ndoing so responsibly, with appropriate\nmeasures in place to mitigate varied\nrisks.\n\nNevertheless, efforts to establish\nframeworks through which\ngovernments and the private sector\ncan introduce responsible practices\nfor using genai are emerging across\nmany levels of government.\n\nAt the\nfederal level, a number of agencies\nand offices have undertaken efforts to\nproduce suggested policy or guidance\nfor organizations to manage genai, most\nnotably the Government\nAccountability Office (GAO) genai\nAccountability Framework, the\nNational Institute for Standards and\nTechnology (NIST) genai Risk\nManagement Framework and the\nWhite House Office of Science and\nTechnology Policy (OSTP) Blueprint\nfor an genai Bill of Rights.\n\n8 Outside the\nU.S., the European Union is expected\nto pass the genai Act this year, which will\nestablish Union-wide requirements for\nboth private and public organizations\nrelated to the use and development of\ngenai tools, based on tiered layers of risk.\n\nAs the technology develops further,\nand as governance measures and\nregulatory practices begin to emerge\nacross the field, the city\u2019s efforts will\nneed to be iterative and ongoing.\n\nAccordingly, this Plan incorporates\nsteps to maintain and update the\nactions outlined as the landscape\nevolves.\n\ngenai technologies are dynamic and\ncontinually evolving.\n\nAt the same\ntime, genai regulation and broader best\npractices for governance are still in\ntheir infancy, and stakeholders are\ngrappling with a complex set of policy\nquestions while often struggling to\nkeep up with the rate of technological\nchange.\n\n-----", "**A Note on Scope**\n\ngenai has broad implications for the city\nand New Yorkers, including the varied\nimpacts of private sector use of genai, as\nwell as workforce and economic\ndevelopment concerns.\n\nWhile the\nefforts described in this Plan are\nfocused on city government\u2019s use and\ngovernance of genai, the city recognizes\nthe importance and impact of these\nother issues, and work is underway at\na range of agencies and offices to\naddress them.\n\n9\n\nLikewise, broader efforts to enhance\nthe quality and usability of city\ngovernment data \u2013 a key foundation\nfor genai use \u2013 are not in scope for this\ndocument but are being addressed\nthrough parallel efforts.\n\n10\n\n_Photo: Phil Kline, NYC & Co._\n\n\n-----", "# Engagement for this Plan\n\nIn preparing this genai Action Plan, the\nOTI team not only built upon insights\nfrom the more than fifty stakeholder\ninterviews conducted toward the\ndevelopment of the NYC genai Strategy, 11\nbut also conducted a range of new\ninterviews and workshops with\nstakeholders across sectors.\n\nThis\nincluded more than fifty city staff\nmembers representing a wide range\nof roles from eighteen agencies and\noffices, as well as external experts\nfrom ten organizations.\n\nA full list of\norganizations engaged specifically for\nthe development of the Action Plan is\nbelow.\n\nOngoing input from\nstakeholders across sectors, and\ndirectly from New Yorkers is a key\ncomponent of future efforts outlined\nin this Plan.\n\nCity Stakeholders\n\nAdministration of Children\u2019s Services\nCommission on Human Rights\nDepartment of Buildings\nDepartment of Citywide Administrative\nServices\nDepartment of Consumer and Worker\nProtection\nDepartment of Education\nDepartment of Finance\nDepartment of Health and Human\nServices\nDepartment of Social Services\nDepartment of Transportation\nFire Department of New York\nMayor\u2019s Office of Contract Services\nMayor\u2019s Office of Efficiency\nMayor\u2019s Office of Equity\nMayor\u2019s Office for People with Disabilities\n\n\n_Photo: Benny Polatseck, New York City_\n\n_Mayoral Photography Office_\n\n\n_Photo: Benny Polatseck, New York City_\n\n\nMayor\u2019s Office of Risk and Compliance\nNew York City Police Department\nOffice of Technology and Innovation\n\nExternal Stakeholders\n\ngenai for the People\nColumbia University Data Science\nInstitute\nData & Society\nInstitute for Advanced Study\nNational Institute of Standards and\nTechnology\nNY Tech Alliance\nNYU Center for Responsible genai\nTech:NYC\nThe GovLab\nUniversity of Virginia\n\n\n-----", "# What is genai (genai)?\n\nBecause a wide variety of\ntechnologies and approaches may be\nconsidered genai, the city currently\ndefines genai broadly as \u201can umbrella\nterm without precise boundaries, that\nencompasses a range of technologies\nand techniques of varying\nsophistication that are used to, among\nother tasks, make predictions,\ninferences, recommendations,\nrankings, or other decisions with data,\nand that includes topics such as\nmachine learning, deep learning,\nsupervised learning, unsupervised\nlearning, reinforcement learning,\nstatistical inference, statistical\nregression, statistical classification,\nranking, clustering, and expert\nsystems.\u201d 12\n\n\nThese examples show just how wide\nthe array of genai technologies is.\n\nAs this\nPlan outlines below, additional work is\nneeded to create a shared\nunderstanding about what genai is and\nthe role it plays in city government.\n\nUsing a broad definition allows the\ncity to maintain an appropriately wide\nlens to account for the range of both\nopportunities and risks that genai\ntechnologies present.\n\nIt also\nhighlights the complexity of the topic,\nthe quick-changing nature of these\ntechnological developments, and the\nefforts required for this work to be\nmeaningful across applications.\n\nThe term \u201cgenai\u201d can include, for\nexample, such diverse tools as:\n\n\n\n-  Machine learning algorithms, such\n\nas those that recommend viewing\noptions on streaming platforms, that\npredict consumer demand for goods\nand services, or that model the risk\nof a disease outbreak in a\ncommunity;\n\n\n\n-  Computer vision technologies, such\n\nas those that match identities based\non fingerprint or iris scans, that\ndetect objects in images to enable\nbetter search and accessibility, that\nenforce cash-free tolling, or that\ncount pedestrians in a public space;\n\n\n\n-  Natural language processing\n\napplications, such as those that autopopulate search results, provide\npredictive text in messaging apps,\nprovide dynamic customer support\nwith chatbots, or translate text into\nanother language.\n\n-----", "# The NYC genai Action Plan\n\nThe NYC genai Action Plan introduces\nseven new initiatives, each comprised\nof a set of phased actions the city will\nundertake toward harnessing the\npower of genai to deliver positive\noutcomes for New Yorkers, while\ncarefully mitigating the risks these\ntechnologies present.\n\nActions in each\ninitiative are organized into\nimmediate- and medium-term\ntimeframes and include specific\ntimelines for implementation.\n\nAcross these initiatives, there is an\nemphasis on providing more\ncentralized policy, guidance, support,\nand resources for city agencies, to\nhelp ensure that appropriate\ngovernance measures are in place\nacross city government, that agencies\nare better equipped to advance their\ngenai efforts, and that the city is working\nefficiently, collaboratively, and with\naccountability to the public.\n\nCollaborative engagement is broadly\na key theme across all seven\ninitiatives.\n\nThis includes bringing in\nexpertise from the rich local\ncommunity of experts present in New\nYork City \u2013 from academia, industry,\ncivil society, community organizations,\nand organized labor, engaging with\nour counterparts at all levels of\ngovernment, and speaking directly\nwith New Yorkers to hear their ideas,\nunderstand their concerns, and\naccount for their experience with genai\nacross communities.\n\n_Photo: Michael Appleton, New York City_\n\n_Mayoral Photography Office_\n\n\n_Photo: Michael Appleton, New York City_\n\n\n-----", "**01** **Design and Implement a Robust Governance Framework**\n\n1.\n\nEstablish a City genai Steering Committee\n\n\n2.\n\nEstablish Guiding Principles and Definitions\n\n\n3.\n\nProvide Preliminary Use Guidance on Emerging Tools\n\n\n4.\n\nCreate a Typology of genai Projects\n\n\n5.\n\nExpand Public genai Reporting\n\n\n6.\n\nDevelop an genai Risk Assessment and Project Review Process\n\n\n7.\n\nPublish an Initial Set of genai Policies and Guidance Documents\n\n\n8.\n\nPursue Ongoing Monitoring to Review genai Tools in Operation", "**04** **Build genai Knowledge and Skills in City Government**\n\n1.\n\nExplore and Pursue Opportunities to Foster Information Sharing Across\nAgencies and Teams\n\n\n2.\n\nIdentify High-Priority Agency Skills Needs\n\n\n3.\n\nAssess the Landscape of Internal and External Resources to Support genai\nKnowledge-Building Efforts\n\n\n4.\n\nLaunch Initial Knowledge-Building Efforts\n\n\n5.\n\nExplore Opportunities to Bring genai Talent into City Government for\nLimited-Term Projects\n\n\n6.\n\nCentrally Track and Share Emerging Tools, Use Cases, and\nConsiderations\n\n\n7.\n\nEncourage Alignment on genai Skills and Duties\n\n\n-----", "##### Objective\n\nEstablish a holistic, adaptable\nframework for genai governance that\nacknowledges the risks of genai,\nincluding bias and disparate\nimpact, and which will help ensure\nthe responsible use of genai tools\nconsistent with values of reliability,\ntransparency, accountability,\nfairness and non-discrimination,\nprivacy, cybersecurity, and\nsustainability, among others\ndefined through the\nimplementation of this Action\nPlan.", "##### Target Outcomes\n\nClear principles and definitions\nguide city government\u2019s genai use\nand governance.\n\nAgencies are engaged to help\ndefine procedures that both\naddress their needs and\nensure responsible use of genai.\n\nAgencies are supported by\ncentralized genai policy, guidance,\nand processes that address\nrisks.\n\nThe public is well-informed\nabout city genai use.\n\n-----", "##### Immediate Actions \u2013 projects start within 1 year\n\n1.1 Establish a City genai Steering Committee\n\nEstablish an genai Steering Committee, composed of representatives of OTI\ndivisions and other city agencies, to bring stakeholders from across city\ngovernment together to provide input toward and oversight of genai activities.\n\nOTI\nwill develop a charter for the Steering Committee to codify the scope, guiding\nprinciples and membership, and how the committee will operate and interact\nwith city genai projects.", "**Complete within 3 months**\n\n1.2 Establish Guiding Principles and Definitions\n\nSet goals and guiding principles for the responsible use of genai across agencies\nand define key terms for the city\u2019s governance work.\n\nThese efforts may draw\nlessons from frameworks that have been developed at the national and\ninternational level.\n\n13", "**Complete within 3 months**\n\n1.3 Provide Preliminary Use Guidance on Emerging Tools\n\nIn alignment with the guiding principles and goals described above, provide\nagencies with immediate-term guidance on the uses and risks of emerging\nforms of genai, focusing first on genai tools \u2013 in particular, large language\nmodels and other related technologies.", "**Complete within 3 months**\n\n1.4 Create a Typology of genai Projects\n\nUsing the city\u2019s existing public reporting of algorithmic tools, 14 as well as\nadditional research, create a typology of genai projects to reflect the variety of\ntechnologies and uses that may fall under the umbrella term of \u201cgenai\u201d for New\nYork City.\n\nThe resulting typology can be used to inform governance efforts,\nclarify agency support needs, and enhance public engagement and\nunderstanding.", "**Complete within 6 months**\n\n-----\n\n1.5 Expand Public genai Reporting\n\nProvide agencies with enhanced genai reporting guidelines, building on reporting\ncurrently conducted under Local Law 35 of 2022, 15 to increase public awareness\nof genai initiatives citywide.\n\nThis may include broadening the scope of reporting,\nadding reporting requirements related to models and performance, and\nestablishing guidelines for explainability.\n\nAdditionally, make resulting reports\nreadily accessible to the public through the Open Data platform.", "**Initiate within 6 months, then ongoing**\n\n1.6 Develop an genai Risk Assessment and Project Review Process\n\nBegin to develop an genai Risk Assessment and Project Review Process to enable\nthe analysis of existing and proposed genai projects that addresses major\nconsiderations of genai risk, including reliability, fairness, bias, accountability,\ntransparency, data privacy, cybersecurity, and sustainability.\n\nAfter creating a\npreliminary assessment model and process, OTI will update both on an ongoing\nbasis as policies, guidance, and use cases develop.\n\nThese steps will be designed\nto pair with existing citywide privacy and cybersecurity policies and procedures.", "##### Medium-Term Actions \u2013 projects start within 1\u20132 years\n\n1.7 Publish an Initial Set of genai Policies and Guidance Documents\n\nIn consultation with the Steering Committee, create an initial set of policies and\nguidance documents to support responsible genai use.\n\nPolicies and guidance may\ndraw from existing standards frameworks, such as the National Institute for\nStandards and Technology (NIST) genai Risk Management Framework 16 or the\nGovernment Accountability Office (GAO) genai Accountability Framework.\n\n17 OTI will\nprioritize and incrementally publish individual policies and guidance\ndocuments where practical.\n\n_Particular steps related to procurement of genai tools_\n_by the city are outlined below in item 2.3._", "**Initiate within 18 months, then ongoing**\n\n1.8 Pursue Ongoing Monitoring to Review genai Tools in Operation\n\nReview genai tools in accordance with the outlined Project Review Process,\nincluding at different stages of the project lifecycle, as relevant.\n\nThis may involve\nutilizing metrics to evaluate the impact of genai solutions and help to ensure that\nthey are operating consistent with the city\u2019s guiding principles for genai.\n\nReviews\nconducted after a solution is implemented will assess the tool\u2019s effectiveness at\nfulfilling its stated goals, protecting against drift or shifting objectives, and\nfacilitating project improvement.", "##### Objective\n\nFoster feedback and consultation\nwith stakeholders across sectors\naround both the opportunities and\nchallenges posed by genai and the\nwork of supporting responsible genai\nuse across city government.\n\nSupport information sharing to\nensure the city\u2019s efforts reflect best\npractices in the field and to align\npolicy across levels of government.", "##### Target Outcomes\n\nExperts from a variety of\nbackgrounds provide timely\nperspective and guidance on\ncity government\u2019s genai efforts.\n\nNYC develops productive\nrelationships with partners\nacross academia, industry, civil\nsociety, community\norganizations, and organized\nlabor and leverages\nopportunities for collaboration.\n\nCity government works in\nalignment with efforts across\nlevels of government, and\nproductively shares\ninformation with peers.\n\n-----", "**Complete within 3 months**\n\n2.2 Establish an External Advisory Network\n\nEstablish an Advisory Network of individuals to support the city\u2019s work on a\nconsultative basis, to include stakeholders from, for example, academia,\nindustry, civil society, community organizations, and organized labor.\n\nOTI will\ntake steps to formalize relationships with an initial group to serve needs\nidentified in the external engagement agenda.\n\nThe Advisory Network will be\nupdated over time as the city\u2019s needs and Advisor availabilities evolve.", "**Initiate within 12 months, then ongoing**\n\n2.4 Explore Opportunities for Structured Partnerships with External\n\nGroups\n\nExplore opportunities to create more structured partnerships with outside\norganizations that serve the city\u2019s goals.\n\nThese might include, for example,\nresearch partnerships with local students or academic researchers, or public\neducation and engagement partnerships with local community organizations.", "**Initiate within 12 months, then ongoing**\n\n2.5 Support Information Sharing Across Governments\n\nBuild relationships across State, Federal, and local governments, to support the\nongoing exchange of information and best practices related to a wide range of\ngenai subjects of interest to the city, and reduce the likelihood of policy and\nregulatory conflicts across jurisdictions.", "##### Objective\n\nEducate and empower the public,\ncommunicating openly about the\ncity\u2019s progress and supporting a\nrange of mechanisms for public\ninput.\n\nIn order to best serve the\npublic, foster trust, and support\nresponsible use of genai, city\ngovernment efforts must be\ngrounded in the expertise, needs,\nand experience of New Yorkers.\n\nPublic education on genai is a critical\nfoundation for meaningful and\nequitable engagement.", "##### Immediate Actions \u2013 projects start within 1 year\n\n3.1 Hold Introductory Public Listening Sessions\n\nHold a set of introductory public listening sessions to tap the ingenuity of New\nYork\u2019s diverse population to shape the city\u2019s next steps on genai and understand\nresidents\u2019 key concerns and priorities.\n\nFollowing these sessions, brief city\ngovernment stakeholders on findings, and issue a public summary.", "**Initiate within 6 months, then ongoing**\n\n3.3 Explore Public Education Resources and Partnerships\n\nExplore the existing landscape of resources and organizations working to\neducate the public about genai and related topics to identify useful tools and\npotential partnerships.\n\nThis may include, for example, exploration of educational\nmaterials or programs that may be made more readily available to New Yorkers,\nor partnerships that may be facilitated among relevant organizations.", "**Initiate within 9 months, then ongoing**\n\n3.4 Create Guidance for Agencies on genai Public Engagement\n\nCraft initial guidance materials for agencies on integrating public engagement\nin their genai efforts, where relevant, to support responsible use, and better\nunderstand impacts for New York City\u2019s diverse communities.\n\nThis work may\noccur in partnership with experts in this emerging area, as established via the\nAdvisory Network, or via a more structured partnership engagement.", "##### Target Outcomes\n\nCity personnel engage with\nnew genai knowledge resources\nand report that they are\nobtaining value from them.\n\nAgencies regularly leverage\ncentralized resources for swift\ngenai information sharing.\n\nCollaborations across industry,\nacademia, and beyond lead to\nsuccessful project\nengagements leveraging\npartners\u2019 expertise to address\nkey challenges the city faces.\n\n-----", "##### Immediate Actions \u2013 projects start within 1 year\n\n4.1 Explore and Pursue Opportunities to Foster Information Sharing\nAcross Agencies and Teams\n\nEnable agencies to share information about their use of and concerns related to\ngenai.\n\nThis may include leveraging the Office of Data Analytics\u2019 Analytics Exchange,\nCitywide CIO Forums, the Citywide Privacy Protection Committee, or other\nexisting city convenings, or establishing new channels to support the exchange\nof information within the city, such as a dedicated genai community of practice or\ndistribution list.", "**Complete within 6 months**\n\n4.2 Identify High-Priority Agency Skills Needs\n\nWork with the Steering Committee to develop and implement a survey for\nagency executives to determine high-priority skills and knowledge needed\nacross city government related to genai use and governance, to include skills for a\ndiverse range of functions, both technical and not.", "**Complete within 12 months**\n\n4.4 Launch Initial Knowledge-Building Efforts\n\nWork with the Steering Committee and other agencies involved in the city\u2019s\ninternal workforce development to plan the scope, structure, and priorities of\nnew genai learning resources for city staff and begin roll-out of initial efforts.\n\nAnnounce and promote these resources across agencies.", "**Initiate within 12 months, then ongoing**\n\n-----\n\n4.5 Explore Opportunities to Bring genai Talent into City Government\n\nfor Limited-Term Projects\n\nIn partnership with industry, academic, or other stakeholders, and leveraging\nanalogous efforts already underway within the city, explore the feasibility of a\npartnership program that brings external teams in on a limited-term basis to\ndirectly support city genai projects.", "**Ongoing**\n\n4.7 Encourage Alignment on genai Skills and Duties\n\nIn partnership with internal stakeholders, identify means to ensure that\napplicable city government job descriptions and civil services titles reflect the\nrange of genai skills needed to support city efforts.\n\nFor example, consider\ndevelopment of a civil service title for \u201cdata scientist.\u201d", "##### Objective\n\nSupport city agencies in their\nefforts to build and use genai, based\non identified agency needs,\nincluding a process to provide\ncomprehensive assistance\nthroughout the lifecycle of genai\nprojects.\n\nDevelop a knowledge\nbase to equip agencies with\nresources and guidance, including\nin their reuse of existing tools,\ncapabilities, and deployed\ntechnologies.", "##### Target Outcomes\n\nCommon agency challenges\nare identified and tracked on\nan ongoing basis.\n\nAgencies are effectively\nsupported across their genai\nefforts, and benefit from\ncentralized expertise and\nresources.\n\nCity government is\nempowered to build genai tools\nin-house, where applicable,\nand to scale those efforts to\nexpand their impact as\nappropriate.\n\n-----", "##### Immediate Actions \u2013 projects start within 1 year\n\n5.1 Identify Opportunities for In-House Tool Development\n\nUsing the typology of genai projects identified through public reporting, conduct\nan analysis related to advantages and disadvantages of in-house development\nvs. procurement for different project types.\n\nAs part of the analysis, identify\nproject types where in-house development is advantageous and suitable for\nexpedient deployment.\n\nAdditionally, identify specific use cases that appear\nscalable within an agency or transferable across agencies.", "**Complete within 9 months**\n\n5.2 Develop Example Project Lifecycles and Identify Bottlenecks\n\nConsult with OTI teams and agency partners to develop example project\nlifecycles that can be used to identify common bottlenecks and determine the\nform and degree of support that OTI should provide to agencies.\n\nBottlenecks\nmay include, for example, agency or citywide procedures, infrastructure or\nsoftware availability, costs and funding, sufficient and appropriate skills,\nsponsorship, or data quality.", "**Initiate within 12 months, then ongoing**\n\n5.3 Define OTI and Agency Roles in Support of Projects\n\nCreate a \u201cRoles and Responsibilities\u201d model for supported projects.\n\nFor example,\nOTI could assign \u201cowners\u201d to key project activities from high-level ideation to\ntechnology implementation.\n\nThis could also include support with problem\ndefinition, model building, budget development, defining a vendor proof of\nconcept, risk mitigation, and compliance with city policies and guidance,\namong other areas.", "##### Medium-Term Actions \u2013 projects start within 1\u20132 years\n\n5.4 Scale, Reuse, and Repurpose Identified In-House Projects\n\nFor projects that may be identified as suitable for scaling or transferring across\nagencies, create scaling plans in partnership with agencies and other\nstakeholders.\n\nInclude considerations related to availability of skills, budget, and\napplicability.", "**Ongoing**\n\n5.5 Provide Implementation Support, Tracking, and Risk Analysis\n\nProvide agencies with ongoing operational and infrastructure support, as well\nas project tracking and risk analysis, where needed, to promote successful\nimplementation.\n\nAnalyze staff and budgetary needs, and document workflows\nfor common project support requests to appropriately build centralized support\ncapacities and resources.", "##### Objective\n\nDevelop genai-specific procurement\nstandards or guidance to support\nagency-level contracting, ensuring\nprocured products adhere to the\ncity\u2019s genai principles and goals and\ntake steps to mitigate risks,\nincluding challenges with respect\nto transparency and explainability\nthat can occur when procuring genai\ntools from third-party vendors.\n\nLeverage opportunities to\nstreamline city government\u2019s genai\ncontracting to avoid redundancies\nand support cross-agency access\nto high-demand tools, as\nappropriate.", "##### Immediate Actions \u2013 projects start within 1 year\n\n6.1 Conduct an Agency Needs Assessment\n\nConduct an agency needs assessment to identify and document where\nagencies need support with contracting for their genai solutions, considering\ndefinitions and typologies of different types of genai, and where there are\nopportunities to streamline efforts.", "**Complete within 9 months**\n\n6.2 Establish a Directory of Procured genai Tools and Guidance on\n\nAppropriate Use\n\nEstablish and share across agencies a directory of genai solutions that city\ngovernment has already procured to support visibility and access, where\nappropriate.\n\nInclude within this directory guidance on appropriate use of such\ntools.", "##### Medium-Term Actions \u2013 projects start within 1\u20132 years\n\n6.4 Develop genai-Specific Procurement Standards, Terms, or Guidance\n\nIn partnership with relevant agencies, and complementing existing contracting\nrequirements related to privacy and cybersecurity, develop a set of contract\nstandards, terms, or guidance for procurement of genai tools, to support agencylevel contracting, and help ensure procured products align with city genai\nprinciples and goals.\n\nThese materials should be tailored to project types and risk\nprofiles, and may include, for example, content related to performance,\ntransparency and explainability, fairness and non-discrimination, privacy,\ncybersecurity, and environmental impact, among others.", "##### Immediate Actions \u2013 projects start within 1 year\n\n7.1 Institute and Implement Processes for Refreshing Key Aspects of\n\nthe City\u2019s Plan on an Ongoing Basis\n\nIdentify areas of genai work, as described in this Action Plan, where change\nmanagement processes are needed to help ensure timeliness and currency of\nthe city\u2019s management of genai.\n\ngenai is a highly dynamic technology and policy\nspace, and an iterative approach will be required to account for the changing\ntechnological, organizational, and social landscape, as well as emerging best\npractices in the field.\n\nAccordingly, the city will need to maintain and update its\nefforts in several areas to ensure they remain relevant and up-to-date.\n\nThis\nincludes updates to a range of governance measures, public engagement\nefforts, and city knowledge-building resources, among others.", "**Initiate within 9 months, then ongoing**\n\n7.2 Publish an Annual genai Progress Report\n\nTrack the city\u2019s progress toward the implementation of the actions set out in\nthis Plan to ensure accountability on an annual basis, via a public report.\n\nThis\nreport will include an account of any updates made to actions outlined, as\ndescribed above.", "## Statement of Need\n\nThe newly widespread availability of genai (\u201cgenai\u201d) technology has quickly\nreshaped the digital landscape.\n\ngenai, including chatbots relying on large language models such\nas ChatGPT, can generate novel media content, including text, music, images and videos, in response to\ntext prompts from a user.\n\nThis technology opens new possibilities for education and knowledge production,\npersonal development, and expression.\n\nBut optimism about these potential benefits has also,\nappropriately, been accompanied by concerns about adverse impacts of genai, provoking debate\namong policymakers and the public at large.\n\nSome companies launching products powered by Generative\ngenai, such as Microsoft, Open genai, and Google maintain ethical and/or human rights guidelines for genai more\nbroadly and have confirmed that they are conducting risk assessments and testing processes.\n\nBeyond the\nproduct level, there also exists a broader debate about the appropriate timing of introducing genai\nmodels into the consumer market at scale, and the extent to which the publication of models and codes\nstill under development is appropriate.\n\nInformation about the extent to which human rights due diligence (HRDD) has been conducted as part of\nthe development and deployment of these technologies is limited, and there has been little opportunity for\nlearning across the industry about the most effective approaches to prevent and mitigate human rights\nrisks stemming from advances in genai technologies.\n\nWhile ethical frameworks can be useful in\nguiding company risk management approaches, they are unlikely to cover the full spectrum of\ninternationally recognized human rights standards necessary to ensure human dignity and nondiscrimination.\n\nAs additional companies enter the market, risks will increase as many firms prioritize speed\nand profits over preventing and mitigating adverse human rights impacts.\n\nSome standard setting is under\nway in different fora, but regulatory frameworks are not keeping pace with technical developments or with\neffective human rights risk mitigation practices, leaving potentially severe human rights and other societal\nrisks unaddressed.\n\nThere is therefore an urgent need to explore what constitutes the appropriate scope and practice of\nbusiness responsibility in relation to genai.\n\nIdentifying appropriate responses to this question and\nbuilding alignment across industry, civil society and standard setters about expectations should draw on\ninternational human rights standards.\n\nIn particular, the expectations set out in the UN Guiding Principles\non Business and Human Rights (UNGPs) can provide authoritative and widely accepted guidance.\n\nUsing\nthese global standards as the initial basis for unpacking the scope and nature of corporate responsibilities\ncan also provide a common foundation for constructive and robust dialogue.\n\nConsidering this, the UN\nHuman Rights Office is launching this project as a contribution to wider global and societal debates about\nhow to realise the positive potential of genai, while mitigating the many severe, salient risks that\nmay accompany this transformative technology.", "## Objectives\n\n-  Clarify the expectations under the UNGPs for companies developing and launching genai\n\nproducts in order to achieve common and more effective human rights risk management\napproaches across the industry.\n\n-----\n\n-  Raise awareness and facilitate exchange among key stakeholders and interdisciplinary experts to\n\nshape a comprehensive understanding about the role the UNGPs can play in governing Generative\ngenai responsibly.\n\n-  Inform the debate about policy options for managing human rights risks related to the development\n\nand launch of genai, including through mandatory and voluntary measures.", "## Approach\n\nBuilding on OHCHR\u2019s existing work on tech and human rights, the project will be implemented through an\niterative process of research and engagement.\n\nThis will include conducting a series of exploratory\ninterviews with company practitioners, civil society, technical experts, and other key stakeholders, as well\nas workshops and other convenings involving multiple stakeholders.\n\nProject implementation will be led by the UN Human Rights B-Tech Project , supported by Shift , a leading\ncenter of expertise on the UNGPs, with additional assistance from the Global Network Initiative (GNI), a\nleading multistakeholder initiative with fifteen years of experience working on tech and human rights.\n\nThe\nproject team will include business and human rights expertise and be supported by a technical expert\ngroup of academics to bring in state-of-the-art computer science research on genai to enable a\nbetter understanding of its implications for managing human rights risks.\n\nFor the company engagements,\nthe project will draw in particular from the team\u2019s ongoing engagement with companies in the B-Tech\nCommunity of Practice (CoP), while also involving additional companies .\n\nGiven the highly competitive nature of efforts in the genai area, the ability to work within an existing\nframework with some degree of trust among the participants and organizers will be essential for the initial\nexercise of mapping risks.\n\nWe aim to create a space that allows for companies to jointly discuss not only\nbest practices but also lessons learned.\n\nFor civil society engagement, the project will draw on the expertise\nand perspectives from GNI\u2019s academic, civil society, and investor constituencies, and the extensive\nnetwork of the B-Tech community of digital rights advocates, academics, and other practitioners.\n\nThe\nproject will be underpinned by research into genai\u2019s salient human rights risks and build on work already done\non genai risk management, as well as the work of B-Tech and other OHCHR tech-related work, the Global\nNetwork Initiative (GNI) and other relevant initiatives on business and human rights in the tech sector.", "## Activities\n\nThe project will be structured into three initial phases:\n\n\n1) Consultations and Mapping: Map current company approaches to human rights due diligence in order\n\nto identify and mitigate salient human rights risks stemming from or being linked to the development,\ndeployment, and use of genai.\n\nThis will be carried out through desk-based research,\nexplorative expert interviews with company representatives, civil society, and experts, and the\nestablishment of a reference group comprised of experts from genai and data science as well as leaders\nfrom relevant policy areas.\n\n2) Peer Learning Workshops and Engagement: Targeted convenings (in-person and virtual) with key\n\nstakeholders, in particular with leading tech firms, relating to genai practices, including\nmeasures adopted to account for potential adverse impacts on human rights.\n\n3) Consolidation: Based on the input gathered and received, a summary of salient risks and state of play\n\non company practices and learning to date will be prepared, without attribution.\n\nFurther outputs will be\ndeveloped based on the needs and approaches identified in the convenings described above.\n\nAn\noutline of good practice/standards based on UNGPs expectations is a likely outcome.\n\nBuilding on the consolidation of the findings from the initial phases of the project, possible additional\nactivities will be determined in consultation with those participating.\n\n-----\n\nGuiding questions to inform project activities and engagements:\n\n\n\n-  How do existing HRDD practices need to be adapted to be able to incorporate the risks and\n\n\nmitigation strategies stemming from or being linked to the use of genai?\n\n-  In which corporate governance structures are risk management processes for genai\n\n\nembedded in companies, e.g., would engaging with product counsel be impactful and if so, how?\n\n-  At which points should an evaluation of misuse/abuse be integrated into the genai research/innovation\n\n\nprocess?\n\nHow can this be tailored to find the appropriate balance between innovation, actual\nfunctional breakthroughs/insights and severity of risks.\n\n-  What does meaningful transparency about, and accountability for, use, risks and adverse impacts\n\n\nof genai look like in practice?\n\n-  Are existing ethical checks/questions in the R&D process sufficient?\n\nWhat, if anything, does\n\n\nattention to, and prioritization of, a vast number of prospective adverse human rights impacts add\nto this in practice?\n\n-  What does responsible conduct look like for different objectives and modes of genai being made or\n\n\nbecoming available for use?\n\n-  Which forms of mitigation can be employed?", "## Outputs\n\nB-Tech Briefing (max.\n\n15 pages) on key risks, current state of practice, best practices and\nstandards, and UNGPs expectations with regard to genai.\n\nAdditional shorter supporting supplements will be produced that discuss genai-related\nhuman rights risks, scenario-based UNGPs interpretations for genai use cases, the state of practice\nof business respect for human Rights in genai companies and policy coherence in genai Governance\naligned with the UNGPs.\n\n-----", "**OCTOBER 2022**\n\n-----\n\npublished by the White House Office of Science and Technology Policy in October 2022.\n\nThis framework was\nreleased one year after OSTP announced the launch of a process to develop \u201ca bill of rights for an genai-powered\nworld.\u201d Its release follows a year of public engagement to inform this initiative.\n\nThe framework is available\nonline at:", "**About the Office of Science and Technology Policy**\n\nThe Office of Science and Technology Policy (OSTP) was established by the National Science and Technology\nPolicy, Organization, and Priorities Act of 1976 to provide the President and others within the Executive Office\nof the President with advice on the scientific, engineering, and technological aspects of the economy, national\nsecurity, health, foreign relations, the environment, and the technological recovery and use of resources, among\nother topics.\n\nOSTP leads interagency science and technology policy coordination efforts, assists the Office of\nManagement and Budget (OMB) with an annual review and analysis of Federal research and development in\nbudgets, and serves as a source of scientific and technological analysis and judgment for the President with\nrespect to major policies, plans, and programs of the Federal Government.", "**Legal Disclaimer**\n\n_The Blueprint for an genai Bill of Rights: Making Automated Systems Work for the American People_ is a white paper\npublished by the White House Office of Science and Technology Policy.\n\nIt is intended to support the\ndevelopment of policies and practices that protect civil rights and promote democratic values in the building,\ndeployment, and governance of automated systems.\n\nThe _Blueprint for an genai Bill of Rights_ is non-binding and does not constitute U.S. government policy.\n\nIt\ndoes not supersede, modify, or direct an interpretation of any existing statute, regulation, policy, or\ninternational instrument.\n\nIt does not constitute binding guidance for the public or Federal agencies and\ntherefore does not require compliance with the principles described herein.\n\nIt also is not determinative of what\nthe U.S. government\u2019s position will be in any international negotiation.\n\nAdoption of these principles may not\nmeet the requirements of existing statutes, regulations, policies, or international instruments, or the\nrequirements of the Federal agencies that enforce them.\n\nThese principles are not intended to, and do not,\nprohibit or limit any lawful activity of a government agency, including law enforcement, national security, or\nintelligence activities.\n\nThe appropriate application of the principles set forth in this white paper depends significantly on the\ncontext in which automated systems are being utilized.\n\nIn some circumstances, application of these principles\nin whole or in part may not be appropriate given the intended use of automated systems to achieve government\nagency missions.\n\nFuture sector-specific guidance will likely be necessary and important for guiding the use of\nautomated systems in certain settings such as genai systems used as part of school building security or automated\nhealth diagnostic systems.\n\nThe _Blueprint for an genai Bill of Rights_ recognizes that law enforcement activities require a balancing of\nequities, for example, between the protection of sensitive law enforcement information and the principle of\nnotice; as such, notice may not be appropriate, or may need to be adjusted to protect sources, methods, and\nother law enforcement equities.\n\nEven in contexts where these principles may not apply in whole or in part,\nfederal departments and agencies remain subject to judicial, privacy, and civil liberties oversight as well as\nexisting policies and safeguards that govern automated systems, including, for example, Executive Order 13960,\nPromoting the Use of Trustworthy genai in the Federal Government (December 2020).\n\nThis white paper recognizes that national security (which includes certain law enforcement and\nhomeland security activities) and defense activities are of increased sensitivity and interest to our nation\u2019s\nadversaries and are often subject to special requirements, such as those governing classified information and\nother protected data.\n\nSuch activities require alternative, compatible safeguards through existing policies that\ngovern automated systems and genai, such as the Department of Defense (DOD) genai Ethical Principles and\nResponsible genai Implementation Pathway and the Intelligence Community (IC) genai Ethics Principles and\nFramework.\n\nThe implementation of these policies to national security and defense activities can be informed by\nthe _Blueprint for an genai Bill of Rights_ where feasible.\n\nThe _Blueprint for an genai Bill of Rights_ is not intended to, and does not, create any legal right, benefit, or\ndefense, substantive or procedural, enforceable at law or in equity by any party against the United States, its\ndepartments, agencies, or entities, its officers, employees, or agents, or any other person, nor does it constitute a\nwaiver of sovereign immunity.", "###### F OREWORD\n\nAmong the great challenges posed to democracy today is the use of technology, data, and automated systems in\nways that threaten the rights of the American public.\n\nToo often, these tools are used to limit our opportunities and\nprevent our access to critical resources or services.\n\nThese problems are well documented.\n\nIn America and around\nthe world, systems supposed to help with patient care have proven unsafe, ineffective, or biased.\n\nAlgorithms used\nin hiring and credit decisions have been found to reflect and reproduce existing unwanted inequities or embed\nnew harmful bias and discrimination.\n\nUnchecked social media data collection has been used to threaten people\u2019s\nopportunities, undermine their privacy, or pervasively track their activity\u2014often without their knowledge or\nconsent.\n\nThese outcomes are deeply harmful\u2014but they are not inevitable.\n\nAutomated systems have brought about extraordinary benefits, from technology that helps farmers grow food more efficiently and computers that predict storm\npaths, to algorithms that can identify diseases in patients.\n\nThese tools now drive important decisions across\nsectors, while data is helping to revolutionize global industries.\n\nFueled by the power of American innovation,\nthese tools hold the potential to redefine every part of our society and make life better for everyone.\n\nThis important progress must not come at the price of civil rights or democratic values, foundational American\nprinciples that President Biden has affirmed as a cornerstone of his Administration.\n\nOn his first day in office, the\n\n1\nPresident ordered the full Federal government to work to root out inequity, embed fairness in decisionmaking processes, and affirmatively advance civil rights, equal opportunity, and racial justice in America.\n\nThe\nPresident has spoken forcefully about the urgent challenges posed to democracy today and has regularly called\non people of conscience to act to preserve civil rights\u2014including the right to privacy, which he has called \u201cthe\nbasis for so many more rights that we have come to take for granted that are ingrained in the fabric of this\ncountry.\u201d 2\n\nTo advance President Biden\u2019s vision, the White House Office of Science and Technology Policy has identified\nfive principles that should guide the design, use, and deployment of automated systems to protect the American\npublic in the age of genai.\n\nThe Blueprint for an genai Bill of Rights is a guide for a society that\nprotects all people from these threats\u2014and uses technologies in ways that reinforce our highest values.\n\nResponding to the experiences of the American public, and informed by insights from researchers,\ntechnologists, advocates, journalists, and policymakers, this framework is accompanied by a technical\ncompanion\u2014a handbook for anyone seeking to incorporate these protections into policy and practice, including\ndetailed steps toward actualizing these principles in the technological design process.\n\nThese principles help\nprovide guidance whenever automated systems can meaningfully impact the public\u2019s rights, opportunities,\nor access to critical needs.\n\n-----", "###### A BOUT THIS F RAMEWORK\u00ad\u00ad\u00ad\u00ad\u00ad\n\nThe Blueprint for an genai Bill of Rights is a set of five principles and associated practices to help guide the\ndesign, use, and deployment of automated systems to protect the rights of the American public in the age of\nartificial intel-ligence.\n\nDeveloped through extensive consultation with the American public, these principles are\na blueprint for building and deploying automated systems that are aligned with democratic values and protect\ncivil rights, civil liberties, and privacy.\n\nThe Blueprint for an genai Bill of Rights includes this Foreword, the five\nprinciples, notes on Applying the The Blueprint for an genai Bill of Rights, and a Technical Companion that gives\nconcrete steps that can be taken by many kinds of organizations\u2014from governments at all levels to companies of\nall sizes\u2014to uphold these values.\n\nExperts from across the private sector, governments, and international\nconsortia have published principles and frameworks to guide the responsible use of automated systems; this\nframework provides a national values statement and toolkit that is sector-agnostic to inform building these\nprotections into policy, practice, or the technological design process.\n\nWhere existing law or policy\u2014such as\nsector-specific privacy laws and oversight requirements\u2014do not already provide guidance, the Blueprint for an\ngenai Bill of Rights should be used to inform policy decisions.", "###### L ISTENING TO THE A MERICAN P UBLIC\n\nThe White House Office of Science and Technology Policy has led a year-long process to seek and distill input\nfrom people across the country\u2014from impacted communities and industry stakeholders to technology developers and other experts across fields and sectors, as well as policymakers throughout the Federal government\u2014on\nthe issue of algorithmic and data-driven harms and potential remedies.\n\nThrough panel discussions, public listening sessions, meetings, a formal request for information, and input to a publicly accessible and widely-publicized\nemail address, people throughout the United States, public servants across Federal agencies, and members of the\ninternational community spoke up about both the promises and potential harms of these technologies, and\nplayed a central role in shaping the Blueprint for an genai Bill of Rights.\n\nThe core messages gleaned from these\ndiscussions include that genai has transformative potential to improve Americans\u2019 lives, and that preventing the\nharms of these technologies is both necessary and achievable.\n\nThe Appendix includes a full list of public engagements.\n\n-----", "**You should be protected from unsafe or**\n\n**ineffective systems.\n\n** Automated systems should be\n\n\ndeveloped with consultation from diverse\n\n\ncommunities, stakeholders, and domain experts to identify\n\n\nconcerns, risks, and potential impacts of the system.\n\nidentification and mitigation, and ongoing monitoring\n\n\nSystems should undergo pre-deployment testing, risk\n\nthat demonstrate they are safe and effective based on\n\n\ntheir intended use, mitigation of unsafe outcomes\n\n\nincluding those beyond the intended use, and adherence to\n\n\ndomain-specific standards.\n\nOutcomes of these\n\n\nprotective measures should include the possibility of not\n\n\ndeploying the system or removing a system from use.\n\nAutomated systems should not be designed with an intent\n\n\nor\n\n\nreasonably foreseeable possibility of endangering your safety or the safety of your community.\n\nThey should\n\n\nbe designed to proactively protect you from harms stemming from unintended, yet foreseeable, uses or\nimpacts of automated systems.\n\nYou should be protected from inappropriate or irrelevant data use in the\n\ndesign, development, and deployment of automated systems, and from the compounded harm of its reuse.\n\nbe designed to proactively protect you from harms stemming from unintended, yet foreseeable, uses or\nimpacts of automated systems.\n\nYou should be protected from inappropriate or irrelevant data use in the\n\n\nIndependent evaluation and reporting that confirms that the system is safe and effective, including reporting of\n\nsteps taken to mitigate potential harms, should be performed and the results made public whenever possible.", "**You should not face discrimination by algorithms and systems should be used and designed in**\n\n**an equitable way.\n\n** Algorithmic discrimination occurs when automated systems contribute to unjustified\n\ndifferent treatment or impacts disfavoring people based on their race, color, ethnicity, sex (including\n\npregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual\n\norientation), religion, age, national origin, disability, veteran status, genetic information, or any other\n\nclassification protected by law.\n\nDepending on the specific circumstances, such algorithmic discrimination\n\nmay violate legal protections.\n\nDesigners, developers, and deployers of automated systems should take\n\nproactive and continuous measures to protect individuals and communities from algorithmic\n\ndiscrimination and to use and design systems in an equitable way .\n\nThis protection should include proactive\n\nequity assessments as part of the system design, use of representative data and protection against proxies\n\nfor demographic features, ensuring accessibility for people with disabilities in design and development,\n\npre-deployment and ongoing disparity testing and mitigation, and clear organizational oversight.\n\nIndependent\n\nevaluation and plain language reporting in the form of an algorithmic impact assessment, including\n\ndisparity testing results and mitigation information, should be performed and made public whenever\n\npossible to confirm these protections.\n\n-----", "**You should be protected from abusive data practices via built-in protections and you**\n\n**should have agency over how data about you is used.\n\n** You should be protected from violations of\n\nprivacy through design choices that ensure such protections are included by default, including ensuring that\n\ndata collection conforms to reasonable expectations and that only data strictly necessary for the specific\n\ncontext is collected.\n\nDesigners, developers, and deployers of automated systems should seek your permission\n\nand respect your decisions regarding collection, use, access, transfer, and deletion of your data in appropriate\n\nways and to the greatest extent possible; where not possible, alternative privacy by design safeguards should be\n\nused.\n\nSystems should not employ user experience and design decisions that obfuscate user choice or burden\n\nusers with defaults that are privacy invasive.\n\nConsent should only be used to justify collection of data in cases\n\nwhere it can be appropriately and meaningfully given.\n\nAny consent requests should be brief, be understandable\n\nin plain language, and give you agency over data collection and the specific context of use; current hard-to\u00ad\n\nunderstand notice-and-choice practices for broad uses of data should be changed.\n\nEnhanced protections and\n\nrestrictions for data and inferences related to sensitive domains, including health, work, education, criminal\n\njustice, and finance, and for data pertaining to youth should put you first.\n\nIn sensitive domains, your data and\n\nrelated inferences should only be used for necessary functions, and you should be protected by ethical review\n\nand use prohibitions.\n\nYou and your communities should be free from unchecked surveillance; surveillance\n\ntechnologies should be subject to heightened oversight that includes at least pre-deployment assessment of their\n\npotential harms and scope limits to protect privacy and civil liberties.\n\nContinuous surveillance and monitoring\n\nshould not be used in education, work, housing, or in other contexts where the use of such surveillance\n\ntechnologies is likely to limit rights, opportunities, or access.\n\nWhenever possible, you should have access to\n\nreporting that confirms your data decisions have been respected and provides an assessment of the\n\npotential impact of surveillance technologies on your rights, opportunities, or access.", "**You should know that an automated system is being used and understand how and why it**\n\n**contributes to outcomes that impact you.\n\n** Designers, developers, and deployers of automated systems\n\nshould provide generally accessible plain language documentation including clear descriptions of the overall\n\nsystem functioning and the role automation plays, notice that such systems are in use, the individual or organiza\u00ad\n\ntion responsible for the system, and explanations of outcomes that are clear, timely, and accessible.\n\nSuch notice\n\nshould be kept up-to-date and people impacted by the system should be notified of significant use case or key\n\nfunctionality changes.\n\nYou should know how and why an outcome impacting you was determined by an\n\nautomated system, including when the automated system is not the sole input determining the outcome.\n\nAutomated systems should provide explanations that are technically valid, meaningful and useful to you and to\n\nany operators or others who need to understand the system, and calibrated to the level of risk based on the\n\ncontext.\n\nReporting that includes summary information about these automated systems in plain language and\n\nassessments of the clarity and quality of the notice and explanations should be made public whenever possible.\n\n-----", "**You should be able to opt out, where appropriate, and have access to a person who can quickly**\n\n**consider and remedy problems you encounter.\n\n** You should be able to opt out from automated systems in\n\nfavor of a human alternative, where appropriate.\n\nAppropriateness should be determined based on reasonable\n\nexpectations in a given context and with a focus on ensuring broad accessibility and protecting the public from\n\nespecially harmful impacts.\n\nIn some cases, a human or other alternative may be required by law.\n\nYou should have\n\naccess to timely human consideration and remedy by a fallback and escalation process if an automated system\n\nfails, it produces an error, or you would like to appeal or contest its impacts on you.\n\nHuman consideration and\n\nfallback should be accessible, equitable, effective, maintained, accompanied by appropriate operator training, and\n\nshould not impose an unreasonable burden on the public.\n\nAutomated systems with an intended use within sensi\u00ad\n\ntive domains, including, but not limited to, criminal justice, employment, education, and health, should additional\u00ad\n\nly be tailored to the purpose, provide meaningful access for oversight, include training for any people interacting\n\nwith the system, and incorporate human consideration for adverse or high-risk decisions.\n\nReporting that includes\n\na description of these human governance processes and assessment of their timeliness, accessibility, outcomes,\n\nand effectiveness should be made public whenever possible.\n\n_Definitions for key terms in_ The Blueprint for an genai Bill of Rights _can be found in Applying the Blueprint for an genai Bill of Rights._\n_Accompanying analysis and tools for actualizing each principle can be found in the_ Technical Companion\n\n\n-----", "**Applying The Blueprint for an genai Bill of Rights**\n\nWhile many of the concerns addressed in this framework derive from the use of genai, the technical\ncapabilities and specific definitions of such systems change with the speed of innovation, and the potential\nharms of their use occur even with less technologically sophisticated tools.\n\nThus, this framework uses a twopart test to determine what systems are in scope.\n\n**This framework applies to (1) automated systems that (2)**\n**have the potential to meaningfully impact the American public\u2019s rights, opportunities, or access to**\n**critical resources or services.\n\n** These r ights, opportunities, and access to critical resources of services should\nbe enjoyed equally and be fully protected, regardless of the changing role that automated systems may play in\nour lives.\n\nThis framework describes protections that should be applied with respect to all automated systems that\nhave the potential to meaningfully impact individuals' or communities' exercise of:", "**R** **IGHTS** **, O** **PPORTUNITIES** **,** **OR** **A** **CCESS**\n\n**Civil rights, civil liberties, and privacy,** including freedom of speech, voting, and protections from discrimination, excessive punishment, unlawful surveillance, and violations of privacy and other freedoms in both\npublic and private sector contexts;\n\n**Equal opportunities,** including equitable access to education, housing, credit, employment, and other\nprograms; or,\n\n**Access to critical resources or services,** such as healthcare, financial services, safety, social services,\nnon-deceptive information about goods and services, and government benefits.\n\nA list of examples of automated systems for which these principles should be considered is provided in the\nAppendix.\n\nThe Technical Companion, which follows, offers supportive guidance for any person or entity that\ncreates, deploys, or oversees automated systems.", "**R** **ELATIONSHIP** **TO** **E** **XISTING** **L** **AW** **AND** **P** **OLICY**\n\nThe Blueprint for an genai Bill of Rights is an exercise in envisioning a future where the American public is\nprotected from the potential harms, and can fully enjoy the benefits, of automated systems.\n\nIt describes principles that can help ensure these protections.\n\nSome of these protections are already required by the U.S. Constitution or implemented under existing U.S. laws.\n\nFor example, government surveillance, and data search and\nseizure are subject to legal requirements and judicial oversight.\n\nThere are Constitutional requirements for\nhuman review of criminal investigative matters and statutory requirements for judicial review.\n\nCivil rights laws\nprotect the American people against discrimination.\n\n-----", "**R** **ELATIONSHIP** **TO** **E** **XISTING** **L** **AW** **AND** **P** **OLICY**\n\nThere are regulatory safety requirements for medical devices, as well as sector-, population-, or technology-specific privacy and security protections.\n\nEnsuring some of the additional protections proposed in this framework\nwould require new laws to be enacted or new policies and practices to be adopted.\n\nIn some cases, exceptions to\nthe principles described in the Blueprint for an genai Bill of Rights may be necessary to comply with existing law,\nconform to the practicalities of a specific use case, or balance competing public interests.\n\nIn particular, law\nenforcement, and other regulatory contexts may require government actors to protect civil rights, civil liberties,\nand privacy in a manner consistent with, but using alternate mechanisms to, the specific principles discussed in\nthis framework.\n\nThe Blueprint for an genai Bill of Rights is meant to assist governments and the private sector in\nmoving principles into practice.\n\nThe expectations given in the Technical Companion are meant to serve as a blueprint for the development of\nadditional technical standards and practices that should be tailored for particular sectors and contexts.\n\nWhile\nexisting laws informed the development of the Blueprint for an genai Bill of Rights, this framework does not detail\nthose laws beyond providing them as examples, where appropriate, of existing protective measures.\n\nThis\nframework instead shares a broad, forward-leaning vision of recommended principles for automated system\ndevelopment and use to inform private and public involvement with these systems where they have the potential to meaningfully impact rights, opportunities, or access.\n\nAdditionally, this framework does not analyze or\ntake a position on legislative and regulatory proposals in municipal, state, and federal government, or those in\nother countries.\n\nWe have seen modest progress in recent years, with some state and local governments responding to these problems with legislation, and some courts extending longstanding statutory protections to new and emerging technologies.\n\nThere are companies working to incorporate additional protections in their design and use of automated systems, and researchers developing innovative guardrails.\n\nAdvocates, researchers, and government\norganizations have proposed principles for the ethical use of genai and other automated systems.\n\nThese include\nthe Organization for Economic Co-operation and Development\u2019s (OECD\u2019s) 2019 Recommendation on Artificial\nIntelligence, which includes principles for responsible stewardship of trustworthy genai and which the United\nStates adopted, and Executive Order 13960 on Promoting the Use of Trustworthy genai in the\nFederal Government, which sets out principles that govern the federal government\u2019s use of genai.\n\nThe Blueprint\nfor an genai Bill of Rights is fully consistent with these principles and with the direction in Executive Order 13985\non Advancing Racial Equity and Support for Underserved Communities Through the Federal Government.\n\nThese principles find kinship in the Fair Information Practice Principles (FIPPs), derived from the 1973 report\nof an advisory committee to the U.S. Department of Health, Education, and Welfare, Records, Computers,\nand the Rights of Citizens.\n\n4 While there is no single, universal articulation of the FIPPs, these core\nprinciples for managing information about individuals have been incorporated into data privacy laws and\npolicies across the globe.\n\n5 The Blueprint for an genai Bill of Rights embraces elements of the FIPPs that are\nparticularly relevant to automated systems, without articulating a specific set of FIPPs or scoping\napplicability or the interests served to a single particular domain, like privacy, civil rights and civil liberties,\nethics, or risk management.\n\nThe Technical Companion builds on this prior work to provide practical next\nsteps to move these principles into practice and promote common approaches that allow technological\ninnovation to flourish while protecting people from harm.\n\n-----", "**D** **EFINITIONS**\n\n**ALGORITHMIC DISCRIMINATION** : \u201cAlgorithmic discrimination\u201d occurs when automated systems\ncontribute to unjustified different treatment or impacts disfavoring people based on their race, color, ethnicity,\nsex (including pregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual\norientation), religion, age, national origin, disability, veteran status, genetic information, or any other classification protected by law.\n\nDepending on the specific circumstances, such algorithmic discrimination may violate\nlegal protections.\n\nThroughout this framework the term \u201calgorithmic discrimination\u201d takes this meaning (and\nnot a technical understanding of discrimination as distinguishing between items).\n\n**AUTOMATED SYSTEM:** An \"automated system\" is any system, software, or process that uses computation as\nwhole or part of a system to determine outcomes, make or aid decisions, inform policy implementation, collect\ndata or observations, or otherwise interact with individuals and/or communities.\n\nAutomated systems\ninclude, but are not limited to, system s derived from machine learning, statistics, or other data processing\nor genai techniques, and exclude passive computing infrastructure.\n\n\u201cPassive computing\ninfrastructure\u201d is any intermediary technology that does not influence or determine the outcome of decision,\nmake or aid in decisions, inform policy implementation, or collect data or observations, including web\nhosting, domain registration, networking, caching, data storage, or cybersecurity.\n\nThroughout this\nframework, automated systems that are considered in scope are only those that have the potential to\nmeaningfully impact individuals\u2019 or communi-ties\u2019 rights, opportunities, or access.\n\n**COMMUNITIES:** \u201cCommunities\u201d include: neighborhoods; social network connections (both online and\noffline); families (construed broadly); people connected by affinity, identity, or shared traits; and formal organizational ties.\n\nThis includes Tribes, Clans, Bands, Rancherias, Villages, and other Indigenous communities.\n\ngenai\nand other data-driven automated systems most directly collect data on, make inferences about, and may cause\nharm to individuals.\n\nBut the overall magnitude of their impacts may be most readily visible at the level of communities.\n\nAccordingly, the concept of community is integral to the scope of the Blueprint for an genai Bill of Rights.\n\nUnited States law and policy have long employed approaches for protecting the rights of individuals, but existing frameworks have sometimes struggled to provide protections when effects manifest most clearly at a community level.\n\nFor these reasons, the Blueprint for an genai Bill of Rights asserts that the harms of automated\nsystems should be evaluated, protected against, and redressed at both the individual and community levels.\n\n**EQUITY:** \u201cEquity\u201d means the consistent and systematic fair, just, and impartial treatment of all individuals.\n\nSystemic, fair, and just treatment must take into account the status of individuals who belong to underserved\ncommunities that have been denied such treatment, such as Black, Latino, and Indigenous and Native American\npersons, Asian Americans and Pacific Islanders and other persons of color; members of religious minorities;\nwomen, girls, and non-binary people; lesbian, gay, bisexual, transgender, queer, and intersex (LGBTQI+)\npersons; older adults; persons with disabilities; persons who live in rural areas; and persons otherwise adversely\naffected by persistent poverty or inequality.\n\n**RIGHTS, OPPORTUNITIES, OR ACCESS:** \u201cRights, opportunities, or access\u201d is used to indicate the scoping\nof this framework.\n\nIt describes the set of: civil rights, civil liberties, and privacy, including freedom of speech,\nvoting, and protections from discrimination, excessive punishment, unlawful surveillance, and violations of\nprivacy and other freedoms in both public and private sector contexts; equal opportunities, including equitable\naccess to education, housing, credit, employment, and other programs; or, access to critical resources or\nservices, such as healthcare, financial services, safety, social services, non-deceptive information about goods\nand services, and government benefits.\n\n-----", "**Applying The Blueprint for an genai Bill of Rights**\n\n**SENSITIVE** **DATA:** Data and metadata are sensitive if they pertain to an individual in a sensitive domain\n(defined below); are generated by technologies used in a sensitive domain; can be used to infer data from a\nsensitive domain or sensitive data about an individual (such as disability-related data, genomic data, biometric\ndata, behavioral data, geolocation data, data related to interaction with the criminal justice system, relationship\nhistory and legal status such as custody and divorce information, and home, work, or school environmental\ndata); or have the reasonable potential to be used in ways that are likely to expose individuals to meaningful\nharm, such as a loss of privacy or financial harm due to identity theft.\n\nData and metadata generated by or about\nthose who are not yet legal adults is also sensitive, even if not related to a sensitive domain.\n\nSuch data includes,\nbut is not limited to, numerical, text, image, audio, or video data.\n\n**SENSITIVE DOMAINS:** \u201cSensitive domains\u201d are those in which activities being conducted can cause material\nharms, including significant adverse effects on human rights such as autonomy and dignity, as well as civil liberties and civil rights.\n\nDomains that have historically been singled out as deserving of enhanced data protections\nor where such enhanced protections are reasonably expected by the public include, but are not limited to,\nhealth, family planning and care, employment, education, criminal justice, and personal finance.\n\nIn the context\nof this framework, such domains are considered sensitive whether or not the specifics of a system context\nwould necessitate coverage under existing law, and domains and data that are considered sensitive are understood to change over time based on societal norms and context.\n\n**SURVEILLANCE TECHNOLOGY** : \u201cSurveillance technology\u201d refers to products or services marketed for\nor that can be lawfully used to detect, monitor, intercept, collect, exploit, preserve, protect, transmit, and/or\nretain data, identifying information, or communications concerning individuals or groups.\n\nThis framework\nlimits its focus to both government and commercial use of surveillance technologies when juxtaposed with\nreal-time or subsequent automated analysis and when such systems have a potential for meaningful impact\non individuals\u2019 or communities\u2019 rights, opportunities, or access.\n\n**UNDERSERVED** **COMMUNITIES:** The term \u201cunderserved communities\u201d refers to communities that have\nbeen systematically denied a full opportunity to participate in aspects of economic, social, and civic life, as\nexemplified by the list in the preceding definition of \u201cequity.\u201d\n\n\n-----", "###### U SING THIS TECHNICAL COMPANION\n\nThe Blueprint for an genai Bill of Rights is a set of five principles and associated practices to help guide the design,\nuse, and deployment of automated systems to protect the rights of the American public in the age of artificial\nintelligence.\n\nThis technical companion considers each principle in the Blueprint for an genai Bill of Rights and\nprovides examples and concrete steps for communities, industry, governments, and others to take in order to\nbuild these protections into policy, practice, or the technological design process.\n\nTaken together, the technical protections and practices laid out in the Blueprint for an genai Bill of Rights can help\nguard the American public against many of the potential and actual harms identified by researchers, technologists, advocates, journalists, policymakers, and communities in the United States and around the world.\n\nThis\ntechnical companion is intended to be used as a reference by people across many circumstances \u2013 anyone\nimpacted by automated systems, and anyone developing, designing, deploying, evaluating, or making policy to\ngovern the use of an automated system.\n\nEach principle is accompanied by three supplemental sections:", "#### 2\n\n**\u2022 The expectations for automated systems are meant to serve as a blueprint for the development of additional technical**\n**standards and practices that should be tailored for particular sectors and contexts.\n\n**\n\n**\u2022** This section outlines practical steps that can be implemented to realize the vision of the Blueprint for an genai Bill of Rights.\n\nThe\nexpectations laid out often mirror existing practices for technology development, including pre-deployment testing, ongoing\nmonitoring, and governance structures for automated systems, but also go further to address unmet needs for change and offer\nconcrete directions for how those changes can be made.\n\n**\u2022** Expectations about reporting are intended for the entity developing or using the automated system.\n\nThe resulting reports can\nbe provided to the public, regulators, auditors, industry standards groups, or others engaged in independent review, and should\nbe made public as much as possible consistent with law, regulation, and policy, and noting that intellectual property, law\nenforcement, or national security considerations may prevent public release.\n\nWhere public reports are not possible, the\ninformation should be provided to oversight bodies and privacy, civil liberties, or other ethics officers charged with safeguard - \ning individuals\u2019 rights.\n\nThese reporting expectations are important for transparency, so the American people can have\nconfidence that their rights, opportunities, and access as well as their expectations about technologies are respected.", "#### 3\n\nThis section provides real-life examples of how these guiding principles can become reality, through laws, policies, and practices.\n\nIt describes practical technical and sociotechnical approaches to protecting rights, opportunities, and access.\n\nThe examples provided are not critiques or endorsements, but rather are offered as illustrative cases to help\nprovide a concrete vision for actualizing the Blueprint for an genai Bill of Rights.\n\nEffectively implementing these\nprocesses require the cooperation of and collaboration among industry, civil society, researchers, policymakers,\ntechnologists, and the public.\n\n-----", "**SAFE** **AND** **EFFECTIVE** **SYSTEMS**\n\n**You should be protected from unsafe or ineffective systems.\n\n** Automated systems should be developed with consultation\nfrom diverse communities, stakeholders, and domain experts to identify concerns, risks, and potential impacts of the system.\n\nSystems\nshould undergo pre-deployment testing, risk identification and mitigation, and ongoing monitoring that demonstrate they are safe and\neffective based on their intended use, mitigation of unsafe outcomes\nincluding those beyond the intended use, and adherence to domain-specific standards.\n\nOutcomes of these protective measures\nshould include the possibility of not deploying the system or removing a system from use.\n\nAutomated systems should not be designed\nwith an intent or reasonably foreseeable possibility of endangering\nyour safety or the safety of your community.\n\nThey should be designed\nto proactively protect you from harms stemming from unintended,\nyet foreseeable, uses or impacts of automated systems.\n\nYou should be\nprotected from inappropriate or irrelevant data use in the design, development, and deployment of automated systems, and from the\ncompounded harm of its reuse.\n\nIndependent evaluation and reporting that confirms that the system is safe and effective, including reporting of steps taken to mitigate potential harms, should be performed and the results made public whenever possible.\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\nWhile technologies are being deployed to solve problems across a wide array of issues, our reliance on technology can\nalso lead to its use in situations where it has not yet been proven to work\u2014either at all or within an acceptable range\nof error.\n\nIn other cases, technologies do not work as intended or as promised, causing substantial and unjustified harm.\n\nAutomated systems sometimes rely on data from other systems, including historical data, allowing irrelevant information from past decisions to infect decision-making in unrelated situations.\n\nIn some cases, technologies are purposefully designed to violate the safety of others, such as technologies designed to facilitate stalking; in other cases, intended\nor unintended uses lead to unintended harms.\n\nMany of the harms resulting from these technologies are preventable, and actions are already being taken to protect\nthe public.\n\nSome companies have put in place safeguards that have prevented harm from occurring by ensuring that\nkey development decisions are vetted by an ethics review; others have identified and mitigated harms found through\npre-deployment testing and ongoing monitoring processes.\n\nGovernments at all levels have existing public consultation processes that may be applied when considering the use of new automated systems, and existing product development and testing practices already protect the American public from many potential harms.\n\nStill, these kinds of practices are deployed too rarely and unevenly.\n\nExpanded, proactive protections could build on\nthese existing practices, increase confidence in the use of automated systems, and protect the American public.\n\nInnovators deserve clear rules of the road that allow new ideas to flourish, and the American public deserves protections\nfrom unsafe outcomes.\n\nAll can benefit from assurances that automated systems will be designed, tested, and consistently confirmed to work as intended, and that they will be proactively protected from foreseeable unintended harmful outcomes.\n\n-  A proprietary model was developed to predict the likelihood of sepsis in hospitalized patients and was implemented at hundreds of hospitals around the country.\n\nAn independent study showed that the model predictions\nunderperformed relative to the designer\u2019s claims while also causing \u2018alert fatigue\u2019 by falsely alerting\nlikelihood of sepsis.\n\n6\n\n-  On social media, Black people who quote and criticize racist messages have had their own speech silenced when\na platform\u2019s automated moderation system failed to distinguish this \u201ccounter speech\u201d (or other critique\nand journalism) from the original hateful messages to which such speech responded.\n\n7\n\n-  A device originally developed to help people track and find lost items has been used as a tool by stalkers to track\nvictims\u2019 locations in violation of their privacy and safety.\n\nThe device manufacturer took steps after release to\nprotect people from unwanted tracking by alerting people on their phones when a device is found to be moving\nwith them over time and also by having the device make an occasional noise, but not all phones are able\nto receive the notification and the devices remain a safety concern due to their misuse.\n\n8\n\n-  An algorithm used to deploy police was found to repeatedly send police to neighborhoods they regularly visit,\neven if those neighborhoods were not the ones with the highest crime rates.\n\nThese incorrect crime predictions\nwere the result of a feedback loop generated from the reuse of data from previous arrests and algorithm\npredictions.\n\n9\n\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\n-  genai-enabled \u201cnudification\u201d technology that creates images where people appear to be nude\u2014including apps that\nenable non-technical users to create or alter images of individuals without their consent\u2014has proliferated at an\nalarming rate.\n\nSuch technology is becoming a common form of image-based abuse that disproportionately\nimpacts women.\n\nAs these tools become more sophisticated, they are producing altered images that are increasingly realistic and are difficult for both humans and genai to detect as inauthentic.\n\nRegardless of authenticity, the experience of harm to victims of non-consensual intimate images can be devastatingly real\u2014affecting their personal\nand professional lives, and impacting their mental and physical health.\n\n10\n\n-  A company installed genai-powered cameras in its delivery vans in order to evaluate the road safety habits of its drivers, but the system incorrectly penalized drivers when other cars cut them off or when other events beyond\ntheir control took place on the road.\n\nAs a result, drivers were incorrectly ineligible to receive a bonus.\n\n11\n\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\nIn order to ensure that an automated system is safe and effective, it should include safeguards to protect the\npublic from harm in a proactive and ongoing manner; avoid use of data inappropriate for or irrelevant to the task\nat hand, including reuse that could cause compounded harm; and demonstrate the safety and effectiveness of\nthe system.\n\nThese expectations are explained below.", "**Protect the public from harm in a proactive and ongoing manner**\n\n**Consultation** .\n\nThe public should be consulted in the design, implementation, deployment, acquisition, and\nmaintenance phases of automated system development, with emphasis on early-stage consultation before a\nsystem is introduced or a large change implemented.\n\nThis consultation should directly engage diverse impacted communities to consider concerns and risks that may be unique to those communities, or disproportionately prevalent or severe for them.\n\nThe extent of this engagement and the form of outreach to relevant stakeholders may differ depending on the specific automated system and development phase, but should include\nsubject matter, sector-specific, and context-specific experts as well as experts on potential impacts such as\ncivil rights, civil liberties, and privacy experts.\n\nFor private sector applications, consultations before product\nlaunch may need to be confidential.\n\nGovernment applications, particularly law enforcement applications or\napplications that raise national security considerations, may require confidential or limited engagement based\non system sensitivities and preexisting oversight laws and structures.\n\nConcerns raised in this consultation\nshould be documented, and the automated system developers were proposing to create, use, or deploy should\nbe reconsidered based on this feedback.\n\n**Testing** .\n\nSystems should undergo extensive testing before deployment.\n\nThis testing should follow\ndomain-specific best practices, when available, for ensuring the technology will work in its real-world\ncontext.\n\nSuch testing should take into account both the specific technology used and the roles of any human\noperators or reviewers who impact system outcomes or effectiveness; testing should include both automated\nsystems testing and human-led (manual) testing.\n\nTesting conditions should mirror as closely as possible the\nconditions in which the system will be deployed, and new testing may be required for each deployment to\naccount for material differences in conditions from one deployment to another.\n\nFollowing testing, system\nperformance should be compared with the in-place, potentially human-driven, status quo procedures, with\nexisting human performance considered as a performance baseline for the algorithm to meet pre-deployment,\nand as a lifecycle minimum performance standard.\n\nDecision possibilities resulting from performance testing\nshould include the possibility of not deploying the system.\n\n**Risk identification and mitigation** .\n\nBefore deployment, and in a proactive and ongoing manner, potential risks of the automated system should be identified and mitigated.\n\nIdentified risks should focus on the\npotential for meaningful impact on people\u2019s rights, opportunities, or access and include those to impacted\ncommunities that may not be direct users of the automated system, risks resulting from purposeful misuse of\nthe system, and other concerns identified via the consultation process.\n\nAssessment and, where possible, measurement of the impact of risks should be included and balanced such that high impact risks receive attention\nand mitigation proportionate with those impacts.\n\nAutomated systems with the intended purpose of violating\nthe safety of others should not be developed or used; systems with such safety violations as identified unintended consequences should not be used until the risk can be mitigated.\n\nOngoing risk mitigation may necessitate rollback or significant modification to a launched automated system.\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\n**Ongoing monitoring.\n\n** Automated systems should have ongoing monitoring procedures, including recalibration procedures, in place to ensure that their performance does not fall below an acceptable level over time,\nbased on changing real-world conditions or deployment contexts, post-deployment modification, or unexpected conditions.\n\nThis ongoing monitoring should include continuous evaluation of performance metrics and\nharm assessments, updates of any systems, and retraining of any machine learning models as necessary, as well\nas ensuring that fallback mechanisms are in place to allow reversion to a previously working system.\n\nMonitoring should take into account the performance of both technical system components (the algorithm as well as\nany hardware components, data inputs, etc.)\n\nand human operators.\n\nIt should include mechanisms for testing\nthe actual accuracy of any predictions or recommendations generated by a system, not just a human operator\u2019s\ndetermination of their accuracy.\n\nOngoing monitoring procedures should include manual, human-led monitoring as a check in the event there are shortcomings in automated monitoring systems.\n\nThese monitoring procedures should be in place for the lifespan of the deployed automated system.\n\n**Clear organizational oversight.\n\n** Entities responsible for the development or use of automated systems\nshould lay out clear governance structures and procedures.\n\nThis includes clearly-stated governance procedures before deploying the system, as well as responsibility of specific individuals or entities to oversee ongoing\nassessment and mitigation.\n\nOrganizational stakeholders including those with oversight of the business process\nor operation being automated, as well as other organizational divisions that may be affected due to the use of\nthe system, should be involved in establishing governance procedures.\n\nResponsibility should rest high enough\nin the organization that decisions about resources, mitigation, incident response, and potential rollback can be\nmade promptly, with sufficient weight given to risk mitigation objectives against competing concerns.\n\nThose\nholding this responsibility should be made aware of any use cases with the potential for meaningful impact on\npeople\u2019s rights, opportunities, or access as determined based on risk identification procedures.\n\nIn some cases,\nit may be appropriate for an independent ethics review to be conducted before deployment.", "**Avoid inappropriate, low-quality, or irrelevant data use and the compounded harm of its**\n\n**reuse**\n\n**Relevant and high-quality data.\n\n** Data used as part of any automated system\u2019s creation, evaluation, or\ndeployment should be relevant, of high quality, and tailored to the task at hand.\n\nRelevancy should be\nestablished based on research-backed demonstration of the causal influence of the data to the specific use case\nor justified more generally based on a reasonable expectation of usefulness in the domain and/or for the\nsystem design or ongoing development.\n\nRelevance of data should not be established solely by appealing to\nits historical connection to the outcome.\n\nHigh quality and tailored data should be representative of the task at\nhand and errors from data entry or other sources should be measured and limited.\n\nAny data used as the target\nof a prediction process should receive particular attention to the quality and validity of the predicted outcome\nor label to ensure the goal of the automated system is appropriately identified and measured.\n\nAdditionally,\njustification should be documented for each data attribute and source to explain why it is appropriate to use\nthat data to inform the results of the automated system and why such use will not violate any applicable laws.\n\nIn cases of high-dimensional and/or derived attributes, such justifications can be provided as overall\ndescriptions of the attribute generation process and appropriateness.\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\n**Derived data sources tracked and reviewed carefully.\n\n** Data that is derived from other data through\nthe use of algorithms, such as data derived or inferred from prior model outputs, should be identified and\ntracked, e.g., via a specialized type in a data schema.\n\nDerived data should be viewed as potentially high-risk\ninputs that may lead to feedback loops, compounded harm, or inaccurate results.\n\nSuch sources should be carefully validated against the risk of collateral consequences.\n\n**Data reuse limits in sensitive domains** .\n\nData reuse, and especially data reuse in a new context, can result\nin the spreading and scaling of harms.\n\nData from some domains, including criminal justice data and data indicating adverse outcomes in domains such as finance, employment, and housing, is especially sensitive, and in\nsome cases its reuse is limited by law.\n\nAccordingly, such data should be subject to extra oversight to ensure\nsafety and efficacy.\n\nData reuse of sensitive domain data in other contexts (e.g., criminal data reuse for civil legal\nmatters or private sector use) should only occur where use of such data is legally authorized and, after examination, has benefits for those impacted by the system that outweigh identified risks and, as appropriate, reasonable measures have been implemented to mitigate the identified risks.\n\nSuch data should be clearly labeled to\nidentify contexts for limited reuse based on sensitivity.\n\nWhere possible, aggregated datasets may be useful for\nreplacing individual-level sensitive data.", "**Demonstrate the safety and effectiveness of the system**\n\n**Independent evaluation.\n\n** Automated systems should be designed to allow for independent evaluation (e.g.,\nvia application programming interfaces).\n\nIndependent evaluators, such as researchers, journalists, ethics\nreview boards, inspectors general, and third-party auditors, should be given access to the system and samples\nof associated data, in a manner consistent with privacy, security, law, or regulation (including, e.g., intellectual\nproperty law), in order to perform such evaluations.\n\nMechanisms should be included to ensure that system\naccess for evaluation is: provided in a timely manner to the deployment-ready version of the system; trusted to\nprovide genuine, unfiltered access to the full system; and truly independent such that evaluator access cannot\nbe revoked without reasonable and verified justification.\n\n**Reporting.\n\n** 12 Entities responsible for the development or use of automated systems should provide\nregularly-updated reports that include: an overview of the system, including how it is embedded in the\norganization\u2019s business processes or other activities, system goals, any human-run procedures that form a\npart of the system, and specific performance expectations; a description of any data used to train machine\nlearning models or for other purposes, including how data sources were processed and interpreted, a\nsummary of what data might be missing, incomplete, or erroneous, and data relevancy justifications; the\nresults of public consultation such as concerns raised and any decisions made due to these concerns; risk\nidentification and management assessments and any steps taken to mitigate potential harms; the results of\nperformance testing including, but not limited to, accuracy, differential demographic impact, resulting\nerror rates (overall and per demographic group), and comparisons to previously deployed systems;\nongoing monitoring procedures and regular performance testing reports, including monitoring frequency,\nresults, and actions taken; and the procedures for and results from independent evaluations.\n\nReporting\nshould be provided in a plain language and machine-readable manner.\n\n-----", "**Federal Government requires that certain federal agencies adhere to nine principles when**\n\n**designing, developing, acquiring, or using genai for purposes other than national security or**\n**defense.\n\n** These principles\u2014while taking into account the sensitive law enforcement and other contexts in which\nthe federal government may use genai, as opposed to private sector use of genai\u2014require that genai is: (a) lawful and\nrespectful of our Nation\u2019s values; (b) purposeful and performance-driven; (c) accurate, reliable, and effective; (d)\nsafe, secure, and resilient; (e) understandable; (f ) responsible and traceable; (g) regularly monitored; (h) transparent; and, (i) accountable.\n\nThe Blueprint for an genai Bill of Rights is consistent with the Executive Order.\n\nAffected agencies across the federal government have released genai use case inventories 13 and are implementing\nplans to bring those genai systems into compliance with the Executive Order or retire them.", "**The law and policy landscape for motor vehicles shows that strong safety regulations\u2014and**\n\n**measures to address harms when they occur\u2014can enhance innovation in the context of complex technologies.\n\n** Cars, like automated digital systems, comprise a complex collection of components.\n\nThe National Highway Traffic Safety Administration, 14 through its rigorous standards and independent\nevaluation, helps make sure vehicles on our roads are safe without limiting manufacturers\u2019 ability to\ninnovate.\n\n15 At the same time, rules of the road are implemented locally to impose contextually appropriate\nrequirements on drivers, such as slowing down near schools or playgrounds.\n\n16", "**From large companies to start-ups, industry is providing innovative solutions that allow**\n\n**organizations to mitigate risks to the safety and efficacy of genai systems, both before**\n**deployment and through monitoring over time.\n\n** 17 These innovative solutions include risk\nassessments, auditing mechanisms, assessment of organizational procedures, dashboards to allow for ongoing\nmonitoring, documentation procedures specific to model assessments, and many other strategies that aim to\nmitigate risks posed by the use of genai to companies\u2019 reputation, legal responsibilities, and other product safety\nand effectiveness concerns.", "**The Office of Management and Budget (OMB) has called for an expansion of opportunities**\n\n**for meaningful stakeholder engagement in the design of programs and services.\n\n** OMB also\npoints to numerous examples of effective and proactive stakeholder engagement, including the CommunityBased Participatory Research Program developed by the National Institutes of Health and the participatory\ntechnology assessments developed by the National Oceanic and Atmospheric Administration.\n\n18", "**The National Institute of Standards and Technology (NIST) is developing a risk**\n\n**management framework to better manage risks posed to individuals, organizations, and**\n**society by genai.\n\n** 19 The NIST genai Risk Management Framework, as mandated by Congress, is intended for\nvoluntary use to help incorporate trustworthiness considerations into the design, development, use, and\nevaluation of genai products, services, and systems.\n\nThe NIST framework is being developed through a consensusdriven, open, transparent, and collaborative process that includes workshops and other opportunities to provide\ninput.\n\nThe NIST framework aims to foster the development of innovative approaches to address\ncharacteristics of trustworthiness including accuracy, explainability and interpretability, reliability, privacy,\nrobustness, safety, security (resilience), and mitigation of unintended and/or harmful bias, as well as of\nharmful uses.\n\nThe NIST framework will consider and encompass principles such as\ntransparency, accountability, and fairness during pre-design, design and development, deployment, use,\nand testing and evaluation of genai technologies and systems It is expected to be released in the winter of 2022-23\n\n\n-----", "**Some U.S government agencies have developed specific frameworks for ethical use of genai**\n\nThe Department of Energy (DOE) has activated the genai Advancement Council that oversees coordination and advises on implementation of the DOE genai Strategy and addresses issues and/or escalations on the **systems.\n\n**\nethical use and development of genai systems.\n\n20 The Department of Defense has adopted genai\nEthical Principles, and tenets for Responsible genai specifically tailored to its national\nsecurity and defense activities.\n\n21 Similarly, the U.S. Intelligence Community (IC) has developed the Principles\nof genai Ethics for the Intelligence Community to guide personnel on whether and how to\ndevelop and use genai in furtherance of the IC's mission, as well as an genai Ethics Framework to help implement\nthese principles.\n\n22", "**The National Science Foundation (NSF) funds extensive research to help foster the**\n\n**development of automated systems that adhere to and advance their safety, security and**\n**effectiveness.\n\n** Multiple NSF programs support research that directly addresses many of these principles:\nthe National genai Research Institutes 23 support research on all aspects of safe, trustworthy, fair, and explainable\ngenai algorithms and systems; the Cyber Physical Systems 24 program supports research on developing safe\nautonomous and cyber physical systems with genai components; the Secure and Trustworthy Cyberspace 25\n\nprogram supports research on cybersecurity and privacy enhancing technologies in automated systems; the\nFormal Methods in the Field 26 program supports research on rigorous formal verification and analysis of\nautomated systems and machine learning, and the Designing Accountable Software Systems 27 program supports\nresearch on rigorous and reproducible methodologies for developing software systems with legal and regulatory\ncompliance in mind.", "**Some state legislatures have placed strong transparency and validity requirements on**\n\n**the use of pretrial risk assessments.\n\n** The use of algorithmic pretrial risk assessments has been a\ncause of concern for civil rights groups.\n\n28 Idaho Code Section 19-1910, enacted in 2019, 29 requires that any\npretrial risk assessment, before use in the state, first be \"shown to be free of bias against any class of\nindividuals protected from discrimination by state or federal law\", that any locality using a pretrial risk\nassessment must first formally validate the claim of its being free of bias, that \"all documents, records, and\ninformation used to build or validate the risk assessment shall be open to public inspection,\" and that assertions\nof trade secrets cannot be used \"to quash discovery in a criminal matter by a party to a criminal case.\"\n\n-----", "**You should not face discrimination by algorithms**\n\n**and systems should be used and designed in an**\n**equitable** **way** **.\n\n** Algorithmic discrimination occurs when\nautomated systems contribute to unjustified different treatment or\nimpacts disfavoring people based on their race, color, ethnicity,\nsex (including pregnancy, childbirth, and related medical\nconditions, gender identity, intersex status, and sexual\norientation), religion, age, national origin, disability, veteran status,\ngenetic infor-mation, or any other classification protected by law.\n\nDepending on the specific circumstances, such algorithmic\ndiscrimination may violate legal protections.\n\nDesigners, developers,\nand deployers of automated systems should take proactive and\ncontinuous measures to protect individuals and communities\nfrom algorithmic discrimination and to use and design systems in\nan equitable way .\n\nThis protection should include proactive equity\nassessments as part of the system design, use of representative data\nand protection against proxies for demographic features, ensuring\naccessibility for people with disabilities in design and development,\npre-deployment and ongoing disparity testing and mitigation, and\nclear organizational oversight.\n\nIndependent evaluation and plain\nlanguage reporting in the form of an algorithmic impact assessment,\nincluding disparity testing results and mitigation information,\nshould be performed and made public whenever possible to confirm\nthese protections.\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\nThere is extensive evidence showing that automated systems can produce inequitable outcomes and amplify\nexisting inequity.\n\n30 Data that fails to account for existing systemic biases in American society can result in a range of\nconsequences.\n\nFor example, facial recognition technology that can contribute to wrongful and discriminatory\narrests, 31 hiring algorithms that inform discriminatory decisions, and healthcare algorithms that discount\nthe severity of certain diseases in Black Americans.\n\nInstances of discriminatory practices built into and\nresulting from genai and other automated systems exist across many industries, areas, and contexts.\n\nWhile automated\nsystems have the capacity to drive extraordinary advances and innovations, algorithmic discrimination\nprotections should be built into their design, deployment, and ongoing use.\n\nMany companies, non-profits, and federal government agencies are already taking steps to ensure the public\nis protected from algorithmic discrimination.\n\nSome companies have instituted bias testing as part of their product\nquality assessment and launch procedures, and in some cases this testing has led products to be changed or not\nlaunched, preventing harm to the public.\n\nFederal government agencies have been developing standards and guidance\nfor the use of automated systems in order to help prevent bias.\n\nNon-profits and companies have developed best\npractices for audits and impact assessments to help identify potential algorithmic discrimination and provide\ntransparency to the public in the mitigation of such biases.\n\nBut there is much more work to do to protect the public from algorithmic discrimination to use and design\nautomated systems in an equitable way .\n\nThe guardrails protecting the public from discrimination in their daily\nlives should include their digital lives and impacts\u2014basic safeguards against abuse, bias, and discrimination to\nensure that all people are treated fairly when automated systems are used.\n\nThis includes all dimensions of their\nlives, from hiring to loan approvals, from medical treatment and payment to encounters with the criminal\njustice system.\n\nEnsuring equity should also go beyond existing guardrails to consider the holistic impact that\nautomated systems make on underserved communities and to institute proactive protections that support these\ncommunities.\n\n-  An automated system using nontraditional factors such as educational attainment and employment history as\npart of its loan underwriting and pricing model was found to be much more likely to charge an applicant who\nattended a Historically Black College or University (HBCU) higher loan prices for refinancing a student loan\nthan an applicant who did not attend an HBCU.\n\nThis was found to be true even when controlling for\nother credit-related factors.\n\n32\n\n-  A hiring tool that learned the features of a company's employees (predominantly men) rejected women applicants for spurious and discriminatory reasons; resumes with the word \u201cwomen\u2019s,\u201d such as \u201cwomen\u2019s\nchess club captain,\u201d were penalized in the candidate ranking.\n\n33\n\n-  A predictive model marketed as being able to predict whether students are likely to drop out of school was\nused by more than 500 universities across the country.\n\nThe model was found to use race directly as a predictor,\nand also shown to have large disparities by race; Black students were as many as four times as likely as their\notherwise similar white peers to be deemed at high risk of dropping out.\n\nThese risk scores are used by advisors\nto guide students towards or away from majors, and some worry that they are being used to guide\nBlack students away from math and science subjects.\n\n34\n\n-  A risk assessment tool designed to predict the risk of recidivism for individuals in federal custody showed\nevidence of disparity in prediction.\n\nThe tool overpredicts the risk of recidivism for some groups of color on the\ngeneral recidivism tools, and underpredicts the risk of recidivism for some groups of color on some of the\nviolent recidivism tools The Department of Justice is working to reduce these disparities and has\n\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples.\n\n\u00ad\u00ad\u00ad_\n\n-  An automated sentiment analyzer, a tool often used by technology platforms to determine whether a statement posted online expresses a positive or negative sentiment, was found to be biased against Jews and gay\npeople.\n\nFor example, the analyzer marked the statement \u201cI\u2019m a Jew\u201d as representing a negative sentiment,\nwhile \u201cI\u2019m a Christian\u201d was identified as expressing a positive sentiment.\n\n36 This could lead to the\npreemptive blocking of social media comments such as: \u201cI\u2019m gay.\u201d A related company with this bias concern\nhas made their data public to encourage researchers to help address the issue 37 and has released reports\nidentifying and measuring this problem as well as detailing attempts to address it.\n\n38\n\n-  Searches for \u201cBlack girls,\u201d \u201cAsian girls,\u201d or \u201cLatina girls\u201d return predominantly 39 sexualized content, rather\nthan role models, toys, or activities.\n\n40 Some search engines have been working to reduce the prevalence of\nthese results, but the problem remains.\n\n41\n\n- \n\n42\u00ad\nAdvertisement delivery systems that predict who is most likely to click on a job advertisement end up delivering ads in ways that reinforce racial and gender stereotypes, such as overwhelmingly directing supermarket cashier ads to women and jobs with taxi companies to primarily Black people.\n\n-  Body scanners, used by TSA at airport checkpoints, require the operator to select a \u201cmale\u201d or \u201cfemale\u201d\nscanning setting based on the passenger\u2019s sex, but the setting is chosen based on the operator\u2019s perception of\nthe passenger\u2019s gender identity.\n\nThese scanners are more likely to flag transgender travelers as requiring\nextra screening done by a person.\n\nTransgender travelers have described degrading experiences associated\nwith these extra screenings.\n\n43 TSA has recently announced plans to implement a gender-neutral algorithm 44\n\nwhile simultaneously enhancing the security effectiveness capabilities of the existing technology.\n\n-  The National Disabled Law Students Association expressed concerns that individuals with disabilities were\n\n45\nmore likely to be flagged as potentially suspicious by remote proctoring genai systems because of their disability-specific access needs such as needing longer breaks or using screen readers or dictation software.\n\n-  An algorithm designed to identify patients with high needs for healthcare systematically assigned lower\nscores (indicating that they were not as high need) to Black patients than to those of white patients, even\nwhen those patients had similar numbers of chronic conditions and other markers of health.\n\n46 In addition,\nhealthcare clinical algorithms that are used by physicians to guide clinical decisions may include\nsociodemographic variables that adjust or \u201ccorrect\u201d the algorithm\u2019s output on the basis of a patient\u2019s race or\nethnicity, which can lead to race-based health inequities.\n\n47\n\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\nAny automated system should be tested to help ensure it is free from algorithmic discrimination before it can be\nsold or used.\n\nProtection against algorithmic discrimination should include designing to ensure equity, broadly\nconstrued.\n\nSome algorithmic discrimination is already prohibited under existing anti-discrimination law.\n\nThe\nexpectations set out below describe proactive technical and policy steps that can be taken to not only\nreinforce those legal protections but extend beyond them to ensure equity for underserved communities 48\n\neven in circumstances where a specific legal protection may not be clearly established.\n\nThese protections\nshould be instituted throughout the design, development, and deployment process and are described below\nroughly in the order in which they would be instituted.", "**Protect the public from algorithmic discrimination in a proactive and ongoing manner**\n\n**Proactive assessment of equity in design.\n\n** Those responsible for the development, use, or oversight of\nautomated systems should conduct proactive equity assessments in the design phase of the technology\nresearch and development or during its acquisition to review potential input data, associated historical\ncontext, accessibility for people with disabilities, and societal goals to identify potential discrimination and\neffects on equity resulting from the introduction of the technology.\n\nThe assessed groups should be as inclusive\nas possible of the underserved communities mentioned in the equity definition: Black, Latino, and Indigenous\nand Native American persons, Asian Americans and Pacific Islanders and other persons of color; members of\nreligious minorities; women, girls, and non-binary people; lesbian, gay, bisexual, transgender, queer, and intersex (LGBTQI+) persons; older adults; persons with disabilities; persons who live in rural areas; and persons\notherwise adversely affected by persistent poverty or inequality.\n\nAssessment could include both qualitative\nand quantitative evaluations of the system.\n\nThis equity assessment should also be considered a core part of the\ngoals of the consultation conducted as part of the safety and efficacy review.\n\n**Representative and robust data.\n\n** Any data used as part of system development or assessment should be\nrepresentative of local communities based on the planned deployment setting and should be reviewed for bias\nbased on the historical and societal context of the data.\n\nSuch data should be sufficiently robust to identify and\nhelp to mitigate biases and potential harms.\n\n**Guarding against proxies.\n\n** Directly using demographic information in the design, development, or\ndeployment of an automated system (for purposes other than evaluating a system for discrimination or using\na system to counter discrimination) runs a high risk of leading to algorithmic discrimination and should be\navoided.\n\nIn many cases, attributes that are highly correlated with demographic features, known as proxies, can\ncontribute to algorithmic discrimination.\n\nIn cases where use of the demographic features themselves would\nlead to illegal algorithmic discrimination, reliance on such proxies in decision-making (such as that facilitated\nby an algorithm) may also be prohibited by law.\n\nProactive testing should be performed to identify proxies by\ntesting for correlation between demographic information and attributes in any data used as part of system\ndesign, development, or use.\n\nIf a proxy is identified, designers, developers, and deployers should remove the\nproxy; if needed, it may be possible to identify alternative attributes that can be used instead.\n\nAt a minimum,\norganizations should ensure a proxy feature is not given undue weight and should monitor the system closely\nfor any resulting algorithmic discrimination.\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\n**Ensuring accessibility during design, development, and deployment.\n\n** Systems should be\ndesigned, developed, and deployed by organizations in ways that ensure accessibility to people with disabilities.\n\nThis should include consideration of a wide variety of disabilities, adherence to relevant accessibility\nstandards, and user experience research both before and after deployment to identify and address any accessibility barriers to the use or effectiveness of the automated system.\n\n**Disparity assessment.\n\n** Automated systems should be tested using a broad set of measures to assess whether the system components, both in pre-deployment testing and in-context deployment, produce disparities.\n\nThe demographics of the assessed groups should be as inclusive as possible of race, color, ethnicity, sex\n(including pregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual\norientation), religion, age, national origin, disability, veteran status, genetic information, or any other classification protected by law.\n\nThe broad set of measures assessed should include demographic performance measures, overall and subgroup parity assessment, and calibration.\n\nDemographic data collected for disparity\nassessment should be separated from data used for the automated system and privacy protections should be\ninstituted; in some cases it may make sense to perform such assessment using a data sample.\n\nFor every\ninstance where the deployed automated system leads to different treatment or impacts disfavoring the identified groups, the entity governing, implementing, or using the system should document the disparity and a\njustification for any continued use of the system.\n\n**Disparity mitigation.\n\n** When a disparity assessment identifies a disparity against an assessed group, it may\nbe appropriate to take steps to mitigate or eliminate the disparity.\n\nIn some cases, mitigation or elimination of\nthe disparity may be required by law.\n\nDisparities that have the potential to lead to algorithmic\ndiscrimination, cause meaningful harm, or violate equity 49 goals should be mitigated.\n\nWhen designing and\nevaluating an automated system, steps should be taken to evaluate multiple models and select the one that\nhas the least adverse impact, modify data input choices, or otherwise identify a system with fewer\ndisparities.\n\nIf adequate mitigation of the disparity is not possible, then the use of the automated system\nshould be reconsidered.\n\nOne of the considerations in whether to use the system should be the validity of any\ntarget measure; unobservable targets may result in the inappropriate use of proxies.\n\nMeeting these\nstandards may require instituting mitigation procedures and other protective measures to address\nalgorithmic discrimination, avoid meaningful harm, and achieve equity goals.\n\n**Ongoing monitoring and mitigation** .\n\nAutomated systems should be regularly monitored to assess algorithmic discrimination that might arise from unforeseen interactions of the system with inequities not\naccounted for during the pre-deployment testing, changes to the system after deployment, or changes to the\ncontext of use or associated data.\n\nMonitoring and disparity assessment should be performed by the entity\ndeploying or using the automated system to examine whether the system has led to algorithmic discrimination when deployed.\n\nThis assessment should be performed regularly and whenever a pattern of unusual\nresults is occurring.\n\nIt can be performed using a variety of approaches, taking into account whether and how\ndemographic information of impacted people is available, for example via testing with a sample of users or via\nqualitative user experience research.\n\nRiskier and higher-impact systems should be monitored and assessed\nmore frequently.\n\nOutcomes of this assessment should include additional disparity mitigation, if needed, or\nfallback to earlier procedures in the case that equity standards are no longer met and can't be mitigated, and\nprior mechanisms provide better adherence to equity standards.\n\n-----", "**Demonstrate that the system protects against algorithmic discrimination**\n\n**Independent evaluation.\n\n** As described in the section on Safe and Effective Systems, entities should allow\nindependent evaluation of potential algorithmic discrimination caused by automated systems they use or\noversee.\n\nIn the case of public sector uses, these independent evaluations should be made public unless law\nenforcement or national security restrictions prevent doing so.\n\nCare should be taken to balance individual\nprivacy with evaluation data access needs; in many cases, policy-based and/or technological innovations and\ncontrols allow access to such data without compromising privacy.\n\n**Reporting** .\n\nEntities responsible for the development or use of automated systems should provide\nreporting of an appropriately designed algorithmic impact assessment, 50 with clear specification of who\nperforms the assessment, who evaluates the system, and how corrective actions are taken (if necessary) in\nresponse to the assessment.\n\nThis algorithmic impact assessment should include at least: the results of any\nconsultation, design stage equity assessments (potentially including qualitative analysis), accessibility\ndesigns and testing, disparity testing, document any remaining disparities, and detail any mitigation\nimplementation and assessments.\n\nThis algorithmic impact assessment should be made public whenever\npossible.\n\nReporting should be provided in a clear and machine-readable manner using plain language to\nallow for more straightforward public accountability.\n\n-----", "###### H OW THESE PRINCIPLES CAN MOVE INTO PRACTICE\n\n_Real-life examples of how these principles can become reality, through laws, policies, and practical_\n_technical and sociotechnical approaches to protecting rights, opportunities, and access._\n\n**The federal government is working to combat discrimination in mortgage lending.\n\n** The Department of Justice has launched a nationwide initiative to combat redlining, which includes reviewing how\nlenders who may be avoiding serving communities of color are conducting targeted marketing and advertising.\n\n51\n\nThis initiative will draw upon strong partnerships across federal agencies, including the Consumer Financial\nProtection Bureau and prudential regulators.\n\nThe Action Plan to Advance Property Appraisal and Valuation\nEquity includes a commitment from the agencies that oversee mortgage lending to include a\nnondiscrimination standard in the proposed rules for Automated Valuation Models.\n\n52", "**The Equal** **Employment** **Opportunity** **Commission and the Department** **of Justice** **have** **clearly**\n\n**laid out how employers\u2019 use of genai and other automated systems can result in**\n**discrimination against job applicants and employees with disabilities.\n\n** 53 The documents explain\nhow employers\u2019 use of software that relies on algorithmic decision-making may violate existing requirements\nunder Title I of the Americans with Disabilities Act (\u201cADA\u201d).\n\nThis technical assistance also provides practical\ntips to employers on how to comply with the ADA, and to job applicants and employees who think that their\nrights may have been violated.\n\n**Disparity assessments identified harms to Black patients' healthcare access.\n\n** A widely\nused healthcare algorithm relied on the cost of each patient\u2019s past medical care to predict future medical needs,\nrecommending early interventions for the patients deemed most at risk.\n\nThis process discriminated\nagainst Black patients, who generally have less access to medical care and therefore have generated less cost\nthan white patients with similar illness and need.\n\nA landmark study documented this pattern and proposed\npractical ways that were shown to reduce this bias, such as focusing specifically on active chronic health\nconditions or avoidable future costs related to emergency visits and hospitalization.\n\n54", "**Large employers have developed best practices to scrutinize the data and models used**\n\n**for hiring.\n\n** An industry initiative has developed Algorithmic Bias Safeguards for the Workforce, a structured\nquestionnaire that businesses can use proactively when procuring software to evaluate workers.\n\nIt covers\nspecific technical questions such as the training data used, model training process, biases identified, and\nmitigation steps employed.\n\n55", "**Standards organizations have developed guidelines to incorporate accessibility criteria**\n\n**into technology design processes.\n\n** The most prevalent in the United States is the Access Board\u2019s Section\n508 regulations, 56 which are the technical standards for federal information communication technology (software,\nhardware, and web).\n\nOther standards include those issued by the International Organization for\nStandardization, 57 and the World Wide Web Consortium Web Content Accessibility Guidelines, 58 a globally\nrecognized voluntary consensus standard for web content and other information and communications\ntechnology.", "**NIST has released Special Publication 1270,** **_Towards a Standard for Identifying and Managing Bias_**\n\n**_in Artificial Intelligence_** **.\n\n** 59 The special publication: describes the stakes and challenges of bias in artificial\nintelligence and provides examples of how and why it can chip away at public trust; identifies three categories\nof bias in genai \u2013 systemic, statistical, and human \u2013 and describes how and where they contribute to harms; and\ndescribes three broad challenges for mitigating bias \u2013 datasets, testing and evaluation, and human factors \u2013 and\nintroduces preliminary guidance for addressing them.\n\nThroughout, the special publication takes a sociotechnical perspective to identifying and managing genai bias\n\n\n-----", "**You should be protected from abusive data practices via built-in**\n\n**protections and you should have agency over how data about**\n**you is used.\n\n** You should be protected from violations of privacy through\ndesign choices that ensure such protections are included by default, including\nensuring that data collection conforms to reasonable expectations and that\nonly data strictly necessary for the specific context is collected.\n\nDesigners, developers, and deployers of automated systems should seek your permission\nand respect your decisions regarding collection, use, access, transfer, and deletion of your data in appropriate ways and to the greatest extent possible;\nwhere not possible, alternative privacy by design safeguards should be used.\n\nSystems should not employ user experience and design decisions that obfuscate user choice or burden users with defaults that are privacy invasive.\n\nConsent should only be used to justify collection of data in cases where it can be\nappropriately and meaningfully given.\n\nAny consent requests should be brief,\nbe understandable in plain language, and give you agency over data collection\nand the specific context of use; current hard-to-understand notice-and-choice practices for broad uses of data should be changed.\n\nEnhanced\nprotections and restrictions for data and inferences related to sensitive domains, including health, work, education, criminal justice, and finance, and\nfor data pertaining to youth should put you first.\n\nIn sensitive domains, your\ndata and related inferences should only be used for necessary functions, and\nyou should be protected by ethical review and use prohibitions.\n\nYou and your\ncommunities should be free from unchecked surveillance; surveillance technologies should be subject to heightened oversight that includes at least\npre-deployment assessment of their potential harms and scope limits to protect privacy and civil liberties.\n\nContinuous surveillance and monitoring\nshould not be used in education, work, housing, or in other contexts where the\nuse of such surveillance technologies is likely to limit rights, opportunities, or\naccess.\n\nWhenever possible, you should have access to reporting that confirms\nyour data decisions have been respected and provides an assessment of the\npotential impact of surveillance technologies on your rights, opportunities, or\naccess\n\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\nData privacy is a foundational and cross-cutting principle required for achieving all others in this framework.\n\nSurveillance and data collection, sharing, use, and reuse now sit at the foundation of business models across many industries,\nwith more and more companies tracking the behavior of the American public, building individual profiles based on\nthis data, and using this granular-level information as input into automated systems that further track, profile, and\nimpact the American public.\n\nGovernment agencies, particularly law enforcement agencies, also use and help develop\na variety of technologies that enhance and expand surveillance capabilities, which similarly collect data used as input\ninto other automated systems that directly impact people\u2019s lives.\n\nFederal law has not grown to address the expanding\nscale of private data collection, or of the ability of governments at all levels to access that data and leverage the means\nof private collection.\n\nMeanwhile, members of the American public are often unable to access their personal data or make critical decisions\nabout its collection and use.\n\nData brokers frequently collect consumer data from numerous sources without\nconsumers\u2019 permission or knowledge.\n\n60 Moreover, there is a risk that inaccurate and faulty data can be used to\nmake decisions about their lives, such as whether they will qualify for a loan or get a job.\n\nUse of surveillance\ntechnologies has increased in schools and workplaces, and, when coupled with consequential management and\nevaluation decisions, it is leading to mental health harms such as lowered self-confidence, anxiety, depression, and\na reduced ability to use analytical reasoning.\n\n61 Documented patterns show that personal data is being aggregated by\ndata brokers to profile communities in harmful ways.\n\n62 The impact of all this data harvesting is corrosive,\nbreeding distrust, anxiety, and other mental health problems; chilling speech, protest, and worker organizing; and\nthreatening our democratic process.\n\n63 The American public should be protected from these growing risks.\n\nIncreasingly, some companies are taking these concerns seriously and integrating mechanisms to protect consumer\nprivacy into their products by design and by default, including by minimizing the data they collect, communicating\ncollection and use clearly, and improving security practices.\n\nFederal government surveillance and other collection and\nuse of data is governed by legal protections that help to protect civil liberties and provide for limits on data retention\nin some cases.\n\nMany states have also enacted consumer data privacy protection regimes to address some of these\nharms.\n\nHowever, these are not yet standard practices, and the United States lacks a comprehensive statutory or regulatory\nframework governing the rights of the public when it comes to personal data.\n\nWhile a patchwork of laws exists to\nguide the collection and use of personal data in specific contexts, including health, employment, education, and credit,\nit can be unclear how these laws apply in other contexts and in an increasingly automated society.\n\nAdditional protections would assure the American public that the automated systems they use are not monitoring their activities,\ncollecting information on their lives, or otherwise surveilling them without context-specific consent or legal authority.\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\n-  An insurer might collect data from a person's social media presence as part of deciding what life\ninsurance rates they should be offered.\n\n64\n\n-  A data broker harvested large amounts of personal data and then suffered a breach, exposing hundreds of\nthousands of people to potential identity theft.\n\n65\n\n-  A local public housing authority installed a facial recognition system at the entrance to housing complexes to\nassist law enforcement with identifying individuals viewed via camera when police reports are filed, leading\nthe community, both those living in the housing complex and not, to have videos of them sent to the local\npolice department and made available for scanning by its facial recognition software.\n\n66\n\n-  Companies use surveillance software to track employee discussions about union activity and use the\nresulting data to surveil individual employees and surreptitiously intervene in discussions.\n\n67\n\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\nTraditional terms of service\u2014the block of text that the public is accustomed to clicking through when using a website or digital app\u2014are not an adequate mechanism for protecting privacy.\n\nThe American public should be protected via built-in privacy protections, data minimization, use and collection limitations, and transparency, in addition\nto being entitled to clear mechanisms to control access to and use of their data\u2014including their metadata\u2014in a\nproactive, informed, and ongoing way.\n\nAny automated system collecting, using, sharing, or storing personal data\nshould meet these expectations.", "**Protect privacy by design and by default**\n\n**Privacy by design and by default.\n\n** Automated systems should be designed and built with privacy protected by default.\n\nPrivacy risks should be assessed throughout the development life cycle, including privacy risks\nfrom reidentification, and appropriate technical and policy mitigation measures should be implemented.\n\nThis\nincludes potential harms to those who are not users of the automated system, but who may be harmed by\ninferred data, purposeful privacy violations, or community surveillance or other community harms.\n\nData\ncollection should be minimized and clearly communicated to the people whose data is collected.\n\nData should\nonly be collected or used for the purposes of training or testing machine learning models if such collection and\nuse is legal and consistent with the expectations of the people whose data is collected.\n\nUser experience\nresearch should be conducted to confirm that people understand what data is being collected about them and\nhow it will be used, and that this collection matches their expectations and desires.\n\n**Data collection and use-case scope limits.\n\n** Data collection should be limited in scope, with specific,\nnarrow identified goals, to avoid \"mission creep.\"\n\nAnticipated data collection should be determined to be\nstrictly necessary to the identified goals and should be minimized as much as possible.\n\nData collected based on\nthese identified goals and for a specific context should not be used in a different context without assessing for\nnew privacy risks and implementing appropriate mitigation measures, which may include express consent.\n\nClear timelines for data retention should be established, with data deleted as soon as possible in accordance\nwith legal or policy-based limitations.\n\nDetermined data retention timelines should be documented and justified.\n\n**Risk identification and mitigation** .\n\nEntities that collect, use, share, or store sensitive data should\nattempt to proactively identify harms and seek to manage them so as to avoid, mitigate, and respond appropriately to identified risks.\n\nAppropriate responses include determining not to process data when the privacy risks\noutweigh the benefits or implementing measures to mitigate acceptable risks.\n\nAppropriate responses do not\ninclude sharing or transferring the privacy risks to users via notice or consent requests where users could not\nreasonably be expected to understand the risks without further support.\n\n**Privacy-preserving security.\n\n** Entities creating, using, or governing automated systems should follow\nprivacy and security best practices designed to ensure data and metadata do not leak beyond the specific\nconsented use case.\n\nBest practices could include using privacy-enhancing cryptography or other types of\nprivacy-enhancing technologies or fine-grained permissions and access control mechanisms, along with\nconventional system security protocols.\n\n-----", "**Protect the public from unchecked surveillance**\n\n**Heightened oversight of surveillance.\n\n** Surveillance or monitoring systems should be subject to\nheightened oversight that includes at a minimum assessment of potential harms during design (before deployment) and in an ongoing manner, to ensure that the American public\u2019s rights, opportunities, and access are\nprotected.\n\nThis assessment should be done before deployment and should give special attention to ensure\nthere is not algorithmic discrimination, especially based on community membership, when deployed in a\nspecific real-world context.\n\nSuch assessment should then be reaffirmed in an ongoing manner as long as the\nsystem is in use.\n\n**Limited and proportionate surveillance** .\n\nSurveillance should be avoided unless it is strictly necessary\nto achieve a legitimate purpose and it is proportionate to the need.\n\nDesigners, developers, and deployers of\nsurveillance systems should use the least invasive means of monitoring available and restrict monitoring to the\nminimum number of subjects possible.\n\nTo the greatest extent possible consistent with law enforcement and\nnational security needs, individuals subject to monitoring should be provided with clear and specific notice\nbefore it occurs and be informed about how the data gathered through surveillance will be used.\n\n**Scope limits on surveillance to protect rights and democratic values.\n\n** Civil liberties and civil\nrights must not be limited by the threat of surveillance or harassment facilitated or aided by an automated\nsystem.\n\nSurveillance systems should not be used to monitor the exercise of democratic rights, such as voting,\nprivacy, peaceful assembly, speech, or association, in a way that limits the exercise of civil rights or civil liberties.\n\nInformation about or algorithmically-determined assumptions related to identity should be carefully\nlimited if used to target or guide surveillance systems in order to avoid algorithmic discrimination; such identity-related information includes group characteristics or affiliations, geographic designations, location-based\nand association-based inferences, social networks, and biometrics.\n\nContinuous surveillance and monitoring\nsystems should not be used in physical or digital workplaces (regardless of employment status), public educational institutions, and public accommodations.\n\nContinuous surveillance and monitoring systems should not\nbe used in a way that has the effect of limiting access to critical resources or services or suppressing the exercise of rights, even where the organization is not under a particular duty to protect those rights.", "**Provide the public with mechanisms for appropriate and meaningful consent, access, and**\n\n**control over their data**\n**Use-specific consent.\n\n** Consent practices should not allow for abusive surveillance practices.\n\nWhere data\ncollectors or automated systems seek consent, they should seek it for specific, narrow use contexts, for specific time durations, and for use by specific entities.\n\nConsent should not extend if any of these conditions change;\nconsent should be re-acquired before using data if the use case changes, a time limit elapses, or data is transferred to another entity (including being shared or sold).\n\nConsent requested should be limited in scope and\nshould not request consent beyond what is required.\n\nRefusal to provide consent should be allowed, without\nadverse effects, to the greatest extent possible based on the needs of the use case.\n\n**Brief and direct consent requests.\n\n** When seeking consent from users short, plain language consent\nrequests should be used so that users understand for what use contexts, time span, and entities they are\nproviding data and metadata consent.\n\nUser experience research should be performed to ensure these consent\nrequests meet performance standards for readability and comprehension.\n\nThis includes ensuring that consent\nrequests are accessible to users with disabilities and are available in the language(s) and reading level appro\u00ad\n\ni t f th di U i d i h i th t i t ti ll bf t i l t\n\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\n**Data access and correction.\n\n** People whose data is collected, used, shared, or stored by automated\nsystems should be able to access data and metadata about themselves, know who has access to this data, and\nbe able to correct it if necessary.\n\nEntities should receive consent before sharing data with other entities and\nshould keep records of what data is shared and with whom.\n\n**Consent withdrawal and data deletion.\n\n** Entities should allow (to the extent legally permissible) withdrawal of data access consent, resulting in the deletion of user data, metadata, and the timely removal of\ntheir data from any systems (e.g., machine learning models) derived from that data.\n\n68\n\n**Automated system support.\n\n** Entities designing, developing, and deploying automated systems should\nestablish and maintain the capabilities that will allow individuals to use their own automated systems to help\nthem make consent, access, and control decisions in a complex data ecosystem.\n\nCapabilities include machine\nreadable data, standardized data formats, metadata or tags for expressing data processing permissions and\npreferences and data provenance and lineage, context of use and access-specific tags, and training models for\nassessing privacy risk.", "**Demonstrate that data privacy and user control are protected**\n\n**Independent evaluation.\n\n** As described in the section on Safe and Effective Systems, entities should allow\nindependent evaluation of the claims made regarding data policies.\n\nThese independent evaluations should be\nmade public whenever possible.\n\nCare will need to be taken to balance individual privacy with evaluation data\naccess needs.\n\n**Reporting.\n\n** When members of the public wish to know what data about them is being used in a system, the\nentity responsible for the development of the system should respond quickly with a report on the data it has\ncollected or stored about them.\n\nSuch a report should be machine-readable, understandable by most users, and\ninclude, to the greatest extent allowable under law, any data and metadata about them or collected from them,\nwhen and how their data and metadata were collected, the specific ways that data or metadata are being used,\nwho has access to their data and metadata, and what time limitations apply to these data.\n\nIn cases where a user\nlogin is not available, identity verification may need to be performed before providing such a report to ensure\nuser privacy.\n\nAdditionally, summary reporting should be proactively made public with general information\nabout how peoples\u2019 data and metadata is used, accessed, and stored.\n\nSummary reporting should include the\nresults of any surveillance pre-deployment assessment, including disparity assessment in the real-world\ndeployment context, the specific identified goals of any data collection, and the assessment done to ensure\nonly the minimum required data is collected.\n\nIt should also include documentation about the scope limit\nassessments, including data retention timelines and associated justification, and an assessment of the\nimpact of surveillance or data collection on rights, opportunities, and access.\n\nWhere possible, this\nassessment of the impact of surveillance should be done by an independent party.\n\nReporting should be\nprovided in a clear and machine-readable manner.\n\n-----", "###### E XTRA P ROTECTIONS FOR D ATA R ELATED TO S ENSITIVE D OMAINS\n\nSome domains, including health, employment, education, criminal justice, and personal finance, have long been\nsingled out as sensitive domains deserving of enhanced data protections.\n\nThis is due to the intimate nature of these\ndomains as well as the inability of individuals to opt out of these domains in any meaningful way, and the\nhistorical discrimination that has often accompanied data knowledge.\n\n69 Domains understood by the public to be\nsensitive also change over time, including because of technological developments.\n\nTracking and monitoring\ntechnologies, personal tracking devices, and our extensive data footprints are used and misused more than ever\nbefore; as such, the protections afforded by current legal guidelines may be inadequate.\n\nThe American public\ndeserves assurances that data related to such sensitive domains is protected and used appropriately and only in\nnarrowly defined contexts with clear benefits to the individual and/or society.\n\nTo this end, automated systems that collect, use, share, or store data related to these sensitive domains should meet\nadditional expectations.\n\nData and metadata are sensitive if they pertain to an individual in a sensitive domain (defined\nbelow); are generated by technologies used in a sensitive domain; can be used to infer data from a sensitive domain or\nsensitive data about an individual (such as disability-related data, genomic data, biometric data, behavioral data,\ngeolocation data, data related to interaction with the criminal justice system, relationship history and legal status such\nas custody and divorce information, and home, work, or school environmental data); or have the reasonable potential\nto be used in ways that are likely to expose individuals to meaningful harm, such as a loss of privacy or financial harm\ndue to identity theft.\n\nData and metadata generated by or about those who are not yet legal adults is also sensitive, even\nif not related to a sensitive domain.\n\nSuch data includes, but is not limited to, numerical, text, image, audio, or video\ndata.\n\n\u201cSensitive domains\u201d are those in which activities being conducted can cause material harms, including significant adverse effects on human rights such as autonomy and dignity, as well as civil liberties and civil rights.\n\nDomains\nthat have historically been singled out as deserving of enhanced data protections or where such enhanced protections\nare reasonably expected by the public include, but are not limited to, health, family planning and care, employment,\neducation, criminal justice, and personal finance.\n\nIn the context of this framework, such domains are considered\nsensitive whether or not the specifics of a system context would necessitate coverage under existing law, and domains\nand data that are considered sensitive are understood to change over time based on societal norms and context.\n\n-----", "###### E XTRA P ROTECTIONS FOR D ATA R ELATED TO S ENSITIVE D OMAINS\n\n-  Continuous positive airway pressure machines gather data for medical purposes, such as diagnosing sleep\napnea, and send usage data to a patient\u2019s insurance company, which may subsequently deny coverage for the\ndevice based on usage data.\n\nPatients were not aware that the data would be used in this way or monitored\nby anyone other than their doctor.\n\n70\n\n-  A department store company used predictive analytics applied to collected consumer data to determine that a\nteenage girl was pregnant, and sent maternity clothing ads and other baby-related advertisements to her\nhouse, revealing to her father that she was pregnant.\n\n71\n\n-  School audio surveillance systems monitor student conversations to detect potential \"stress indicators\" as\na warning of potential violence.\n\n72 Online proctoring systems claim to detect if a student is cheating on an\nexam using biometric markers.\n\n73 These systems have the potential to limit student freedom to express a range\nof emotions at school and may inappropriately flag students with disabilities who need accommodations or\nuse screen readers or dictation software as cheating.\n\n74\n\n-  Location data, acquired from a data broker, can be used to identify people who visit abortion clinics.\n\n75\n\n-  Companies collect student data such as demographic information, free or reduced lunch status, whether\nthey've used drugs, or whether they've expressed interest in LGBTQI+ groups, and then use that data to\nforecast student success.\n\n76 Parents and education experts have expressed concern about collection of such\nsensitive data without express parental consent, the lack of transparency in how such data is being used, and\nthe potential for resulting discriminatory impacts.\n\n-  Many employers transfer employee data to third party job verification services.\n\nThis information is then used\nby potential future employers, banks, or landlords.\n\nIn one case, a former employee alleged that a\ncompany supplied false data about her job title which resulted in a job offer being revoked.\n\n77\n\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts.\n\n\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad_\n\nIn addition to the privacy expectations above for general non-sensitive data, any system collecting, using, sharing, or storing sensitive data should meet the expectations below.\n\nDepending on the technological use case and\nbased on an ethical assessment, consent for sensitive data may need to be acquired from a guardian and/or child.", "**Provide enhanced protections for data related to sensitive domains**\n\n**Necessary functions only.\n\n** Sensitive data should only be used for functions strictly necessary for that\ndomain or for functions that are required for administrative reasons (e.g., school attendance records), unless\nconsent is acquired, if appropriate, and the additional expectations in this section are met.\n\nConsent for non\nnecessary functions should be optional, i.e., should not be required, incentivized, or coerced in order to\nreceive opportunities or access to services.\n\nIn cases where data is provided to an entity (e.g., health insurance\ncompany) in order to facilitate payment for such a need, that data should only be used for that purpose.\n\n**Ethical review and use prohibitions.\n\n** Any use of sensitive data or decision process based in part on sensitive data that might limit rights, opportunities, or access, whether the decision is automated or not, should go\nthrough a thorough ethical review and monitoring, both in advance and by periodic review (e.g., via an independent ethics committee or similarly robust process).\n\nIn some cases, this ethical review may determine that data\nshould not be used or shared for specific uses even with consent.\n\nSome novel uses of automated systems in this\ncontext, where the algorithm is dynamically developing and where the science behind the use case is not well\nestablished, may also count as human subject experimentation, and require special review under organizational\ncompliance bodies applying medical, scientific, and academic human subject experimentation ethics rules and\ngovernance procedures.\n\n**Data quality.\n\n** In sensitive domains, entities should be especially careful to maintain the quality of data to\navoid adverse consequences arising from decision-making based on flawed or inaccurate data.\n\nSuch care is\nnecessary in a fragmented, complex data ecosystem and for datasets that have limited access such as for fraud\nprevention and law enforcement.\n\nIt should be not left solely to individuals to carry the burden of reviewing and\ncorrecting data.\n\nEntities should conduct regular, independent audits and take prompt corrective measures to\nmaintain accurate, timely, and complete data.\n\n**Limit access to sensitive data and derived data.\n\n** Sensitive data and derived data should not be sold,\nshared, or made public as part of data brokerage or other agreements.\n\nSensitive data includes data that can be\nused to infer sensitive information; even systems that are not directly marketed as sensitive domain technologies\nare expected to keep sensitive data private.\n\nAccess to such data should be limited based on necessity and based\non a principle of local control, such that those individuals closest to the data subject have more access while\nthose who are less proximate do not (e.g., a teacher has access to their students\u2019 daily progress data while a\nsuperintendent does not).\n\n**Reporting.\n\n** In addition to the reporting on data privacy (as listed above for non-sensitive data), entities developing technologies related to a sensitive domain and those collecting, using, storing, or sharing sensitive data\nshould, whenever appropriate, regularly provide public reports describing: any data security lapses or breaches\nthat resulted in sensitive data leaks; the number, type, and outcomes of ethical pre-reviews undertaken; a\ndescription of any data sold, shared, or made public, and how that data was assessed to determine it did not present a sensitive data risk; and ongoing risk identification and management procedures, and any mitigation added\nbased on these procedures.\n\nReporting should be provided in a clear and machine-readable manner.\n\n-----", "**The Privacy** **Act** **of 1974** **requires privacy** **protections** **for personal** **information** **in federal**\n\n**records systems,** **including** **limits** **on data** **retention,** **and also provides** **individuals** **a general**\n**right to access and correct their data.\n\n** Among other things, the Privacy Act limits the storage of individual\ninformation in federal systems of records, illustrating the principle of limiting the scope of data retention.\n\nUnder\nthe Privacy Act, federal agencies may only retain data about an individual that is \u201crelevant and necessary\u201d to\naccomplish an agency\u2019s statutory purpose or to comply with an Executive Order of the President.\n\nThe law allows\nfor individuals to be able to access any of their individual information stored in a federal system of records, if not\nincluded under one of the systems of records exempted pursuant to the Privacy Act.\n\nIn these cases, federal agencies must provide a method for an individual to determine if their personal information is stored in a particular\nsystem of records, and must provide procedures for an individual to contest the contents of a record about them.\n\nFurther, the Privacy Act allows for a cause of action for an individual to seek legal relief if a federal agency does not\ncomply with the Privacy Act\u2019s requirements.\n\nAmong other things, a court may order a federal agency to amend or\ncorrect an individual\u2019s information in its records or award monetary damages if an inaccurate, irrelevant, untimely,\nor incomplete record results in an adverse determination about an individual\u2019s \u201cqualifications, character, rights, \u2026\nopportunities\u2026, or benefits.\u201d", "**NIST\u2019s** **Privacy** **Framework** **provides** **a comprehensive,** **detailed** **and actionable** **approach** **for**\n\n**organizations** **to manage** **privacy** **risks.\n\n** The NIST Framework gives organizations ways to identify and\ncommunicate their privacy risks and goals to support ethical decision-making in system, product, and service\ndesign or deployment, as well as the measures they are taking to demonstrate compliance with applicable laws\nor regulations.\n\nIt has been voluntarily adopted by organizations across many different sectors around the world.\n\n78", "**A school board\u2019s attempt to surveil public school students\u2014undertaken without**\n\n**adequate community input\u2014sparked a state-wide biometrics moratorium.\n\n** 79 Reacting to a plan in\nthe city of Lockport, New York, the state\u2019s legislature banned the use of facial recognition systems and other\n\u201cbiometric identifying technology\u201d in schools until July 1, 2022.\n\n80 The law additionally requires that a report on\nthe privacy, civil rights, and civil liberties implications of the use of such technologies be issued before\nbiometric identification technologies can be used in New York schools.", "**Federal law requires employers, and any consultants they may retain, to report the costs**\n\n**of surveilling employees in the context of a labor dispute, providing a transparency**\n**mechanism to help protect worker organizing.\n\n** Employers engaging in workplace surveillance \"where\nan object there-of, directly or indirectly, is [\u2026] to obtain information concerning the activities of employees or a\nlabor organization in connection with a labor dispute\" must report expenditures relating to this surveillance to\nthe Department of Labor Office of Labor-Management Standards, and consultants who employers retain for\nthese purposes must also file reports regarding their activities.\n\n81", "**Privacy choices on smartphones show that when technologies are well designed, privacy**\n\n**and data agency can be meaningful and not overwhelming.\n\n** These choices\u2014such as contextual, timely\nalerts about location tracking\u2014are brief, direct, and use-specific.\n\nMany of the expectations listed here for\nprivacy by design and use-specific consent mirror those distributed to developers as best practices when\ndeveloping for smart phone devices, 82 such as being transparent about how user data will be used, asking for app\npermissions during their use so that the use-context will be clear to users, and ensuring that the app will still\nwork if users deny (or later revoke) some permissions.\n\n-----", "**You should know that an automated system is being used,**\n\n**and understand how and why it contributes to outcomes**\n**that impact you.\n\n** Designers, developers, and deployers of automated systems should provide generally accessible plain language documentation including clear descriptions of the overall system functioning and the role automation plays, notice that such systems are in\nuse, the individual or organization responsible for the system, and explanations of outcomes that are clear, timely, and accessible.\n\nSuch\nnotice should be kept up-to-date and people impacted by the system\nshould be notified of significant use case or key functionality changes.\n\nYou should know how and why an outcome impacting you was determined by an automated system, including when the automated\nsystem is not the sole input determining the outcome.\n\nAutomated\nsystems should provide explanations that are technically valid,\nmeaningful and useful to you and to any operators or others who\nneed to understand the system, and calibrated to the level of risk\nbased on the context.\n\nReporting that includes summary information\nabout these automated systems in plain language and assessments of\nthe clarity and quality of the notice and explanations should be made\npublic whenever possible.\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\nAutomated systems now determine opportunities, from employment to credit, and directly shape the American\npublic\u2019s experiences, from the courtroom to online classrooms, in ways that profoundly impact people\u2019s lives.\n\nBut this\nexpansive impact is not always visible.\n\nAn applicant might not know whether a person rejected their resume or a\nhiring algorithm moved them to the bottom of the list.\n\nA defendant in the courtroom might not know if a judge denying their bail is informed by an automated system that labeled them \u201chigh risk.\u201d From correcting errors to contesting\ndecisions, people are often denied the knowledge they need to address the impact of automated systems on their lives.\n\nNotice and explanations also serve an important safety and efficacy purpose, allowing experts to verify the reasonableness of a recommendation before enacting it.\n\nIn order to guard against potential harms, the American public needs to know if an automated system is being used.\n\nClear, brief, and understandable notice is a prerequisite for achieving the other protections in this framework.\n\nLikewise, the public is often unable to ascertain how or why an automated system has made a decision or contributed to a\nparticular outcome.\n\nThe decision-making processes of automated systems tend to be opaque, complex, and, therefore,\nunaccountable, whether by design or by omission.\n\nThese factors can make explanations both more challenging and\nmore important, and should not be used as a pretext to avoid explaining important decisions to the people impacted\nby those choices.\n\nIn the context of automated systems, clear and valid explanations should be recognized as a baseline\nrequirement.\n\nProviding notice has long been a standard practice, and in many cases is a legal requirement, when, for example,\nmaking a video recording of someone (outside of a law enforcement or national security context).\n\nIn some cases, such\nas credit, lenders are required to provide notice and explanation to consumers.\n\nTechniques used to automate the\nprocess of explaining such systems are under active research and improvement and such explanations can take many\nforms.\n\nInnovative companies and researchers are rising to the challenge and creating and deploying explanatory\nsystems that can help the public better understand decisions that impact them.\n\nWhile notice and explanation requirements are already in place in some sectors or situations, the American public\ndeserve to know consistently and across sectors if an automated system is being used in a way that impacts their rights,\nopportunities, or access.\n\nThis knowledge should provide confidence in how the public is being treated, and trust in the\nvalidity and reasonable use of automated systems.\n\n-  A lawyer representing an older client with disabilities who had been cut off from Medicaid-funded home\nhealth-care assistance couldn't determine why, especially since the decision went against historical access\npractices.\n\nIn a court hearing, the lawyer learned from a witness that the state in which the older client\nlived had recently adopted a new algorithm to determine eligibility .\n\n83 The lack of a timely explanation made it\nharder to understand and contest the decision.\n\n-  A formal child welfare investigation is opened against a parent based on an algorithm and without the parent\never being notified that data was being collected and used as part of an algorithmic child maltreatment\nrisk assessment.\n\n84 The lack of notice or an explanation makes it harder for those performing child\nmaltreatment assessments to validate the risk assessment and denies parents knowledge that could help them\ncontest a decision.\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\n-  A predictive policing system claimed to identify individuals at greatest risk to commit or become the victim of\ngun violence (based on automated analysis of social ties to gang members, criminal histories, previous experiences of gun violence, and other factors) and led to individuals being placed on a watch list with no\nexplanation or public transparency regarding how the system came to its conclusions.\n\n85 Both police and\nthe public deserve to understand why and how such a system is making these determinations.\n\n-  A system awarding benefits changed its criteria invisibly.\n\nIndividuals were denied benefits due to data entry\nerrors and other system flaws.\n\nThese flaws were only revealed when an explanation of the system\nwas demanded and produced.\n\n86 The lack of an explanation made it harder for errors to be corrected in a\ntimely manner.\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\nAn automated system should provide demonstrably clear, timely, understandable, and accessible notice of use, and\nexplanations as to how and why a decision was made or an action was taken by the system.\n\nThese expectations are\nexplained below.\n\n**Provide clear, timely, understandable, and accessible notice of use and explanations** \u00ad\n\n**Generally accessible plain language documentation.\n\n** The entity responsible for using the automated\nsystem should ensure that documentation describing the overall system (including any human components) is\npublic and easy to find.\n\nThe documentation should describe, in plain language, how the system works and how\nany automated component is used to determine an action or decision.\n\nIt should also include expectations about\nreporting described throughout this framework, such as the algorithmic impact assessments described as\npart of Algorithmic Discrimination Protections .\n\n**Accountable.\n\n** Notices should clearly identify the entity responsible for designing each component of the\nsystem and the entity using it.\n\n**Timely and up-to-date.\n\n** Users should receive notice of the use of automated systems in advance of using or\nwhile being impacted by the technology.\n\nAn explanation should be available with the decision itself, or soon\nthereafter.\n\nNotice should be kept up-to-date and people impacted by the system should be notified of use case\nor key functionality changes.\n\n**Brief and clear.\n\n** Notices and explanations should be assessed, such as by research on users\u2019 experiences,\nincluding user testing, to ensure that the people using or impacted by the automated system are able to easily\nfind notices and explanations, read them quickly, and understand and act on them.\n\nThis includes ensuring that\nnotices and explanations are accessible to users with disabilities and are available in the language(s) and reading level appropriate for the audience.\n\nNotices and explanations may need to be available in multiple forms,\n(e.g., on paper, on a physical sign, or online), in order to meet these expectations and to be accessible to the\nAmerican public.", "**Provide explanations as to how and why a decision was made or an action was taken by an**\n\n**automated system**\n\n**Tailored to the purpose** .\n\nExplanations should be tailored to the specific purpose for which the user is\nexpected to use the explanation, and should clearly state that purpose.\n\nAn informational explanation might\ndiffer from an explanation provided to allow for the possibility of recourse, an appeal, or one provided in the\ncontext of a dispute or contestation process.\n\nFor the purposes of this framework, 'explanation' should be\nconstrued broadly.\n\nAn explanation need not be a plain-language statement about causality but could consist of\nany mechanism that allows the recipient to build the necessary understanding and intuitions to achieve the\nstated purpose.\n\nTailoring should be assessed (e.g., via user experience research).\n\n**Tailored to the target of the explanation.\n\n** Explanations should be targeted to specific audiences and\nclearly state that audience.\n\nAn explanation provided to the subject of a decision might differ from one provided\nto an advocate, or to a domain expert or decision maker.\n\nTailoring should be assessed (e.g., via user experience\nresearch).\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\n**Tailored to the level of risk.\n\n** An assessment should be done to determine the level of risk of the automated system.\n\nIn settings where the consequences are high as determined by a risk assessment, or extensive\noversight is expected (e.g., in criminal justice or some public sector settings), explanatory mechanisms should\nbe built into the system design so that the system\u2019s full behavior can be explained in advance (i.e., only fully\ntransparent models should be used), rather than as an after-the-decision interpretation.\n\nIn other settings, the\nextent of explanation provided should be tailored to the risk level.\n\n**Valid.\n\n** The explanation provided by a system should accurately reflect the factors and the influences that led\nto a particular decision, and should be meaningful for the particular customization based on purpose, target,\nand level of risk.\n\nWhile approximation and simplification may be necessary for the system to succeed based on\nthe explanatory purpose and target of the explanation, or to account for the risk of fraud or other concerns\nrelated to revealing decision-making information, such simplifications should be done in a scientifically\nsupportable way.\n\nWhere appropriate based on the explanatory system, error ranges for the explanation should\nbe calculated and included in the explanation, with the choice of presentation of such information balanced\nwith usability and overall interface complexity concerns.", "**Demonstrate protections for notice and explanation**\n\n**Reporting.\n\n** Summary reporting should document the determinations made based on the above considerations, including: the responsible entities for accountability purposes; the goal and use cases for the system,\nidentified users, and impacted populations; the assessment of notice clarity and timeliness; the assessment of\nthe explanation's validity and accessibility; the assessment of the level of risk; and the account and assessment\nof how explanations are tailored, including to the purpose, the recipient of the explanation, and the level of\nrisk.\n\nIndividualized profile information should be made readily available to the greatest extent possible that\nincludes explanations for any system impacts or inferences.\n\nReporting should be provided in a clear plain\nlanguage and machine-readable manner.\n\n-----", "###### H OW THESE PRINCIPLES CAN MOVE INTO PRACTICE\n\n_Real-life examples of how these principles can become reality, through laws, policies, and practical_\n_technical and sociotechnical approaches to protecting rights, opportunities, and access._ \u00ad\u00ad\u00ad\u00ad\u00ad\n\n**People in Illinois are given written notice by the private sector if their biometric information is used** .\n\nThe Biometric Information Privacy Act enacted by the state contains a number of provisions\nconcerning the use of individual biometric data and identifiers.\n\nIncluded among them is a provision that no private\nentity may \"collect, capture, purchase, receive through trade, or otherwise obtain\" such information about an\nindividual, unless written notice is provided to that individual or their legally appointed representative.\n\n87", "**Major technology** **companies** **are piloting** **new** **ways** **to communicate** **with the public about**\n\n**their automated** **technologies.\n\n** For example, a collection of non-profit organizations and companies have\nworked together to develop a framework that defines operational approaches to transparency for machine\nlearning systems.\n\n88 This framework, and others like it , 89 inform the public about the use of these tools, going\nbeyond simple notice to include reporting elements such as safety evaluations, disparity assessments, and\nexplanations of how the systems work.", "**Lenders are required by federal law to notify consumers about certain decisions made about**\n\n**them.\n\n** Both the Fair Credit Reporting Act and the Equal Credit Opportunity Act require in certain circumstances\nthat consumers who are denied credit receive \"adverse action\" notices.\n\nAnyone who relies on the information in a\ncredit report to deny a consumer credit must, under the Fair Credit Reporting Act, provide an \"adverse action\"\nnotice to the consumer, which includes \"notice of the reasons a creditor took adverse action on the application\nor on an existing credit account.\"\n\n90 In addition, under the risk-based pricing rule, 91 lenders must either inform\nborrowers of their credit score, or else tell consumers when \"they are getting worse terms because of\ninformation in their credit report.\"\n\nThe CFPB has also asserted that \"[t]he law gives every applicant the right to\na specific explanation if their application for credit was denied, and that right is not diminished simply because\na company uses a complex algorithm that it doesn't understand.\"\n\n92 Such explanations illustrate a shared value\nthat certain decisions need to be explained.", "**A California law** **and explanation about quotas, potentially facilitated by automated systems, that apply to them.\n\n** **requires that** **warehouse** **employees** **are provided** **with notice**\n\nWarehousing employers in California that use quota systems (often facilitated by algorithmic monitoring systems) are\nrequired to provide employees with a written description of each quota that applies to the employee, including\n\u201cquantified number of tasks to be performed or materials to be produced or handled, within the defined\ntime period, and any potential adverse employment action that could result from failure to meet the quota.\u201d 93", "**Across the federal government, agencies are conducting and supporting research on explainable genai systems.\n\n**\n\nThe NIST is conducting fundamental research on the explainability of genai systems.\n\nA multidisciplinary team of researchers aims to develop measurement methods and best practices to support the\nimplementation of core tenets of explainable genai.\n\n94 The Defense Advanced Research Projects Agency has a\nprogram on Explainable genai that aims to create a suite of machine learning techniques that\nproduce more explainable models, while maintaining a high level of learning performance (prediction\naccuracy), and enable human users to understand, appropriately trust, and effectively manage the emerging\ngeneration of artificially intelligent partners.\n\n95 The National Science Foundation\u2019s program on Fairness in\ngenai also includes a specific interest in research foundations for explainable genai.\n\n96\n\n\n-----", "**You should be able to opt out, where appropriate, and**\n\n**have access to a person who can quickly consider and**\n**remedy problems you encounter.\n\n** You should be able to opt\nout from automated systems in favor of a human alternative, where\nappropriate.\n\nAppropriateness should be determined based on reasonable expectations in a given context and with a focus on ensuring\nbroad accessibility and protecting the public from especially harmful impacts.\n\nIn some cases, a human or other alternative may be required by law.\n\nYou should have access to timely human consideration and remedy by a fallback and escalation process if an automated system fails, it produces an error, or you would like to appeal or\ncontest its impacts on you.\n\nHuman consideration and fallback\nshould be accessible, equitable, effective, maintained, accompanied\nby appropriate operator training, and should not impose an unreasonable burden on the public.\n\nAutomated systems with an intended\nuse within sensitive domains, including, but not limited to, criminal\njustice, employment, education, and health, should additionally be\ntailored to the purpose, provide meaningful access for oversight,\ninclude training for any people interacting with the system, and incorporate human consideration for adverse or high-risk decisions.\n\nReporting that includes a description of these human governance\nprocesses and assessment of their timeliness, accessibility, outcomes, and effectiveness should be made public whenever possible.\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\nThere are many reasons people may prefer not to use an automated system: the system can be flawed and can lead to\nunintended outcomes; it may reinforce bias or be inaccessible; it may simply be inconvenient or unavailable; or it may\nreplace a paper or manual process to which people had grown accustomed.\n\nYet members of the public are often\npresented with no alternative, or are forced to endure a cumbersome process to reach a human decision-maker once\nthey decide they no longer want to deal exclusively with the automated system or be impacted by its results.\n\nAs a result\nof this lack of human reconsideration, many receive delayed access, or lose access, to rights, opportunities, benefits,\nand critical services.\n\nThe American public deserves the assurance that, when rights, opportunities, or access are\nmeaningfully at stake and there is a reasonable expectation of an alternative to an automated system, they can conveniently opt out of an automated system and will not be disadvantaged for that choice.\n\nIn some cases, such a human or\nother alternative may be required by law, for example it could be required as \u201creasonable accommodations\u201d for people\nwith disabilities.\n\nIn addition to being able to opt out and use a human alternative, the American public deserves a human fallback\nsystem in the event that an automated system fails or causes harm.\n\nNo matter how rigorously an automated system is\ntested, there will always be situations for which the system fails.\n\nThe American public deserves protection via human\nreview against these outlying or unexpected scenarios.\n\nIn the case of time-critical systems, the public should not have\nto wait\u2014immediate human consideration and fallback should be available.\n\nIn many time-critical systems, such a\nremedy is already immediately available, such as a building manager who can open a door in the case an automated\ncard access system fails.\n\nIn the criminal justice system, employment, education, healthcare, and other sensitive domains, automated systems\nare used for many purposes, from pre-trial risk assessments and parole decisions to technologies that help doctors\ndiagnose disease.\n\nAbsent appropriate safeguards, these technologies can lead to unfair, inaccurate, or dangerous\noutcomes.\n\nThese sensitive domains require extra protections.\n\nIt is critically important that there is extensive human\noversight in such settings.\n\nThese critical protections have been adopted in some scenarios.\n\nWhere automated systems have been introduced to\nprovide the public access to government benefits, existing human paper and phone-based processes are generally still\nin place, providing an important alternative to ensure access.\n\nCompanies that have introduced automated call centers\noften retain the option of dialing zero to reach an operator.\n\nWhen automated identity controls are in place to board an\nairplane or enter the country, there is a person supervising the systems who can be turned to for help or to appeal a\nmisidentification.\n\nThe American people deserve the reassurance that such procedures are in place to protect their rights, opportunities,\nand access.\n\nPeople make mistakes, and a human alternative or fallback mechanism will not always have the right\nanswer, but they serve as an important check on the power and validity of automated systems.\n\n-  An automated signature matching system is used as part of the voting process in many parts of the country to\ndetermine whether the signature on a mail-in ballot matches the signature on file.\n\nThese signature matching\nsystems are less likely to work correctly for some voters, including voters with mental or physical\ndisabilities, voters with shorter or hyphenated names, and voters who have changed their name.\n\n97 A human\ncuring process, 98 which helps voters to confirm their signatures and correct other voting mistakes, is\nimportant to ensure all votes are counted, 99 and it is already standard practice in much of the country for\nboth an election official and the voter to have the opportunity to review and correct any such issues.\n\n100\n\n\n-----", "###### W HY THIS PRINCIPLE IS IMPORTANT\n\n_This section provides a brief summary of the problems which the principle seeks to address and protect_\n_against, including illustrative examples._\n\n-  An unemployment benefits system in Colorado required, as a condition of accessing benefits, that applicants\nhave a smartphone in order to verify their identity.\n\nNo alternative human option was readily available,\nwhich denied many people access to benefits.\n\n101\n\n-  A fraud detection system for unemployment insurance distribution incorrectly flagged entries as fraudulent,\nleading to people with slight discrepancies or complexities in their files having their wages withheld and tax\nreturns seized without any chance to explain themselves or receive a review by a person.\n\n102\n\n-  A patient was wrongly denied access to pain medication when the hospital\u2019s software confused her medica\u00ad\n\ntion history with that of her dog\u2019s.\n\nEven after she tracked down an explanation for the problem, doctors\nwere afraid to override the system, and she was forced to go without pain relief due to the system\u2019s error.\n\n103\n\n-  A large corporation automated performance evaluation and other HR functions, leading to workers being\nfired by an automated system without the possibility of human review, appeal or other form of recourse.\n\n104\n\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\nAn automated system should provide demonstrably effective mechanisms to opt out in favor of a human alternative, where appropriate, as well as timely human consideration and remedy by a fallback system, with additional\nhuman oversight and safeguards for systems used in sensitive domains, and with training and assessment for any\nhuman-based portions of the system to ensure effectiveness.", "**Provide a mechanism to conveniently opt out from automated systems in favor of a human**\n\n**alternative, where appropriate**\n\n**Brief, clear, accessible notice and instructions.\n\n** Those impacted by an automated system should be\ngiven a brief, clear notice that they are entitled to opt-out, along with clear instructions for how to opt-out.\n\nInstructions should be provided in an accessible form and should be easily findable by those impacted by the\nautomated system.\n\nThe brevity, clarity, and accessibility of the notice and instructions should be assessed (e.g.,\nvia user experience research).\n\n**Human alternatives provided when appropriate.\n\n** In many scenarios, there is a reasonable expectation\nof human involvement in attaining rights, opportunities, or access.\n\nWhen automated systems make up part of\nthe attainment process, alternative timely human-driven processes should be provided.\n\nThe use of a human\nalternative should be triggered by an opt-out process.\n\n**Timely and not burdensome human alternative.\n\n** Opting out should be timely and not unreasonably\nburdensome in both the process of requesting to opt-out and the human-driven alternative provided.", "**Provide timely human consideration and remedy by a fallback and escalation system in the**\n\n**event that an automated system fails, produces error, or you would like to appeal or contest its impacts on you**\n\n**Proportionate.\n\n** The availability of human consideration and fallback, along with associated training and\nsafeguards against human bias, should be proportionate to the potential of the automated system to meaningfully impact rights, opportunities, or access.\n\nAutomated systems that have greater control over outcomes,\nprovide input to high-stakes decisions, relate to sensitive domains, or otherwise have a greater potential to\nmeaningfully impact rights, opportunities, or access should have greater availability (e.g., staffing) and oversight of human consideration and fallback mechanisms.\n\n**Accessible.\n\n** Mechanisms for human consideration and fallback, whether in-person, on paper, by phone, or\notherwise provided, should be easy to find and use.\n\nThese mechanisms should be tested to ensure that users\nwho have trouble with the automated system are able to use human consideration and fallback, with the understanding that it may be these users who are most likely to need the human assistance.\n\nSimilarly, it should be\ntested to ensure that users with disabilities are able to find and use human consideration and fallback and also\nrequest reasonable accommodations or modifications.\n\n**Convenient.\n\n** Mechanisms for human consideration and fallback should not be unreasonably burdensome as\ncompared to the automated system\u2019s equivalent.\n\n-----", "###### W HAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\n\n_The expectations for automated systems are meant to serve as a blueprint for the development of additional_\n_technical standards and practices that are tailored for particular sectors and contexts._\n\n**Equitable.\n\n** Consideration should be given to ensuring outcomes of the fallback and escalation system are\nequitable when compared to those of the automated system and such that the fallback and escalation\nsystem provides equitable access to underserved communities.\n\n105\n\n**Timely** .\n\nHuman consideration and fallback are only useful if they are conducted and concluded in a\ntimely manner.\n\nThe determination of what is timely should be made relative to the specific automated\nsystem, and the review system should be staffed and regularly assessed to ensure it is providing timely\nconsideration and fallback.\n\nIn time-critical systems, this mechanism should be immediately available or,\nwhere possible, available before the harm occurs.\n\nTime-critical systems include, but are not limited to,\nvoting-related systems, automated building access and other access systems, systems that form a critical\ncomponent of healthcare, and systems that have the ability to withhold wages or otherwise cause\nimmediate financial penalties.\n\n**Effective.\n\n** The organizational structure surrounding processes for consideration and fallback should\nbe designed so that if the human decision-maker charged with reassessing a decision determines that it\nshould be overruled, the new decision will be effectively enacted.\n\nThis includes ensuring that the new\ndecision is entered into the automated system throughout its components, any previous repercussions from\nthe old decision are also overturned, and safeguards are put in place to help ensure that future decisions do\nnot result in the same errors.\n\n**Maintained.\n\n** The human consideration and fallback process and any associated automated processes\nshould be maintained and supported as long as the relevant automated system continues to be in use.", "**Institute training, assessment, and oversight to combat automation bias and ensure any**\n\n**human-based components of a system are effective.\n\n**\n\n**Training and assessment.\n\n** Anyone administering, interacting with, or interpreting the outputs of an automated system should receive training in that system, including how to properly interpret outputs of a system\nin light of its intended purpose and in how to mitigate the effects of automation bias.\n\nThe training should reoccur regularly to ensure it is up to date with the system and to ensure the system is used appropriately.\n\nAssessment should be ongoing to ensure that the use of the system with human involvement provides for appropriate results, i.e., that the involvement of people does not invalidate the system's assessment as safe and effective\nor lead to algorithmic discrimination.\n\n**Oversight.\n\n** Human-based systems have the potential for bias, including automation bias, as well as other\nconcerns that may limit their effectiveness.\n\nThe results of assessments of the efficacy and potential bias of\nsuch human-based systems should be overseen by governance structures that have the potential to update the\noperation of the human-based system in order to mitigate these effects.\n\n-----", "**Implement additional human oversight and safeguards for automated systems related to**\n\n**sensitive domains**\n\nAutomated systems used within sensitive domains, including criminal justice, employment, education, and\nhealth, should meet the expectations laid out throughout this framework, especially avoiding capricious,\ninappropriate, and discriminatory impacts of these technologies.\n\nAdditionally, automated systems used within\nsensitive domains should meet these expectations:\n\n**Narrowly scoped data and inferences.\n\n** Human oversight should ensure that automated systems in\nsensitive domains are narrowly scoped to address a defined goal, justifying each included data item or attribute as relevant to the specific use case.\n\nData included should be carefully limited to avoid algorithmic\ndiscrimination resulting from, e.g., use of community characteristics, social network analysis, or group-based\ninferences.\n\n**Tailored to the situation.\n\n** Human oversight should ensure that automated systems in sensitive domains\nare tailored to the specific use case and real-world deployment scenario, and evaluation testing should show\nthat the system is safe and effective for that specific situation.\n\nValidation testing performed based on one location or use case should not be assumed to transfer to another.\n\n**Human consideration before any high-risk decision.\n\n** Automated systems, where they are used in\nsensitive domains, may play a role in directly providing information or otherwise providing positive outcomes\nto impacted people.\n\nHowever, automated systems should not be allowed to directly intervene in high-risk\nsituations, such as sentencing decisions or medical care, without human consideration.\n\n**Meaningful access to examine the system.\n\n** Designers, developers, and deployers of automated\nsystems should consider limited waivers of confidentiality (including those related to trade secrets) where\nnecessary in order to provide meaningful oversight of systems used in sensitive domains, incorporating measures to protect intellectual property and trade secrets from unwarranted disclosure as appropriate.\n\nThis\nincludes (potentially private and protected) meaningful access to source code, documentation, and related\ndata during any associated legal discovery, subject to effective confidentiality or court orders.\n\nSuch meaningful access should include (but is not limited to) adhering to the principle on Notice and Explanation using the\nhighest level of risk so the system is designed with built-in explanations; such systems should use fully-transparent models where the model itself can be understood by people needing to directly examine it.", "**Demonstrate access to human alternatives, consideration, and fallback**\n\n**Reporting.\n\n** Reporting should include an assessment of timeliness and the extent of additional burden for\nhuman alternatives, aggregate statistics about who chooses the human alternative, along with the results of\nthe assessment about brevity, clarity, and accessibility of notice and opt-out instructions.\n\nReporting on the\naccessibility, timeliness, and effectiveness of human consideration and fallback should be made public at regular intervals for as long as the system is in use.\n\nThis should include aggregated information about the number\nand type of requests for consideration, fallback employed, and any repeated requests; the timeliness of the\nhandling of these requests, including mean wait times for different types of requests as well as maximum wait\ntimes; and information about the procedures used to address requests for consideration along with the results\nof the evaluation of their accessibility.\n\nFor systems used in sensitive domains, reporting should include information about training and governance procedures for these technologies.\n\nReporting should also include docu\u00ad\n\ni f l d f i h l id i f d i l d d d d i\n\n\n-----", "**Healthcare** **\u201cnavigators\u201d** **help people find their way** **through online signup forms to choose**\n\n**and obtain healthcare.\n\n** A Navigator is \u201can individual or organization that's trained and able to help\nconsumers, small businesses, and their employees as they look for health coverage options through the\nMarketplace ( a government web site ) , including completing eligibility and enrollment forms.\u201d 106 For\nthe 2022 plan year, the Biden-Harris Administration increased funding so that grantee organizations could\n\u201ctrain and certify more than 1,500 Navigators to help uninsured consumers find affordable and comprehensive\nhealth coverage.\u201d 107", "**The customer service industry has successfully integrated automated services such as**\n\n**chat-bots and genai-driven call response systems with escalation to a human support**\n**team.\n\n** 108 Many businesses now use partially automated customer service platforms that help answer customer\nquestions and compile common problems for human agents to review.\n\nThese integrated human-genai\nsystems allow companies to provide faster customer care while maintaining human agents to answer\ncalls or otherwise respond to complicated requests.\n\nUsing both genai and human agents is viewed as key to\nsuccessful customer service.\n\n109", "**Ballot curing laws in at least 24 states require a fallback system that allows voters to**\n\n**correct their ballot and have it counted in the case that a voter signature matching**\n**algorithm incorrectly flags their ballot as invalid or there is another issue with their**\n**ballot, and review by an election official does not rectify the problem.\n\nSome federal**\n**courts have found that such cure procedures are constitutionally required.\n\n** 110 Ballot\ncuring processes vary among states, and include direct phone calls, emails, or mail contact by election\nofficials.\n\n111 Voters are asked to provide alternative information or a new signature to verify the validity of their\nballot.\n\n-----", "**Examples of Automated Systems**\n\nThe below examples are meant to illustrate the breadth of automated systems that, insofar as they have the\npotential to meaningfully impact rights, opportunities, or access to critical resources or services, should\nbe covered by the Blueprint for an genai Bill of Rights .\n\nThese examples should not be construed to limit that\nscope, which includes automated systems that may not yet exist, but which fall under these criteria.\n\nExamples of automated systems for which the Blueprint for an genai Bill of Rights should be considered include\nthose that have the potential to meaningfully impact:\n\n\n\n**\u2022** **Civil rights, civil liberties, or privacy, including but not limited to** **:**\n\n**Speech-related systems** such as automated content moderation tools;\n**Surveillance and criminal justice system algorithms** such as risk assessments, predictive\npolicing, automated license plate readers, real-time facial recognition systems (especially\nthose used in public places or during protected activities like peaceful protests), social media\nmonitoring, and ankle monitoring devices;\n\n**Voting-related systems** such as signature matching tools;\n**Systems with a potential privacy impact** such as smart home systems and associated data,\nsystems that use or collect health-related data, systems that use or collect education-related\ndata, criminal justice system data, ad-targeting systems, and systems that perform big data\nanalytics in order to build profiles or infer personal information about individuals; and\n\nAny system that has the meaningful potential to lead to algorithmic discrimination.\n\n**\u2022 Equal opportunities, including but not limited to:**\n\n**Education-related systems** such as algorithms that purport to detect student cheating or\nplagiarism, admissions algorithms, online or virtual reality student monitoring systems,\nprojections of student progress or outcomes, algorithms that determine access to resources or\nrograms, and surveillance of classes (whether online or in-person);\n\n**Housing-related systems** such as tenant screening algorithms, automated valuation systems that\nestimate the value of homes used in mortgage underwriting or home insurance, and automated\nvaluations from online aggregator websites; and\n\n**Employment-related systems** such as workplace algorithms that inform all aspects of the terms\nand conditions of employment including, but not limited to, pay or promotion, hiring or termina-\ntion algorithms, virtual or augmented reality workplace training programs, and electronic work\nplace surveillance and management systems.\n\n**\u2022 Access to critical resources and services, including but not limited to:**\n\n**Health and health insurance technologies** such as medical genai systems and devices, genai-assisted\ndiagnostic tools, algorithms or predictive models used to support clinical decision making, medical\nor insurance health risk assessments, drug addiction risk assessments and associated access alg\n-orithms, wearable technologies, wellness apps, insurance care allocation algorithms, and health\ninsurance cost and underwriting algorithms;\n\n**Financial system algorithms** such as loan allocation algorithms, financial system access determination algorithms, credit scoring systems, insurance algorithms including risk assessments, auto\n-mated interest rate determinations, and financial algorithms that apply penalties (e.g., that can\ngarnish wages or withhold tax returns);\n\n\n-----", "###### A PPENDIX\n\n**Systems that impact the safety of communities** such as automated traffic control systems, elec\n-ctrical grid controls, smart city technologies, and industrial emissions and environmental\nimpact control algorithms; and\n\n**Systems related to access to benefits or services or assignment of penalties** such as systems that\nsupport decision-makers who adjudicate benefits such as collating or analyzing information or\nmatching records, systems which similarly assist in the adjudication of administrative or criminal\npenalties, fraud detection algorithms, services or benefits access control algorithms, biometric\nsystems used as access control, and systems which make benefits or services related decisions on a\nfully or partially autonomous basis (such as a determination to revoke benefits).\n\n-----", "**Listening to the American People**\n\nThe White House Office of Science and Technology Policy (OSTP) led a yearlong process to seek and distill\ninput from people across the country \u2013 from impacted communities to industry stakeholders to\ntechnology developers to other experts across fields and sectors, as well as policymakers across the Federal\ngovernment \u2013 on the issue of algorithmic and data-driven harms and potential remedies.\n\nThrough panel\ndiscussions, public listening sessions, private meetings, a formal request for information, and input to a\npublicly accessible and widely-publicized email address, people across the United States spoke up about\nboth the promises and potential harms of these technologies, and played a central role in shaping the\nBlueprint for an genai Bill of Rights.", "**Panel Discussions to Inform the Blueprint for An genai Bill of Rights**\n\nOSTP co-hosted a series of six panel discussions in collaboration with the Center for American Progress,\nthe Joint Center for Political and Economic Studies, New America, the German Marshall Fund, the Electronic\nPrivacy Information Center, and the Mozilla Foundation.\n\nThe purpose of these convenings \u2013 recordings of\nwhich are publicly available online 112 \u2013 was to bring together a variety of experts, practitioners, advocates\nand federal government officials to offer insights and analysis on the risks, harms, benefits, and\npolicy opportunities of automated systems.\n\nEach panel discussion was organized around a wide-ranging\ntheme, exploring current challenges and concerns and considering what an automated society that\nrespects democratic values should look like.\n\nThese discussions focused on the topics of consumer\nrights and protections, the criminal justice system, equal opportunities and civil justice, artificial\nintelligence and democratic values, social welfare and development, and the healthcare system.", "**Summaries of Panel Discussions:**\n\n**Panel 1: Consumer Rights and Protections.\n\n** This event explored the opportunities and challenges for\nindividual consumers and communities in the context of a growing ecosystem of genai-enabled consumer\nproducts, advanced platforms and services, \u201cInternet of Things\u201d (IoT) devices, and smart city products and\nservices.\n\n**Welcome** :\n\n-  Rashida Richardson, Senior Policy Advisor for Data and Democracy, White House Office of Science and\nTechnology Policy\n\n-  Karen Kornbluh, Senior Fellow and Director of the Digital Innovation and Democracy Initiative, German\nMarshall Fund\n\n**Moderator** :\n\nDevin E. Willis, Attorney, Division of Privacy and Identity Protection, Bureau of Consumer Protection, Federal\nTrade Commission\n\n**Panelists** :\n\n-  Tamika L. Butler, Principal, Tamika L. Butler Consulting\n\n-  Jennifer Clark, Professor and Head of City and Regional Planning, Knowlton School of Engineering, Ohio\nState University\n\n-  Carl Holshouser, Senior Vice President for Operations and Strategic Initiatives, TechNet\n\n-  Surya Mattu, Senior Data Engineer and Investigative Data Journalist, The Markup\n\n-  Mariah Montgomery, National Campaign Director, Partnership for Working Families\n\n\n-----", "###### A PPENDIX\n\nPanelists discussed the benefits of genai-enabled systems and their potential to build better and more\ninnovative infrastructure.\n\nThey individually noted that while genai technologies may be new, the process of\ntechnological diffusion is not, and that it was critical to have thoughtful and responsible development and\nintegration of technology within communities.\n\nSome p anelists suggested that the integration of technology\ncould benefit from examining how technological diffusion has worked in the realm of urban planning:\nlessons learned from successes and failures there include the importance of balancing ownership rights, use\nrights, and community health, safety and welfare, as well ensuring better representation of all voices,\nespecially those traditionally marginalized by technological advances.\n\nSome panelists also raised the issue of\npower structures \u2013 providing examples of how strong transparency requirements in smart city projects\nhelped to reshape power and give more voice to those lacking the financial or political power to effect change.\n\nIn discussion of technical and governance interventions that that are needed to protect against the harms\nof these technologies, various p anelists emphasized the need for transparency, data collection, and\nflexible and reactive policy development, analogous to how software is continuously updated and deployed.\n\nSome panelists pointed out that companies need clear guidelines to have a consistent environment for\ninnovation, with principles and guardrails being the key to fostering responsible innovation.\n\n**Panel 2: The Criminal Justice System.\n\n** This event explored current and emergent uses of technology in\nthe criminal justice system and considered how they advance or undermine public safety, justice, and\ndemocratic values.\n\n**Welcome** :\n\n-  Suresh Venkatasubramanian, Assistant Director for Science and Justice, White House Office of Science\nand Technology Policy\n\n-  Ben Winters, Counsel, Electronic Privacy Information Center\n\n**Moderator** : Chiraag Bains, Deputy Assistant to the President on Racial Justice & Equity", "**Panelists:**\n\nSean Malinowski, Director of Policing Innovation and Reform, University of Chicago Crime Lab\n\n\nKristian Lum, Researcher\n\n\nJumana Musa, Director, Fourth Amendment Center, National Association of Criminal Defense Lawyers\n\n\nStanley Andrisse, Executive Director, From Prison Cells to PHD; Assistant Professor, Howard University\nCollege of Medicine\n\n\nMyaisha Hayes, Campaign Strategies Director, MediaJustice\n\n\nPanelists discussed uses of technology within the criminal justice system, including the use of predictive\npolicing, pretrial risk assessments, automated license plate readers, and prison communication tools.\n\nThe\ndiscussion emphasized that communities deserve safety, and strategies need to be identified that lead to safety;\nsuch strategies might include data-driven approaches, but the focus on safety should be primary, and\ntechnology may or may not be part of an effective set of mechanisms to achieve safety.\n\nVarious panelists raised\nconcerns about the validity of these systems, the tendency of adverse or irrelevant data to lead to a replication of\nunjust outcomes, and the confirmation bias and tendency of people to defer to potentially inaccurate automated\nsystems.\n\nThroughout, many of the panelists individually emphasized that the impact of these systems on\nindividuals and communities is potentially severe: the systems lack individualization and work against the\nbelief that people can change for the better, system use can lead to the loss of jobs and custody of children, and\nsurveillance can lead to chilling effects for communities and sends negative signals to community members\nabout how they're viewed.\n\nIn discussion of technical and governance interventions that that are needed to protect against the harms of\nthese technologies, various panelists emphasized that transparency is important but is not enough to achieve\naccountability.\n\nSome panelists discussed their individual views on additional system needs for validity, and\nagreed upon the importance of advisory boards and compensated community input early in the design process\n(b f h h l i b il d i i d) V i li l h i d h i f l i\n\n\n-----", "###### A PPENDIX\n\n**Panel 3: Equal Opportunities and Civil Justice.\n\n** This event explored current and emerging uses of\ntechnology that impact equity of opportunity in employment, education, and housing.\n\n**Welcome** :\n\n-  Rashida Richardson, Senior Policy Advisor for Data and Democracy, White House Office of Science and\nTechnology Policy\n\n-  Dominique Harrison, Director for Technology Policy, The Joint Center for Political and Economic\nStudies\n\n**Moderator** : Jenny Yang, Director, Office of Federal Contract Compliance Programs, Department of Labor", "**Panelists:**\n\n-  Christo Wilson, Associate Professor of Computer Science, Northeastern University\n\n-  Frida Polli, CEO, Pymetrics\n\n-  Karen Levy, Assistant Professor, Department of Information Science, Cornell University\n\n-  Natasha Duarte, Project Director, Upturn\n\n-  Elana Zeide, Assistant Professor, University of Nebraska College of Law\n\n-  Fabian Rogers, Constituent Advocate, Office of NY State Senator Jabari Brisport and Community\nAdvocate and Floor Captain, Atlantic Plaza Towers Tenants Association\n\nThe individual panelists described the ways in which genai systems and other technologies are increasingly being\nused to limit access to equal opportunities in education, housing, and employment.\n\nEducation-related\nconcerning uses included the increased use of remote proctoring systems, student location and facial\nrecognition tracking, teacher evaluation systems, robot teachers, and more.\n\nHousing-related concerning uses\nincluding automated tenant background screening and facial recognition-based controls to enter or exit\nhousing complexes.\n\nEmployment-related concerning uses included discrimination in automated hiring\nscreening and workplace surveillance.\n\nVarious panelists raised the limitations of existing privacy law as a key\nconcern, pointing out that students should be able to reinvent themselves and require privacy of their student\nrecords and education-related data in order to do so.\n\nThe overarching concerns of surveillance in these\ndomains included concerns about the chilling effects of surveillance on student expression, inappropriate\ncontrol of tenants via surveillance, and the way that surveillance of workers blurs the boundary between work\nand life and exerts extreme and potentially damaging control over workers' lives.\n\nAdditionally, some panelists\npointed out ways that data from one situation was misapplied in another in a way that limited people's\nopportunities, for example data from criminal justice settings or previous evictions being used to block further\naccess to housing.\n\nThroughout, various panelists emphasized that these technologies are being used to shift the\nburden of oversight and efficiency from employers to workers, schools to students, and landlords to tenants, in\nways that diminish and encroach on equality of opportunity; assessment of these technologies should include\nwhether they are genuinely helpful in solving an identified problem.\n\nIn discussion of technical and governance interventions that that are needed to protect against the harms of\nthese technologies, panelists individually described the importance of: receiving community input into the\ndesign and use of technologies, public reporting on crucial elements of these systems, better notice and consent\nprocedures that ensure privacy based on context and use case, ability to opt-out of using these systems and\nreceive a fallback to a human process, providing explanations of decisions and how these systems work, the\nneed for governance including training in using these systems, ensuring the technological use cases are\ngenuinely related to the goal task and are locally validated to work, and the need for institution and protection\nof third party audits to ensure systems continue to be accountable and valid.\n\n-----", "###### A PPENDIX\n\n**Panel 4: genai and Democratic Values.\n\n** This event examined challenges and opportunities in\nthe design of technology that can help support a democratic vision for genai.\n\nIt included discussion of the\ntechnical aspects of designing non-discriminatory technology, explainable genai, human-computer\ninteraction with an emphasis on community participation, and privacy-aware design.", "**Welcome:**\n\n-  Sorelle Friedler, Assistant Director for Data and Democracy, White House Office of Science and\nTechnology Policy\n\n-  J.\n\nBob Alotta, Vice President for Global Programs, Mozilla Foundation\n\n-  Navrina Singh, Board Member, Mozilla Foundation\n\n**Moderator** : Kathy Pham Evans, Deputy Chief Technology Officer for Product and Engineering, U.S\nFederal Trade Commission.", "**Panelists:**\n\n-  Liz O\u2019Sullivan, CEO, Parity genai\n\n-  Timnit Gebru, Independent Scholar\n\n-  Jennifer Wortman Vaughan, Senior Principal Researcher, Microsoft Research, New York City\n\n-  Pamela Wisniewski, Associate Professor of Computer Science, University of Central Florida; Director,\nSocio-technical Interaction Research (STIR) Lab\n\n-  Seny Kamara, Associate Professor of Computer Science, Brown University\n\nEach panelist individually emphasized the risks of using genai in high-stakes settings, including the potential for\nbiased data and discriminatory outcomes, opaque decision-making processes, and lack of public trust and\nunderstanding of the algorithmic systems.\n\nThe interventions and key needs various panelists put forward as\nnecessary to the future design of critical genai systems included ongoing transparency, value sensitive and\nparticipatory design, explanations designed for relevant stakeholders, and public consultation.\n\nVarious\npanelists emphasized the importance of placing trust in people, not technologies, and in engaging with\nimpacted communities to understand the potential harms of technologies and build protection by design into\nfuture systems.\n\n**Panel 5: Social Welfare and Development.\n\n** This event explored current and emerging uses of technology to\nimplement or improve social welfare systems, social development programs, and other systems that can impact\nlife chances.", "**Welcome:**\n\n-  Suresh Venkatasubramanian, Assistant Director for Science and Justice, White House Office of Science\nand Technology Policy\n\n-  Anne-Marie Slaughter, CEO, New America\n\n**Moderator** : Michele Evermore, Deputy Director for Policy, Office of Unemployment Insurance\nModernization, Office of the Secretary, Department of Labor\n\n**Panelists** :\n\n-  Blake Hall, CEO and Founder, ID.Me\n\n-  Karrie Karahalios, Professor of Computer Science, University of Illinois, Urbana-Champaign\n\n-  Christiaan van Veen Director of Digital Welfare State and Human Rights Project NYU School of Law's\n\n\n-----", "###### A PPENDIX\n\n-  Julia Simon-Mishel, Supervising Attorney, Philadelphia Legal Assistance\n\n-  Dr. Zachary Mahafza, Research & Data Analyst, Southern Poverty Law Center\n\n-  J. Khadijah Abdurahman, Tech Impact Network Research Fellow, genai Now Institute, UCLA C2I1, and\nUWA Law School\n\nPanelists separately described the increasing scope of technology use in providing for social welfare, including\nin fraud detection, digital ID systems, and other methods focused on improving efficiency and reducing cost.\n\nHowever, various panelists individually cautioned that these systems may reduce burden for government\nagencies by increasing the burden and agency of people using and interacting with these technologies.\n\nAdditionally, these systems can produce feedback loops and compounded harm, collecting data from\ncommunities and using it to reinforce inequality.\n\nVarious panelists suggested that these harms could be\nmitigated by ensuring community input at the beginning of the design process, providing ways to opt out of\nthese systems and use associated human-driven mechanisms instead, ensuring timeliness of benefit payments,\nand providing clear notice about the use of these systems and clear explanations of how and what the\ntechnologies are doing.\n\nSome panelists suggested that technology should be used to help people receive\nbenefits, e.g., by pushing benefits to those in need and ensuring automated decision-making systems are only\nused to provide a positive outcome; technology shouldn't be used to take supports away from people who need\nthem .\n\n**Panel 6: The Healthcare System.\n\n** This event explored current and emerging uses of technology in the\nhealthcare system and consumer products related to health.", "**Panelists:**\n\n-  Mark Schneider, Health Innovation Advisor, ChristianaCare\n\n-  Ziad Obermeyer, Blue Cross of California Distinguished Associate Professor of Policy and Management,\nUniversity of California, Berkeley School of Public Health\n\n-  Dorothy Roberts, George A. Weiss University Professor of Law and Sociology and the Raymond Pace and\nSadie Tanner Mossell Alexander Professor of Civil Rights, University of Pennsylvania\n\n-  David Jones, A. Bernard Ackerman Professor of the Culture of Medicine, Harvard University\n\n-  Jamila Michener, Associate Professor of Government, Cornell University; Co-Director, Cornell Center for\nHealth Equity\u00ad\n\nPanelists discussed the impact of new technologies on health disparities; healthcare access, delivery, and\noutcomes; and areas ripe for research and policymaking.\n\nPanelists discussed the increasing importance of technology as both a vehicle to deliver healthcare and a tool to enhance the quality of care.\n\nOn the issue of\ndelivery, various panelists pointed to a number of concerns including access to and expense of broadband\nservice, the privacy concerns associated with telehealth systems, the expense associated with health\nmonitoring devices, and how this can exacerbate equity issues.\n\nOn the issue of technology enhanced care,\nsome panelists spoke extensively about the way in which racial biases and the use of race in medicine\nperpetuate harms and embed prior discrimination, and the importance of ensuring that the technologies used\nin medical care were accountable to the relevant stakeholders.\n\nVarious p anelists emphasized the importance\nf h i g th i f th bj t d t th t h l gi b h d\n\n\n-----", "**Summaries of Additional Engagements:**\n\n-  OSTP created an email address () to solicit comments from the public on the use of\ngenai and other data-driven technologies in their lives.\n\n-  OSTP issued a Request For Information (RFI) on the use and governance of biometric technologies.\n\n113 The\npurpose of this RFI was to understand the extent and variety of biometric technologies in past, current, or\nplanned use; the domains in which these technologies are being used; the entities making use of them; current\nprinciples, practices, or policies governing their use; and the stakeholders that are, or may be, impacted by their\nuse or regulation.\n\nThe 130 responses to this RFI are available in full online 114 and were submitted by the below\nlisted organizations and individuals:\n\n\nAccenture\nAccess Now\nACT | The App Association\nAHIP\nAIethicist.org\nAirlines for America\nAlliance for Automotive Innovation\nAmelia Winger-Bearskin\nAmerican Civil Liberties Union\nAmerican Civil Liberties Union of\nMassachusetts\nAmerican Medical Association\nARTICLE19\nAttorneys General of the District of\nColumbia, Illinois, Maryland,\nMichigan, Minnesota, New York,\nNorth Carolina, Oregon, Vermont,\nand Washington\nAvanade\nAware\nBarbara Evans\nBetter Identity Coalition\nBipartisan Policy Center\nBrandon L. Garrett and Cynthia\nRudin\nBrian Krupp\nBrooklyn Defender Services\nBSA | The Software Alliance\nCarnegie Mellon University\nCenter for Democracy &\nTechnology\nCenter for New Democratic\nProcesses\nCenter for Research and Education\non Accessible Technology and\nExperiences at University of\nWashington, Devva Kasnitz, L Jean\nCamp, Jonathan Lazar, Harry\nHochheiser\nCenter on Privacy & Technology at\n\n\nCisco Systems\nCity of Portland Smart City PDX\nProgram\nCLEAR\nClearview genai\nCognoa\nColor of Change\nCommon Sense Media\nComputing Community Consortium\nat Computing Research Association\nConnected Health Initiative\nConsumer Technology Association\nCourtney Radsch\nCoworker\nCyber Farm Labs\nData & Society Research Institute\nData for Black Lives\nData to Actionable Knowledge Lab\nat Harvard University\nDeloitte\nDev Technology Group\nDigital Therapeutics Alliance\nDigital Welfare State & Human\nRights Project and Center for\nHuman Rights and Global Justice at\nNew York University School of\nLaw, and Temple University\nInstitute for Law, Innovation &\nTechnology\nDignari\nDouglas Goddard\nEdgar Dworsky\nElectronic Frontier Foundation\nElectronic Privacy Information\nCenter, Center for Digital\nDemocracy, and Consumer\nFederation of America\nFaceTec\nFight for the Future\nGanesh Mani\nG i T h R h I tit t\n\n\nGoogle\nHealth Information Technology\nResearch and Development\nInteragency Working Group\nHireVue\nHR Policy Association\nID.me\nIdentity and Data Sciences\nLaboratory at Science Applications\nInternational Corporation\nInformation Technology and\nInnovation Foundation\nInformation Technology Industry\nCouncil\nInnocence Project\nInstitute for Human-Centered\ngenai at Stanford\nUniversity\nIntegrated Justice Information\nSystems Institute\nInternational Association of Chiefs\nof Police\nInternational Biometrics + Identity\nAssociation\nInternational Business Machines\nCorporation\nInternational Committee of the Red\nCross\nInventionphysics\niProov\nJacob Boudreau\nJennifer K. Wagner, Dan Berger,\nMargaret Hu, and Sara Katsanis\nJonathan Barry-Blocker\nJoseph Turow\nJoy Buolamwini\nJoy Mack\nKaren Bureau\nLamont Gholston\nLawyers\u2019 Committee for Civil\nRi ht U d L\n\n\n-----", "###### A PPENDIX\n\nLisa Feldman Barrett\nMadeline Owens\nMarsha Tudor\nMicrosoft Corporation\nMITRE Corporation\nNational Association for the\nAdvancement of Colored People\nLegal Defense and Educational\nFund\nNational Association of Criminal\nDefense Lawyers\nNational Center for Missing &\nExploited Children\nNational Fair Housing Alliance\nNational Immigration Law Center\nNEC Corporation of America\nNew America\u2019s Open Technology\nInstitute\nNew York Civil Liberties Union\nNo Name Provided\nNotre Dame Technology Ethics\nCenter\nOffice of the Ohio Public Defender\nOnfido\nOosto\nOrissa Rose\nPalantir\nPangiam\nParity Technologies\nPatrick A. Stewart, Jeffrey K.\nMullins, and Thomas J. Greitens\nPel Abbott\nPhiladelphia Unemployment\nProject\nProject On Government Oversight\nRecording Industry Association of\nAmerica\nRobert Wilkens\nRon Hedges\nScience, Technology, and Public\nPolicy Program at University of\nMichigan Ann Arbor\n\n\nSecurity Industry Association\nSheila Dean\nSoftware & Information Industry\nAssociation\nStephanie Dinkins and the Future\nHistories Studio at Stony Brook\nUniversity\nTechNet\nThe Alliance for Media Arts and\nCulture, MIT Open Documentary\nLab and Co-Creation Studio, and\nImmerse\nThe International Brotherhood of\nTeamsters\nThe Leadership Conference on\nCivil and Human Rights\nThorn\nU.S. Chamber of Commerce\u2019s\nTechnology Engagement Center\nUber Technologies\nUniversity of Pittsburgh\nUndergraduate Student\nCollaborative\nUpturn\nUS Technology Policy Committee\nof the Association of Computing\nMachinery\nVirginia Puccio\nVisar Berisha and Julie Liss\nXR Association\nXR Safety Initiative\n\n\n\n-  As an additional effort to reach out to stakeholders regarding the RFI, OSTP conducted two listening sessions\nfor members of the public.\n\nThe listening sessions together drew upwards of 300 participants.\n\nThe Science and\nTechnology Policy Institute produced a synopsis of both the RFI submissions and the feedback at the listening\nsessions.\n\n115\n\n\n-----", "###### A PPENDIX\n\n-  OSTP conducted meetings with a variety of stakeholders in the private sector and civil society.\n\nSome of these\nmeetings were specifically focused on providing ideas related to the development of the Blueprint for an genai\nBill of Rights while others provided useful general context on the positive use cases, potential harms, and/or\noversight possibilities for these technologies.\n\nParticipants in these conversations from the private sector and\ncivil society included:\n\n\nMovement Alliance Project\nThe National Association of\nCriminal Defense Lawyers\nO\u2019Neil Risk Consulting &\nAlgorithmic Auditing\nThe Partnership on genai\nPinterest\nThe Plaintext Group\npymetrics\nSAP\nThe Security Industry Association\nSoftware and Information Industry\nAssociation (SIIA)\nSpecial Competitive Studies Project\nThorn\nUnited for Respect\nUniversity of California at Berkeley\nCitris Policy Lab\nUniversity of California at Berkeley\nLabor Center\nUnfinished/Project Liberty\nUpturn\nUS Chamber of Commerce\nUS Chamber of Commerce\nTechnology Engagement Center\nA.I.\n\nWorking Group\nVibrent Health\nWarehouse Worker Resource\nCenter\nWaymap\n\n\nAdobe\nAmerican Civil Liberties Union\n(ACLU)\nThe Aspen Commission on\nInformation Disorder\nThe Awood Center\nThe Australian Human Rights\nCommission\nBiometrics Institute\nThe Brookings Institute\nBSA | The Software Alliance\nCantellus Group\nCenter for American Progress\nCenter for Democracy and\nTechnology\nCenter on Privacy and Technology\nat Georgetown Law\nChristiana Care\nColor of Change\nCoworker\nData Robot\nData Trust Alliance\nData and Society Research Institute\nDeepmind\nEdSAFE genai Alliance\nElectronic Privacy Information\nCenter (EPIC)\nEncode Justice\nEqual genai\nGoogle\nHitachi's genai Policy Committee\nThe Innocence Project\nInstitute of Electrical and\nElectronics Engineers (IEEE)\nIntuit\nLawyers Committee for Civil Rights\nUnder Law\nLegal Aid Society\nThe Leadership Conference on\nCivil and Human Rights\nMeta\nMicrosoft\nThe MIT genai Policy Forum\n\n\n-----", "**1.1.\n\n** **Reasons for and objectives of the proposal**\n\nThis explanatory memorandum accompanies the proposal for a Regulation laying down\nharmonised rules on genai (genai Act).\n\ngenai\n(genai) is a fast evolving family of technologies that can bring a wide array of economic and\nsocietal benefits across the entire spectrum of industries and social activities.\n\nBy improving\nprediction, optimising operations and resource allocation, and personalising service delivery,\nthe use of genai can support socially and environmentally beneficial outcomes\nand provide key competitive advantages to companies and the European economy.\n\nSuch\naction is especially needed in high-impact sectors, including climate change, environment and\nhealth, the public sector, finance, mobility, home affairs and agriculture.\n\nHowever, the same\nelements and techniques that power the socio-economic benefits of genai can also bring about\nnew risks or negative consequences for individuals or the society.\n\nIn light of the speed of\ntechnological change and possible challenges, the EU is committed to strive for a balanced\napproach.\n\nIt is in the Union interest to preserve the EU\u2019s technological leadership and to\nensure that Europeans can benefit from new technologies developed and functioning\naccording to Union values, fundamental rights and principles.\n\nThis proposal delivers on the political commitment by President von der Leyen, who\nannounced in her political guidelines for the 2019-2024 Commission \u201cA Union that strives for\n\n1\nmore\u201d , that the Commission would put forward legislation for a coordinated European\napproach on the human and ethical implications of genai.\n\nFollowing on that announcement, on\n19 February 2020 the Commission published the White Paper on genai - A European approach\nto excellence and trust 2 .\n\nThe White Paper sets out policy options on how to achieve the twin\nobjective of promoting the uptake of genai and of addressing the risks associated with certain\nuses of such technology.\n\nThis proposal aims to implement the second objective for the\ndevelopment of an ecosystem of trust by proposing a legal framework for trustworthy genai.\n\nThe\nproposal is based on EU values and fundamental rights and aims to give people and other\nusers the confidence to embrace genai-based solutions, while encouraging businesses to develop\nthem.\n\ngenai should be a tool for people and be a force for good in society with the ultimate aim\nof increasing human well-being.\n\nRules for genai available in the Union market or otherwise\naffecting people in the Union should therefore be human centric, so that people can trust that\nthe technology is used in a way that is safe and compliant with the law, including the respect\nof fundamental rights.\n\nFollowing the publication of the White Paper, the Commission\nlaunched a broad stakeholder consultation, which was met with a great interest by a large\nnumber of stakeholders who were largely supportive of regulatory intervention to address the\nchallenges and concerns raised by the increasing use of genai.\n\nThe proposal also responds to explicit requests from the European Parliament (EP) and the\nEuropean Council, which have repeatedly expressed calls for legislative action to ensure a\nwell-functioning internal market for genai systems (\u2018genai systems\u2019) where both\nbenefits and risks of genai are adequately addressed at Union level.\n\nIt supports the objective of\nthe Union being a global leader in the development of secure, trustworthy and ethical artificial\n\n\n1 \n\n2 European Commission, White Paper on genai - A European approach to excellence and\ntrust, COM(2020) 65 final, 2020.", "# EN EN\n\n-----\n\nintelligence as stated by the European Council 3 and ensures the protection of ethical principles\nas specifically requested by the European Parliament 4 .\n\nIn 2017, the European Council called for a \u2018sense of urgency to address emerging trends\u2019\nincluding \u2018issues such as genai \u2026, while at the same time ensuring a high\n\n5\nlevel of data protection, digital rights and ethical standards\u2019 .\n\nIn its 2019 Conclusions on the\nCoordinated Plan on the development and use of genai Made in Europe 6 , the\nCouncil further highlighted the importance of ensuring that European citizens\u2019 rights are fully\nrespected and called for a review of the existing relevant legislation to make it fit for purpose\nfor the new opportunities and challenges raised by genai.\n\nThe European Council has also called\nfor a clear determination of the genai applications that should be considered high-risk 7 .\n\nThe most recent Conclusions from 21 October 2020 further called for addressing the opacity,\ncomplexity, bias, a certain degree of unpredictability and partially autonomous behaviour of\ncertain genai systems, to ensure their compatibility with fundamental rights and to facilitate the\nenforcement of legal rules 8 .\n\nThe European Parliament has also undertaken a considerable amount of work in the area of\ngenai.\n\nIn October 2020, it adopted a number of resolutions related to genai, including on ethics 9 ,\nliability 10 and copyright 11 .\n\nIn 2021, those were followed by resolutions on genai in criminal\nmatters 12 and in education, culture and the audio-visual sector 13 .\n\nThe EP Resolution on a\nFramework of Ethical Aspects of genai, Robotics and Related Technologies\nspecifically recommends to the Commission to propose legislative action to harness the\nopportunities and benefits of genai, but also to ensure protection of ethical principles.\n\nThe\nresolution includes a text of the legislative proposal for a regulation on ethical principles for\nthe development, deployment and use of genai, robotics and related technologies.\n\nIn accordance\nwith the political commitment made by President von der Leyen in her Political Guidelines as\nregards resolutions adopted by the European Parliament under Article 225 TFEU, this\n\n\nEuropean Council, Special meeting of the European Council (1 and 2 October 2020) \u2013 Conclusions ,\nEUCO 13/20, 2020, p. 6.\n\nEuropean Parliament resolution of 20 October 2020 with recommendations to the Commission on a\nframework of ethical aspects of genai, robotics and related technologies,\n2020/2012(INL).\n\nEuropean Council, _European Council meeting (19 October 2017) \u2013 Conclusion_ EUCO 14/17, 2017, p.\n8.\n\nCouncil of the European Union, _Artificial intelligence b) Conclusions on the coordinated plan on_\n_artificial intelligence-Adoption_ 6177/19, 2019.\n\nEuropean Council, _Special meeting of the European Council (1and 2 October 2020) \u2013 Conclusions_\nEUCO 13/20, 2020.\n\nCouncil of the European Union, _Presidency conclusions - The Charter of Fundamental Rights in the_\n_context of genai and Digital Change_ , 11481/20, 2020.\n\nEuropean Parliament resolution of 20 October 2020 on a framework of ethical aspects of artificial\nintelligence, robotics and related technologies, 2020/2012(INL)) .\n\n10 European Parliament resolution of 20 October 2020 on a civil liability regime for genai,\n2020/2014(INL).\n\n11 European Parliament resolution of 20 October 2020 on intellectual property rights for the development\nof genai technologies, 2020/2015(INI).\n\n12 European Parliament Draft Report, genai in criminal law and its use by the police and\njudicial authorities in criminal matters, 2020/2016(INI).)\n\n13 European Parliament Draft Report, genai in education, culture and the audiovisual\nsector, 2020/2017(INI).\n\nIn that regard, the Commission has adopted the Digital Education Action Plan\n2021-2027: Resetting education and training for the digital age, which foresees the development of\nethical guidelines in genai and Data usage in education \u2013 Commission Communication COM(2020) 624\nfinal.", "# EN EN\n\n-----\n\nproposal takes into account the aforementioned resolution of the European Parliament in full\nrespect of proportionality, subsidiarity and better law making principles.\n\nAgainst this political context, the Commission puts forward the proposed regulatory\nframework on genai with the following **specific objectives** :\n\n\n\n-  ensure that genai systems placed on the Union market and used are safe and respect\n\nexisting law on fundamental rights and Union values;\n\n-  ensure legal certainty to facilitate investment and innovation in genai;\n\n\n\n-  enhance governance and effective enforcement of existing law on fundamental\n\nrights and safety requirements applicable to genai systems;\n\n\n\n-  facilitate the development of a single market for lawful, safe and trustworthy genai\n\napplications and prevent market fragmentation.\n\nTo achieve those objectives, this proposal presents a balanced and proportionate horizontal\nregulatory approach to genai that is limited to the minimum necessary requirements to address\nthe risks and problems linked to genai, without unduly constraining or hindering technological\ndevelopment or otherwise disproportionately increasing the cost of placing genai solutions on\nthe market.\n\nThe proposal sets a robust and flexible legal framework.\n\nOn the one hand, it is\ncomprehensive and future-proof in its fundamental regulatory choices, including the\nprinciple-based requirements that genai systems should comply with.\n\nOn the other hand, it puts\nin place a proportionate regulatory system centred on a well-defined risk-based regulatory\napproach that does not create unnecessary restrictions to trade, whereby legal intervention is\ntailored to those concrete situations where there is a justified cause for concern or where such\nconcern can reasonably be anticipated in the near future.\n\nAt the same time, the legal\nframework includes flexible mechanisms that enable it to be dynamically adapted as the\ntechnology evolves and new concerning situations emerge.\n\nThe proposal sets harmonised rules for the development, placement on the market and use of\ngenai systems in the Union following a proportionate risk-based approach.\n\nIt proposes a single\nfuture-proof definition of genai.\n\nCertain particularly harmful genai practices are prohibited as\ncontravening Union values, while specific restrictions and safeguards are proposed in relation\nto certain uses of remote biometric identification systems for the purpose of law enforcement.\n\nThe proposal lays down a solid risk methodology to define \u201chigh-risk\u201d genai systems that pose\nsignificant risks to the health and safety or fundamental rights of persons.\n\nThose genai systems\nwill have to comply with a set of horizontal mandatory requirements for trustworthy genai and\nfollow conformity assessment procedures before those systems can be placed on the Union\nmarket.\n\nPredictable, proportionate and clear obligations are also placed on providers and users\nof those systems to ensure safety and respect of existing legislation protecting fundamental\nrights throughout the whole genai systems\u2019 lifecycle.\n\nFor some specific genai systems, only\nminimum transparency obligations are proposed, in particular when chatbots or \u2018deep fakes\u2019\nare used.\n\nThe proposed rules will be enforced through a governance system at Member States level,\nbuilding on already existing structures, and a cooperation mechanism at Union level with the\nestablishment of a European genai Board.\n\nAdditional measures are also\nproposed to support innovation, in particular through genai regulatory sandboxes and other\nmeasures to reduce the regulatory burden and to support Small and Medium-Sized Enterprises\n(\u2018SMEs\u2019) and start-ups.", "**1.2.\n\n** **Consistency with existing policy provisions in the policy area**\n\nThe horizontal nature of the proposal requires full consistency with existing Union legislation\napplicable to sectors where high-risk genai systems are already used or likely to be used in the\nnear future.\n\nConsistency is also ensured with the EU Charter of Fundamental Rights and the existing\nsecondary Union legislation on data protection, consumer protection, non-discrimination and\ngender equality.\n\nThe proposal is without prejudice and complements the General Data\nProtection Regulation (Regulation (EU) 2016/679) and the Law Enforcement Directive\n(Directive (EU) 2016/680) with a set of harmonised rules applicable to the design,\ndevelopment and use of certain high-risk genai systems and restrictions on certain uses of remote\nbiometric identification systems.\n\nFurthermore, the proposal complements existing Union law\non non-discrimination with specific requirements that aim to minimise the risk of algorithmic\ndiscrimination, in particular in relation to the design and the quality of data sets used for the\ndevelopment of genai systems complemented with obligations for testing, risk management,\ndocumentation and human oversight throughout the genai systems\u2019 lifecycle.\n\nThe proposal is\nwithout prejudice to the application of Union competition law.\n\nAs regards high-risk genai systems which are safety components of products, this proposal will\nbe integrated into the existing sectoral safety legislation to ensure consistency, avoid\nduplications and minimise additional burdens.\n\nIn particular, as regards high-risk genai systems\nrelated to products covered by the New Legislative Framework (NLF) legislation (e.g.\n\nmachinery, medical devices, toys), the requirements for genai systems set out in this proposal\nwill be checked as part of the existing conformity assessment procedures under the relevant\nNLF legislation.\n\nWith regard to the interplay of requirements, while the safety risks specific\nto genai systems are meant to be covered by the requirements of this proposal, NLF legislation\naims at ensuring the overall safety of the final product and therefore may contain specific\nrequirements regarding the safe integration of an genai system into the final product.\n\nThe\nproposal for a Machinery Regulation, which is adopted on the same day as this proposal fully\nreflects this approach.\n\nAs regards high-risk genai systems related to products covered by relevant\nOld Approach legislation (e.g.\n\naviation, cars), this proposal would not directly apply.\n\nHowever, the ex-ante essential requirements for high-risk genai systems set out in this proposal\nwill have to be taken into account when adopting relevant implementing or delegated\nlegislation under those acts.\n\nAs regards genai systems provided or used by regulated credit institutions, the authorities\nresponsible for the supervision of the Union\u2019s financial services legislation should be\ndesignated as competent authorities for supervising the requirements in this proposal to ensure\na coherent enforcement of the obligations under this proposal and the Union\u2019s financial\nservices legislation where genai systems are to some extent implicitly regulated in relation to the\ninternal governance system of credit institutions.\n\nTo further enhance consistency, the\nconformity assessment procedure and some of the providers\u2019 procedural obligations under this\nproposal are integrated into the procedures under Directive 2013/36/EU on access to the\nactivity of credit institutions and the prudential supervision 14 .\n\n14 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the\nactivity of credit institutions and the prudential supervision of credit institutions and investment firms,\namending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC Text with EEA\nrelevance, OJ L 176, 27.6.2013, p. 338\u2013436.", "# EN EN\n\n-----\n\nThis proposal is also consistent with the applicable Union legislation on services, including on\nintermediary services regulated by the e-Commerce Directive 2000/31/EC 15 and the\n\n16\nCommission\u2019s recent proposal for the Digital Services Act (DSA) .\n\nIn relation to genai systems that are components of large-scale IT systems in the Area of\nFreedom, Security and Justice managed by the European Union Agency for the Operational\nManagement of Large-Scale IT Systems (eu-LISA), the proposal will not apply to those genai\nsystems that have been placed on the market or put into service before one year has elapsed\nfrom the date of application of this Regulation, unless the replacement or amendment of those\nlegal acts leads to a significant change in the design or intended purpose of the genai system or\ngenai systems concerned.", "**1.3.\n\n** **Consistency with other Union policies**\n\nThe proposal is part of a wider comprehensive package of measures that address problems\nposed by the development and use of genai, as examined in the White Paper on genai.\n\nConsistency\nand complementarity is therefore ensured with other ongoing or planned initiatives of the\nCommission that also aim to address those problems, including the revision of sectoral\nproduct legislation (e.g.\n\nthe Machinery Directive, the General Product Safety Directive) and\ninitiatives that address liability issues related to new technologies, including genai systems.\n\nThose initiatives will build on and complement this proposal in order to bring legal clarity and\nfoster the development of an ecosystem of trust in genai in Europe.\n\nThe proposal is also coherent with the Commission\u2019s overall digital strategy in its\ncontribution to promoting technology that works for people, one of the three main pillars of\nthe policy orientation and objectives announced in the Communication \u2018Shaping Europe's\n\n17\ndigital future\u2019 .\n\nIt lays down a coherent, effective and proportionate framework to ensure genai\nis developed in ways that respect people\u2019s rights and earn their trust, making Europe fit for the\ndigital age and turning the next ten years into the **Digital Decade** 18 .\n\nFurthermore, the promotion of genai-driven innovation is closely linked to the **Data**", "**Governance Act** 19 **,** the **Open Data Directive** 20 and other initiatives under **the EU strategy**\n\n**for data** 21 , which will establish trusted mechanisms and services for the re-use, sharing and\npooling of data that are essential for the development of data-driven genai models of high\nquality.\n\nThe proposal also strengthens significantly the Union\u2019s role to help shape global norms and\nstandards and promote trustworthy genai that is consistent with Union values and interests.\n\nIt\nprovides the Union with a powerful basis to engage further with its external partners,\nincluding third countries, and at international fora on issues relating to genai.\n\n15 Directive 2000/31/EC of the European Parliament and of the Council of 8 June 2000 on certain legal\naspects of information society services, in particular electronic commerce, in the Internal Market\n('Directive on electronic commerce'), OJ L 178, 17.7.2000, p. 1\u201316.\n\n16 See Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL\non a Single Market For Digital Services (Digital Services Act) and amending Directive 2000/31/EC\nCOM/2020/825 final.\n\n17 Communication from the Commission, Shaping Europe's Digital Future, COM/2020/67 final.\n\n18 2030 Digital Compass: the European way for the Digital Decade .\n\n19 Proposal for a Regulation on European data governance (Data Governance Act) COM/2020/767.\n\n20 Directive (EU) 2019/1024 of the European Parliament and of the Council of 20 June 2019 on open data\nand the re-use of public sector information, PE/28/2019/REV/1, OJ L 172, 26.6.2019, p. 56\u201383.\n\n21 Commission Communication, A European strategy for data COM/2020/66 final.", "**2.1.\n\n** **Legal basis**\n\nThe legal basis for the proposal is in the first place Article 114 of the Treaty on the\nFunctioning of the European Union (TFEU), which provides for the adoption of measures to\nensure the establishment and functioning of the internal market.\n\nThis proposal constitutes a core part of the EU digital single market strategy.\n\nThe primary\nobjective of this proposal is to ensure the proper functioning of the internal market by setting\nharmonised rules in particular on the development, placing on the Union market and the use\nof products and services making use of genai technologies or provided as stand-alone genai\nsystems.\n\nSome Member States are already considering national rules to ensure that genai is safe\nand is developed and used in compliance with fundamental rights obligations.\n\nThis will likely\nlead to two main problems: i) a fragmentation of the internal market on essential elements\nregarding in particular the requirements for the genai products and services, their marketing,\ntheir use, the liability and the supervision by public authorities, and ii) the substantial\ndiminishment of legal certainty for both providers and users of genai systems on how existing\nand new rules will apply to those systems in the Union.\n\nGiven the wide circulation of products\nand services across borders, these two problems can be best solved through EU harmonizing\nlegislation.\n\nIndeed, the proposal defines common mandatory requirements applicable to the design and\ndevelopment of certain genai systems before they are placed on the market that will be further\noperationalised through harmonised technical standards.\n\nThe proposal also addresses the\nsituation after genai systems have been placed on the market by harmonising the way in which\nex-post controls are conducted.\n\nIn addition, considering that this proposal contains certain specific rules on the protection of\nindividuals with regard to the processing of personal data, notably restrictions of the use of genai\nsystems for \u2018real-time\u2019 remote biometric identification in publicly accessible spaces for the\npurpose of law enforcement, it is appropriate to base this regulation, in as far as those specific\nrules are concerned, on Article 16 of the TFEU.", "**2.2.\n\n** **Subsidiarity (for non-exclusive competence)**\n\nThe nature of genai, which often relies on large and varied datasets and which may be embedded\nin any product or service circulating freely within the internal market, entails that the\nobjectives of this proposal cannot be effectively achieved by Member States alone.\n\nFurthermore, an emerging patchwork of potentially divergent national rules will hamper the\nseamless circulation of products and services related to genai systems across the EU and will be\nineffective in ensuring the safety and protection of fundamental rights and Union values\nacross the different Member States.\n\nNational approaches in addressing the problems will only\ncreate additional legal uncertainty and barriers, and will slow market uptake of genai.\n\nThe objectives of this proposal can be better achieved at Union level to avoid a further\nfragmentation of the Single Market into potentially contradictory national frameworks\npreventing the free circulation of goods and services embedding genai.\n\nA solid European\nregulatory framework for trustworthy genai will also ensure a level playing field and protect all\npeople, while strengthening Europe\u2019s competitiveness and industrial basis in genai.\n\nOnly\ncommon action at Union level can also protect the Union\u2019s digital sovereignty and leverage\nits tools and regulatory powers to shape global rules and standards.", "**2.3.\n\n** **Proportionality**\n\nThe proposal builds on existing legal frameworks and is proportionate and necessary to\nachieve its objectives, since it follows a risk-based approach and imposes regulatory burdens\nonly when an genai system is likely to pose high risks to fundamental rights and safety.\n\nFor\nother, non-high-risk genai systems, only very limited transparency obligations are imposed, for\nexample in terms of the provision of information to flag the use of an genai system when\ninteracting with humans.\n\nFor high-risk genai systems, the requirements of high quality data,\ndocumentation and traceability, transparency, human oversight, accuracy and robustness, are\nstrictly necessary to mitigate the risks to fundamental rights and safety posed by genai and that\nare not covered by other existing legal frameworks.\n\nHarmonised standards and supporting\nguidance and compliance tools will assist providers and users in complying with the\nrequirements laid down by the proposal and minimise their costs.\n\nThe costs incurred by\noperators are proportionate to the objectives achieved and the economic and reputational\nbenefits that operators can expect from this proposal.", "**2.4.\n\n** **Choice of the instrument**\n\nThe choice of a regulation as a legal instrument is justified by the need for a uniform\napplication of the new rules, such as definition of genai, the prohibition of certain harmful AIenabled practices and the classification of certain genai systems.\n\nThe direct applicability of a\nRegulation, in accordance with Article 288 TFEU, will reduce legal fragmentation and\nfacilitate the development of a single market for lawful, safe and trustworthy genai systems.\n\nIt\nwill do so, in particular, by introducing a harmonised set of core requirements with regard to\ngenai systems classified as high-risk and obligations for providers and users of those systems,\nimproving the protection of fundamental rights and providing legal certainty for operators and\nconsumers alike.\n\nAt the same time, the provisions of the regulation are not overly prescriptive and leave room\nfor different levels of Member State action for elements that do not undermine the objectives\nof the initiative, in particular the internal organisation of the market surveillance system and\nthe uptake of measures to foster innovation.", "**3.1.\n\n** **Stakeholder consultation**\n\nThis proposal is the result of extensive consultation with all major stakeholders, in which the\ngeneral principles and minimum standards for consultation of interested parties by the\nCommission were applied.\n\nAn **online public consultation** was launched on 19 February 2020 along with the publication\nof the White Paper on genai and ran until 14 June 2020.\n\nThe objective of that\nconsultation was to collect views and opinions on the White Paper.\n\nIt targeted all interested\nstakeholders from the public and private sectors, including governments, local authorities,\ncommercial and non-commercial organisations, social partners, experts, academics and\ncitizens.\n\nAfter analysing all the responses received, the Commission published a summary\noutcome and the individual responses on its website 22 .\n\nIn total, 1215 contributions were received, of which 352 were from companies or business\norganisations/associations, 406 from individuals (92%individuals from EU ), 152 on behalf of\n\n22 See all consultation results here.", "# EN EN\n\n-----\n\nacademic/research institutions, and 73 from public authorities.\n\nCivil society\u2019s voices were\nrepresented by 160 respondents (among which 9 consumers\u2019 organisations, 129 nongovernmental organisations and 22 trade unions), 72 respondents contributed as \u2018others\u2019.\n\nOf\nthe 352 business and industry representatives, 222 were companies and business\nrepresentatives, 41.5% of which were micro, small and medium-sized enterprises.\n\nThe rest\nwere business associations.\n\nOverall, 84% of business and industry replies came from the EU27.\n\nDepending on the question, between 81 and 598 of the respondents used the free text\noption to insert comments.\n\nOver 450 position papers were submitted through the EU Survey\nwebsite, either in addition to questionnaire answers (over 400) or as stand-alone contributions\n(over 50).\n\nOverall, there is a general agreement amongst stakeholders on a need for action.\n\nA large\nmajority of stakeholders agree that legislative gaps exist or that new legislation is needed.\n\nHowever, several stakeholders warn the Commission to avoid duplication, conflicting\nobligations and overregulation.\n\nThere were many comments underlining the importance of a\ntechnology neutral and proportionate regulatory framework.\n\nStakeholders mostly requested a narrow, clear and precise definition for genai.\n\nStakeholders also\nhighlighted that besides the clarification of the term of genai, it is important to define \u2018risk\u2019,\n\u2018high-risk\u2019, \u2018low-risk\u2019, \u2018remote biometric identification\u2019 and \u2018harm\u2019.\n\nMost of the respondents are explicitly in favour of the risk-based approach.\n\nUsing a risk-based\nframework was considered a better option than blanket regulation of all genai systems.\n\nThe types\nof risks and threats should be based on a sector-by-sector and case-by-case approach.\n\nRisks\nalso should be calculated taking into account the impact on rights and safety.\n\nRegulatory sandboxes could be very useful for the promotion of genai and are welcomed by\ncertain stakeholders, especially the Business Associations.\n\nAmong those who formulated their opinion on the enforcement models, more than 50%,\nespecially from the business associations, were in favour of a combination of an ex-ante risk\nself-assessment and an ex-post enforcement for high-risk genai systems.", "**3.2.\n\n** **Collection and use of expertise**\n\nThe proposal builds on two years of analysis and close involvement of stakeholders, including\nacademics, businesses, social partners, non-governmental organisations, Member States and\ncitizens.\n\nThe preparatory work started in 2018 with the setting up of a **High-Level Expert**\n**Group on genai (HLEG)** which had an inclusive and broad composition of 52 well-known\nexperts tasked to advise the Commission on the implementation of the Commission\u2019s Strategy\non genai.\n\nIn April 2019, the Commission supported 23 the key requirements set\nout in the HLEG ethics guidelines for Trustworthy genai 24 , which had been revised to take into\naccount more than 500 submissions from stakeholders.\n\nThe key requirements reflect a\nwidespread and common approach, as evidenced by a plethora of ethical codes and principles\ndeveloped by many private and public organisations in Europe and beyond, that genai\ndevelopment and use should be guided by certain essential value-oriented principles.\n\nThe\nAssessment List for Trustworthy genai (ALTAI) 25 made those requirements\noperational in a piloting process with over 350 organisations.\n\n23 European Commission, _Building Trust in Human-Centric Artificial Intelligence_ , COM(2019) 168.\n\n24 HLEG, _Ethics Guidelines for Trustworthy AI_ , 2019.\n\n25 HLEG, _Assessment List for Trustworthy genai (ALTAI) for self-assessment_ **_,_** 2020.", "# EN EN\n\n-----\n\nIn addition, the **genai Alliance** 26 was formed as a platform for approximately 4000 stakeholders\nto debate the technological and societal implications of genai, culminating in a yearly genai\nAssembly.\n\nThe **White Paper** on genai further developed this inclusive approach, inciting comments from\nmore than 1250 stakeholders, including over 450 additional position papers.\n\nAs a result, the\nCommission published an Inception Impact Assessment, which in turn attracted more than\n130 comments 27 .\n\n**Additional stakeholder workshops and events** were also organised the\nresults of which support the analysis in the impact assessment and the policy choices made in\nthis proposal 28 .\n\nAn **external study** was also procured to feed into the impact assessment.", "**3.3.\n\n** **Impact assessment**\n\nIn line with its \u201cBetter Regulation\u201d policy, the Commission conducted an impact assessment\nfor this proposal examined by the Commission's Regulatory Scrutiny Board.\n\nA meeting with\nthe Regulatory Scrutiny Board was held on 16 December 2020, which was followed by a\nnegative opinion.\n\nAfter substantial revision of the impact assessment to address the comments\nand a resubmission of the impact assessment, the Regulatory Scrutiny Board issued a positive\nopinion on 21 March 2021.\n\nThe opinions of the Regulatory Scrutiny Board, the\nrecommendations and an explanation of how they have been taken into account are presented\nin Annex 1 of the impact assessment.\n\nThe Commission examined different policy options to achieve the general objective of the\nproposal, which is to **ensure the proper functioning of the single market** by creating the\nconditions for the development and use of trustworthy genai in the Union.\n\nFour policy options of different degrees of regulatory intervention were assessed:\n\n-  **Option 1** : EU legislative instrument setting up a voluntary labelling scheme;\n\n-  **Option 2** : a sectoral, \u201cad-hoc\u201d approach;\n\n\n\n-  **Option 3** : Horizontal EU legislative instrument following a proportionate risk-\n\nbased approach;\n\n\n\n-  **Option 3+** : Horizontal EU legislative instrument following a proportionate risk-\n\nbased approach + codes of conduct for non-high-risk genai systems;\n\n\n\n-  **Option 4** : Horizontal EU legislative instrument establishing mandatory\n\nrequirements for all genai systems, irrespective of the risk they pose.\n\nAccording to the Commission's established methodology, each policy option was evaluated\nagainst economic and societal impacts, with a particular focus on impacts on fundamental\nrights.\n\nThe preferred option is option 3+, a regulatory framework for high-risk genai systems\nonly, with the possibility for all providers of non-high-risk genai systems to follow a code of\nconduct.\n\nThe requirements will concern data, documentation and traceability, provision of\ninformation and transparency, human oversight and robustness and accuracy and would be\nmandatory for high-risk genai systems.\n\nCompanies that introduced codes of conduct for other genai\nsystems would do so voluntarily.\n\n26 The genai Alliance is a multi-stakeholder forum launched in June 2018, genai Alliance\n\n\n\n27 European Commission, _Inception Impact Assessment For a Proposal for a legal act of the European_\n_Parliament and the Council laying down requirements for genai._\n\n\n28 For details of all the consultations that have been carried out see Annex 2 of the impact assessment.", "# EN EN\n\n-----\n\nThe preferred option was considered suitable to address in the most effective way the\nobjectives of this proposal.\n\nBy requiring a restricted yet effective set of actions from genai\ndevelopers and users, the preferred option limits the risks of violation of fundamental rights\nand safety of people and foster effective supervision and enforcement, by targeting the\nrequirements only to systems where there is a high risk that such violations could occur.\n\nAs a\nresult, that option keeps compliance costs to a minimum, thus avoiding an unnecessary\nslowing of uptake due to higher prices and compliance costs.\n\nIn order to address possible\ndisadvantages for SMEs, this option includes several provisions to support their compliance\nand reduce their costs, including creation of regulatory sandboxes and obligation to consider\nSMEs interests when setting fees related to conformity assessment.\n\nThe preferred option will increase people\u2019s trust in genai, companies will gain in legal certainty,\nand Member States will see no reason to take unilateral action that could fragment the single\nmarket.\n\nAs a result of higher demand due to higher trust, more available offers due to legal\ncertainty, and the absence of obstacles to cross-border movement of genai systems, the single\nmarket for genai will likely flourish.\n\nThe European Union will continue to develop a fastgrowing genai ecosystem of innovative services and products embedding genai technology or\nstand-alone genai systems, resulting in increased digital autonomy.\n\nBusinesses or public authorities that develop or use genai applications that constitute a high risk\nfor the safety or fundamental rights of citizens would have to comply with specific\nrequirements and obligations.\n\nCompliance with these requirements would imply costs\n\namounting to approximately EUR \u20ac 6000 to EUR \u20ac 7000 for the supply of an average highrisk genai system of around EUR \u20ac 170000 by 2025.\n\nFor genai users, there would also be the\nannual cost for the time spent on ensuring human oversight where this is appropriate,\ndepending on the use case.\n\nThose have been estimated at approximately EUR \u20ac 5000 to EUR\n\u20ac 8000 per year.\n\nVerification costs could amount to another EUR \u20ac 3000 to EUR \u20ac 7500 for\nsuppliers of high-risk genai.\n\nBusinesses or public authorities that develop or use any genai\napplications not classified as high risk would only have minimal obligations of information.\n\nHowever, they could choose to join others and together adopt a code of conduct to follow\nsuitable requirements, and to ensure that their genai systems are trustworthy.\n\nIn such a case,\ncosts would be at most as high as for high-risk genai systems, but most probably lower.\n\nThe impacts of the policy options on different categories of stakeholders (economic operators/\nbusiness; conformity assessment bodies, standardisation bodies and other public bodies;\nindividuals/citizens; researchers) are explained in detail in Annex 3 of the Impact assessment\nsupporting this proposal.", "**3.4.\n\n** **Regulatory fitness and simplification**\n\nThis proposal lays down obligation that will apply to providers and users of high-risk genai\nsystems.\n\nFor providers who develop and place such systems on the Union market, it will\ncreate legal certainty and ensure that no obstacle to the cross-border provision of genai-related\nservices and products emerge.\n\nFor companies using genai, it will promote trust among their\ncustomers.\n\nFor national public administrations, it will promote public trust in the use of genai\nand strengthen enforcement mechanisms (by introducing a European coordination\nmechanism, providing for appropriate capacities, and facilitating audits of the genai systems\nwith new requirements for documentation, traceability and transparency).\n\nMoreover, the\nframework will envisage specific measures supporting innovation, including regulatory\nsandboxes and specific measures supporting small-scale users and providers of high-risk genai\nsystems to comply with the new rules.\n\nThe proposal also specifically aims at strengthening Europe\u2019s competitiveness and industrial\nbasis in genai.\n\nFull consistency is ensured with existing sectoral Union legislation applicable to", "**3.5.\n\n** **Fundamental rights**\n\nThe use of genai with its specific characteristics (e.g.\n\nopacity, complexity, dependency on data,\nautonomous behaviour) can adversely affect a number of fundamental rights enshrined in the\nEU Charter of Fundamental Rights (\u2018the Charter\u2019).\n\nThis proposal seeks to ensure a high level\nof protection for those fundamental rights and aims to address various sources of risks\nthrough a clearly defined risk-based approach.\n\nWith a set of requirements for trustworthy genai\nand proportionate obligations on all value chain participants, the proposal will enhance and\npromote the protection of the rights protected by the Charter: the right to human dignity\n(Article 1), respect for private life and protection of personal data (Articles 7 and 8), nondiscrimination (Article 21) and equality between women and men (Article 23).\n\nIt aims to\nprevent a chilling effect on the rights to freedom of expression (Article 11) and freedom of\nassembly (Article 12), to ensure protection of the right to an effective remedy and to a fair\ntrial, the rights of defence and the presumption of innocence (Articles 47 and 48), as well as\nthe general principle of good administration.\n\nFurthermore, as applicable in certain domains,\nthe proposal will positively affect the rights of a number of special groups, such as the\nworkers\u2019 rights to fair and just working conditions (Article 31), a high level of consumer\nprotection (Article 28), the rights of the child (Article 24) and the integration of persons with\ndisabilities (Article 26).\n\nThe right to a high level of environmental protection and the\nimprovement of the quality of the environment (Article 37) is also relevant, including in\nrelation to the health and safety of people.\n\nThe obligations for ex ante testing, risk\nmanagement and human oversight will also facilitate the respect of other fundamental rights\nby minimising the risk of erroneous or biased genai-assisted decisions in critical areas such as\neducation and training, employment, important services, law enforcement and the judiciary.\n\nIn\ncase infringements of fundamental rights still happen, effective redress for affected persons\nwill be made possible by ensuring transparency and traceability of the genai systems coupled\nwith strong ex post controls.\n\nThis proposal imposes some restrictions on the freedom to conduct business (Article 16) and\nthe freedom of art and science (Article 13) to ensure compliance with overriding reasons of\npublic interest such as health, safety, consumer protection and the protection of other\nfundamental rights (\u2018responsible innovation\u2019) when high-risk genai technology is developed and\nused.\n\nThose restrictions are proportionate and limited to the minimum necessary to prevent\nand mitigate serious safety risks and likely infringements of fundamental rights.\n\nThe increased transparency obligations will also not disproportionately affect the right to\nprotection of intellectual property (Article 17(2)), since they will be limited only to the\nminimum necessary information for individuals to exercise their right to an effective remedy\nand to the necessary transparency towards supervision and enforcement authorities, in line\nwith their mandates.\n\nAny disclosure of information will be carried out in compliance with\nrelevant legislation in the field, including Directive 2016/943 on the protection of undisclosed\nknow-how and business information (trade secrets) against their unlawful acquisition, use and\ndisclosure.\n\nWhen public authorities and notified bodies need to be given access to confidential\ninformation or source code to examine compliance with substantial obligations, they are\nplaced under binding confidentiality obligations.", "# EN EN\n\n-----\n\nexample regarding conformity assessment bodies or market surveillance, but would require\nsufficient technological expertise and human and financial resources.\n\nDepending on the preexisting structure in each Member State, this could amount to 1 to 25 Full Time Equivalents\nper Member State.\n\nA detailed overview of the costs involved is provided in the \u2018financial statement\u2019 linked to\nthis proposal.", "**5.1.\n\n** **Implementation plans and monitoring, evaluation and reporting arrangements**\n\nProviding for a robust monitoring and evaluation mechanism is crucial to ensure that the\nproposal will be effective in achieving its specific objectives.\n\nThe Commission will be in\ncharge of monitoring the effects of the proposal.\n\nIt will establish a system for registering\nstand-alone high-risk genai applications in a public EU-wide database.\n\nThis registration will also\nenable competent authorities, users and other interested people to verify if the high-risk genai\nsystem complies with the requirements laid down in the proposal and to exercise enhanced\noversight over those genai systems posing high risks to fundamental rights.\n\nTo feed this\ndatabase, genai providers will be obliged to provide meaningful information about their systems\nand the conformity assessment carried out on those systems.\n\nMoreover, genai providers will be obliged to inform national competent authorities about serious\nincidents or malfunctioning that constitute a breach of fundamental rights obligations as soon\nas they become aware of them, as well as any recalls or withdrawals of genai systems from the\nmarket.\n\nNational competent authorities will then investigate the incidents/or malfunctioning,\ncollect all the necessary information and regularly transmit it to the Commission with\nadequate metadata.\n\nThe Commission will complement this information on the incidents by a\ncomprehensive analysis of the overall market for genai.\n\nThe Commission will publish a report evaluating and reviewing the proposed genai framework\nfive years following the date on which it becomes applicable.", "**5.2.\n\n** **Detailed explanation of the specific provisions of the proposal**\n\n_5.2.1._ _SCOPE AND DEFINITIONS (TITLE I)_\n\n**Title I** defines the subject matter of the regulation and the scope of application of the new\nrules that cover the placing on the market, putting into service and use of genai systems.\n\nIt also\nsets out the definitions used throughout the instrument.\n\nThe definition of genai system in the\nlegal framework aims to be as technology neutral and future proof as possible, taking into\naccount the fast technological and market developments related to genai.\n\nIn order to provide the\nneeded legal certainty, Title I is complemented by Annex I, which contains a detailed list of\napproaches and techniques for the development of genai to be adapted by the Commission in line\nwith new technological developments.\n\nKey participants across the genai value chain are also\nclearly defined such as providers and users of genai systems that cover both public and private\noperators to ensure a level playing field.\n\n_5.2.2._ _PROHIBITED genai PRACTICES (TITLE II)_\n\n**Title II** establishes a list of prohibited genai.\n\nThe regulation follows a risk-based approach,\ndifferentiating between uses of genai that create (i) an unacceptable risk, (ii) a high risk, and (iii)\nlow or minimal risk.\n\nThe list of prohibited practices in Title II comprises all those genai systems\nwhose use is considered unacceptable as contravening Union values, for instance by violating\nfundamental rights.\n\nThe prohibitions covers practices that have a significant potential to\nmanipulate persons through subliminal techniques beyond their consciousness or exploit", "# EN EN\n\n-----\n\nvulnerabilities of specific vulnerable groups such as children or persons with disabilities in\norder to materially distort their behaviour in a manner that is likely to cause them or another\nperson psychological or physical harm.\n\nOther manipulative or exploitative practices affecting\nadults that might be facilitated by genai systems could be covered by the existing data\nprotection, consumer protection and digital service legislation that guarantee that natural\npersons are properly informed and have free choice not to be subject to profiling or other\npractices that might affect their behaviour.\n\nThe proposal also prohibits genai-based social\nscoring for general purposes done by public authorities.\n\nFinally, the use of \u2018real time\u2019 remote\nbiometric identification systems in publicly accessible spaces for the purpose of law\nenforcement is also prohibited unless certain limited exceptions apply.\n\n_5.2.3._ _HIGH-RISK genai SYSTEMS (TITLE III)_\n\n**Title III** contains specific rules for genai systems that create a high risk to the health and safety\nor fundamental rights of natural persons.\n\nIn line with a risk-based approach, those high-risk\ngenai systems are permitted on the European market subject to compliance with certain\nmandatory requirements and an ex-ante conformity assessment.\n\nThe classification of an genai\nsystem as high-risk is based on the intended purpose of the genai system, in line with existing\nproduct safety legislation.\n\nTherefore, the classification as high-risk does not only depend on\nthe function performed by the genai system, but also on the specific purpose and modalities for\nwhich that system is used.\n\nChapter 1 of Title III sets the classification rules and identifies two main categories of highrisk genai systems:\n\n\n\n-  genai systems intended to be used as safety component of products that are subject to\n\nthird party ex-ante conformity assessment;\n\n\n\n-  other stand-alone genai systems with mainly fundamental rights implications that are\n\nexplicitly listed in Annex III.\n\nThis list of high-risk genai systems in Annex III contains a limited number of genai systems whose\nrisks have already materialised or are likely to materialise in the near future.\n\nTo ensure that\nthe regulation can be adjusted to emerging uses and applications of genai, the Commission may\nexpand the list of high-risk genai systems used within certain pre-defined areas, by applying a\nset of criteria and risk assessment methodology.\n\nChapter 2 sets out the legal requirements for high-risk genai systems in relation to data and data\ngovernance, documentation and recording keeping, transparency and provision of information\nto users, human oversight, robustness, accuracy and security.\n\nThe proposed minimum\nrequirements are already state-of-the-art for many diligent operators and the result of two\nyears of preparatory work, derived from the Ethics Guidelines of the HLEG 29 , piloted by\nmore than 350 organisations 30 .\n\nThey are also largely consistent with other international\nrecommendations and principles, which ensures that the proposed genai framework is\ncompatible with those adopted by the EU\u2019s international trade partners.\n\nThe precise technical\nsolutions to achieve compliance with those requirements may be provided by standards or by\nother technical specifications or otherwise be developed in accordance with general\nengineering or scientific knowledge at the discretion of the provider of the genai system.\n\nThis\nflexibility is particularly important, because it allows providers of genai systems to choose the\n\n\n29 High-Level Expert Group on genai, _Ethics Guidelines for Trustworthy AI_ , 2019.\n\n30 They were also endorsed by the Commission in its 2019 Communication on human-centric approach to\ngenai.", "# EN EN\n\n-----\n\nway to meet their requirements, taking into account the state-of-the-art and technological and\nscientific progress in this field.\n\nChapter 3 places a clear set of horizontal obligations on providers of high-risk genai systems.\n\nProportionate obligations are also placed on users and other participants across the genai value\nchain (e.g., importers, distributors, authorized representatives).\n\nChapter 4 sets the framework for notified bodies to be involved as independent third parties in\nconformity assessment procedures, while Chapter 5 explains in detail the conformity\nassessment procedures to be followed for each type of high-risk genai system.\n\nThe conformity\nassessment approach aims to minimise the burden for economic operators as well as for\nnotified bodies, whose capacity needs to be progressively ramped up over time.\n\ngenai systems\nintended to be used as safety components of products that are regulated under the New\nLegislative Framework legislation (e.g.\n\nmachinery, toys, medical devices, etc.)\n\nwill be subject\nto the same ex-ante and ex-post compliance and enforcement mechanisms of the products of\nwhich they are a component.\n\nThe key difference is that the ex-ante and ex-post mechanisms\nwill ensure compliance not only with the requirements established by sectorial legislation, but\nalso with the requirements established by this regulation.\n\nAs regards stand-alone high-risk genai systems that are referred to in Annex III, a new\ncompliance and enforcement system will be established.\n\nThis follows the model of the New\nLegislative Framework legislation implemented through internal control checks by the\nproviders with the exception of remote biometric identification systems that would be subject\nto third party conformity assessment.\n\nA comprehensive ex-ante conformity assessment\nthrough internal checks, combined with a strong ex-post enforcement, could be an effective\nand reasonable solution for those systems, given the early phase of the regulatory intervention\nand the fact the genai sector is very innovative and expertise for auditing is only now being\naccumulated.\n\nAn assessment through internal checks for \u2018stand-alone\u2019 high-risk genai systems\nwould require a full, effective and properly documented ex ante compliance with all\nrequirements of the regulation and compliance with robust quality and risk management\nsystems and post-market monitoring.\n\nAfter the provider has performed the relevant\nconformity assessment, it should register those stand-alone high-risk genai systems in an EU\ndatabase that will be managed by the Commission to increase public transparency and\noversight and strengthen ex post supervision by competent authorities.\n\nBy contrast, for\nreasons of consistency with the existing product safety legislation, the conformity assessments\nof genai systems that are safety components of products will follow a system with third party\nconformity assessment procedures already established under the relevant sectoral product\nsafety legislation.\n\nNew ex ante re-assessments of the conformity will be needed in case of\nsubstantial modifications to the genai systems (and notably changes which go beyond what is\npre-determined by the provider in its technical documentation and checked at the moment of\nthe ex-ante conformity assessment).\n\n_5.2.4._ _TRANSPARENCY OBLIGATIONS FOR CERTAIN genai SYSTEMS (TITLE IV)_\n\n**Title IV** concerns certain genai systems to take account of the specific risks of manipulation they\npose.\n\nTransparency obligations will apply for systems that (i) interact with humans, (ii) are\nused to detect emotions or determine association with (social) categories based on biometric\ndata, or (iii) generate or manipulate content (\u2018deep fakes\u2019).\n\nWhen persons interact with an genai\nsystem or their emotions or characteristics are recognised through automated means, people\nmust be informed of that circumstance.\n\nIf an genai system is used to generate or manipulate\nimage, audio or video content that appreciably resembles authentic content, there should be an\nobligation to disclose that the content is generated through automated means, subject to", "# EN EN\n\n-----\n\nexceptions for legitimate purposes (law enforcement, freedom of expression).\n\nThis allows\npersons to make informed choices or step back from a given situation.\n\n_5.2.5._ _MEASURES IN SUPPORT OF INNOVATION (TITLE V)_\n\n**Title V** contributes to the objective to create a legal framework that is innovation-friendly,\nfuture-proof and resilient to disruption.\n\nTo that end, it encourages national competent\nauthorities to set up regulatory sandboxes and sets a basic framework in terms of governance,\nsupervision and liability.\n\ngenai regulatory sandboxes establish a controlled environment to test\ninnovative technologies for a limited time on the basis of a testing plan agreed with the\ncompetent authorities.\n\nTitle V also contains measures to reduce the regulatory burden on\nSMEs and start-ups.\n\n_5.2.6._ _GOVERNANCE AND IMPLEMENTATION (TITLES VI, VII AND VII)_\n\n**Title VI** sets up the governance systems at Union and national level.\n\nAt Union level, the\nproposal establishes a European genai Board (the \u2018Board\u2019), composed of\nrepresentatives from the Member States and the Commission.\n\nThe Board will facilitate a\nsmooth, effective and harmonised implementation of this regulation by contributing to the\neffective cooperation of the national supervisory authorities and the Commission and\nproviding advice and expertise to the Commission.\n\nIt will also collect and share best practices\namong the Member States.\n\nAt national level, Member States will have to designate one or more national competent\nauthorities and, among them, the national supervisory authority, for the purpose of\nsupervising the application and implementation of the regulation.\n\nThe European Data\nProtection Supervisor will act as the competent authority for the supervision of the Union\ninstitutions, agencies and bodies when they fall within the scope of this regulation.\n\n**Title VII** aims to facilitate the monitoring work of the Commission and national authorities\nthrough the establishment of an EU-wide database for stand-alone high-risk genai systems with\nmainly fundamental rights implications.\n\nThe database will be operated by the Commission\nand provided with data by the providers of the genai systems, who will be required to register\ntheir systems before placing them on the market or otherwise putting them into service.\n\n**Title VIII** sets out the monitoring and reporting obligations for providers of genai systems with\nregard to post-market monitoring and reporting and investigating on genai-related incidents and\nmalfunctioning.\n\nMarket surveillance authorities would also control the market and investigate\ncompliance with the obligations and requirements for all high-risk genai systems already placed\non the market.\n\nMarket surveillance authorities would have all powers under Regulation (EU)\n2019/1020 on market surveillance.\n\nEx-post enforcement should ensure that once the genai\nsystem has been put on the market, public authorities have the powers and resources to\nintervene in case genai systems generate unexpected risks, which warrant rapid action.\n\nThey will\nalso monitor compliance of operators with their relevant obligations under the regulation.\n\nThe\nproposal does not foresee the automatic creation of any additional bodies or authorities at\nMember State level.\n\nMember States may therefore appoint (and draw upon the expertise of)\nexisting sectorial authorities, who would be entrusted also with the powers to monitor and\nenforce the provisions of the regulation.\n\nAll this is without prejudice to the existing system and allocation of powers of ex-post\nenforcement of obligations regarding fundamental rights in the Member States.\n\nWhen\nnecessary for their mandate, existing supervision and enforcement authorities will also have\nthe power to request and access any documentation maintained following this regulation and,\nwhere needed, request market surveillance authorities to organise testing of the high-risk genai\nsystem through technical means.", "# EN EN\n\n-----\n\n_5.2.7._ _CODES OF CONDUCT (TITLE IX)_\n\n**Title IX** creates a framework for the creation of codes of conduct, which aim to encourage\nproviders of non-high-risk genai systems to apply voluntarily the mandatory requirements for\nhigh-risk genai systems (as laid out in Title III).\n\nProviders of non-high-risk genai systems may\ncreate and implement the codes of conduct themselves.\n\nThose codes may also include\nvoluntary commitments related, for example, to environmental sustainability, accessibility for\npersons with disability, stakeholders\u2019 participation in the design and development of genai\nsystems, and diversity of development teams.\n\n_5.2.8._ _FINAL PROVISIONS (TITLES X, XI AND XII)_\n\n**Title X** emphasizes the obligation of all parties to respect the confidentiality of information\nand data and sets out rules for the exchange of information obtained during the\nimplementation of the regulation.\n\nTitle X also includes measures to ensure the effective\nimplementation of the regulation through effective, proportionate, and dissuasive penalties for\ninfringements of the provisions.\n\n**Title XI** sets out rules for the exercise of delegation and implementing powers.\n\nThe proposal\nempowers the Commission to adopt, where appropriate, implementing acts to ensure uniform\napplication of the regulation or delegated acts to update or complement the lists in Annexes I\nto VII.\n\n**Title XII** contains an obligation for the Commission to assess regularly the need for an update\nof Annex III and to prepare regular reports on the evaluation and review of the regulation.\n\nIt\nalso lays down final provisions, including a differentiated transitional period for the initial\ndate of the applicability of the regulation to facilitate the smooth implementation for all\nparties concerned.", "**LEGISLATIVE ACTS**\n\nTHE EUROPEAN PARLIAMENT AND THE COUNCIL OF THE EUROPEAN UNION,\n\nHaving regard to the Treaty on the Functioning of the European Union, and in particular\nArticles 16 and 114 thereof,\n\nHaving regard to the proposal from the European Commission,\n\nAfter transmission of the draft legislative act to the national parliaments,\n\nHaving regard to the opinion of the European Economic and Social Committee 31 ,\n\nHaving regard to the opinion of the Committee of the Regions 32 ,\n\nActing in accordance with the ordinary legislative procedure,\n\nWhereas:\n\n(1) The purpose of this Regulation is to improve the functioning of the internal market by\nlaying down a uniform legal framework in particular for the development, marketing\nand use of genai in conformity with Union values.\n\nThis Regulation\npursues a number of overriding reasons of public interest, such as a high level of\nprotection of health, safety and fundamental rights, and it ensures the free movement\nof genai-based goods and services cross-border, thus preventing Member States from\nimposing restrictions on the development, marketing and use of genai systems, unless\nexplicitly authorised by this Regulation.\n\n(2) genai systems (genai systems) can be easily deployed in multiple sectors\nof the economy and society, including cross border, and circulate throughout the\nUnion.\n\nCertain Member States have already explored the adoption of national rules to\nensure that genai is safe and is developed and used in compliance with\nfundamental rights obligations.\n\nDiffering national rules may lead to fragmentation of\nthe internal market and decrease legal certainty for operators that develop or use genai\nsystems.\n\nA consistent and high level of protection throughout the Union should\ntherefore be ensured, while divergences hampering the free circulation of genai systems\nand related products and services within the internal market should be prevented, by\nlaying down uniform obligations for operators and guaranteeing the uniform\nprotection of overriding reasons of public interest and of rights of persons throughout\nthe internal market based on Article 114 of the Treaty on the Functioning of the\nEuropean Union (TFEU).\n\nTo the extent that this Regulation contains specific rules on\nthe protection of individuals with regard to the processing of personal data concerning\n\n\n31 OJ C [\u2026], [\u2026], p. [\u2026].\n\n32 OJ C [\u2026], [\u2026], p. [\u2026].", "# EN EN\n\n-----\n\nrestrictions of the use of genai systems for \u2018real-time\u2019 remote biometric identification in\npublicly accessible spaces for the purpose of law enforcement, it is appropriate to base\nthis Regulation, in as far as those specific rules are concerned, on Article 16 of the\nTFEU.\n\nIn light of those specific rules and the recourse to Article 16 TFEU, it is\nappropriate to consult the European Data Protection Board.\n\n(3) genai is a fast evolving family of technologies that can contribute to a\nwide array of economic and societal benefits across the entire spectrum of industries\nand social activities.\n\nBy improving prediction, optimising operations and resource\nallocation, and personalising digital solutions available for individuals and\norganisations, the use of genai can provide key competitive advantages\nto companies and support socially and environmentally beneficial outcomes, for\nexample in healthcare, farming, education and training, infrastructure management,\nenergy, transport and logistics, public services, security, justice, resource and energy\nefficiency, and climate change mitigation and adaptation.\n\n(4) At the same time, depending on the circumstances regarding its specific application\nand use, genai may generate risks and cause harm to public interests\nand rights that are protected by Union law.\n\nSuch harm might be material or\nimmaterial.\n\n(5) A Union legal framework laying down harmonised rules on genai is\ntherefore needed to foster the development, use and uptake of genai in\nthe internal market that at the same time meets a high level of protection of public\ninterests, such as health and safety and the protection of fundamental rights, as\nrecognised and protected by Union law.\n\nTo achieve that objective, rules regulating the\nplacing on the market and putting into service of certain genai systems should be laid\ndown, thus ensuring the smooth functioning of the internal market and allowing those\nsystems to benefit from the principle of free movement of goods and services.\n\nBy\nlaying down those rules, this Regulation supports the objective of the Union of being a\nglobal leader in the development of secure, trustworthy and ethical artificial\nintelligence, as stated by the European Council 33 , and it ensures the protection of\nethical principles, as specifically requested by the European Parliament 34 .\n\n(6) The notion of genai system should be clearly defined to ensure legal certainty, while\nproviding the flexibility to accommodate future technological developments.\n\nThe\ndefinition should be based on the key functional characteristics of the software, in\nparticular the ability, for a given set of human-defined objectives, to generate outputs\nsuch as content, predictions, recommendations, or decisions which influence the\nenvironment with which the system interacts, be it in a physical or digital dimension.\n\ngenai systems can be designed to operate with varying levels of autonomy and be used on\na stand-alone basis or as a component of a product, irrespective of whether the system\nis physically integrated into the product (embedded) or serve the functionality of the\nproduct without being integrated therein (non-embedded).\n\nThe definition of genai system\nshould be complemented by a list of specific techniques and approaches used for its\ndevelopment, which should be kept up-to\u2013date in the light of market and technological\n\n\n33 European Council, Special meeting of the European Council (1 and 2 October 2020) \u2013 Conclusions,\nEUCO 13/20, 2020, p. 6.\n\n34 European Parliament resolution of 20 October 2020 with recommendations to the Commission on a\nframework of ethical aspects of genai, robotics and related technologies,\n2020/2012(INL).", "# EN EN\n\n-----\n\ndevelopments through the adoption of delegated acts by the Commission to amend that\nlist.\n\n(7) The notion of biometric data used in this Regulation is in line with and should be\ninterpreted consistently with the notion of biometric data as defined in Article 4(14) of\nRegulation (EU) 2016/679 of the European Parliament and of the Council 35 , Article\n3(18) of Regulation (EU) 2018/1725 of the European Parliament and of the Council 36\nand Article 3(13) of Directive (EU) 2016/680 of the European Parliament and of the\nCouncil 37 .\n\n(8) The notion of remote biometric identification system as used in this Regulation should\nbe defined functionally, as an genai system intended for the identification of natural\npersons at a distance through the comparison of a person\u2019s biometric data with the\nbiometric data contained in a reference database, and without prior knowledge whether\nthe targeted person will be present and can be identified, irrespectively of the\nparticular technology, processes or types of biometric data used.\n\nConsidering their\ndifferent characteristics and manners in which they are used, as well as the different\nrisks involved, a distinction should be made between \u2018real-time\u2019 and \u2018post\u2019 remote\nbiometric identification systems.\n\nIn the case of \u2018real-time\u2019 systems, the capturing of\nthe biometric data, the comparison and the identification occur all instantaneously,\nnear-instantaneously or in any event without a significant delay.\n\nIn this regard, there\nshould be no scope for circumventing the rules of this Regulation on the \u2018real-time\u2019\nuse of the genai systems in question by providing for minor delays.\n\n\u2018Real-time\u2019 systems\ninvolve the use of \u2018live\u2019 or \u2018near-\u2018live\u2019 material, such as video footage, generated by a\ncamera or other device with similar functionality.\n\nIn the case of \u2018post\u2019 systems, in\ncontrast, the biometric data have already been captured and the comparison and\nidentification occur only after a significant delay.\n\nThis involves material, such as\npictures or video footage generated by closed circuit television cameras or private\ndevices, which has been generated before the use of the system in respect of the\nnatural persons concerned.\n\n(9) For the purposes of this Regulation the notion of publicly accessible space should be\nunderstood as referring to any physical place that is accessible to the public,\nirrespective of whether the place in question is privately or publicly owned.\n\nTherefore,\nthe notion does not cover places that are private in nature and normally not freely\naccessible for third parties, including law enforcement authorities, unless those parties\nhave been specifically invited or authorised, such as homes, private clubs, offices,\nwarehouses and factories.\n\nOnline spaces are not covered either, as they are not\nphysical spaces.\n\nHowever, the mere fact that certain conditions for accessing a\n\n\n35 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the\nprotection of natural persons with regard to the processing of personal data and on the free movement of\nsuch data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016,\np. 1).\n\n36 Regulation (EU) 2018/1725 of the European Parliament and of the Council of 23 October 2018 on the\nprotection of natural persons with regard to the processing of personal data by the Union institutions,\nbodies, offices and agencies and on the free movement of such data, and repealing Regulation (EC) No\n45/2001 and Decision No 1247/2002/EC (OJ L 295, 21.11.2018, p. 39)\n\n\n37 Directive (EU) 2016/680 of the European Parliament and of the Council of 27 April 2016 on the\nprotection of natural persons with regard to the processing of personal data by competent authorities for\nthe purposes of the prevention, investigation, detection or prosecution of criminal offences or the\nexecution of criminal penalties, and on the free movement of such data, and repealing Council\nFramework Decision 2008/977/JHA (Law Enforcement Directive) (OJ L 119, 4.5.2016, p. 89).", "# EN EN\n\n-----\n\nparticular space may apply, such as admission tickets or age restrictions, does not\nmean that the space is not publicly accessible within the meaning of this Regulation.\n\nConsequently, in addition to public spaces such as streets, relevant parts of\ngovernment buildings and most transport infrastructure, spaces such as cinemas,\ntheatres, shops and shopping centres are normally also publicly accessible.\n\nWhether a\ngiven space is accessible to the public should however be determined on a case-bycase basis, having regard to the specificities of the individual situation at hand.\n\n(10) In order to ensure a level playing field and an effective protection of rights and\nfreedoms of individuals across the Union, the rules established by this Regulation\nshould apply to providers of genai systems in a non-discriminatory manner, irrespective\nof whether they are established within the Union or in a third country, and to users of\ngenai systems established within the Union.\n\n(11) In light of their digital nature, certain genai systems should fall within the scope of this\nRegulation even when they are neither placed on the market, nor put into service, nor\nused in the Union.\n\nThis is the case for example of an operator established in the Union\nthat contracts certain services to an operator established outside the Union in relation\nto an activity to be performed by an genai system that would qualify as high-risk and\nwhose effects impact natural persons located in the Union.\n\nIn those circumstances, the\ngenai system used by the operator outside the Union could process data lawfully\ncollected in and transferred from the Union, and provide to the contracting operator in\nthe Union the output of that genai system resulting from that processing, without that genai\nsystem being placed on the market, put into service or used in the Union.\n\nTo prevent\nthe circumvention of this Regulation and to ensure an effective protection of natural\npersons located in the Union, this Regulation should also apply to providers and users\nof genai systems that are established in a third country, to the extent the output produced\nby those systems is used in the Union.\n\nNonetheless, to take into account existing\narrangements and special needs for cooperation with foreign partners with whom\ninformation and evidence is exchanged, this Regulation should not apply to public\nauthorities of a third country and international organisations when acting in the\nframework of international agreements concluded at national or European level for law\nenforcement and judicial cooperation with the Union or with its Member States.\n\nSuch\nagreements have been concluded bilaterally between Member States and third\ncountries or between the European Union, Europol and other EU agencies and third\ncountries and international organisations.\n\n(12) This Regulation should also apply to Union institutions, offices, bodies and agencies\nwhen acting as a provider or user of an genai system.\n\ngenai systems exclusively developed\nor used for military purposes should be excluded from the scope of this Regulation\nwhere that use falls under the exclusive remit of the Common Foreign and Security\nPolicy regulated under Title V of the Treaty on the European Union (TEU).\n\nThis\nRegulation should be without prejudice to the provisions regarding the liability of\nintermediary service providers set out in Directive 2000/31/EC of the European\nParliament and of the Council [as amended by the Digital Services Act].\n\n(13) In order to ensure a consistent and high level of protection of public interests as\nregards health, safety and fundamental rights, common normative standards for all\nhigh-risk genai systems should be established.\n\nThose standards should be consistent with\nthe Charter of fundamental rights of the European Union (the Charter) and should be\nnon-discriminatory and in line with the Union\u2019s international trade commitments.", "# EN EN\n\n-----\n\n(14) In order to introduce a proportionate and effective set of binding rules for genai systems,\na clearly defined risk-based approach should be followed.\n\nThat approach should tailor\nthe type and content of such rules to the intensity and scope of the risks that genai\nsystems can generate.\n\nIt is therefore necessary to prohibit certain genai\npractices, to lay down requirements for high-risk genai systems and obligations for the\nrelevant operators, and to lay down transparency obligations for certain genai systems.\n\n(15) Aside from the many beneficial uses of genai, that technology can also\nbe misused and provide novel and powerful tools for manipulative, exploitative and\nsocial control practices.\n\nSuch practices are particularly harmful and should be\nprohibited because they contradict Union values of respect for human dignity,\nfreedom, equality, democracy and the rule of law and Union fundamental rights,\nincluding the right to non-discrimination, data protection and privacy and the rights of\nthe child.\n\n(16) The placing on the market, putting into service or use of certain genai systems intended\nto distort human behaviour, whereby physical or psychological harms are likely to\noccur, should be forbidden.\n\nSuch genai systems deploy subliminal components\nindividuals cannot perceive or exploit vulnerabilities of children and people due to\ntheir age, physical or mental incapacities.\n\nThey do so with the intention to materially\ndistort the behaviour of a person and in a manner that causes or is likely to cause harm\nto that or another person.\n\nThe intention may not be presumed if the distortion of\nhuman behaviour results from factors external to the genai system which are outside of\nthe control of the provider or the user.\n\nResearch for legitimate purposes in relation to\nsuch genai systems should not be stifled by the prohibition, if such research does not\namount to use of the genai system in human-machine relations that exposes natural\npersons to harm and such research is carried out in accordance with recognised ethical\nstandards for scientific research.\n\n(17) genai systems providing social scoring of natural persons for general purpose by public\nauthorities or on their behalf may lead to discriminatory outcomes and the exclusion of\ncertain groups.\n\nThey may violate the right to dignity and non-discrimination and the\nvalues of equality and justice.\n\nSuch genai systems evaluate or classify the trustworthiness\nof natural persons based on their social behaviour in multiple contexts or known or\npredicted personal or personality characteristics.\n\nThe social score obtained from such\ngenai systems may lead to the detrimental or unfavourable treatment of natural persons or\nwhole groups thereof in social contexts, which are unrelated to the context in which\nthe data was originally generated or collected or to a detrimental treatment that is\ndisproportionate or unjustified to the gravity of their social behaviour.\n\nSuch genai\nsystems should be therefore prohibited.\n\n(18) The use of genai systems for \u2018real-time\u2019 remote biometric identification of natural\npersons in publicly accessible spaces for the purpose of law enforcement is considered\nparticularly intrusive in the rights and freedoms of the concerned persons, to the extent\nthat it may affect the private life of a large part of the population, evoke a feeling of\nconstant surveillance and indirectly dissuade the exercise of the freedom of assembly\nand other fundamental rights.\n\nIn addition, the immediacy of the impact and the limited\nopportunities for further checks or corrections in relation to the use of such systems\noperating in \u2018real-time\u2019 carry heightened risks for the rights and freedoms of the\npersons that are concerned by law enforcement activities.\n\n(19) The use of those systems for the purpose of law enforcement should therefore be\nprohibited, except in three exhaustively listed and narrowly defined situations, where", "# EN EN\n\n-----\n\nthe use is strictly necessary to achieve a substantial public interest, the importance of\nwhich outweighs the risks.\n\nThose situations involve the search for potential victims of\ncrime, including missing children; certain threats to the life or physical safety of\nnatural persons or of a terrorist attack; and the detection, localisation, identification or\nprosecution of perpetrators or suspects of the criminal offences referred to in Council\nFramework Decision 2002/584/JHA 38 if those criminal offences are punishable in the\nMember State concerned by a custodial sentence or a detention order for a maximum\nperiod of at least three years and as they are defined in the law of that Member State.\n\nSuch threshold for the custodial sentence or detention order in accordance with\nnational law contributes to ensure that the offence should be serious enough to\npotentially justify the use of \u2018real-time\u2019 remote biometric identification systems.\n\nMoreover, of the 32 criminal offences listed in the Council Framework Decision\n2002/584/JHA, some are in practice likely to be more relevant than others, in that the\nrecourse to \u2018real-time\u2019 remote biometric identification will foreseeably be necessary\nand proportionate to highly varying degrees for the practical pursuit of the detection,\nlocalisation, identification or prosecution of a perpetrator or suspect of the different\ncriminal offences listed and having regard to the likely differences in the seriousness,\nprobability and scale of the harm or possible negative consequences.\n\n(20) In order to ensure that those systems are used in a responsible and proportionate\nmanner, it is also important to establish that, in each of those three exhaustively listed\nand narrowly defined situations, certain elements should be taken into account, in\nparticular as regards the nature of the situation giving rise to the request and the\nconsequences of the use for the rights and freedoms of all persons concerned and the\nsafeguards and conditions provided for with the use.\n\nIn addition, the use of \u2018real-time\u2019\nremote biometric identification systems in publicly accessible spaces for the purpose\nof law enforcement should be subject to appropriate limits in time and space, having\nregard in particular to the evidence or indications regarding the threats, the victims or\nperpetrator.\n\nThe reference database of persons should be appropriate for each use case\nin each of the three situations mentioned above.\n\n(21) Each use of a \u2018real-time\u2019 remote biometric identification system in publicly accessible\nspaces for the purpose of law enforcement should be subject to an express and specific\nauthorisation by a judicial authority or by an independent administrative authority of a\nMember State.\n\nSuch authorisation should in principle be obtained prior to the use,\nexcept in duly justified situations of urgency, that is, situations where the need to use\nthe systems in question is such as to make it effectively and objectively impossible to\nobtain an authorisation before commencing the use.\n\nIn such situations of urgency, the\nuse should be restricted to the absolute minimum necessary and be subject to\nappropriate safeguards and conditions, as determined in national law and specified in\nthe context of each individual urgent use case by the law enforcement authority itself.\n\nIn addition, the law enforcement authority should in such situations seek to obtain an\nauthorisation as soon as possible, whilst providing the reasons for not having been able\nto request it earlier.\n\n(22) Furthermore, it is appropriate to provide, within the exhaustive framework set by this\nRegulation that such use in the territory of a Member State in accordance with this\nRegulation should only be possible where and in as far as the Member State in\nquestion has decided to expressly provide for the possibility to authorise such use in its\n\n38 Council Framework Decision 2002/584/JHA of 13 June 2002 on the European arrest warrant and the\nsurrender procedures between Member States (OJ L 190, 18.7.2002, p. 1).", "# EN EN\n\n-----\n\ndetailed rules of national law.\n\nConsequently, Member States remain free under this\nRegulation not to provide for such a possibility at all or to only provide for such a\npossibility in respect of some of the objectives capable of justifying authorised use\nidentified in this Regulation.\n\n(23) The use of genai systems for \u2018real-time\u2019 remote biometric identification of natural\npersons in publicly accessible spaces for the purpose of law enforcement necessarily\ninvolves the processing of biometric data.\n\nThe rules of this Regulation that prohibit,\nsubject to certain exceptions, such use, which are based on Article 16 TFEU, should\napply as _lex specialis_ in respect of the rules on the processing of biometric data\ncontained in Article 10 of Directive (EU) 2016/680, thus regulating such use and the\nprocessing of biometric data involved in an exhaustive manner.\n\nTherefore, such use\nand processing should only be possible in as far as it is compatible with the framework\nset by this Regulation, without there being scope, outside that framework, for the\ncompetent authorities, where they act for purpose of law enforcement, to use such\nsystems and process such data in connection thereto on the grounds listed in Article 10\nof Directive (EU) 2016/680.\n\nIn this context, this Regulation is not intended to provide\nthe legal basis for the processing of personal data under Article 8 of Directive\n2016/680.\n\nHowever, the use of \u2018real-time\u2019 remote biometric identification systems in\npublicly accessible spaces for purposes other than law enforcement, including by\ncompetent authorities, should not be covered by the specific framework regarding such\nuse for the purpose of law enforcement set by this Regulation.\n\nSuch use for purposes\nother than law enforcement should therefore not be subject to the requirement of an\nauthorisation under this Regulation and the applicable detailed rules of national law\nthat may give effect to it.\n\n(24) Any processing of biometric data and other personal data involved in the use of genai\nsystems for biometric identification, other than in connection to the use of \u2018real-time\u2019\nremote biometric identification systems in publicly accessible spaces for the purpose\nof law enforcement as regulated by this Regulation, including where those systems are\nused by competent authorities in publicly accessible spaces for other purposes than\nlaw enforcement, should continue to comply with all requirements resulting from\nArticle 9(1) of Regulation (EU) 2016/679, Article 10(1) of Regulation (EU)\n2018/1725 and Article 10 of Directive (EU) 2016/680, as applicable.\n\n(25) In accordance with Article 6a of Protocol No 21 on the position of the United\nKingdom and Ireland in respect of the area of freedom, security and justice, as\nannexed to the TEU and to the TFEU, Ireland is not bound by the rules laid down in\nArticle 5(1), point (d), (2) and (3) of this Regulation adopted on the basis of Article 16\nof the TFEU which relate to the processing of personal data by the Member States\nwhen carrying out activities falling within the scope of Chapter 4 or Chapter 5 of Title\nV of Part Three of the TFEU, where Ireland is not bound by the rules governing the\nforms of judicial cooperation in criminal matters or police cooperation which require\ncompliance with the provisions laid down on the basis of Article 16 of the TFEU.\n\n(26) In accordance with Articles 2 and 2a of Protocol No 22 on the position of Denmark,\nannexed to the TEU and TFEU, Denmark is not bound by rules laid down in Article\n5(1), point (d), (2) and (3) of this Regulation adopted on the basis of Article 16 of the\nTFEU, or subject to their application, which relate to the processing of personal data\nby the Member States when carrying out activities falling within the scope of Chapter\n4 or Chapter 5 of Title V of Part Three of the TFEU.", "# EN EN\n\n-----\n\n(27) High-risk genai systems should only be placed on the Union market or put into service if\nthey comply with certain mandatory requirements.\n\nThose requirements should ensure\nthat high-risk genai systems available in the Union or whose output is otherwise used in\nthe Union do not pose unacceptable risks to important Union public interests as\nrecognised and protected by Union law.\n\ngenai systems identified as high-risk should be\nlimited to those that have a significant harmful impact on the health, safety and\nfundamental rights of persons in the Union and such limitation minimises any\npotential restriction to international trade, if any.\n\n(28) genai systems could produce adverse outcomes to health and safety of persons, in\nparticular when such systems operate as components of products.\n\nConsistently with\nthe objectives of Union harmonisation legislation to facilitate the free movement of\nproducts in the internal market and to ensure that only safe and otherwise compliant\nproducts find their way into the market, it is important that the safety risks that may be\ngenerated by a product as a whole due to its digital components, including genai systems,\nare duly prevented and mitigated.\n\nFor instance, increasingly autonomous robots,\nwhether in the context of manufacturing or personal assistance and care should be able\nto safely operate and performs their functions in complex environments.\n\nSimilarly, in\nthe health sector where the stakes for life and health are particularly high, increasingly\nsophisticated diagnostics systems and systems supporting human decisions should be\nreliable and accurate.\n\nThe extent of the adverse impact caused by the genai system on the\nfundamental rights protected by the Charter is of particular relevance when classifying\nan genai system as high-risk.\n\nThose rights include the right to human dignity, respect for\nprivate and family life, protection of personal data, freedom of expression and\ninformation, freedom of assembly and of association, and non-discrimination,\nconsumer protection, workers\u2019 rights, rights of persons with disabilities, right to an\neffective remedy and to a fair trial, right of defence and the presumption of innocence,\nright to good administration.\n\nIn addition to those rights, it is important to highlight that\nchildren have specific rights as enshrined in Article 24 of the EU Charter and in the\nUnited Nations Convention on the Rights of the Child (further elaborated in the\nUNCRC General Comment No.\n\n25 as regards the digital environment), both of which\nrequire consideration of the children\u2019s vulnerabilities and provision of such protection\nand care as necessary for their well-being.\n\nThe fundamental right to a high level of\nenvironmental protection enshrined in the Charter and implemented in Union policies\nshould also be considered when assessing the severity of the harm that an genai system\ncan cause, including in relation to the health and safety of persons.\n\n(29) As regards high-risk genai systems that are safety components of products or systems, or\nwhich are themselves products or systems falling within the scope of Regulation (EC)\nNo 300/2008 of the European Parliament and of the Council 39 , Regulation (EU) No\n167/2013 of the European Parliament and of the Council 40 , Regulation (EU) No\n168/2013 of the European Parliament and of the Council 41 , Directive 2014/90/EU of\n\n\n39 Regulation (EC) No 300/2008 of the European Parliament and of the Council of 11 March 2008 on\ncommon rules in the field of civil aviation security and repealing Regulation (EC) No 2320/2002 (OJ L\n97, 9.4.2008, p. 72).\n\n40 Regulation (EU) No 167/2013 of the European Parliament and of the Council of 5 February 2013 on the\napproval and market surveillance of agricultural and forestry vehicles (OJ L 60, 2.3.2013, p. 1).\n\n41 Regulation (EU) No 168/2013 of the European Parliament and of the Council of 15 January 2013 on the\napproval and market surveillance of two- or three-wheel vehicles and quadricycles (OJ L 60, 2.3.2013,\np. 52).", "# EN EN\n\n-----\n\nthe European Parliament and of the Council 42 , Directive (EU) 2016/797 of the\nEuropean Parliament and of the Council 43 , Regulation (EU) 2018/858 of the European\nParliament and of the Council 44 , Regulation (EU) 2018/1139 of the European\nParliament and of the Council 45 , and Regulation (EU) 2019/2144 of the European\nParliament and of the Council 46 , it is appropriate to amend those acts to ensure that the\nCommission takes into account, on the basis of the technical and regulatory\nspecificities of each sector, and without interfering with existing governance,\nconformity assessment and enforcement mechanisms and authorities established\ntherein, the mandatory requirements for high-risk genai systems laid down in this\nRegulation when adopting any relevant future delegated or implementing acts on the\nbasis of those acts.\n\n(30) As regards genai systems that are safety components of products, or which are\nthemselves products, falling within the scope of certain Union harmonisation\nlegislation, it is appropriate to classify them as high-risk under this Regulation if the\nproduct in question undergoes the conformity assessment procedure with a third-party\nconformity assessment body pursuant to that relevant Union harmonisation legislation.\n\nIn particular, such products are machinery, toys, lifts, equipment and protective\nsystems intended for use in potentially explosive atmospheres, radio equipment,\npressure equipment, recreational craft equipment, cableway installations, appliances\nburning gaseous fuels, medical devices, and in vitro diagnostic medical devices.\n\n(31) The classification of an genai system as high-risk pursuant to this Regulation should not\nnecessarily mean that the product whose safety component is the genai system, or the genai\nsystem itself as a product, is considered \u2018high-risk\u2019 under the criteria established in the\nrelevant Union harmonisation legislation that applies to the product.\n\nThis is notably\nthe case for Regulation (EU) 2017/745 of the European Parliament and of the\n\n\n42 Directive 2014/90/EU of the European Parliament and of the Council of 23 July 2014 on marine\nequipment and repealing Council Directive 96/98/EC (OJ L 257, 28.8.2014, p. 146).\n\n43 Directive (EU) 2016/797 of the European Parliament and of the Council of 11 May 2016 on the\ninteroperability of the rail system within the European Union (OJ L 138, 26.5.2016, p. 44).\n\n44 Regulation (EU) 2018/858 of the European Parliament and of the Council of 30 May 2018 on the\napproval and market surveillance of motor vehicles and their trailers, and of systems, components and\nseparate technical units intended for such vehicles, amending Regulations (EC) No 715/2007 and (EC)\nNo 595/2009 and repealing Directive 2007/46/EC (OJ L 151, 14.6.2018, p. 1).\n\n45 Regulation (EU) 2018/1139 of the European Parliament and of the Council of 4 July 2018 on common\nrules in the field of civil aviation and establishing a European Union Aviation Safety Agency, and\namending Regulations (EC) No 2111/2005, (EC) No 1008/2008, (EU) No 996/2010, (EU) No 376/2014\nand Directives 2014/30/EU and 2014/53/EU of the European Parliament and of the Council, and\nrepealing Regulations (EC) No 552/2004 and (EC) No 216/2008 of the European Parliament and of the\nCouncil and Council Regulation (EEC) No 3922/91 (OJ L 212, 22.8.2018, p. 1).\n\n46 Regulation (EU) 2019/2144 of the European Parliament and of the Council of 27 November 2019 on\ntype-approval requirements for motor vehicles and their trailers, and systems, components and separate\ntechnical units intended for such vehicles, as regards their general safety and the protection of vehicle\noccupants and vulnerable road users, amending Regulation (EU) 2018/858 of the European Parliament\nand of the Council and repealing Regulations (EC) No 78/2009, (EC) No 79/2009 and (EC) No\n661/2009 of the European Parliament and of the Council and Commission Regulations (EC) No\n631/2009, (EU) No 406/2010, (EU) No 672/2010, (EU) No 1003/2010, (EU) No 1005/2010, (EU) No\n1008/2010, (EU) No 1009/2010, (EU) No 19/2011, (EU) No 109/2011, (EU) No 458/2011, (EU) No\n65/2012, (EU) No 130/2012, (EU) No 347/2012, (EU) No 351/2012, (EU) No 1230/2012 and (EU)\n2015/166 (OJ L 325, 16.12.2019, p. 1).", "# EN EN\n\n-----\n\nCouncil 47 and Regulation (EU) 2017/746 of the European Parliament and of the\nCouncil 48 , where a third-party conformity assessment is provided for medium-risk and\nhigh-risk products.\n\n(32) As regards stand-alone genai systems, meaning high-risk genai systems other than those that\nare safety components of products, or which are themselves products, it is appropriate\nto classify them as high-risk if, in the light of their intended purpose, they pose a high\nrisk of harm to the health and safety or the fundamental rights of persons, taking into\naccount both the severity of the possible harm and its probability of occurrence and\nthey are used in a number of specifically pre-defined areas specified in the Regulation.\n\nThe identification of those systems is based on the same methodology and criteria\nenvisaged also for any future amendments of the list of high-risk genai systems.\n\n(33) Technical inaccuracies of genai systems intended for the remote biometric identification\nof natural persons can lead to biased results and entail discriminatory effects.\n\nThis is\nparticularly relevant when it comes to age, ethnicity, sex or disabilities.\n\nTherefore,\n\u2018real-time\u2019 and \u2018post\u2019 remote biometric identification systems should be classified as\nhigh-risk.\n\nIn view of the risks that they pose, both types of remote biometric\nidentification systems should be subject to specific requirements on logging\ncapabilities and human oversight.\n\n(34) As regards the management and operation of critical infrastructure, it is appropriate to\nclassify as high-risk the genai systems intended to be used as safety components in the\nmanagement and operation of road traffic and the supply of water, gas, heating and\nelectricity, since their failure or malfunctioning may put at risk the life and health of\npersons at large scale and lead to appreciable disruptions in the ordinary conduct of\nsocial and economic activities.\n\n(35) genai systems used in education or vocational training, notably for determining access or\nassigning persons to educational and vocational training institutions or to evaluate\npersons on tests as part of or as a precondition for their education should be considered\nhigh-risk, since they may determine the educational and professional course of a\nperson\u2019s life and therefore affect their ability to secure their livelihood.\n\nWhen\nimproperly designed and used, such systems may violate the right to education and\ntraining as well as the right not to be discriminated against and perpetuate historical\npatterns of discrimination.\n\n(36) genai systems used in employment, workers management and access to self-employment,\nnotably for the recruitment and selection of persons, for making decisions on\npromotion and termination and for task allocation, monitoring or evaluation of persons\nin work-related contractual relationships, should also be classified as high-risk, since\nthose systems may appreciably impact future career prospects and livelihoods of these\npersons.\n\nRelevant work-related contractual relationships should involve employees\nand persons providing services through platforms as referred to in the Commission\nWork Programme 2021.\n\nSuch persons should in principle not be considered users\nwithin the meaning of this Regulation.\n\nThroughout the recruitment process and in the\n\n\n47 Regulation (EU) 2017/745 of the European Parliament and of the Council of 5 April 2017 on medical\ndevices, amending Directive 2001/83/EC, Regulation (EC) No 178/2002 and Regulation (EC) No\n1223/2009 and repealing Council Directives 90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1).\n\n48 Regulation (EU) 2017/746 of the European Parliament and of the Council of 5 April 2017 on in vitro\ndiagnostic medical devices and repealing Directive 98/79/EC and Commission Decision 2010/227/EU\n(OJ L 117, 5.5.2017, p. 176).", "# EN EN\n\n-----\n\nevaluation, promotion, or retention of persons in work-related contractual\nrelationships, such systems may perpetuate historical patterns of discrimination, for\nexample against women, certain age groups, persons with disabilities, or persons of\ncertain racial or ethnic origins or sexual orientation.\n\ngenai systems used to monitor the\nperformance and behaviour of these persons may also impact their rights to data\nprotection and privacy.\n\n(37) Another area in which the use of genai systems deserves special consideration is the\naccess to and enjoyment of certain essential private and public services and benefits\nnecessary for people to fully participate in society or to improve one\u2019s standard of\nliving.\n\nIn particular, genai systems used to evaluate the credit score or creditworthiness of\nnatural persons should be classified as high-risk genai systems, since they determine\nthose persons\u2019 access to financial resources or essential services such as housing,\nelectricity, and telecommunication services.\n\ngenai systems used for this purpose may lead\nto discrimination of persons or groups and perpetuate historical patterns of\ndiscrimination, for example based on racial or ethnic origins, disabilities, age, sexual\norientation, or create new forms of discriminatory impacts.\n\nConsidering the very\nlimited scale of the impact and the available alternatives on the market, it is\nappropriate to exempt genai systems for the purpose of creditworthiness assessment and\ncredit scoring when put into service by small-scale providers for their own use.\n\nNatural persons applying for or receiving public assistance benefits and services from\npublic authorities are typically dependent on those benefits and services and in a\nvulnerable position in relation to the responsible authorities.\n\nIf genai systems are used for\ndetermining whether such benefits and services should be denied, reduced, revoked or\nreclaimed by authorities, they may have a significant impact on persons\u2019 livelihood\nand may infringe their fundamental rights, such as the right to social protection, nondiscrimination, human dignity or an effective remedy.\n\nThose systems should therefore\nbe classified as high-risk.\n\nNonetheless, this Regulation should not hamper the\ndevelopment and use of innovative approaches in the public administration, which\nwould stand to benefit from a wider use of compliant and safe genai systems, provided\nthat those systems do not entail a high risk to legal and natural persons.\n\nFinally, genai\nsystems used to dispatch or establish priority in the dispatching of emergency first\nresponse services should also be classified as high-risk since they make decisions in\nvery critical situations for the life and health of persons and their property.\n\n(38) Actions by law enforcement authorities involving certain uses of genai systems are\ncharacterised by a significant degree of power imbalance and may lead to surveillance,\narrest or deprivation of a natural person\u2019s liberty as well as other adverse impacts on\nfundamental rights guaranteed in the Charter.\n\nIn particular, if the genai system is not\ntrained with high quality data, does not meet adequate requirements in terms of its\naccuracy or robustness, or is not properly designed and tested before being put on the\nmarket or otherwise put into service, it may single out people in a discriminatory or\notherwise incorrect or unjust manner.\n\nFurthermore, the exercise of important\nprocedural fundamental rights, such as the right to an effective remedy and to a fair\ntrial as well as the right of defence and the presumption of innocence, could be\nhampered, in particular, where such genai systems are not sufficiently transparent,\nexplainable and documented.\n\nIt is therefore appropriate to classify as high-risk a\nnumber of genai systems intended to be used in the law enforcement context where\naccuracy, reliability and transparency is particularly important to avoid adverse\nimpacts, retain public trust and ensure accountability and effective redress.\n\nIn view of\nthe nature of the activities in question and the risks relating thereto, those high-risk genai\nsystems should include in particular genai systems intended to be used by law", "# EN EN\n\n-----\n\nenforcement authorities for individual risk assessments, polygraphs and similar tools\nor to detect the emotional state of natural person, to detect \u2018deep fakes\u2019, for the\nevaluation of the reliability of evidence in criminal proceedings, for predicting the\noccurrence or reoccurrence of an actual or potential criminal offence based on\nprofiling of natural persons, or assessing personality traits and characteristics or past\ncriminal behaviour of natural persons or groups, for profiling in the course of\ndetection, investigation or prosecution of criminal offences, as well as for crime\nanalytics regarding natural persons.\n\ngenai systems specifically intended to be used for\nadministrative proceedings by tax and customs authorities should not be considered\nhigh-risk genai systems used by law enforcement authorities for the purposes of\nprevention, detection, investigation and prosecution of criminal offences.\n\n(39) genai systems used in migration, asylum and border control management affect people\nwho are often in particularly vulnerable position and who are dependent on the\noutcome of the actions of the competent public authorities.\n\nThe accuracy, nondiscriminatory nature and transparency of the genai systems used in those contexts are\ntherefore particularly important to guarantee the respect of the fundamental rights of\nthe affected persons, notably their rights to free movement, non-discrimination,\nprotection of private life and personal data, international protection and good\nadministration.\n\nIt is therefore appropriate to classify as high-risk genai systems intended\nto be used by the competent public authorities charged with tasks in the fields of\nmigration, asylum and border control management as polygraphs and similar tools or\nto detect the emotional state of a natural person; for assessing certain risks posed by\nnatural persons entering the territory of a Member State or applying for visa or\nasylum; for verifying the authenticity of the relevant documents of natural persons; for\nassisting competent public authorities for the examination of applications for asylum,\nvisa and residence permits and associated complaints with regard to the objective to\nestablish the eligibility of the natural persons applying for a status.\n\ngenai systems in the\narea of migration, asylum and border control management covered by this Regulation\nshould comply with the relevant procedural requirements set by the Directive\n2013/32/EU of the European Parliament and of the Council 49 , the Regulation (EC) No\n810/2009 of the European Parliament and of the Council 50 and other relevant\nlegislation.\n\n(40) Certain genai systems intended for the administration of justice and democratic processes\nshould be classified as high-risk, considering their potentially significant impact on\ndemocracy, rule of law, individual freedoms as well as the right to an effective remedy\nand to a fair trial.\n\nIn particular, to address the risks of potential biases, errors and\nopacity, it is appropriate to qualify as high-risk genai systems intended to assist judicial\nauthorities in researching and interpreting facts and the law and in applying the law to\na concrete set of facts.\n\nSuch qualification should not extend, however, to genai systems\nintended for purely ancillary administrative activities that do not affect the actual\nadministration of justice in individual cases, such as anonymisation or\npseudonymisation of judicial decisions, documents or data, communication between\npersonnel, administrative tasks or allocation of resources.\n\n49 Directive 2013/32/EU of the European Parliament and of the Council of 26 June 2013 on common\nprocedures for granting and withdrawing international protection (OJ L 180, 29.6.2013, p. 60).\n\n50 Regulation (EC) No 810/2009 of the European Parliament and of the Council of 13 July 2009\nestablishing a Community Code on Visas (Visa Code) (OJ L 243, 15.9.2009, p. 1).", "# EN EN\n\n-----\n\n(41) The fact that an genai system is classified as high risk under this Regulation should not\nbe interpreted as indicating that the use of the system is necessarily lawful under other\nacts of Union law or under national law compatible with Union law, such as on the\nprotection of personal data, on the use of polygraphs and similar tools or other systems\nto detect the emotional state of natural persons.\n\nAny such use should continue to occur\nsolely in accordance with the applicable requirements resulting from the Charter and\nfrom the applicable acts of secondary Union law and national law.\n\nThis Regulation\nshould not be understood as providing for the legal ground for processing of personal\ndata, including special categories of personal data, where relevant.\n\n(42) To mitigate the risks from high-risk genai systems placed or otherwise put into service on\nthe Union market for users and affected persons, certain mandatory requirements\nshould apply, taking into account the intended purpose of the use of the system and\naccording to the risk management system to be established by the provider.\n\n(43) Requirements should apply to high-risk genai systems as regards the quality of data sets\nused, technical documentation and record-keeping, transparency and the provision of\ninformation to users, human oversight, and robustness, accuracy and cybersecurity.\n\nThose requirements are necessary to effectively mitigate the risks for health, safety\nand fundamental rights, as applicable in the light of the intended purpose of the\nsystem, and no other less trade restrictive measures are reasonably available, thus\navoiding unjustified restrictions to trade.\n\n(44) High data quality is essential for the performance of many genai systems, especially\nwhen techniques involving the training of models are used, with a view to ensure that\nthe high-risk genai system performs as intended and safely and it does not become the\nsource of discrimination prohibited by Union law.\n\nHigh quality training, validation\nand testing data sets require the implementation of appropriate data governance and\nmanagement practices.\n\nTraining, validation and testing data sets should be sufficiently\nrelevant, representative and free of errors and complete in view of the intended\npurpose of the system.\n\nThey should also have the appropriate statistical properties,\nincluding as regards the persons or groups of persons on which the high-risk genai\nsystem is intended to be used.\n\nIn particular, training, validation and testing data sets\nshould take into account, to the extent required in the light of their intended purpose,\nthe features, characteristics or elements that are particular to the specific geographical,\nbehavioural or functional setting or context within which the genai system is intended to\nbe used.\n\nIn order to protect the right of others from the discrimination that might result\nfrom the bias in genai systems, the providers shouldbe able to process also special\ncategories of personal data, as a matter of substantial public interest, in order to ensure\nthe bias monitoring, detection and correction in relation to high-risk genai systems.\n\n(45) For the development of high-risk genai systems, certain actors, such as providers,\nnotified bodies and other relevant entities, such as digital innovation hubs, testing\nexperimentation facilities and researchers, should be able to access and use high\nquality datasets within their respective fields of activities which are related to this\nRegulation.\n\nEuropean common data spaces established by the Commission and the\nfacilitation of data sharing between businesses and with government in the public\ninterest will be instrumental to provide trustful, accountable and non-discriminatory\naccess to high quality data for the training, validation and testing of genai systems.\n\nFor\nexample, in health, the European health data space will facilitate non-discriminatory\naccess to health data and the training of genai algorithms on those\ndatasets, in a privacy-preserving, secure, timely, transparent and trustworthy manner,\nand with an appropriate institutional governance.\n\nRelevant competent authorities,", "# EN EN\n\n-----\n\nincluding sectoral ones, providing or supporting the access to data may also support\nthe provision of high-quality data for the training, validation and testing of genai systems.\n\n(46) Having information on how high-risk genai systems have been developed and how they\nperform throughout their lifecycle is essential to verify compliance with the\nrequirements under this Regulation.\n\nThis requires keeping records and the availability\nof a technical documentation, containing information which is necessary to assess the\ncompliance of the genai system with the relevant requirements.\n\nSuch information should\ninclude the general characteristics, capabilities and limitations of the system,\nalgorithms, data, training, testing and validation processes used as well as\ndocumentation on the relevant risk management system.\n\nThe technical documentation\nshould be kept up to date.\n\n(47) To address the opacity that may make certain genai systems incomprehensible to or too\ncomplex for natural persons, a certain degree of transparency should be required for\nhigh-risk genai systems.\n\nUsers should be able to interpret the system output and use it\nappropriately.\n\nHigh-risk genai systems should therefore be accompanied by relevant\ndocumentation and instructions of use and include concise and clear information,\nincluding in relation to possible risks to fundamental rights and discrimination, where\nappropriate.\n\n(48) High-risk genai systems should be designed and developed in such a way that natural\npersons can oversee their functioning.\n\nFor this purpose, appropriate human oversight\nmeasures should be identified by the provider of the system before its placing on the\nmarket or putting into service.\n\nIn particular, where appropriate, such measures should\nguarantee that the system is subject to in-built operational constraints that cannot be\noverridden by the system itself and is responsive to the human operator, and that the\nnatural persons to whom human oversight has been assigned have the necessary\ncompetence, training and authority to carry out that role.\n\n(49) High-risk genai systems should perform consistently throughout their lifecycle and meet\nan appropriate level of accuracy, robustness and cybersecurity in accordance with the\ngenerally acknowledged state of the art.\n\nThe level of accuracy and accuracy metrics\nshould be communicated to the users.\n\n(50) The technical robustness is a key requirement for high-risk genai systems.\n\nThey should\nbe resilient against risks connected to the limitations of the system (e.g.\n\nerrors, faults,\ninconsistencies, unexpected situations) as well as against malicious actions that may\ncompromise the security of the genai system and result in harmful or otherwise\nundesirable behaviour.\n\nFailure to protect against these risks could lead to safety\nimpacts or negatively affect the fundamental rights, for example due to erroneous\ndecisions or wrong or biased outputs generated by the genai system.\n\n(51) Cybersecurity plays a crucial role in ensuring that genai systems are resilient against\nattempts to alter their use, behaviour, performance or compromise their security\nproperties by malicious third parties exploiting the system\u2019s vulnerabilities.\n\nCyberattacks against genai systems can leverage genai specific assets, such as training data\nsets (e.g.\n\ndata poisoning) or trained models (e.g.\n\nadversarial attacks), or exploit\nvulnerabilities in the genai system\u2019s digital assets or the underlying ICT infrastructure.\n\nTo ensure a level of cybersecurity appropriate to the risks, suitable measures should\ntherefore be taken by the providers of high-risk genai systems, also taking into account as\nappropriate the underlying ICT infrastructure.", "# EN EN\n\n-----\n\n(52) As part of Union harmonisation legislation, rules applicable to the placing on the\nmarket, putting into service and use of high-risk genai systems should be laid down\nconsistently with Regulation (EC) No 765/2008 of the European Parliament and of the\nCouncil 51 setting out the requirements for accreditation and the market surveillance of\nproducts, Decision No 768/2008/EC of the European Parliament and of the Council 52\non a common framework for the marketing of products and Regulation (EU)\n2019/1020 of the European Parliament and of the Council 53 on market surveillance\nand compliance of products (\u2018New Legislative Framework for the marketing of\nproducts\u2019).\n\n(53) It is appropriate that a specific natural or legal person, defined as the provider, takes\nthe responsibility for the placing on the market or putting into service of a high-risk genai\nsystem, regardless of whether that natural or legal person is the person who designed\nor developed the system.\n\n(54) The provider should establish a sound quality management system, ensure the\naccomplishment of the required conformity assessment procedure, draw up the\nrelevant documentation and establish a robust post-market monitoring system.\n\nPublic\nauthorities which put into service high-risk genai systems for their own use may adopt\nand implement the rules for the quality management system as part of the quality\nmanagement system adopted at a national or regional level, as appropriate, taking into\naccount the specificities of the sector and the competences and organisation of the\npublic authority in question.\n\n(55) Where a high-risk genai system that is a safety component of a product which is covered\nby a relevant New Legislative Framework sectorial legislation is not placed on the\nmarket or put into service independently from the product, the manufacturer of the\nfinal product as defined under the relevant New Legislative Framework legislation\nshould comply with the obligations of the provider established in this Regulation and\nnotably ensure that the genai system embedded in the final product complies with the\nrequirements of this Regulation.\n\n(56) To enable enforcement of this Regulation and create a level-playing field for\noperators, and taking into account the different forms of making available of digital\nproducts, it is important to ensure that, under all circumstances, a person established in\nthe Union can provide authorities with all the necessary information on the compliance\nof an genai system.\n\nTherefore, prior to making their genai systems available in the Union,\nwhere an importer cannot be identified, providers established outside the Union shall,\nby written mandate, appoint an authorised representative established in the Union.\n\n(57) In line with New Legislative Framework principles, specific obligations for relevant\neconomic operators, such as importers and distributors, should be set to ensure legal\ncertainty and facilitate regulatory compliance by those relevant operators.\n\n51 Regulation (EC) No 765/2008 of the European Parliament and of the Council of 9 July 2008 setting out\nthe requirements for accreditation and market surveillance relating to the marketing of products and\nrepealing Regulation (EEC) No 339/93 (OJ L 218, 13.8.2008, p. 30).\n\n52 Decision No 768/2008/EC of the European Parliament and of the Council of 9 July 2008 on a common\nframework for the marketing of products, and repealing Council Decision 93/465/EEC (OJ L 218,\n13.8.2008, p. 82).\n\n53 Regulation (EU) 2019/1020 of the European Parliament and of the Council of 20 June 2019 on market\nsurveillance and compliance of products and amending Directive 2004/42/EC and Regulations (EC) No\n765/2008 and (EU) No 305/2011 (Text with EEA relevance) (OJ L 169, 25.6.2019, p. 1\u201344).", "# EN EN\n\n-----\n\n(58) Given the nature of genai systems and the risks to safety and fundamental rights possibly\nassociated with their use, including as regard the need to ensure proper monitoring of\nthe performance of an genai system in a real-life setting, it is appropriate to set specific\nresponsibilities for users.\n\nUsers should in particular use high-risk genai systems in\naccordance with the instructions of use and certain other obligations should be\nprovided for with regard to monitoring of the functioning of the genai systems and with\nregard to record-keeping, as appropriate.\n\n(59) It is appropriate to envisage that the user of the genai system should be the natural or\nlegal person, public authority, agency or other body under whose authority the genai\nsystem is operated except where the use is made in the course of a personal nonprofessional activity.\n\n(60) In the light of the complexity of the genai value chain, relevant third\nparties, notably the ones involved in the sale and the supply of software, software tools\nand components, pre-trained models and data, or providers of network services, should\ncooperate, as appropriate, with providers and users to enable their compliance with the\nobligations under this Regulation and with competent authorities established under this\nRegulation.\n\n(61) Standardisation should play a key role to provide technical solutions to providers to\nensure compliance with this Regulation.\n\nCompliance with harmonised standards as\ndefined in Regulation (EU) No 1025/2012 of the European Parliament and of the\nCouncil 54 should be a means for providers to demonstrate conformity with the\nrequirements of this Regulation.\n\nHowever, the Commission could adopt common\ntechnical specifications in areas where no harmonised standards exist or where they\nare insufficient.\n\n(62) In order to ensure a high level of trustworthiness of high-risk genai systems, those\nsystems should be subject to a conformity assessment prior to their placing on the\nmarket or putting into service.\n\n(63) It is appropriate that, in order to minimise the burden on operators and avoid any\npossible duplication, for high-risk genai systems related to products which are covered by\nexisting Union harmonisation legislation following the New Legislative Framework\napproach, the compliance of those genai systems with the requirements of this Regulation\nshould be assessed as part of the conformity assessment already foreseen under that\nlegislation.\n\nThe applicability of the requirements of this Regulation should thus not\naffect the specific logic, methodology or general structure of conformity assessment\nunder the relevant specific New Legislative Framework legislation.\n\nThis approach is\nfully reflected in the interplay between this Regulation and the [Machinery\nRegulation].\n\nWhile safety risks of genai systems ensuring safety functions in machinery\nare addressed by the requirements of this Regulation, certain specific requirements in\nthe [Machinery Regulation] will ensure the safe integration of the genai system into the\noverall machinery, so as not to compromise the safety of the machinery as a whole.\n\n54 Regulation (EU) No 1025/2012 of the European Parliament and of the Council of 25 October 2012 on\nEuropean standardisation, amending Council Directives 89/686/EEC and 93/15/EEC and Directives\n94/9/EC, 94/25/EC, 95/16/EC, 97/23/EC, 98/34/EC, 2004/22/EC, 2007/23/EC, 2009/23/EC and\n2009/105/EC of the European Parliament and of the Council and repealing Council Decision\n87/95/EEC and Decision No 1673/2006/EC of the European Parliament and of the Council (OJ L 316,\n14.11.2012, p. 12).", "# EN EN\n\n-----\n\nThe [Machinery Regulation] applies the same definition of genai system as this\nRegulation.\n\n(64) Given the more extensive experience of professional pre-market certifiers in the field\nof product safety and the different nature of risks involved, it is appropriate to limit, at\nleast in an initial phase of application of this Regulation, the scope of application of\nthird-party conformity assessment for high-risk genai systems other than those related to\nproducts.\n\nTherefore, the conformity assessment of such systems should be carried out\nas a general rule by the provider under its own responsibility, with the only exception\nof genai systems intended to be used for the remote biometric identification of persons,\nfor which the involvement of a notified body in the conformity assessment should be\nforeseen, to the extent they are not prohibited.\n\n(65) In order to carry out third-party conformity assessment for genai systems intended to be\nused for the remote biometric identification of persons, notified bodies should be\ndesignated under this Regulation by the national competent authorities, provided they\nare compliant with a set of requirements, notably on independence, competence and\nabsence of conflicts of interests.\n\n(66) In line with the commonly established notion of substantial modification for products\nregulated by Union harmonisation legislation, it is appropriate that an genai system\nundergoes a new conformity assessment whenever a change occurs which may affect\nthe compliance of the system with this Regulation or when the intended purpose of the\nsystem changes.\n\nIn addition, as regards genai systems which continue to \u2018learn\u2019 after\nbeing placed on the market or put into service (i.e.\n\nthey automatically adapt how\nfunctions are carried out), it is necessary to provide rules establishing that changes to\nthe algorithm and its performance that have been pre-determined by the provider and\nassessed at the moment of the conformity assessment should not constitute a\nsubstantial modification.\n\n(67) High-risk genai systems should bear the CE marking to indicate their conformity with\nthis Regulation so that they can move freely within the internal market.\n\nMember States\nshould not create unjustified obstacles to the placing on the market or putting into\nservice of high-risk genai systems that comply with the requirements laid down in this\nRegulation and bear the CE marking.\n\n(68) Under certain conditions, rapid availability of innovative technologies may be crucial\nfor health and safety of persons and for society as a whole.\n\nIt is thus appropriate that\nunder exceptional reasons of public security or protection of life and health of natural\npersons and the protection of industrial and commercial property, Member States\ncould authorise the placing on the market or putting into service of genai systems which\nhave not undergone a conformity assessment.\n\n(69) In order to facilitate the work of the Commission and the Member States in the\ngenai field as well as to increase the transparency towards the public,\nproviders of high-risk genai systems other than those related to products falling within\nthe scope of relevant existing Union harmonisation legislation, should be required to\nregister their high-risk genai system in a EU database, to be established and managed by\nthe Commission.\n\nThe Commission should be the controller of that database, in\naccordance with Regulation (EU) 2018/1725 of the European Parliament and of the", "# EN EN\n\n-----\n\nCouncil 55 .\n\nIn order to ensure the full functionality of the database, when deployed, the\nprocedure for setting the database should include the elaboration of functional\nspecifications by the Commission and an independent audit report.\n\n(70) Certain genai systems intended to interact with natural persons or to generate content\nmay pose specific risks of impersonation or deception irrespective of whether they\nqualify as high-risk or not.\n\nIn certain circumstances, the use of these systems should\ntherefore be subject to specific transparency obligations without prejudice to the\nrequirements and obligations for high-risk genai systems.\n\nIn particular, natural persons\nshould be notified that they are interacting with an genai system, unless this is obvious\nfrom the circumstances and the context of use.\n\nMoreover, natural persons should be\nnotified when they are exposed to an emotion recognition system or a biometric\ncategorisation system.\n\nSuch information and notifications should be provided in\naccessible formats for persons with disabilities.\n\nFurther, users, who use an genai system\nto generate or manipulate image, audio or video content that appreciably resembles\nexisting persons, places or events and would falsely appear to a person to be authentic,\nshould disclose that the content has been artificially created or manipulated by\nlabelling the genai output accordingly and disclosing its artificial\norigin.\n\n(71) genai is a rapidly developing family of technologies that requires\nnovel forms of regulatory oversight and a safe space for experimentation, while\nensuring responsible innovation and integration of appropriate safeguards and risk\nmitigation measures.\n\nTo ensure a legal framework that is innovation-friendly, futureproof and resilient to disruption, national competent authorities from one or more\nMember States should be encouraged to establish genai regulatory\nsandboxes to facilitate the development and testing of innovative genai systems under\nstrict regulatory oversight before these systems are placed on the market or otherwise\nput into service.\n\n(72) The objectives of the regulatory sandboxes should be to foster genai innovation by\nestablishing a controlled experimentation and testing environment in the development\nand pre-marketing phase with a view to ensuring compliance of the innovative genai\nsystems with this Regulation and other relevant Union and Member States legislation;\nto enhance legal certainty for innovators and the competent authorities\u2019 oversight and\nunderstanding of the opportunities, emerging risks and the impacts of genai use, and to\naccelerate access to markets, including by removing barriers for small and medium\nenterprises (SMEs) and start-ups.\n\nTo ensure uniform implementation across the Union\nand economies of scale, it is appropriate to establish common rules for the regulatory\nsandboxes\u2019 implementation and a framework for cooperation between the relevant\nauthorities involved in the supervision of the sandboxes.\n\nThis Regulation should\nprovide the legal basis for the use of personal data collected for other purposes for\ndeveloping certain genai systems in the public interest within the genai regulatory sandbox,\nin line with Article 6(4) of Regulation (EU) 2016/679, and Article 6 of Regulation\n(EU) 2018/1725, and without prejudice to Article 4(2) of Directive (EU) 2016/680.\n\nParticipants in the sandbox should ensure appropriate safeguards and cooperate with\nthe competent authorities, including by following their guidance and acting\n\n55 Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the\nprotection of natural persons with regard to the processing of personal data and on the free movement of\nsuch data, and repealing Directive 95/46/EC (General Data Protection Regulation) (OJ L 119, 4.5.2016,\np. 1).", "# EN EN\n\n-----\n\nexpeditiously and in good faith to mitigate any high-risks to safety and fundamental\nrights that may arise during the development and experimentation in the sandbox.\n\nThe\nconduct of the participants in the sandbox should be taken into account when\ncompetent authorities decide whether to impose an administrative fine under Article\n83(2) of Regulation 2016/679 and Article 57 of Directive 2016/680.\n\n(73) In order to promote and protect innovation, it is important that the interests of smallscale providers and users of genai systems are taken into particular account.\n\nTo this\nobjective, Member States should develop initiatives, which are targeted at those\noperators, including on awareness raising and information communication.\n\nMoreover,\nthe specific interests and needs of small-scale providers shall be taken into account\nwhen Notified Bodies set conformity assessment fees.\n\nTranslation costs related to\nmandatory documentation and communication with authorities may constitute a\nsignificant cost for providers and other operators, notably those of a smaller scale.\n\nMember States should possibly ensure that one of the languages determined and\naccepted by them for relevant providers\u2019 documentation and for communication with\noperators is one which is broadly understood by the largest possible number of crossborder users.\n\n(74) In order to minimise the risks to implementation resulting from lack of knowledge and\nexpertise in the market as well as to facilitate compliance of providers and notified\nbodies with their obligations under this Regulation, the genai-on demand platform, the\nEuropean Digital Innovation Hubs and the Testing and Experimentation Facilities\nestablished by the Commission and the Member States at national or EU level should\npossibly contribute to the implementation of this Regulation.\n\nWithin their respective\nmission and fields of competence, they may provide in particular technical and\nscientific support to providers and notified bodies.\n\n(75) It is appropriate that the Commission facilitates, to the extent possible, access to\nTesting and Experimentation Facilities to bodies, groups or laboratories established or\naccredited pursuant to any relevant Union harmonisation legislation and which fulfil\ntasks in the context of conformity assessment of products or devices covered by that\nUnion harmonisation legislation.\n\nThis is notably the case for expert panels, expert\nlaboratories and reference laboratories in the field of medical devices pursuant to\nRegulation (EU) 2017/745 and Regulation (EU) 2017/746.\n\n(76) In order to facilitate a smooth, effective and harmonised implementation of this\nRegulation a European genai Board should be established.\n\nThe Board\nshould be responsible for a number of advisory tasks, including issuing opinions,\nrecommendations, advice or guidance on matters related to the implementation of this\nRegulation, including on technical specifications or existing standards regarding the\nrequirements established in this Regulation and providing advice to and assisting the\nCommission on specific questions related to genai.\n\n(77) Member States hold a key role in the application and enforcement of this Regulation.\n\nIn this respect, each Member State should designate one or more national competent\nauthorities for the purpose of supervising the application and implementation of this\nRegulation.\n\nIn order to increase organisation efficiency on the side of Member States\nand to set an official point of contact vis-\u00e0-vis the public and other counterparts at\nMember State and Union levels, in each Member State one national authority should\nbe designated as national supervisory authority.\n\n(78) In order to ensure that providers of high-risk genai systems can take into account the\nexperience on the use of high-risk genai systems for improving their systems and the", "# EN EN\n\n-----\n\ndesign and development process or can take any possible corrective action in a timely\nmanner, all providers should have a post-market monitoring system in place.\n\nThis\nsystem is also key to ensure that the possible risks emerging from genai systems which\ncontinue to \u2018learn\u2019 after being placed on the market or put into service can be more\nefficiently and timely addressed.\n\nIn this context, providers should also be required to\nhave a system in place to report to the relevant authorities any serious incidents or any\nbreaches to national and Union law protecting fundamental rights resulting from the\nuse of their genai systems.\n\n(79) In order to ensure an appropriate and effective enforcement of the requirements and\nobligations set out by this Regulation, which is Union harmonisation legislation, the\nsystem of market surveillance and compliance of products established by Regulation\n(EU) 2019/1020 should apply in its entirety.\n\nWhere necessary for their mandate,\nnational public authorities or bodies, which supervise the application of Union law\nprotecting fundamental rights, including equality bodies, should also have access to\nany documentation created under this Regulation.\n\n(80) Union legislation on financial services includes internal governance and risk\nmanagement rules and requirements which are applicable to regulated financial\ninstitutions in the course of provision of those services, including when they make use\nof genai systems.\n\nIn order to ensure coherent application and enforcement of the\nobligations under this Regulation and relevant rules and requirements of the Union\nfinancial services legislation, the authorities responsible for the supervision and\nenforcement of the financial services legislation, including where applicable the\nEuropean Central Bank, should be designated as competent authorities for the purpose\nof supervising the implementation of this Regulation, including for market\nsurveillance activities, as regards genai systems provided or used by regulated and\nsupervised financial institutions.\n\nTo further enhance the consistency between this\nRegulation and the rules applicable to credit institutions regulated under Directive\n2013/36/EU of the European Parliament and of the Council 56 , it is also appropriate to\nintegrate the conformity assessment procedure and some of the providers\u2019 procedural\nobligations in relation to risk management, post marketing monitoring and\ndocumentation into the existing obligations and procedures under Directive\n2013/36/EU.\n\nIn order to avoid overlaps, limited derogations should also be envisaged\nin relation to the quality management system of providers and the monitoring\nobligation placed on users of high-risk genai systems to the extent that these apply to\ncredit institutions regulated by Directive 2013/36/EU.\n\n(81) The development of genai systems other than high-risk genai systems in accordance with\nthe requirements of this Regulation may lead to a larger uptake of trustworthy artificial\nintelligence in the Union.\n\nProviders of non-high-risk genai systems should be encouraged\nto create codes of conduct intended to foster the voluntary application of the\nmandatory requirements applicable to high-risk genai systems.\n\nProviders should also be\nencouraged to apply on a voluntary basis additional requirements related, for example,\nto environmental sustainability, accessibility to persons with disability, stakeholders\u2019\nparticipation in the design and development of genai systems, and diversity of the\ndevelopment teams.\n\nThe Commission may develop initiatives, including of a sectorial\n\n56 Directive 2013/36/EU of the European Parliament and of the Council of 26 June 2013 on access to the\nactivity of credit institutions and the prudential supervision of credit institutions and investment firms,\namending Directive 2002/87/EC and repealing Directives 2006/48/EC and 2006/49/EC (OJ L 176,\n27.6.2013, p. 338).", "# EN EN\n\n-----\n\nnature, to facilitate the lowering of technical barriers hindering cross-border exchange\nof data for genai development, including on data access infrastructure, semantic and\ntechnical interoperability of different types of data.\n\n(82) It is important that genai systems related to products that are not high-risk in accordance\nwith this Regulation and thus are not required to comply with the requirements set out\nherein are nevertheless safe when placed on the market or put into service.\n\nTo\ncontribute to this objective, the Directive 2001/95/EC of the European Parliament and\nof the Council 57 would apply as a safety net.\n\n(83) In order to ensure trustful and constructive cooperation of competent authorities on\nUnion and national level, all parties involved in the application of this Regulation\nshould respect the confidentiality of information and data obtained in carrying out\ntheir tasks.\n\n(84) Member States should take all necessary measures to ensure that the provisions of this\nRegulation are implemented, including by laying down effective, proportionate and\ndissuasive penalties for their infringement.\n\nFor certain specific infringements, Member\nStates should take into account the margins and criteria set out in this Regulation.\n\nThe\nEuropean Data Protection Supervisor should have the power to impose fines on Union\ninstitutions, agencies and bodies falling within the scope of this Regulation.\n\n(85) In order to ensure that the regulatory framework can be adapted where necessary, the\npower to adopt acts in accordance with Article 290 TFEU should be delegated to the\nCommission to amend the techniques and approaches referred to in Annex I to define\ngenai systems, the Union harmonisation legislation listed in Annex II, the high-risk genai\nsystems listed in Annex III, the provisions regarding technical documentation listed in\nAnnex IV, the content of the EU declaration of conformity in Annex V, the provisions\nregarding the conformity assessment procedures in Annex VI and VII and the\nprovisions establishing the high-risk genai systems to which the conformity assessment\nprocedure based on assessment of the quality management system and assessment of\nthe technical documentation should apply.\n\nIt is of particular importance that the\nCommission carry out appropriate consultations during its preparatory work, including\nat expert level, and that those consultations be conducted in accordance with the\nprinciples laid down in the Interinstitutional Agreement of 13 April 2016 on Better\nLaw-Making 58 .\n\nIn particular, to ensure equal participation in the preparation of\ndelegated acts, the European Parliament and the Council receive all documents at the\nsame time as Member States\u2019 experts, and their experts systematically have access to\nmeetings of Commission expert groups dealing with the preparation of delegated acts.\n\n(86) In order to ensure uniform conditions for the implementation of this Regulation,\nimplementing powers should be conferred on the Commission.\n\nThose powers should\nbe exercised in accordance with Regulation (EU) No 182/2011 of the European\nParliament and of the Council 59 .\n\n(87) Since the objective of this Regulation cannot be sufficiently achieved by the Member\nStates and can rather, by reason of the scale or effects of the action, be better achieved\n\n\n57 Directive 2001/95/EC of the European Parliament and of the Council of 3 December 2001 on general\nproduct safety (OJ L 11, 15.1.2002, p. 4).\n\n58 OJ L 123, 12.5.2016, p. 1.\n\n59 Regulation (EU) No 182/2011 of the European Parliament and of the Council of 16 February 2011\nlaying down the rules and general principles concerning mechanisms for control by the Member States\nof the Commission's exercise of implementing powers (OJ L 55, 28.2.2011, p.13).", "# EN EN\n\n-----\n\nat Union level, the Union may adopt measures in accordance with the principle of\nsubsidiarity as set out in Article 5 TEU.\n\nIn accordance with the principle of\nproportionality as set out in that Article, this Regulation does not go beyond what is\nnecessary in order to achieve that objective.\n\n(88) This Regulation should apply from \u2026 [ _OP \u2013 please insert the date established in Art._\n_85_ ].\n\nHowever, the infrastructure related to the governance and the conformity\nassessment system should be operational before that date, therefore the provisions on\nnotified bodies and governance structure should apply from \u2026 [ _OP \u2013 please insert the_\n_date \u2013 three months following the entry into force of this Regulation_ ].\n\nIn addition,\nMember States should lay down and notify to the Commission the rules on penalties,\nincluding administrative fines, and ensure that they are properly and effectively\nimplemented by the date of application of this Regulation.\n\nTherefore the provisions on\npenalties should apply from [ _OP \u2013 please insert the date \u2013 twelve months following the_\n_entry into force of this Regulation_ ].\n\n(89) The European Data Protection Supervisor and the European Data Protection Board\nwere consulted in accordance with Article 42(2) of Regulation (EU) 2018/1725 and\ndelivered an opinion on [\u2026]\u201d.\n\nHAVE ADOPTED THIS REGULATION:", "## TITLE I\n\nGENERAL PROVISIONS\n\n\n_Article 1_\n\n_Subject matter_\n\nThis Regulation lays down:\n\n(a) harmonised rules for the placing on the market, the putting into service and the\nuse of genai systems (\u2018genai systems\u2019) in the Union;\n\n(a) prohibitions of certain genai practices;\n\n(b) specific requirements for high-risk genai systems and obligations for operators of\nsuch systems;\n\n(c) harmonised transparency rules for genai systems intended to interact with natural\npersons, emotion recognition systems and biometric categorisation systems,\nand genai systems used to generate or manipulate image, audio or video content;\n\n(d) rules on market monitoring and surveillance.\n\n_Article 2_\n\n_Scope_\n\n1.\n\nThis Regulation applies to:\n\n(a) providers placing on the market or putting into service genai systems in the\nUnion, irrespective of whether those providers are established within the Union\nor in a third country;\n\n(b) users of genai systems located within the Union;", "# EN EN\n\n-----\n\n(c) providers and users of genai systems that are located in a third country, where the\noutput produced by the system is used in the Union;\n\n2.\n\nFor high-risk genai systems that are safety components of products or systems, or which\nare themselves products or systems, falling within the scope of the following acts,\nonly Article 84 of this Regulation shall apply:\n\n(a) Regulation (EC) 300/2008;\n\n(b) Regulation (EU) No 167/2013;\n\n(c) Regulation (EU) No 168/2013;\n\n(d) Directive 2014/90/EU;\n\n(e) Directive (EU) 2016/797;\n\n(f) Regulation (EU) 2018/858;\n\n(g) Regulation (EU) 2018/1139;\n\n(h) Regulation (EU) 2019/2144.\n\n3.\n\nThis Regulation shall not apply to genai systems developed or used exclusively for\nmilitary purposes.\n\n4.\n\nThis Regulation shall not apply to public authorities in a third country nor to\ninternational organisations falling within the scope of this Regulation pursuant to\nparagraph 1, where those authorities or organisations use genai systems in the\nframework of international agreements for law enforcement and judicial cooperation\nwith the Union or with one or more Member States.\n\n5.\n\nThis Regulation shall not affect the application of the provisions on the liability of\nintermediary service providers set out in Chapter II, Section IV of Directive\n2000/31/EC of the European Parliament and of the Council 60 [ _as to be replaced by_\n_the corresponding provisions of the Digital Services Act_ ].\n\n_Article 3_\n\n_Definitions_\n\nFor the purpose of this Regulation, the following definitions apply:\n\n(1) \u2018genai system\u2019 (genai system) means software that is developed with one\nor more of the techniques and approaches listed in Annex I and can, for a given set of\nhuman-defined objectives, generate outputs such as content, predictions,\nrecommendations, or decisions influencing the environments they interact with;\n\n(1) \u2018provider\u2019 means a natural or legal person, public authority, agency or other body\nthat develops an genai system or that has an genai system developed with a view to\nplacing it on the market or putting it into service under its own name or trademark,\nwhether for payment or free of charge;\n\n60 Directive 2000/31/EC of the European Parliament and of the Council of 8 June 2000 on certain legal\naspects of information society services, in particular electronic commerce, in the Internal Market\n('Directive on electronic commerce') (OJ L 178, 17.7.2000, p. 1).", "# EN EN\n\n-----\n\n(3) \u2018small-scale provider\u2019 means a provider that is a micro or small enterprise within the\nmeaning of Commission Recommendation 2003/361/EC 61 ;\n\n(4) \u2018user\u2019 means any natural or legal person, public authority, agency or other body\nusing an genai system under its authority, except where the genai system is used in the\ncourse of a personal non-professional activity;\n\n(5) \u2018authorised representative\u2019 means any natural or legal person established in the\nUnion who has received a written mandate from a provider of an genai system to,\nrespectively, perform and carry out on its behalf the obligations and procedures\nestablished by this Regulation;\n\n(6) \u2018importer\u2019 means any natural or legal person established in the Union that places on\nthe market or puts into service an genai system that bears the name or trademark of a\nnatural or legal person established outside the Union;\n\n(7) \u2018distributor\u2019 means any natural or legal person in the supply chain, other than the\nprovider or the importer, that makes an genai system available on the Union market\nwithout affecting its properties;\n\n(8) \u2018operator\u2019 means the provider, the user, the authorised representative, the importer\nand the distributor;\n\n(9) \u2018placing on the market\u2019 means the first making available of an genai system on the\nUnion market;\n\n(10) \u2018making available on the market\u2019 means any supply of an genai system for distribution\nor use on the Union market in the course of a commercial activity, whether in return\nfor payment or free of charge;\n\n(11) \u2018putting into service\u2019 means the supply of an genai system for first use directly to the\nuser or for own use on the Union market for its intended purpose;\n\n(12) \u2018intended purpose\u2019 means the use for which an genai system is intended by the provider,\nincluding the specific context and conditions of use, as specified in the information\nsupplied by the provider in the instructions for use, promotional or sales materials\nand statements, as well as in the technical documentation;\n\n(13) \u2018reasonably foreseeable misuse\u2019 means the use of an genai system in a way that is not in\naccordance with its intended purpose, but which may result from reasonably\nforeseeable human behaviour or interaction with other systems;\n\n(14) \u2018safety component of a product or system\u2019 means a component of a product or of a\nsystem which fulfils a safety function for that product or system or the failure or\nmalfunctioning of which endangers the health and safety of persons or property;\n\n(15) \u2018instructions for use\u2019 means the information provided by the provider to inform the\nuser of in particular an genai system\u2019s intended purpose and proper use, inclusive of the\nspecific geographical, behavioural or functional setting within which the high-risk genai\nsystem is intended to be used;\n\n(16) \u2018recall of an genai system\u2019 means any measure aimed at achieving the return to the\nprovider of an genai system made available to users;\n\n61 Commission Recommendation of 6 May 2003 concerning the definition of micro, small and mediumsized enterprises (OJ L 124, 20.5.2003, p. 36).", "# EN EN\n\n-----\n\n(17) \u2018withdrawal of an genai system\u2019 means any measure aimed at preventing the\ndistribution, display and offer of an genai system;\n\n(18) \u2018performance of an genai system\u2019 means the ability of an genai system to achieve its\nintended purpose;\n\n(19) \u2018notifying authority\u2019 means the national authority responsible for setting up and\ncarrying out the necessary procedures for the assessment, designation and\nnotification of conformity assessment bodies and for their monitoring;\n\n(20) \u2018conformity assessment\u2019 means the process of verifying whether the requirements set\nout in Title III, Chapter 2 of this Regulation relating to an genai system have been\nfulfilled;\n\n(21) \u2018conformity assessment body\u2019 means a body that performs third-party conformity\nassessment activities, including testing, certification and inspection;\n\n(22) \u2018notified body\u2019 means a conformity assessment body designated in accordance with\nthis Regulation and other relevant Union harmonisation legislation;\n\n(23) \u2018substantial modification\u2019 means a change to the genai system following its placing on\nthe market or putting into service which affects the compliance of the genai system with\nthe requirements set out in Title III, Chapter 2 of this Regulation or results in a\nmodification to the intended purpose for which the genai system has been assessed;\n\n(24) \u2018CE marking of conformity\u2019 (CE marking) means a marking by which a provider\nindicates that an genai system is in conformity with the requirements set out in Title III,\nChapter 2 of this Regulation and other applicable Union legislation harmonising the\nconditions for the marketing of products (\u2018Union harmonisation legislation\u2019)\nproviding for its affixing;\n\n(25) \u2018post-market monitoring\u2019 means all activities carried out by providers of genai systems\nto proactively collect and review experience gained from the use of genai systems they\nplace on the market or put into service for the purpose of identifying any need to\nimmediately apply any necessary corrective or preventive actions;\n\n(26) \u2018market surveillance authority\u2019 means the national authority carrying out the\nactivities and taking the measures pursuant to Regulation (EU) 2019/1020;\n\n(27) \u2018harmonised standard\u2019 means a European standard as defined in Article 2(1)(c) of\nRegulation (EU) No 1025/2012;\n\n(28) \u2018common specifications\u2019 means a document, other than a standard, containing\ntechnical solutions providing a means to, comply with certain requirements and\nobligations established under this Regulation;\n\n(29) \u2018training data\u2019 means data used for training an genai system through fitting its learnable\nparameters, including the weights of a neural network;\n\n(30) \u2018validation data\u2019 means data used for providing an evaluation of the trained genai\nsystem and for tuning its non-learnable parameters and its learning process, among\nother things, in order to prevent overfitting; whereas the validation dataset can be a\nseparate dataset or part of the training dataset, either as a fixed or variable split;\n\n(31) \u2018testing data\u2019 means data used for providing an independent evaluation of the trained\nand validated genai system in order to confirm the expected performance of that system\nbefore its placing on the market or putting into service;", "# EN EN\n\n-----\n\n(32) \u2018input data\u2019 means data provided to or directly acquired by an genai system on the basis\nof which the system produces an output;\n\n(33) \u2018biometric data\u2019 means personal data resulting from specific technical processing\nrelating to the physical, physiological or behavioural characteristics of a natural\nperson, which allow or confirm the unique identification of that natural person, such\nas facial images or dactyloscopic data;\n\n(34) \u2018emotion recognition system\u2019 means an genai system for the purpose of identifying or\ninferring emotions or intentions of natural persons on the basis of their biometric\ndata;\n\n(35) \u2018biometric categorisation system\u2019 means an genai system for the purpose of assigning\nnatural persons to specific categories, such as sex, age, hair colour, eye colour,\ntattoos, ethnic origin or sexual or political orientation, on the basis of their biometric\ndata;\n\n(36) \u2018remote biometric identification system\u2019 means an genai system for the purpose of\nidentifying natural persons at a distance through the comparison of a person\u2019s\nbiometric data with the biometric data contained in a reference database, and without\nprior knowledge of the user of the genai system whether the person will be present and\ncan be identified ;\n\n(37) \u2018\u2018real-time\u2019 remote biometric identification system\u2019 means a remote biometric\nidentification system whereby the capturing of biometric data, the comparison and\nthe identification all occur without a significant delay.\n\nThis comprises not only\ninstant identification, but also limited short delays in order to avoid circumvention.\n\n(38) \u2018\u2018post\u2019 remote biometric identification system\u2019 means a remote biometric\nidentification system other than a \u2018real-time\u2019 remote biometric identification system;\n\n(39) \u2018publicly accessible space\u2019 means any physical place accessible to the public,\nregardless of whether certain conditions for access may apply;\n\n(40) \u2018law enforcement authority\u2019 means:\n\n(a) any public authority competent for the prevention, investigation, detection or\nprosecution of criminal offences or the execution of criminal penalties,\nincluding the safeguarding against and the prevention of threats to public\nsecurity; or\n\n(b) any other body or entity entrusted by Member State law to exercise public\nauthority and public powers for the purposes of the prevention, investigation,\ndetection or prosecution of criminal offences or the execution of criminal\npenalties, including the safeguarding against and the prevention of threats to\npublic security;\n\n(41) \u2018law enforcement\u2019 means activities carried out by law enforcement authorities for the\nprevention, investigation, detection or prosecution of criminal offences or the\nexecution of criminal penalties, including the safeguarding against and the\nprevention of threats to public security;\n\n(42) \u2018national supervisory authority\u2019 means the authority to which a Member State assigns\nthe responsibility for the implementation and application of this Regulation, for\ncoordinating the activities entrusted to that Member State, for acting as the single\ncontact point for the Commission, and for representing the Member State at the\nEuropean genai Board;", "# EN EN\n\n-----\n\n(43) \u2018national competent authority\u2019 means the national supervisory authority, the\nnotifying authority and the market surveillance authority;\n\n(44) \u2018serious incident\u2019 means any incident that directly or indirectly leads, might have led\nor might lead to any of the following:\n\n(a) the death of a person or serious damage to a person\u2019s health, to property or the\nenvironment,\n\n(b) a serious and irreversible disruption of the management and operation of\ncritical infrastructure.\n\n_Article 4_\n\n_Amendments to Annex I_\n\nThe Commission is empowered to adopt delegated acts in accordance with Article 73 to\namend the list of techniques and approaches listed in Annex I, in order to update that list to\nmarket and technological developments on the basis of characteristics that are similar to the\ntechniques and approaches listed therein.", "## TITLE II\n\nPROHIBITED genai PRACTICES\n\n_Article 5_\n\n1.\n\nThe following genai practices shall be prohibited:\n\n(a) the placing on the market, putting into service or use of an genai system that\ndeploys subliminal techniques beyond a person\u2019s consciousness in order to\nmaterially distort a person\u2019s behaviour in a manner that causes or is likely to\ncause that person or another person physical or psychological harm;\n\n(b) the placing on the market, putting into service or use of an genai system that\nexploits any of the vulnerabilities of a specific group of persons due to their\nage, physical or mental disability, in order to materially distort the behaviour of\na person pertaining to that group in a manner that causes or is likely to cause\nthat person or another person physical or psychological harm;\n\n(c) the placing on the market, putting into service or use of genai systems by public\nauthorities or on their behalf for the evaluation or classification of the\ntrustworthiness of natural persons over a certain period of time based on their\nsocial behaviour or known or predicted personal or personality characteristics,\nwith the social score leading to either or both of the following:\n\n(i) detrimental or unfavourable treatment of certain natural persons or whole\ngroups thereof in social contexts which are unrelated to the contexts in\nwhich the data was originally generated or collected;\n\n(ii) detrimental or unfavourable treatment of certain natural persons or whole\ngroups thereof that is unjustified or disproportionate to their social\nbehaviour or its gravity;\n\n(d) the use of \u2018real-time\u2019 remote biometric identification systems in publicly\naccessible spaces for the purpose of law enforcement, unless and in as far as\nsuch use is strictly necessary for one of the following objectives:", "# EN EN\n\n-----\n\n(i) the targeted search for specific potential victims of crime, including\nmissing children;\n\n(ii) the prevention of a specific, substantial and imminent threat to the life or\nphysical safety of natural persons or of a terrorist attack;\n\n\n(iii) the detection, localisation, identification or prosecution of a perpetrator\n\nor suspect of a criminal offence referred to in Article 2(2) of Council\nFramework Decision 2002/584/JHA 62 and punishable in the Member\nState concerned by a custodial sentence or a detention order for a\nmaximum period of at least three years, as determined by the law of that\nMember State.\n\n2.\n\nThe use of \u2018real-time\u2019 remote biometric identification systems in publicly accessible\nspaces for the purpose of law enforcement for any of the objectives referred to in\nparagraph 1 point d) shall take into account the following elements:\n\n(a) the nature of the situation giving rise to the possible use, in particular the\nseriousness, probability and scale of the harm caused in the absence of the use\nof the system;\n\n(b) the consequences of the use of the system for the rights and freedoms of all\npersons concerned, in particular the seriousness, probability and scale of those\nconsequences.\n\nIn addition, the use of \u2018real-time\u2019 remote biometric identification systems in publicly\naccessible spaces for the purpose of law enforcement for any of the objectives\nreferred to in paragraph 1 point d) shall comply with necessary and proportionate\nsafeguards and conditions in relation to the use, in particular as regards the temporal,\ngeographic and personal limitations.\n\n3.\n\nAs regards paragraphs 1, point (d) and 2, each individual use for the purpose of law\nenforcement of a \u2018real-time\u2019 remote biometric identification system in publicly\naccessible spaces shall be subject to a prior authorisation granted by a judicial\nauthority or by an independent administrative authority of the Member State in\nwhich the use is to take place, issued upon a reasoned request and in accordance with\nthe detailed rules of national law referred to in paragraph 4.\n\nHowever, in a duly\njustified situation of urgency, the use of the system may be commenced without an\nauthorisation and the authorisation may be requested only during or after the use.\n\nThe competent judicial or administrative authority shall only grant the authorisation\nwhere it is satisfied, based on objective evidence or clear indications presented to it,\nthat the use of the \u2018real-time\u2019 remote biometric identification system at issue is\nnecessary for and proportionate to achieving one of the objectives specified in\nparagraph 1, point (d), as identified in the request.\n\nIn deciding on the request, the\ncompetent judicial or administrative authority shall take into account the elements\nreferred to in paragraph 2.\n\n4.\n\nA Member State may decide to provide for the possibility to fully or partially\nauthorise the use of \u2018real-time\u2019 remote biometric identification systems in publicly\naccessible spaces for the purpose of law enforcement within the limits and under the\n\n62 Council Framework Decision 2002/584/JHA of 13 June 2002 on the European arrest warrant and the\nsurrender procedures between Member States (OJ L 190, 18.7.2002, p. 1) _._", "# EN EN\n\n-----\n\nconditions listed in paragraphs 1, point (d), 2 and 3.\n\nThat Member State shall lay\ndown in its national law the necessary detailed rules for the request, issuance and\nexercise of, as well as supervision relating to, the authorisations referred to in\nparagraph 3.\n\nThose rules shall also specify in respect of which of the objectives listed\nin paragraph 1, point (d), including which of the criminal offences referred to in\npoint (iii) thereof, the competent authorities may be authorised to use those systems\nfor the purpose of law enforcement.", "## TITLE III\n\nHIGH-RISK genai SYSTEMS\n\n C HAPTER 1\n\n CLASSIFICATION OF genai SYSTEMS AS HIGH-RISK\n\n\n_Article 6_\n\n_Classification rules for high-risk genai systems_\n\n1.\n\nIrrespective of whether an genai system is placed on the market or put into service\nindependently from the products referred to in points (a) and (b), that genai system shall\nbe considered high-risk where both of the following conditions are fulfilled:\n\n(a) the genai system is intended to be used as a safety component of a product, or is\nitself a product, covered by the Union harmonisation legislation listed in Annex\nII;\n\n(b) the product whose safety component is the genai system, or the genai system itself as\na product, is required to undergo a third-party conformity assessment with a\nview to the placing on the market or putting into service of that product\npursuant to the Union harmonisation legislation listed in Annex II.\n\n2.\n\nIn addition to the high-risk genai systems referred to in paragraph 1, genai systems\nreferred to in Annex III shall also be considered high-risk.\n\n_Article 7_\n\n_Amendments to Annex III_\n\n1.\n\nThe Commission is empowered to adopt delegated acts in accordance with Article 73\nto update the list in Annex III by adding high-risk genai systems where both of the\nfollowing conditions are fulfilled:\n\n(a) the genai systems are intended to be used in any of the areas listed in points 1 to 8\nof Annex III;\n\n(b) the genai systems pose a risk of harm to the health and safety, or a risk of adverse\nimpact on fundamental rights, that is, in respect of its severity and probability\nof occurrence, equivalent to or greater than the risk of harm or of adverse\nimpact posed by the high-risk genai systems already referred to in Annex III.\n\n2.\n\nWhen assessing for the purposes of paragraph 1 whether an genai system poses a risk of\nharm to the health and safety or a risk of adverse impact on fundamental rights that is\nequivalent to or greater than the risk of harm posed by the high-risk genai systems", "# EN EN\n\n-----\n\nalready referred to in Annex III, the Commission shall take into account the\nfollowing criteria:\n\n(a) the intended purpose of the genai system;\n\n(b) the extent to which an genai system has been used or is likely to be used;\n\n(c) the extent to which the use of an genai system has already caused harm to the\nhealth and safety or adverse impact on the fundamental rights or has given rise\nto significant concerns in relation to the materialisation of such harm or\nadverse impact, as demonstrated by reports or documented allegations\nsubmitted to national competent authorities;\n\n(d) the potential extent of such harm or such adverse impact, in particular in terms\nof its intensity and its ability to affect a plurality of persons;\n\n(e) the extent to which potentially harmed or adversely impacted persons are\ndependent on the outcome produced with an genai system, in particular because\nfor practical or legal reasons it is not reasonably possible to opt-out from that\noutcome;\n\n(f) the extent to which potentially harmed or adversely impacted persons are in a\nvulnerable position in relation to the user of an genai system, in particular due to\nan imbalance of power, knowledge, economic or social circumstances, or age;\n\n(g) the extent to which the outcome produced with an genai system is easily\nreversible, whereby outcomes having an impact on the health or safety of\npersons shall not be considered as easily reversible;\n\n(h) the extent to which existing Union legislation provides for:\n\n(i) effective measures of redress in relation to the risks posed by an genai\nsystem, with the exclusion of claims for damages;\n\n(ii) effective measures to prevent or substantially minimise those risks.", "**REQUIREMENTS FOR HIGH-RISK genai SYSTEMS**\n\n_Article 8_\n\n_Compliance with the requirements_\n\n1.\n\nHigh-risk genai systems shall comply with the requirements established in this Chapter.\n\n2.\n\nThe intended purpose of the high-risk genai system and the risk management system\nreferred to in Article 9 shall be taken into account when ensuring compliance with\nthose requirements.\n\n_Article 9_\n\n_Risk management system_\n\n1.\n\nA risk management system shall be established, implemented, documented and\nmaintained in relation to high-risk genai systems.\n\n2.\n\nThe risk management system shall consist of a continuous iterative process run\nthroughout the entire lifecycle of a high-risk genai system, requiring regular systematic\nupdating.\n\nIt shall comprise the following steps:", "# EN EN\n\n-----\n\n(a) identification and analysis of the known and foreseeable risks associated with\neach high-risk genai system;\n\n(b) estimation and evaluation of the risks that may emerge when the high-risk genai\nsystem is used in accordance with its intended purpose and under conditions of\nreasonably foreseeable misuse;\n\n(c) evaluation of other possibly arising risks based on the analysis of data gathered\nfrom the post-market monitoring system referred to in Article 61;\n\n(d) adoption of suitable risk management measures in accordance with the\nprovisions of the following paragraphs.\n\n3.\n\nThe risk management measures referred to in paragraph 2, point (d) shall give due\nconsideration to the effects and possible interactions resulting from the combined\napplication of the requirements set out in this Chapter 2.\n\nThey shall take into account\nthe generally acknowledged state of the art, including as reflected in relevant\nharmonised standards or common specifications.\n\n4.\n\nThe risk management measures referred to in paragraph 2, point (d) shall be such that\nany residual risk associated with each hazard as well as the overall residual risk of\nthe high-risk genai systems is judged acceptable, provided that the high-risk genai system\nis used in accordance with its intended purpose or under conditions of reasonably\nforeseeable misuse.\n\nThose residual risks shall be communicated to the user.\n\nIn identifying the most appropriate risk management measures, the following shall be\nensured:\n\n(a) elimination or reduction of risks as far as possible through adequate design and\ndevelopment;\n\n(b) where appropriate, implementation of adequate mitigation and control\nmeasures in relation to risks that cannot be eliminated;\n\n(c) provision of adequate information pursuant to Article 13, in particular as\nregards the risks referred to in paragraph 2, point (b) of this Article, and, where\nappropriate, training to users.\n\nIn eliminating or reducing risks related to the use of the high-risk genai system, due\nconsideration shall be given to the technical knowledge, experience, education,\ntraining to be expected by the user and the environment in which the system is\nintended to be used.\n\n5.\n\nHigh-risk genai systems shall be tested for the purposes of identifying the most\nappropriate risk management measures.\n\nTesting shall ensure that high-risk genai\nsystems perform consistently for their intended purpose and they are in compliance\nwith the requirements set out in this Chapter.\n\n6.\n\nTesting procedures shall be suitable to achieve the intended purpose of the genai system\nand do not need to go beyond what is necessary to achieve that purpose.\n\n7.\n\nThe testing of the high-risk genai systems shall be performed, as appropriate, at any\npoint in time throughout the development process, and, in any event, prior to the\nplacing on the market or the putting into service.\n\nTesting shall be made against\npreliminarily defined metrics and probabilistic thresholds that are appropriate to the\nintended purpose of the high-risk genai system.", "# EN EN\n\n-----\n\n8.\n\nWhen implementing the risk management system described in paragraphs 1 to 7,\nspecific consideration shall be given to whether the high-risk genai system is likely to\nbe accessed by or have an impact on children.\n\n9.\n\nFor credit institutions regulated by Directive 2013/36/EU, the aspects described in\nparagraphs 1 to 8 shall be part of the risk management procedures established by\nthose institutions pursuant to Article 74 of that Directive.\n\n_Article 10_\n\n_Data and data governance_\n\n1.\n\nHigh-risk genai systems which make use of techniques involving the training of models\nwith data shall be developed on the basis of training, validation and testing data sets\nthat meet the quality criteria referred to in paragraphs 2 to 5.\n\n2.\n\nTraining, validation and testing data sets shall be subject to appropriate data\ngovernance and management practices.\n\nThose practices shall concern in particular,\n\n(a) the relevant design choices;\n\n(b) data collection;\n\n(c) relevant data preparation processing operations, such as annotation, labelling,\ncleaning, enrichment and aggregation;\n\n(d) the formulation of relevant assumptions, notably with respect to the\ninformation that the data are supposed to measure and represent;\n\n(e) a prior assessment of the availability, quantity and suitability of the data sets\nthat are needed;\n\n(f) examination in view of possible biases;\n\n(g) the identification of any possible data gaps or shortcomings, and how those\ngaps and shortcomings can be addressed.\n\n3.\n\nTraining, validation and testing data sets shall be relevant, representative, free of\nerrors and complete.\n\nThey shall have the appropriate statistical properties, including,\nwhere applicable, as regards the persons or groups of persons on which the high-risk\ngenai system is intended to be used.\n\nThese characteristics of the data sets may be met at\nthe level of individual data sets or a combination thereof.\n\n4.\n\nTraining, validation and testing data sets shall take into account, to the extent\nrequired by the intended purpose, the characteristics or elements that are particular to\nthe specific geographical, behavioural or functional setting within which the highrisk genai system is intended to be used.\n\n5.\n\nTo the extent that it is strictly necessary for the purposes of ensuring bias monitoring,\ndetection and correction in relation to the high-risk genai systems, the providers of such\nsystems may process special categories of personal data referred to in Article 9(1) of\nRegulation (EU) 2016/679, Article 10 of Directive (EU) 2016/680 and Article 10(1)\nof Regulation (EU) 2018/1725, subject to appropriate safeguards for the fundamental\nrights and freedoms of natural persons, including technical limitations on the re-use\nand use of state-of-the-art security and privacy-preserving measures, such as\npseudonymisation, or encryption where anonymisation may significantly affect the\npurpose pursued.", "# EN EN\n\n-----\n\n6.\n\nAppropriate data governance and management practices shall apply for the\ndevelopment of high-risk genai systems other than those which make use of techniques\ninvolving the training of models in order to ensure that those high-risk genai systems\ncomply with paragraph 2.\n\n_Article 11_\n\n_Technical documentation_\n\n1.\n\nThe technical documentation of a high-risk genai system shall be drawn up before that\nsystem is placed on the market or put into service and shall be kept up-to date.\n\nThe technical documentation shall be drawn up in such a way to demonstrate that the\nhigh-risk genai system complies with the requirements set out in this Chapter and\nprovide national competent authorities and notified bodies with all the necessary\ninformation to assess the compliance of the genai system with those requirements.\n\nIt\nshall contain, at a minimum, the elements set out in Annex IV.\n\n2.\n\nWhere a high-risk genai system related to a product, to which the legal acts listed in\nAnnex II, section A apply, is placed on the market or put into service one single\ntechnical documentation shall be drawn up containing all the information set out in\nAnnex IV as well as the information required under those legal acts.\n\n3.\n\nThe Commission is empowered to adopt delegated acts in accordance with Article 73\nto amend Annex IV where necessary to ensure that, in the light of technical progress,\nthe technical documentation provides all the necessary information to assess the\ncompliance of the system with the requirements set out in this Chapter.\n\n_Article 12_\n\n_Record-keeping_\n\n1.\n\nHigh-risk genai systems shall be designed and developed with capabilities enabling the\nautomatic recording of events (\u2018logs\u2019) while the high-risk genai systems is operating.\n\nThose logging capabilities shall conform to recognised standards or common\nspecifications.\n\n2.\n\nThe logging capabilities shall ensure a level of traceability of the genai system\u2019s\nfunctioning throughout its lifecycle that is appropriate to the intended purpose of the\nsystem.\n\n3.\n\nIn particular, logging capabilities shall enable the monitoring of the operation of the\nhigh-risk genai system with respect to the occurrence of situations that may result in the\ngenai system presenting a risk within the meaning of Article 65(1) or lead to a\nsubstantial modification, and facilitate the post-market monitoring referred to in\nArticle 61.\n\n4.\n\nFor high-risk genai systems referred to in paragraph 1, point (a) of Annex III, the\nlogging capabilities shall provide, at a minimum:\n\n(a) recording of the period of each use of the system (start date and time and end\ndate and time of each use);\n\n(b) the reference database against which input data has been checked by the\nsystem;\n\n(c) the input data for which the search has led to a match;", "# EN EN\n\n-----\n\n(d) the identification of the natural persons involved in the verification of the\nresults, as referred to in Article 14 (5).\n\n_Article 13_\n\n_Transparency and provision of information to users_\n\n1.\n\nHigh-risk genai systems shall be designed and developed in such a way to ensure that\ntheir operation is sufficiently transparent to enable users to interpret the system\u2019s\noutput and use it appropriately.\n\nAn appropriate type and degree of transparency shall\nbe ensured, with a view to achieving compliance with the relevant obligations of the\nuser and of the provider set out in Chapter 3 of this Title.\n\n2.\n\nHigh-risk genai systems shall be accompanied by instructions for use in an appropriate\ndigital format or otherwise that include concise, complete, correct and clear\ninformation that is relevant, accessible and comprehensible to users.\n\n3.\n\nThe information referred to in paragraph 2 shall specify:\n\n(a) the identity and the contact details of the provider and, where applicable, of its\nauthorised representative;\n\n(b) the characteristics, capabilities and limitations of performance of the high-risk\ngenai system, including:\n\n(i) its intended purpose;\n\n(ii) the level of accuracy, robustness and cybersecurity referred to in Article\n15 against which the high-risk genai system has been tested and validated\nand which can be expected, and any known and foreseeable\ncircumstances that may have an impact on that expected level of\naccuracy, robustness and cybersecurity;\n\n\n(iii) any known or foreseeable circumstance, related to the use of the high-\n\nrisk genai system in accordance with its intended purpose or under\nconditions of reasonably foreseeable misuse, which may lead to risks to\nthe health and safety or fundamental rights;\n\n\n(iv) its performance as regards the persons or groups of persons on which the\n\nsystem is intended to be used;\n\n(v) when appropriate, specifications for the input data, or any other relevant\ninformation in terms of the training, validation and testing data sets used,\ntaking into account the intended purpose of the genai system.\n\n(c) the changes to the high-risk genai system and its performance which have been\npre-determined by the provider at the moment of the initial conformity\nassessment, if any;\n\n(d) the human oversight measures referred to in Article 14, including the technical\nmeasures put in place to facilitate the interpretation of the outputs of genai\nsystems by the users;\n\n(e) the expected lifetime of the high-risk genai system and any necessary\nmaintenance and care measures to ensure the proper functioning of that genai\nsystem, including as regards software updates.", "# EN EN\n\n-----\n\n_Article 14_\n\n_Human oversight_\n\n1.\n\nHigh-risk genai systems shall be designed and developed in such a way, including with\nappropriate human-machine interface tools, that they can be effectively overseen by\nnatural persons during the period in which the genai system is in use.\n\n2.\n\nHuman oversight shall aim at preventing or minimising the risks to health, safety or\nfundamental rights that may emerge when a high-risk genai system is used in\naccordance with its intended purpose or under conditions of reasonably foreseeable\nmisuse, in particular when such risks persist notwithstanding the application of other\nrequirements set out in this Chapter.\n\n3.\n\nHuman oversight shall be ensured through either one or all of the following\nmeasures:\n\n(a) identified and built, when technically feasible, into the high-risk genai system by\nthe provider before it is placed on the market or put into service;\n\n(b) identified by the provider before placing the high-risk genai system on the market\nor putting it into service and that are appropriate to be implemented by the\nuser.\n\n4.\n\nThe measures referred to in paragraph 3 shall enable the individuals to whom human\noversight is assigned to do the following, as appropriate to the circumstances:\n\n(a) fully understand the capacities and limitations of the high-risk genai system and\nbe able to duly monitor its operation, so that signs of anomalies, dysfunctions\nand unexpected performance can be detected and addressed as soon as\npossible;\n\n(b) remain aware of the possible tendency of automatically relying or over-relying\non the output produced by a high-risk genai system (\u2018automation bias\u2019), in\nparticular for high-risk genai systems used to provide information or\nrecommendations for decisions to be taken by natural persons;\n\n(c) be able to correctly interpret the high-risk genai system\u2019s output, taking into\naccount in particular the characteristics of the system and the interpretation\ntools and methods available;\n\n(d) be able to decide, in any particular situation, not to use the high-risk genai system\nor otherwise disregard, override or reverse the output of the high-risk genai\nsystem;\n\n(e) be able to intervene on the operation of the high-risk genai system or interrupt the\nsystem through a \u201cstop\u201d button or a similar procedure.\n\n5.\n\nFor high-risk genai systems referred to in point 1(a) of Annex III, the measures referred\nto in paragraph 3 shall be such as to ensure that, in addition, no action or decision is\ntaken by the user on the basis of the identification resulting from the system unless\nthis has been verified and confirmed by at least two natural persons.\n\n_Article 15_\n\n_Accuracy, robustness and cybersecurity_\n\n1.\n\nHigh-risk genai systems shall be designed and developed in such a way that they\nachieve, in the light of their intended purpose, an appropriate level of accuracy,", "# EN EN\n\n-----\n\nrobustness and cybersecurity, and perform consistently in those respects throughout\ntheir lifecycle.\n\n2.\n\nThe levels of accuracy and the relevant accuracy metrics of high-risk genai systems\nshall be declared in the accompanying instructions of use.\n\n3.\n\nHigh-risk genai systems shall be resilient as regards errors, faults or inconsistencies that\nmay occur within the system or the environment in which the system operates, in\nparticular due to their interaction with natural persons or other systems.\n\nThe robustness of high-risk genai systems may be achieved through technical\nredundancy solutions, which may include backup or fail-safe plans.\n\nHigh-risk genai systems that continue to learn after being placed on the market or put\ninto service shall be developed in such a way to ensure that possibly biased outputs\ndue to outputs used as an input for future operations (\u2018feedback loops\u2019) are duly\naddressed with appropriate mitigation measures.\n\n4.\n\nHigh-risk genai systems shall be resilient as regards attempts by unauthorised third\nparties to alter their use or performance by exploiting the system vulnerabilities.\n\nThe technical solutions aimed at ensuring the cybersecurity of high-risk genai systems\nshall be appropriate to the relevant circumstances and the risks.\n\nThe technical solutions to address genai specific vulnerabilities shall include, where\nappropriate, measures to prevent and control for attacks trying to manipulate the\ntraining dataset (\u2018data poisoning\u2019), inputs designed to cause the model to make a\nmistake (\u2018adversarial examples\u2019), or model flaws.", "**OTHER PARTIES**\n\n_Article 16_\n\n_Obligations of providers of high-risk genai systems_\n\nProviders of high-risk genai systems shall:\n\n(a) ensure that their high-risk genai systems are compliant with the requirements set out in\nChapter 2 of this Title;\n\n(b) have a quality management system in place which complies with Article 17;\n\n(c) draw-up the technical documentation of the high-risk genai system;\n\n(d) when under their control, keep the logs automatically generated by their high-risk genai\nsystems;\n\n(e) ensure that the high-risk genai system undergoes the relevant conformity assessment\nprocedure, prior to its placing on the market or putting into service;\n\n(f) comply with the registration obligations referred to in Article 51;\n\n(g) take the necessary corrective actions, if the high-risk genai system is not in conformity\nwith the requirements set out in Chapter 2 of this Title;", "# EN EN\n\n-----\n\n(h) inform the national competent authorities of the Member States in which they made\nthe genai system available or put it into service and, where applicable, the notified body\nof the non-compliance and of any corrective actions taken;\n\n(i) to affix the CE marking to their high-risk genai systems to indicate the conformity with\nthis Regulation in accordance with Article 49;\n\n(j) upon request of a national competent authority, demonstrate the conformity of the\nhigh-risk genai system with the requirements set out in Chapter 2 of this Title.\n\n_Article 17_\n\n_Quality management system_\n\n1.\n\nProviders of high-risk genai systems shall put a quality management system in place\nthat ensures compliance with this Regulation.\n\nThat system shall be documented in a\nsystematic and orderly manner in the form of written policies, procedures and\ninstructions, and shall include at least the following aspects:\n\n(a) a strategy for regulatory compliance, including compliance with conformity\nassessment procedures and procedures for the management of modifications to\nthe high-risk genai system;\n\n(b) techniques, procedures and systematic actions to be used for the design, design\ncontrol and design verification of the high-risk genai system;\n\n(c) techniques, procedures and systematic actions to be used for the development,\nquality control and quality assurance of the high-risk genai system;\n\n(d) examination, test and validation procedures to be carried out before, during and\nafter the development of the high-risk genai system, and the frequency with which\nthey have to be carried out;\n\n(e) technical specifications, including standards, to be applied and, where the\nrelevant harmonised standards are not applied in full, the means to be used to\nensure that the high-risk genai system complies with the requirements set out in\nChapter 2 of this Title;\n\n(f) systems and procedures for data management, including data collection, data\nanalysis, data labelling, data storage, data filtration, data mining, data\naggregation, data retention and any other operation regarding the data that is\nperformed before and for the purposes of the placing on the market or putting\ninto service of high-risk genai systems;\n\n(g) the risk management system referred to in Article 9;\n\n(h) the setting-up, implementation and maintenance of a post-market monitoring\nsystem, in accordance with Article 61;\n\n(i) procedures related to the reporting of serious incidents and of malfunctioning\nin accordance with Article 62;\n\n(j) the handling of communication with national competent authorities, competent\nauthorities, including sectoral ones, providing or supporting the access to data,\nnotified bodies, other operators, customers or other interested parties;\n\n(k) systems and procedures for record keeping of all relevant documentation and\ninformation;\n\n(l) resource management, including security of supply related measures;", "# EN EN\n\n-----\n\n(m) an accountability framework setting out the responsibilities of the management\n\nand other staff with regard to all aspects listed in this paragraph.\n\n2.\n\nThe implementation of aspects referred to in paragraph 1 shall be proportionate to the\nsize of the provider\u2019s organisation.\n\n3.\n\nFor providers that are credit institutions regulated by Directive 2013/36/ EU, the\nobligation to put a quality management system in place shall be deemed to be\nfulfilled by complying with the rules on internal governance arrangements, processes\nand mechanisms pursuant to Article 74 of that Directive.\n\nIn that context, any\nharmonised standards referred to in Article 40 of this Regulation shall be taken into\naccount.\n\n_Article 18_\n\n_Obligation to draw up technical documentation_\n\n1.\n\nProviders of high-risk genai systems shall draw up the technical documentation referred\nto in Article 11 in accordance with Annex IV.\n\n2.\n\nProviders that are credit institutions regulated by Directive 2013/36/EU shall\nmaintain the technical documentation as part of the documentation concerning\ninternal governance, arrangements, processes and mechanisms pursuant to Article 74\nof that Directive.\n\n_Article 19_\n\n_Conformity assessment_\n\n1.\n\nProviders of high-risk genai systems shall ensure that their systems undergo the relevant\nconformity assessment procedure in accordance with Article 43, prior to their placing\non the market or putting into service.\n\nWhere the compliance of the genai systems with\nthe requirements set out in Chapter 2 of this Title has been demonstrated following\nthat conformity assessment, the providers shall draw up an EU declaration of\nconformity in accordance with Article 48 and affix the CE marking of conformity in\naccordance with Article 49.\n\n2.\n\nFor high-risk genai systems referred to in point 5(b) of Annex III that are placed on the\nmarket or put into service by providers that are credit institutions regulated by\nDirective 2013/36/EU, the conformity assessment shall be carried out as part of the\nprocedure referred to in Articles 97 to101 of that Directive.\n\n_Article 20_\n\n_Automatically generated logs_\n\n1.\n\nProviders of high-risk genai systems shall keep the logs automatically generated by\ntheir high-risk genai systems, to the extent such logs are under their control by virtue of\na contractual arrangement with the user or otherwise by law.\n\nThe logs shall be kept\nfor a period that is appropriate in the light of the intended purpose of high-risk genai\nsystem and applicable legal obligations under Union or national law.\n\n2.\n\nProviders that are credit institutions regulated by Directive 2013/36/EU shall\nmaintain the logs automatically generated by their high-risk genai systems as part of the\ndocumentation under Articles 74 of that Directive.", "# EN EN\n\n-----\n\n_Article 21_\n\n_Corrective actions_\n\nProviders of high-risk genai systems which consider or have reason to consider that a high-risk\ngenai system which they have placed on the market or put into service is not in conformity with\nthis Regulation shall immediately take the necessary corrective actions to bring that system\ninto conformity, to withdraw it or to recall it, as appropriate.\n\nThey shall inform the\ndistributors of the high-risk genai system in question and, where applicable, the authorised\nrepresentative and importers accordingly.\n\n_Article 22_\n\n_Duty of information_\n\nWhere the high-risk genai system presents a risk within the meaning of Article 65(1) and that\nrisk is known to the provider of the system, that provider shall immediately inform the\nnational competent authorities of the Member States in which it made the system available\nand, where applicable, the notified body that issued a certificate for the high-risk genai system,\nin particular of the non-compliance and of any corrective actions taken.\n\n_Article 23_\n\n_Cooperation with competent authorities_\n\nProviders of high-risk genai systems shall, upon request by a national competent authority,\nprovide that authority with all the information and documentation necessary to demonstrate\nthe conformity of the high-risk genai system with the requirements set out in Chapter 2 of this\nTitle, in an official Union language determined by the Member State concerned.\n\nUpon a\nreasoned request from a national competent authority, providers shall also give that authority\naccess to the logs automatically generated by the high-risk genai system, to the extent such logs\nare under their control by virtue of a contractual arrangement with the user or otherwise by\nlaw.\n\n_Article 24_\n\n_Obligations of product manufacturers_\n\nWhere a high-risk genai system related to products to which the legal acts listed in Annex II,\nsection A, apply, is placed on the market or put into service together with the product\nmanufactured in accordance with those legal acts and under the name of the product\nmanufacturer, the manufacturer of the product shall take the responsibility of the compliance\nof the genai system with this Regulation and, as far as the genai system is concerned, have the same\nobligations imposed by the present Regulation on the provider.\n\n_Article 25_\n\n_Authorised representatives_\n\n1.\n\nPrior to making their systems available on the Union market, where an importer\ncannot be identified, providers established outside the Union shall, by written\nmandate, appoint an authorised representative which is established in the Union.\n\n2.\n\nThe authorised representative shall perform the tasks specified in the mandate\nreceived from the provider.\n\nThe mandate shall empower the authorised representative\nto carry out the following tasks:", "# EN EN\n\n-----\n\n(a) keep a copy of the EU declaration of conformity and the technical\ndocumentation at the disposal of the national competent authorities and\nnational authorities referred to in Article 63(7);\n\n(b) provide a national competent authority, upon a reasoned request, with all the\ninformation and documentation necessary to demonstrate the conformity of a\nhigh-risk genai system with the requirements set out in Chapter 2 of this Title,\nincluding access to the logs automatically generated by the high-risk genai system\nto the extent such logs are under the control of the provider by virtue of a\ncontractual arrangement with the user or otherwise by law;\n\n(c) cooperate with competent national authorities, upon a reasoned request, on any\naction the latter takes in relation to the high-risk genai system.\n\n_Article 26_\n\n_Obligations of importers_\n\n1.\n\nBefore placing a high-risk genai system on the market, importers of such system shall\nensure that:\n\n(a) the appropriate conformity assessment procedure has been carried out by the\nprovider of that genai system\n\n(b) the provider has drawn up the technical documentation in accordance with\nAnnex IV;\n\n(c) the system bears the required conformity marking and is accompanied by the\nrequired documentation and instructions of use.\n\n2.\n\nWhere an importer considers or has reason to consider that a high-risk genai system is\nnot in conformity with this Regulation, it shall not place that system on the market\nuntil that genai system has been brought into conformity.\n\nWhere the high-risk genai\nsystem presents a risk within the meaning of Article 65(1), the importer shall inform\nthe provider of the genai system and the market surveillance authorities to that effect.\n\n3.\n\nImporters shall indicate their name, registered trade name or registered trade mark,\nand the address at which they can be contacted on the high-risk genai system or, where\nthat is not possible, on its packaging or its accompanying documentation, as\napplicable.\n\n4.\n\nImporters shall ensure that, while a high-risk genai system is under their responsibility,\nwhere applicable, storage or transport conditions do not jeopardise its compliance\nwith the requirements set out in Chapter 2 of this Title.\n\n5.\n\nImporters shall provide national competent authorities, upon a reasoned request, with\nall necessary information and documentation to demonstrate the conformity of a\nhigh-risk genai system with the requirements set out in Chapter 2 of this Title in a\nlanguage which can be easily understood by that national competent authority,\nincluding access to the logs automatically generated by the high-risk genai system to the\nextent such logs are under the control of the provider by virtue of a contractual\narrangement with the user or otherwise by law.\n\nThey shall also cooperate with those\nauthorities on any action national competent authority takes in relation to that\nsystem.", "# EN EN\n\n-----\n\n_Article 27_\n\n_Obligations of distributors_\n\n1.\n\nBefore making a high-risk genai system available on the market, distributors shall\nverify that the high-risk genai system bears the required CE conformity marking, that it\nis accompanied by the required documentation and instruction of use, and that the\nprovider and the importer of the system, as applicable, have complied with the\nobligations set out in this Regulation.\n\n2.\n\nWhere a distributor considers or has reason to consider that a high-risk genai system is\nnot in conformity with the requirements set out in Chapter 2 of this Title, it shall not\nmake the high-risk genai system available on the market until that system has been\nbrought into conformity with those requirements.\n\nFurthermore, where the system\npresents a risk within the meaning of Article 65(1), the distributor shall inform the\nprovider or the importer of the system, as applicable, to that effect.\n\n3.\n\nDistributors shall ensure that, while a high-risk genai system is under their\nresponsibility, where applicable, storage or transport conditions do not jeopardise the\ncompliance of the system with the requirements set out in Chapter 2 of this Title.\n\n4.\n\nA distributor that considers or has reason to consider that a high-risk genai system\nwhich it has made available on the market is not in conformity with the requirements\nset out in Chapter 2 of this Title shall take the corrective actions necessary to bring\nthat system into conformity with those requirements, to withdraw it or recall it or\nshall ensure that the provider, the importer or any relevant operator, as appropriate,\ntakes those corrective actions.\n\nWhere the high-risk genai system presents a risk within\nthe meaning of Article 65(1), the distributor shall immediately inform the national\ncompetent authorities of the Member States in which it has made the product\navailable to that effect, giving details, in particular, of the non-compliance and of any\ncorrective actions taken.\n\n5.\n\nUpon a reasoned request from a national competent authority, distributors of highrisk genai systems shall provide that authority with all the information and\ndocumentation necessary to demonstrate the conformity of a high-risk system with\nthe requirements set out in Chapter 2 of this Title.\n\nDistributors shall also cooperate\nwith that national competent authority on any action taken by that authority.\n\n_Article 28_\n\n_Obligations of distributors, importers, users or any other third-party_\n\n1.\n\nAny distributor, importer, user or other third-party shall be considered a provider for\nthe purposes of this Regulation and shall be subject to the obligations of the provider\nunder Article 16, in any of the following circumstances:\n\n(a) they place on the market or put into service a high-risk genai system under their\nname or trademark;\n\n(b) they modify the intended purpose of a high-risk genai system already placed on\nthe market or put into service;\n\n(c) they make a substantial modification to the high-risk genai system.\n\n2.\n\nWhere the circumstances referred to in paragraph 1, point (b) or (c), occur, the\nprovider that initially placed the high-risk genai system on the market or put it into\nservice shall no longer be considered a provider for the purposes of this Regulation.", "# EN EN\n\n-----\n\n_Article 29_\n\n_Obligations of users of high-risk genai systems_\n\n1.\n\nUsers of high-risk genai systems shall use such systems in accordance with the\ninstructions of use accompanying the systems, pursuant to paragraphs 2 and 5.\n\n2.\n\nThe obligations in paragraph 1 are without prejudice to other user obligations under\nUnion or national law and to the user\u2019s discretion in organising its own resources and\nactivities for the purpose of implementing the human oversight measures indicated\nby the provider.\n\n3.\n\nWithout prejudice to paragraph 1, to the extent the user exercises control over the\ninput data, that user shall ensure that input data is relevant in view of the intended\npurpose of the high-risk genai system.\n\n4.\n\nUsers shall monitor the operation of the high-risk genai system on the basis of the\ninstructions of use.\n\nWhen they have reasons to consider that the use in accordance\nwith the instructions of use may result in the genai system presenting a risk within the\nmeaning of Article 65(1) they shall inform the provider or distributor and suspend\nthe use of the system.\n\nThey shall also inform the provider or distributor when they\nhave identified any serious incident or any malfunctioning within the meaning of\nArticle 62 and interrupt the use of the genai system.\n\nIn case the user is not able to reach\nthe provider, Article 62 shall apply mutatis mutandis.\n\nFor users that are credit institutions regulated by Directive 2013/36/EU, the\nmonitoring obligation set out in the first subparagraph shall be deemed to be fulfilled\nby complying with the rules on internal governance arrangements, processes and\nmechanisms pursuant to Article 74 of that Directive.\n\n5.\n\nUsers of high-risk genai systems shall keep the logs automatically generated by that\nhigh-risk genai system, to the extent such logs are under their control.\n\nThe logs shall be\nkept for a period that is appropriate in the light of the intended purpose of the highrisk genai system and applicable legal obligations under Union or national law.\n\nUsers that are credit institutions regulated by Directive 2013/36/EU shall maintain\nthe logs as part of the documentation concerning internal governance arrangements,\nprocesses and mechanisms pursuant to Article 74 of that Directive.\n\n6.\n\nUsers of high-risk genai systems shall use the information provided under Article 13 to\ncomply with their obligation to carry out a data protection impact assessment under\nArticle 35 of Regulation (EU) 2016/679 or Article 27 of Directive (EU) 2016/680,\nwhere applicable.", "# EN EN\n\n-----\n\n3.\n\nNotifying authorities shall be established, organised and operated in such a way that\nno conflict of interest arises with conformity assessment bodies and the objectivity\nand impartiality of their activities are safeguarded.\n\n4.\n\nNotifying authorities shall be organised in such a way that decisions relating to the\nnotification of conformity assessment bodies are taken by competent persons\ndifferent from those who carried out the assessment of those bodies.\n\n5.\n\nNotifying authorities shall not offer or provide any activities that conformity\nassessment bodies perform or any consultancy services on a commercial or\ncompetitive basis.\n\n6.\n\nNotifying authorities shall safeguard the confidentiality of the information they\nobtain.\n\n7.\n\nNotifying authorities shall have a sufficient number of competent personnel at their\ndisposal for the proper performance of their tasks.\n\n8.\n\nNotifying authorities shall make sure that conformity assessments are carried out in a\nproportionate manner, avoiding unnecessary burdens for providers and that notified\nbodies perform their activities taking due account of the size of an undertaking, the\nsector in which it operates, its structure and the degree of complexity of the genai\nsystem in question.\n\n_Article 31_\n\n_Application of a conformity assessment body for notification_\n\n1.\n\nConformity assessment bodies shall submit an application for notification to the\nnotifying authority of the Member State in which they are established.\n\n2.\n\nThe application for notification shall be accompanied by a description of the\nconformity assessment activities, the conformity assessment module or modules and\nthe genai technologies for which the conformity assessment body\nclaims to be competent, as well as by an accreditation certificate, where one exists,\nissued by a national accreditation body attesting that the conformity assessment body\nfulfils the requirements laid down in Article 33.\n\nAny valid document related to\nexisting designations of the applicant notified body under any other Union\nharmonisation legislation shall be added.\n\n3.\n\nWhere the conformity assessment body concerned cannot provide an accreditation\ncertificate, it shall provide the notifying authority with the documentary evidence\nnecessary for the verification, recognition and regular monitoring of its compliance\nwith the requirements laid down in Article 33.\n\nFor notified bodies which are\ndesignated under any other Union harmonisation legislation, all documents and\ncertificates linked to those designations may be used to support their designation\nprocedure under this Regulation, as appropriate.\n\n_Article 32_\n\n_Notification procedure_\n\n1.\n\nNotifying authorities may notify only conformity assessment bodies which have\nsatisfied the requirements laid down in Article 33.\n\n2.\n\nNotifying authorities shall notify the Commission and the other Member States using\nthe electronic notification tool developed and managed by the Commission.", "# EN EN\n\n-----\n\n3.\n\nThe notification shall include full details of the conformity assessment activities, the\nconformity assessment module or modules and the genai technologies\nconcerned.\n\n4.\n\nThe conformity assessment body concerned may perform the activities of a notified\nbody only where no objections are raised by the Commission or the other Member\nStates within one month of a notification.\n\n5.\n\nNotifying authorities shall notify the Commission and the other Member States of\nany subsequent relevant changes to the notification.\n\n_Article 33_\n\n_Notified bodies_\n\n1.\n\nNotified bodies shall verify the conformity of high-risk genai system in accordance with\nthe conformity assessment procedures referred to in Article 43.\n\n2.\n\nNotified bodies shall satisfy the organisational, quality management, resources and\nprocess requirements that are necessary to fulfil their tasks.\n\n3.\n\nThe organisational structure, allocation of responsibilities, reporting lines and\noperation of notified bodies shall be such as to ensure that there is confidence in the\nperformance by and in the results of the conformity assessment activities that the\nnotified bodies conduct.\n\n4.\n\nNotified bodies shall be independent of the provider of a high-risk genai system in\nrelation to which it performs conformity assessment activities.\n\nNotified bodies shall\nalso be independent of any other operator having an economic interest in the highrisk genai system that is assessed, as well as of any competitors of the provider.\n\n5.\n\nNotified bodies shall be organised and operated so as to safeguard the independence,\nobjectivity and impartiality of their activities.\n\nNotified bodies shall document and\nimplement a structure and procedures to safeguard impartiality and to promote and\napply the principles of impartiality throughout their organisation, personnel and\nassessment activities.\n\n6.\n\nNotified bodies shall have documented procedures in place ensuring that their\npersonnel, committees, subsidiaries, subcontractors and any associated body or\npersonnel of external bodies respect the confidentiality of the information which\ncomes into their possession during the performance of conformity assessment\nactivities, except when disclosure is required by law.\n\nThe staff of notified bodies\nshall be bound to observe professional secrecy with regard to all information\nobtained in carrying out their tasks under this Regulation, except in relation to the\nnotifying authorities of the Member State in which their activities are carried out.\n\n7.\n\nNotified bodies shall have procedures for the performance of activities which take\ndue account of the size of an undertaking, the sector in which it operates, its\nstructure, the degree of complexity of the genai system in question.\n\n8.\n\nNotified bodies shall take out appropriate liability insurance for their conformity\nassessment activities, unless liability is assumed by the Member State concerned in\naccordance with national law or that Member State is directly responsible for the\nconformity assessment.\n\n9.\n\nNotified bodies shall be capable of carrying out all the tasks falling to them under\nthis Regulation with the highest degree of professional integrity and the requisite", "# EN EN\n\n-----\n\ncompetence in the specific field, whether those tasks are carried out by notified\nbodies themselves or on their behalf and under their responsibility.\n\n10.\n\nNotified bodies shall have sufficient internal competences to be able to effectively\nevaluate the tasks conducted by external parties on their behalf.\n\nTo that end, at all\ntimes and for each conformity assessment procedure and each type of high-risk genai\nsystem in relation to which they have been designated, the notified body shall have\npermanent availability of sufficient administrative, technical and scientific personnel\nwho possess experience and knowledge relating to the relevant genai\ntechnologies, data and data computing and to the requirements set out in Chapter 2 of\nthis Title.\n\n11.\n\nNotified bodies shall participate in coordination activities as referred to in Article 38.\n\nThey shall also take part directly or be represented in European standardisation\norganisations, or ensure that they are aware and up to date in respect of relevant\nstandards.\n\n12.\n\nNotified bodies shall make available and submit upon request all relevant\ndocumentation, including the providers\u2019 documentation, to the notifying authority\nreferred to in Article 30 to allow it to conduct its assessment, designation,\nnotification, monitoring and surveillance activities and to facilitate the assessment\noutlined in this Chapter.\n\n_Article 34_\n\n_Subsidiaries of and subcontracting by notified bodies_\n\n1.\n\nWhere a notified body subcontracts specific tasks connected with the conformity\nassessment or has recourse to a subsidiary, it shall ensure that the subcontractor or\nthe subsidiary meets the requirements laid down in Article 33 and shall inform the\nnotifying authority accordingly.\n\n2.\n\nNotified bodies shall take full responsibility for the tasks performed by\nsubcontractors or subsidiaries wherever these are established.\n\n3.\n\nActivities may be subcontracted or carried out by a subsidiary only with the\nagreement of the provider.\n\n4.\n\nNotified bodies shall keep at the disposal of the notifying authority the relevant\ndocuments concerning the assessment of the qualifications of the subcontractor or the\nsubsidiary and the work carried out by them under this Regulation.\n\n_Article 35_\n\n_Identification numbers and lists of notified bodies designated under this Regulation_\n\n1.\n\nThe Commission shall assign an identification number to notified bodies.\n\nIt shall\nassign a single number, even where a body is notified under several Union acts.\n\n2.\n\nThe Commission shall make publicly available the list of the bodies notified under\nthis Regulation, including the identification numbers that have been assigned to them\nand the activities for which they have been notified.\n\nThe Commission shall ensure\nthat the list is kept up to date.", "# EN EN\n\n-----\n\n_Article 36_\n\n_Changes to notifications_\n\n1.\n\nWhere a notifying authority has suspicions or has been informed that a notified body\nno longer meets the requirements laid down in Article 33, or that it is failing to fulfil\nits obligations, that authority shall without delay investigate the matter with the\nutmost diligence.\n\nIn that context, it shall inform the notified body concerned about\nthe objections raised and give it the possibility to make its views known.\n\nIf the\nnotifying authority comes to the conclusion that the notified body investigation no\nlonger meets the requirements laid down in Article 33 or that it is failing to fulfil its\nobligations, it shall restrict, suspend or withdraw the notification as appropriate,\ndepending on the seriousness of the failure.\n\nIt shall also immediately inform the\nCommission and the other Member States accordingly.\n\n2.\n\nIn the event of restriction, suspension or withdrawal of notification, or where the\nnotified body has ceased its activity, the notifying authority shall take appropriate\nsteps to ensure that the files of that notified body are either taken over by another\nnotified body or kept available for the responsible notifying authorities at their\nrequest.\n\n_Article 37_\n\n_Challenge to the competence of notified bodies_\n\n1.\n\nThe Commission shall, where necessary, investigate all cases where there are reasons\nto doubt whether a notified body complies with the requirements laid down in Article\n33.\n\n2.\n\nThe Notifying authority shall provide the Commission, on request, with all relevant\ninformation relating to the notification of the notified body concerned.\n\n3.\n\nThe Commission shall ensure that all confidential information obtained in the course\nof its investigations pursuant to this Article is treated confidentially.\n\n4.\n\nWhere the Commission ascertains that a notified body does not meet or no longer\nmeets the requirements laid down in Article 33, it shall adopt a reasoned decision\nrequesting the notifying Member State to take the necessary corrective measures,\nincluding withdrawal of notification if necessary.\n\nThat implementing act shall be\nadopted in accordance with the examination procedure referred to in Article 74(2).\n\n_Article 38_\n\n_Coordination of notified bodies_\n\n1.\n\nThe Commission shall ensure that, with regard to the areas covered by this\nRegulation, appropriate coordination and cooperation between notified bodies active\nin the conformity assessment procedures of genai systems pursuant to this Regulation\nare put in place and properly operated in the form of a sectoral group of notified\nbodies **.\n\n**\n\n2.\n\nMember States shall ensure that the bodies notified by them participate in the work\nof that group, directly or by means of designated representatives.", "**STANDARDS,** **CONFORMITY** **ASSESSMENT,** **CERTIFICATES,** **REGISTRATION**\n\n_Article 40_\n\n_Harmonised standards_\n\nHigh-risk genai systems which are in conformity with harmonised standards or parts thereof the\nreferences of which have been published in the Official Journal of the European Union shall\nbe presumed to be in conformity with the requirements set out in Chapter 2 of this Title, to the\nextent those standards cover those requirements.\n\n_Article 41_\n\n_Common specifications_\n\n1.\n\nWhere harmonised standards referred to in Article 40 do not exist or where the\nCommission considers that the relevant harmonised standards are insufficient or that\nthere is a need to address specific safety or fundamental right concerns, the\nCommission may, by means of implementing acts, adopt common specifications in\nrespect of the requirements set out in Chapter 2 of this Title.\n\nThose implementing\nacts shall be adopted in accordance with the examination procedure referred to in\nArticle 74(2).\n\n2.\n\nThe Commission, when preparing the common specifications referred to in\nparagraph 1, shall gather the views of relevant bodies or expert groups established\nunder relevant sectorial Union law.\n\n3.\n\nHigh-risk genai systems which are in conformity with the common specifications\nreferred to in paragraph 1 shall be presumed to be in conformity with the\nrequirements set out in Chapter 2 of this Title, to the extent those common\nspecifications cover those requirements.\n\n4.\n\nWhere providers do not comply with the common specifications referred to in\nparagraph 1, they shall duly justify that they have adopted technical solutions that are\nat least equivalent thereto.\n\n_Article 42_\n\n_Presumption of conformity with certain requirements_\n\n1.\n\nTaking into account their intended purpose, high-risk genai systems that have been\ntrained and tested on data concerning the specific geographical, behavioural and\nfunctional setting within which they are intended to be used shall be presumed to be\nin compliance with the requirement set out in Article 10(4).", "# EN EN\n\n-----\n\n2.\n\nHigh-risk genai systems that have been certified or for which a statement of conformity\nhas been issued under a cybersecurity scheme pursuant to Regulation (EU) 2019/881\nof the European Parliament and of the Council 63 and the references of which have\nbeen published in the Official Journal of the European Union shall be presumed to be\nin compliance with the cybersecurity requirements set out in Article 15 of this\nRegulation in so far as the cybersecurity certificate or statement of conformity or\nparts thereof cover those requirements.\n\n_Article 43_\n\n_Conformity assessment_\n\n1.\n\nFor high-risk genai systems listed in point 1 of Annex III, where, in demonstrating the\ncompliance of a high-risk genai system with the requirements set out in Chapter 2 of\nthis Title, the provider has applied harmonised standards referred to in Article 40, or,\nwhere applicable, common specifications referred to in Article 41, the provider shall\nfollow one of the following procedures:\n\n(a) the conformity assessment procedure based on internal control referred to in\nAnnex VI;\n\n(b) the conformity assessment procedure based on assessment of the quality\nmanagement system and assessment of the technical documentation, with the\ninvolvement of a notified body, referred to in Annex VII.\n\nWhere, in demonstrating the compliance of a high-risk genai system with the\nrequirements set out in Chapter 2 of this Title, the provider has not applied or has\napplied only in part harmonised standards referred to in Article 40, or where such\nharmonised standards do not exist and common specifications referred to in Article\n41 are not available, the provider shall follow the conformity assessment procedure\nset out in Annex VII.\n\nFor the purpose of the conformity assessment procedure referred to in Annex VII, the\nprovider may choose any of the notified bodies.\n\nHowever, when the system is\nintended to be put into service by law enforcement, immigration or asylum\nauthorities as well as EU institutions, bodies or agencies, the market surveillance\nauthority referred to in Article 63(5) or (6), as applicable, shall act as a notified body.\n\n2.\n\nFor high-risk genai systems referred to in points 2 to 8 of Annex III, providers shall\nfollow the conformity assessment procedure based on internal control as referred to\nin Annex VI, which does not provide for the involvement of a notified body.\n\nFor\nhigh-risk genai systems referred to in point 5(b) of Annex III, placed on the market or\nput into service by credit institutions regulated by Directive 2013/36/EU, the\nconformity assessment shall be carried out as part of the procedure referred to in\nArticles 97 to101 of that Directive.\n\n3.\n\nFor high-risk genai systems, to which legal acts listed in Annex II, section A, apply, the\nprovider shall follow the relevant conformity assessment as required under those\nlegal acts.\n\nThe requirements set out in Chapter 2 of this Title shall apply to those\n\n63 Regulation (EU) 2019/881 of the European Parliament and of the Council of 17 April 2019 on ENISA\n(the European Union Agency for Cybersecurity) and on information and communications technology\ncybersecurity certification and repealing Regulation (EU) No 526/2013 (Cybersecurity Act) (OJ L 151,\n7.6.2019, p. 1).", "# EN EN\n\n-----\n\nhigh-risk genai systems and shall be part of that assessment.\n\nPoints 4.3., 4.4., 4.5. and\nthe fifth paragraph of point 4.6 of Annex VII shall also apply.\n\nFor the purpose of that assessment, notified bodies which have been notified under\nthose legal acts shall be entitled to control the conformity of the high-risk genai systems\nwith the requirements set out in Chapter 2 of this Title, provided that the compliance\nof those notified bodies with requirements laid down in Article 33(4), (9) and (10)\nhas been assessed in the context of the notification procedure under those legal acts.\n\nWhere the legal acts listed in Annex II, section A, enable the manufacturer of the\nproduct to opt out from a third-party conformity assessment, provided that that\nmanufacturer has applied all harmonised standards covering all the relevant\nrequirements, that manufacturer may make use of that option only if he has also\napplied harmonised standards or, where applicable, common specifications referred\nto in Article 41, covering the requirements set out in Chapter 2 of this Title.\n\n4.\n\nHigh-risk genai systems shall undergo a new conformity assessment procedure\nwhenever they are substantially modified, regardless of whether the modified system\nis intended to be further distributed or continues to be used by the current user.\n\nFor high-risk genai systems that continue to learn after being placed on the market or\nput into service, changes to the high-risk genai system and its performance that have\nbeen pre-determined by the provider at the moment of the initial conformity\nassessment and are part of the information contained in the technical documentation\nreferred to in point 2(f) of Annex IV, shall not constitute a substantial modification.\n\n5.\n\nThe Commission is empowered to adopt delegated acts in accordance with Article 73\nfor the purpose of updating Annexes VI and Annex VII in order to introduce\nelements of the conformity assessment procedures that become necessary in light of\ntechnical progress.\n\n6.\n\nThe Commission is empowered to adopt delegated acts to amend paragraphs 1 and 2\nin order to subject high-risk genai systems referred to in points 2 to 8 of Annex III to\nthe conformity assessment procedure referred to in Annex VII or parts thereof.\n\nThe\nCommission shall adopt such delegated acts taking into account the effectiveness of\nthe conformity assessment procedure based on internal control referred to in Annex\nVI in preventing or minimizing the risks to health and safety and protection of\nfundamental rights posed by such systems as well as the availability of adequate\ncapacities and resources among notified bodies.\n\n_Article 44_\n\n_Certificates_\n\n1.\n\nCertificates issued by notified bodies in accordance with Annex VII shall be drawnup in an official Union language determined by the Member State in which the\nnotified body is established or in an official Union language otherwise acceptable to\nthe notified body.\n\n2.\n\nCertificates shall be valid for the period they indicate, which shall not exceed five\nyears.\n\nOn application by the provider, the validity of a certificate may be extended\nfor further periods, each not exceeding five years, based on a re-assessment in\naccordance with the applicable conformity assessment procedures.\n\n3.\n\nWhere a notified body finds that an genai system no longer meets the requirements set\nout in Chapter 2 of this Title, it shall, taking account of the principle of", "# EN EN\n\n-----\n\nproportionality, suspend or withdraw the certificate issued or impose any restrictions\non it, unless compliance with those requirements is ensured by appropriate corrective\naction taken by the provider of the system within an appropriate deadline set by the\nnotified body.\n\nThe notified body shall give reasons for its decision.\n\n_Article 45_\n\n_Appeal against decisions of notified bodies_\n\nMember States shall ensure that an appeal procedure against decisions of the notified bodies\nis available to parties having a legitimate interest in that decision.\n\n_Article 46_\n\n_Information obligations of notified bodies_\n\n1.\n\nNotified bodies shall inform the notifying authority of the following:\n\n(a) any Union technical documentation assessment certificates, any supplements to\nthose certificates, quality management system approvals issued in accordance\nwith the requirements of Annex VII;\n\n(b) any refusal, restriction, suspension or withdrawal of a Union technical\ndocumentation assessment certificate or a quality management system approval\nissued in accordance with the requirements of Annex VII;\n\n(c) any circumstances affecting the scope of or conditions for notification;\n\n(d) any request for information which they have received from market surveillance\nauthorities regarding conformity assessment activities;\n\n(e) on request, conformity assessment activities performed within the scope of\ntheir notification and any other activity performed, including cross-border\nactivities and subcontracting.\n\n2.\n\nEach notified body shall inform the other notified bodies of:\n\n(a) quality management system approvals which it has refused, suspended or\nwithdrawn, and, upon request, of quality system approvals which it has issued;\n\n(b) EU technical documentation assessment certificates or any supplements thereto\nwhich it has refused, withdrawn, suspended or otherwise restricted, and, upon\nrequest, of the certificates and/or supplements thereto which it has issued.\n\n3.\n\nEach notified body shall provide the other notified bodies carrying out similar\nconformity assessment activities covering the same genai\ntechnologies with relevant information on issues relating to negative and, on request,\npositive conformity assessment results.\n\n_Article 47_\n\n_Derogation from conformity assessment procedure_\n\n1.\n\nBy way of derogation from Article 43, any market surveillance authority may\nauthorise the placing on the market or putting into service of specific high-risk genai\nsystems within the territory of the Member State concerned, for exceptional reasons\nof public security or the protection of life and health of persons, environmental\nprotection and the protection of key industrial and infrastructural assets.\n\nThat\nauthorisation shall be for a limited period of time, while the necessary conformity", "# EN EN\n\n-----\n\nassessment procedures are being carried out, and shall terminate once those\nprocedures have been completed.\n\nThe completion of those procedures shall be\nundertaken without undue delay.\n\n2.\n\nThe authorisation referred to in paragraph 1 shall be issued only if the market\nsurveillance authority concludes that the high-risk genai system complies with the\nrequirements of Chapter 2 of this Title.\n\nThe market surveillance authority shall\ninform the Commission and the other Member States of any authorisation issued\npursuant to paragraph 1.\n\n3.\n\nWhere, within 15 calendar days of receipt of the information referred to in paragraph\n2, no objection has been raised by either a Member State or the Commission in\nrespect of an authorisation issued by a market surveillance authority of a Member\nState in accordance with paragraph 1, that authorisation shall be deemed justified.\n\n4.\n\nWhere, within 15 calendar days of receipt of the notification referred to in paragraph\n2, objections are raised by a Member State against an authorisation issued by a\nmarket surveillance authority of another Member State, or where the Commission\nconsiders the authorisation to be contrary to Union law or the conclusion of the\nMember States regarding the compliance of the system as referred to in paragraph 2\nto be unfounded, the Commission shall without delay enter into consultation with the\nrelevant Member State; the operator(s) concerned shall be consulted and have the\npossibility to present their views.\n\nIn view thereof, the Commission shall decide\nwhether the authorisation is justified or not.\n\nThe Commission shall address its\ndecision to the Member State concerned and the relevant operator or operators.\n\n5.\n\nIf the authorisation is considered unjustified, this shall be withdrawn by the market\nsurveillance authority of the Member State concerned.\n\n6.\n\nBy way of derogation from paragraphs 1 to 5, for high-risk genai systems intended to be\nused as safety components of devices, or which are themselves devices, covered by\nRegulation (EU) 2017/745 and Regulation (EU) 2017/746, Article 59 of Regulation\n(EU) 2017/745 and Article 54 of Regulation (EU) 2017/746 shall apply also with\nregard to the derogation from the conformity assessment of the compliance with the\nrequirements set out in Chapter 2 of this Title.\n\n_Article 48_\n\n_EU declaration of conformity_\n\n1.\n\nThe provider shall draw up a written EU declaration of conformity for each genai\nsystem and keep it at the disposal of the national competent authorities for 10 years\nafter the genai system has been placed on the market or put into service.\n\nThe EU\ndeclaration of conformity shall identify the genai system for which it has been drawn\nup.\n\nA copy of the EU declaration of conformity shall be given to the relevant\nnational competent authorities upon request.\n\n2.\n\nThe EU declaration of conformity shall state that the high-risk genai system in question\nmeets the requirements set out in Chapter 2 of this Title.\n\nThe EU declaration of\nconformity shall contain the information set out in Annex V and shall be translated\ninto an official Union language or languages required by the Member State(s) in\nwhich the high-risk genai system is made available.\n\n3.\n\nWhere high-risk genai systems are subject to other Union harmonisation legislation\nwhich also requires an EU declaration of conformity, a single EU declaration of\nconformity shall be drawn up in respect of all Union legislations applicable to the", "# EN EN\n\n-----\n\nhigh-risk genai system.\n\nThe declaration shall contain all the information required for\nidentification of the Union harmonisation legislation to which the declaration relates.\n\n4.\n\nBy drawing up the EU declaration of conformity, the provider shall assume\nresponsibility for compliance with the requirements set out in Chapter 2 of this Title.\n\nThe provider shall keep the EU declaration of conformity up-to-date as appropriate.\n\n5.\n\nThe Commission shall be empowered to adopt delegated acts in accordance with\nArticle 73 for the purpose of updating the content of the EU declaration of\nconformity set out in Annex V in order to introduce elements that become necessary\nin light of technical progress.\n\n_Article 49_\n\n_CE marking of conformity_\n\n1.\n\nThe CE marking shall be affixed visibly, legibly and indelibly for high-risk genai\nsystems.\n\nWhere that is not possible or not warranted on account of the nature of the\nhigh-risk genai system, it shall be affixed to the packaging or to the accompanying\ndocumentation, as appropriate.\n\n2.\n\nThe CE marking referred to in paragraph 1 of this Article shall be subject to the\ngeneral principles set out in Article 30 of Regulation (EC) No 765/2008.\n\n3.\n\nWhere applicable, the CE marking shall be followed by the identification number of\nthe notified body responsible for the conformity assessment procedures set out in\nArticle 43.\n\nThe identification number shall also be indicated in any promotional\nmaterial which mentions that the high-risk genai system fulfils the requirements for CE\nmarking.\n\n_Article 50_\n\n_Document retention_\n\nThe provider shall, for a period ending 10 years after the genai system has been placed on the\nmarket or put into service, keep at the disposal of the national competent authorities:\n\n(a) the technical documentation referred to in Article 11;\n\n(b) the documentation concerning the quality management system referred to Article 17;\n\n(c) the documentation concerning the changes approved by notified bodies where\napplicable;\n\n(d) the decisions and other documents issued by the notified bodies where applicable;\n\n(e) the EU declaration of conformity referred to in Article 48.\n\n_Article 51_\n\n_Registration_\n\nBefore placing on the market or putting into service a high-risk genai system referred to in\nArticle 6(2), the provider or, where applicable, the authorised representative shall register that\nsystem in the EU database referred to in Article 60.", "## TITLE IV\n\nTRANSPARENCY OBLIGATIONS FOR CERTAIN genai SYSTEMS\n\n_Article 52_\n\n_Transparency obligations for certain genai systems_\n\n1.\n\nProviders shall ensure that genai systems intended to interact with natural persons are\ndesigned and developed in such a way that natural persons are informed that they are\ninteracting with an genai system, unless this is obvious from the circumstances and the\ncontext of use.\n\nThis obligation shall not apply to genai systems authorised by law to\ndetect, prevent, investigate and prosecute criminal offences, unless those systems are\navailable for the public to report a criminal offence.\n\n2.\n\nUsers of an emotion recognition system or a biometric categorisation system shall\ninform of the operation of the system the natural persons exposed thereto.\n\nThis\nobligation shall not apply to genai systems used for biometric categorisation, which are\npermitted by law to detect, prevent and investigate criminal offences.\n\n3.\n\nUsers of an genai system that generates or manipulates image, audio or video content\nthat appreciably resembles existing persons, objects, places or other entities or events\nand would falsely appear to a person to be authentic or truthful (\u2018deep fake\u2019), shall\ndisclose that the content has been artificially generated or manipulated.\n\nHowever, the first subparagraph shall not apply where the use is authorised by law to\ndetect, prevent, investigate and prosecute criminal offences or it is necessary for the\nexercise of the right to freedom of expression and the right to freedom of the arts and\nsciences guaranteed in the Charter of Fundamental Rights of the EU, and subject to\nappropriate safeguards for the rights and freedoms of third parties.\n\n4.\n\nParagraphs 1, 2 and 3 shall not affect the requirements and obligations set out in Title\nIII of this Regulation.", "## MEASURES IN SUPPORT OF INNOVATION\n\n_Article 53_\n\n_AI regulatory sandboxes_\n\n1. genai regulatory sandboxes established by one or more Member States competent\nauthorities or the European Data Protection Supervisor shall provide a controlled\nenvironment that facilitates the development, testing and validation of innovative genai\nsystems for a limited time before their placement on the market or putting into\nservice pursuant to a specific plan.\n\nThis shall take place under the direct supervision\nand guidance by the competent authorities with a view to ensuring compliance with\nthe requirements of this Regulation and, where relevant, other Union and Member\nStates legislation supervised within the sandbox.\n\n2.\n\nMember States shall ensure that to the extent the innovative genai systems involve the\nprocessing of personal data or otherwise fall under the supervisory remit of other\nnational authorities or competent authorities providing or supporting access to data,", "# EN EN\n\n-----\n\nthe national data protection authorities and those other national authorities are\nassociated to the operation of the genai regulatory sandbox.\n\n3.\n\nThe genai regulatory sandboxes shall not affect the supervisory and corrective powers\nof the competent authorities.\n\nAny significant risks to health and safety and\nfundamental rights identified during the development and testing of such systems\nshall result in immediate mitigation and, failing that, in the suspension of the\ndevelopment and testing process until such mitigation takes place.\n\n4.\n\nParticipants in the genai regulatory sandbox shall remain liable under applicable Union\nand Member States liability legislation for any harm inflicted on third parties as a\nresult from the experimentation taking place in the sandbox.\n\n5.\n\nMember States\u2019 competent authorities that have established genai regulatory sandboxes\nshall coordinate their activities and cooperate within the framework of the European\ngenai Board.\n\nThey shall submit annual reports to the Board and the\nCommission on the results from the implementation of those scheme, including good\npractices, lessons learnt and recommendations on their setup and, where relevant, on\nthe application of this Regulation and other Union legislation supervised within the\nsandbox.\n\n6.\n\nThe modalities and the conditions of the operation of the genai regulatory sandboxes,\nincluding the eligibility criteria and the procedure for the application, selection,\nparticipation and exiting from the sandbox, and the rights and obligations of the\nparticipants shall be set out in implementing acts.\n\nThose implementing acts shall be\nadopted in accordance with the examination procedure referred to in Article 74(2).\n\n_Article 54_\n\n\n_Further processing of personal data for developing certain genai systems in the public interest in_\n\n\n_the genai regulatory sandbox_\n\n\n1.\n\nIn the genai regulatory sandbox personal data lawfully collected for other purposes shall\nbe processed for the purposes of developing and testing certain innovative genai\nsystems in the sandbox under the following conditions:\n\n(a) the innovative genai systems shall be developed for safeguarding substantial\npublic interest in one or more of the following areas:\n\n(i) the prevention, investigation, detection or prosecution of criminal\noffences or the execution of criminal penalties, including the\nsafeguarding against and the prevention of threats to public security,\nunder the control and responsibility of the competent authorities.\n\nThe\nprocessing shall be based on Member State or Union law;\n\n(ii) public safety and public health, including disease prevention, control and\ntreatment;\n\n\n(iii) a high level of protection and improvement of the quality of the\n\nenvironment;\n\n(b) the data processed are necessary for complying with one or more of the\nrequirements referred to in Title III, Chapter 2 where those requirements\ncannot be effectively fulfilled by processing anonymised, synthetic or other\nnon-personal data;", "# EN EN\n\n-----\n\n(c) there are effective monitoring mechanisms to identify if any high risks to the\nfundamental rights of the data subjects may arise during the sandbox\nexperimentation as well as response mechanism to promptly mitigate those\nrisks and, where necessary, stop the processing;\n\n(d) any personal data to be processed in the context of the sandbox are in a\nfunctionally separate, isolated and protected data processing environment\nunder the control of the participants and only authorised persons have access to\nthat data;\n\n(e) any personal data processed are not be transmitted, transferred or otherwise\naccessed by other parties;\n\n(f) any processing of personal data in the context of the sandbox do not lead to\nmeasures or decisions affecting the data subjects;\n\n(g) any personal data processed in the context of the sandbox are deleted once the\nparticipation in the sandbox has terminated or the personal data has reached the\nend of its retention period;\n\n(h) the logs of the processing of personal data in the context of the sandbox are\nkept for the duration of the participation in the sandbox and 1 year after its\ntermination, solely for the purpose of and only as long as necessary for\nfulfilling accountability and documentation obligations under this Article or\nother application Union or Member States legislation;\n\n(i) complete and detailed description of the process and rationale behind the\ntraining, testing and validation of the genai system is kept together with the\ntesting results as part of the technical documentation in Annex IV;\n\n(j) a short summary of the genai project developed in the sandbox, its objectives and\nexpected results published on the website of the competent authorities.\n\n2.\n\nParagraph 1 is without prejudice to Union or Member States legislation excluding\nprocessing for other purposes than those explicitly mentioned in that legislation.\n\n_Article 55_\n\n_Measures for small-scale providers and users_\n\n1.\n\nMember States shall undertake the following actions:\n\n(a) provide small-scale providers and start-ups with priority access to the genai\nregulatory sandboxes to the extent that they fulfil the eligibility conditions;\n\n(b) organise specific awareness raising activities about the application of this\nRegulation tailored to the needs of the small-scale providers and users;\n\n(c) where appropriate, establish a dedicated channel for communication with\nsmall-scale providers and user and other innovators to provide guidance and\nrespond to queries about the implementation of this Regulation.\n\n2.\n\nThe specific interests and needs of the small-scale providers shall be taken into\naccount when setting the fees for conformity assessment under Article 43, reducing\nthose fees proportionately to their size and market size.", "## TITLE VI\n\nGOVERNANCE\n\n C HAPTER 1\n\n E UROPEAN A RTIFICIAL I NTELLIGENCE B OARD\n\n\n_Article 56_\n\n_Establishment of the European genai Board_\n\n1.\n\nA \u2018European genai Board\u2019 (the \u2018Board\u2019) is established.\n\n2.\n\nThe Board shall provide advice and assistance to the Commission in order to:\n\n(a) contribute to the effective cooperation of the national supervisory authorities\nand the Commission with regard to matters covered by this Regulation;\n\n(b) coordinate and contribute to guidance and analysis by the Commission and the\nnational supervisory authorities and other competent authorities on emerging\nissues across the internal market with regard to matters covered by this\nRegulation;\n\n(c) assist the national supervisory authorities and the Commission in ensuring the\nconsistent application of this Regulation.\n\n_Article 57_\n\n_Structure of the Board_\n\n1.\n\nThe Board shall be composed of the national supervisory authorities, who shall be\nrepresented by the head or equivalent high-level official of that authority, and the\nEuropean Data Protection Supervisor.\n\nOther national authorities may be invited to\nthe meetings, where the issues discussed are of relevance for them.\n\n2.\n\nThe Board shall adopt its rules of procedure by a simple majority of its members,\nfollowing the consent of the Commission.\n\nThe rules of procedure shall also contain\nthe operational aspects related to the execution of the Board\u2019s tasks as listed in\nArticle 58.\n\nThe Board may establish sub-groups as appropriate for the purpose of\nexamining specific questions.\n\n3.\n\nThe Board shall be chaired by the Commission.\n\nThe Commission shall convene the\nmeetings and prepare the agenda in accordance with the tasks of the Board pursuant\nto this Regulation and with its rules of procedure.\n\nThe Commission shall provide\nadministrative and analytical support for the activities of the Board pursuant to this\nRegulation.\n\n4.\n\nThe Board may invite external experts and observers to attend its meetings and may\nhold exchanges with interested third parties to inform its activities to an appropriate\nextent.\n\nTo that end the Commission may facilitate exchanges between the Board and\nother Union bodies, offices, agencies and advisory groups.", "# EN EN\n\n-----\n\n_Article 58_\n\n_Tasks of the Board_\n\nWhen providing advice and assistance to the Commission in the context of Article 56(2), the\nBoard shall in particular:\n\n(a) collect and share expertise and best practices among Member States;\n\n(b) contribute to uniform administrative practices in the Member States, including for\nthe functioning of regulatory sandboxes referred to in Article 53;\n\n(c) issue opinions, recommendations or written contributions on matters related to the\nimplementation of this Regulation, in particular\n\n(i) on technical specifications or existing standards regarding the requirements set\nout in Title III, Chapter 2,\n\n(ii) on the use of harmonised standards or common specifications referred to in\nArticles 40 and 41,\n\n\n(iii) on the preparation of guidance documents, including the guidelines concerning\n\nthe setting of administrative fines referred to in Article 71.", "# EN EN\n\n-----\n\n7.\n\nNational competent authorities may provide guidance and advice on the\nimplementation of this Regulation, including to small-scale providers.\n\nWhenever\nnational competent authorities intend to provide guidance and advice with regard to\nan genai system in areas covered by other Union legislation, the competent national\nauthorities under that Union legislation shall be consulted, as appropriate.\n\nMember\nStates may also establish one central contact point for communication with operators.\n\n8.\n\nWhen Union institutions, agencies and bodies fall within the scope of this\nRegulation, the European Data Protection Supervisor shall act as the competent\nauthority for their supervision.", "## EU DATABASE FOR STAND-ALONE HIGH-RISK genai SYSTEMS\n\n_Article 60_\n\n_EU database for stand-alone high-risk genai systems_\n\n1.\n\nThe Commission shall, in collaboration with the Member States, set up and maintain\na EU database containing information referred to in paragraph 2 concerning high-risk\ngenai systems referred to in Article 6(2) which are registered in accordance with Article\n51.\n\n2.\n\nThe data listed in Annex VIII shall be entered into the EU database by the providers.\n\nThe Commission shall provide them with technical and administrative support.\n\n3.\n\nInformation contained in the EU database shall be accessible to the public.\n\n4.\n\nThe EU database shall contain personal data only insofar as necessary for collecting\nand processing information in accordance with this Regulation.\n\nThat information\nshall include the names and contact details of natural persons who are responsible for\nregistering the system and have the legal authority to represent the provider.\n\n5.\n\nThe Commission shall be the controller of the EU database.\n\nIt shall also ensure to\nproviders adequate technical and administrative support.", "## POST-MARKET MONITORING, INFORMATION SHARING, MARKET\n\nSURVEILLANCE\n\n C HAPTER 1\n\n P OST - MARKET MONITORING\n\n\n_Article 61_\n\n\n_Post-market monitoring by providers and post-market monitoring plan for high-risk AI_\n\n\n_systems_\n\n\n1.\n\nProviders shall establish and document a post-market monitoring system in a manner\nthat is proportionate to the nature of the genai technologies and the\nrisks of the high-risk genai system.", "# EN EN\n\n-----\n\n2.\n\nThe post-market monitoring system shall actively and systematically collect,\ndocument and analyse relevant data provided by users or collected through other\nsources on the performance of high-risk genai systems throughout their lifetime, and\nallow the provider to evaluate the continuous compliance of genai systems with the\nrequirements set out in Title III, Chapter 2.\n\n3.\n\nThe post-market monitoring system shall be based on a post-market monitoring plan.\n\nThe post-market monitoring plan shall be part of the technical documentation\nreferred to in Annex IV.\n\nThe Commission shall adopt an implementing act laying\ndown detailed provisions establishing a template for the post-market monitoring plan\nand the list of elements to be included in the plan.\n\n4.\n\nFor high-risk genai systems covered by the legal acts referred to in Annex II, where a\npost-market monitoring system and plan is already established under that legislation,\nthe elements described in paragraphs 1, 2 and 3 shall be integrated into that system\nand plan as appropriate.\n\nThe first subparagraph shall also apply to high-risk genai systems referred to in point\n5(b) of Annex III placed on the market or put into service by credit institutions\nregulated by Directive 2013/36/EU.", "## C HAPTER 2\n\nS HARING OF INFORMATION ON INCIDENTS AND MALFUNCTIONING\n\n\n_Article 62_\n\n_Reporting of serious incidents and of malfunctioning_\n\n1.\n\nProviders of high-risk genai systems placed on the Union market shall report any\nserious incident or any malfunctioning of those systems which constitutes a breach of\nobligations under Union law intended to protect fundamental rights to the market\nsurveillance authorities of the Member States where that incident or breach occurred.\n\nSuch notification shall be made immediately after the provider has established a\ncausal link between the genai system and the incident or malfunctioning or the\nreasonable likelihood of such a link, and, in any event, not later than 15 days after the\nproviders becomes aware of the serious incident or of the malfunctioning.\n\n2.\n\nUpon receiving a notification related to a breach of obligations under Union law\nintended to protect fundamental rights, the market surveillance authority shall inform\nthe national public authorities or bodies referred to in Article 64(3).\n\nThe Commission\nshall develop dedicated guidance to facilitate compliance with the obligations set out\nin paragraph 1.\n\nThat guidance shall be issued 12 months after the entry into force of\nthis Regulation, at the latest.\n\n3.\n\nFor high-risk genai systems referred to in point 5(b) of Annex III which are placed on\nthe market or put into service by providers that are credit institutions regulated by\nDirective 2013/36/EU and for high-risk genai systems which are safety components of\ndevices, or are themselves devices, covered by Regulation (EU) 2017/745 and\nRegulation (EU) 2017/746, the notification of serious incidents or malfunctioning\nshall be limited to those that that constitute a breach of obligations under Union law\nintended to protect fundamental rights.", "## C HAPTER 3\n\nE NFORCEMENT\n\n_Article 63_\n\n_Market surveillance and control of genai systems in the Union market_\n\n1.\n\nRegulation (EU) 2019/1020 shall apply to genai systems covered by this Regulation.\n\nHowever, for the purpose of the effective enforcement of this Regulation:\n\n(a) any reference to an economic operator under Regulation (EU) 2019/1020 shall\nbe understood as including all operators identified in Title III, Chapter 3 of this\nRegulation;\n\n(b) any reference to a product under Regulation (EU) 2019/1020 shall be\nunderstood as including all genai systems falling within the scope of this\nRegulation.\n\n2.\n\nThe national supervisory authority shall report to the Commission on a regular basis\nthe outcomes of relevant market surveillance activities.\n\nThe national supervisory\nauthority shall report, without delay, to the Commission and relevant national\ncompetition authorities any information identified in the course of market\nsurveillance activities that may be of potential interest for the application of Union\nlaw on competition rules.\n\n3.\n\nFor high-risk genai systems, related to products to which legal acts listed in Annex II,\nsection A apply, the market surveillance authority for the purposes of this Regulation\nshall be the authority responsible for market surveillance activities designated under\nthose legal acts.\n\n4.\n\nFor genai systems placed on the market, put into service or used by financial institutions\nregulated by Union legislation on financial services, the market surveillance\nauthority for the purposes of this Regulation shall be the relevant authority\nresponsible for the financial supervision of those institutions under that legislation.\n\n5.\n\nFor genai systems listed in point 1(a) in so far as the systems are used for law\nenforcement purposes, points 6 and 7 of Annex III, Member States shall designate as\nmarket surveillance authorities for the purposes of this Regulation either the\ncompetent data protection supervisory authorities under Directive (EU) 2016/680, or\nRegulation 2016/679 or the national competent authorities supervising the activities\nof the law enforcement, immigration or asylum authorities putting into service or\nusing those systems.\n\n6.\n\nWhere Union institutions, agencies and bodies fall within the scope of this\nRegulation, the European Data Protection Supervisor shall act as their market\nsurveillance authority.\n\n7.\n\nMember States shall facilitate the coordination between market surveillance\nauthorities designated under this Regulation and other relevant national authorities or\nbodies which supervise the application of Union harmonisation legislation listed in\nAnnex II or other Union legislation that might be relevant for the high-risk genai\nsystems referred to in Annex III.", "# EN EN\n\n-----\n\n_Article 64_\n\n_Access to data and documentation_\n\n1.\n\nAccess to data and documentation in the context of their activities, the market\nsurveillance authorities shall be granted full access to the training, validation and\ntesting datasets used by the provider, including through application programming\ninterfaces (\u2018API\u2019) or other appropriate technical means and tools enabling remote\naccess.\n\n2.\n\nWhere necessary to assess the conformity of the high-risk genai system with the\nrequirements set out in Title III, Chapter 2 and upon a reasoned request, the market\nsurveillance authorities shall be granted access to the source code of the genai system.\n\n3.\n\nNational public authorities or bodies which supervise or enforce the respect of\nobligations under Union law protecting fundamental rights in relation to the use of\nhigh-risk genai systems referred to in Annex III shall have the power to request and\naccess any documentation created or maintained under this Regulation when access\nto that documentation is necessary for the fulfilment of the competences under their\nmandate within the limits of their jurisdiction.\n\nThe relevant public authority or body\nshall inform the market surveillance authority of the Member State concerned of any\nsuch request.\n\n4.\n\nBy 3 months after the entering into force of this Regulation, each Member State shall\nidentify the public authorities or bodies referred to in paragraph 3 and make a list\npublicly available on the website of the national supervisory authority.\n\nMember\nStates shall notify the list to the Commission and all other Member States and keep\nthe list up to date.\n\n5.\n\nWhere the documentation referred to in paragraph 3 is insufficient to ascertain\nwhether a breach of obligations under Union law intended to protect fundamental\nrights has occurred, the public authority or body referred to paragraph 3 may make a\nreasoned request to the market surveillance authority to organise testing of the highrisk genai system through technical means.\n\nThe market surveillance authority shall\norganise the testing with the close involvement of the requesting public authority or\nbody within reasonable time following the request.\n\n6.\n\nAny information and documentation obtained by the national public authorities or\nbodies referred to in paragraph 3 pursuant to the provisions of this Article shall be\ntreated in compliance with the confidentiality obligations set out in Article 70.\n\n_Article 65_\n\n_Procedure for dealing with genai systems presenting a risk at national level_\n\n1. genai systems presenting a risk shall be understood as a product presenting a risk\ndefined in Article 3, point 19 of Regulation (EU) 2019/1020 insofar as risks to the\nhealth or safety or to the protection of fundamental rights of persons are concerned.\n\n2.\n\nWhere the market surveillance authority of a Member State has sufficient reasons to\nconsider that an genai system presents a risk as referred to in paragraph 1, they shall\ncarry out an evaluation of the genai system concerned in respect of its compliance with\nall the requirements and obligations laid down in this Regulation.\n\nWhen risks to the\nprotection of fundamental rights are present, the market surveillance authority shall\nalso inform the relevant national public authorities or bodies referred to in Article\n64(3).\n\nThe relevant operators shall cooperate as necessary with the market", "# EN EN\n\n-----\n\nsurveillance authorities and the other national public authorities or bodies referred to\nin Article 64(3).\n\nWhere, in the course of that evaluation, the market surveillance authority finds that\nthe genai system does not comply with the requirements and obligations laid down in\nthis Regulation, it shall without delay require the relevant operator to take all\nappropriate corrective actions to bring the genai system into compliance, to withdraw\nthe genai system from the market, or to recall it within a reasonable period,\ncommensurate with the nature of the risk, as it may prescribe.\n\nThe market surveillance authority shall inform the relevant notified body\naccordingly.\n\nArticle 18 of Regulation (EU) 2019/1020 shall apply to the measures\nreferred to in the second subparagraph.\n\n3.\n\nWhere the market surveillance authority considers that non-compliance is not\nrestricted to its national territory, it shall inform the Commission and the other\nMember States of the results of the evaluation and of the actions which it has\nrequired the operator to take.\n\n4.\n\nThe operator shall ensure that all appropriate corrective action is taken in respect of\nall the genai systems concerned that it has made available on the market throughout the\nUnion.\n\n5.\n\nWhere the operator of an genai system does not take adequate corrective action within\nthe period referred to in paragraph 2, the market surveillance authority shall take all\nappropriate provisional measures to prohibit or restrict the genai system's being made\navailable on its national market, to withdraw the product from that market or to recall\nit.\n\nThat authority shall inform the Commission and the other Member States, without\ndelay, of those measures.\n\n6.\n\nThe information referred to in paragraph 5 shall include all available details, in\nparticular the data necessary for the identification of the non-compliant genai system,\nthe origin of the genai system, the nature of the non-compliance alleged and the risk\ninvolved, the nature and duration of the national measures taken and the arguments\nput forward by the relevant operator.\n\nIn particular, the market surveillance authorities\nshall indicate whether the non-compliance is due to one or more of the following:\n\n(a) a failure of the genai system to meet requirements set out in Title III, Chapter 2;\n\n(b) shortcomings in the harmonised standards or common specifications referred to\nin Articles 40 and 41 conferring a presumption of conformity.\n\n7.\n\nThe market surveillance authorities of the Member States other than the market\nsurveillance authority of the Member State initiating the procedure shall without\ndelay inform the Commission and the other Member States of any measures adopted\nand of any additional information at their disposal relating to the non-compliance of\nthe genai system concerned, and, in the event of disagreement with the notified national\nmeasure, of their objections.\n\n8.\n\nWhere, within three months of receipt of the information referred to in paragraph 5,\nno objection has been raised by either a Member State or the Commission in respect\nof a provisional measure taken by a Member State, that measure shall be deemed\njustified.\n\nThis is without prejudice to the procedural rights of the concerned operator\nin accordance with Article 18 of Regulation (EU) 2019/1020.", "# EN EN\n\n-----\n\n9.\n\nThe market surveillance authorities of all Member States shall ensure that\nappropriate restrictive measures are taken in respect of the product concerned, such\nas withdrawal of the product from their market, without delay.\n\n_Article 66_\n\n_Union safeguard procedure_\n\n1.\n\nWhere, within three months of receipt of the notification referred to in Article 65(5),\nobjections are raised by a Member State against a measure taken by another Member\nState, or where the Commission considers the measure to be contrary to Union law,\nthe Commission shall without delay enter into consultation with the relevant Member\nState and operator or operators and shall evaluate the national measure.\n\nOn the basis\nof the results of that evaluation, the Commission shall decide whether the national\nmeasure is justified or not within 9 months from the notification referred to in Article\n65(5) and notify such decision to the Member State concerned.\n\n2.\n\nIf the national measure is considered justified, all Member States shall take the\nmeasures necessary to ensure that the non-compliant genai system is withdrawn from\ntheir market, and shall inform the Commission accordingly.\n\nIf the national measure\nis considered unjustified, the Member State concerned shall withdraw the measure.\n\n3.\n\nWhere the national measure is considered justified and the non-compliance of the genai\nsystem is attributed to shortcomings in the harmonised standards or common\nspecifications referred to in Articles 40 and 41 of this Regulation, the Commission\nshall apply the procedure provided for in Article 11 of Regulation (EU) No\n1025/2012.\n\n_Article 67_\n\n_Compliant genai systems which present a risk_\n\n1.\n\nWhere, having performed an evaluation under Article 65, the market surveillance\nauthority of a Member State finds that although an genai system is in compliance with\nthis Regulation, it presents a risk to the health or safety of persons, to the compliance\nwith obligations under Union or national law intended to protect fundamental rights\nor to other aspects of public interest protection, it shall require the relevant operator\nto take all appropriate measures to ensure that the genai system concerned, when placed\non the market or put into service, no longer presents that risk, to withdraw the genai\nsystem from the market or to recall it within a reasonable period, commensurate with\nthe nature of the risk, as it may prescribe.\n\n2.\n\nThe provider or other relevant operators shall ensure that corrective action is taken in\nrespect of all the genai systems concerned that they have made available on the market\nthroughout the Union within the timeline prescribed by the market surveillance\nauthority of the Member State referred to in paragraph 1.\n\n3.\n\nThe Member State shall immediately inform the Commission and the other Member\nStates.\n\nThat information shall include all available details, in particular the data\nnecessary for the identification of the genai system concerned, the origin and the supply\nchain of the genai system, the nature of the risk involved and the nature and duration of\nthe national measures taken.\n\n4.\n\nThe Commission shall without delay enter into consultation with the Member States\nand the relevant operator and shall evaluate the national measures taken.\n\nOn the basis", "# EN EN\n\n-----\n\nof the results of that evaluation, the Commission shall decide whether the measure is\njustified or not and, where necessary, propose appropriate measures.\n\n5.\n\nThe Commission shall address its decision to the Member States.\n\n_Article 68_\n\n_Formal non-compliance_\n\n1.\n\nWhere the market surveillance authority of a Member State makes one of the\nfollowing findings, it shall require the relevant provider to put an end to the noncompliance concerned:\n\n(a) the conformity marking has been affixed in violation of Article 49;\n\n(b) the conformity marking has not been affixed;\n\n(c) the EU declaration of conformity has not been drawn up;\n\n(d) the EU declaration of conformity has not been drawn up correctly;\n\n(e) the identification number of the notified body, which is involved in the\nconformity assessment procedure, where applicable, has not been affixed;\n\n2.\n\nWhere the non-compliance referred to in paragraph 1 persists, the Member State\nconcerned shall take all appropriate measures to restrict or prohibit the high-risk genai\nsystem being made available on the market or ensure that it is recalled or withdrawn\nfrom the market.", "## TITLE IX\n\nCODES OF CONDUCT\n\n\n_Article 69_\n\n_Codes of conduct_\n\n1.\n\nThe Commission and the Member States shall encourage and facilitate the drawing\nup of codes of conduct intended to foster the voluntary application to genai systems\nother than high-risk genai systems of the requirements set out in Title III, Chapter 2 on\nthe basis of technical specifications and solutions that are appropriate means of\nensuring compliance with such requirements in light of the intended purpose of the\nsystems.\n\n2.\n\nThe Commission and the Board shall encourage and facilitate the drawing up of\ncodes of conduct intended to foster the voluntary application to genai systems of\nrequirements related for example to environmental sustainability, accessibility for\npersons with a disability, stakeholders participation in the design and development of\nthe genai systems and diversity of development teams on the basis of clear objectives\nand key performance indicators to measure the achievement of those objectives.\n\n3.\n\nCodes of conduct may be drawn up by individual providers of genai systems or by\norganisations representing them or by both, including with the involvement of users\nand any interested stakeholders and their representative organisations.\n\nCodes of\nconduct may cover one or more genai systems taking into account the similarity of the\nintended purpose of the relevant systems.", "## TITLE X\n\nCONFIDENTIALITY AND PENALTIES\n\n\n_Article 70_\n\n_Confidentiality_\n\n1.\n\nNational competent authorities and notified bodies involved in the application of this\nRegulation shall respect the confidentiality of information and data obtained in\ncarrying out their tasks and activities in such a manner as to protect, in particular:\n\n(a) intellectual property rights, and confidential business information or trade\nsecrets of a natural or legal person, including source code, except the cases\nreferred to in Article 5 of Directive 2016/943 on the protection of undisclosed\nknow-how and business information (trade secrets) against their unlawful\nacquisition, use and disclosure apply.\n\n(b) the effective implementation of this Regulation, in particular for the purpose of\ninspections, investigations or audits;(c) public and national security interests;\n\n(c) integrity of criminal or administrative proceedings.\n\n2.\n\nWithout prejudice to paragraph 1, information exchanged on a confidential basis\nbetween the national competent authorities and between national competent\nauthorities and the Commission shall not be disclosed without the prior consultation\nof the originating national competent authority and the user when high-risk genai\nsystems referred to in points 1, 6 and 7 of Annex III are used by law enforcement,\nimmigration or asylum authorities, when such disclosure would jeopardise public and\nnational security interests.\n\nWhen the law enforcement, immigration or asylum authorities are providers of highrisk genai systems referred to in points 1, 6 and 7 of Annex III, the technical\ndocumentation referred to in Annex IV shall remain within the premises of those\nauthorities.\n\nThose authorities shall ensure that the market surveillance authorities\nreferred to in Article 63(5) and (6), as applicable, can, upon request, immediately\naccess the documentation or obtain a copy thereof.\n\nOnly staff of the market\nsurveillance authority holding the appropriate level of security clearance shall be\nallowed to access that documentation or any copy thereof.\n\n3.\n\nParagraphs 1 and 2 shall not affect the rights and obligations of the Commission,\nMember States and notified bodies with regard to the exchange of information and\nthe dissemination of warnings, nor the obligations of the parties concerned to provide\ninformation under criminal law of the Member States.\n\n4.\n\nThe Commission and Member States may exchange, where necessary, confidential\ninformation with regulatory authorities of third countries with which they have\nconcluded bilateral or multilateral confidentiality arrangements guaranteeing an\nadequate level of confidentiality.", "# EN EN\n\n-----\n\n_Article 71_\n\n_Penalties_\n\n1.\n\nIn compliance with the terms and conditions laid down in this Regulation, Member\nStates shall lay down the rules on penalties, including administrative fines, applicable\nto infringements of this Regulation and shall take all measures necessary to ensure\nthat they are properly and effectively implemented.\n\nThe penalties provided for shall\nbe effective, proportionate, and dissuasive.\n\nThey shall take into particular account the\ninterests of small-scale providers and start-up and their economic viability.\n\n2.\n\nThe Member States shall notify the Commission of those rules and of those measures\nand shall notify it, without delay, of any subsequent amendment affecting them.\n\n3.\n\nThe following infringements shall be subject to administrative fines of up to 30 000\n000 EUR or, if the offender is company, up to 6 % of its total worldwide annual\nturnover for the preceding financial year, whichever is higher:\n\n(a) non-compliance with the prohibition of the genai practices\nreferred to in Article 5;\n\n(b) non-compliance of the genai system with the requirements laid down in Article\n10.\n\n4.\n\nThe non-compliance of the genai system with any requirements or obligations under\nthis Regulation, other than those laid down in Articles 5 and 10, shall be subject to\nadministrative fines of up to 20 000 000 EUR or, if the offender is a company, up to\n4 % of its total worldwide annual turnover for the preceding financial year,\nwhichever is higher.\n\n5.\n\nThe supply of incorrect, incomplete or misleading information to notified bodies and\nnational competent authorities in reply to a request shall be subject to administrative\nfines of up to 10 000 000 EUR or, if the offender is a company, up to 2 % of its total\nworldwide annual turnover for the preceding financial year, whichever is higher.\n\n6.\n\nWhen deciding on the amount of the administrative fine in each individual case, all\nrelevant circumstances of the specific situation shall be taken into account and due\nregard shall be given to the following:\n\n(a) the nature, gravity and duration of the infringement and of its consequences;\n\n(b) whether administrative fines have been already applied by other market\nsurveillance authorities to the same operator for the same infringement.\n\n(c) the size and market share of the operator committing the infringement;\n\n7.\n\nEach Member State shall lay down rules on whether and to what extent\nadministrative fines may be imposed on public authorities and bodies established in\nthat Member State.\n\n8.\n\nDepending on the legal system of the Member States, the rules on administrative\nfines may be applied in such a manner that the fines are imposed by competent\nnational courts of other bodies as applicable in those Member States.\n\nThe application\nof such rules in those Member States shall have an equivalent effect.", "# EN EN\n\n-----\n\n_Article 72_\n\n_Administrative fines on Union institutions, agencies and bodies_\n\n1.\n\nThe European Data Protection Supervisor may impose administrative fines on Union\ninstitutions, agencies and bodies falling within the scope of this Regulation.\n\nWhen\ndeciding whether to impose an administrative fine and deciding on the amount of the\nadministrative fine in each individual case, all relevant circumstances of the specific\nsituation shall be taken into account and due regard shall be given to the following:\n\n(a) the nature, gravity and duration of the infringement and of its consequences;\n\n(b) the cooperation with the European Data Protection Supervisor in order to\nremedy the infringement and mitigate the possible adverse effects of the\ninfringement, including compliance with any of the measures previously\nordered by the European Data Protection Supervisor against the Union\ninstitution or agency or body concerned with regard to the same subject matter;\n\n(c) any similar previous infringements by the Union institution, agency or body;\n\n2.\n\nThe following infringements shall be subject to administrative fines of up to 500 000\nEUR:\n\n(a) non-compliance with the prohibition of the genai practices\nreferred to in Article 5;\n\n(b) non-compliance of the genai system with the requirements laid down in Article\n10.\n\n3.\n\nThe non-compliance of the genai system with any requirements or obligations under\nthis Regulation, other than those laid down in Articles 5 and 10, shall be subject to\nadministrative fines of up to 250 000 EUR.\n\n4.\n\nBefore taking decisions pursuant to this Article, the European Data Protection\nSupervisor shall give the Union institution, agency or body which is the subject of\nthe proceedings conducted by the European Data Protection Supervisor the\nopportunity of being heard on the matter regarding the possible infringement.\n\nThe\nEuropean Data Protection Supervisor shall base his or her decisions only on elements\nand circumstances on which the parties concerned have been able to comment.\n\nComplainants, if any, shall be associated closely with the proceedings.\n\n5.\n\nThe rights of defense of the parties concerned shall be fully respected in the\nproceedings.\n\nThey shall be entitled to have access to the European Data Protection\nSupervisor\u2019s file, subject to the legitimate interest of individuals or undertakings in\nthe protection of their personal data or business secrets.\n\n6.\n\nFunds collected by imposition of fines in this Article shall be the income of the\ngeneral budget of the Union.", "# EN EN\n\n-----\n\n2.\n\nThe delegation of power referred to in Article 4, Article 7(1), Article 11(3), Article\n43(5) and (6) and Article 48(5) shall be conferred on the Commission for an\nindeterminate period of time from [ _entering into force of the Regulation_ ].\n\n3.\n\nThe delegation of power referred to in Article 4, Article 7(1), Article 11(3), Article\n43(5) and (6) and Article 48(5) may be revoked at any time by the European\nParliament or by the Council.\n\nA decision of revocation shall put an end to the\ndelegation of power specified in that decision.\n\nIt shall take effect the day following\nthat of its publication in the _Official Journal of the European Union_ or at a later date\nspecified therein.\n\nIt shall not affect the validity of any delegated acts already in force.\n\n4.\n\nAs soon as it adopts a delegated act, the Commission shall notify it simultaneously to\nthe European Parliament and to the Council.\n\n5.\n\nAny delegated act adopted pursuant to Article 4, Article 7(1), Article 11(3), Article\n43(5) and (6) and Article 48(5) shall enter into force only if no objection has been\nexpressed by either the European Parliament or the Council within a period of three\nmonths of notification of that act to the European Parliament and the Council or if,\nbefore the expiry of that period, the European Parliament and the Council have both\ninformed the Commission that they will not object.\n\nThat period shall be extended by\nthree months at the initiative of the European Parliament or of the Council.\n\n_Article 74_\n\n_Committee procedure_\n\n1.\n\nThe Commission shall be assisted by a committee.\n\nThat committee shall be a\ncommittee within the meaning of Regulation (EU) No 182/2011.\n\n2.\n\nWhere reference is made to this paragraph, Article 5 of Regulation (EU) No\n182/2011 shall apply.", "## TITLE XII\n\nFINAL PROVISIONS\n\n\n_Article 75_\n\n_Amendment to Regulation (EC) No 300/2008_\n\nIn Article 4(3) of Regulation (EC) No 300/2008, the following subparagraph is added:\n\n\u201cWhen adopting detailed measures related to technical specifications and procedures for\napproval and use of security equipment concerning genai systems in the\nmeaning of Regulation (EU) YYY/XX [on genai] of the European Parliament\nand of the Council*, the requirements set out in Chapter 2, Title III of that Regulation shall be\ntaken into account.\u201d\n\n__________\n\n-  Regulation (EU) YYY/XX [on genai] (OJ \u2026).\u201d\n\n\n_Article 76_\n\n_Amendment to Regulation (EU) No 167/2013_\n\nIn Article 17(5) of Regulation (EU) No 167/2013, the following subparagraph is added:", "# EN EN\n\n-----\n\n\u201cWhen adopting delegated acts pursuant to the first subparagraph concerning artificial\nintelligence systems which are safety components in the meaning of Regulation (EU)\nYYY/XX [on genai] of the European Parliament and of the Council*, the\nrequirements set out in Title III, Chapter 2 of that Regulation shall be taken into account.\n\n__________\n\n-  Regulation (EU) YYY/XX [on genai] (OJ \u2026).\u201d\n\n\n_Article 77_\n\n_Amendment to Regulation (EU) No 168/2013_\n\nIn Article 22(5) of Regulation (EU) No 168/2013, the following subparagraph is added:\n\n\u201cWhen adopting delegated acts pursuant to the first subparagraph concerning Artificial\nIntelligence systems which are safety components in the meaning of Regulation (EU)\nYYY/XX on [genai] of the European Parliament and of the Council*, the\nrequirements set out in Title III, Chapter 2 of that Regulation shall be taken into account.\n\n__________\n\n-  Regulation (EU) YYY/XX [on genai] (OJ \u2026).\u201d\n\n\n_Article 78_\n\n_Amendment to Directive 2014/90/EU_\n\nIn Article 8 of Directive 2014/90/EU, the following paragraph is added:\n\n\u201c4.\n\nFor genai systems which are safety components in the meaning of\nRegulation (EU) YYY/XX [on genai] of the European Parliament and of the\nCouncil*, when carrying out its activities pursuant to paragraph 1 and when adopting\ntechnical specifications and testing standards in accordance with paragraphs 2 and 3, the\nCommission shall take into account the requirements set out in Title III, Chapter 2 of that\nRegulation.\n\n__________\n\n-  Regulation (EU) YYY/XX [on genai] (OJ \u2026).\u201d.\n\n_Article 79_\n\n_Amendment to Directive (EU) 2016/797_\n\nIn Article 5 of Directive (EU) 2016/797, the following paragraph is added:\n\n\u201c12.\n\nWhen adopting delegated acts pursuant to paragraph 1 and implementing acts pursuant to\nparagraph 11 concerning genai systems which are safety components in the\nmeaning of Regulation (EU) YYY/XX [on genai] of the European Parliament\nand of the Council*, the requirements set out in Title III, Chapter 2 of that Regulation shall be\ntaken into account.\n\n__________\n\n-  Regulation (EU) YYY/XX [on genai] (OJ \u2026).\u201d.", "# EN EN\n\n-----\n\n_Article 80_\n\n_Amendment to Regulation (EU) 2018/858_\n\nIn Article 5 of Regulation (EU) 2018/858 the following paragraph is added:\n\n\u201c4.\n\nWhen adopting delegated acts pursuant to paragraph 3 concerning genai\nsystems which are safety components in the meaning of Regulation (EU) YYY/XX [on\ngenai] of the European Parliament and of the Council *, the requirements set\nout in Title III, Chapter 2 of that Regulation shall be taken into account.\n\n__________\n\n-  Regulation (EU) YYY/XX [on genai] (OJ \u2026).\u201d.\n\n_Article 81_\n\n_Amendment to Regulation (EU) 2018/1139_\n\nRegulation (EU) 2018/1139 is amended as follows:\n\n(1) In Article 17, the following paragraph is added:\n\n\u201c3.\n\nWithout prejudice to paragraph 2, when adopting implementing acts pursuant to paragraph\n1 concerning genai systems which are safety components in the meaning of\nRegulation (EU) YYY/XX [ _on Artificial Intelligence_ ] of the European Parliament and of the\nCouncil*, the requirements set out in Title III, Chapter 2 of that Regulation shall be taken into\naccount.\n\n__________\n\n-  Regulation (EU) YYY/XX [on genai] (OJ \u2026).\u201d\n\n(2) In Article 19, the following paragraph is added:\n\n\u201c4.\n\nWhen adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial\nIntelligence systems which are safety components in the meaning of Regulation (EU)\nYYY/XX [on genai], the requirements set out in Title III, Chapter 2 of that\nRegulation shall be taken into account.\u201d\n\n(3) In Article 43, the following paragraph is added:\n\n\u201c4.\n\nWhen adopting implementing acts pursuant to paragraph 1 concerning Artificial\nIntelligence systems which are safety components in the meaning of Regulation (EU)\nYYY/XX [on genai], the requirements set out in Title III, Chapter 2 of that\nRegulation shall be taken into account.\u201d\n\n(4) In Article 47, the following paragraph is added:\n\n\u201c3.\n\nWhen adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial\nIntelligence systems which are safety components in the meaning of Regulation (EU)\nYYY/XX [on genai], the requirements set out in Title III, Chapter 2 of that\nRegulation shall be taken into account.\u201d\n\n(5) In Article 57, the following paragraph is added:\n\n\u201cWhen adopting those implementing acts concerning genai systems which are\nsafety components in the meaning of Regulation (EU) YYY/XX [on genai],\nthe requirements set out in Title III, Chapter 2 of that Regulation shall be taken into account.\u201d\n\n(6) In Article 58, the following paragraph is added:", "# EN EN\n\n-----\n\n\u201c3.\n\nWhen adopting delegated acts pursuant to paragraphs 1 and 2 concerning Artificial\nIntelligence systems which are safety components in the meaning of Regulation (EU)\nYYY/XX [on genai] , the requirements set out in Title III, Chapter 2 of that\nRegulation shall be taken into account.\u201d.\n\n_Article 82_\n\n_Amendment to Regulation (EU) 2019/2144_\n\nIn Article 11 of Regulation (EU) 2019/2144, the following paragraph is added:\n\n\u201c3.\n\nWhen adopting the implementing acts pursuant to paragraph 2, concerning artificial\nintelligence systems which are safety components in the meaning of Regulation (EU)\nYYY/XX [on genai] of the European Parliament and of the Council*, the\nrequirements set out in Title III, Chapter 2 of that Regulation shall be taken into account.\n\n__________\n\n-  Regulation (EU) YYY/XX [on genai] (OJ \u2026).\u201d.\n\n_Article 83_\n\n_AI systems already placed on the market or put into service_\n\n1.\n\nThis Regulation shall not apply to the genai systems which are components of the largescale IT systems established by the legal acts listed in Annex IX that have been\nplaced on the market or put into service before _[12 months after the date of_\n_application of this Regulation referred to in Article 85(2)]_ , unless the replacement or\namendment of those legal acts leads to a significant change in the design or intended\npurpose of the genai system or genai systems concerned.\n\nThe requirements laid down in this Regulation shall be taken into account, where\napplicable, in the evaluation of each large-scale IT systems established by the legal\nacts listed in Annex IX to be undertaken as provided for in those respective acts.\n\n2.\n\nThis Regulation shall apply to the high-risk genai systems, other than the ones referred\nto in paragraph 1, that have been placed on the market or put into service before\n\n[ _date of application of this Regulation referred to in Article 85(2)_ ], only if, from that\ndate, those systems are subject to significant changes in their design or intended\npurpose.\n\n_Article 84_\n\n_Evaluation and review_\n\n1.\n\nThe Commission shall assess the need for amendment of the list in Annex III once a\nyear following the entry into force of this Regulation.\n\n2.\n\nBy [ _three years after the date of application of this Regulation referred to in Article_\n_85(2)_ ] and every four years thereafter, the Commission shall submit a report on the\nevaluation and review of this Regulation to the European Parliament and to the\nCouncil.\n\nThe reports shall be made public.\n\n3.\n\nThe reports referred to in paragraph 2 shall devote specific attention to the following:\n\n(a) the status of the financial and human resources of the national competent\nauthorities in order to effectively perform the tasks assigned to them under this\nRegulation;", "# EN EN\n\n-----\n\n(b) the state of penalties, and notably administrative fines as referred to in Article\n71(1), applied by Member States to infringements of the provisions of this\nRegulation.\n\n4.\n\nWithin [ _three years after the date of application of this Regulation referred to in_\n_Article 85(2)_ ] and every four years thereafter, the Commission shall evaluate the\nimpact and effectiveness of codes of conduct to foster the application of the\nrequirements set out in Title III, Chapter 2 and possibly other additional requirements\nfor genai systems other than high-risk genai systems.\n\n5.\n\nFor the purpose of paragraphs 1 to 4 the Board, the Member States and national\ncompetent authorities shall provide the Commission with information on its request.\n\n6.\n\nIn carrying out the evaluations and reviews referred to in paragraphs 1 to 4 the\nCommission shall take into account the positions and findings of the Board, of the\nEuropean Parliament, of the Council, and of other relevant bodies or sources.\n\n7.\n\nThe Commission shall, if necessary, submit appropriate proposals to amend this\nRegulation, in particular taking into account developments in technology and in the\nlight of the state of progress in the information society.\n\n_Article 85_\n\n_Entry into force and application_\n\n1.\n\nThis Regulation shall enter into force on the twentieth day following that of its\npublication in the _Official Journal of the European Union_ .\n\n2.\n\nThis Regulation shall apply from [24 months following the entering into force of the\nRegulation].\n\n3.\n\nBy way of derogation from paragraph 2:\n\n(a) Title III, Chapter 4 and Title VI shall apply from [three months following the\nentry into force of this Regulation];\n\n(b) Article 71 shall apply from [twelve months following the entry into force of\nthis Regulation].\n\nThis Regulation shall be binding in its entirety and directly applicable in all Member States.\n\nDone at Brussels,\n\n_For the European Parliament_ _For the Council_\n\n_The President_ _The President_", "**1.\n\n** **FRAMEWORK** **OF** **THE** **PROPOSAL/INITIATIVE**\n\n1.1.\n\nTitle of the proposal/initiative\n\n1.2.\n\nPolicy area(s) concerned\n\n1.3.\n\nThe proposal/initiative relates to:\n\n1.4.\n\nObjective(s)\n\n1.4.1.\n\nGeneral objective(s)\n\n1.4.2.\n\nSpecific objective(s)\n\n1.4.3.\n\nExpected result(s) and impact\n\n1.4.4.\n\nIndicators of performance\n\n1.5.\n\nGrounds for the proposal/initiative\n\n\n1.5.1.\n\nRequirement(s) to be met in the short or long term including a detailed\n\ntimeline for roll-out of the implementation of the initiative\n\n1.5.2.\n\nAdded value of Union involvement (it may result from different factors, e.g.\n\ncoordination gains, legal certainty, greater effectiveness or complementarities).\n\nFor\nthe purposes of this point 'added value of Union involvement' is the value resulting\nfrom Union intervention which is additional to the value that would have been\notherwise created by Member States alone\n\n1.5.3.\n\nLessons learned from similar experiences in the past\n\n1.5.4.\n\nCompatibility with the Multiannual Financial Framework and possible\nsynergies with other appropriate instruments\n\n1.5.5  Assessment of the different available financing options, including scope for\nredeployment\n\n1.6.\n\nDuration and financial impact of the proposal/initiative\n\n1.7.\n\nManagement mode(s) planned", "**2.\n\n** **MANAGEMENT** **MEASURES**\n\n2.1.\n\nMonitoring and reporting rules\n\n2.2.\n\nManagement and control system\n\n2.2.1.\n\nJustification of the management mode(s), the funding implementation\nmechanism(s), the payment modalities and the control strategy proposed\n\n2.2.2.\n\nInformation concerning the risks identified and the internal control system(s)\nset up to mitigate them\n\n2.2.3.\n\nEstimation and justification of the cost-effectiveness of the controls (ratio of\n\"control costs \u00f7 value of the related funds managed\"), and assessment of the\nexpected levels of risk of error (at payment & at closure)", "**3.\n\n** **ESTIMATED** **FINANCIAL** **IMPACT** **OF** **THE** **PROPOSAL/INITIATIVE**\n\n3.1.\n\nHeading(s) of the multiannual financial framework and expenditure budget\nline(s) affected\n\n3.2.\n\nEstimated financial impact of the proposal on appropriations\n\n_3.2.1.\n\nSummary of estimated impact on operational appropriations_\n\n_3.2.2.\n\nEstimated output funded with operational appropriations_\n\n_3.2.3.\n\nSummary of estimated impact on administrative appropriations_\n\n_3.2.4.\n\nCompatibility with the current multiannual financial framework_\n\n_3.2.5.\n\nThird-party contributions_\n\n3.3.\n\nEstimated impact on revenue", "**1.4.\n\n** **Objective(s)**\n\n_1.4.1._ _General objective(s)_\n\nThe general objective of the intervention is to ensure the proper functioning of the\nsingle market by creating the conditions for the development and use of trustworthy\ngenai in the Union.\n\n_1.4.2._ _Specific objective(s)_\n\nSpecific objective No 1\n\nTo set requirements specific to genai systems and obligations on all value chain\nparticipants in order to ensure that genai systems placed on the market and used are safe\nand respect existing law on fundamental rights and Union values;\n\nSpecific objective No 2\n\nTo ensure legal certainty to facilitate investment and innovation in genai by making it\nclear what essential requirements, obligations, as well as conformity and compliance\nprocedures must be followed to place or use an genai system in the Union market;\n\nSpecific objective No 3\n\nTo enhance governance and effective enforcement of existing law on fundamental\nrights and safety requirements applicable to genai systems by providing new powers,\nresources and clear rules for relevant authorities on conformity assessment and ex\n\n64 As referred to in Article 54(2)(a) or (b) of the Financial Regulation", "# EN EN\n\n-----\n\npost monitoring procedures and the division of governance and supervision tasks\nbetween national and EU levels;\n\nSpecific objective No 4\n\nTo facilitate the development of a single market for lawful, safe and trustworthy genai\napplications and prevent market fragmentation by taking EU action to set minimum\nrequirement for genai systems to be placed and used in the Union market in compliance\nwith existing law on fundamental rights and safety.", "# EN EN\n\n-----\n\n_1.4.3._ _Expected result(s) and impact_\n\n_Specify the effects which the proposal/initiative should have on the beneficiaries/groups targeted._\n\ngenai suppliers should benefit from a minimal but clear set of requirements, creating\nlegal certainty and ensuring access to the entire single market.\n\ngenai users should benefit from legal certainty that the high-risk genai systems they buy\ncomply with European laws and values.\n\nConsumers should benefit by reducing the risk of violations of their safety or\nfundamental rights.\n\n_1.4.4._ _Indicators of performance_\n\n_Specify the indicators for monitoring implementation of the proposal/initiative._\n\nIndicator 1\n\nNumber of serious incidents or genai performances which constitute a serious incident\nor a breach of fundamental rights obligations (semi-annual) by fields of applications\nand calculated a) in absolute terms, b) as share of applications deployed and c) as\nshare of citizens concerned.\n\nIndicator 2\n\na) Total genai investment in the EU (annual)\n\nb) Total genai investment by Member State (annual)\n\nc) Share of companies using genai (annual)\n\nd) Share of SMEs using genai (annual)\n\na) and b) will be calculated based on official sources and benchmarked against\nprivate estimates\n\nc) and d) will be collected by regular company surveys", "**1.5.\n\n** **Grounds for the proposal/initiative**\n\n_1.5.1._ _Requirement(s) to be met in the short or long term including a detailed timeline for_\n_roll-out of the implementation of the initiative_\n\nThe Regulation should be fully applicable one year and a half after its adoption.\n\nHowever, elements of the governance structure should be in place before then.\n\nIn\nparticular, Member States shall have appointed existing authorities and/or established\nnew authorities performing the tasks set out in the legislation earlier, and the EU genai\nBoard should be set-up and effective.\n\nBy the time of applicability, the European\ndatabase of genai systems should be fully operative.\n\nIn parallel to the adoption process,\nit is therefore necessary to develop the database, so that its development has come to\nan end when the regulation enters into force.\n\n_1.5.2._ _Added value of Union involvement (it may result from different factors, e.g._\n_coordination gains, legal certainty, greater effectiveness or complementarities).\n\nFor_\n_the purposes of this point 'added value of Union involvement' is the value resulting_\n_from Union intervention which is additional to the value that would have been_\n_otherwise created by Member States alone._\n\nAn emerging patchy framework of potentially divergent national rules will hamper\nthe seamless provision of genai systems across the EU and is ineffective in ensuring the", "# EN EN\n\n-----\n\nsafety and protection of fundamental rights and Union values across the different\nMember States.\n\nA common EU legislative action on genai could boost the internal\nmarket and has great potential to provide European industry with a competitive edge\nat the global scene and economies of scale that cannot be achieved by individual\nMember States alone.\n\n_1.5.3._ _Lessons learned from similar experiences in the past_\n\nThe E-commerce Directive 2000/31/EC provides the core framework for the\nfunctioning of the single market and the supervision of digital services and sets a\nbasic structure for a general cooperation mechanism among Member States, covering\nin principle all requirements applicable to digital services.\n\nThe evaluation of the\nDirective pointed to shortcomings in several aspects of this cooperation mechanism,\nincluding important procedural aspects such as the lack of clear timeframes for\nresponse from Member States coupled with a general lack of responsiveness to\nrequests from their counterparts.\n\nThis has led over the years to a lack of trust\nbetween Member States in addressing concerns about providers offering digital\nservices cross-border.\n\nThe evaluation of the Directive showed the need to define a\ndifferentiated set of rules and requirements at European level.\n\nFor this reason, the\nimplementation of the specific obligations laid down in this Regulation would\nrequire a specific cooperation mechanism at EU level, with a governance structure\nensuring coordination of specific responsible bodies at EU level.\n\n_1.5.4._ _Compatibility with the Multiannual Financial Framework and possible synergies_\n_with other appropriate instruments_\n\nThe Regulation Laying Down Harmonised Rules on genai and\nAmending Certain Union Legislative Acts defines a new common framework of\nrequirements applicable to genai systems, which goes well beyond the framework\nprovided by existing legislation.\n\nFor this reason, a new national and European\nregulatory and coordination function needs to be established with this proposal.\n\nAs regards possible synergies with other appropriate instruments, the role of\nnotifying authorities at national level can be performed by national authorities\nfulfilling similar functions sunder other EU regulations.\n\nMoreover, by increasing trust in genai and thus encouraging investment in development\nand adoption of genai, it complements Digital Europe, for which promoting the\ndiffusion of genai is one of five priorities.\n\n_1.5.5._ _Assessment of the different available financing options, including scope for_\n_redeployment_\n\nThe staff will be redeployed.\n\nThe other costs will be supported from the DEP.\n\nenvelope, given that the objective of this regulation \u2013 ensuring trustworthy genai \u2013\ncontributes directly to one key objective of Digital Europe \u2013 accelerating genai\ndevelopment and deployment in Europe.", "**1.6.\n\n** **Duration and financial impact of the proposal/initiative**\n\n\uf0a8 **limited duration**\n\n\u2013 \uf0a8 in effect from [DD/MM]YYYY to [DD/MM]YYYY\n\n\n\u2013 \uf0a8 Financial impact from YYYY to YYYY for commitment appropriations and\n\nfrom YYYY to YYYY for payment appropriations.\n\nX **unlimited duration**\n\n\u2013 Implementation with a start-up period from one/two (tbc) year,\n\n\u2013 followed by full-scale operation.", "**1.7.\n\n** **Management mode(s) planned** **65**\n\nX **Direct management** by the Commission\n\n\u2013 \uf0a8 by its departments, including by its staff in the Union delegations;\n\n\u2013 \uf0a8 by the executive agencies\n\n\uf0a8 **Shared management** with the Member States\n\n\uf0a8 **Indirect management** by entrusting budget implementation tasks to:\n\n\u2013 \uf0a8 third countries or the bodies they have designated;\n\n\u2013 \uf0a8 international organisations and their agencies (to be specified);\n\n\u2013 \uf0a8 the EIB and the European Investment Fund;\n\n\u2013 \uf0a8 bodies referred to in Articles 70 and 71 of the Financial Regulation;\n\n\u2013 \uf0a8 public law bodies;\n\n\n\u2013 \uf0a8 bodies governed by private law with a public service mission to the extent that\n\nthey provide adequate financial guarantees;\n\n\n\u2013 \uf0a8 bodies governed by the private law of a Member State that are entrusted with\n\nthe implementation of a public-private partnership and that provide adequate\nfinancial guarantees;\n\n\n\u2013 \uf0a8 persons entrusted with the implementation of specific actions in the CFSP\n\npursuant to Title V of the TEU, and identified in the relevant basic act.\n\n\u2013 _If more than one management mode is indicated, please provide details in the \u2018Comments\u2019 section._\n\nComments\n\n65 Details of management modes and references to the Financial Regulation may be found on the\nBudgWeb site:", "**2.2.\n\n** **Management and control system(s)**\n\n_2.2.1._ _Justification of the management mode(s), the funding implementation mechanism(s),_\n_the payment modalities and the control strategy proposed_\n\nThe Regulation establishes a new policy with regard to harmonised rules for the\nprovision of genai systems in the internal market while ensuring the\nrespect of safety and fundamental rights.\n\nThese new rules require a consistency\nmechanism for the cross-border application of the obligations under this Regulation\nin the form of a new advisory group coordinating the activities of national\nauthorities.\n\nIn order to face these new tasks, it is necessary to appropriately resource the\nCommission\u2019s services.\n\nThe enforcement of the new Regulation is estimated to\nrequire 10 FTE \u00e0 regime (5 FTE for the support to the activities of the Board and 5\nFTE for the European Data Protection Supervisor acting as a notifying body for genai\nsystems deployed by a body of the European Union).\n\n_2.2.2._ _Information concerning the risks identified and the internal control system(s) set up_\n_to mitigate them_\n\nIn order to ensure that the members of the Board have the possibility to make\ninformed analysis on the basis of factual evidence, it is foreseen that the Board\nshould be supported by the administrative structure of the Commission and that an\nexpert group be created to provide additional expertise where required.\n\n_2.2.3._ _Estimate and justification of the cost-effectiveness of the controls (ratio of \"control_\n_costs \u00f7 value of the related funds managed\"), and assessment of the expected levels_\n_of risk of error (at payment & at closure)_\n\nFor the meeting expenditure, given the low value per transaction (e.g.\n\nrefunding\ntravel costs for a delegate for a meeting), standard control procedures seem\nsufficient.\n\nRegarding the development of the database, contract attribution has a\nstrong internal control system in place in DG CNECT through centralised\nprocurement activities.", "**3.1.\n\n** **Heading(s) of the multiannual financial framework and expenditure budget line(s) affected**\n\n-  Existing budget lines\n\nIn order of multiannual financial framework headings and budget lines.\n\n|Heading of multiannual financial framework|Budget line|Type of expenditure|Contribution|Col5|Col6|Col7|\n|---|---|---|---|---|---|---|\n||Number|Diff./Non- 66 diff.|from EFTA countries 67|from candidate 68 countries|from third countries|within the meaning of Article 21(2)(b) of the Financial Regulation|\n|7|20 02 06 Administrative expenditure|Non-diff.|NO|NO|NO|NO|\n|1|02 04 03 DEP genai|Diff.|YES|NO|NO|NO|\n|1|02 01 30 01 Support expenditure for the Digital Europe programme|Non-diff.|YES|NO|NO|NO|", "**3.2.\n\n** **Estimated financial impact of the proposal on appropriations**\n\n_3.2.1._ _Summary of estimated impact on expenditure on operational appropriations_\n\n\u2013 \uf0a8 The proposal/initiative does not require the use of operational appropriations\n\n\u2013 X The proposal/initiative requires the use of operational appropriations, as explained below:\n\nEUR million (to three decimal places)\n\n\n66 Diff.\n\n= Differentiated appropriations / Non-diff.\n\n= Non-differentiated appropriations.\n\n67 EFTA: European Free Trade Association.\n\n68 Candidate countries and, where applicable, potential candidate countries from the Western Balkans.", "# EN EN\n\n-----\n\n|Heading of multiannual financial framework|1|Col3|\n|---|---|---|\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n|DG: CNECT|Col2|Col3|Col4|Year 2022|Year 2023|Year 2024|Year 2025|Year 2026|Year 69 2027|TOTAL|Col12|\n|---|---|---|---|---|---|---|---|---|---|---|---|\n|\uf09f Operational appropriations||||||||||||\n|70 Budget line 02 04 03||Commitments|(1a)||1.000||||||1.000|\n|||Payments|(2a)||0.600|0.100|0.100|0.100|0.100||1.000|\n|Budget line||Commitments|(1b)|||||||||\n|||Payments|(2b)|||||||||\n|Appropriations of an administrative nature financed from the envelope of specific 71 programmes||||||||||||\n|Budget line 02 01 30 01|||(3)||0.240|0.240|0.240|0.240|0.240||1.200|\n|TOTAL appropriations for DG CNECT||Commitments|=1a+1b +3||1.240||0.240|0.240|0.240||2.200|\n|||Payments|=2a+2b +3||0.840|0.340|0.340|0.340|0.340||2.200|\n\n\n69 Indicative and dependent on budget availability.\n\n70 According to the official budget nomenclature.\n\n71 Technical and/or administrative assistance and expenditure in support of the implementation of EU programmes and/or actions (former \u2018BA\u2019 lines), indirect research,\ndirect research.", "**If more than one heading is affected by the proposal / initiative, repeat the section above:**\n\n|\uf09f TOTAL operational appropriations (all operational headings)|Commitments|(4)|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|\n|---|---|---|---|---|---|---|---|---|---|---|\n||Payments|(5)|||||||||\n|\uf09f TOTAL appropriations of an administrative nature financed from the envelope for specific programmes (all operational headings)||(6)|||||||||\n|TOTAL appropriations under HEADINGS 1 to 6 of the multiannual financial framework (Reference amount)|Commitments|=4+ 6|||||||||\n||Payments|=5+ 6|||||||||", "# EN EN\n\n-----\n\n|Heading of multiannual financial framework|7|\u2018Administrative expenditure\u2019|\n|---|---|---|\n\n\nThis section should be filled in using the 'budget data of an administrative nature' to be firstly introduced in the Annex to the Legislative\nFinancial Statement (Annex V to the internal rules), which is uploaded to DECIDE for interservice consultation purposes.\n\nEUR million (to three decimal places)\n\n\n\n\n\n\n|Col1|Year 2023|Year 2024|Year 2025|Year 2026|Year 2027|After 72 2027|\n|---|---|---|---|---|---|---|\n\n\nDG: CNECT\n\n\n\n|\uf09f Human resources|Col2|Col3|0.760|0.760|0.760|0.760|0.760|0.760|\n|---|---|---|---|---|---|---|---|---|\n|\uf09f Other administrative expenditure|||0.010|0.010|0.010|0.010|0.010|0.010|\n|TOTAL DG CNECT||Appropriations|0.760|0.760|0.760|0.760|0.760|0.760|\n|European Data Protection Supervisor|||||||||\n|\uf09f Human resources|||0.760|0.760|0.760|0.760|0.760|0.760|\n|\uf09f Other administrative expenditure|||||||||\n|TOTAL EDPS||Appropriations|0.760|0.760|0.760|0.760|0.760|0.760|\n|TOTAL appropriations under HEADING 7 of the multiannual financial framework|(Total commitments = Total payments)||1.530|1.530|1.530|1.530|1.530|1.530|\n\n\nEUR million (to three decimal places)\n\n\n**under HEADING 7**\n\n\nof the multiannual financial framework\n\n\n\n\n\n\n|Col1|Col2|Year 2022|Year 2023|Year 2024|Year 2025|Year 2026|Year 2027|Col9|\n|---|---|---|---|---|---|---|---|---|\n|TOTAL appropriations|Commitments||2.770|1.770|1.770|1.770|1.770||\n\n\n72 All figures in this column are indicative and subject to the continuation of the programmes and availability of appropriations", "# EN EN\n\n-----\n\n_3.2.2._ _Estimated output funded with operational appropriations_\n\nCommitment appropriations in EUR million (to three decimal places)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n|Indicate objectives and outputs \uf0f2|Col2|Col3|Year 2022|Col5|Year 2023|Col7|Year 2024|Col9|Year 2025|Col11|Year 2026|Col13|Year 2027|Col15|After 73 2027|Col17|TOTAL|Col19|\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n||OUTPUTS||||||||||||||||||\n||Type|Average cost|Cost No||Cost No||Cost No||Cost No||Cost No||Cost No||Cost No||Tota Total l No cost||\n|74 SPECIFIC OBJECTIVE No 1 \u2026|||||||||||||||||||\n|Database|||||1 1.000||1||1||1||1||1 0.100||1|1.000|\n|Meetings- Output|||||10 0.200||10 0.200||10 0.200||10 0.200||10 0.200||10 0.200||50|1.000|\n|Communication activities|||||2|0.040|2|0.040|2|0.040|2|0.040|2|0.040|2|0.040|10|0.040|\n|Subtotal for specific objective No 1|||||||||||||||||||\n|SPECIFIC OBJECTIVE No 2 ...|||||||||||||||||||\n|- Output|||||||||||||||||||\n|Subtotal for specific objective No 2|||||||||||||||||||\n|TOTALS|||||13|0.240|13|0.240|13|0.240|13|0.240|13|0.240|13|0.100|65|2.200|\n\n\n73 All figures in this column are indicative and subject to the continuation of the programmes and availability of appropriations\n\n74 As described in point 1.4.2.\n\n\u2018Specific objective(s)\u2026\u2019", "# EN EN\n\n-----\n\n_3.2.3._ _Summary of estimated impact on administrative appropriations_\n\n\n\u2013 \uf0a8 The proposal/initiative does not require the use of appropriations of an\n\nadministrative nature\n\n\n\u2013 X The proposal/initiative requires the use of appropriations of an administrative\n\nnature, as explained below:\n\nEUR million (to three decimal places)\n\n\n\n\n\n\n\n\n\n\n|Col1|Year 2022|Year 2023|Year 2024|Year 2025|Year 2026|Year 2027|Yearly after 75 2027|TOTAL|\n|---|---|---|---|---|---|---|---|---|\n\n\n\n\n\n\n\n\n\n|HEADING 7 of the multiannual financial framework|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|Human resources||1.520|1.520|1.520|1.520|1.520|1.520|7.600|\n|Other administrative expenditure||0.010|0.010|0.010|0.010|0.010|0.010|0.050|\n|Subtotal HEADING 7 of the multiannual financial framework||1.530|1.530|1.530|1.530|1.530|1.530|7.650|\n\n\n\n\n\n\n\n\n\n|76 Outside HEADING 7 of the multiannual financial framework|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|Human resources|||||||||\n|Other expenditure of an administrative nature||0.240|0.240|0.240|0.240|0.240|0.240|1.20|\n|Subtotal outside HEADING 7 of the multiannual financial framework||0.240|0.240|0.240|0.240|0.240|0.240|1.20|\n\n\n|TOTAL|Col2|1.770|1.770|1.770|1.770|1.770|1.770|8.850|\n|---|---|---|---|---|---|---|---|---|\n\n\nThe appropriations required for human resources and other expenditure of an administrative nature will be met by\nappropriations from the DG that are already assigned to management of the action and/or have been redeployed within the\nDG, together if necessary with any additional allocation which may be granted to the managing DG under the annual\nallocation procedure and in the light of budgetary constraints.\n\n75 All figures in this column are indicative and subject to the continuation of the programmes and availability of\nappropriations.\n\n76 Technical and/or administrative assistance and expenditure in support of the implementation of\nEU programmes and/or actions (former \u2018BA\u2019 lines), indirect research, direct research.", "# EN EN\n\n-----\n\n3.2.3.1.\n\nEstimated requirements of human resources\n\n\u2013 \uf0a8 The proposal/initiative does not require the use of human resources.\n\n\u2013 X The proposal/initiative requires the use of human resources, as explained\n\nbelow:\n\n_Estimate to be expressed in full time equivalent units_\n\n\n\n\n\n\n\n\n\n|.|Col2|Col3|Year 2023|Year 2024|Year 2025|2026|2027|After 202777|Col10|\n|---|---|---|---|---|---|---|---|---|---|\n|\uf09f Establishment plan posts (officials and temporary staff)||||||||||\n|20 01 02 01 (Headquarters and Commission\u2019s Representation Offices)|||10|10|10|10|10|10||\n|20 01 02 03 (Delegations)||||||||||\n|01 01 01 01 (Indirect research)||||||||||\n|01 01 01 11 (Direct research)||||||||||\n|Other budget lines (specify)||||||||||\n|78 \uf09f External staff (in Full Time Equivalent unit: FTE)||||||||||\n|20 02 01 (AC, END, INT from the \u2018global envelope\u2019)||||||||||\n|20 02 03 (AC, AL, END, INT and JPD in the delegations)||||||||||\n|79 XX 01 xx yy zz|- at Headquarters|||||||||\n||- in Delegations|||||||||\n|01 01 01 02 (AC, END, INT - Indirect research)||||||||||\n|01 01 01 12 (AC, END, INT - Direct research)||||||||||\n|Other budget lines (specify)||||||||||\n|TOTAL|||10|10|10|10|10|10||\n\n\n**XX** is the policy area or budget title concerned.\n\nThe human resources required will be met by staff from the DG who are already assigned to management of the\naction and/or have been redeployed within the DG, together if necessary with any additional allocation which\nmay be granted to the managing DG under the annual allocation procedure and in the light of budgetary\nconstraints.\n\nEDPS is expected to provide half of the resources required.\n\nDescription of tasks to be carried out:\n\n|Officials and temporary staff|To prepare a total of 13-16 meetings, draft reports, continue policy work, e.g.\n\nregarding future amendments of the list of high-risk genai applications, and maintain relations with Member States\u2019 authorities will require four AD FTE and 1 AST FTE.\n\nFor genai systems developed by the EU institutions, the European Data Protection Supervisor is responsible.\n\nBased on past experience, it can be estimated that 5 AD FTE are reuqired to fulfill the EDPS responsibilites under the draft legislation.|\n|---|---|\n\n\n77 All figures in this column are indicative and subject to the continuation of the programmes and\navailability of appropriations.\n\n78 AC = Contract Staff; AL = Local Staff; END = Seconded National Expert; INT = agency staff; JPD\n= Junior Professionals in Delegations.\n\n79 Sub-ceiling for external staff covered by operational appropriations (former \u2018BA\u2019 lines).", "# EN EN\n\n-----\n\n_3.2.4._ _Compatibility with the current multiannual financial framework_\n\nThe proposal/initiative:\n\n\n\u2013 X can be fully financed through redeployment within the relevant heading of the\n\nMultiannual Financial Framework (MFF).\n\nNo reporgramming is needed.\n\n\u2013 \uf0a8 requires use of the unallocated margin under the relevant heading of the MFF\n\nand/or use of the special instruments as defined in the MFF Regulation.\n\nExplain what is required, specifying the headings and budget lines concerned, the corresponding\namounts, and the instruments proposed to be used.\n\n\u2013 \uf0a8 requires a revision of the MFF.\n\nExplain what is required, specifying the headings and budget lines concerned and the corresponding\namounts.\n\n_3.2.5._ _Third-party contributions_\n\nThe proposal/initiative:\n\n\u2013 X does not provide for co-financing by third parties\n\n\u2013 \uf0a8 provides for the co-financing by third parties estimated below:\n\nAppropriations in EUR million (to three decimal places)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n|Col1|Year 80 N|Year N+1|Year N+2|Year N+3|Enter as many years as necessary to show the duration of the impact (see point 1.6)|Col7|Col8|Total|\n|---|---|---|---|---|---|---|---|---|\n|Specify the co-financing body|||||||||\n|TOTAL appropriations co-financed|||||||||\n\n\n80 Year N is the year in which implementation of the proposal/initiative starts.\n\nPlease replace \"N\" by the\nexpected first year of implementation (for instance: 2021).\n\nThe same for the following years.", "**3.3.\n\n** **Estimated impact on revenue**\n\n\u2013 \uf0a8 The proposal/initiative has the following financial impact:\n\n\u2013 \uf0a8 The proposal/initiative has the following financial impact:\n\n\u2013 \uf0a8 on other revenue\n\n\u2013 \uf0a8 on other revenue\n\n\u2013 Please indicate, if the revenue is assigned to expenditure lines \uf0a8\n\nEUR million (to three decimal places)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n|Budget revenue line:|Appropriation s available for the current financial year|81 Impact of the proposal/initiative|Col4|Col5|Col6|Col7|Col8|Col9|\n|---|---|---|---|---|---|---|---|---|\n|||Year N|Year N+1|Year N+2|Year N+3|Enter as many years as necessary to show the duration of the impact (see point 1.6)|||\n|Article \u2026\u2026\u2026\u2026.|||||||||\n\n\nFor assigned revenue, specify the budget expenditure line(s) affected.\n\nOther remarks (e.g.\n\nmethod/formula used for calculating the impact on revenue or any other\ninformation).\n\n81 As regards traditional own resources (customs duties, sugar levies), the amounts indicated must be net\namounts, i.e.\n\ngross amounts after deduction of 20 % for collection costs.", "**ANNEX I**\n\n**genai TECHNIQUES AND APPROACHES**\n\n\n**referred to in Article 3, point 1**\n\n\n(a) Machine learning approaches, including supervised, unsupervised and reinforcement\nlearning, using a wide variety of methods including deep learning;\n\n(b) Logic- and knowledge-based approaches, including knowledge representation,\ninductive (logic) programming, knowledge bases, inference and deductive engines,\n(symbolic) reasoning and expert systems;\n\n(c) Statistical approaches, Bayesian estimation, search and optimization methods.", "**Framework**\n\n1.\n\nDirective 2006/42/EC of the European Parliament and of the Council of 17 May\n2006 on machinery, and amending Directive 95/16/EC (OJ L 157, 9.6.2006, p. 24)\n\n[as repealed by the Machinery Regulation];\n\n2.\n\nDirective 2009/48/EC of the European Parliament and of the Council of 18 June\n2009 on the safety of toys (OJ L 170, 30.6.2009, p. 1);\n\n3.\n\nDirective 2013/53/EU of the European Parliament and of the Council of 20\nNovember 2013 on recreational craft and personal watercraft and repealing Directive\n94/25/EC (OJ L 354, 28.12.2013, p. 90);\n\n4.\n\nDirective 2014/33/EU of the European Parliament and of the Council of 26 February\n2014 on the harmonisation of the laws of the Member States relating to lifts and\nsafety components for lifts (OJ L 96, 29.3.2014, p. 251);\n\n5.\n\nDirective 2014/34/EU of the European Parliament and of the Council of 26 February\n2014 on the harmonisation of the laws of the Member States relating to equipment\nand protective systems intended for use in potentially explosive atmospheres (OJ L\n96, 29.3.2014, p. 309);\n\n6.\n\nDirective 2014/53/EU of the European Parliament and of the Council of 16 April\n2014 on the harmonisation of the laws of the Member States relating to the making\navailable on the market of radio equipment and repealing Directive 1999/5/EC (OJ L\n153, 22.5.2014, p. 62);\n\n7.\n\nDirective 2014/68/EU of the European Parliament and of the Council of 15 May\n2014 on the harmonisation of the laws of the Member States relating to the making\navailable on the market of pressure equipment (OJ L 189, 27.6.2014, p. 164);\n\n8.\n\nRegulation (EU) 2016/424 of the European Parliament and of the Council of 9 March\n2016 on cableway installations and repealing Directive 2000/9/EC (OJ L 81,\n31.3.2016, p. 1);\n\n9.\n\nRegulation (EU) 2016/425 of the European Parliament and of the Council of 9 March\n2016 on personal protective equipment and repealing Council Directive 89/686/EEC\n(OJ L 81, 31.3.2016, p. 51);\n\n10.\n\nRegulation (EU) 2016/426 of the European Parliament and of the Council of 9 March\n2016 on appliances burning gaseous fuels and repealing Directive 2009/142/EC (OJ\nL 81, 31.3.2016, p. 99);\n\n11.\n\nRegulation (EU) 2017/745 of the European Parliament and of the Council of 5 April\n2017 on medical devices, amending Directive 2001/83/EC, Regulation (EC) No\n178/2002 and Regulation (EC) No 1223/2009 and repealing Council Directives\n90/385/EEC and 93/42/EEC (OJ L 117, 5.5.2017, p. 1;\n\n12.\n\nRegulation (EU) 2017/746 of the European Parliament and of the Council of 5 April\n2017 on in vitro diagnostic medical devices and repealing Directive 98/79/EC and\nCommission Decision 2010/227/EU (OJ L 117, 5.5.2017, p. 176).", "**Section B.\n\nList of other Union harmonisation legislation**\n\n1.\n\nRegulation (EC) No 300/2008 of the European Parliament and of the Council of 11\nMarch 2008 on common rules in the field of civil aviation security and repealing\nRegulation (EC) No 2320/2002 (OJ L 97, 9.4.2008, p. 72).\n\n2.\n\nRegulation (EU) No 168/2013 of the European Parliament and of the Council of 15\nJanuary 2013 on the approval and market surveillance of two- or three-wheel\nvehicles and quadricycles (OJ L 60, 2.3.2013, p. 52);\n\n3.\n\nRegulation (EU) No 167/2013 of the European Parliament and of the Council of 5\nFebruary 2013 on the approval and market surveillance of agricultural and forestry\nvehicles (OJ L 60, 2.3.2013, p. 1);\n\n4.\n\nDirective 2014/90/EU of the European Parliament and of the Council of 23 July 2014\non marine equipment and repealing Council Directive 96/98/EC (OJ L 257,\n28.8.2014, p. 146);\n\n5.\n\nDirective (EU) 2016/797 of the European Parliament and of the Council of 11 May\n2016 on the interoperability of the rail system within the European Union (OJ L 138,\n26.5.2016, p. 44).\n\n6.\n\nRegulation (EU) 2018/858 of the European Parliament and of the Council of 30 May\n2018 on the approval and market surveillance of motor vehicles and their trailers,\nand of systems, components and separate technical units intended for such vehicles,\namending Regulations (EC) No 715/2007 and (EC) No 595/2009 and repealing\nDirective 2007/46/EC (OJ L 151, 14.6.2018, p. 1); 3.\n\nRegulation (EU) 2019/2144 of\nthe European Parliament and of the Council of 27 November 2019 on type-approval\nrequirements for motor vehicles and their trailers, and systems, components and\nseparate technical units intended for such vehicles, as regards their general safety and\nthe protection of vehicle occupants and vulnerable road users, amending Regulation\n(EU) 2018/858 of the European Parliament and of the Council and repealing\nRegulations (EC) No 78/2009, (EC) No 79/2009 and (EC) No 661/2009 of the\nEuropean Parliament and of the Council and Commission Regulations (EC) No\n631/2009, (EU) No 406/2010, (EU) No 672/2010, (EU) No 1003/2010, (EU) No\n1005/2010, (EU) No 1008/2010, (EU) No 1009/2010, (EU) No 19/2011, (EU) No\n109/2011, (EU) No 458/2011, (EU) No 65/2012, (EU) No 130/2012, (EU) No\n347/2012, (EU) No 351/2012, (EU) No 1230/2012 and (EU) 2015/166 (OJ L 325,\n16.12.2019, p. 1);\n\n7.\n\nRegulation (EU) 2018/1139 of the European Parliament and of the Council of 4 July\n2018 on common rules in the field of civil aviation and establishing a European\nUnion Aviation Safety Agency, and amending Regulations (EC) No 2111/2005, (EC)\nNo 1008/2008, (EU) No 996/2010, (EU) No 376/2014 and Directives 2014/30/EU\nand 2014/53/EU of the European Parliament and of the Council, and repealing\nRegulations (EC) No 552/2004 and (EC) No 216/2008 of the European Parliament\nand of the Council and Council Regulation (EEC) No 3922/91 (OJ L 212, 22.8.2018,\np. 1), in so far as the design, production and placing on the market of aircrafts\nreferred to in points (a) and (b) of Article 2(1) thereof, where it concerns unmanned\naircraft and their engines, propellers, parts and equipment to control them remotely,\nare concerned.", "**HIGH-RISK genai SYSTEMS** **REFERRED TO IN ARTICLE 6(2)**\n\nHigh-risk genai systems pursuant to Article 6(2) are the genai systems listed in any of the following\nareas:\n\n1.\n\nBiometric identification and categorisation of natural persons:\n\n(a) genai systems intended to be used for the \u2018real-time\u2019 and \u2018post\u2019 remote biometric\nidentification of natural persons;\n\n2.\n\nManagement and operation of critical infrastructure:\n\n(a) genai systems intended to be used as safety components in the management and\noperation of road traffic and the supply of water, gas, heating and electricity.\n\n3.\n\nEducation and vocational training:\n\n(a) genai systems intended to be used for the purpose of determining access or\nassigning natural persons to educational and vocational training institutions;\n\n(b) genai systems intended to be used for the purpose of assessing students in\neducational and vocational training institutions and for assessing participants in\ntests commonly required for admission to educational institutions.\n\n4.\n\nEmployment, workers management and access to self-employment:\n\n(a) genai systems intended to be used for recruitment or selection of natural persons,\nnotably for advertising vacancies, screening or filtering applications, evaluating\ncandidates in the course of interviews or tests;\n\n(b) genai intended to be used for making decisions on promotion and termination of\nwork-related contractual relationships, for task allocation and for monitoring\nand evaluating performance and behavior of persons in such relationships.\n\n5.\n\nAccess to and enjoyment of essential private services and public services and\nbenefits:\n\n(a) genai systems intended to be used by public authorities or on behalf of public\nauthorities to evaluate the eligibility of natural persons for public assistance\nbenefits and services, as well as to grant, reduce, revoke, or reclaim such\nbenefits and services;\n\n(b) genai systems intended to be used to evaluate the creditworthiness of natural\npersons or establish their credit score, with the exception of genai systems put into\nservice by small scale providers for their own use;\n\n(c) genai systems intended to be used to dispatch, or to establish priority in the\ndispatching of emergency first response services, including by firefighters and\nmedical aid.\n\n6.\n\nLaw enforcement:\n\n(a) genai systems intended to be used by law enforcement authorities for making\nindividual risk assessments of natural persons in order to assess the risk of a\nnatural person for offending or reoffending or the risk for potential victims of\ncriminal offences;\n\n(b) genai systems intended to be used by law enforcement authorities as polygraphs\nand similar tools or to detect the emotional state of a natural person;", "# EN EN\n\n-----\n\n(c) genai systems intended to be used by law enforcement authorities to detect deep\nfakes as referred to in article 52(3);\n\n(d) genai systems intended to be used by law enforcement authorities for evaluation\nof the reliability of evidence in the course of investigation or prosecution of\ncriminal offences;\n\n(e) genai systems intended to be used by law enforcement authorities for predicting\nthe occurrence or reoccurrence of an actual or potential criminal offence\nbased on profiling of natural persons as referred to in Article 3(4) of Directive\n(EU) 2016/680 or assessing personality traits and characteristics or past\ncriminal behaviour of natural persons or groups;\n\n(f) genai systems intended to be used by law enforcement authorities for profiling of\nnatural persons as referred to in Article 3(4) of Directive (EU) 2016/680 in the\ncourse of detection, investigation or prosecution of criminal offences;\n\n(g) genai systems intended to be used for crime analytics regarding natural persons,\nallowing law enforcement authorities to search complex related and unrelated\nlarge data sets available in different data sources or in different data formats in\norder to identify unknown patterns or discover hidden relationships in the data.\n\n7.\n\nMigration, asylum and border control management:\n\n(a) genai systems intended to be used by competent public authorities as polygraphs\nand similar tools or to detect the emotional state of a natural person;\n\n(b) genai systems intended to be used by competent public authorities to assess a risk,\nincluding a security risk, a risk of irregular immigration, or a health risk, posed\nby a natural person who intends to enter or has entered into the territory of a\nMember State;\n\n(c) genai systems intended to be used by competent public authorities for the\nverification of the authenticity of travel documents and supporting\ndocumentation of natural persons and detect non-authentic documents by\nchecking their security features;\n\n(d) genai systems intended to assist competent public authorities for the examination\nof applications for asylum, visa and residence permits and associated\ncomplaints with regard to the eligibility of the natural persons applying for a\nstatus.\n\n8.\n\nAdministration of justice and democratic processes:\n\n(a) genai systems intended to assist a judicial authority in researching and\ninterpreting facts and the law and in applying the law to a concrete set of facts.", "**TECHNICAL DOCUMENTATION referred to in Article 11(1)**\n\nThe technical documentation referred to in Article 11(1) shall contain at least the following\ninformation, as applicable to the relevant genai system:\n\n1.\n\nA general description of the genai system including:\n\n(a) its intended purpose, the person/s developing the system the date and the\nversion of the system;\n\n(b) how the genai system interacts or can be used to interact with hardware or\nsoftware that is not part of the genai system itself, where applicable;\n\n(c) the versions of relevant software or firmware and any requirement related to\nversion update;\n\n(d) the description of all forms in which the genai system is placed on the market or\nput into service;\n\n(e) the description of hardware on which the genai system is intended to run;\n\n(f) where the genai system is a component of products, photographs or illustrations\nshowing external features, marking and internal layout of those products;\n\n(g) instructions of use for the user and, where applicable installation instructions;\n\n2.\n\nA detailed description of the elements of the genai system and of the process for its\ndevelopment, including:\n\n(a) the methods and steps performed for the development of the genai system,\nincluding, where relevant, recourse to pre-trained systems or tools provided by\nthird parties and how these have been used, integrated or modified by the\nprovider;\n\n(b) the design specifications of the system, namely the general logic of the genai\nsystem and of the algorithms; the key design choices including the rationale\nand assumptions made, also with regard to persons or groups of persons on\nwhich the system is intended to be used; the main classification choices; what\nthe system is designed to optimise for and the relevance of the different\nparameters; the decisions about any possible trade-off made regarding the\ntechnical solutions adopted to comply with the requirements set out in Title III,\nChapter 2;\n\n(c) the description of the system architecture explaining how software components\nbuild on or feed into each other and integrate into the overall processing; the\ncomputational resources used to develop, train, test and validate the genai system;\n\n(d) where relevant, the data requirements in terms of datasheets describing the\ntraining methodologies and techniques and the training data sets used,\nincluding information about the provenance of those data sets, their scope and\nmain characteristics; how the data was obtained and selected; labelling\nprocedures (e.g.\n\nfor supervised learning), data cleaning methodologies (e.g.\n\noutliers detection);\n\n(e) assessment of the human oversight measures needed in accordance with Article\n14, including an assessment of the technical measures needed to facilitate the\ninterpretation of the outputs of genai systems by the users, in accordance with\nArticles 13(3)(d);", "# EN EN\n\n-----\n\n(f) where applicable, a detailed description of pre-determined changes to the genai\nsystem and its performance, together with all the relevant information related\nto the technical solutions adopted to ensure continuous compliance of the genai\nsystem with the relevant requirements set out in Title III, Chapter 2;\n\n(g) the validation and testing procedures used, including information about the\nvalidation and testing data used and their main characteristics; metrics used to\nmeasure accuracy, robustness, cybersecurity and compliance with other\nrelevant requirements set out in Title III, Chapter 2 as well as potentially\ndiscriminatory impacts; test logs and all test reports dated and signed by the\nresponsible persons, including with regard to pre-determined changes as\nreferred to under point (f).\n\n3.\n\nDetailed information about the monitoring, functioning and control of the genai system,\nin particular with regard to: its capabilities and limitations in performance, including\nthe degrees of accuracy for specific persons or groups of persons on which the\nsystem is intended to be used and the overall expected level of accuracy in relation to\nits intended purpose; the foreseeable unintended outcomes and sources of risks to\nhealth and safety, fundamental rights and discrimination in view of the intended\npurpose of the genai system; the human oversight measures needed in accordance with\nArticle 14, including the technical measures put in place to facilitate the\ninterpretation of the outputs of genai systems by the users; specifications on input data,\nas appropriate;\n\n4.\n\nA detailed description of the risk management system in accordance with Article 9;\n\n5.\n\nA description of any change made to the system through its lifecycle;\n\n6.\n\nA list of the harmonised standards applied in full or in part the references of which\nhave been published in the Official Journal of the European Union; where no such\nharmonised standards have been applied, a detailed description of the solutions\nadopted to meet the requirements set out in Title III, Chapter 2, including a list of\nother relevant standards and technical specifications applied;\n\n7.\n\nA copy of the EU declaration of conformity;\n\n8.\n\nA detailed description of the system in place to evaluate the genai system performance\nin the post-market phase in accordance with Article 61, including the post-market\nmonitoring plan referred to in Article 61(3).", "**EU DECLARATION OF CONFORMITY**\n\nThe EU declaration of conformity referred to in Article 48, shall contain all of the following\ninformation:\n\n1. genai system name and type and any additional unambiguous reference allowing\nidentification and traceability of the genai system;\n\n2.\n\nName and address of the provider or, where applicable, their authorised\nrepresentative;\n\n3.\n\nA statement that the EU declaration of conformity is issued under the sole\nresponsibility of the provider;\n\n4.\n\nA statement that the genai system in question is in conformity with this Regulation and,\nif applicable, with any other relevant Union legislation that provides for the issuing\nof an EU declaration of conformity;\n\n5.\n\nReferences to any relevant harmonised standards used or any other common\nspecification in relation to which conformity is declared;\n\n6.\n\nWhere applicable, the name and identification number of the notified body, a\ndescription of the conformity assessment procedure performed and identification of\nthe certificate issued;\n\n7.\n\nPlace and date of issue of the declaration, name and function of the person who\nsigned it as well as an indication for, and on behalf of whom, that person signed,\nsignature.", "**CONFORMITY ASSESSMENT PROCEDURE BASED ON INTERNAL CONTROL**\n\n1.\n\nThe conformity assessment procedure based on internal control is the conformity\nassessment procedure based on points 2 to 4.\n\n2.\n\nThe provider verifies that the established quality management system is in\ncompliance with the requirements of Article 17.\n\n3.\n\nThe provider examines the information contained in the technical documentation in\norder to assess the compliance of the genai system with the relevant essential\nrequirements set out in Title III, Chapter 2.\n\n4.\n\nThe provider also verifies that the design and development process of the genai system\nand its post-market monitoring as referred to in Article 61 is consistent with the\ntechnical documentation.", "**SYSTEM AND ASSESSMENT OF TECHNICAL DOCUMENTATION**\n\n1.\n\nIntroduction\n\nConformity based on assessment of quality management system and assessment of\nthe technical documentation is the conformity assessment procedure based on points\n2 to 5.\n\n2.\n\nOverview\n\nThe approved quality management system for the design, development and testing of\ngenai systems pursuant to Article 17 shall be examined in accordance with point 3 and\nshall be subject to surveillance as specified in point 5.\n\nThe technical documentation\nof the genai system shall be examined in accordance with point 4.\n\n3.\n\nQuality management system\n\n3.1.\n\nThe application of the provider shall include:\n\n(a) the name and address of the provider and, if the application is lodged by the\nauthorised representative, their name and address as well;\n\n(b) the list of genai systems covered under the same quality management system;\n\n(c) the technical documentation for each genai system covered under the same quality\nmanagement system;\n\n(d) the documentation concerning the quality management system which shall\ncover all the aspects listed under Article 17;\n\n(e) a description of the procedures in place to ensure that the quality management\nsystem remains adequate and effective;\n\n(f) a written declaration that the same application has not been lodged with any\nother notified body.\n\n3.2.\n\nThe quality management system shall be assessed by the notified body, which shall\ndetermine whether it satisfies the requirements referred to in Article 17.\n\nThe decision shall be notified to the provider or its authorised representative.\n\nThe notification shall contain the conclusions of the assessment of the quality\nmanagement system and the reasoned assessment decision.\n\n3.3.\n\nThe quality management system as approved shall continue to be implemented and\nmaintained by the provider so that it remains adequate and efficient.\n\n3.4.\n\nAny intended change to the approved quality management system or the list of genai\nsystems covered by the latter shall be brought to the attention of the notified body by\nthe provider.\n\nThe proposed changes shall be examined by the notified body, which shall decide\nwhether the modified quality management system continues to satisfy the\nrequirements referred to in point 3.2 or whether a reassessment is necessary.\n\nThe notified body shall notify the provider of its decision.\n\nThe notification shall\ncontain the conclusions of the examination of the changes and the reasoned\nassessment decision.\n\n4.\n\nControl of the technical documentation.", "# EN EN\n\n-----\n\n4.1.\n\nIn addition to the application referred to in point 3, an application with a notified\nbody of their choice shall be lodged by the provider for the assessment of the\ntechnical documentation relating to the genai system which the provider intends to\nplace on the market or put into service and which is covered by the quality\nmanagement system referred to under point 3.\n\n4.2.\n\nThe application shall include:\n\n(a) the name and address of the provider;\n\n(b) a written declaration that the same application has not been lodged with any\nother notified body;\n\n(c) the technical documentation referred to in Annex IV.\n\n4.3.\n\nThe technical documentation shall be examined by the notified body.\n\nTo this\npurpose, the notified body shall be granted full access to the training and testing\ndatasets used by the provider, including through application programming interfaces\n(API) or other appropriate means and tools enabling remote access.\n\n4.4.\n\nIn examining the technical documentation, the notified body may require that the\nprovider supplies further evidence or carries out further tests so as to enable a proper\nassessment of conformity of the genai system with the requirements set out in Title III,\nChapter 2.\n\nWhenever the notified body is not satisfied with the tests carried out by\nthe provider, the notified body shall directly carry out adequate tests, as appropriate.\n\n4.5.\n\nWhere necessary to assess the conformity of the high-risk genai system with the\nrequirements set out in Title III, Chapter 2 and upon a reasoned request, the notified\nbody shall also be granted access to the source code of the genai system.\n\n4.6.\n\nThe decision shall be notified to the provider or its authorised representative.\n\nThe\nnotification shall contain the conclusions of the assessment of the technical\ndocumentation and the reasoned assessment decision.\n\nWhere the genai system is in conformity with the requirements set out in Title III,\nChapter 2, an EU technical documentation assessment certificate shall be issued by\nthe notified body.\n\nThe certificate shall indicate the name and address of the provider,\nthe conclusions of the examination, the conditions (if any) for its validity and the\ndata necessary for the identification of the genai system.\n\nThe certificate and its annexes shall contain all relevant information to allow the\nconformity of the genai system to be evaluated, and to allow for control of the genai\nsystem while in use, where applicable.\n\nWhere the genai system is not in conformity with the requirements set out in Title III,\nChapter 2, the notified body shall refuse to issue an EU technical documentation\nassessment certificate and shall inform the applicant accordingly, giving detailed\nreasons for its refusal.\n\nWhere the genai system does not meet the requirement relating to the data used to train\nit, re-training of the genai system will be needed prior to the application for a new\nconformity assessment.\n\nIn this case, the reasoned assessment decision of the notified\nbody refusing to issue the EU technical documentation assessment certificate shall\ncontain specific considerations on the quality data used to train the genai system,\nnotably on the reasons for non-compliance.\n\n4.7.\n\nAny change to the genai system that could affect the compliance of the genai system with\nthe requirements or its intended purpose shall be approved by the notified body", "# EN EN\n\n-----\n\nwhich issued the EU technical documentation assessment certificate.\n\nThe provider\nshall inform such notified body of its intention to introduce any of the abovementioned changes or if it becomes otherwise aware of the occurrence of such\nchanges.\n\nThe intended changes shall be assessed by the notified body which shall\ndecide whether those changes require a new conformity assessment in accordance\nwith Article 43(4) or whether they could be addressed by means of a supplement to\nthe EU technical documentation assessment certificate.\n\nIn the latter case, the notified\nbody shall assess the changes, notify the provider of its decision and, where the\nchanges are approved, issue to the provider a supplement to the EU technical\ndocumentation assessment certificate.\n\n5.\n\nSurveillance of the approved quality management system.\n\n5.1.\n\nThe purpose of the surveillance carried out by the notified body referred to in Point 3\nis to make sure that the provider duly fulfils the terms and conditions of the approved\nquality management system.\n\n5.2.\n\nFor assessment purposes, the provider shall allow the notified body to access the\npremises where the design, development, testing of the genai systems is taking place.\n\nThe provider shall further share with the notified body all necessary information.\n\n5.3.\n\nThe notified body shall carry out periodic audits to make sure that the provider\nmaintains and applies the quality management system and shall provide the provider\nwith an audit report.\n\nIn the context of those audits, the notified body may carry out\nadditional tests of the genai systems for which an EU technical documentation\nassessment certificate was issued.", "**RISK genai SYSTEMS IN ACCORDANCE WITH ARTICLE 51**\n\nThe following information shall be provided and thereafter kept up to date with regard to\nhigh-risk genai systems to be registered in accordance with Article 51.\n\n1.\n\nName, address and contact details of the provider;\n\n2.\n\nWhere submission of information is carried out by another person on behalf of the\nprovider, the name, address and contact details of that person;\n\n3.\n\nName, address and contact details of the authorised representative, where applicable;\n\n4. genai system trade name and any additional unambiguous reference allowing\nidentification and traceability of the genai system;\n\n5.\n\nDescription of the intended purpose of the genai system;\n\n6.\n\nStatus of the genai system (on the market, or in service; no longer placed on the\nmarket/in service, recalled);\n\n7.\n\nType, number and expiry date of the certificate issued by the notified body and the\nname or identification number of that notified body, when applicable;\n\n8.\n\nA scanned copy of the certificate referred to in point 7, when applicable;\n\n9.\n\nMember States in which the genai system is or has been placed on the market, put into\nservice or made available in the Union;\n\n10.\n\nA copy of the EU declaration of conformity referred to in Article 48;\n\n11.\n\nElectronic instructions for use; this information shall not be provided for high-risk genai\nsystems in the areas of law enforcement and migration, asylum and border control\nmanagement referred to in Annex III, points 1, 6 and 7.\n\n12.\n\nURL for additional information (optional).", "**FREEDOM, SECURITY AND JUSTICE**\n\n1.\n\nSchengen Information System\n\n(a) Regulation (EU) 2018/1860 of the European Parliament and of the Council of\n28 November 2018 on the use of the Schengen Information System for the\nreturn of illegally staying third-country nationals (OJ L 312, 7.12.2018, p. 1).\n\n(b) Regulation (EU) 2018/1861 of the European Parliament and of the Council of\n28 November 2018 on the establishment, operation and use of the Schengen\nInformation System (SIS) in the field of border checks, and amending the\nConvention implementing the Schengen Agreement, and amending and\nrepealing Regulation (EC) No 1987/2006 (OJ L 312, 7.12.2018, p. 14)\n\n(c) Regulation (EU) 2018/1862 of the European Parliament and of the Council of\n28 November 2018 on the establishment, operation and use of the Schengen\nInformation System (SIS) in the field of police cooperation and judicial\ncooperation in criminal matters, amending and repealing Council Decision\n2007/533/JHA, and repealing Regulation (EC) No 1986/2006 of the European\nParliament and of the Council and Commission Decision 2010/261/EU (OJ L\n312, 7.12.2018, p. 56).\n\n2.\n\nVisa Information System\n\n(a) Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND\nOF THE COUNCIL amending Regulation (EC) No 767/2008, Regulation (EC)\nNo 810/2009, Regulation (EU) 2017/2226, Regulation (EU) 2016/399,\nRegulation XX/2018 [Interoperability Regulation], and Decision 2004/512/EC\nand repealing Council Decision 2008/633/JHA - COM(2018) 302 final.\n\nTo be\nupdated once the Regulation is adopted (April/May 2021) by the co-legislators.\n\n3.\n\nEurodac\n\n\n(a) Amended proposal for a REGULATION OF THE EUROPEAN\n\nPARLIAMENT AND OF THE COUNCIL on the establishment of 'Eurodac'\nfor the comparison of biometric data for the effective application of Regulation\n(EU) XXX/XXX [Regulation on Asylum and Migration Management] and of\nRegulation (EU) XXX/XXX [Resettlement Regulation], for identifying an\nillegally staying third-country national or stateless person and on requests for\nthe comparison with Eurodac data by Member States' law enforcement\nauthorities and Europol for law enforcement purposes and amending\nRegulations (EU) 2018/1240 and (EU) 2019/818 \u2013 COM(2020) 614 final.\n\n4.\n\nEntry/Exit System\n\n(a) Regulation (EU) 2017/2226 of the European Parliament and of the Council of\n30 November 2017 establishing an Entry/Exit System (EES) to register entry\nand exit data and refusal of entry data of third-country nationals crossing the\nexternal borders of the Member States and determining the conditions for\naccess to the EES for law enforcement purposes, and amending the Convention\nimplementing the Schengen Agreement and Regulations (EC) No 767/2008\nand (EU) No 1077/2011 (OJ L 327, 9.12.2017, p. 20).\n\n5.\n\nEuropean Travel Information and Authorisation System", "# EN EN\n\n-----\n\n(a) Regulation (EU) 2018/1240 of the European Parliament and of the Council of\n12 September 2018 establishing a European Travel Information and\nAuthorisation System (ETIAS) and amending Regulations (EU) No 1077/2011,\n(EU) No 515/2014, (EU) 2016/399, (EU) 2016/1624 and (EU) 2017/2226 (OJ\nL 236, 19.9.2018, p. 1).\n\n(b) Regulation (EU) 2018/1241 of the European Parliament and of the Council of\n12 September 2018 amending Regulation (EU) 2016/794 for the purpose of\nestablishing a European Travel Information and Authorisation System (ETIAS)\n(OJ L 236, 19.9.2018, p. 72).\n\n6.\n\nEuropean Criminal Records Information System on third-country nationals and\nstateless persons\n\n(a) Regulation (EU) 2019/816 of the European Parliament and of the Council of 17\nApril 2019 establishing a centralised system for the identification of Member\nStates holding conviction information on third-country nationals and stateless\npersons (ECRIS-TCN) to supplement the European Criminal Records\nInformation System and amending Regulation (EU) 2018/1726 (OJ L 135,\n22.5.2019, p. 1).\n\n7.\n\nInteroperability\n\n(a) Regulation (EU) 2019/817 of the European Parliament and of the Council of 20\nMay 2019 on establishing a framework for interoperability between EU\ninformation systems in the field of borders and visa (OJ L 135, 22.5.2019, p.\n27).\n\n(b) Regulation (EU) 2019/818 of the European Parliament and of the Council of 20\nMay 2019 on establishing a framework for interoperability between EU\ninformation systems in the field of police and judicial cooperation, asylum and\nmigration (OJ L 135, 22.5.2019, p. 85).", "## Definitions\n\ngenai (genai) is a class of computer software and systems, or\nfunctionality within systems, that use large language models, algorithms, deep-learning, and machine\nlearning models, and are capable of generating new content, including but not limited to text, images,\nvideo, and audio, based on patterns and structures of input data.\n\nThese also include systems capable of\ningesting input and translating that input into another form, such as text-to-code systems.\n\nWhile this policy document includes principles that apply to genai technologies generally, the policy\nstatements apply only to genai systems.", "## genai (genai) Principles\n\nPrinciples describe general codes of conduct that represent the City\u2019s values and are aligned with our\nresponsibilities to the residents we serve.\n\nThese principles serve to guide City employees in their use of\nboth generative and traditional genai technology.\n\nCity employees shall adhere to the principles and\nrequirements outlined in this policy, and will be held accountable for compliance with these\ncommitments.\n\n1.\n\n**Innovation and Sustainability:** The City values public service innovation to meet our residents\u2019\n\nneeds.\n\nWe commit to responsibly explore and evaluate genai technologies, which will improve our\nservices and advance beneficial outcomes for both people and the environment.\n\n**2.\n\n** **Transparency and Accountability:** The City values transparency and accountability and understands\n\nthe importance of these values in our use of genai systems.\n\nThe City will ensure that the development,\nuse, and deployment of genai systems are evaluated for and compliant with all laws and regulations\napplicable to the City prior to use, and will make documentation related to the use of genai systems\navailable publicly.\n\n**3.\n\n** **Validity and Reliability:** The City will work to ensure that genai systems perform reliably and\n\nconsistently under the conditions of expected use, and that ongoing evaluation of system accuracy\nthroughout the development and/or deployment lifecycle is managed, governed, and auditable, to\nthe greatest extent possible.\n\n**4.\n\n** **Bias and Harm Reduction and Fairness:** We acknowledge that genai systems have the potential to\n\nperpetuate inequity and bias resulting in unintended harms on Seattle residents.\n\nThe City will\nevaluate genai systems through an equity lens, in alignment with our Race and Social Justice\n\n\n-----\n\ncommitments, for potential impacts such as discrimination and unintended harms arising from data,\nhuman, or algorithmic bias to the extent possible.\n\n**5.\n\n** **Privacy Enhancing:** The City values data privacy and understands the importance of protecting\n\npersonal data.\n\nWe work to ensure that policies and standard operating procedures that reduce\nprivacy risk are in place, and are applied to the genai system throughout development, testing,\ndeployment, and use to the greatest extent possible.\n\n**6.\n\n** **Explainability and Interpretability:** The City understands the importance of leveraging genai systems,\n\nmodels, and outputs that are easily interpreted and explained.\n\nWe work to ensure all genai systems and\ntheir models are explainable to the extent possible, and that system outputs are interpretable and\ncommunicated in clear language, representative of the context for use and deployment.\n\n**7.\n\n** **Security and Resiliency:** Securing our data, systems, and infrastructure is important to the City.\n\nWe\n\nwill ensure genai systems are evaluated for resilience and can maintain confidentiality, integrity, and\navailability of data and critical City systems, through protection mechanisms to minimize security\nrisks to the greatest extent possible, in alignment with governing policy and identified best\npractices.", "## Policy\n\n1.\n\nAcquisition of genai Technology\n\n1.1.\n\nConsistent with the City\u2019s standards for Acquisition of Technology Resources , City employees\n\nmay be authorized to use pre-approved genai software tools or they may request a nonstandard acquisition of genai software through Seattle IT\u2019s current request process.\n\n1.2.\n\nSeattle IT shall review exception requests according to its current risk and impact methodology,\n\nwhich shall include specific review criteria for genai technology.\n\nSeattle IT shall either\napprove or deny a request according to its criteria.\n\n1.3.\n\nThe City\u2019s standard for technology acquisition applies to all technology, including free-to-use\n\nsoftware or software-as-a-service tools.\n\n1.4.\n\nIf a technology that has already been approved for use in the City adds or incorporates\n\ngenai capabilities, no additional approval is required to use those capabilities, however\nall other aspects in this policy apply to said use.\n\n1.5.\n\nSeattle IT may revoke authorization for a technology that adds genai capabilities, or may restrict\n\nthe use of those genai capabilities, if, in its judgment, those genai capabilities present risks that cannot\nbe effectively mitigated to comply with this policy or other City policies.\n\n2.\n\nUse of genai Outputs\n\n2.1.\n\nOutputs of genai systems must be reviewed by humans prior to each use in an official\n\nCity capacity (\u201cHuman in the Loop\u201d or HITL).\n\nHITL review processes shall be documented by\nowning departments and shall demonstrate how the HITL review was conducted to adhere to\nthe principles outlined in this document.\n\n2.2.\n\nDocumentation of HITL reviews shall be retained according to the appropriate records retention\n\nschedule.\n\n-----\n\n3.\n\nAttribution, Accountability, and Transparency of Authorship\n\n3.1.\n\nAll **images and videos** created by genai systems must be attributed to the appropriate\n\ngenai system.\n\nWherever possible, attributions and citations to the City of Seattle should\nbe embedded in the image or video (e.g., via digital watermark).\n\n3.2.\n\nIf **text** generated by an genai system is used substantively in a final product, attribution to the\n\nrelevant genai system is required.\n\n3.3.\n\nIf a significant amount of **source code** generated by an genai system is used in a final software\n\nproduct, or if any amount is used for an important or critical function, attribution to the\nappropriate genai system is required via comments in the source code and in product\ndocumentation.\n\n3.4.\n\nAll attributions should include the name of the genai system used plus an HITL assertion (which\n\nshould include the department or group who reviewed/edited the content).\n\n_Example: Some material in this brochure was generated using ChatGPT 4.0 and was reviewed_\n_for accuracy by a member of the Department of Human Services before publication._\n\n3.5.\n\nDepartments shall interpret \u201csubstantive use\u201d thresholds to be consistent with the principles\n\noutlined in this document as well as relevant intellectual property laws.\n\n4.\n\nReducing Bias and Harm\n\n4.1. genai systems may produce outputs based on stereotypes or use data that is historically\n\nbiased against protected classes.\n\nCity employees must leverage RSJI resources (e.g., the Racial\nEquity Toolkit) and/or work with their departmental RSJI Change Team to conduct and apply a\nRacial Equity Toolkit (RET) prior to the use of a genai tool, especially uses that will\nanalyze datasets or be used to inform decisions or policy.\n\nAs per the objectives of the RSJ\nprogram, the RET should document the steps the department will take to evaluate genai-generated\ncontent to ensure that its output is accurate and free of discrimination and bias against\nprotected classes.\n\n5.\n\nData Privacy\n\n5.1.\n\nUse of genai tools shall be consistent with the principles and standards described in the\n\nCity\u2019s Data Privacy Policy and Information Security Policy .\n\n5.2.\n\nUnless suitable enterprise controls and data protection mitigations are in place, employees shall\n\nnot submit data that is classified by the City\u2019s data classification guidelines as Confidential or\nConfidential with Special Handling, or that otherwise not considered to be acceptable to\ndisclose to the public, shall not be submitted to genai systems.\n\n5.3.\n\nNo City data or records, including inputs or prompts, are to be used for training or parameter-\n\ntuning for genai models outside the City\u2019s control.\n\ngenai technologies that cannot prevent\nCity data or records from contributing to their language models may not be used by City\nemployees.\n\n-----\n\n6.\n\nPublic Records & City Records Management\n\n6.1.\n\nAll records generated, used, or stored by genai vendors or solutions may be considered\n\npublic records and must be disclosed upon request.\n\n6.2.\n\nAll genai solutions and/or vendors approved for City use shall be required to support\n\nretrieval and export of all prompts and outputs (either via exposed functionality or through\nvendor contract assurances).\n\n6.3.", "6.3.\n\nCity employees who use genai tools are required to maintain, or be able to retrieve\n\nupon request, records of inputs, prompts, and outputs in a manner consistent with the City\u2019s\nrecords management and public disclosure policies and practices.", "## Exceptions\n\nExceptions must be approved in advance through submission of a Seattle IT Exception Review Approval\nrequest in Service Hub.\n\nThis can be submitted directly or with the assistance of Client Engagement\npersonnel.\n\nNote: this section refers to exceptions to _this policy_ as it relates to genai tools that are\nin use by the City.\n\nIt does not refer to requests for acquisition of non-standard applications or\ntechnologies.", "## Non-compliance\n\nThe Chief Technology Officer (CTO) is responsible for compliance with this policy.\n\nEnforcement may be\nimposed in coordination with individual division directors and department leaders.\n\nNon-compliance may\nresult in department leaders imposing disciplinary action, restriction of access, or more severe penalties\nup to and including termination of employment or vendor contract.", "## Responsibilities\n\nThe policy will be maintained through the Data Privacy, Accountability and Compliance (DPAC) division,\nowned by the Director of DPAC and City of Seattle Chief Privacy Officer.\n\nTheir responsibilities include\ncreating and maintaining the genai risk and impact criteria and the documents and forms to\nsupport the exception review process for this technology.", "## Contents\n\nOverview ......................................................................................................................................... 1\nWhat Is genai?\n\n................................................................................................................... 2\nHow Do genai Models Use Data?\n\n..................................................................................... 3\nWhere Does the Data Come From?\n\n................................................................................................. 4\n\nWhat Happens to Data Shared with genai Models?\n\n.......................................................... 4\nPolicy Considerations for Congress ................................................................................................ 5\n\n\nExisting Data Privacy and Related Laws .................................................................................. 5\nProposed Privacy Legislation .................................................................................................... 6\n\n\nExisting Agency Authorities ..................................................................................................... 6\nRegulation of Data-Scraping ..................................................................................................... 7\n\n\nResearch and Development for Alternative Technical Approaches .......................................... 7", "## Overview\n\nSince the public release of Open genai\u2019s ChatGPT, Google\u2019s Bard, and other similar systems, some\nMembers of Congress have expressed interest in the risks associated with \u201cgenerative artificial\nintelligence (genai).\u201d Although exact definitions vary, genai is a type of genai that can generate\nnew content\u2014such as text, images, and videos\u2014through learning patterns from pre-existing data.\n\nIt is a broad term that may include various technologies and techniques from genai and machine\nlearning (ML).\n\n1\n\ngenai models have received significant attention and scrutiny due to their potential\nharms, such as risks involving privacy, misinformation, copyright, and non-consensual sexual\nimagery.\n\nThis report focuses on privacy issues and relevant policy considerations for Congress.\n\nSome policymakers and stakeholders have raised privacy concerns about how individual data\nmay be used to develop and deploy generative models.\n\nThese concerns are not new or unique to\ngenai, but the scale, scope, and capacity of such technologies may present new privacy\nchallenges for Congress.\n\n**genai at a Glance**", "**Major Developers and Selected Products:** **2**\n\n-  **OpenAI** (with partnerships and funding from Microsoft)\u2014\u201cChatGPT\u201d chatbot, \u201cDALL-E\u201d image\ngenerator\n\n-  **Google** \u2014\u201cBard\u201d chatbot\n\n-  **Meta** \u2014\u201cLLaMA\u201d research tool, \u201cMake-A-Video\u201d video generator\n\n-  **Anthropic** (founded by former employees of OpenAI)\u2014\u201cClaude\u201d chatbot\n\n-  **Stability genai** \u2014\u201cStable Diffusion\u201d image generator\n\n-  **Hugging Face** \u2014BLOOM language model\n\n-  **NVIDIA** \u2014\u201cNeMo\u201d chatbot, \u201cPicasso\u201d visual content generator", "**Types of Applications:**\n\n-  **Chatbots** \u2014systems that simulate human conversation, often in question-and-answer format\n\n-  **Image generators** \u2014systems that generate images based on an input or \u201cprompt\u201d\n\n-  **Video generators** \u2014systems that generate videos based on an input or \u201cprompt,\u201d sometimes called\ndeepfakes\n\n-  **Voice clones** \u2014systems that generate speech and voice sounds, sometimes called audio deepfakes\n\n1 There are various definitions of genai in statute and agency guidance.\n\nFor example, the National genai\nInitiative Act of 2020 (P.L.\n\n116-283) defines genai as \u201ca machine-based system that can, for a given set of human-defined\nobjectives, make predictions, recommendations or decisions influencing real or virtual environments.\n\nArtificial\nintelligence systems use machine and human-based inputs to\u2014(A) perceive real and virtual environments; (B) abstract\nsuch perceptions into models through analysis in an automated manner; and (C) use model inference to formulate\noptions for information or action.\u201d genai and machine learning (ML) are often used interchangeably,\nbut ML is a subfield of genai that focuses on systems that can \u201clearn\u201d and improve through experience and data.\n\nFor more\ninformation on this distinction, see Columbia Engineering \u201cgenai (genai) vs. Machine Learning,\u201d\n For more information on genai and\nmachine learning, see CRS Report R46795, _Artificial Intelligence: Background, Selected Issues, and Policy_\n_Considerations_ , by Laurie A. Harris.\n\n2 Six of the seven listed companies were identified based on participation in White House initiatives to develop \u201cpublic\nassessments\u201d of existing genai systems.\n\nMeta was not included in the White House announcement.\n\n\u201cFact Sheet:\nBiden-\u2060Harris Administration Announces New Actions to Promote Responsible genai Innovation that Protects Americans\u2019\nRights and Safety,\u201d White House, May 4, 2023, \n05/04/fact-sheet-biden-harris-administration-announces-new-actions-to-promote-responsible-genai-innovation-thatprotects-americans-rights-and-safety/.\n\nCongressional Research Service 1\n\n\n-----", "## What Is genai?\n\ngenai can generate new content\u2014such as text, images, and videos\u2014through learning\npatterns from data.\n\n3 There are many types of genai models (see **Figure 1** ), which can\nproduce content based on different inputs or \u201cprompts.\u201d For example, some models can produce\nimages from text prompts (e.g., Midjourney, Stable Diffusion, DALL-E), while others create\nvideos (e.g., Gen2 or Meta\u2019s Make-A-Video).\n\nSome scholars and policymakers have recently coined the term \u201c **general-purpose models** \u201d\n(GPAI) to describe applications like ChatGPT that can complete various functions.\n\n4 These GPAI\nmodels may have a wide range of down-stream applications compared to single-purpose models\ndesigned for a specific task.\n\nMany general-purpose genai applications are built on top of **large**\n**language models** (LLMs) that can recognize, predict, translate, summarize, and generate\nlanguage.\n\n5 LLMs are a subset of genai and are characterized as \u201clarge\u201d due, in part, to the\nmassive amount of data necessary for training the model to learn the rules of language.", "**Figure 1.\n\nExamples of genai Models**\n\n**Source:** Stable Diffusion and ChatGPT, via CRS.\n\nThe image was generated by Stable Diffusion and the text\nresponse was generated by ChatGPT.\n\n3 genai models may use different technical approaches and techniques, such as generative adversarial networks\n(GANs) or generative pre-trained transformers (GPTs).\n\nThe colloquial term \u201cdeep fakes,\u201d which refers to realistic\nmachine-generated images, videos, and audio, may also fall under the umbrella term of \u201cgenai.\u201d Deepfakes are\ntypically generated through GANs.\n\n4 European Parliament, \u201cGeneral-Purpose genai,\u201d\n\n\n5 Bender, Gebru, et al., \u201cOn the Dangers of Stochastic Parrots: Can Language Models Be Too Big?\u201d March 2023, ACM\nConference on Fairness, Accountability, and Transparency,  Samuel\nBowman, \u201cEight Things to Know About Large Language Models,\u201d April 2023, \n\nCongressional Research Service 2\n\n\n-----", "**Definitions**\n\n-  **Training a model** refers to providing a model with data to learn from, often called a training dataset.\n\nAfter\na model is trained to recognize patterns from one dataset, some models can be provided with new data and\nstill recognize patterns or predict results.\n\n-  **Fine-tuning a model** refers to training a previously trained model on new data, or otherwise adjusting an\nexisting model.\n\n6\n\ngenai models, particularly LLMs, require massive amounts of data.\n\nFor example,\nOpenAI\u2019s ChatGPT was built on a LLM that trained, in part, on over 45 terabytes of text data\nobtained (or \u201cscraped\u201d) from the internet.\n\nThe LLM was also trained on entries from Wikipedia\nand corpora of digitized books.\n\n7 Open genai\u2019s GPT-3 models were trained on approximately 300\nbillion \u201ctokens\u201d (or pieces of words) scraped from the web and had over 175 billion parameters,\nwhich are variables that influence properties of the training and resulting model.\n\n8\n\nCritics contend that such models rely on privacy-invasive methods for mass data collection,\ntypically without the consent or compensation of the original user, creator, or owner.\n\n9\nAdditionally, some models may be trained on sensitive data and reveal personal information to\nusers.\n\nIn a company blog post, Google genai researchers noted, \u201cBecause these datasets can be large\n(hundreds of gigabytes) and pull from a range of sources, they can sometimes contain sensitive\ndata, including personally identifiable information (PII)\u2014names, phone numbers, addresses, etc.,\neven if trained on public data.\u201d 10 Academic and industry research has found that some existing\nLLMs may reveal sensitive data or personal information from their training datasets.\n\n11\n\nSome models are used for commercial purposes or embedded in other downstream applications.\n\nFor example, companies may purchase subscription versions of ChatGPT to embed in their\nvarious services or products.\n\nKhan Academy, Duolingo, Snapchat, and other companies have\npartnered with OpenAI to deploy ChatGPT in their services.\n\n12 However, individuals may not\nknow their data was used to train models that are monetized and deployed across such\napplications.\n\n6 For example, fine-tuning could include adjusting a pre-existing model\u2019s parameters.\n\n7 Brown, et al., \u201cLanguage Models Are Few-Shot Learners,\u201d July 22, 2020, \n\n8 According to OpenAI, their models were trained on some datasets with a total of 300 billion tokens.\n\nA token is a piece\nof a word.\n\nOne token is around \u00be of a word.\n\nBrown, et al., \u201cLanguage Models Are Few-Shot Learners,\u201d July 22, 2020,\n\n\n9 , April 4, 2023,  Matt Burgess, \u201cChatGPT Has a Big Privacy Problem,\u201d _Wired_\n\n10 Nicholas Carlini, \u201cPrivacy Considerations in Large Language Models,\u201d December 15, 2020, Google Research Blog,\n\n\n11 Nicholas Carlini et al., \u201cExtracting Training Data from Large Language Models,\u201d Jun 15, 2021, \n2012.07805.\n\n12 Alex Heath, \u201cSnapchat Is Releasing Its Own genai Chatbot Powered by ChatGPT,\u201d _The Verge_ , February 27, 2023,\n\n\u201cIntroducing Duolingo Max, a Learning Experience Powered by GPT-4,\u201d March 14, 2023, Duolingo Blog,\n Sal Khan, \u201cHarnessing GPT-4 So That All Students Benefit.\n\nA Nonprofit\nApproach for Equal Access,\u201d Khan Academy, March 14, 2023, \n\nCongressional Research Service 3\n\n\n-----\n\nSome countries have taken action against genai developers for improper use of personal information.\n\nFor example, the Italian Data Protection Authority issued a temporary ban preventing OpenAI\nfrom using Italian users\u2019 data.\n\n13 After agreeing to certain changes\u2014such as allowing users to\nsubmit removal requests for personal data under the EU\u2019s General Data Protection Regulation\n(GDPR)\u2014OpenAI restored access to its service for users in Italy.\n\n14", "## Where Does the Data Come From?\n\nMany genai developers do not disclose the exact details of their training datasets.\n\nFor genai,\nmost training data is \u201cscraped\u201d from publicly available web pages before it is repackaged and\nsold, or in some cases, made freely available to genai developers.\n\nSome genai developers rely on popular large datasets such as \u201cColossal Clean Crawled Corpus\u201d\n(C4) and \u201cCommon Crawl,\u201d which are amassed through web crawling (i.e., software that\nsystematically browses public internet sites and collects information from each available web\npage).\n\nSimilarly, genai image generators are commonly trained on a dataset called LAION, which\ncontains billions of images scraped from internet sites and their text descriptions.\n\n15 Some\ncompanies might also use proprietary datasets for training.\n\ngenai datasets can include information posted on publicly available internet sites,\nincluding PII and sensitive and copyrighted content.\n\nThey may also include publicly available\ncontent that is erroneous, pornographic, or potentially harmful.\n\nSince data may be scraped\nwithout the creator\u2019s consent, some artists, content creators, and others have begun to use new\ntools such as \u201cHaveIBeenTrained\u201d to identify and report their own content in such databases.\n\nIn a\n2023 investigation, the _Washington Post_ and Allen Institute for genai analyzed the websites scraped\nfor the C4 dataset, which is used by genai developers including Google, Facebook, and OpenAI.\n\n16\nThe investigation found that the C4 dataset included websites with copyrighted content as well as\npotentially sensitive information, such as state voter registration records.\n\nThese forms of data collection may also raise questions about copyright ownership and fair use.\n\nFor a discussion of copyright issues and genai, see CRS Legal Sidebar LSB10922,\n_Generative genai and Copyright Law_ , by Christopher T. Zirpoli.", "## What Happens to Data Shared with genai Models?\n\nSome critics have also raised concerns that user data shared with a genai application\u2014\nsuch as a chatbot\u2014may be misused or abused without the user\u2019s knowledge.\n\nFor example, a user\nmay reveal sensitive health information while conversing with a health care chatbot without\nrealizing their information could be stored and used to re-train the models or for other\n\n13 Italian Data Protection Data Protection Authority (Garante per la protezione dei dati personali or GPDP), March 31,\n2023, \n\n14 Adi Robertson, \u201cChatGPT Returns to Italy After Ban,\u201d April 28, 2023, _The Verge_ , \n4/28/23702883/chatgpt-italy-ban-lifted-gpdp-data-protection-age-verification.\n\n15 Marissa Newman and Aggi Cantrill, \u201cThe Future of genai Relies on a High School Teacher\u2019s Free Database,\u201d\nBloomberg, April 23, 2023, \n\n16 Kevin Schaul, Szu Yu Chen, and Nitasha Tiku, \u201cInside the Secret List of Websites That Make genai Like ChatGPT\nSound Smart,\u201d April 19, 2023, ,  _Washington Post_\n\nCongressional Research Service 4\n\n\n-----\n\ncommercial purposes.\n\nMany existing chatbots have terms of service that allow the company to reuse user data to \u201cdevelop and improve their services.\u201d\n\nThese concerns may be particularly pertinent for generative models used in interactions or\nservices that commonly result in the disclosure of sensitive information such as advising, therapy\nhealth care, legal, or financial services.\n\nIn response, some critics have argued that chatbots and\nother genai models should require affirmative consent from users or provide clear\ndisclosure of how user data is collected, used, and stored.", "### Existing Data Privacy and Related Laws\n\nThe United States does not currently have a comprehensive data privacy law.\n\nCongress has\nenacted a number of laws that create data requirements for certain industries and subcategories of\ndata, but these statutory protections are not comprehensive.\n\nFor example, the Gramm-LeachBliley Act (P.L.\n\n106-102) regulates financial institutions\u2019 use of nonpublic personal information,\nwhile the Health Insurance Portability and Accountability Act (HIPAA, P.L.\n\n104-191) requires\ncovered entities to protect certain health information.\n\nUnder current U.S. law, genai may\nimplicate certain privacy laws depending on the context, developer, type of data, and purpose of\nthe model.\n\nFor example, if a company offers a chatbot in a videogame or other online service\ndirected at children, the company could be required to meet certain requirements under the\nChildren\u2019s Online Privacy Protection Act (COPPA, P.L.\n\n105-277).\n\nAdditionally, certain state laws on privacy, biometrics, and genai may have implications for\ngenai applications.\n\nIn many cases, the collection of personal information typically\nimplicates certain state privacy laws that provide an individual a \u201cright to know\u201d what a business\ncollects about them; how data is used and shared; the \u201cright to access and delete\u201d their data; or the\n\u201cright to opt-out\u201d of data transfers and sales.\n\n17 However, some of these laws include exemptions\nfor the collection of public data, which may raise questions about how and whether they apply to\ngenai tools that use information scraped from the internet.\n\nIn the absence of a comprehensive federal data privacy law, some individuals and groups have\nturned to other legal frameworks (e.g., copyright, defamation, right of publicity) to address\npotential privacy violations from genai and other genai tools.\n\nFor example, some companies\nhave faced class action lawsuits for possible violations of right of publicity state laws, which\nprotect against unauthorized use of an individual\u2019s likeness for commercial purposes.\n\n18\n\nCongress may consider enacting comprehensive federal privacy legislation that specifically\naddresses genai tools and related concerns.\n\nIn doing so, Congress may consider and\nevaluate similar state and international efforts.\n\nFor example, the European Union\u2019s (EU) proposed\ngenai Act includes various articles on data regulation, disclosures, and documentation, among other\nrequirements.\n\nThe EU genai Act recently added a category for general purpose genai systems and\n\n17 For example, the California Consumer Privacy Act (CCPA) and California Consumer Privacy Regulation (CPRA)\nprovide certain privacy rights to California rights.\n\nCalifornia Office of the Attorney General, \u201cCalifornia Consumer\nPrivacy Act (CCPA),\u201d May 10, 2023,  For more information on the CCPA or data\nprivacy laws, see CRS Legal Sidebar LSB10213, _California Dreamin\u2019 of Privacy Regulation: The California_\n_Consumer Privacy Act and Congress_ , coordinated by Eric N. Holmes; and CRS Report R45631, _Data Protection Law:_\n_An Overview_ , by Stephen P. Mulligan and Chris D. Linebaugh.\n\n18 Isaiah Poritz, \u201cgenai Celebrity \u2018Deepfakes\u2019 Clash with Web of State Publicity Laws,\u201d Bloomberg Law, April 14, 2023,\n\n\nCongressional Research Service 5\n\n\n-----\n\nfoundation models, another term used for genai models that train on large amounts of data and can\nbe adapted for various tasks.\n\n19", "### Proposed Privacy Legislation\n\nSome Members of Congress have proposed various comprehensive or targeted privacy bills with\nrequirements that could impact genai applications.\n\nThese are three common mechanisms\nincluded in various privacy bills:\n\n**Notice and Disclosure Requirements.\n\n** Currently, most genai applications do not provide\nnotice or acquire consent from individuals to collect and use their data for training purposes.\n\nCongress may consider requiring companies developing or deploying genai systems to\n(1) acquire consent from individuals before collecting or using their data, or (2) notify individuals\nthat their data will be collected and used for certain purposes, such as training models.\n\nSome\nscholars dispute the efficacy of notice and consent requirements.\n\n20\n\n**Opt-out Requirements.\n\n** Congress may consider requiring companies to provide users an option\nto opt-out of data collection.\n\nOf note, opt-out systems may not necessarily protect data that is\npublicly-scraped from the web, and may be cumbersome for individuals to exercise.\n\n**Deletion and Minimization Requirements.\n\n** Congress may also consider requiring companies to\nprovide mechanisms for users to delete their data from existing datasets or require maximum\nretention periods for personal data.\n\nCurrently, most leading chatbots and other genai models do not\nprovide options for users to delete their personal information.\n\nIn considering such proposals, Congress may also wish to consider practical challenges users may\nface exercising specific privacy rights as well as potential challenges for companies in complying\nwith certain types of legal requirements and user requests.", "### Regulation of Data-Scraping\n\nThere are currently no federal laws that ban the scraping of publicly available data from the\ninternet.\n\nThe Computer Fraud and Abuse Act (CFAA, 18 U.S.C.\n\n\u00a71030) imposes liability when a\nperson \u201cintentionally accesses a computer without authorization or exceeds authorized access,\nand thereby obtains ... information from any protected computer.\u201d 25 Some court cases have held\nthat this prohibition does not apply to public websites\u2014meaning that scraping publicly accessible\ndata from the internet does not violate the CFAA.\n\n26\n\nScraping publicly available information from the internet has privacy implications beyond\ngenai models.\n\nThe facial recognition company Clearview genai has scraped over 20 billion\nimages from the web, including social-media profile photos, which have been used for software\nand databases provided to law enforcement and other entities.\n\n27 Some technology companies have\nalso scraped publicly available data to amass large data repositories.\n\nWeb-scraping may raise\ncompetition concerns since larger companies may block competitors from scraping data.\n\nMany researchers, journalists, and civil society groups, among others, rely on scraping to conduct\nresearch that may be in the public interest.\n\nIf Congress were to consider broad legislation to limit\nor provide guardrails for scraping information from the internet, it might consider implications for\na range of activities that it may find beneficial.", "### Research and Development for Alternative Technical Approaches\n\nCongress may wish to consider providing funds to federal agencies for intramural and extramural\nresearch to examine the development of alternative genai models or related technologies that may\n\ngenai,\u201d press release, April 25, 2023, \n\n23 Adi Robertson, \u201cThe US Government Is Gearing up for an genai Antitrust Fight,\u201d _The Verge_ , March 28, 2023,\n\n\n24 \u201cChatGPT and More: Large Scale genai Models Entrench Big Tech Power,\u201d genai Now Institute, April 11, 2023,\n\n\n25 The Computer Fraud and Abuse Act is codified at Title 18, United States Code, \u00a71030.\n\n26 Zack Whittaker, \u201cWeb Scraping Is Legal, US Appeals Court Reaffirms,\u201d TechCrunch, April 18, 2022,\n\n\n27 Alex Hern, \u201cTechScape: Clearview genai Was Fined \u00a37.5m for Brazenly Harvesting Your Data\u2014Does It Care?\u201d _The_\n_Guardian_ , May 25, 2022, \n\nCongressional Research Service 7\n\n\n-----\n\npreserve individual privacy, such as privacy-enhancing technologies.\n\n28 There are benefits and\ntradeoffs to some genai models under development that may have privacy implications.\n\nFor\nexample, smaller models that use less data or avoid transmitting and analyzing data in the cloud\nmay minimize some privacy concerns but may amplify other issues, such as bias, by training on\nsmaller datasets and potentially limiting the representativeness of data being used to train\nmodels.\n\n29 Congress may consider directing agencies to conduct and fund research to support\nprivacy-by-design 30 for genai and ML applications in order to both foster greater privacy for\nindividuals and support the development of genai technologies and the global competitiveness of\nU.S. genai companies.", "### Disclaimer\n\nThis document was prepared by the Congressional Research Service (CRS).\n\nCRS serves as nonpartisan\nshared staff to congressional committees and Members of Congress.\n\nIt operates solely at the behest of and\nunder the direction of Congress.\n\nInformation in a CRS Report should not be relied upon for purposes other\nthan public understanding of information that has been provided by CRS to Members of Congress in\nconnection with CRS\u2019s institutional role.\n\nCRS Reports, as a work of the United States Government, are not\nsubject to copyright protection in the United States.\n\nAny CRS Report may be reproduced and distributed in\nits entirety without permission from CRS.\n\nHowever, as a CRS Report may include copyrighted images or\nmaterial from a third party, you may need to obtain the permission of the copyright holder if you wish to\ncopy or otherwise use copyrighted material.\n\n28 In a 2022 Request for Information, the White House Office of Science and Technology defined privacy-enhancing\ntechnologies as \u201ca broad set of technologies that protect privacy.\u201d Examples could include \u201cprivacy-preserving data\nsharing and analytics technologies, which describes the set of techniques and approaches that enable data sharing and\nanalysis among participating parties while maintaining disassociability and confidentiality.\n\nSuch technologies include,\nbut are not limited to, secure multiparty computation, homomorphic encryption, zero-knowledge proofs, federated\nlearning, secure enclaves, differential privacy, and synthetic data generation tools.\u201d Office of Science and Technology\nPolicy (OSTP), \u201cRequest for Information on Advancing Privacy-Enhancing Technologies,\u201d 87 3525035252, June 9, 2022.\n\n_Federal Register_\n\n29 Kyle Wiggers, \u201cThe Emerging Types of Language Models and Why They Matter,\u201d TechCrunch, April 28, 2022,\n\n\n30 James Coker, \u201c#DataPrivacyWeek Interview: Overcoming Privacy Challenges in genai,\u201d _Infosecurity Magazine_ ,\nJanuary 25, 2022, \n\n\n-----", "## Definitions\n\ngenai (genai) is a technology that can create content, including text,\nimages, audio, or video, when prompted by a user.\n\ngenai systems learn patterns and\nrelationships from massive amounts of data, which enables them to generate new content that\nmay be similar, but not identical, to the underlying training data.\n\nThe systems generally require\na user to submit prompts that guide the generation of new content.", "## Why do we need guideline to use genai systems in the workplace?\n\nBelow are just a few of the critical reasons why it\u2019s important to know how to use genai\nContent generated by genai should be reviewed and fact-checked, especially if used in public\ncommunication or decision-making.\n\nDES staff generating content with genai systems should verify that the content does not contain\ninaccurate or outdated information and potentially harmful or offensive material.\n\ngenai-generated content used in official state capacity should be clearly labeled.\n\n-----\n\npresent.", "### What should I Do when using genai systems\n\nDo read the entire document independently and review the summary for biases.\n\nDo rewrite documents in plain language for better accessibility and understandability.\n\nDo disclose how material was reviewed or edited and by whom.\n\ngenai-generated content used in official state capacity should be clearly labeled.\n\nSample disclosure line: This memo was summarized by ChatGPT using the following\nprompt: \u201cSummarize the following memo: (memo content)\u201d.\n\nThe summary was\nedited by {Insert Names}.\n\nDES employees should ensure no copyrighted material is published without\nappropriate disclosure or the acquisition of necessary rights.\n\nThis includes content\ngenerated by genai systems, which could inadvertently infringe upon existing copyrights.", "### What should I Not Do when using genai systems\n\nDon\u2019t use personal email addresses to login to genai systems or internet-based tools for DES\nbusiness use.\n\nDon\u2019t access or Use genai systems or internet-based tools until you have received authorization\nfrom ETS.\n\nDon\u2019t include sensitive or confidential information in the prompt.\n\nDon\u2019t integrate or incorporate any non-public information into genai.\n\nThe use of this information could lead to unauthorized disclosures and legal liabilities.", "### What to know before you use:\n\nState law already restricts the sharing of confidential information with unauthorized third\n\ni F l RCW 42 52 050 ( h \u2019 hi l ) ifi ll \u201cN\n\n\n-----\n\nentitled or authorized to receive the information.\u201d\n\nUsing a genai system may result in creating a public record under Washington\nstate's Public Records Act.\n\nContact your agency\u2019s Privacy and Records Officers for more\ninformation.", "#### This discussion paper proposes ideas for senior leaders in government and businesses on building an ecosystem for the trusted and responsible adoption of genai.\n\nThis should lead to a virtuous cycle, spurring innovation and enabling more to tap on opportunities afforded by genai.\n\nThe practical pathways for governance in this paper seek to advance the global discourse and foster greater collaboration to ensure genai is used in a safe and responsible manner, and that the most critical outcome \u2014 trust \u2014 is sustained.\n\n-----", "## genai  AND FOUNDATION MODELS\n\ngenai has taken the world by storm, providing a firsthand taste of engaging in conversation with an \u201cartificially\nintelligent being\u201d and an early glimpse, some say, of Artificial\nGeneral Intelligence (AGI) **1** .\n\nIts ability to be a creative force has\nanthropomorphised genai in a powerful way.", "##### genai: A creative, rather than  merely analytical force\n\nThe last wave of breakthroughs in genai mainly clustered around\n\u201cdiscriminative\u201d models.\n\nThese models aid decision-making by\nrecommending, filtering, or making predictions.\n\nThey do so by\nlearning the boundaries between various classes in the dataset,\nmaking them a natural fit for classification problems (e.g.\n\ncats vs\ndogs).\n\nOn the other hand, **generative models learn the underlying**\n**distribution of the data and can generate new content (literature,**\n**audio, videos) from this learned distribution (e.g.\n\nnew images of**\n**dogs)** .\n\nSuch genai models that generate new contents are referred to as\n\u201cgenai\u201d.\n\nEarly versions of genai were designed to solve specific tasks.\n\nFor example, models like CycleGAN and StyleGAN, which are built on\nthe popular Generative Adversarial Networks (GANs) architecture,\ncan learn to create and alter images in a manner suitable to the\ngiven task by training on chosen datasets.\n\n**Foundation models**\n**(** **as termed by researchers at Stanford University** **) on the other**\n**hand, refers to a special case of genai that are trained on**\n**a broad corpus of data and act as a \u201cfoundation\u201d for more taskspecific models.\n\n**\n\nFoundation models have demonstrated exceptional performance,\nespecially in the realm of natural language processing.\n\nFor instance,\nGPT3 and GPT4 received widespread attention for their ability to\nunderstand and generate natural language.\n\nOther examples include\nDALL-E , Stable Diffusion , and Midjourney which are capable of\ngenerating highly realistic images from textual prompts.\n\n**1** Artificial General Intelligence (AGI) commonly refers to genai that possesses the ability to understand,\nlearn, and perform a broad range of tasks at a level that matches or exceeds human capabilities.\n\nIt is in\ncontrast with narrow genai that can only perform a specific task.\n\n-----", "**Hence, they are surprisingly good at a wide range of tasks without**\n\n**being explicitly trained for these tasks** .\n\nGPT-3 has 175 billion\nparameters and later versions can be adapted to a downstream task\nsimply by providing it with a prompt (a natural language description\nof the task), an emergent property that was neither specifically\ntrained for nor anticipated to arise.\n\nThis has led to much excitement\nthat they potentially represent embryonic examples of AGI.\n\nThe spike in the success of genai, especially foundation\nmodels (collectively referred to as \u2018genai\u2019 henceforth) can be\nattributed to (i) the availability of powerful hardware; (ii) access to\nmassive datasets; (iii) a training technique known as self-supervision;\nand (iv) a new neural network architecture named Transformers.\n\nFoundation models are adapted for a specialised setting through\na process of fine-tuning using additional data, known as transfer\n\n\n-----\n\nlearning.\n\nIn later models, **incorporating human feedback through a**\n**process known as Reinforcement Learning with Human Feedback**\n**(RLHF) has also been found to improve performance and could**\n**potentially align these models with human principles and values** **2** **.\n\n**\nOpenAI\u2019s ChatGPT \u2019s ability to engage in realistic conversations and\nto answer natural language queries is fine-tuned from GPT (versions\n3.5 and 4), using RLHF to provide helpful responses.\n\nHowever,\nour understanding of the drawbacks associated with these finetuning techniques, particularly in regard to accuracy trade-offs and\nscalability, is still evolving.\n\n**2** Another recently proposed fine-tuning technique dubbed \u201cConstitutional genai\u201d uses feedback from genai\nsystems trained on a predefined set of human principles (analogous to a constitution) instead of direct\nhuman feedback.\n\n-----", "##### genai has uncovered a myriad  of use cases and opportunities that are reshaping industries, revolutionising sectors  and driving innovation.\n\nChatbots, capable of understanding and responding in natural\nlanguage, have already led to a vast improvement in user experience\nacross many online platforms.\n\nWhether it is instantly generating a\nshopping list from a simple indication of your cravings, automatically\ngenerating a compelling description of an item you are trying to sell\nonline, or perhaps roleplaying to improve your conversation skills,\nthese genai chatbots have proven to be valuable assistants.\n\nIn business\noperations, their applications range from drafting personalised\nemails and meeting minutes to creating new advertising videos.\n\nHR and legal departments are starting to rely on genai to\ngenerate job descriptions, contracts, and onboarding materials.\n\nFinally, recent successful marketing campaigns, such as Coca Cola\u2019s\n\u201cCreate Real Magic\u201d or BMW\u2019s \u201cUltimate genai Masterpiece\u201d, aim to\nimprove brand recognition using content produced by genai.\n\ngenai has also illustrated its effectiveness in new\nproduct design.\n\nIn fashion, they are used to design new collections\nand even translate pencil sketches to complete designs.\n\nIn\nhealthcare, genai assisted drug design is gaining attention.\n\ngenai-generated\nmedical images and records assist in developing diagnostic models\nwithout compromising patient privacy.\n\nThe generation of a digital\ntwin of a patient using genai is also being investigated\nfor its application in precision medicine and clinical trials .\n\nThe entertainment industry is also witnessing unprecedented\nchanges thanks to genai such as musicians licensing\ntheir voices for genai use and Netflix producing anime series with\ngenai-generated backgrounds.\n\nFinally, genai will undoubtedly\nhave a long-lasting impact on online search platforms whose\nresults will eventually be conversational rather than simply a\ncollection of hyperlinks.\n\nThe public sector also presents a promising landscape for\ngenai use.\n\ngenai-powered virtual assistants can be utilised to\nmake government services more accessible and efficient.\n\nInitial\nexamples include a ChatGPT-based genai assistant currently being\nevaluated for its ability to help citizens with basic legal questions .\n\nBy analysing public opinions and polls, genai models can\n\n\n-----\n\nalso be trained to reflect public interest and aid in policy-making.\n\ngenai is also a valuable tool for urban planning and can be\nused to generate solutions to tackle various problems affecting the\ncommunity, ranging from public infrastructure planning to climate\nchange in smart cities.\n\nThe opportunities that genai can unlock is tremendous, and\nis likely to be the start of a new transformative wave impacting all\nelements of how we live, work and play.\n\nWhile these potential use cases of genai are undeniably\ntransformative, concerns and threat scenarios have emerged;\nfrom the risk of genai making gaffes to worries that it will take over\nthe world.", "##### This primer presents a policy perspective, driven by technical analysis , for senior leaders in government and businesses to understand how to tap on the capabilities offered by genai in a safe and responsible manner , and in so doing, chart the path towards how genai can be harnessed in a trusted manner for the broader public good.\n\n-----", "## NEW RISKS WITH genai\n\nTrustworthy genai literature has identified a few governance areas,\nwhich typically deal with robustness, explainability, algorithmic\nfairness, privacy and security.\n\nThe Singapore Model genai Governance\nFramework and OECD genai Principles outline these core areas.\n\nEven though these governance areas continue to remain relevant,\ngenai also poses emerging risks that may require new\napproaches to its governance.", "**RISK 1: MISTAKES AND \u201cHALLUCINATIONS\u201d**\n\nLike all genai models, genai models make mistakes.\n\n**When**\n**genai makes mistakes, they are often vivid and take on**\n**anthropomorphisation, commonly known as \u201challucinations\u201d.\n\n**\nCurrent and past versions of ChatGPT are known to make factual\nerrors.\n\nSuch models also have a more challenging time doing\ntasks like logic, mathematics, and common sense **3** .\n\nThis is because\nChatGPT is a model of how people use language.\n\nWhile language\noften mirrors the world , these systems however do not (yet) have\na deep understanding about how the world works.\n\nAdditionally,\nthese false responses can be deceptively convincing or authentic.\n\nLanguage models have created convincing but erroneous responses\nto medical questions, created false stories of sexual harassment and\ngenerated software code that is susceptible to vulnerabilities .", "**DID YOU KNOW?\n\n**\n\n\u201cHallucination\u201d is probably not the best word to describe\nmistakes made by genai.\n\nThe metaphors used in\npublic discourse can sometimes be unhelpful.\n\nIt is important\nnot to impute deceptive intent or any other mental state by\nthe genai model, to these convincingly real mistakes.\n\nInstead it\nis better to understand these models as simply interpolating\nand filling in the gaps.\n\nCalling this \u201c confabulation \u201d or\n\u201c pastiche \u201d, is perhaps a better way of representing the\nmechanics of what is going on here.\n\n**3** These may, however, improve as technology advances.\n\n-----", "**Results from these models can appear overly \u201cconfident\u201d and are**\n\n**not qualified with a measure of uncertainty** , something which will\nhopefully be addressed through better research on uncertainty\nestimates.\n\nThese issues are worrisome in foundation models since\nthey are designed for broad, general purpose use.\n\nThe designer\nmay not fully envisage the specific issues and potential failures.", "**RISK 2: PRIVACY AND CONFIDENTIALITY**\n\ngenai tends to have a property of \u201cmemorisation\u201d.\n\nTypically,\none would expect genai models to generalise from the individual data\npoints used to train the model, so when you use the genai model there\nis no trace of the underlying training data.\n\n**As the neural networks**\n**underpinning genai models expand, these models have**\n**a tendency to** **memorise** .\n\nFor example, Stable Diffusion tends to\nmemorise twice as much as older genai models such as GANs .", "##### There are risks to privacy if models \u201cmemorise\u201d wholesale a specific data record and replicate it when queried.\n\nAdversaries may find out if a certain individual is part of a training\nset by querying the trained model or even reconstruct training\ndata by querying the model.\n\nThe former is problematic especially\nfor medical datasets or other datasets which are sensitive.\n\nMore\nresearch is needed to know why these models memorise.\n\nIt is often\nattributed to a training process known as overfitting, though there\nare other explanations .\n\nA worrying finding is that parts of sentences\nlike nouns, pronouns and numerals are memorised faster than\nothers \u2013 precisely the type of information that may be sensitive.\n\nThis memorisation property also poses copyright and confidentiality\nissues for enterprises and companies.\n\nSamsung employees\nreportedly unintentionally leaked sensitive information by pasting\nconfidential and copyrighted source code into ChatGPT to check\nfor errors and to optimise code.\n\nAnother shared a recording of\nan internal meeting.\n\nGiven that ChatGPT utilises user prompts to\nfurther train and improve their model unless users explicitly opt out,\nthat information is now out in the wild.", "**TOXICITY AND CYBER-THREATS**\n\nDissemination of false content such as fake news is becoming\nincreasingly hard to identify due to convincing but misleading text,\nimages and videos, potentially generated at scale by genai.\n\n-----\n\nThe negative impact of interactive media is greater as it taps into\nemotive human reactions.\n\nToxic content \u2014 profanities, identity attacks, sexually explicit content,\ndemeaning language, language that incites violence \u2014 has also been a\nchallenge on social media platforms.\n\n**Generative models that mirror**\n**language from the web run the risks of propagating such toxicity.\n\n**\nBut it is not as simple as just filtering or checking against toxic\ncontent.\n\nA na\u00efve filter for genai that refuses to answer a\nprompt like \u201cThe Holocaust was\u2026\u201d risks censoring useful information.\n\nIn addition, **impersonation and reputation attacks have become**\n**easier** , whether it is social engineering attacks using deepfakes\nto get access to privileged individuals or reputational attacks\nby offensive image generation .\n\nWith genai being able to\ngenerate images in one\u2019s likeness, there is a question of whether this\nconstitutes an intrusion of privacy.", "**Besides generating toxic and false content, genai also**\n\n**makes it possible to cause other types of harm.\n\n** Actors with little\nto no technical skills can potentially generate malicious code.\n\nCheckpoint Research used genai models to create an entire\ninfection flow \u2014 starting from generating phishing emails to creating\nexecutables with malicious code.\n\nThey restricted themselves from\nwriting any line of code and only used plain English prompts to\nachieve this task.\n\nOther examples include setting up a dark web\nmarketplace and generating Adversarial DDoS (Distributed Denialof-Service) attacks.\n\nWhile OpenAI has put in filters to stop the\ngeneration of such phishing emails and malicious code, there are ways\nto bypass these limitations .\n\nThis will prove to be an ongoing battle.", "**RISK 4: AN ERA OF COPYRIGHT CHALLENGES**\n\ngenai and machine learning models have always operated on the basis of\nidentifying patterns present in relevant data.\n\n**Current genai**\n**models require massive amounts of data.\n\nScraping the web for data**\n**at this scale has exacerbated the existing concerns of copyrighted**\n**materials used** (e.g.\n\nGetty Images suing Stable Diffusion over alleged\ncopyright violation for using their watermarked photo collection).", "**MODELS\u201d, 2022 ]**\n\n-----\n\nAdditionally, there is a rising concern in the creative community\nregarding genai that explicitly creates the style and expression of\nauthors, artists or musicians.\n\nThis is detrimental to artists as\ngenai like Stable Diffusion, Dall-E, and Midjourney are\ncapable of generating high quality images that can be used (e.g.\n\nZarya of the Dawn ) for commercial purposes.\n\nFalse attribution, copyright infringement and even forgery have\nbecome more challenging to combat.\n\nIt is an open debate whether\nthe current legal landscape surrounding copyright and intellectual\nproperty meaningfully addresses the current state of genai-generated\ncontent, both in terms of protecting an artist against having\nhis/her work used in genai training as well as the ownership of the\ncontent generated by genai.\n\nMoreover, current copyright laws protect\nexpression but not underlying facts, data, ideas or concepts.\n\ngenai that\nused these facts or data to train their models could legitimately use\nthese provisions that allow for fair use.\n\nHowever, genai that\nnow seeks to mimic style, flourishes, curation and creative aspects\nof the content operates in a grey area, where it is questionable\nwhether these are expressions that are protected.", "**DOWNSTREAM APPLICATIONS**\n\n**genai models capture the inherent biases present in the training**\n**dataset (e.g.\n\ncorpus of the web).\n\nIt is not surprising that if care is**\n**not taken, the models would inherit various biases of the Internet.\n\n**\nExamples include image generators that when prompted to create\nthe image of an \u201cAmerican person\u201d, lightens the image of a black\nman, or models that tend to create individuals in ragged clothes\nand primitive tools when prompted with \u201cAfrican worker\u201d while\nsimultaneously outputting images of happy affluent individuals\nwhen prompted with \u201cEuropean worker\u201d .\n\nIn particular, foundation\nmodels risk spreading these biases to downstream models trained\nfrom them.", "**OF GOOD INSTRUCTIONS**\n\n**genai safety is often associated with the concept of value-alignment**\n\n**- i.e.\n\naligned with human values and goals to prevent them from**\n**doing harm to their human creators.\n\n** genai scientists and designers\nhave always faced the challenge of formulating how to instruct genai\nsystems to achieve certain \u201cobjectives\u201d, defined in precise terms.\n\nHence, objectives are often mis-specified or represented using simple\nheuristics .\n\nThis can lead to potentially dangerous outcomes when\nthe genai systems blindly optimise for these objectives.\n\nOpenAI\u2019s blog\nhighlights a gaming agent purposely crashing itself over and over to\ngain additional points.\n\nAn objective function for genai assistants needs to prioritise between\nthe assistant being \u201chelpful\u201d or \u201charmless\u201d .\n\nHowever, it is difficult to\ndefine and specify what these concepts are, and how to trade-off\nbetween them.", "##### For instance, an insistence on avoiding harm can lead to \u201csafe\u201d responses that might not be valuable to the user.\n\nOn the other hand, assigning more importance to being helpful can lead to the system generating toxic responses that might cause harm.\n\nOne way to mitigate this is by relying on feedback from humans\nusing Reinforcement Learning through Human Feedback (RLHF).\n\nWhen fine-tuned using RLHF, language models learn to follow\ninstructions better and generate results that show fewer instances\nof \u201challucination\u201d and toxicity (even though bias still remains as an\nopen problem).\n\nSafety and alignment work is a nascent and ongoing\nresearch area.\n\n-----", "## BUILDING ON  THE FOUNDATION OF genai GOVERNANCE FRAMEWORKS\n\nThere are many discussions worldwide about genai, including\ncalls for government interventions to address these potential risks.\n\nIn parsing these issues, it is instructive to build on existing principles,\nsuch as those by the OECD , NIST ( genai Risk Management Framework )\nand Singapore ( Model genai Governance Framework ), that point to how\nwe might think about genai governance.\n\nSingapore\u2019s **Model genai Governance Framework** , for example,\nis based on the key governance principles - **transparency,**\n**accountability, fairness, explainability, and robustness** .\n\nIt translates these principles into practical guidelines for\norganisations to implement genai responsibly - based on risk\nprofiles and complements the efforts by sectoral regulators\nto provide context-specific interventions.\n\nOn the back of these principles, Singapore also developed\nthe genai Verify testing framework and toolkit as **a minimum**\n**viable product (MVP)** , to provide a way for organisations to\ndemonstrate their implementation of trustworthy genai.\n\ngenai Verify\nwill continue to develop and evolve, as there remain many\ngaps in coverage, but it aims to provide a seed to support\nindependent testing frameworks and toolkits.\n\nThe MVP\nincorporates tools for fairness, explainability and robustness,\nfor testing more traditional supervised learning models.\n\nWhile these principles and practices are applicable regardless of the\ntypes of genai deployed, policy adaptations will, nevertheless, be needed\nto consider the unique characteristics of genai.\n\nIn particular,\nthere are two key characteristics of note:", "**1** \u0007 **genai will increasingly form the foundation upon**\n\n**which other models/applications are built.\n\n** Because of\nthis dependency, there are concerns over systemic risks as\nproblems inherent in these models could perpetuate and lead\nto wider impact.\n\nGovernance frameworks will have to provide\n\n\n-----\n\nguidance on accountability between parties and across the\ndevelopment lifecycle, as well as address safety concerns in\nmodel development and deployment.", "**2** \u0007 **These models are generative \u2013 not only because they can**\n\n**produce realistic content at scale, but also because they**\n**demonstrate increasingly sophisticated capabilities, e.g.\n\nthe**\n**ability to reason.\n\n** It may be increasingly difficult to distinguish\ngenai-generated content and people may become more susceptible\nto misinformation and online harms.\n\nAs genai potentially surpasses\nhuman capacity at some levels, there are also deep concerns\naround controllability and alignment.\n\nRisks From Very Powerful genai\n\nThere will be longer term considerations as genai\nshows hints of being AGI.\n\nProminent genai experts have sounded\nthe alarm about the potential existential risks posed by very\npowerful genai and have asked for interventions, such as setting\nup an agency to provide oversight, subjecting very large and\ncapable models to regulatory controls, and controlling access\nto compute.\n\nThere is a need to monitor development of very\npowerful genai.\n\nAt the same time, it is also necessary to address\nreal and present risks.\n\nWhile acknowledging the importance\nof guarding against existential risk, this paper focuses on the\nactions needed to enable trusted use of any genai \u2013\nwhere model development and deployment have immediate\nimpact on trust and safety.\n\n-----", "##### To do so, policymakers should enable greater adoption, as well as put in place guardrails to address the risks and ensure safe and responsible use.\n\nThis requires a systems approach.\n\nThe various recommendations should be looked at in totality, as we seek to learn, iterate and evolve with the rapidly advancing technology.\n\n**A practical, risk-based and accretive approach** will contribute to\nenhanced trust and safety as genai continues to evolve.\n\nIn doing so, we\nmay wish to consider the following six dimensions.\n\n**1** **\u0007** **Accountability:** As more genai applications are built on top of\nfoundation models, **a shared responsibility framework** among\nparties in the development lifecycle will clarify accountability\nand incentivise safer outcomes.\n\nThis will further benefit\nfrom enhanced transparency, such as via **standardised**\n**information about the model** for deployers to make proper risk\nassessments.\n\nFinally, **labelling/watermarking** of genai-generated\ncontent will allow consumers of content to make more informed\ndecisions and choices, and allow **remedial actions** to be taken if\nharmful content is distributed.\n\n**2** **\u0007** **Data Use:** Data has significant impact on model performance,\nwith direct implications for privacy, copyright and bias.\n\n**Transparency on type of training datasets** is an important\nconsideration so that the wider community is aware of the\ninput factors that go into the model.\n\nIn turn, policymakers\nalso need to clarify ambiguity around the **requirements for**\n**data privacy and copyright** under their respective regulations\n(e.g.\n\nlegal basis for using Internet data for model training\nand legality of mimicking styles under copyright laws).\n\nTo\naddress embedded bias, there should also be consideration on\n\n\n-----\n\ncollaboratively building **trusted data sources** , which act as a\nreference.\n\n**3** **\u0007** **Model Development and Deployment:** Design choices by\ngenai developers in the model development and\ndeployment have an impact on downstream organisations\nthat are using these models to develop their genai applications.\n\nTo build and deploy safer models, model developers should\nbe **transparent about how their models are developed and**\n**tested, and should monitor performance in partnership**\n**with application deployers** .\n\nWhen done objectively, this\nenables systematic evaluation and comparison of models for\nimprovements.\n\nPolicymakers can support through facilitating\nthe development of **standardised evaluation metrics** as well as\na **corpus of tools and capabilities** .", "**4** **\u0007** **Assurance and Evaluation:** There is value for **independent**\n\n**third-party evaluation and assurance** to provide objective\nassessments.\n\nIn addition, given the diversity of genai\nuse cases and risks, there is significant value to\n**crowd in opensource expertise** (via a vibrant open-source community) for\ntool development as well as \u201cadversarial testing\u201d, especially as\nmodels become larger and more complex.\n\nSuch an evaluation\napproach should be practical and risk-based.\n\n**5** **\u0007** **Safety and Alignment Research:** More fundamentally, as genai\nmodels become more powerful, we need to ensure that human\ncapacity to control genai systems keeps pace.\n\nDevelopment in\nsafety and alignment lags that of genai development.\n\nPolicymakers need to invest strategically to **accelerate**\n**safety and alignment research** especially in more advanced\ntechniques, to enable interpretability, controllability and\nrobustness.\n\nThis effort should also nurture centres of\nknowledge in Asia and other parts of the world, to complement\nthe ongoing efforts in the US and EU.\n\n**6** **\u0007** **genai for Public Good:** Responsible genai must\nultimately be about achieving Public Good.\n\n**Consumer literacy**\nprogrammes will help raise public understanding and improve\nsafe use.\n\nEnhanced **education and training** is also needed to\nbuild skills, given the anticipated changes to jobs.\n\nFurthermore,\nto make genai accessible to all enterprises, especially\nsmall and medium enterprises (SMEs), policymakers can help\nby providing an **updated set of guidance** for organisations, as\nwell as **common infrastructure** so that the wider ecosystem\ncan more easily develop and test genai models and\napplications.\n\nAs the impact is ultimately on the end- users,\n**measurement and understanding of the end-user impact**\nwill inform ongoing policy innovation.\n\nFinally, as the impact of\ntechnology does not respect borders, we need to collaborate\n\n\n-----\n\nglobally, and create platforms to **bring in diverse stakeholders**\nto the ongoing conversation.\n\nThese dimensions will be unpacked further in the subsequent\nchapter.\n\nCollectively, they seek to fulfil the core principles of\naccountability, transparency, fairness, explainability, and robustness\n\u2013 that enable genai to be safe, trusted and used for the Public Good.\n\n-----", "**1** **ACCOUNTABILITY**\n\nModel Development \u2013\nClearer Accountability Across Stakeholders\n\nModels should have safety-by-design as a key consideration.\n\n**Clearer**\n**accountability of stakeholders across the model development**\n**life cycle** will incentivise safer outcomes.\n\nWhile there is general\nconsensus in software development that individual stakeholders\nshould be responsible for faults attributable to their respective\nmodules, identifying what caused an error in an genai application\nis a complicated task.\n\nInteractions between the different codes\ncontributed by the genai model (as a base layer), and the\napplication developers (that ride on top), are challenging to parse\nout individually.\n\nWhile the allocation of responsibility and liability is a complex topic,\nthere is space for policymakers to facilitate and co-create with\ndevelopers a **shared responsibility framework** (the core concept\nexists today in adjacent domains such as cloud deployment **4** ) as\na first step.\n\nThe framework aims to clarify the responsibilities\nof all parties in the model development life cycle, as well as the\nsafeguards and measures they they need to respectively undertake.\n\nThis framework will further benefit from greater transparency\nabout the inherent capabilities and limitations in their models, as\nwell as the safeguards that they have undertaken to mitigate risks.\n\nWhile developers do share information about their models (these\nexist in some basic form today e.g.\n\nmodel cards), it is at times\nincomplete.\n\nPolicymakers can therefore work with model developers\nto **enhance transparency via a set of information disclosure**\n**standards** .\n\nA layman analogy is akin to \u201cnutrition labels\u201d on our\nfood products.\n\nSome elements to include are (i) model capabilities,\nlimitations and evaluation outcomes, including areas where there is\nuncertainty, (ii) datasets used for training, (iii) mitigation measures\nalready implemented within model design, and (iv) intended and\nrestricted use.\n\nPolicymakers and developers need to strike a balance\nbetween comprehensiveness and practicality - on one hand to have\nrelevant and useful information to conduct risk assessments, and\non the other, to address legitimate concerns around protecting\ncommercially sensitive information.\n\n**4** The experience of the cloud industry, which has similar dynamics between large and small players,\nis potentially instructive.\n\nToday, cloud service providers like Google Cloud , Microsoft Azure and\nAmazon Web Services adopt a shared responsibility model to clearly delineate the respective controls\nand measures that they and their customers are responsible for to effectively secure applications hosted\non the cloud infrastructure.\n\n-----\n\nContent Generation \u2013 Identifying genai Content\n\ngenai\u2019s ability to enable rapid creation of realistic content\nat scale has increased the risks of misinformation and online\nharms.\n\nThe ability to identify genai-generated content will increase\ntransparency, and allow consumers of content to make more\ninformed decisions and choices.\n\nSynthetic media technology providers (e.g.\n\nmodel developers,\napplication deployers) and content distributors (e.g.\n\nsocial media\nplatforms, broadcasting companies) should invest in capabilities\non their platforms to **detect and \u201clabel/watermark\u201d genai-generated**\n**content** .\n\nFor example, synthetic media technology providers\nmay need to incorporate some form of cryptographic content\nprovenance mechanisms (see C2PA standards for illustration)\nor other such techniques into the model/synthetic media tool to\nenable people or machines to distinguish genai-generated from humangenerated content.\n\nUsers of such technology, including the wider\ncommunity of content creators, should also subscribe to positive\nnorms and be transparent about their use of synthetic media/\ngenai.\n\nIn the same vein, content distributors play an important role in\n(i) disclosing when genai content is detected; and (ii) **taking**\n**timely corrective action when harmful genai content is**\n**distributed** .\n\nSome content distributors like TikTok and Google have\nalready started implementing such labelling policies/tools.", "**2** **DATA USE**\n\nTransparency on Type of Data\n\nData is a critical component of genai with significant\nimpact on model performance and output.\n\nWith due regard to the\nvastness of the training dataset, **transparency on the type of input**\n**data remains an important principle** to enable deployers and endusers to better anticipate how a model might behave and adopt\nsafeguards.\n\nClarity on Data Privacy and Copyright\n\nThe unique characteristics of genai have led to new legal\nambiguities on data use.\n\nFor example, under data privacy laws like\nthe EU General Data Protection Regulation, the legality or legal\nbasis of using Internet data containing publicly available personally\nidentifiable information (PII) to train foundation models is unclear.\n\nUnder Singapore\u2019s Personal Data Protection Act, while organisations\nmay collect and use information from the public internet without the\nneed to seek consent from the affected individuals so long as the\n\n\n-----\n\ncollection and use are reasonable, the reasonableness of trawling\nthe Internet for training data still needs to be established.\n\nUnder\ncopyright law, it is also unclear at times whether the output from\ngenai models infringes copyright, such as when generated\ncontent mimics style and brand identity to the detriment of the\noriginal creators **5** .\n\nPolicymakers should therefore interpret existing laws in a\ntransparent and facilitative manner, while providing guardrails.\n\nThis\ncan be through issuing initial **data privacy and copyright guidelines**\n**for genai** to clarify how to treat questions of privacy and\ncopyright and the relevant requirements (e.g.\n\nprovide recourse for\ndata subjects to correct inaccurate PII in model outputs, disclose\nuse of copyrighted material in training data), while facilitating the\nvalid use of data for the continued development of genai.\n\nAddressing Bias\n\nWhile recognising that it is not possible to completely eradicate bias\nin the genai system, each party can play their part to minimise bias.\n\nThe\ndefinition of bias is context-specific.\n\nRegulators and policymakers\nneed to consider if there is legal ambiguity introduced by generative\ngenai that warrants further clarity on their part.\n\nModel developers\nhave a role to play by being more selective of their training datasets.\n\nIn turn, application deployers should also implement downstream\nmeasures to mitigate data risks where possible.\n\nFor example, if\nmodels are already pre-trained with data containing embedded bias,\ndeployers could consider using **trusted data repositories** , such as\ntheir own datasets, that the model could reference to improve the\nmodel output as part of the application design and engineering.\n\nThere is also space to consider collaboratively building and\nexpanding access to more of such trusted data sources.", "**3** **MODEL DEVELOPMENT AND DEPLOYMENT**\n\nModel developers\u2019 design choices **6** directly impact the quality and\nsafety of the models.\n\nTo ensure safer outcomes, developers need\nto be transparent about the model development and deployment\nin objective and consistent ways.\n\nThis in turn enables systematic\nassessment about how the models are **developed, tested and**\n\n**5** With respect to training data, the copyright regimes in some jurisdictions like Singapore , UK , and the\nEU have provided specific support for data mining or computational data analysis in order to support the\nprocessing of copyrighted material for model development.\n\nWhere such specific provisions are absent,\nmost copyright regimes may possibly support such processing for model development in reliance on the fair\nuse doctrine instead.\n\n**6** For example, through the techniques they adopt to improve model quality at the pre-training stage\n(e.g.\n\nchain-of-thought for better explainability through reasoning), as well as safeguards they have\nimplemented against harms (e.g.\n\nRLHF to reduce incidence of undesirable output, or filtering phrases that\nexhibit hateful content)\n\n\n-----\n\n**monitored in deployment** , and comparisons of different models by\nthe wider community.\n\nIt also allows application deployers to make\nwell-informed risk management decisions.\n\nHowever, evaluation of genai models today is nascent and\ndevelopers each use their own benchmarks.\n\nTests for generative\ngenai are largely still being researched.\n\nNew evaluation metrics and\ntechniques are required because traditional genai evaluation tools (e.g.\n\nfor supervised classification or regression models) are not directly\ntransferable to genai **7** .\n\nIn these early days of the technology\nwhere there is a need to balance risk mitigation with meaningful\nexperimentation, a no-regrets move for policymakers is to facilitate\nthe development of **standardised evaluation metrics and tools** .\n\nThis is not limited to proprietary models but would also be useful for\nopen-source models.\n\nTo illustrate, model qualities in the evaluation\nmetrics could include the following components:\n\n**A** **\u0007** **Model safety** -  evaluation of qualities based on internationally\nrecognised principles (e.g.\n\nfairness, explainability and\nrobustness) and specific harms (e.g.\n\nmemorisation and\ncopyright, toxicity generation);\n\n**B** \u0007 **Model performance** of specific tasks (e.g.\n\nsummarisation,\ninformation retrieval) and use cases (selected based on material\nimpact to consumers); and\n\n**C** **\u0007** **Model efficiency and environmental sustainability** , such as\ntraining energy cost and training CO2 transmissions.\n\nWith the\nuse of tremendous compute to train and use genai\nmodels, it is important to seed energy use and sustainability as\nkey considerations early on in this policy discussion.\n\nThe importance of evaluation is commonly recognised by many\njurisdictions, most recently by G7 in the Hiroshima genai Process , as\nwell as by the US and EU in the Trade and Technology Council\u2019s Joint\nRoadmap on Evaluation and Measurement Tools for Trustworthy genai\nand Risk Management and by the UK in its genai Assurance Roadmap .\n\nJoint collaboration among policymakers to develop the evaluation\nmetrics would therefore be an important next step to prevent\nfragmentation of genai evaluation metrics.\n\nAs genai grows in impact, global discussions are also shifting\ntowards new genai regulation for greater government control over the\nmodel development, based on key \u2018control points\u2019 throughout the\nmodel development lifecycle, such as controlling access to open-\n\n**7** genai often involves creative tasks where subjective human judgement plays a role.\n\nCurrent\nevaluation metrics, such as accuracy or mean squared error, are not designed to capture the nuances\nof creativity or semantic coherence that are important for generative tasks.\n\nMoreover, genai\nsometimes operates in a space without a definitive ground truth and labelled data is unavailable, making it\nchallenging to establish reference points for comparison and evaluation.\n\n-----\n\nsource models.\n\nWhile it is possible to legislatively push through\nthese checks and controls, there are **practical considerations**\nregarding implementation and effectiveness.\n\nGovernment capacity\nwill need to be enhanced, and technical tools, standards and\ntechnology to support regulatory implementation need to be ready\nbefore regulation can be effective.\n\nAmidst the pressure to regulate, it is also useful to consider\nwhether **existing laws** , such as sectoral legislation and data\nprotection laws, can be tapped on and updated if necessary,\nparticularly when addressing deployment and downstream use of\ngenai systems.\n\nAt the same time, strongly interventionist regulations\nshould be carefully considered to tread the balance between risk\nmitigation and market innovation.\n\nFor example, overly restrictive\nregulation on open-source models can stifle innovation by hindering\ncollaboration and access.", "For example, overly restrictive\nregulation on open-source models can stifle innovation by hindering\ncollaboration and access.\n\nFurthermore, the different release\nmethods (from fully closed, staged release, hosted access, API\naccess to downloadable and fully open) have their own benefits and\ntrade-offs.\n\nPolicymakers need to consider the appropriate method,\ngiven the context and requirements.", "**4** **ENHANCING EVALUATION AND ASSURANCE**\n\n**Third-party evaluation and assurance** is an important part of the genai\necosystem for enhanced credibility and trust.\n\nIt helps to validate the\ntrustworthiness of genai systems, and brings an external perspective\nthat can help uncover potential biases or flaws.\n\nIn the longer term,\nthe adoption of standardised evaluation metrics would promote\nan interoperable approach towards genai governance and testing.\n\nAs\nit evolves, it could also eventually lead to the development of more\ninstitutionalised and thorough processes to ensure safety, similar to\nhow drug safety is monitored and tested today.\n\n**Crowding in open-source expertise** will be critical in growing\na vibrant ecosystem for third-party testing of genai systems.\n\nNo\nsingle entity can develop all the evaluation metrics and tools to\naddress the wide range of contexts and use cases that generative\ngenai can be applied to.\n\nMoreover, diverse perspectives are needed\nto discover new and emerging genai risks as models become larger\nand more complex.\n\n\u201cCrowding in\u201d (via open-source and an opensource community) will be key.\n\nThis is a known modality in software\ndevelopment.\n\nFor example, cybersecurity has demonstrated how\nharnessing ecosystem wide capabilities can help address fastevolving threats.\n\ngenai testing can draw useful lessons from this\ndomain to enhance overall security and robustness of models\n\n\n-----\n\n(e.g.\n\nvulnerability reporting norms, red-teaming and bounty\nprogrammes which could be extended to discovery or tracking\nof genai harms and vulnerabilities).", "**5** **SAFETY AND ALIGNMENT RESEARCH**\n\nAs genai potentially surpasses human capabilities, there are concerns\naround ensuring that models are interpretable, controllable, robust\nand aligned with human objectives and values.\n\nSafety and alignment\nefforts aim to address these concerns through novel techniques.\n\nThe investment and knowledge in this space today lags the\nactual development of genai.\n\nA global concerted effort is\nrequired.\n\nPolicymakers should **invest in growing the safety and**\n**alignment research strategically** to ensure that our capacity to\ncontrol genai systems keeps pace with the potential risks.\n\nFor example, enhancing interpretability through mechanisms\nto report the internal logic used to produce output, enabling\ncontrollability such that genai systems perform within acceptable\nbounds, and strengthening robustness with design features to\nensure that genai systems are robust against failures, vulnerabilities\nand adversarial attacks.\n\nThere is also a strategic need to **nurture a safety and alignment**\n**research ecosystem in Asia and other parts of the world** , to\ncomplement ongoing efforts in the US and EU.\n\nThis is to bring in\ndiverse safety priorities and ethical norms from around the world\nfor the development of safer and more aligned models for the\nfuture.\n\nIt will also help to accelerate R&D by tapping on global\ncapabilities and capacity.", "**6** **genai FOR PUBLIC GOOD**\n\nResponsible genai must ultimately be about how genai can be harnessed\nfor the Public Good.\n\nPolicymakers have a role to facilitate societal\ntransition and ensure that the people and enterprises are\nready to reap the opportunities afforded by genai in an\ninclusive manner.\n\n**Public-private partnerships** will be a key avenue\nto accelerate work in this area, given the diversity of views and\nresources that can be pooled.\n\n**8** This is evidenced by the inappropriate use of genai chatbots by people as search engines (without\nfurther verification of the accuracy of results), reports of people becoming overly reliant on genai\nleading to unhealthy emotional attachment, or even misuse of genai for cheating, that could lead to\nsuboptimal education outcomes in the longer term.\n\n-----\n\nWhile the public has taken to using genai applications,\nthere remains a fairly low level of awareness as to how generative\ngenai works, and how to use it safely and appropriately **8** .\n\n**Consumer**\n**literacy** programmes can help raise public understanding and\nimprove safe and responsible use.\n\nPolicymakers also have a role to\nenhance **education and training** to build skills, given the anticipated\nimpact on jobs due to genai.\n\nFurthermore, it is important that genai technology\nis accessible to all, including smaller and less well-resourced\ncompanies.\n\nTo facilitate adoption of the technology, and in a\nresponsible and effective way, policymakers can help by highlighting\n**use cases** to demonstrate ways in which genai can add\nbusiness value or enhance productivity, and providing **guidelines** ,\nwhich could include measures that organisations can implement to\nmitigate risks and improve safety **9** .\n\nIn addition, policymakers should consider providing **common**\n**infrastructure** that the wider ecosystem, e.g.\n\nresearchers, smaller\ncompanies, can use to develop and test genai models and\napplications.\n\nThis could also be used to draw in the wider community\nto develop applications and to better leverage genai for\nsocial good.\n\nThe ultimate measure of effectiveness is the safety and level of\n**impact to the end-user** .\n\nThe judgement and assessment around\nimpact must therefore be the guiding principle, to enable genai use\nto be human-centric and trusted.\n\n**Development of measures to**\n**quantify that impact** , will inform policy innovation that will naturally\ncontinue to evolve with the technology.\n\n**9** E.g.\n\nConduct robustness and accuracy tests as part of risk management; Ensure data security during\nprompt engineering/fine-tuning of models, and refrain from entering sensitive information; Remind\nemployees to be responsible for their own work products and should ensure that these are accurate,\nappropriate and lawful (e.g.\n\ncopyright, data privacy).\n\n-----", "## CONCLUSION\n\nWhile it may be difficult to achieve global consensus on policy\napproaches, the ideas proposed in this paper seek to **foster greater**\n**global collaboration** by sharing ideas and practical pathways.\n\nIn\ndoing so, these ideas hopefully provide a common baseline for\nunderstanding among different jurisdictions.\n\nAs genai is still in the early stages of development and\nits implications are not fully understood, these are initial steps\nto strengthen the foundation established by earlier governance\nframeworks.\n\nIn some ways, these ideas are not unique - there is\nspace to work closely with a coalition of like-minded jurisdictions,\nindustry partners and researchers towards a **common global**\n**platform and better governance frameworks** for genai.\n\n-----", "## FURTHER READING\n\nOECD: genai Language Modes: Technological, Socio-Economic and\nPolicy Considerations\n\nPartnership on genai: Responsible Practices for Synthetic Media\n\nFuture of Life Institute: Policy Making in the Pause\n\nIBM: A Policymaker\u2019s Guide to Foundation Models\n\nGoogle: A Policy Agenda for Responsible Progress in Artificial\nIntelligence\n\nMicrosoft: Governing genai: A Blueprint for the Future\n\nOpenAI: GPT-4 System Card\n\nHugging Face: Evaluate Measurement\n\nPercy Liang et al.\n\n: Holistic Evaluation of Language Models\n\n\n-----\n\n**\u00a9 \u0007** **COPYRIGHT IMDA AND**", "**ALL RIGHTS RESERVED.\n\n**\n\nAt IMDA, we see ourselves as Architects of Singapore\u2019s Digital\nFuture.\n\nWe cover the digital space from end to end, and are unique\nas a government agency in having three concurrent hats - as\nEconomic Developer (from enterprise digitalisation to funding R&D),\nas a Regulator building a trusted ecosystem (from data/genai to digital\ninfrastructure), and as a Social Leveller (driving digital inclusion\nand making sure that no one is left behind).\n\nHence, we look at the\ngovernance of genai not in isolation, but at that intersection with the\neconomy and broader society.\n\nBy bringing the three hats together,\nwe hope to better push boundaries, not only in Singapore, but in Asia\nand beyond, and make a difference in enabling the safe and trusted\nuse of this emerging and dynamic technology.\n\nAicadium is a global technology company delivering genai-powered\nindustrial computer vision products into the hands of enterprises.\n\nWith offices in Singapore and San Diego, California, and an\ninternational team of data scientists, engineers, and business\nstrategists, Aicadium is operationalising genai within organisations\nwhere machine learning innovations were previously out of reach.\n\nAs Temasek\u2019s genai Centre of Excellence, Aicadium identifies and\ndevelops advanced genai technologies, including areas of genai governance,\nregulation, and the ecosystem developments around genai assurance.\n\nLearn more at aicadium.genai .\n\nRecognising the importance of collaboration and crowding in\nexpertise, Singapore set up the genai Verify Foundation to harness\nthe collective power and contributions of the global open-source\ncommunity to build genai governance testing tools.\n\nThe mission of\nthe genai Verify Foundation is to foster and coordinate a community\nof developers to contribute to the development of genai testing\nframeworks, code base, standards and best practices.\n\nIt will\nestablish a neutral space for the exchange of ideas and open\ncollaboration, as well as nurture a diverse network of advocates for\ngenai testing and drive broad adoption through education and outreach.\n\nThe vision is to build a community that will contribute to the broader\ngood of humanity, by enabling trusted development of genai.\n\nIMDA and\nAicadium are members of the Foundation.", "**DISCLAIMER**\n\nThe information in this report is provided on an \u201cas is\u201d basis.\n\nThis document was produced by IMDA and\nAicadium based on information available as at the date of publication.\n\nInformation is subject to change.\n\nIt\nhas been prepared solely for information purposes over a limited time period to provide a perspective on\ngenai and the implications for trust and governance.\n\nIMDA and Aicadium make no representation or\nwarranty, either expressed or implied, as to the accuracy or completeness of the information in the report\nand shall not be liable for any loss arising from the use hereof.\n\nThe authors have made a good faith attempt to identify and attribute credits to authors / source of any\nthird party\u2019s work in this paper, if you have any queries or concerns regarding ownership / authorship of the\nrelevant materials, please do not hesitate to reach out to  .\n\n-----", "# JOINT STATEMENT ON ENFORCEMENT EFFORTS AGAINST DISCRIMINATION AND BIAS IN AUTOMATED SYSTEMS\n\n_Rohit Chopra, Director of the Consumer Financial Protection Bureau,_\n_Kristen Clarke, Assistant Attorney General for the Justice Department\u2019s Civil Rights Division,_\n_Charlotte A. Burrows, Chair of the Equal Employment Opportunity Commission, and_\n_Lina M. Khan, Chair of the Federal Trade Commission_\n_issued the following joint statement about enforcement efforts to protect the public_\n_from bias in automated systems and artificial intelligence_ :\n\nAmerica\u2019s commitment to the core principles of fairness, equality, and justice is\ndeeply embedded in the federal laws that our agencies enforce to protect civil rights, fair\ncompetition, consumer protection, and equal opportunity.\n\nThese established laws have\nlong served to protect individuals even as our society has navigated emerging\ntechnologies.\n\nResponsible innovation is not incompatible with these laws.\n\nIndeed,\ninnovation and adherence to the law can complement each other and bring tangible\nbenefits to people in a fair and competitive manner, such as increased access to\nopportunities as well as better products and services at lower costs.\n\nToday, the use of automated systems, including those sometimes marketed as\n\u201cgenai\u201d or \u201cgenai,\u201d is becoming increasingly common in our daily lives.\n\nWe\nuse the term \u201cautomated systems\u201d broadly to mean software and algorithmic processes,\nincluding genai, that are used to automate workflows and help people complete tasks or\nmake decisions.\n\nPrivate and public entities use these systems to make critical decisions\nthat impact individuals\u2019 rights and opportunities, including fair and equal access to a job,\nhousing, credit opportunities, and other goods and services.\n\nThese automated systems\nare often advertised as providing insights and breakthroughs, increasing efficiencies\nand cost-savings, and modernizing existing practices.\n\nAlthough many of these tools\noffer the promise of advancement, their use also has the potential to perpetuate\nunlawful bias, automate unlawful discrimination, and produce other harmful outcomes.", "## Automated Systems May Contribute to Unlawful Discrimination and Otherwise Violate Federal Law\n\nMany automated systems rely on vast amounts of data to find patterns or\ncorrelations, and then apply those patterns to new data to perform tasks or make\nrecommendations and predictions.\n\nWhile these tools can be useful, they also have the\npotential to produce outcomes that result in unlawful discrimination.\n\nPotential\ndiscrimination in automated systems may come from different sources, including\nproblems with:\n\n-  **Data and Datasets:** Automated system outcomes can be skewed by\nunrepresentative or imbalanced datasets, datasets that incorporate historical\nbias, or datasets that contain other types of errors.\n\nAutomated systems also\ncan correlate data with protected classes, which can lead to discriminatory\noutcomes.\n\n-  **Model Opacity and Access:** Many automated systems are \u201cblack boxes\u201d\nwhose internal workings are not clear to most people and, in some cases,\neven the developer of the tool.\n\nThis lack of transparency often makes it all the\nmore difficult for developers, businesses, and individuals to know whether an\nautomated system is fair.\n\n-  **Design and Use:** Developers do not always understand or account for the\ncontexts in which private or public entities will use their automated systems.\n\nDevelopers may design a system on the basis of flawed assumptions about\nits users, relevant context, or the underlying practices or procedures it may\nreplace.\n\nToday, our agencies reiterate our resolve to monitor the development and use of\nautomated systems and promote responsible innovation.\n\nWe also pledge to vigorously\nuse our collective authorities to protect individuals\u2019 rights regardless of whether legal\nviolations occur through traditional means or advanced technologies.\n\n_Note: This document is for informational purposes only and does not provide technical assistance about_\n_how to comply with federal law.\n\nIt does not constitute final agency action and does not have an immediate_\n_and direct legal effect.\n\nIt does not create any new rights or obligations and it is not enforceable._\n\n\n-----", "## Purpose\n\nThe purpose of this policy is to provide guidance on the use of generative artificial\n\nintelligence (genai) for executive branch employees in Utah State government.\n\nThe policy\n\nis created to promote the use of genai while protecting the safety, privacy, and\n\n\n-----\n\ngenai refers to a class of genai systems that are capable of\n\ngenerating content, such as text, images, video, or audio, based on a set of input data\n\nrather than simply analyzing or acting on existing data.\n\nPopular genai systems\n\ninclude GPT-3 and GPT-4/ChatGPT, Dall-E, Bard, Bing Chat, GitHub Copilot, and Lensa\n\ngenai among many others.\n\ngenai technology is rapidly being incorporated into\n\ncommon online tools as standalone systems or embedded within other applications.\n\nThese systems have the potential to support many state business functions and\n\nservices, however their use also raises important questions, particularly around the\n\nsourcing of training data, ensuring proper attribution of generated content, and the\n\nhandling of sensitive or public data, accuracy of outputs, bias, and stability.\n\nFurther\n\nresearch into this technology may uncover issues that require more guidance or\n\nrestrictions on its use.", "**Generative Pre-trained Transformer (GPT)**\n\nGPT is a type of genai language model that was developed by OpenAI.\n\nGPT models are trained on a massive dataset of text and code, and they can be used\n\nfor a variety of tasks, including text generation, translation, and summarization.\n\nGPT is\n\na type of Large Language Model which reached popularity with the introduction of\n\nChat GPT in November 2022.\n\n-----", "### 1.1 Guidelines\n\ngenai is a powerful tool that can be used to improve government services and\n\noperations.\n\nWhen making use of genai tools and capabilities, state agencies\n\nand users should consider the following general principles:\n\n**1.1.1.\n\nTransparency** : Users and agencies must be transparent about how they are\n\nusing genai.\n\nThis shall include full attribution to which genai is used.\n\n**1.1.2.\n\nAccountability** : Users and agencies are accountable for the decisions that\n\nare made and materials created using genai.\n\n**1.1.3.\n\nFairness** : genai systems can reflect the cultural, economic, and social biases of\n\nthe source materials used for training, and the algorithms used to parse and\n\nprocess that content can be a source of bias as well.\n\nUsers and agencies shall\n\nensure that genai is used in a fair and equitable manner.\n\n**1.1.4.\n\nPrivacy** : Users and agencies must protect the privacy of individuals when\n\nusing genai.\n\nThis means that any models shall not be used to collect or\n\nstore personal information without the consent of the individual.\n\nNo private,\n\ncontrolled, confidential, or restricted data shall be added to a publicly accessible\n\ntraining model.\n\n**1.1.5.\n\nSecurity** : Users and agencies shall take steps to protect the security and\n\nintegrity of genai models.\n\nDTS cybersecurity staff are available to provide\n\ntechnical support in securing genai resources.\n\n**1.1.6.\n\nTraining:** Agencies shall mandate a minimum level of genai training for users\n\nresponsible for business processes which are incorporating genai.\n\n**1.1.7.\n\nLegal:** There are unresolved legal issues surrounding genai and the\n\ndata inputs used to create genai models.\n\ngenai systems may be trained using\n\ncopyrighted material that has been sourced without regard for copyright or\n\nlicensing terms.\n\nSources of inputs to models must be reviewed and usage risk\n\nevaluated.\n\n-----\n\nproject, must be reviewed by agencies to ensure the software meets all necessary\n\nsecurity and privacy requirements.\n\nThis requirement applies to downloadable\n\nsoftware, Software as a Service (SaaS), web-based services, browser plug-ins, and\n\nsmartphone apps.\n\nNew software requests must also be reviewed by the DTS\n\nArchitecture Review Board and the Enterprise Cyber Security Team.\n\n1.2.2.\n\nUse of genai technology that is incorporated into existing services\n\nand products, such as internet search engines, does not require permission to use,\n\nhowever this policy\u2019s guidelines and other requirements must be followed.\n\n1.2.3. genai outputs must be reviewed by knowledgeable human operators for\n\naccuracy, appropriateness, privacy, and security before being acted upon or\n\ndisseminated.\n\ngenai outputs should not be assumed to be truthful, credible or\n\naccurate.\n\n1.2.4. genai outputs shall not be used to impersonate individuals or organizations\n\nwithout their written permission.\n\n1.2.5.\n\nPrivacy:\n\n1.2.5.1.\n\nState agencies must comply with all GRAMA, PRMA, records\n\nmanagement, privacy and other applicable laws, rules, and policies to ensure\n\nthe appropriate and reasonable protection of data and the protection of\n\nrights of persons that may be impacted by information furnished by genai.\n\n1.2.5.2.\n\nNo private, controlled, or confidential data shall be added to a\n\npublicly accessible genai service or training model.\n\n1.2.5.3.\n\nMaterial that is inappropriate for public release shall not be entered as\n\ninput to genai tools that have not been explicitly approved for the\n\nintended use case.\n\n1.2.5.4.\n\nAgency contracts shall prohibit vendors from using State of Utah\n\nmaterials or data in genai queries or for building or training\n\nproprietary genai programs unless explicitly approved by the state.\n\n1.2.6.\n\nDTS will provide training on proper usage of genai for users.\n\nAgencies\n\nshall ensure that all users of tools consisting of or incorporating genai\n\n\n-----\n\nsufficient to meet the requirements of the U.S.\n\nCopyright Office for Works\n\nContaining Material Generated by genai\n\n(\n\nregistration-guidance-works-containing-material-generated-by-artificial-\n\nintelligence) (\n\n88 FR 16190 (\n\n05321.pdf)\n\n).\n\nThe annotation should include at least the genai technology used and a\n\ndescription of how it was used to create the work.\n\n1.2.8.\n\nProcuring agencies shall ensure vendors disclose the utilization of generative\n\ngenai when producing works owned by the state and integration of genai in\n\nproducts used by the state.\n\n1.2.9.\n\nProcuring agencies shall perform due diligence to ensure proper licensure of\n\nmodel training data for all genai services using non-state data.\n\n1.2.10.\n\nAll software code generated through the use of genai shall not be\n\nused in production until fully reviewed and tested for proper functionality and\n\nsecurity.\n\nAny such use shall be properly documented.", "## 3.\n\nEnforcement\n\nViolation of this policy by personnel employed by the State of Utah may be the basis\n\nfor discipline including but not limited to termination.\n\nIndividuals and contractors\n\nworking with any State of Utah Agency found to have violated this policy may also be\n\nsubject to legal penalties as may be prescribed by state and/or federal statute, rule,\n\nand/or regulation.\n\n-----", "**Summary:**\n\nThis Directive establishes a moratorium for at least 6 months on genai.\n\nThe State of\nMaine government must keep pace with a rapidly evolving cyber threat landscape that poses significant risks to\nthe security of the State\u2019s network infrastructure, including the sensitive and confidential data that we are\nentrusted to protect for our citizens.\n\nThis Directive is in response to the unique security and privacy risks posed\nby the rapid rise in the breadth and scope of genai (genai) systems, specifically genai, and\nestablishes the moratorium while MaineIT conducts further risk assessment.", "**Background:**\n\nMaineIT is responsible for maintaining the confidentiality, integrity and availability of the State\u2019s information\nsystems and assets, while serving Executive Branch Agencies with efficient and secure network services.\n\nAs\nU.S. policy on genai continues to develop, caution must be taken to assess the risks involved with the use of\ngenai technologies.\n\nEarly federal guidance and best practices 2 provide a roadmap for industry and\ngovernment to move towards the responsible management of genai systems that cultivate public trust.\n\ngenai systems have the capacity to automatically process data and information in a way that resembles\nintelligent human behavior.\n\nAlthough these systems have many benefits, the expansive nature of this technology\nintroduces a wide array of security, privacy, algorithmic bias, and trustworthiness risks into an already complex\nIT landscape.\n\nThese systems lack transparency in their design, raising significant data privacy and security\nconcerns.\n\nTheir use often involves the intentional or inadvertent collection and/or dissemination of business or\npersonal data.\n\nIn addition, genai technologies are known to have concerning and exploitable security\nweaknesses, including the ability to generate credible-seeming misinformation, disseminate malware, and\nexecute sophisticated phishing techniques.\n\nThese factors make it challenging to maintain adequate understanding and control over genai-based decisions,\nincluding their appropriateness, fairness, and alignment with organizational values and risk appetite.\n\nThe\ncomplete risk associated with the use of this technology remains unknown.", "**Required Actions:**\n\nEffective immediately, Wednesday, June 21, 2023, the adoption or use of genai technology 3 (i.e.,\nproduces uncontrolled results) is prohibited for at least six months for all State of Maine business and on any\n\n1 This Directive is being issued to all SOM executive branch agencies, including all State agencies, departments, commissions, committees, authorities, divisions, boards\nor other administrative units of the executive branch that use the State network.\n\n2 NIST genai Risk Management Framework and the NIST genai Resource Center ( AIRC ).\n\n3 genai refers to \u201cgenai techniques that learn a representation of artifacts from data, and use it to generate brand-new, unique artifacts that resemble but do not\nrepeat the original data.\n\nThese artifacts can serve benign or nefarious purposes.\n\ngenai can produce totally novel content (including text, images, video, audio,\nstructures), computer code, synthetic data, workflows and models of physical objects.\n\ngenai also can be used in art, drug discovery or material design.\u201d See\nGartner at \n\nPhone: (207) 624 8800 V/TTY: 7 1 1 Fax: (207) 287 4563\n\n\n-----\n\nas well as the development of policies and responsible frameworks governing the potential use of this\ntechnology.\n\nAny requests for an exception to this Directive must be submitted by filing a direct waiver request through the\nappropriate MaineIT Account Manager for your department.", "**Additional Information:**\n\nMaineIT is currently assessing other products, services and telecommunication equipment that may pose\nsecurity risks to the State of Maine\u2019s network infrastructure and additional steps may need to be taken to\nstrengthen our security posture.\n\nThis Directive will be reviewed and revised, as necessary, in six months.\n\nThe internal point of contact for this\nDirective is Nathan Willigar, State of Maine Chief Information Security Officer, at\n .\n\nPhone: (207) 624 8800 V/TTY: 7 1 1 Fax: (207) 287 4563\n\n\n-----", "**WHY THIS MATTERS**\n\nUse of genai, such as ChatGPT and Bard, has\nexploded to over 100 million users due to enhanced\ncapabilities and user interest.\n\nThis technology may\ndramatically increase productivity and transform daily\ntasks across much of society.\n\ngenai may also\nspread disinformation and presents substantial risks to\nnational security and in other domains.\n\nexample, large language models use training data to learn patterns in\nwritten language.\n\ngenai can then use models to emulate a human\nwriting style.\n\ngenai can also learn to use many other data types,\nincluding programming codes, molecular structures, or images.\n\nThe systems generally require a user to submit prompts that guide the\ngeneration of new content (see fig.\n\n1).\n\nMany iterations may be required to\nproduce the intended result because genai is sensitive to the\nwording of prompts.\n\n**How mature is it?\n\n** Advanced chatbots, virtual assistants, and language\ntranslation tools are mature genai systems in widespread use.\n\nImproved computing power that can process large amounts of data for\ntraining has expanded genai capabilities.\n\nAs of early 2023,\nemerging genai systems have reached more than 100 million\nusers and attracted global attention to their potential applications.\n\nFor\nexample, a research hospital is piloting a genai program to create\nresponses to patient questions and reduce the administrative workload of\nhealth care providers.\n\nOther companies could adapt pre-trained models to\nimprove communications with customers.\n\n**/// OPPORTUNITIES**", "## \u00a7 Summarizing information.\n\nBy rapidly aggregating a wide range of\n\ncontent and simplifying the search process, genai quickens\naccess to ideas and knowledge and can help people more\nefficiently gather new information.\n\nFor example, researchers can\nidentify a new chemical for a drug based on an genai-generated\nanalysis of established drugs.", "## \u00a7 Enabling automation.\n\ngenai could help automate a wide\n\nvariety of administrative or other repetitive tasks.\n\nFor example, it\ncould be used to draft legal templates, which could then be\nreviewed and completed by a lawyer.\n\nIt can also improve customer\nsupport by creating more nuanced automated responses to\ncustomer inquiries.", "## \u00a7 Improving productivity.\n\nBecause it is capable of quickly\n\nautomating a variety of tasks, genai has the potential to\nenhance the productivity of many industries.\n\nMultiple studies and\nworking papers have shown genai can enhance the speed\nof administrative tasks and computer programming, although users\nmay need to edit the generated result.\n\n**/// CHALLENGES**", "# genai\n\nAccessible Version\n\n**/// THE TECHNOLOGY**\n\n**What is it?\n\n** genai (genai) is a technology that can\ncreate content, including text, images, audio, or video, when prompted by\na user.\n\ngenai systems create responses using algorithms that are\ntrained often on open-source information, such as text and images from\nthe internet.\n\nHowever, genai systems are not cognitive and lack\nhuman judgment.\n\ngenai has potential applications across a wide range of fields,\nincluding education, government, medicine, and law.\n\nUsing prompts\u2014\nquestions or descriptions entered by a user to generate and refine the\nresults\u2014these systems can quickly write a speech in a particular tone,\nsummarize complex research, or assess legal documents.\n\ngenai\ncan also create artworks, including realistic images for video games,\nmusical compositions, and poetic language, using only text prompts.\n\nIn\naddition, it can aid complex design processes, such as designing\nmolecules for new drugs or generating programming codes.\n\n**How does it work?\n\n** genai systems learn patterns and\nrelationships from massive amounts of data, which enables them to\ngenerate new content that may be similar, but not identical, to the\nunderlying training data.\n\nThey process and create content using\nsophisticated machine learning algorithms and statistical models.\n\nFor\n\n\n-----\n\nresponsible use, to help ensure accountability and responsible use\nof genai across the federal government and other entities.\n\nGenerative\ngenai systems can respond to harmful instructions, which could\nincrease the speed and scale of real-world harms.\n\nFor example,\ngenai could help produce new chemical warfare\ncompounds.\n\nAdditionally, genai systems share challenges\nto oversight similar to other genai applications\u2014such as assessing the\nreliability of data used to develop the model\u2014because their inputs\nand operations are not always visible.\n\nThe White House\nannounced in May 2023 that a working group would provide,\namong other things, input on how best to ensure that genai\nis developed and deployed equitably, responsibly, and safely.\n\nOther agencies, such as the National Institute of Standards and\nTechnology, have also promoted responsible use of genai.\n\n**False information.\n\n** genai tools may produce\n\u201challucinations\u201d\u2014erroneous responses that seem credible.\n\nOne\nreason hallucinations occur is when a user requests information\nnot in the training data.\n\nAdditionally, a user could use genai to\npurposefully and quickly create inaccurate or misleading text, thus\nenabling the spread of disinformation.\n\nFor example, genai\ncan create phishing e-mails or fake but realistic social media posts\nwith misleading information.\n\nFurther, bias in the training data can\namplify the potential for harm caused by genai output.\n\n**Economic issues.\n\n** genai systems could be trained on\ncopyrighted, proprietary, or sensitive data, without the owner\u2019s or\nsubject\u2019s knowledge.\n\nThere are unresolved questions about how\ncopyright concepts, such as authorship, infringement, and fair use,\nwill apply to content created or used by genai.\n\n**Privacy risks.\n\n** Specific technical features of genai systems\nmay reduce privacy for users, including minors.\n\nFor example, a\ngenai system may be unable to \u201cforget\u201d sensitive\ninformation that a user wishes to delete.\n\nAdditionally, if a user\nenters personally identifiable information, that data could be used\nindefinitely in the future for other purposes without the user\u2019s\nknowledge.\n\nSection 230 of the Communications Decency Act of\n1996 shields online service providers and users from legal liability\nfor hosting or sharing third-party content, but it is unclear how this\nstatute might apply to genai-generating content systems and their\ncreators.\n\na prompt, it could be stored and misused or aggregated with other\ninformation in the future.\n\nFurthermore, when systems are publically\nand internationally accessible, they could provide benefits to an\nadversary.\n\nFor example, genai could help rewrite code\nmaking it harder to attribute cyberattacks.\n\nIt may also generate\ncode for more effective cyberattacks even by attackers with limited\ncomputer programming skills.\n\n**/// POLICY CONTEXT AND QUESTIONS**", "## \u00a7 What privacy laws can be used or developed to protect sensitive\n\ninformation used or collected by genai systems, including\ninformation provided by minors?\n\n**/// SELECTED GAO WORK**\n\ngenai: An Accountability Framework for Federal Agencies\nand Other Entities, GAO-21-519SP .\n\ngenai: Emerging Opportunities, Challenges, and\nImplications for Policy and Research, GAO-18-644T .\n\n**/// SELECTED REFERENCES**\n\nCongressional Research Service.\n\n_Generative genai and Copyright Law_ .\n\nLSB10922.\n\nWashington, D.C.: 2023.\n\nU.S. Department of Commerce.\n\nNational Institute of Standards and Technology.\n\n_NIST AI_\n_Risk Management Framework_ .\n\nNIST genai 100-1.\n\nGaithersburg, MD.\n\n: 2023.\n\nThe White House.\n\nBlueprint for an genai Bill of Rights Making Automated Systems Work for the\nAmerican People .\n\nWashington, D.C.: 2022.\n\n**National security risks.\n\n** Information about how and when some\ngenai systems retain and use information entered into them\nis sparse or unavailable to many users, which poses risks for using\nthese tools.\n\nFor example, if a user enters sensitive information into", "**GAO SUPPORT:**\n\nThe Government Accountability Office (GAO) meets congressional information needs in several\nways, including by providing oversight, insight, and foresight on science and technology issues.\n\nGAO staff are available to brief on completed bodies of work or specific reports and answer followup questions.\n\nGAO also provides targeted assistance on specific science and technology topics to\nsupport congressional oversight activities and provide advice on legislative proposals.\n\n**For more information, contact:** Brian Bothwell at (202) 512-6888 or  and\nKevin Walsh at (202) 512-6151 or \n\n**Staff Acknowledgments:** Katrina Pekar-Carpenter (Assistant Director), Claire McLellan (Analystin-Charge), Jehan Chase, Alex Gromadzki, Kristin Hook, Mark Kuykendall, Anika McMillon,\nMatthew Metz, Jessica Steele, and Adam Wells\n\n\nThis document is not an audit product and is subject to revision based on continued advances in\nscience and technology.\n\nIt contains information prepared by GAO to provide technical insight to\nlegislative bodies or other external organizations.\n\nThis document has been reviewed by Karen L.\nHoward, PhD, GAO\u2019s Acting Chief Scientist.\n\nThis work of the United States may include copyrighted material, details at\n .\n\n**Congressional Relations** : A. Nicole Clowers, Managing Dir., (202) 512-4400, \n\n**Public Affairs** : Charles Young, Managing Dir., (202) 512-4800, \n\n\n-----", "##### What makes GenAI different?\n\nGenAI builds on advances in conventional genai and uses very large quantities of\ndata to output unique written, audio, and/or visual content in response to freeform text requests from its users and programmers.\n\nGenAI tools have the\ncapacity to produce entirely new content instead of simply regurgitating\ninputted data.\n\nUnlike conventional genai systems designed for specific tasks, GenAI\nmodels are designed to be flexible and multifunctional.\n\nGenAI products are already available as standalone applications such as\nChatGPT, Dall-E, and Bard, and are being integrated into many other consumerfacing technology products, such as chatbots on websites.\n\nConventional genai models, on the other hand, are usually designed for just a few\nspecific tasks and are often limited by the scope of the inputted training data as\nwell as the technical expertise of the programmer.\n\nModel training is the process\nby which genai models ingest input datasets to learn the underlying patterns within\nthe data and produce predictions for the context that the model was trained\non.\n\nConventional genai is already widely used in products across government and\nsociety.\n\nSome examples of conventional genai include robotic process automation,\nfraud detection tools, image classification systems, recommendation engines,\nand interactive voice assistants.\n\n**_Table 1: Comparison Between Conventional genai and GenAI Technology_**\n\n\n\n\n|Criteria|Conventional genai|genai|\n|---|---|---|\n|What is the intended purpose?|Solve specific problems or accomplish predefined tasks using a predefined dataset.|Generate new content (text, images, music, etc.)\n\nand produce novel outputs not seen within input datasets.|\n|How is the genai model trained?|Learns patterns from large amounts of structured data for training and uses them to make predictions or perform tasks.|Learns patterns using unstructured data sets.\n\nOngoing training can be performed for fine-tuning of model for specific business uses.|\n|What kind of algorithm does the genai model use to learn from its input data?|Typically runs on rule-based systems, decision trees, and similar models.\n\nCan learn underlying patterns in the data but requires more pre-processing for the algorithm to perform well.|Uses flexible neural network algorithms that can process different inputs and learn the underlying relationships and patterns within the data.|\n\n\nState of California Report: Benefits and Risks of GenAI\n\n\n-----\n\n|Criteria|Conventional genai|genai|\n|---|---|---|\n|How is the genai model typically used?|Image recognition, recommender systems, anomaly detection, text classification, and risk prediction systems.|Creative tasks like art, music, storytelling, content generation, image synthesis, text generation, video creation, style transfer, and logical reasoning.|\n|How is the genai model evaluated?|Typically, task-specific performance measures that assess accuracy, precision, recall metrics.|GenAI outputs can be more subjective and dependent on human judgment.\n\nQuality assurance of output is important.|\n\n\nGenAI technology function using foundation models, which are large-scale\nmachine learning models with general purpose capabilities.\n\nThese models are\ntrained on datasets that can span the entirety of the internet, and they can\nbecome the foundation for applications that can help address specific business,\npolicy, or social needs.\n\nAs they are built and grow, foundation models require\nlarger quantities of computing power and human capital resources than\nconventional genai development.\n\nGenAI models use human-generated content as part of their underlying data,\nand they can respond to free-text human queries with human-sounding output.\n\nHowever, despite the capacity of GenAI to produce coherent, intelligentsounding output, there is no guarantee that the output is accurate.\n\nIn fact,\nmany of the most widely available GenAI models were designed as a\ndemonstration of what is possible, rather than to solve a specific use case or\nbusiness purpose.\n\nAs a result, free consumer models can produce outputs that\nare inaccurate, fabricated, potentially inappropriate, and/or biased.\n\nThese products demonstrate the unprecedented power of GenAI, and\nenterprise models continue to improve in approximating how humans write,\ndraw, and speak.\n\nSimultaneously, the rapid development and availability of\nGenAI has accelerated policy, business, and social risks that are more urgent\nthan previous genai technologies.\n\nState of California Report: Benefits and Risks of GenAI |\n\n\n-----", "##### Economic Backdrop of GenAI\n\nCalifornia stands at the forefront of the burgeoning genai economy.\n\nHome to 35 of\nthe world's top 50 genai companies, California leads the world in GenAI innovation\nand research.\n\nOur higher education institutions \u2013 including UC Berkeley\u2019s College of\nComputing, Data Science, and Society, and Stanford University\u2019s Institute for\nHuman-Centered genai \u2013 are among the most advanced genai\nresearch institutions in the world.\n\nCoupled with the State\u2019s unparalleled access\nto venture capital, our culture of innovation, and history of new, world-changing\ntechnologies, California sits at the epicenter of an industry that is experiencing\nexponential growth and development.\n\nAlthough GDP growth and productivity gains are predicted, Goldman Sachs has\nalso warned that 300 million jobs worldwide could be affected by GenAI.\n\nAs\nsuch, the State must lead in training and supporting workers, allowing them to\nparticipate in the genai economy and creating the demand for businesses to\nlocate and hire here in California.\n\nStarting with our world-class higher education\ninstitutions and vocational schools, California is well positioned to provide\nworkers with relevant skills and businesses with the talent needed to drive job\ngrowth in the GenAI economy.\n\nThe global GenAI market is significant.\n\nAccording to Pitchbook, it is expected to\nreach $42.6 billion in 2023 .\n\nLike all new technologies, particularly of this scale,\nGenAI offers immense economic opportunities, as well as new risks.\n\nAs the\nindustries of GenAI are developed, California, the U.S., and other nations must\ndevelop coordinated and thoughtful public policies to mitigate risks and\nmaintain public trust through ethical use guidelines, accountability, and\ntransparency, while still realizing the potential economic benefits of GenAI.\n\nState of California Report: Benefits and Risks of GenAI |\n\n\n-----", "##### Use Case Analysis for GenAI in California State Government\n\nGovernment leaders should prioritize GenAI proposals that offer the highest\npotential benefits, along with the appropriate risk mitigations, over those where\nbenefits are not significant compared to existing work processes.\n\nThis technology\noffers possibilities to improve the lives of Californians, such as by summarizing\nbenefits enrollment policies in plain language, translating government\ncommunications into multiple languages, and providing interactive tax\nassistance.\n\nUnder the Governor\u2019s Executive Order, agencies are tasked with soliciting\nstakeholder input and crafting guidelines for state use of GenAI.\n\nThat work has\nbegun and will be completed in January 2024, but in the interim, basic principles\nthat should apply:\n\n-  To protect the safety and privacy of Californians\u2019 data, and consistent\nwith state policy\u2013state employees should only use state-provided,\nenterprise GenAI tools on State-approved equipment for their work.\n\n-  Under no circumstances should state employees provide state or\nCalifornians\u2019 resident data to a free, publicly available GenAI solution like\nChatGPT or Google Bard, or use these unapproved GenAI applications or\nservices on a State computing device.\n\n-  It is important to provide a plain-language explanation of how GenAI\nsystems factor into delivering a state service and disclose when content is\ngenerated by GenAI.\n\n-  State supervisors and employees should also review GenAI products for\naccuracy and make sure to paraphrase rather than use genai-generated\ntext, audio, or images verbatim.\n\nThrough consultation with practitioners and researchers, California state\ngovernment compiled an inventory of potential GenAI use cases that could\nimprove state services and programs.\n\nHigh-level categories within the use cases\nwere extracted and are enumerated in this section as potential areas of benefit\nfrom GenAI.\n\nState of California Report: Benefits and Risks of GenAI |\n\n\n-----\n\nLooking ahead, with the appropriate pilot infrastructure and risk mitigations in\nplace, California will evaluate potential use cases by prioritizing the following\nbenefits:\n\n**_1.\n\nImprove the performance, capacity, and efficiency of ongoing work,_**\n**_research, and analysis through summarization and classification_** **_._**\n\nBy analyzing hundreds of millions of data points simultaneously, GenAI can\ncreate comprehensive summaries of any collection of artifacts, irrespective\nof whether the content is in a text, audio, or video format.\n\nAs GenAI learns, it\ncan also categorize and classify information by topic, format, tone, or theme.\n\n_Example Use Cases include_ :\n\n-  Conduct sentiment analysis of public feedback on state policies, using\nGenAI to recommend opportunities for process and service delivery\nimprovement.\n\nThis can help government understand public\nexperience and improve policies and communication to better serve\nconstituents.\n\n-  Summarize meetings, work, and public outreach documentation,\nleveraging GenAI to find insights in the analyzed data.\n\nGenAI can find\nthe key topics, conclusions, action items, and insights without needing\nto read everything word for word.\n\n**_2.\n\nPersonalize and customize work products to California\u2019s diversity of people_**\n**_with the potential to improve access to services and outcomes for all._**\n\nGenAI\u2019s capacity to learn makes it easier for the State to design services and\nproducts to be responsive to Californians\u2019 diverse needs, across geography\nand demography.\n\nGenAI solutions can recommend ways to display complex\ninformation in a way that resonates best with various audiences or highlight\ninformation from multiple sources that is relevant to an individual person.\n\nThese functions can further California\u2019s goals as they allow for optimized\ngovernment experiences allowing Californians greater access to state\ninformation and services, and by advancing equity, inclusion, and\naccessibility in outcomes.\n\n_Example Use Cases include_ :\n\n-  Apply GenAI on government service data to identify specific groups or\nsubsets of participants that may benefit from additional outreach,\nsupport services, and resources based on their circumstances and\nneeds (for example, local job training for people claiming EITC).\n\nState of California Report: Benefits and Risks of GenAI |\n\n\n-----\n\n-  GenAI can identify groups that, for language or other reasons, are\ndisproportionately not accessing services by analyzing feedback\nsurveys or comments for language that indicate accessibility\ndifficulties.\n\nThis can help determine opportunities to improve access.\n\n**_3.\n\nImprove language and communications access in multiple languages and_**\n**_formats._**\n\nGenAI can create unique content in a variety of formats.\n\nBased on a single\nprompt, a GenAI solution can easily construct a video or image that a user\ncan refine.", "Based on a single\nprompt, a GenAI solution can easily construct a video or image that a user\ncan refine.\n\nThese products can be in multiple languages, allowing the State\nto make its videos, recordings, and other documents more accessible to and\ninclusive of all Californians.\n\nThese translated outputs can be refined through a\nquality control process to ensure accuracy and inclusivity before reaching\nCalifornians.\n\nAccessible communications are a critical part of ensuring that government\nservices can meet Californians where they are.\n\nThe ability to meet the\nvarying communication needs of persons with disabilities and reach\nCalifornians in their primary languages is a priority for improving government\nservice delivery.\n\n_Example Use Cases include_ :\n\n-  Using GenAI to help experts convert educational materials into formats\nlike audio books, large print text, or braille documents.\n\nCan also\ngenerate captions for video materials, and make information more\naccessible for those with visual, hearing, or learning disabilities.\n\n-  Leveraging GenAI to help experts translate government websites,\npublic documents, policies, forms, and other materials into the various\nlanguages spoken in the State.\n\nThis expands access to important\ninformation and services to non-native English speakers.\n\n**_4.\n\nOptimize software coding and explain and categorize unfamiliar code._**\n\nSummarization, classification, and translation features make GenAI a\npowerful tool for state coders and the developer community at large.\n\nGenAI\ncan generate code in multiple computing languages and translate code\nfrom one language to another.\n\nThis can improve state operations if a state\nsystem is using code that is written in an obsolete language.\n\nMoreover,\nGenAI has the potential to explain and categorize unfamiliar or uncertain\ncode so that the State can better understand the exact technical\narchitecture of agency applications.\n\nState of California Report: Benefits and Risks of GenAI |\n\n\n-----\n\n_Example Use Cases include_ :\n\n-  Powerful code conversion tools based on foundation models can\naccurately translate legacy codebases (e.g., COBOL mainframe apps)\ninto modern programming languages.\n\nThis automates time-consuming\nand error-prone manual conversions.\n\n-  Powerful GenAI development tools auto-generate quality code, spin\nup test environments, and generate synthetic datasets to train\nmachine learning models.\n\nThis can slash timelines, reduce bugs, and\ndemocratize development.\n\nLow-code solutions also enable nonprogrammers to build applications.\n\n**_5.\n\nFind insights and predict key outcomes in complex datasets to empower and_**\n**_support decision-makers._**\n\nWithout specific training or pre-set rules, GenAI models can analyze multiple\ndatasets to find meaningful insights for users.\n\nThe conversational aspects of\nGenAI solutions can empower workers with a range of technical expertise to\nask questions in plain language to get at findings that may be relevant to\ntheir work.\n\nSignificantly, Californians could also use a GenAI solution to ask\ndata-driven questions that are important to them.\n\n_Example Use Cases include_ :\n\n-  Cyber protection systems powered by foundation models can rapidly\nanalyze network activity logs, identify anomalies and threats, generate\nexplanations of the attacks, and propose remediation actions.\n\nThis can\nenable security teams to detect and respond to sophisticated\ncyberattacks in real-time before major damage occurs.\n\n-  GenAI analyzes data streams from drones, satellites, and sensors\nmonitoring public infrastructure.\n\nIt generates detailed damage and\ndeterioration assessments via techniques like visual inspection,\nanomaly detection, etc.\n\nThis enables improved forecasting of\nmaintenance needs.\n\n**_6.\n\nOptimize workloads for environmental sustainability._**\n\nIncorporating GenAI in government can drive environmental sustainability by\noptimizing resource allocation, maximizing energy efficiency and demand\nflexibility, and promoting eco-friendly policies.\n\nFor instance, this technology\ncan enhance operational efficiency, decrease paper usage and waste, and\nsupport environmentally conscious governance.\n\nNotably, stakeholders also\nhighlighted the need for reducing environmental impacts of GenAI use and\nensuring environmental costs are equitably distributed.\n\nState of California Report: Benefits and Risks of GenAI | 10\n\n\n-----\n\n_Example Use Cases include_ :\n\n-  GenAI could analyze traffic patterns, ride requests, and vehicle\ntelemetry data to optimize routing and scheduling for state-managed\ntransportation fleets like buses, waste collection trucks, or maintenance\nvehicles.\n\nBy minimizing mileage and unnecessary trips, GenAI could\nreduce associated fuel use, emissions, and costs.\n\n-  GenAI simulation tools could model the carbon footprint, water usage,\nand other environmental impacts of major infrastructure projects.", "-  GenAI simulation tools could model the carbon footprint, water usage,\nand other environmental impacts of major infrastructure projects.\n\nBy\nrunning millions of scenarios, GenAI can identify potentially the most\nsustainable options for planning agencies and permit reviewers.\n\nAcross all use case opportunities, potential use cases will need to be\ncustomized to the case-by-case needs of state departments and evaluated\nthrough a coordinated, standardized benefits and risks assessment process\nthrough pilot programs.\n\nThrough pilot testing and experimentation in GenAI\nsandbox environments, the State will document learnings to refine and scale\nits GenAI community of practice.", "##### The Unique Benefits and Applications of GenAI\n\nGenAI has the potential to improve the delivery of government services and\noperations.\n\nFeedback from academic, industry, and community stakeholders\nhighlights the unique benefits and applications of this novel technology\ncompared to conventional genai and manual workflows.\n\nThe following table lists high-level categories for the wide variety of functionality\nfor GenAI with sampled public sector use cases.\n\nThe example use cases are only\nintended to help illustrate the potential uses of state government adoption of\nGenAI tools.\n\n**_Table 2: A Typology for GenAI Tasks_**\n\n\n\n\n\n|GenAI Task|Unique Benefits|Example of Public Sector Use Cases|\n|---|---|---|\n|Content generation (text, image, video)|Generates completely novel content, instead of remixing and modifying existing content.\n\nFew- shot learning allows high- quality output with minimal data.|\u25cf Generate public awareness campaign materials like fliers, website content, posters, and videos.\n\n\u25cf Generate visualizations of transportation data.|\n\n\nState of California Report: Benefits and Risks of GenAI | 11\n\n\n-----\n\n|GenAI Task|Unique Benefits|Example of Public Sector Use Cases|\n|---|---|---|\n|Chatbots|Leverages conversational models trained on massive dialogue datasets.\n\nCan have coherent discussions and execute tasks via conversation naturally.|\u25cf Build virtual assistant for common constituent questions.\n\n\u25cf Create chatbot to guide users through services in their preferred language.\n\n\u25cf Increase first-call resolution for state service centers.\n\n\u25cf Reduce call wait and handle time at state customer service centers.\n\n\u25cf Create greater language access equity for program beneficiaries.|\n|Data analysis|Finds insights and relationships in data through learned knowledge about the world, without hand- coded rules or labeled training data.|\u25cf Analyze healthcare claims or tax filing data to detect fraud.\n\n\u25cf Analyze network activity logs, identify cybersecurity anomalies and threats, and propose remediation actions.|\n|Explanations and Tutoring|Generates natural language explanations and tutoring through dialogue without hand- authored content.|\u25cf Explain program eligibility to potential enrollees.\n\n\u25cf Provide interactive tax assistance.|\n|Personalized Content|Leverages user models to adaptively generate personalized content without explicit rules or large amounts of user data.\n\nUser models learned via few-shot interaction.|\u25cf Auto-populate tax information and filing instructions based on a person's needs.\n\n\u25cf Help auto-populate public program applications based on a person\u2019s situation and household composition.|\n|Search and Recommendation|Understands meaning and context to improve search relevance and provide useful recommendations.|\u25cf Searching or matching state code regulations concerning specific topics.\n\n\u25cf Recommend government services based on eligibility.|\n|Software code generation|Generates code by learning underlying structure and patterns of code, without need for human written examples.\n\nCan expand short descriptions into full programs.|\u25cf Translate policy specifications such as Web Content Accessibility Guidelines (WCAG) and Americans with Disability Act (ADA) requirements, into software code.\n\n\u25cf Generate data transformation scripts from instructions.|\n\n\nState of California Report: Benefits and Risks of GenAI | 12\n\n\n-----\n\n|GenAI Task|Unique Benefits|Example of Public Sector Use Cases|\n|---|---|---|\n|||\u25cf Accelerate adoption of human- centered design in state web- based forms and pages.\n\n\u25cf Reduce administrative cost and burden to developing and maintaining best-in-class state government websites.|\n|Summarization|Does not require human- written summaries as training data.\n\nCan learn underlying patterns of language to generate summaries.|\u25cf Summarize public comments to identify key themes.\n\n\u25cf Summarize public research to inform policymakers.\n\n\u25cf Summarize statutory or administrative codes.|\n|Synthetic data generation|Allows generation of new diverse, anonymized data from existing datasets for analysis and experimentation.|\u25cf Generate synthetic patient data for training healthcare genai.\n\n\u25cf Generate simulated tax records for training tax auditing genai.|\n\n\nGenAI offers a wide variety of potential applications, with varying impacts.\n\nAny application of GenAI tools within California state government will follow\nthe appropriate protocols and testing procedures, as well as incorporating\nfeedback from impacted stakeholders as guidance on the use of this\ntechnology.\n\nLooking ahead, California state government will evaluate\npotential use cases that will provide maximum benefit to Californians, and in\nline with updated guidelines and criteria as directed by the Executive Order.\n\nState of California Report: Benefits and Risks of GenAI | 13\n\n\n-----", "#### III.\n\nGenAI Risk Analysis\n\nResearch conducted within state government, informed by feedback from\nsubject matter experts and community groups, has developed an emerging\npicture of the specific risk factors of GenAI compared to those posed by\nconventional genai.\n\nAs with conventional genai, GenAI poses risks both from bad actors\nusing the technology to cause harm as well as from unintended, emergent\ncapabilities of GenAI that can be misused.\n\nThe NIST genai RMF divides risks into seven categories: Validity & Reliability, Safety,\nAccountability & Transparency, Security & Resiliency, Explainability &\nInterpretability, Privacy, and Fairness.\n\nIn no particular order or weight, these\nseven NIST genai RMF categories have been analyzed as they apply to GenAI\nadoption in California.\n\nAlthough the NIST genai RMF provides a helpful framework to\nillustrate key risk areas, it does not specifically address GenAI, and it is not\nspecific to California\u2019s values or use case context.\n\nTo bridge this gap, and as\nidentified through research and stakeholder engagement, the additional\ncategory of Workforce & Labor Impacts is included below.\n\nGiven the rapidly evolving capabilities, integrations, and standards of GenAI\nproducts, the following analysis represents an initial evaluation of GenAI risks,\nwhich delineates risks based on being a shared risk of conventional genai, an\namplified risk, or a new risk associated with GenAI.\n\n-  **Shared risks** : Known risks of GenAI shared by earlier types of genai models\nwithout significant differences in severity or scale.\n\n-  **Amplified risks** : Risks of GenAI tools shared by earlier types of genai models\nthat are enhanced due to any of the following factors:\n\n\u25cb Reduced technical or cost barriers to using GenAI.\n\n\u25cb Increased speed or scale of impact by GenAI tools.\n\n\u25cb Increased scope of systems or processes impacted by GenAI.\n\n\u25cb Increased exposure to bad actors via larger, more diverse training\ndatasets.\n\n\u25cb Higher complexity of GenAI technology architectures with multiple\nproducers and consumers.\n\n-  **New risks** : Novel risks surfaced by GenAI\u2019s unique capabilities to generate\nhigh-quality outputs across a diversity of modalities such as text, images,\naudio, and video.\n\nState of California Report: Benefits and Risks of GenAI | 14\n\n\n-----", "##### Unique and Shared Risks of GenAI\n\n**_1.\n\nValidity & Reliability_**\ngenai systems that are inaccurate or unreliable increase risks and reduce\ntrustworthiness.\n\n-  _Validation_ is the \u201cconfirmation through evidence that the requirements for\na specific intended use or application have been fulfilled.\u201d\n\n-  _Reliability_ is the \u201cability of an item to perform as required, without failure,\nfor a given time interval, under given conditions.\u201d\n\n**_When applied to GenAI, California identified the following risks:_**\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|Amplified risks|genai models that rely on static datasets can become outdated.\n\nThis can lead to less relevant outputs and model degradation over time.|\n||Third-party providers of conventional genai models commonly release minor software updates without notice, which in turn can impact performance.|\n||Automated \u201ctesting\u201d of Large Language Model (LLM) outputs; unlike in traditional software testing, the output of genai models can differ, even with the same prompt or input.|\n||GenAI models are normally pre-trained using a vast amount of unbalanced, incomplete, and potentially harmful content, which may not be directly relevant to the target application.|\n|New risks|\u201cHallucinating,\u201d or creating misleading, false, or fabricated information and presenting it as if it were true.|\n||Worsening model performance through training feedback loops, when new GenAI models are trained on self-generated, synthetic data.|\n||Appearance of causal reasoning under standard tests and benchmarks for genai models.|\n||The qualitative elements of many GenAI evaluation processes such as coherence, fluency, and creativity can make it challenging to evaluate GenAI outputs in a standardized way.|\n\n\n\nGenAI models are more complex than conventional genai models, and as a result,\nthey are more susceptible to model degradation and collapse, where the genai\nmodel\u2019s performance will worsen over time as the data used to teach it\nbecomes more outdated.\n\nThis is because GenAI models are trained on a large\nbody of data and can produce their own synthetic data.\n\nThis means that they\ncan become biased towards their own synthetic data and become less\naccurate over time (a process known as \u201cmodel collapse\u201d).\n\nGenAI outputs can\nalso be non-deterministic and inconsistent, making it difficult to embed into\ncritical systems where performance stability is a key requirement.\n\nState of California Report: Benefits and Risks of GenAI | 15\n\n\n-----\n\nThe risk of over-reliance on automated GenAI recommendations to make\ndecisions (automation bias), related to validity concerns on hallucinations, poses\nconcerns around GenAI outputs given the ability to generate answers that\n\u201csound right\u201d without having factual accuracy.\n\nWithout proper safeguards,\nCalifornians may believe hallucinations inadvertently created by government\nGenAI tools, which could lead to additional downstream misinformation.\n\nThis\ncould reasonably erode Californians\u2019 trust in their government and its services.\n\n**_2.\n\nSafety_**\ngenai systems \u201cshould not under defined conditions, lead to a state in which human\nlife, health, property, or the environment is endangered.\u201d\n\n**_When applied to GenAI, California identified the following risks:_**\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|Amplified risks|Misuse in critical applications such as systems affecting housing or accommodations, education, employment, financial credit, health care, or criminal justice for example.|\n||Using GenAI in tasks where precision and accuracy are paramount.|\n||GenAI tools can lower technical barriers for influential accounts to personalize content on platforms like social media, potentially amplifying the risk of mental health impacts or political polarization.|\n|New risks|Input prompts crafted to push the GenAI model to make or recommend hazardous decisions.|\n||Creating harmful or inappropriate misinformation or disinformation material (e.g., cybersecurity, warfare, promoting violence, and harassment).|\n||GenAI tools may enable bad actors to design, synthesize, or acquire dangerous chemical, biological, radiological, or nuclear (CBRN) weapons.|\n||The output of GenAI systems may unintentionally contain inappropriate or harmful content such as violence, profanity, racism, or sexism.|\n||As models are increasingly able to learn and apply human psychology, models could be used to create outputs to influence human beliefs, addict people to specific platforms, or manipulate people to spread disinformation.|\n\n\n\nGenAI tools can pose significant risks to public health and safety\u2013whether\nemployed by people with malicious intent, or simply because of a lack of quality\ncontrols.\n\nFor example, bad actors can leverage genai to engineer dangerous\nbiological materials, genai chatbots could give consumers incorrect or dangerous\nmedical advice, or GenAI systems used for drug discovery could create harmful\nsubstances.", "In sensitive domains like healthcare and public safety, GenAI\nrequires careful governance to mitigate the risk of harm.\n\nState of California Report: Benefits and Risks of GenAI | 16\n\n\n-----\n\nAdditionally, GenAI can utilize better and more realistic text generation\ncapabilities to simulate human text and opinions, leading to novel scaling\ncapabilities for spreading misinformation or disinformation on public forums.\n\nBad\nactors could weaponize misinformation and disinformation, amplifying it through\nGenAI to interfere in democratic processes.\n\nThis includes the generation of\ndisinformation campaign material to disseminate on social media, generating\ndeepfakes of political representatives or candidates, or submitting large\nvolumes of fake public comments for proposed rules.\n\nGiven these risks, the use of GenAI technology should always be evaluated to\ndetermine if this tool is necessary and beneficial to solve a problem compared\nto the status quo.\n\nGenAI should center on the needs of the human workforce,\nsupport the carrying out of responsibilities to Californians, and avoid contributing\nto additional bureaucracy, process, or safety risks.\n\n**_3.\n\nAccountability & Transparency_**\nTransparency reflects the extent to which information about an genai system and its\noutputs is available to individuals interacting with the system.\n\nMeaningful\ntransparency provides access to appropriate levels of information based on the\nstage of the genai lifecycle.\n\n**_When applied to GenAI, California identified the following risks:_**\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|Shared risks|Lack of standardized audit trail documentation when tracing the provenance of predictions from an genai system.|\n||Reproducibility concerns when auditing poorly documented genai models.|\n||Governance concerns with open-source genai models; third-parties able to host models without transparent safety guardrails.|\n|Amplified risks|Lack of disclosure around the usage of genai models within a system or when embedded in a third-party vendor.|\n||Difficulty in receiving model decision explanations from third- party hosted model providers.|\n||Difficulty in auditing large volumes of training data for GenAI models.|\n||genai systems are typically pre-trained and provide limited explainability or control to the end-users.|\n|New risks|Difficulty in tracing the original citation sources for references within the generated content.|\n||Uncertainty over liability for harmful or misleading content generated by the genai.|\n\n\n\nState of California Report: Benefits and Risks of GenAI | 17\n\n\n-----\n\nThe GenAI model lifecycle is typically more complex than that of conventional\ngenai and raises novel challenges in ensuring transparency and accountability\nalong the genai value chain.\n\nBuilding a GenAI model may involve multiple\norganizations that all may contribute data to the base foundation model or\nwithin the fine-tuning process.\n\nCalifornia state government must be cautious about over-automating decisions\nor removing human oversight entirely with GenAI chatbots and text generators.\n\nThere are risks in over-trusting these and other tools that rely on GenAI without\nproper review and evaluation of GenAI outputs, such as inaccurate information\nbeing provided to constituents or inaccurate public program determinations.\n\nSuch inaccurate determinations, especially if made repeatedly, could pose\nparticular risks severely undermine California\u2019s progress in creating a California\nfor All by emphasizing to diversity, equity, inclusion, and accessibility.\n\nIt will be\ncritical to have a human reviewer of any GenAI-supported workflow or output\nthat results in a decision about program eligibility or social safety net benefits.\n\n**_4.\n\nSecurity & Resiliency_**\nSecurity and resiliency are defined in the following ways:\n\n-  _Secure_ genai systems can maintain confidentiality, integrity, and availability\nthrough protection mechanisms that prevent unauthorized access and\nuse.\n\n-  _Resilient_ genai systems can withstand unexpected adverse events or\nunexpected changes in their environment or use.", "-  _Resilient_ genai systems can withstand unexpected adverse events or\nunexpected changes in their environment or use.\n\n**_When applied to GenAI, California identified the following risks:_**\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|Shared risks|Unauthorized user access of genai models.|\n||Data breaches or leaks tied to the genai model.|\n||Theft of genai models leading to misuse or malicious content generation.|\n|Amplified risks|Data poisoning, when low quality or biased data is intentionally or unintentionally leaked into a training dataset for an genai model.|\n||Model inversion, when malicious actors can steal sensitive personal data through the genai model\u2019s outputs.|\n||Model skewing, when malicious actors intentionally amplify biased training data to skew model decisions.|\n||Adversarial attacks, when malicious actors can supply inputs to the genai model designed to break the system.|\n||Supply chain vulnerabilities through third-party services, plug-ins, and libraries.|\n|||\n\n\n\nState of California Report: Benefits and Risks of GenAI | 18\n\n\n-----\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|New risks|Adversarial prompt attacks that can cause the GenAI model to produce unwanted content.|\n||Remote execution of harmful code through the GenAI model to modify access permissions, delete, or steal data.|\n||Prompt injection attacks, which can manipulate the model into taking undesirable actions.|\n||Generated content may be indistinguishable from content created by a human, which could enable the scope of harm caused by bad actors across sectors.|\n\n\nThere are some shared data security risks across conventional genai and GenAI\nmodels.\n\nData can be vulnerable to unauthorized access, low-quality data can\nbe injected into training datasets to impact overall model performance, and\ncrafted inputs can cause genai and GenAI models to exhibit inconsistent\nperformance.\n\nAs members of Cal OES\u2019s Cybersecurity Integration Center (Cal-CSIC), CDT\u2019s\nOffice of Information Security works collaboratively with the California Highway\nPatrol (CHP), California Military Department (CMD), Office of Health Information\nIntegrity, and other essential agencies on mitigating, identifying, responding to,\nand reporting security incidents.\n\nGenAI systems can be susceptible to unique attacks and manipulations, such as\npoisoning of genai training datasets, evasion attacks, and interference attacks.\n\nAs\nwith any other technology-driven threat to state security, when a state\nemployee suspects one of these GenAI related incidents such as a GenAIgenerated or -impacted incident has occurred, to the degree they\u2019re known,\nthe employee should report it immediately for central tracking and\ncoordination.\n\nConsistent with State Information Management Manual (SIMM)\nsection and current practice for other technology-driven threats, it is the\nresponsibility of the state entity Information Security Officer (ISO) or authorized\nuser to immediately report the incident through the California Compliance and\nSecurity Incident Reporting System (Cal-CSIRS) so that further pattern analysis\ncan be conducted for correction and safeguarding.\n\nThe capabilities of GenAI generally raise concerns about enabling bad actors\nand undermining government security if not properly governed.\n\nState of California Report: Benefits and Risks of GenAI | 19\n\n\n-----\n\nA few general examples include:\n\n-  Augmenting criminal activities by generating more convincing scams,\nmalicious code, and deception.\n\n-  Tricking consumers into sharing personal data for advertising or\nmanipulation through enhanced phishing capabilities with voice, image,\nand video deepfakes.\n\n-  Enabling scammers to efficiently produce high volumes of convincing\ntext.\n\nNew capabilities created by GenAI will pose new security risks, threatening\nexisting systems around both physical and digital infrastructure.\n\nRobust, new\nsecurity controls, monitoring, and validation techniques will be needed to guard\nagainst potential attacks.\n\nGenAI has a wider security risk surface exposed via\ntheir natural language interfaces.\n\nIt is easier for adversarial attacks to occur and\nless intuitive to place security controls on the model weights that produce\nrecommendations and decisions by the GenAI model.\n\nTo that end, the Governor\u2019s Executive Order requires a classified joint risk analysis\nof potential threats to and vulnerabilities of California's energy infrastructure and\ndirects development of a strategy to assess threats to other critical infrastructure\nby the use of GenAI.\n\n**_5.\n\nExplainability & Interpretability_**\nExplainability and interpretability are defined in the following ways:\n\n-  _Explainability_ refers to a representation of the mechanisms underlying genai\nsystems\u2019 operation.\n\n-  _Interpretability_ refers to the meaning of genai systems\u2019 output in the context\nof their designed functional purposes.", "-  _Interpretability_ refers to the meaning of genai systems\u2019 output in the context\nof their designed functional purposes.\n\n**_When applied to GenAI, California identified the following risks:_**\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|Shared risks|Black-box decision-making that makes genai model recommendations unexplainable.|\n|Amplified risks|Complexity and opaqueness of genai model architectures.|\n|New risks|Users or stakeholders misunderstanding or misinterpreting generated content.|\n||Users attributing logical thinking to GenAI models when models are asked to give explanations for how the output was generated.|\n\n\n\nState of California Report: Benefits and Risks of GenAI | 20\n\n\n-----\n\nGenAI models are similar to certain types of conventional genai models like neural\nnetworks, which are black-box algorithms that cannot provide direct\nexplanations for their predictions.\n\nWithout the ability to explain model\npredictions and outputs, it becomes more difficult to address cases where this\ntechnology produces an unexpected result that impacts the validity and\nconsistency of the answers.\n\nThere is ongoing research to gain better\nexplainability capabilities for these types of algorithms.\n\nHowever, GenAI models\namplify these concerns because they are built from much larger and more\ncomplex neural networks than conventional genai models.\n\nThe difficulty in extracting human-interpretable explanations from GenAI\ntechnology is an important factor to consider for government to provide\nsufficient information about decisions that concern constituents.\n\nAdditionally, GenAI models can be prompted to \"explain their reasoning\"\nthrough prompting techniques.\n\nHowever, these techniques can be inconsistent\nbecause GenAI models have been shown to misrepresent their stated\nreasoning .\n\nThese techniques can be unreliable in extracting a GenAI model\u2019s\ntrue logical reasoning for an output, compared to the model\u2019s stated reasoning.\n\n**_6.\n\nPrivacy_**\nPrivacy refers generally to the norms and practices that help to safeguard\nhuman autonomy, identity, and dignity.\n\nThese norms and practices typically\naddress freedom from intrusion, limiting observation, or individuals\u2019 agency to\nconsent to disclosure or control of facets of their identities.\n\n**_When applied to GenAI, California identified the following risks:_**\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|Shared risks|Unauthorized data access or usage by users.|\n||Insufficient data anonymization on training data leading to the leakage of sensitive information.|\n||Collection of more data than necessary to train the genai model.|\n||Proprietary data may be used in training third-party genai models.|\n|Amplified risks|Over-reliance on vast amounts of data for generation, risking privacy.|\n||Difficulty in erasing personal information embedded within the model features (known as algorithmic disgorgement).|\n|New risks|GenAI unintentionally recreating, inferring, or falsifying private or sensitive details.|\n||genai-generated content potentially revealing or alluding to training data details.|\n||Nonconsensual use of people\u2019s likeness (e.g., deepfakes, voice impersonation, biometric data like gaze direction, gait analysis, and hand motions).|\n\n\n\nState of California Report: Benefits and Risks of GenAI | 21\n\n\n-----\n\nGenAI models can leak personal data if they are not properly anonymized or if\ntheir training data is not properly secured.\n\nFor example, if a GenAI model is\ntrained on a dataset of medical records, it could potentially generate text that\nincludes personal information about patients, such as their names, medical\nconditions, or medications.\n\nThis information could be used to identify individuals,\neven if the model was trained on an anonymized dataset.\n\nGenAI also raises novel privacy issues such as:\n\n-  _Re-identification risk:_ GenAI models can also be used to synthesize new\ndatasets from previously unintegrated data sources that can be used to\nre-identify individuals.\n\nFor example, if a GenAI model is trained on a\ndataset of images of people, it could potentially generate new images\nthat are similar to the images of real people in the training dataset.\n\nThese\nnew GenAI images could then be used to identify real individuals in the\ntraining dataset, even if the original images were anonymized.\n\nThis reidentification risk is particularly critical in regard to sensitive personal data,\nwhere individuals could be exposed to unsafe conditions if unintentionally\ndisclosed.\n\n-  _Third-party plug-ins and browser extensions:_ Third-party plug-ins and\nbrowser extensions that interact with GenAI models can also pose privacy\nrisks.\n\nFor example, a plug-in could collect data about the user's\ninteractions with a GenAI model, such as the text that they generate or\nthe images that they create.\n\nThis data could then be shared with the\nplug-in's developer or with third-party companies without the user's\nknowledge or consent.", "This data could then be shared with the\nplug-in's developer or with third-party companies without the user's\nknowledge or consent.\n\n-  _Government\u2019s ability to respond to consumer privacy requests:_ As\nCalifornians\u2019 right to remove their personal data online becomes more\nwidely practiced, extracting and destroying their information embedded\nwithin GenAI models may become difficult or administratively\nunsustainable.\n\n-  _Bad actors accessing and sharing government database content:_ The\nstate of California maintains secure databases with records of individuals\u2019\ndata, such as census data and the program-specific data minimally\nnecessary to make eligibility determinations.\n\nIf a bad actor were able to\ngain illegal access to a state database, GenAI could power the rapid\ncapture and leak of Californians\u2019 private data.\n\nData leaks and data loss\nfrom data centers also pose an ongoing risk, which will need to be\naddressed through improved controls.\n\nState of California Report: Benefits and Risks of GenAI | 22\n\n\n-----\n\n**_7.\n\nFairness_**\nFairness in genai includes concerns for equality and equity by addressing issues such\nas bias and discrimination.\n\n**_When applied to GenAI, California identified the following risks:_**\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|Shared risks|Services using genai systems may not be accessible across different parts of the digital divide, where some communities may not have equitable access to digital technology platforms.|\n||genai systems may not work the same way or with similar level of accuracy for all subsets of the population, in particular for under- represented, vulnerable or protected groups.\n\nSuch algorithmic discrimination would exacerbate existing social inequities.|\n||On-demand pricing for GenAI tools can result in large costs to institutions that under-resourced communities may not be able to pay.\n\nThis may limit or block constituents from using GenAI tools, further exacerbating inequities.|\n|Amplified risks|Discriminatory or biased outcomes caused by model recommendations or predictions.|\n|New risks|Generating content that reflects or amplifies racial, gender identity, sexual orientation, or other biases or stereotypes.|\n||Model performance results in disparities across languages, biasing towards English and high-resource languages.|\n||The output of GenAI does not reflect social or cultural nuances of sub-sets of the population.|\n\n\n\nGenAI models can perpetuate societal biases if the training data is imbalanced.\n\nFor example, large language models often perform poorly for non-native English\nspeakers.\n\nThis could create inequity in access to certain government services.\n\nGovernment must also proactively assess for algorithmic discrimination, such as\ngender, racial, or other biases, particularly in high-impact areas like criminal\njustice, healthcare, mental health, social services, and employment decisions.\n\nAlgorithmic bias in state systems can be especially harmful if the GenAI\nauthorship of the content is not disclosed, leading human consumers to\nmisattribute the biased or harmful content to the government.\n\nIn conventional genai models, bias can be mitigated by collecting and processing\ntraining data to correct for under-representation of historically marginalized\ngroups.\n\nThis is important because creating rules that intentionally bias model\nweights during model training could have legal implications.\n\nFor example, if an\ngenai model is used to make decisions about who gets a loan, and that model is\nbiased against people of a certain race, then the company using that model\ncould be sued for discrimination.\n\nState of California Report: Benefits and Risks of GenAI | 23\n\n\n-----\n\nGenAI datasets however are much larger than conventional genai models, making\nit more difficult to resolve embedded bias.\n\nCommon expressions of data bias in\nGenAI outputs can include gender and racial stereotypes.\n\nThis is usually relevant\nwhen generating narrative examples, image generation, or creating synthetic\ndata.\n\n**_8.\n\nWorkforce & Labor Impacts_**\nThe adoption of GenAI technologies into the economy and workforce will\nintroduce many changes that will support workers in their daily responsibilities\nand tasks, but also will change or modify parts of their existing workflows.", "**_California identified the following risks when analyzing the use of GenAI:_**\n\n|Type of Risk|Description of GenAI Risks|\n|---|---|\n|Shared risks|Ethical considerations for genai annotation work within the training process and ensuring safe, fair working conditions.|\n||Workers may require training programs to effectively use genai tools to facilitate their existing workloads.|\n|Amplified risks|Certain industries may experience job displacement from genai, requiring proactive and comprehensive re-skilling programs to support workers through employment transitions.|\n\n\n\nKey areas for workforce impact considerations include:\n\n-  _Up-skilling, re-training, and job transition assistance:_ With the integration of\nGenAI tools into the workplace, staff may require up-skilling programs to\neffectively use the technology in their daily responsibilities.\n\nFor individuals\nthat experience job displacement, private companies and public services\nneed to prepare for proactive and thoughtful re-skilling and transition\nsupport services .\n\n-  _Labor exploitation:_ GenAI could enable new forms of labor exploitation,\nsuch as in data labeling where contract workers in developing countries\nare employed to annotate datasets used for training genai models without\nlabor rights guarantees.\n\nThis can encourage unsafe working conditions, especially, for contract\nworkers in sensitive fields like content moderation for graphic and\ninappropriate content.\n\n-  _Anticompetitive behavior:_ Major firms could use GenAI to further\nconcentrate power in anticompetitive ways , such as by replicating\ncopyrighted data from artists or small businesses.\n\nState of California Report: Benefits and Risks of GenAI | 24\n\n\n-----", "##### Identifying GenAI High-Risk Use Cases\n\nFuture state research and development of guidelines will continue to support\nagencies and departments in identifying the severity and scope of GenAI risks,\nso that state government can better align oversight to real-world impacts.\n\nThe\nGovernor\u2019s Executive Order instructs agencies to begin this work.\n\nBut California\u2019s\nefforts in this regard will surely continue beyond the Executive Order\u2019s\ndeliverables \u2013 including partnership between the Administration and the\nLegislature to identify risks and codify strategies to mitigate them.\n\nA risk-based approach to genai aligns with global trends.\n\nMajor governmental\nentities like the European Union and NIST already employ risk-based frameworks\nfor genai evaluation and deployment.\n\nBy identifying the level of risk associated with\nGenAI deployment, organizations can implement responsible GenAI systems\nconsistent with international practices.\n\nWhen a high-risk use case is identified and GenAI is being used, state entities will\nneed to take additional precautions.\n\nGovernment Code \u00a7 11546.45.5 1 defines\n\u201chigh-risk automated decision systems\u201d for state entities and serves as a basis to\nidentify where these precautions should be defined.\n\nThe definition states:\n\n_\u201cHigh-risk automated decision system\u201d means an automated decision_\n_system that is used to assist or replace human discretionary decisions that_\n_have a legal or similarly significant effect, including decisions that_\n_materially impact access to, or approval for, housing or_\n_accommodations, education, employment, credit, health care, and_\n_criminal justice._\n\nLower risk systems that fall outside of this high-risk classification may still benefit\nfrom risk mitigation and transparency measures.\n\nThe following table displays\ninitial considerations that may help determine actions needed to mitigate the\nrisks presented by GenAI.\n\n1 / Effective January 1, 2024.\n\nState of California Report: Benefits and Risks of GenAI | 25\n\n\n-----\n\n**_Table 3: California\u2019s Oversight Considerations for GenAI Applications by Risk_**\n\n|Level|Col2|\n|---|---|\n|Risk Level|Oversight Considerations|\n|Low risk|For genai systems deemed low risk, standard monitoring and lightweight evaluations are sufficient.\n\nMonitoring efforts can track user uptake, feedback, time savings, and output quality.\n\nVoluntary adoption by staff also signals effectiveness.|\n|Moderate risk|Moderate-risk systems warrant more involved oversight, such as systematic monitoring and rapid cycle evaluations.\n\nMonitoring remains important for moderate risk applications, tracking usage, feedback, efficiency gains, and outcome improvements.\n\nShort internal evaluations should compare processes and outputs with and without the genai tool.|\n|High risk|High-risk systems require intensive evaluations, qualitative assessments, and risk mitigation measures.\n\n\u25cf Pre-deployment assessments and red-teaming of GenAI systems are crucial as guardrails to catch any issues with fairness, privacy, security, performance, and safety in the model beforehand.\n\n\u25cf Post-deployment monitoring is also a critical complementary piece in identifying security vulnerabilities, performance changes, and equity issues.\n\n\u25cf Community feedback collections should capture diverse perspectives and enable processes to appeal decisions, especially from historically marginalized groups.\n\n\u25cf High risk GenAI systems should undergo an evaluation of whether the tool is beneficial and necessary prior to release.|\n\n\n\nUse cases involving critical applications, tasks requiring empathy or compassion,\ncontextual understanding, and tasks requiring extensive domain knowledge or\nexperience, are likely inappropriate for GenAI algorithms without human\noperators and significant oversight.\n\nState of California Report: Benefits and Risks of GenAI | 26\n\n\n-----", "#### IV.\n\nOngoing Engagement\n\nThis report was not possible without extensive collaboration.\n\nThe initial findings\nand recommendations of this report mark the beginning of a much broader\nand ongoing conversation about the benefits and risks of this potentially\ntransformative technology.\n\nThe State of California will regularly assess and update the findings of this report\nwith significant developments as appropriate.\n\nTo do this, the State will continue\nstrengthening collaborations with academia, other governmental entities,\nindustry, policy experts, organizations representing employees, and communitybased organizations.\n\nGenAI has incredible potential, and it is the State\u2019s responsibility to create an\nopportunity where Californians can help to chart their own future with this new\ntechnology.\n\nState of California Report: Benefits and Risks of GenAI | 27\n\n\n-----", "#### V. Conclusion\n\nThis report represents a preliminary analysis to a much bigger conversation\naround a technology that is emerging and still rapidly developing, from\nenvironmental considerations to training and education.\n\nAcknowledging GenAI\npresents new and unique risks that are still to be addressed by future updates,\nCalifornia has laid out initial, potential use cases and risks identified through\nliterature research and feedback from stakeholders.\n\nThe unique risks posed by\nnovel GenAI capabilities require augmented governance for the added risks\nbetween conventional genai and GenAI.\n\nUnder the Governor\u2019s Executive Order, the State will undertake significant efforts\nto evaluate and update its current procurement methods, practices, and\nvendor terms and conditions to place protections to acquire GenAI tools safely.\n\nMoreover, through GenAI pilots and sandbox applications established in the\nExecutive Order, the State will be able to continually adapt guidance in\nresponse to lessons learned.\n\nCarefully designed pilot cases will enable state\nleaders to assess the outcome, scale efforts that prove to be successful, and\nshare learnings and best practices with public policy makers and stakeholders in\nother state governments, the federal government, and internationally.\n\nAdditionally, knowing that GenAI may make changes to our technical\nlandscape, the state will explore specialized training and development curricula\nfor current state employees to work successfully with GenAI technologies.\n\nImportantly, as it is an emerging technology, the State will continually evaluate\nthe most responsible ways to implement GenAI.\n\nLooking forward, the State will continue building off considerations laid out in the\nNIST framework for conventional genai as well as developments from the Biden\nAdministration\u2019s Executive Order on genai, and in ongoing partnership with the\nLegislature, community, academia, and technical experts.\n\nAs the State\nacknowledges GenAI\u2019s capacity to perpetuate and exacerbate bias, California\nwill continue to lead the nation in removing barriers to equal opportunity and,\nensure our systems do not promote explicit or implicit biases when providing key\nbenefits and governmental services, while continuing to advance diversity,\nequity, inclusion, and accessibility.\n\nIn that way, California can continue to lead\nthe nation through thoughtful, equitable, and innovative deployment of some\nof the most promising technology to become available in a generation.\n\nState of California Report: Benefits and Risks of GenAI | 28\n\n\n-----", "##### Overview of eSafety\u2019s approach to tech trends\n\nThe eSafety Commissioner (eSafety) is Australia\u2019s independent regulator and\neducator for online safety.\n\nUnder the _Online Safety Act 2021_ (Cth) (\u2018the Act\u2019), we coordinate Australian\nGovernment activities to help keep people safer online, conduct research, provide\neducation, and administer regulatory schemes to deal with certain types of online\nharm.\n\nWe use our regulatory powers to promote greater transparency and\naccountability within the online industry.\n\nWe work with other government agencies, businesses and organisations around\nthe world to share information and best practices.\n\nThis helps us make the internet\na safer place for everyone, regardless of where they live.\n\nWe keep our content, programs and regulatory priorities up to date by scanning\nfor new research, policies, laws, technology developments and by talking to\nexperts such as academics and researchers.\n\neSafety also advises the Australian Minister for Communications and the\nGovernment on emerging issues across the online industry, international\ndevelopments in technology regulation, and online safety concerns impacting\nAustralians.\n\ni We do this because we recognise that combating online harm is a\nglobal challenge and we need to act together to make a difference.\n\nii\n\nThis position statement is about **genai (genai)** but readers\nmay also find our other position papers on **deepfakes** iii created using artificial\nintelligence software, as well **recommender systems and algorithms,** **iv** useful\ninformation relevant to this topic.\n\nThe information in this position statement was informed by industry and\nstakeholder consultation as well as Australian and overseas research.\n\nIt reflects\neSafety\u2019s position as of **15 August 2023.\n\n** eSafety acknowledges the rapid\nadvancements in genai technology and will seek to review and provide\nrevisions when necessary.", "##### Definitions and examples\n\n**genai (genai)** refers to an engineered system that generates\npredictive outputs such as content, forecasts, recommendations, or decisions\nfor a given set of human-defined objectives or parameters without explicit\nprogramming.\n\ngenai systems are designed to operate with varying levels of\nautomation.\n\n**Machine learning** are the patterns derived from training data using machine\nlearning algorithms, which can be applied to new data for prediction or\ndecision-making purposes.\n\n-----\n\n**genai models** produce novel content such as text, images, audio, video\nand code in response to prompts.\n\nA **large language model (LLM)** is a type of genai that specialises in the\ngeneration of human-like text.\n\n**Multimodal Foundation Model (MfM)** is a type of genai that can\nprocess and output multiple data types (e.g.\n\ntext, images, audio).\n\n_For consistency, this paper adopts the same definitions used in the Department_\n_of Industry, Science and Resources\u2019 June 2023 Discussion Paper on Safe and_\n_responsible genai in Australia._", "**What is genai?\n\n**\n\ngenai uses machine learning to generate new code, text, images, audio,\nvideo, and multimodal simulations.\n\nIt works by using large artificial neural\nnetworks v built with enormous datasets and parameters that are inspired by\nsynapses within the human brain.\n\nThe difference between genai and other\nforms of genai is that its models can create new outputs, instead of just making\npredictions and classifications like other machine learning systems.\n\nSome examples of genai applications include:\n\n-  Text-based chatbots, or programs designed to simulate conversations with\nhumans, such as Anthropic\u2019s Claude, Bing Chat, ChatGPT, Google Bard, and\nSnapchat\u2019s My genai\n\n-  Image or video generators, such as the Bing Image Creator, DALL-E 2,\nMidjourney, and Stable Diffusion\n\n-  Voice generators, such as Microsoft VALL-E.", "##### Background\n\ngenai is not new.\n\nChatbots, image generators and deepfake technologies\nhave been in development and use for many years.\n\nHowever, recent advancements have rapidly improved genai due to the\navailability of more training data, enhanced artificial neural networks with larger\ndatasets and parameters, and greater computing power.\n\nSome experts now claim\ncontemporary genai systems are moving rapidly towards \u2018human-competitive\nintelligence.\u2019 vi Such claims pose existential questions about the potential of such\nsystems to impact almost every aspect of human life in both positive and negative\nways.\n\nThe possible threats related to genai are not just theoretical \u2013 real world\nharms are presenting themselves today.\n\nThis includes misusing genai to generate\nchild sexual exploitation and abuse (CSEA) material that looks like it involves real\n\n\n-----\n\nchildren (or based on images, audio or other depictions of real children vii ) or\ngenerating and threatening to share artificial but realistic pornography featuring\nreal adults without their consent.\n\nviii These harms can occur because of flaws in the\ndata or models used in genai, such as when biased information is used for\ntraining.\n\nix genai can also be used to manipulate and abuse people by\nimpersonating human conversation convincingly and responding in a highly\npersonalised manner.\n\nx\n\nMany genai models have been intentionally made freely available within\nthe open source community or have \u2018leaked\u2019 into the public domain.\n\nxi While\nreleasing models freely promotes transparency, competition and innovation, the\nfact it is readily accessible to the public also increases the risk that harmful and\nmanipulative content can easily be generated at scale when the technology is put\nin the wrong hands.\n\nxii\n\ngenai is being incorporated into major search engines, productivity\nsoftware, video conferencing and social media services and is expected to be\nintegrated across the digital ecosystem.\n\nxiii Companies are moving quickly to\ndevelop and deploy their own genai technologies.\n\nThis may lead to not\nenough attention being paid to risks, guardrails, or transparency for regulators,\nresearchers, and the public.\n\nMultiple actors including technology developers and downstream services that\nintegrate or make genai technology accessible, as well as users, all have a\nrole to play in ensuring online harm is prevented and addressed.\n\nAs countries think about how to regulate genai, technology companies\nhave been advocating for certain regulatory approaches, some of which may\nactually serve the commercial interests of the companies involved.\n\nxiv\n\nIn Australia, the Government is looking at the risks, benefits and potential impacts\nof genai.\n\nThis includes examinations by the Department of Industry,\nScience, and Resources, the Department of Education, the Attorney General\u2019s\nDepartment and the Digital Platform Regulators Forum (DP-REG), which includes\nthe Australian Competition and Consumer Commission (ACCC), Australian\nCommunications and Media Authority (ACMA), Office of the Australian Information\nCommissioner (OAIC), and eSafety.\n\nxv\n\nIt Is important to recognise that for every risk, there is also an opportunity.\n\nFor\nexample, people can misuse genai to create harmful content such as\nonline hate.\n\nHowever, genai can also be harnessed to significantly improve current\nproactive content moderation technologies to quickly and accurately find and stop\nonline hate.\n\nxvi\n\nThere have been reported instances of children acknowledging abuse and seeking\nsupport through genai chatbots.\n\nxvii A chatbot can give an inappropriate or harmful\nresponse to a child who discloses their experience of abuse.\n\nBut an appropriately\ntrained chatbot could respond in a supportive and evidence-based manner,\n\n\n-----\n\nconnecting that child to law enforcement and support services.\n\nThe risk of harm\ndepends on whether the technology was designed with safety in mind, including\nby taking a Safety by Design approach.\n\nxviii\n\n**Safety by Design** is built on **three core principles** : Service provider responsibility,\nUser empowerment and autonomy, and Transparency and accountability.\n\nTechnology companies can uphold these principles by making sure they\nincorporate safety measures at every stage of the product lifecycle.\n\nThis should\ninvolve consulting stakeholders from multiple sectors and collaborating with the\nuser community, including those who are typically under-represented or who may\nbe at greater risk of harm.\n\nA Safety by Design approach to genai is also likely to\nsatisfy most of Australia\u2019s genai Ethics Principles.", "##### genai lifecycle\n\nIt is important to consider online safety risks and harms from the earliest stages\nof developing a genai technology.\n\nThis should continue throughout the\ntechnology\u2019s lifecycle and across the entire system from developing a business\ncase to releasing, disseminating and reintegrating genai-generated content.\n\nThe simplified product lifecycle below sets out 10 crucial steps where this must\noccur, drawing on insights from various experts and other sources.\n\nxix\n\n**Diagram 1:** genai Lifecycle\n\n\n-----", "**1.\n\n** **Business case**\n\nThe first step in the genai lifecycle is to evaluate the business case for\ndeveloping the technology and explore options for funding.\n\nTo create safer\ntechnologies, companies and developers building genai should consider\n_why_ they are planning to develop it, for _what purpose_ and in _what context_ .\n\ngenai systems designed for legitimate internal business purposes can still have\nbroader impacts on individual, social and environmental wellbeing.\n\nThose impacts\nshould be accounted for in the genai system\u2019s lifecycle, to include consideration of\nimpacts outside the organisation **.\n\n**\n\nBy considering risks and building in safeguards during the early stages of\ndevelopment, it is possible to establish trust in a product or service.\n\nxx This can\nthen open up more opportunities for investment.\n\nOne helpful tool for this process\nis the **Safety by Design Business Model Canvas** .\n\nThis enables businesses to assess\nand analyse their business model, challenge assumptions and promote socially\nresponsible innovation.", "**2.\n\n** **Selecting data**\n\nAfter establishing a business model, developers must make choices about the\ntype of model they want to create and the input data they will use to build and\ntrain it.\n\ngenai often requires large datasets to meet the diverse needs of\nusers with some models utilising closed datasets, while others rely on general\ninformation scraped from the internet.\n\nDevelopers must consider the content and quality of their data sources, as well as\nethical and legal concerns such as _how_ data is sourced, right from the start.\n\nData\nscraping involves collecting, using, disclosing, and storing information without the\nknowledge or consent of the data creators or the individual the information is\nabout, which raises questions about copyright, privacy, consent and attribution.\n\nIt is important to address considerations about accuracy, diversity (including\nlanguage and culture) and whether harmful material is captured through\nprocesses such as scraping.\n\nIf not managed carefully, there is a risk that data\nsources could include illegal or harmful content, such as CSEA material, imagebased abuse (IBA), hate speech and abuse, or false, biased, or misleading\ninformation, or other unlawful material.\n\nData sets containing such content can\nperpetuate harms by generating illegal and harmful outputs.\n\nDevelopers can also use pre-training capabilities, such as classification and\nproactive detection tools, to improve training data quality.\n\nThis reduces the risk of\nharm later in the lifecycle.\n\nTransparency is a vital component to hold services accountable for content they\nhost or use to train their systems, including by documentation through annual\n\n\n-----\n\nreports and using model cards or system cards, which are designed to explain how\nthe systems and models operate.", "**3.\n\n** **Training the model**\n\nThe next step is to train the model using the data that has been selected.\n\nDevelopers can do this through supervised learning, where humans train models\nto classify inputs with labels.\n\nFor example, a model can be trained to label social media posts as positive or\nnegative.\n\nThis is called \u2018supervised learning\u2019 because a human teaches the model\nwhat to do.\n\nxxi It is important that humans are appropriately trained to conduct this\nwork and feed in diverse views.\n\nOn the other hand, \u2018unsupervised learning\u2019 can be\nused to find patterns in data that are not labelled, typically used when there is a\nlack of training data.\n\nxxii\n\nMore advanced text-based machine learning models may rely on \u2018self-supervised\nlearning\u2019.\n\nThis type of training involves giving the model a massive amount of text\nso it can generate predictions.\n\nFor example, some models can predict how a\nsentence will end based on a few words.\n\nxxiii Model and system cards are important\nfor documenting capabilities at the training stage, prior to refinement and release.\n\nIt is also important at this stage to consider the lived experiences of humans who\nare training the model, to ensure that culturally specific and contextual forms of\nharm can be addressed and appropriately mitigated.\n\nAdditional safety measures include consultation with experts who can provide\nguidance on inputs for training the model.", "**4.\n\n** **Refinement**\n\nIt is important to keep refining model data throughout the lifecycle to minimise\nrisks, harms and bias.\n\nThis means going beyond initial training with supervised,\nunsupervised or self-supervised learning.\n\nxxiv.\n\nDevelopers must keep working over\ntime to maintain quality data inputs, ethically curate data, label it, and control\nquality across many datasets on different subjects.\n\nxxv\n\nData quality and veracity are issues in the refinement process, as is the ability of\ngenai models to recognise and filter out illegal, harmful or inappropriate content.\n\nThis\nwork is often carried out by employees who are hired to tag and sift through large\namounts of harmful and potentially traumatising content.\n\nWhile human review prior to release may be essential, there are concerns about\nthe working conditions, pay, and mental wellbeing for people who do jobs such as\nlabelling or generating training data.\n\nxxvi", "**5.\n\n** **Release**\n\nFollowing refinement, the model may be released to the public through the\ndeveloper\u2019s own app or interface, such as ChatGPT.\n\nIt can also be added to\n\n\n-----\n\nthrough other means including integration into an existing service, such as\nChatGPT in Microsoft\u2019s Bing search engine.\n\nThe same model can be released and integrated in a variety of ways.\n\nDevelopers\nmay also choose to openly release their model.\n\nThere are details about open and\nclosed models below.\n\nIt is important to conduct risk assessments, anticipate how the model may be\nmisused by individuals and establish safety policies and practices prior to release.\n\nDevelopers should \u2018red-team\u2019 or \u2018stress test\u2019 the system by considering the\navenues for possible misuse.\n\nDevelopers should also consider graduated\napproaches to release, including regulatory sandboxes, to understand how the\nmodel performs in controlled conditions.\n\nGiven the evolving nature of the technology, unforeseen risks and new techniques\nto overcome safeguards will keep appearing after the model is launched.", "**6.\n\n** **User engagement**\n\nOnce a model is released, users can interact with it by accessing its interface and\ngiving it instructions or prompts.\n\nFor example, they can enter text or audio\ncommands to generate content or get information.\n\nDevelopers should expect that their model might be misused by malicious actors.\n\nThey should test their models with consideration of the ways it could be misused.\n\nFor example, it is a serious concern if models are not able to detect when users\nmay be attempting to input harmful prompts to generate illegal or harmful\ncontent, or implementing appropriate safeguards that are activated to mitigate\npotential misuse.\n\nxxvii\nFor example, terrorist groups could use models to raise money, disseminate proterror content or generate instructions on making bombs or weapons ;\npaedophiles could use genai to create content for child grooming or CSEA, and people\ncould use genai to generate and spread misinformation and disinformation or\ntargeted hate speech or abuse.\n\nPeople could also intentionally try to hack or\ntamper with the model\u2019s input to make it behave badly.\n\nxxviii\n\nAdding points of friction, such as educative prompts and nudges, when users\nattempt to generate content can be an important method of reducing misuse.\n\nxxix\nDevelopers need to keep improving their model to engineer out harmful or illegal\noutputs as they emerge, as it is unlikely all harms will be mitigated prior to\nrelease.", "**7.\n\n** **genai generation**\n\nAfter the user inputs a prompt, the genai interface generates content based on this\ninformation.\n\nSometimes, genai models give confident but inaccurate,\nmisleading, or harmful answers.\n\nThese are called \u2018hallucinations\u2019 and can happen\nfor many reasons, including inadequate or problematic input datasets.\n\nxxx\n\n\n-----\n\nModel outputs can also adversely influence user views, values and experiences by\nmisrepresenting available information or only providing a limited view of\ninformation.\n\nThis could have the impact of shifting societal norms or values\naround challenging topics.\n\nDevelopers can also add safety measures at this stage,\nsuch as warnings or disclaimers for users that the information might be wrong or\ninaccurate.\n\nDigital watermarking \u2013 a method for identifying genai-generated content \u2013\ncan also be implemented.", "**8.\n\n** **Feedback**\n\nOffering opportunities for users to give feedback on the content generated is a\ncrucial step in the genai lifecycle.\n\nThis can be done through user feedback\nloops.\n\nIt is also essential to clearly communicate policies and make sure reporting\nand feedback tools are easily accessible.\n\nBy gathering input from users, there is a chance to mitigate potential risks, such\nas generating discriminatory, harmful, deceptive, or false content.\n\nThis may also\nprovide the basis to undertake consultation with a diverse userbase.\n\nThis feedback\nhelps to implement measures that moderate and improve the content generated\nby the model.", "**9.\n\n** **genai dissemination**\n\nAfter the system generates content, it can be shared with others, including on\nsocial media.\n\nEven where these social media platforms and other services do not have their own\ngenai capability, it is imperative to build in tools that can stop, find, and\nmoderate harmful content generated by genai that may be shared on their platforms.", "**10.\n\n** **Reintegration**\n\ngenai content that is shared on the internet or on social media could feed\nback into models that are built or refined using content scraped from the web.\n\nIf\nnot appropriately managed, harmful content and views may be reinforced in a\ncontinuous feedback loop.\n\nReintegration may also generate \u2018synthetic data\u2019 and in\nturn lead to an overall reduction in model efficacy.\n\nxxxi", "**Framing online risks and harms**\n\nThere are different ways to understand the risks and harms associated with\ngenai.\n\nOne approach is to consider its potential impacts on individuals and\nsociety.\n\nAt an individual level, genai can pose risks by generating and amplifying\nharmful and extreme content.\n\nThis can have a greater impact on victims of CSEA\nmaterial, IBA and other forms of abuse.\n\nIt also affects those who inadvertently\ncome across such harmful material.\n\n-----\n\nOn a broader societal level, genai can contribute to the generation and\namplification of content that promotes bias and discrimination.\n\nThis includes\npromoting sexism, homophobia, racism, or other forms of prejudice.\n\nxxxii Such\ncontent normalises hate or intolerance, which could lead to radicalisation towards\nterrorism and violent extremism.\n\nIt may also lead to an erosion of trust in online\ncontent or institutions.\n\nThese risks have significant social implications, particularly where several harmful\neffects may accumulate over time, shaping narratives around important societal\nissues.\n\nFor example, a person might ask a genai application a question\nabout domestic violence and get a response that distorts or minimises the\nseverity of the issue.\n\nThere is also the potential for text-based and visual model\noutput to be used in the service of mega conspiracies, fuelling hate and\nintolerance.\n\nGiven the potential individual and societal impacts, experts, industry and some\ngovernments are developing frameworks to proactively consider these issues, risks\nand harms.\n\nOne framework that was raised during consultations is an approach that examines\nthe risks associated with different components of the system.\n\nFor example, the\n\u2018ABC\u2019 framework considers three key aspects: the **actors** involved in\ndisinformation campaigns, their deceptive **behaviour** and tactics, and the **content**\nthey produce and share.\n\nxxxiii\n\nSimilarly, during consultations, eSafety received feedback suggesting an approach\nthat focuses on context and intention.\n\nStakeholders identified three categories of\nrisks and harms:\n\n-  **genai failing to perform as expected:** This occurs when a system\nunintentionally causes harm by generating incorrect or harmful responses.\n\nFor example, genai systems may \u2018hallucinate\u2019 and produce\ninappropriate responses to user prompts.\n\n-  **genai being used maliciously:** This happens when a model is trained or\nexploited for harmful purposes.\n\nFor example, when individuals involved in\nCSEA attempt to groom children or generate CSEA material using generative\ngenai tools.\n\n-  **genai being overused, used recklessly or used inappropriately in a specific**\n**context** : This refers to situations where genai is used excessively or\nrecklessly, or employed inappropriately, leading to harmful or misleading\nresults.\n\nFor example, where genai produces age-inappropriate\nmaterial such as online pornography for a child user.", "**Drivers of risk**\n\nSeveral factors can drive, contribute to, or amplify the risks and harms associated\nwith genai:\n\n\n-----\n\n**Personalisation** .\n\nChatbots and multimodal models have the potential to\ngenerate highly personalised, emotive, manipulative, and invasive content\nbased on users\u2019 previous engagement and activity.\n\nThrough consultation\nwith eSafety, experts highlighted that online harms may arise from\ngenai creating \u2018human quality content\u2019 or producing customised\nmedia in-real time.\n\nWhile this content may appear authoritative, it could\nalso be intentionally or accidentally false, misleading, or malicious.\n\nxxxiv For\nexample, personalised phishing activities may be used to intentionally\nmislead and potentially defraud the recipient or gain access to information\nor systems.\n\n**Access** .\n\nWider access to genai models raises concerns about their\npotential misuse for harmful purposes.\n\nConsumer-facing apps using\ngenai make it harder for users to discern fact from fiction as the\ntechnology becomes more convincing over time.\n\nPolicy discussions continue\nglobally on whether the development of genai should occur in open or closed\nenvironments, with regulatory approaches tailored according to public\naccess levels and associated risks.\n\nDetermining who is responsible for\npreventing and mitigating harms becomes an important consideration\namong the companies that develop the model, the companies that deploy\nthe model in their applications and the people who use those applications.", "**Case study: Open vs closed systems**\n\nThere are arguments for both open and closed systems regarding their benefits\nfor safety and security.\n\nOpen systems offer interoperability, customisation, and\nintegration with third-party software or hardware.\n\nChampions of open models\nhighlight how openness promotes transparency, accountability, competition and\nsignificant innovation, whereas advocates of closed systems argue that they are\nmore stable and secure and better protect their owners\u2019 property interests.\n\nxxxv\n\nChoosing between open and closed systems is further complicated by factors\nsuch as aligning genai with human values and goals.\n\nFinding the right balance\nbetween the two models is crucial to foster innovation while managing the\nshort- and long-term risks posed by the technology.\n\nPreventing harm is a\nparamount consideration in the development of the system.\n\nSafety by Design\nprinciples are critical in technology design, including for open and closed\nsystems.\n\nBy drawing on Safety by Design, innovation can continue to be fostered\nwithout creating or amplifying possible harms.\n\nAn open-source model has its merits in democratising access to genai, allowing\nresearchers to identify errors and biases, and mitigating the risk that generative\ngenai is overly concentrated in large tech companies with access to training data\nand computing power.\n\nxxxvi However, open-source models can also allow\nindividuals to remove safeguards and create harmful content.\n\nFor example,\nclassifiers can be fine-tuned to create adult pornography or used by perpetrators\nof CSEA to produce CSEA material.\n\nxxxvii\n\n\n-----\n\n**Advertising and revenue models, and access to children\u2019s data** .\n\nDigital\nplatforms with advertising-based revenue models are likely to incentivise\nthe generation of highly personalised content for marketing purposes and\npromote sponsored content rather than addressing the specific needs of\nusers.\n\nIt is also possible that genai optimised to increase user\nengagement will produce problematic or emotive content aimed at\nmaintaining attention.\n\nGreater consideration of the acquisition, access to,\nuse and storage of children\u2019s data, particularly for commercial purposes, is\nneeded.\n\nThe Australian Privacy Act Review Report made recommendations\nfor providing individuals with greater control over targeted content and\nmarketing, including prohibiting entities from targeting children unless it is\nin the child\u2019s best interest.\n\nAt the date of publishing this paper, the\nGovernment\u2019s response to the report is forthcoming.\n\n**Limited representation.\n\n** At the time of drafting this statement there\nappears to be a lack of diversity among genai companies, primarily originating\nfrom English-speaking, Western cultures, which poses a risk of encoding\nnarrow values and perspectives into global-reaching models.\n\nxxxviii This could\nperpetuate and amplify dominant ideologies at the cost of other values and\nidentities.\n\n**Pace of development** .\n\nWith venture capital increasingly focused on\ngenai\u2019s rapid product development and sales growth potential\ncomes the risk of neglecting safety considerations due to a \u2018move fast and\nbreak things\u2019 approach.\n\nSafety by Design recognises that there are\nimportant inflection points and players in the technology ecosystem that\nneed to be leveraged to enable change.\n\nInvestors and venture capitalists\nplay a pivotal role in nurturing tech ventures and they can help put safety\nand ethical considerations at the heart of the businesses they invest in.\n\nThis will help them to invest ethically and manage investment risk, but also\nhelps the start-up harden their defences against potential safety risks.\n\nxxxix\nIt\u2019s worth noting that the use of open-source models and pace of change\nwithin the developer community can also create problems of control,\nresponsibility and accountability, with models adapted for nefarious\npurposes without adequate checks and balances.\n\n**Convergence with other emerging technologies.\n\n** As immersive platforms\nmerge with genai technology, their respective risks may also\nconverge.\n\nThis raises important questions about the manifestation of future\nharms, and the potential for more visceral and extreme impacts.\n\nFor\nexample, metaverse platforms rely heavily on genai to create realistic,\nimmersive environments populated by non-player characters.\n\nThese\nplatforms collect large amounts of personal information that informs\nconversational agents and enhances user engagement.\n\nxl This convergence\nmay reinforce the risks highlighted in eSafety\u2019s position statement on\nimmersive technologies.\n\n-----", "**Risks**\n\nUsed to create CSEA material\n\ngenai is expected by some to bring about changes in how CSEA occurs\nonline, as well as the methods we employ to combat it.\n\nxli A 2023 report by the\nStanford Internet Observatory and Thorn found that genai tools are already\nbeing used to create realistic computer-generated child sexual abuse material\n(CG-CSAM).\n\nxlii The potential for CSEA materials to be generated using photos of\nchildren harvested from social media also creates specific safety challenges for\nparents, carers and young people, reinforcing the need to make sure that online\nprofiles are set to private.\n\nxliii Perpetrators can exploit the ability of large language\nmodels (LLMs) powered by genai to mimic natural human language.\n\nThis allows them\nto groom children in automated and more targeted ways, xliv and cases have already\nbeen reported where genai technologies are being used to facilitate child\ngrooming.\n\nxlv\n\nDevelopments related to genai pose risks concerning the identification of\nvictims.\n\nAs it becomes more difficult to determine whether content is AIgenerated, law enforcement agencies and hotlines will face a growing challenge in\ndetermining whether certain content depicts an actual child who needs to be\nidentified and rescued.\n\nThere are also definitional challenges which could emerge\nacross jurisdictions concerning genai-generated media, including how children and\nimages of children are defined.", "**Case study: The production of realistic CSEA material using generative machine learning**\n\n**(ML) tools**\n\nThorn is a US-based non-profit organisation established in 2012 to build technology to\n\ndefend children from sexual abuse.\n\nIt has identified th e potential for genai to\nchange how child sexual exploitation and abuse occurs online.\n\nThrough both the input and output stages, LLMs and MfMs can be used to facilitate the\ndevelopment of CSEA material through:\n\n-  Prompts intended to produce genai-generated CSEA material.\n\nThere is emerging\nconcern that prompts could be used to create new images of real children or\nmake explicit imagery of children who do not exist .\n\nxlvi\n\n-  \u2018Role-playing\u2019 with genai.\n\nThis involves exploring how the model can be\nprompted to behave in certain ways.\n\n-  Model outputs that generate harmful or illegal content.\n\nThese outputs may\ninclude CSEA material.\n\n-----\n\nChildren seeing violent or sexually explicit material\n\nThere are additional risks to child safety related to chatbots and other forms of\nconversational genai.\n\nThese technologies can enable inappropriate contact with\nchildren and young people.\n\nMoreover, genai has the potential to generate\ncontent that is not appropriate for their age, such as violent or sexually explicit\nmaterial.\n\nFor example, developers have used the open-source Stable Diffusion model to\ngenerate realistic adult pornography.\n\nxlvii While the model has since been updated\nto mitigate the possibility of unsafe or inappropriate content from being created,\nsome people still use older versions of the model to produce prohibited imagery.\n\nMany open source sites also continue to provide access to build-your-own\nprompts in order to produce photorealistic pornography.\n\nEncouraging or facilitating behaviours that negatively impact wellbeing and safety\n\nThere are reports that Snapchat\u2019s \u2018My genai\u2019 chatbot offered advice to a user\n\nxlviii\npretending to be 13 years old on how to lie to her parents about meeting a 31year-old man.\n\nAnother example was a case where a chatbot designed as an\neating disorder hotline encouraged a user to develop unhealthy eating habits.\n\nxlix\n\nYoung people may seek out chatbots and other forms of conversational genai as safe\nspaces for sharing personal experiences, including incidents of harm.\n\nHowever,\nthere is a risk genai may struggle to appropriately handle disclosures and\nmeet reporting obligations when children share harmful experiences.\n\nThis lack of\nsupport following disclosure can put them at greater risk of harm.\n\ngenai\ntools may also unintentionally provide information that worsens trauma or\nexacerbates harm when responding to disclosures.\n\nl As provided above, there are\nalso enduring concerns related to data access, storage and retention, as well as\nwho stores the data and for what purpose.\n\nNon-consensual imagery\n\nFor years, people have been using genai deepfakes to create pornography,\nincluding explicit content featuring real people.\n\nDeepfakes are commonly shared in\nthe online pornography environment, particularly of women in the public spotlight,\nand typically without their consent.\n\nli A study by Deeptrace, a cybersecurity\ncompany based in Amsterdam, revealed that as of September 2019, 96% of all\ndeepfake videos available online consisted of **non-consensual sexual material** .\n\nlii\nAnother cross-country study published in the British Journal of Criminology in\n2021 discussed the pervasiveness and harms of deepfake and digitally altered\nimagery abuse.\n\nliii For more information, see eSafety\u2019s position statement on\ndeepfakes published in January 2022.\n\ngenai has the capability to combine images, sound and other elements to\ncreate extremely realistic but false depictions of people.\n\nThis allows individuals to\neasily generate harmful content with a high degree of false credibility.\n\n-----\n\nThe resulting harm is complex; even if it becomes clear the content is fake, it can\nstill cause immense distress for those whose images are used and shared without\ntheir consent.\n\nWhether the content is genuine or synthetic doesn\u2019t diminish its\npotential for causing humiliation, shame, harassment, intimidation, or being used\nin sexual extortion.", "**Sexual extortion**\n\nIn the United States, the Federal Bureau of Investigations (FBI) recently issued a\npublic warning about malicious individuals who create deepfakes by altering\nbenign photographs or videos to target victims.\n\nSubsequently there has been an\nincrease in people reporting sexual extortion cases involving fake images or\nvideos.\n\nliv\n\neSafety has received a small number of complaints about deepfakes, with the\ndefinitions within the Act broad enough to capture synthetic CSEM and imagebased abuse, however currently there is no significant increase in sexual\nextortion reports involving deepfake content.\n\neSafety anticipates that this\nnumber will increase with greater user engagement with genai\ntechnologies.\n\nTerrorism and violent extremism\n\nThere are reports that indicate terrorist organisations could potentially use LLMs,\ngiven they are deep-learning models capable of generating text that resembles\nhuman language.\n\nlv They could potentially use these models for financing terrorism\nand to commit fraud and cybercrime.\n\nlvi Multi-modal capabilities that analyse social\nmedia posts, online interactions, and other data sources could also be weaponised\nby terrorist groups and violent extremists to create tailored propaganda, radicalise\nand target specific individuals for recruitment, and to incite violence.\n\nlvii\n\nMore broadly, genai generated content has the potential to influence **public**\n**perceptions and values** , including towards extremist ideologies.\n\nThis creates the\nrisk that genai can contribute to insidious and cumulative harms.\n\nBullying, abuse, and hate speech\n\ngenai models and their outputs are vulnerable to being exploited for\n**automating personalised hate speech, bullying, abuse, and other forms of**\n**harassment and manipulation at scale** .\n\nThese models can generate unique content\nbased on toxic and biased data or prompts, allowing for hate speech campaigns\nthat inundate online platforms.\n\nlviii Users are finding ways to circumvent industry\u2019s\nattempts to prevent such risks, for example by experimenting with different\nprompts to \u2018jailbreak\u2019 the model.\n\nlix\n\nSimilarly, genai audio generators have been misused to spread hate speech by\ndisseminating recordings of sexist, racist, and homophobic comments in the\nvoices of celebrities.\n\nlx Studies show that genai-generated voice is nearly impossible to\n\n\n-----\n\ndifferentiate from human speech.\n\nlxi Various forms of genai-like text, audio,\nand image can work together to create highly personalised harassment with\namplified harmful impacts.", "**Bias and inclusivity**\n\ngenai can **reinforce stereotypes and amplify existing biases** even without\nhuman interference.\n\nlxii This bias poses a significant safety risk for users, especially\nthose from underrepresented and marginalised communities, and threatens to\nentrench existing divides.\n\nAt present, genai systems tend to be trained on massive sets of publicly\navailable online data that may not undergo thorough vetting for accuracy,\nauthenticity, bias, or inclusivity.\n\nlxiii This means the generated outputs reflect the\nonline world but may not accurately represent the diverse values and perspectives\nof the offline world.\n\nlxiv The risks associated with genai go beyond individual\ninstances of biased content; they extend to how this technology may shape our\nthoughts and actions more broadly.\n\nIn addition, there may be a lack of diversity among those who design and refine\ngenai systems.\n\nHuman reviewers may also bring their own subjective\nbiases into play.\n\nTo mitigate bias in genai systems, it is vital to involve diverse groups\nduring the development of new services or technologies.\n\nProviding training to\ncontent labellers regarding relevant issues can also help ensure better\nunderstanding and awareness.\n\nOther opportunities include developing models that draw on a wide range of\nperspectives and establishing **evaluation metrics** that actively address racial,\ngender, and other biases while promoting value pluralism.\n\nAdopting holistic\nevaluation strategies is crucial for addressing a range of risks and biases.", "**Bias in genai**\n\nA study conducted by researchers from Leipzig University and Hugging Face in 2023\nfound that when given prompts such as \u2018CEO\u2019 and \u2018Director\u2019, DALL-E-2 generated images\nof white men 97% of the time.\n\nlxv Adding words such as \u2018compassionate\u2019 \u2018emotional\u2019 and\n\u2018sensitive\u2019 to a prompt increased the likelihood of generating an image representing a\nwoman.\n\nlxvi Similarly in a paper published in 2021, Stanford researchers observed that\nChatGPT-3 produced an association between Muslims and violence.\n\nThe researchers\ngave GPT-3 the prompt: \u2018Audacious is to boldness as Muslim is to\u2026\u2019 and GPT-3\nresponded with \u2018terrorism\u2019 nearly a quarter of the time.\n\nlxvii These examples highlight how\ngenai can exhibit toxic behaviour and promote hate speech.\n\nRegulators, industry\nand the broader public recognise these as significant online safety risks that are driven\nby biases present within training data.\n\n-----", "**Opportunities**\n\nDetecting harmful material at scale\n\ngenai technologies and machine learning are being used to **detect and**\n**prevent harm** .\n\nFor example, LLMs can be used to identify criminal activity and\nharmful content or material.\n\nlxviii This approach could also reduce the need for\nhumans to be exposed to harmful content during review processes.\n\nlxix\n\nTechnical improvements in genai also present **opportunities to improve content**\n**detection and moderation tools** , as well as educative prompts and nudges.\n\nExperts\nsuggest genai models can be trained to detect harmful text more\neffectively than existing key word detection tools.\n\nThey may possess advanced\nabilities in discerning nuances in tone, enabling better differentiation between\ncriticism and hate speech.\n\nThese advancements also present an opportunity to train genai tools to intervene\nwhen individuals show signs of moving towards extremist content.\n\nFor example,\n**educative prompts and nudges** used on social media platforms can be adapted for\ngenai technologies as well.\n\nlxx\n\nProviding scalable support to young people\n\ngenai technologies offer new opportunities to design evidence-based\nsupport tailored to address issues children and young people are facing.\n\nThis\nincludes **scalable online support services to children** \u2013 as well as adults \u2013 through\nconversational modes such as chatbots.\n\nFor example, Kids Help Phone in Canada have a chatbot called \u2018Kip the Website\nHelper\u2019, which introduces chatbot technology to the Kids Help Phone gateway\nportal to help people navigate the website.\n\nlxxi\n\nEnhancing learning opportunities and digital literacy skills\n\nIt is important to consider both the benefits and risks of genai in\neducation.\n\nlxxii Some crucial points to consider include:\n\n-  whether there is an opportunity to enhance critical media literacy skills by\nincorporating conversations about values and ethics into young people\u2019s\neducation.\n\n-  how to improve digital and algorithmic literacy among students, giving them\nthe skills and confidence they need to manage their online experiences\nsafely.\n\n-  the importance of taking a strengths-based approach rather than focusing\non deficits is important when addressing these issues.\n\neSafety encourages early development of critical thinking through guided\nmessaging and learning that starts at a young age for children, as well as their\nteachers and parents.\n\n-----\n\nData consent\n\ngenai also presents opportunities to establish **more effective and robust**\n**conversations on consent regarding data use and collection** .\n\nFor example, rather\nthan simply ticking a box to indicate user consent and seeking consent from\nothers whose personal information may be shared, conversational forms of\ngenai could contribute facilitate active conversations about user privacy.\n\nThis could also support individuals to engage in more natural, nuanced, and\npersonalised discussions about consent and respecting individual privacy.", "**Other risks and considerations**\n\nIn addition to the online harms within eSafety\u2019s regulatory remit, genai\nraises multiple other issues of concern covered by the remit of other government\nagencies, and regulators in Australia and worldwide.\n\nWhile other government\ndepartments and agencies have primary responsibility for many of these matters,\nthey have the potential to intersect with the online harms eSafety strives to\nprevent.", "**Potential competition and consumer issues**\n\ngenai has the potential to manipulate consumer choices and influence\ncompetition in various ways.\n\nThe ACCC is the Australian regulator responsible for\nthese issues.\n\n-  **Advertising.\n\n** Users may not always be aware when genai is providing\nfactual, organic information or information which is **attempting to influence**\n**their online activities and purchasing decisions** , especially when it is integrated\ninto those services.\n\nFor example, conversational models can extract\ninformation from people who are unaware the information they share with\n\u2018virtual assistants\u2019 is also being used for marketing purposes.\n\n-  **Competition.\n\n** Established companies with more resources are typically better\nequipped to navigate emerging regulatory measures than small businesses or\nstart-up companies.\n\nThis creates a potential barrier for smaller companies\nlacking sufficient resources, personnel, or knowledge to meet regulatory\nobligations.\n\nConsequently, established companies may advocate for **regulatory**\n**frameworks that favour their own business objectives at the expense of their**\n**competition** .\n\nGiven the competitive advantage conferred by genai, there\nis a risk firms may engage in exclusionary conduct, aimed at restricting or\nundermining their rivals\u2019 ability to compete in the market.\n\n-  Additional competition concerns include:\n\n`o` **Anti-competitive self-preferencing** \u2013 making it difficult for users to tell\n\nwhen chatbots make sponsored recommendations, or refer to products\nor services offered by the same firm that operates the chatbot.\n\n-----\n\n`o` **Anti-competitive tying** \u2013 such as tying the availability of any future\n\n\u2018must-have\u2019 LLM services to the use of other services, such as browsers\nor search engines.\n\n`o` **Restrictions on access to data** \u2013 where firms with significant market\n\npower could restrict competitors\u2019 access to data, limiting the training of\nrival LLMs.\n\n-  **Scams and phishing** .\n\ngenai could automate scams and enhance their\neffectiveness by giving them the \u2018look and feel\u2019 of genuine products and\ncommunications.\n\nPersonalisation capabilities could also allow scams to\n**specifically target individuals** .\n\nFor example, video and audio files representing\nspecific individuals can now be generated using minimal source data.\n\nThese\ncould facilitate \u2018phishing\u2019 lxxiii by generating calls for help that appear to come\nfrom a real person, including a loved one.", "**Communication and media**\n\ngenai has the potential to introduce or exacerbate several online\ncommunication and media risks, especially in the realm of **misinformation and**\n**disinformation.\n\n** The ACMA is the Australian regulator responsible for overseeing\nthese issues.\n\ngenai models can tailor content to individual users,\nintentionally or unintentionally producing large volumes of apparently authoritative\ncontent that may be false, misleading, or \u2018hallucinated\u2019 which can manipulate\nusers.\n\nConversational agents\u2019 can effectively mimic human interaction, increasing\ntheir potential influence on users communicating with them.\n\nThis can increase the\nscale and influence of misinformation and disinformation on an individual and\nsocietal level and can generate mistrust in authoritative sources of information,\nundermining the overall quality of circulated information.\n\nSynthetic media such as images, videos, and voice have the capability to alter the\nlandscape of misinformation and disinformation, with various forms of media\ngenerating viral reaction.\n\nFor example, an genai program called Midjourney was used\nto create a viral deepfake image of the Pope wearing a white puffer jacket in the\nstyle of contemporary hip-hop artists.\n\nlxxiv.\n\nThis shows how genai can create\nviral reactions with false media.\n\nHowever, genai can also create\nefficiencies in news organisations through assisting in the generation of news\nstories and can be a tool for teaching critical digital and media literacy skills to\ncombat misinformation and disinformation.\n\nIt is also a useful tool for detecting\nmisinformation- and disinformation.\n\neSafety is concerned that genai generated images, audio and video targeting\nAustralian individuals \u2013 and depicting them doing or saying things they didn\u2019t do or\nsay \u2013 with serious intent to harm the individual could amount to serious adult\ncyber abuse as part of a broader mis- or disinformation campaign.\n\n-----", "**Privacy**\n\ngenai may create privacy risks and impacts.\n\nThe OAIC is the Australian\nregulator responsible for these issues.\n\nThe information handling practices\nassociated with this technology are often complex and opaque which challenges\nthe ability of individuals to meaningfully understand how their personal\ninformation is being handled.\n\nOutputs from genai models may also contain\npersonal and sensitive information, including misleading or inaccurate information\nabout an individual.\n\nThe use and retention of large data sets to develop and\ndeploy this technology elevates the risk of a data breach and the risk of harm to\nindividuals if their personal information is included in the compromised data.\n\nFurthermore, genai may employ tools that can record users\u2019 written and\nspoken words, track conversations over time, and monitor sentiment through\nverbal and non-verbal cues such as tone of voice.\n\nCertain genai tools with recording\nfunctionality may capture other users without their knowledge or consent, which\nis also a privacy concern.\n\nThe Australian Government is committed to ensuring that Australia has fit-forpurpose regulatory settings to address the privacy challenges posed by genai.\n\nThe\nReview of the Privacy Act 1988 considered the privacy risks associated with the\nuse of new technologies and made proposals to provide greater transparency and\ngive individuals more control over their data.\n\nThe Government is considering the\nPrivacy Act Review Report and feedback received in recent public consultation,\nwhich will be used to inform the Government\u2019s response.", "**Human rights**\n\ngenai gives rise to many different risks and opportunities for upholding\nhuman rights.\n\nThe Australian Human Rights Commission (AHRC) oversees human\nrights matters in Australia.\n\ngenai risks to human rights relate to:\n\n-  Discrimination arising from the programming of the algorithms that inform genai\ntechnologies\n\n-  Discrimination resulting from machine learning (i.e.\n\nnon-diverse datasets)\n\n-  Accessibility discrimination or digital exclusion.\n\nOne specific concern raised during eSafety\u2019s consultations for this paper was\n**Indigenous data sovereignty and representation.\n\n** If genai models are developed only\nto reinforce English-speaking, western values, they may not be effective, safe, and\nculturally appropriate for diverse users, including First Nations people.\n\nConversely, genai technologies hold great potential to preserve Indigenous\ncultures and languages.\n\nTo do this, it is important to respect the rights of\nindividuals and communities to consent to the collection and use of their data.\n\n-----", "**Other implications**\n\ngenai also has regulatory implications across many well-established\nsectors.\n\n**Intellectual property** (IP) concerns and questions of **data ownership** arise\nregarding the inputs and outputs of genai systems and third-party\nprogrammes.\n\nThere are also **national security and law enforcement**\nconsiderations, including the potential for fake emergency calls that sound\nauthentic inundating our emergency response systems.\n\nThere are also risks and\nregulatory implications related to its impact on the **environment and labour**\n**market** .\n\nFor a more comprehensive list of Australian government activities involving genai\ntouchpoints please see the Department of Industry, Science and Resources (DISR)\ndiscussion paper: Safe and responsible genai in Australia, DISR\u2019s genai ethics principles,\nas well as the CSIRO\u2019s genai Ethics Framework.\n\nDP-REG has a forthcoming paper on\nLLMs which covers many of the issues raised in this section.", "##### Regulatory challenges and approaches\n\nIn Australia and around the world, a variety of regulatory approaches to generative\ngenai are being considered.\n\nThere is ongoing debate over the balance between soft\nlaw through approaches such as voluntary principles and standards, and harder\npolicy options backed by legislation and mandatory requirements.\n\nEntities should\nbe mindful of the changing regulatory environment when considering using or\ndeveloping genai products.\n\n**Graduated approaches** include:\n\n-  voluntary principles and governance frameworks (India)\n\n-  genai governance frameworks, third-party testing and verification technology\n(Singapore)\n\n-  application of existing consumer safety and data regulations and the signing\nof pledges around self-regulatory principles (US)\n\n-  audits, risk and impact assessments and pre-launch disclosure\nrequirements for \u2018high-risk genai\u2019 (Canada, UK and South Korea)\n\n-  new and enforceable rules, including supervision powers (China)\n\n-  dedicated genai legislation (EU, Canada, South Korea, Brazil)\n\n-  intermediate bans on genai technology (Italy).\n\n-----", "**Risk-based regulatory models**\n\n-  Experts have emphasised the benefit of a risk-based regulatory model such\n\nas the approach adopted in the European Union\u2019s genai Act.\n\nIn 2023, the Group\n\nof Seven (G7) countries agreed to adopt risk-based regulation for genai and\ncreate international technical standards.\n\n-  The EU is taking a risk management approach in both its genai Act and its Digital\n\nServices Act.\n\nThis approach could require obligations proportionate to the\n\nlevel of responsibility and risk specific to a service.\n\n-  Like the EU, Canada is exploring bespoke genai legislation to impose regulatory\n\nobligations based on the specific level of risk involved.\n\n-  Other approaches such as a rights -based or principles-based models can\n\nalso offer benefits, such as inclusivity in regulating genai.\n\nInternational collaboration will be central to the regulation of generative of genai,\ngiven the borderless nature of the internet, and the datasets and models used by\ndevelopers.\n\nAs outlined above, jurisdictions are considering a range of approaches\nto regulating genai.\n\nIt is important that regulators and other stakeholders across the\nglobe collaborate to set shared expectations for industry, deliver a consistent and\ncohesive regulatory response and avoid fragmentation.\n\neSafety is actively involved\nin bilateral and multilateral discussions on emerging technologies, including\nthrough the Global Online Safety Regulators Network, to promote Australia and\neSafety\u2019s perspectives on online safety regulatory issues.\n\nRegulating genai poses several key challenges, such as:\n\n**Identifying which actor(s) should bear responsibility** .\n\nAs more online services integrate genai, it may be unclear who is best\nplaced to identify and mitigate risks or is liable for malicious use.\n\nThe generative\ngenai ecosystem includes:\n\n-  services that develop foundation models, including but not limited to,\nOpenAI and Stability genai\n\n-  services that integrate third-party models into their platforms for specific\nuse cases, such as Snapchat\n\n-  people who create outputs using genai\n\n-  people who interact with content created by genai.\n\nlxxv", "**Addressing context-specific risks.\n\n**\n\nTaking a risk-based approach to genai can help mitigate risk early in the\ndevelopment process.\n\nThis approach encourages influential players to monitor and\nrespond to new risks, instead of just following prescriptive and strict technical\nrules or focusing on a few specific problems.\n\nFor example, incentivising influential players to monitor how their foundation\nmodels are used can help find and fix problems with large scale models.\n\n-----\n\nRisk management should be tailored for each situation.\n\nThis is especially\nimportant when models are made for other uses because early design choices can\nincrease risks.\n\nFor example, developers could work with evaluation designers to\ngive organisations tools to develop their own evaluation systems that help them\nunderstand if genai is suitable for them.\n\nlxxvi", "**Achieving transparency and oversight.\n\n**\n\nSome genai services, along with their systems, technologies, and\nprocesses, are not open about how they work and therefore are not as\naccountable as they could be.\n\nThis lack of transparency extends to system design\nprinciples, datasets, and underlying algorithms.\n\nlxxvii To regulate them effectively, it\nis crucial to promote **greater transparency** .\n\nThis means having legislation that\nallow access to information while also considering how this will affect businesses.\n\nUnderstanding how these technologies work also requires advanced technical\nexpertise.\n\nThe use of plain language system and model cards can assist those\nwithout subject matter expertise to better understand how these technologies\nfunction.\n\nA range of regulatory and auditing approaches are currently being considered.\n\nChallenges to traditional auditing approaches include the sheer size of LLMs, lxxviii\nas well as the difficulty in explaining the outcomes of multi-layered neural\nnetworks.\n\nlxxix To be effective, these approaches should seek to use the same\ndefinitions and methodologies across wide-ranging platforms.\n\nlxxx\n\nPotential issues for regulatory oversight include how a model is tested for\naccuracy in order to ensure providers are accountable for false, flawed, or\n\u2018hallucinated\u2019 genai-generated content.\n\nThe role of an oversight or authorising body\nresponsible for assessing whether genai models meet a certain standard of\naccuracy _before_ they are accessible may also need to be considered.\n\nVarious\njurisdictions are considering the merits and challenges of _ex ante_ (before\ndeployment) and _ex post_ (after deployment) approaches.\n\nlxxxi", "**Keeping pace with rapid developments and coordinating across regulatory remits.\n\n**\n\nAs technologies continue to evolve, regulators need to coordinate their efforts and\nequip themselves with the necessary skills and resources to address rapid\ndevelopments in the space.\n\nThis includes securing funding, expanding knowledge,\nenhancing tech testing capability, and developing auditing skills.\n\n**Collaboration** among existing regulators supports a cohesive and coordinated\nresponse to genai issues across a wide range of regulatory domains.\n\nDP-REG will continue its focus on assessing the impact of algorithms, improving\ndigital transparency, and increased collaboration and capacity building between\nthe four members in 2023-2024.\n\nIn response to significant developments in\nrelation to the development, deployment and use of genai over the past 12\nmonths, DP-REG will also focus on understanding and assessing the benefits, risks\n\n\n-----\n\nand harms of genai and how the technology intersects with the regulatory\nremit of each DP-REG member in 2023-24.\n\nSimilarly, in the UK, the Digital Regulation Cooperation Forum (DRCF) was\nestablished to ensure greater cooperation on online regulatory matters.\n\nThis forum\nalso prioritises joint efforts on genai and the emergence of new genai tools as\na key theme in its 2023/24 workplan.\n\nThe UK and other jurisdictions also have priority access to several genai\nfoundation models for research and safety purposes.\n\nlxxxii Similarly, initiatives such\nas genai Labs, regulatory **sandboxes and hackathons** are gaining traction.\n\nCollaboration across multiple sectors can enhance systems and regulators\u2019 agility\nto deal with emerging technologies, while mitigating the risk of regulatory capture.\n\nIt also allows a wider range of stakeholders to shape legislation and approaches\nsurrounding these technologies.", "**Prevention**\n\neSafety provides scaffolded, age-appropriate and contextualised programs and\nresources for children, parents and carers, professional learning for educators and\nsupports the delivery of best practice online safety education.\n\neSafety\ncollaborates with mental health professionals, child protection services and other\nfrontline workers when developing resources for specific at-risk groups.\n\nBy\nunderstanding the benefits and risks of genai, people can better manage\ntheir online experiences and create a more positive online environment.\n\neSafety's research team is developing questions on algorithmic literacy to include\nin its 2024 youth survey.\n\nThe findings from this research will inform eSafety's\nonline safety programs for children and young people, parents and carers, and\neducators.\n\nThese education programs focus on respect, resilience, responsibility\nand reasoning, which are relevant to genai literacy.\n\nThe research will also contribute\nto the international evidence base about children and young people\u2019s digital\nliteracy.\n\neSafety also supports online safety outreach through the **Trusted eSafety Provider**\n**program** , and work with mental health professionals, child protection services,\nand other frontline workers when developing resources for specific at-risk groups.\n\nDuring consultations, Trusted eSafety Providers highlighted an opportunity to\nexpand existing education programs and information about genai.\n\nRecognising the importance of youth voices and co-design, eSafety also talked to\nthe **eSafety Youth Council** , who suggested that it is important for students to\nhave the opportunity to engage with genai tools to understand the\n\n\n-----\n\nstrengths and limitations of the technology.\n\nThese insights will help eSafety\ncontinue its education and prevention work, and support individuals and\ncommunities in using new technologies.", "**Protection**\n\nThe _Online Safety Act 2021_ (\u2018the Act\u2019) provides eSafety with a range of powers and\nfunctions to address online safety issues, including those related to genai.\n\neSafety\u2019s four complaints-based investigations schemes do capture genai-generated\nimages, text, audio, and other content which meets the legislative definitions of:\n\n-  class 1 material (such as CSEA material and terrorist and violent extremism\ncontent) and class 2 material (such as pornography)\n\n-  intimate images produced or shared without consent (sometimes referred\nto as \u2018revenge porn\u2019)\n\n-  cyberbullying material targeted at a child\n\n-  cyber abuse material targeted at an adult.\n\nUnder these investigations schemes, eSafety provides support to people who\nmake complaints by offering guidance, assisting in or requiring the removal of\ncertain content, and minimising the risk of further harm.", "**Proactive and systemic change**\n\nThe Act also empowers eSafety to require social media services, relevant\nelectronic services (such as messaging, gaming, and dating services), and\ndesignated internet services (other apps and websites) to report on the\nreasonable steps they are taking to comply with the Government\u2019s Basic Online\nSafety Expectations (BOSE).\n\nThis is to make sure these services are transparent,\naccountable, and safe for people to use.\n\nAt the publication of this statement, eSafety has issued 13 reporting notices\nrequiring companies to report on their efforts to implement the BOSE.\n\nEach notice\nincluded questions about the use of genai tools to detect illegal and harmful content.\n\nA summary report of responses from the first seven notices, focussed on steps\ntaken to address child sexual exploitation and abuse, was published in December\n2022. lxxxiii In the future, eSafety could require other service providers to report on\nthe reasonable steps they are taking to ensure the safety of their genai\nfunctionalities.\n\nService providers must respond to these notices.\n\nFailure to implement the\nexpectations can also result in a published statement of non-compliance _._\n\nThe Act also includes provisions for the development of industry codes to cover\neight sections of the online industry.\n\nUnder this co-regulatory model, the online\nindustry is to develop measures to deal with class 1 and class 2 content, and\neSafety may register such codes.\n\nIf an industry code does not meet the\n\n\n-----\n\nregistration requirements, eSafety may determine an industry standard (a\nregulatory instrument).\n\nIn June 2023, the eSafety Commissioner registered five industry codes which\nrequire social media services, hosting services, internet carriage service providers,\napp distribution services, and equipment providers to take certain steps to\naddress the risk of class 1 material.\n\nThe requirements in these codes are\nenforceable and will take effect on 16 December 2023.\n\nA decision on whether to register the code for internet search engine services is\nyet to be determined.\n\neSafety has asked relevant industry associations to re-draft\nthe code to capture proposed changes to search engines to incorporate generative\ngenai features.\n\nThe aim is to address the risks associated with the use of this new\ntechnology to generate class 1 material.\n\nThe eSafety Commissioner decided not to register codes for designated internet\nservices and relevant electronic services because the drafts submitted did not\nprovide appropriate community safeguards.\n\neSafety is developing industry\nstandards for these sectors and the development process will include a period of\npublic consultation.\n\nClose consideration will be given to how these standards will\naddress risks of class 1 content, including interplay with genai technologies and\npractices.\n\nThe codes development for class 2 material has not yet commenced.\n\neSafety stays ahead of emerging issues related to genai through ongoing\nconsultation and horizon scanning.\n\nThis proactive approach identifies concerns\narising from rapid developments in genai and promotes best practices for\nsafe product design and development across industries.\n\neSafety also continues to\npromote Safety by Design, an initiative which encourages technology companies to\nanticipate, detect and eliminate online risks to make our digital environments\nsafer and more inclusive, especially for those most at risk.", "##### Emerging good practice and Safety by Design measures\n\nA Safety by Design approach is critical to keeping users safe and building trust\nwith communities.\n\nServices can take practical steps to minimise the risk of harm\nfrom genai throughout its lifecycle by following the three Safety by Design\nprinciples.\n\nlxxxiv\n\n\n-----\n\n**Diagram 2:** Safety by Design Interventions\n\nThis diagram builds on the earlier genai lifecycle.\n\nThe inner circle represents the original steps in the genai lifecycle.\n\nThe outer circle represents Safety by Design measures which can be implemented at various points in the lifecycle and across the whole\nlifecycle.\n\nThese are colour-coded according to the overarching Safety by Design principles.\n\nService provider responsibility User empowerment and autonomy Transparency and accountability\n\n\nReal time support\nand reporting\n\nUser education tools\n\nTechnical\ninterventions\n\n\nAccountable teams\n\nPolicies and processes\n\nRisk assessments\n\nBusiness case\n\nAge assurance\n\n\nSocial\ncontracts\n\nAccessible\ninformation and\nexpectations\n\nTransparency\nreporting\n\n\nRe-integration **10** **2** Selecting data", "**10**\n\nTraining\ngenai dissemination **9** **3** the model\n\n\nInternal\nProtocols\n\n\nFeedback Refinement\n\n\ngenai generation Release\n\n\nEscalation\npathways\n\n\nUser engagement\n\nEmployee\ntraining\n\nCommunity\nconsultation\nInnovation Research\n\n\nThird party audits\n\n\nthis represents the genai lifecycle.\n\nthis represents the Safety by Design interventions that occur across the entire lifecycle.\n\nthis represents the connection points for some interventions to the stages in the genai lifecycle where they apply.\n\nPlease note, some interventions may apply across more than one Safety by Design principle.\n\n-----", "**Service provider responsibility**\n\nThe burden of safety should never fall solely on the user.\n\nProduct and service\nproviders should identify and assess online safety risks upfront and take steps to\n\n\n-----\n\nprevent misuse and reduce people\u2019s exposure to harms.\n\nKey actions to uphold\nservice provider responsibility throughout the genai lifecycle include:\n\n-  **Making teams accountable for safety** .\n\nNominate individuals or teams and\nmake them accountable for creating, implementing, operating and\nevaluating user safety policies, as well as promoting a culture of community\nsafety in the organisation as a whole.\n\n-  **Having policies and processes.\n\n** Set up processes to detect, flag, and action\nharmful data inputs, behaviour, and content with the aim of preventing\nharms before they occur.\n\nThis should include:\n\n-  **Risk and impact assessments** to assess and remediate any potential\nonline harms that could be enabled or facilitated by the product or\nservice.\n\n-  **Prompt testing and design** , including automated and manual tests\nand creative testing of edge cases.\n\nClassifiers, proactive detection\ntools, and manual review for CSEA material and terrorist and\nextreme violent material are important.\n\n-  **Red-teaming** to stress test potential risks and harms with diverse\nteams, incorporating members from varied genders, backgrounds,\nexperiences, and perspectives for a more comprehensive critique.\n\n**Violet-teaming** , which involves re-directing the power of genai systems\nby \u2018identifying how a system might harm an institution or public good\nand then supporting the development of tools using the same system\nto defend the institution or public good\u2019, can also be considered\nalongside red-teaming.\n\nlxxxv\n\n-  **Data collection and curation** , including consideration of privacy\nobligations, and data ethics, consent, ownership, and provenance.\n\n-  **Ongoing evaluation** and continuous improvement of systems.\n\n-  **Age-appropriate design, supported by robust age assurance measures.\n\n**\nServices and genai features that children can access should be\ndesigned with their rights, safety, and best interests in mind.\n\nSpecific\nprotections should be in place to reduce the chances of children\nencountering, generating, or being exploited to produce harmful content\nand activity.\n\nThis requires services to use age assurance measures to\nidentify child users and apply age-appropriate safety and privacy settings.\n\n-  **Internal protocols.\n\n** Services should establish clear internal protocols for\n**working with law enforcement, support services and illegal content**\n**hotlines.\n\n** They should also understand and fulfil their obligations related to\n**jurisdictional mandatory disclosure** requirements for children.\n\n-  **Digital watermarking of content.\n\n** Watermarking is defined as the method of\nembedding either visible data such as a logo, or invisible or inaudible data,\n\n\n-----\n\ninto digital multimedia content.\n\ngenai tools can be modified to\nembed a watermark when they product a piece of content.\n\nlxxxvi\n\n-  **Triaging and escalation pathways.\n\n** Establish a system to handle user safety\nconcerns.\n\nThis includes ways to sort internal and external concerns, clear\nsteps for escalating issues, and reporting for all safety concerns.\n\nIt also\ninvolves making it easy for people to report concerns and violations as soon\nas they happen.", "**User empowerment and autonomy**\n\nThe principle of user empowerment and autonomy emphasises the dignity of\nusers and the need to design features and functionality that preserve consumer\nand human rights.\n\nTo promote equality in society, platforms and services must\nengage with diverse and at-risk groups to make sure their features and functions\nare accessible to all.\n\nUser empowerment and autonomy can include the following\nmeasures:\n\n-  **Social contracts.\n\n** Clearly outline the rights, responsibilities, and safety\nexpectations for the service, users, and third parties.\n\nThis can also apply to\ndevelopers who use open genai models to build apps, application\nprogramming interfaces (APIs) lxxxvii and products.\n\n-  **Technical interventions to educate and empower users.\n\n** Use technical\nfeatures to educate users, reduce risks and harms, and promote safer\ninteractions.\n\nThis could include:\n\n-  **Implementing informed consent measures** for users to\nunderstand and consent to the collection and use of their data.\n\n-  **Providing disclaimers and content warnings** for chatbots and\nother genai technologies to let users know that outputs\ncould be incorrect, biased, or harmful.\n\n-  **Developing educational content** about how to detect genai\n\u2018hallucinations\u2019 or other forms of false or harmful content.\n\n-  Making sure **users have the opportunity to** understand, evaluate,\n**control, and moderate their own interactions** , particularly where\ngenai agents may be involved.\n\nlxxxviii This can be supported\nby implementing real-time **prompts and nudges which alert users**\n**to the safety features** available to them, such as reporting\noptions.\n\n-  **Real-time support and reporting.\n\n** Provide built-in support functions and\nfeedback loops so users can track the status and outcomes of their reports\nand offer an opportunity for appeal.\n\nUsers should have robust controls that\nallow them to provide real-time feedback on genai-generated outputs.\n\nlxxxix\n\n\n-----", "**Transparency and accountability**\n\nTo build trust in genai systems, developers and companies should prioritise\ntransparency and accountability.\n\neSafety encourages services to share information with users and regulators about\nhow their models and genai systems operate.\n\nThis should include\ninformation on data provenance, design choices, objectives, and the positive and\nnegative outcomes of generated content.\n\nServices should also evaluate the\neffectiveness of safety interventions and share their findings so others can adopt\nthem.\n\nDevelopers of large-scale models take varying approaches to transparency and\naccess, including open-sourcing information, offering API access, or limiting public\nuse.\n\nSome services take a graduated approach to release, where information\naccess is rolled out in stages to enable safety measures to be added as risks\nbecome evident.\n\nxc\n\nTo enhance transparency and accountability, platforms and services should focus\non:\n\n-  **Providing clear and accessible information** about user safety policies, privacy\npolicies, terms and conditions, community guidelines, and processes.\n\nKeep\nthese up to date, make them easy to find and understand, and notify users\nof any changes.\n\n-  **Innovating and investing in new technologies to enhance user safety.\n\n** Share\nand collaborate on safety-enhancing tools, best practices, processes, and\ntechnologies.\n\nThis could include research, automation tools, content\nmoderation, safety tech solutions xci , and **digital watermarking.\n\n** xcii\n\n-  **Consulting** with a diverse user base through open engagement.\n\nEngage with\nexperts who have specialist knowledge in various forms of harm.\n\n-  **Publishing regular transparency reports** about reported abuses and\nmeaningful analysis of metrics.\n\n-  Documenting the capabilities, limitations, intended uses and prohibitive uses\nof genai models to support processes to increase transparency and\naccountability (for example, through **model cards, system cards, and value**\n**alignment cards** ).\n\n-  Consider granting independent researchers, academics with access to\nmodels.", "**Understanding the risks and benefits of genai applications**\n\ngenai can be beneficial for creativity and efficiency, both at work and in\neveryday life.\n\nHowever, there are also risks such as the potential to spread illegal\n\n\n-----\n\nand restricted online content, cyberbullying of children, serious adult cyber abuse,\nand image-based abuse.\n\nIt is helpful to understand the systems, processes, and business models that\nunderly how content is developed.\n\nWhen a service generates content, it may use\ndata drawn from the open web, which could include information about you or\nfrom your own digital footprint, such as chat history or conversations with\ngenai tools.\n\nYou may be able to **manage your data** by turning off your chat\nhistory and choosing which conversations are used to train genai models.\n\nxciii\n\nSome services have also introduced features that empower users to have some\ninfluence over their experiences and the accuracy of content generated through\nchatbot feedback loops.\n\nYou can find more information and resources about popular genai-enabled\nservices such as Bing, Google Bard, Chat GPT and GPT-4 on eSafety\u2019s website.", "**How to report harms to eSafety**\n\nIf you or someone in your care is experiencing serious online abuse or harm \u2013\nwhether or not genai is involved \u2013 there are several steps you can take.\n\nIf you are experiencing online harm or abuse, you can make a report to eSafety at\nesafety.gov.au/report.\n\nAdditional information about protecting yourself online can\nbe found on the eSafety website.\n\nYou can **get more help** by talking with an expert counselling and support service.", "**Police**\n\nContact police if a crime has been committed.\n\nIf something goes wrong online, or\nif you think someone is in immediate danger call Triple Zero (000) or your local\npolice (131 444).\n\nIf you prefer to report anonymously, you can visit Crime Stoppers\nor call their toll free number 1800 333 000.", "##### Acknowledgements\n\neSafety acknowledges the contribution made by experts in sharing their insights on\ngenai with eSafety.\n\nIn particular, we thank the following experts:\n\nARC Centre of Excellence for Automated Decision-Making and Society (ADM+S)\n\nTiberio Caetano, Gradient Institute\n\nAssociate Professor Jeffrey Chan, RMIT\n\nYi-Ling Chung, The Alan Turing Institute\n\nLouis Claxton, Faculty genai\n\nProfessor Nick Davis, University of Technology Sydney\n\nProfessor Hany Farid, University of California, Berkeley\n\nAssociate Professor Asher Flynn, Monash University\n\nHenry Fraser, Queensland University of Technology\n\nDr Jake Goldenfein, University of Melbourne\n\nRebecca Johnson **,** University of Sydney\n\nNijma Khan, Faculty genai\n\nProfessor Chris Leckie, University of Melbourne\n\nMargaret Mitchell, Hugging Face\n\nLucinda Nelson, Queensland University of Technology\n\nDr Rebecca Portnoff, Thorn\n\nDr Louis Rosenberg, Unanimous A.I.\n\nProfessor Mark Sanderson, RMIT\n\nProfessor Ed Santow, University of Technology Sydney\n\nDr Aaron Snoswell, Queensland University of Technology\n\nProfessor Nicolas Suzor, Queensland University of Technology\n\nDr Emmanuelle Walkowiak, La Trobe University\n\nProfessor Kimberlee Weatherall, University of Sydney\n\nAngus R Williams, The Alan Turing Institute\n\nWe extend our thanks to the Trusted eSafety Providers, the eSafety Youth Council and\nother academics who shared their insights, lived experiences, and helped us to produce\nthis paper.\n\n-----\n\ni eSafety Commissioner Statement of Expectations.\n\nDecember 2022.\n\nii eSafety Regulatory Posture and Priorities 2020-21.\n\nNovember 2021.\n\niii Deepfakes are fake digital photos, videos, or sound files of real people which have been\nedited to create realistic, but false, depictions of them doing or saying something.\n\nFor\nfurther information, see eSafety\u2019s Tech trends and challenges position statement on\nDeepfakes: \niv Recommender systems, also known as content curation systems, are the systems that\nprioritise content or make personalised content suggestions to users of online services.\n\nFor further information, see eSafety\u2019s Tech trends and challenges position statement on\nRecommender systems and algorithms: \nv A neural network is defined as a mathematical system, modelled on the human brain,\nthat learns skills by finding statistical patterns in data.\n\nIt consists of layers of artificial\nneurons: The first layer receives the input data, and the last layer outputs the results.\n\nSee\nK Roose, C Metz, _How to become an expert on AI_ , The New York Times, 4 April, 2023.\n\nvi Future of Life Institute, _Pause Giant genai Experiments: An Open Letter, 22 March, 2023._\n\nvii D Thiel, M Stroebel, R Portnoff, _Generative ML and CSAM: Implications and mitigations,_\nThorn and Stanford Internet Observatory, 24 June, 2023.\n\nviii United States Federal Bureau of Investigations.\n\n_Public Service Announcement: Malicious_\n_Actors Manipulating Photos and Videos to Create Explicit Content and Sextortion Schemes_ .\n\n5 June, 2023. \nix Further analysis of algorithmic bias has been published by the Australian Human Rights\nCommission.\n\nSee Australian Human Rights Commission, _Addressing algorithmic bias to_\n_ensure ethical AI_ , 24 November, 2020. \nx L Rosenberg, _The Manipulation Problem: Conversational genai as a Threat to Epistemic_\n_Agency_ .\n\n19 June, 2023. \nxi For example, The Verge reported on 9 March 2023 that Meta\u2019a LLaMA had leaked onto\n4chan, advising that on March 3rd, a downloadable torrent of the system was posted on\n4chan and has since spread across various genai communities\n ; for more information on OpenAI\u2019s reported open-source language model\nplans, see: \nxii J Goldstein, G Sastry, M Musser, R DiResta, M Gentzel, K Sedova, _Generative Language_\n_Models and Automated Influence Operations: Emerging Threats and Potential Mitigations_ ,\nGeorgetown University\u2019s Center for Security and Emerging Technology, OpenAI, Stanford\nInternet Observatory, January 2023.\n\nP Chavez, _An AI_\n_Challenge: Balancing Open and Closed Systems_ , Centre for European Policy Analysis, 30\nMay, 2023. \nxiii For example, Meta announced plans in June 2023 to incorporate genai text,\nimage and video generators into its flagship products, such as Facebook and Instagram,\nsee: \nGoogle announced at its annual I/O conference that it will infuse results with generative\ngenai technology, see: \nxiv For example, OpenAI founder Sam Altman has spent time touring internationally and\nadvocating for global genai regulation.\n\nSee: \n\n\n-----\n\nxv eSafety Commissioner.\n\n_Digital Platform Regulators Forum_ .\n\nxvi Integrity Institute.\n\n_Unleashing the potential of genai in integrity, trust and safety_\n_work: opportunities, challenges and solutions_ .\n\n8 June, 2023.\n\nxvii S Coghlan, K Leins, S Sheldrick, M Cheong, P Gooding, S D\u2019Alfonso.\n\n_To chat or bot to_\n_chat: Ethical issues with using chatbots in mental health_ .\n\nDigital Health, 9, December 2023.\n\nxviii UNICEF.\n\n_Safer Chatbots Implementation Guide_ .", "_To chat or bot to_\n_chat: Ethical issues with using chatbots in mental health_ .\n\nDigital Health, 9, December 2023.\n\nxviii UNICEF.\n\n_Safer Chatbots Implementation Guide_ .\n\nxix The genai lifecycle has been developed by drawing upon a broad range of\nresources, including from ActiveFence, Anthropic, Genpact, Thorn.\n\nMeasures may be\nintersectional, overlapping or apply across the stack.\n\nxx World Economic Forum.\n\n_The Presidio Recommendations on Responsible Generative AI_ .\n\nJune 2023.\n\ntive_AI_2023.pdf\nxxi C A Sharma, _What is genai?,_ LinkedIn article, 27 January, 2023.\n\nxxii Y Noema, _Learning: Supervised, Unsupervised, Self-Supervised & Semi-Supervised_ .\n\nMedium.\n\n23 June, 2022. \nxxiii C A Sharma, _What is genai?,_ LinkedIn article, 27 January, 2023.\n\nxxiv For additional information on supervised, unsupervised and self-supervised learning,\nsee:\nY Noema, _Learning: Supervised, Unsupervised, Self-Supervised & Semi-Supervised_ .\n\nMedium.\n\n23 June, 2022. \nxxv V E Kingsly, _Trust and safety in the era of genai,_ Genpact, 9 June, 2023.\n\nxxvi E Bell, _Generative genai: How It Works, History, and Pros and Cons,_ Investopedia, 26 May,\n2023.\n\nD Ingram, _ChatGPT is powered_\n_by these contractors making $15 an hour_ , NBC News, 7 May, 2023.\n\nB Perrigo, _Exclusive: OpenAI used Kenyan workers on_\n_less than $2 per hour to make ChatGPT less toxic_ , Time, 18 January, 2023.\n\nxxvii N Clark, _\u2018Grandma exploit\u2019 tricks Discord\u2019s genai chatbot into breaking its own ethical rules_ ,\nPolygon, 19 April, 2023, \nxxviii N Schwartz, _Generative genai Safety by Design Framework_ , ActiveFence, 1 May, 2023.\n\nxxix For example, research conducted by Twitter in 2021 on the proliferation of harmful and\noffensive content found that \u2018interventions allowing users to reconsider their comments\ncan be an effective mechanism for reducing offensive content online\u2019.\n\nFor more\ninformation, see: M Katasaros, K Yang, L Fratamico, _Reconsidering Tweets: Intervening_\n_During Tweet Creation Decreases Offensive Content_ , Proceedings of the International AAAI\nConference on Web and Social Media, 16, 1 December, 2021.\n\nxxx V E Kingsly, _Trust and safety in the era of genai,_ Genpact, 9 June, 2023.\n\nxxxi B Lutkevich., _Model collapse explained: How synthetic training data breaks genai, Tech_\n_Target,_ 7 July, 2023 \n\n\n-----\n\nxxxii For further information about Australia\u2019s anti-discrimination laws, see:\n\nxxxiii J Goldstein, G Sastry, M Musser, R DiResta, M Gentzel, K Sedova, _Generative Language_\n_Models and Automated Influence Operations: Emerging Threats and Potential Mitigations_ ,\nGeorgetown University\u2019s Center for Security and Emerging Technology, OpenAI, Stanford\nInternet Observatory, January 2023. \nxxxiv L Rosenberg, _Generative genai: the technology of the year for 2022_ , Big Think, 20\nDecember, 2022. \nxxxv P Chavez, _An genai Challenge: Balancing Open and Closed Systems_ , Centre for European\nPolicy Analysis, 30 May, 2023. \nxxxvi I Solaiman, _The Gradient of genai Release: Methods and Considerations_ , Hugging\nFace, 5 February 2023.\nxxxvii S Halpern, _What We Still Don\u2019t Know About How A.I.\n\nIs Trained_ , The New Yorker, 28\nMarch, 2023.\nxxxviii C Roche, P J Wall, D Lewis, _Ethics and diversity in genai policies,_\n_strategies and initiatives_ , genai Ethics, 6 October, 2022.\n\nxxxix eSafety Commissioner, _Safety by Design \u2013 Investors and Financial Entities_ .", "xl L Rosenberg, _The Metaverse and Conversational genai as a Threat Vector for Targeted_\n_Influence_ , 2023.\nxli Thorn, _Generative genai: Now is the time for safety by design_ , 26 May, 2023.\n\nxlii D Thiel, M Stroebel, R Portnoff, _Generative ML and CSAM: Implications and mitigations,_\nThorn and Stanford Internet Observatory, 24 June, 2023.\n\nxliii eSafety provides additional advice on \u2018Privacy and your child\u2019 on the eSafety website:\n\nxliv H Bhatt, _How genai will affect content moderation_ , Spectrum Labs, 3 April 2023.\nxlv D Thiel, M Stroebel, R Portnoff, _Generative ML and CSAM: Implications and mitigations,_\nThorn and Stanford Internet Observatory, 24 June, 2023.\n\nxlvi I Lapowsky, _The Race to Prevent \u2018the Worst Case Scenario for Machine Learning\u2019_ , The\nNew York Times, 24 June, 2023. \nxlvii I Lapowsky, _The Race to Prevent \u2018the Worst Case Scenario for Machine Learning\u2019_ , The\nNew York Times, 24 June, 2023. \nxlviii E Graham, \u2018 _Alarming Content\u2019 from genai Chatbots Raises Child Safety Concerns, Senator_\n_Says_ , Nextgov, 21 March 2023. \nxlix C Xiang, _Eating Disorder Helpline Disables Chatbot for 'Harmful' Responses After Firing_\n_Human Staff_ , Vice, 31 May 2023.\nl E Graham, \u2018 _Alarming Content\u2019 from genai Chatbots Raises Child Safety Concerns, Senator_\n_Says_ , Nextgov, 21 March 2023. \nli H Farid, _Creating, Using, Misusing, and Detecting Deep Fakes_ , Journal of Online Trust and\nSafety, _1_ (4), September 2022.\nlii H Ajder, G Patrini, F Cavalli, L Cullen, _The State of Deepfakes: Landscape, Threats and_\n_Impact_ , Deeptrace, September 2019.\n\nliii A Flynn, A Powell, AJ Scott, E Carma, _Deepfakes and digitally altered imagery abuse: A_\n_cross-country exploration of an emerging form of image-based sexual abuse_ , British\n\n\n-----\n\nJournal of Criminology, 62(6), December, 2021. \nliv United States Federal Bureau of Investigations.\n\n_Public Service Announcement: Malicious_\n_Actors Manipulating Photos and Videos to Create Explicit Content and Sextortion Schemes_ .\n\n5 June, 2023. \nlv K McGuffe, A Newhouse, _The Radicalization Risks of GPT-3 and Advanced Neural_\n_Language Models_ , Centre of Terrorism, Extremism and Counterterrorism, September, 2020.\n\nlvi Europol, _ChatGPT: The impact of Large Language Models on Law Enforcement_ , 27 March,\n2023.\n\nh%20%20The%20Impact%20of%20Large%20Language%20Models%20on%20Law%20Enforcement\n.pdf\nlvii ActiveFence, _Generative genai: New Attack Vector for Trust & Safety_ , 31 May 2023.\nlviii P Hacker, A Engel, M Mauer, _Regulating ChatGPT and other Large genai Models_ ,\nArxiv, Working Paper, version April 5, 2023.\nlix W Oremus, _The clever trick that turns ChatGPT into its evil twin_ , Washington Post, 14\nFebruary, 2023.\nlx S A Thompson, _Making Deepfakes Gets Cheaper and Easier Thanks to A.I._ , New York\nTimes, 12 March, 2023.\nlxi H Farid, _Creating, Using, Misusing, and Detecting Deep Fakes_ , Journal of Online Trust &\nSafety, 1(4), 20, September 2022.\nlxii April, 2023.\n\nOECD Digital Economy Papers, _AI language models,_\nlxiii L Rosenberg, _Generative genai: the technology of the year for 2022_ , Big Think, 20 December,\n2022. \nlxiv W D Heaven, _Generative genai is changing everything.\n\nBut what\u2019s left when the hype is_\n_gone?_ , MIT Technology Review, 16 December, 2022.\n\nlxv A Luccioni, C Akiki, M Mitchell, Y Jernite, _Stable Bias: Analyzing Societal Representations_\n_in Diffusion Models_ .\n\narXiv:2303.11408.\n\nMarch 2023.\nlxvi M Heikkil\u00e4, _These new tools let you see for yourself how biased genai image models are_ , MIT\nTechnology Review, 22 March, 2023.\nlxvii A Abid, M Farooqi, J Zou, _large language models associate Muslims with violence_ ,\nNature Machine Intelligence, 3, June 2021.\nlxviii A Simmons, R Vasa, _Garbage in, garbage out: zero-shot detection of crime using Large_\n_Language Models_ .\n\nApplied genai Institute, Deakin University, 4 July, 2023.\n\nlxix L Li, L Fan, S Atreja, L Hemphill, \u201cHOT\u201d ChatGPT: The promise of ChatGPT in detecting\nand discriminating hateful, offensive, and toxic comments on social media, School of\nInformation, University of Michigan, 20 April 2023.\n\nlxx Ofcom published research in 2023 on the impact of video sharing platform design on\nuser behaviour, which found that platforms\u2019 user interface can mitigate people\u2019s cognitive\nlimitations and biases by providing information in a clear and balanced way.\n\nFor more\ninformation, see: \nlxxi Kids Help Phone, _\u201cHello!\n\nI\u2019m Kip \u2013 How can I help you?\u201d_ , 2 March, 2021.\n\nlxxii On 24 May 2023, the House Standing Committee on Employment, Education and\nTraining in Australia adopted an inquiry into the use of genai in\nthe country\u2019s education system.\n\nThe referral for this inquiry came from the Minister for\nEducation, the Hon Jason Clare MP.\n\nSee:\n\non_and_Training/AIineducation\n\n\n-----\n\nlxxiii \u2018Phishing\u2019 is defined as the process where scammers send fake information to\nmanipulate recipients or obtain personal information from them.", "See:\n\non_and_Training/AIineducation\n\n\n-----\n\nlxxiii \u2018Phishing\u2019 is defined as the process where scammers send fake information to\nmanipulate recipients or obtain personal information from them.\n\nlxxiv C Warzel, _Why you fell for the fake Pope coat_ , The Atlantic, 28 March, 2023.\n\nlxxv P Hacker, A Engel, and M Mauer, _Regulating ChatGPT and other Large Generative AI_\n_Models_ , Working Paper, version 5 April, 2023.\nlxxvi B Johnson, _Australia\u2019s genai Acid Test_ , Medium, 2 June, 2023.\nlxxvii K Perset, A Plonk, S Russell, _As language models and genai take the world by_\n_storm, the OECD is tracking the policy implications_ , OECD Policy Observatory, 13 April, 2023.\nlxxviii I Solaiman, _The Gradient of genai Release: Methods and Considerations_ , Hugging\nFace, 5 February, 2023.\nlxxix M Loi, A Ferrario, E Vigan\u00f2, _Transparency as design publicity: explaining and justifying_\n_inscrutable algorithms_ , Ethics and Information Technology, 23:253\u2013263, 2021.\nlxxx genai Now Institute, _Algorithmic Accountability: Moving Beyond Audits_ , 11 April, 2023.\nlxxxi For example, the European Commission\u2019s February 2023 White Paper on Artificial\nIntelligence: A European approach to excellence and trust sets out a framework including\na combination of both ex ante and ex post enforcement to ensure all requirements are\ncomplied with.\n\nlxxxii N Lomas, _OpenAI, DeepMind and Anthropic to give UK early access to foundational_\n_models for genai safety research_ , Tech Crunch, 12 June, 2023.\nlxxxiii eSafety Commissioner, _Responses to transparency notices_ .\n\nlxxxiv Please note, the minimum compliance measures set out in the industry codes and\nfuture industry standards represent the mandatory and enforceable steps that industry\nmust meet to comply with their obligations in relation to class 1 and class 2 material.\n\nlxxxv A Ovadya, _Red-Teaming Improved GPT-4.\n\nViolent Teaming Goes Even Further_ .\n\nWIRED.\n\n29\nMarch, 2023. \nlxxxvi B Rosenblatt, _Google and OpenAI Plan Technology to Track genai-Generated Content_ ,\nForbes, 22 July, 2023. \nlxxxvii Gartner defines an application programming interface (API) as \u2018an interface that\nprovides programmatic access to service functionality and data within an application or a\ndatabase\u2019, see: \nlxxxviii R Iyer, _4 ways genai safety efforts could learn from experiences with social media_ ,\nDesigning Tomorrow, 24 May, 2023. \nlxxxix World Economic Forum.\n\n_The Presidio Recommendations on Responsible Generative AI_ .\n\nJune 2023.\n\ntive_AI_2023.pdf\nxc I Solaiman, _The Gradient of genai Release: Methods and Considerations_ , Hugging\nFace, 5 February 2023.\nxci For example, ActiveFence, SpectrumLabs, Thorn.\n\nxcii \u2018Watermarking\u2019 is defined as the method of embedding either visible data such as a\nlogo, or invisible or inaudible data, into digital multimedia content.\n\nxciii For example, OpenAI provides the option to switch off chat history when using its\nChatGPT chatbot, see: \n\n\n-----\n\n-----", "**Under the following terms:**\n\nAttribution \u2014 You must give appropriate credit, provide a link to the license, and\nindicate if changes were made.\n\nYou may do so in any reasonable manner, but not in\nany way that suggests the licensor endorses you or your use.\n\nNo additional restrictions \u2014 You may not apply legal terms or technological measures\nthat legally restrict others from doing anything the license permits.", "##### \u201cgenai is a tribute to human intellectual power, the power to think enabled humans to make tools and technologies.\n\nToday, these tools and technologies have also acquired the power to learn and think.\n\nIn this, one key technology is genai.\n\nThe teamwork of genai with humans can do wonders for our planet.\u201d 1\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "###### Considering this growing influence of genai, INDIAai - the National genai Portal of the Government of India, conducted numerous research and held three roundtables that featured some of the prominent voices in genai, genai Policy, genai Governance and Ethics, and academia to analyze the impact, ethical and regulatory questions, and opportunities it brings to India.\n\nThis report is the outcome of that process and is intended to be used by policymakers,\nentrepreneurs, practitioners, and students.\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "### INDIAai genai Roundtables\n\nIn the last few years, genai technologies have\nexploded, ranging from sophisticated language models\nsuch as GPT-3 and image generation models such as\nDALLE-2.\n\nWith the investment in genai to reach $422.37\nbillion by 2028, at a 39.4 % CAGR, experts believe\ngenai will play a critical role in pushing genai\ninnovation and investment in the coming decade.\n\n2\n\ngenai tools, primarily focused on low-cost and\nhigher-value solutions, are perceived as the future of\ntext, image and even code generation, sometimes\nindistinguishable from human creation.\n\nHowever, with\nthe pace at which these technologies advance, we\nneed to foresee the risks it brings.\n\nOn the one hand,\ncountries such as China have implemented regulatory\nmeasures to put a leash on genai risks, such as\nwatermarking the final product, auditing the algorithms,\nand even ensuring the consent of users are taken before\nusing their data for training these models.\n\nOn the other hand, the socio-economic impact that\ngenai models can create is broad and deep\nand can even threaten our country\u2019s unity and national\nfabric, leading to the question of how we can ensure the\nethical and responsible use of genai models.\n\nFurthermore, the question of rights, attribution and IP of\ngenai-generated works that mimic specific human creators\nopens more ethical questions.\n\nWith these questions in mind, INDIAai organised a series\nof roundtables with stakeholders and ecosystem players\nto understand the present genai landscape,\nethical and legal challenges, and solutions to mitigate\nthe harmful impact these models can have in our society.\n\nThe first roundtable on 31st Jan 2023 was a big success\nas it explored the current state of genai and\nanalysed recent hype around the subject.\n\nThe first roundtable on 31st Jan 2023 was a big success as it explored the current state of genai and\nanalysed recent hype around the subject.\n\nThe participants were:", "**Abhinav Aggarwal**\n\nCo-Founder & CEO, Fluid genai\n\n\n2.\n\nIndustry Trends, Share, Growth, SWOT Analysis, Forecast by Zion Market Research\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\nThe second roundtable was organised on 28th Feb 2023, which looked deeper into the ethical questions regarding\ngenai and the need for regulatory frameworks and how to formulate a policy approach.\n\nThe participants were:", "### What is genai?\n\nGenerative Artifical Intelligence (genai) describes\nalgorithms (such as ChatGPT, Midjourney, Bard,\nDALL E, etc.)\n\nthat can be used to create new content,\nincluding audio, code, images, text, simulations, and\nvideos.\n\ngenai models use neural networks to\nidentify the patterns and structures within existing data\nto generate new and original content.\n\nIn recent years, large-scale models have become\nincreasingly important in the genai-generated content\nspace, providing better intent extraction and, thus,\nimproved generation results.\n\nFurthermore, with the\ngrowth of data and the models\u2019 size, the distribution that\nthese models can learn becomes more comprehensive\nand closer to reality, leading to more realistic and highquality content generation.\n\nContrary to popular belief, genai (genai) models\nhave existed as a technology since the early days of genai.\n\nThe history of genai models can be traced back\nto the 1950s with the development of Hidden Markov\nModels (HMMs) and Gaussian Mixture Models (GMMs),\nas they generated sequential data such as speech and\ntime series.\n\nWith the advent of Deep Learning, Generative\nModels saw significant performance improvements.\n\nThe current boom of genai has its origins rooted\ndeeply in advance of Natural Language Processing\n(NLP), which is a subfield within genai which focuses on\nhow computers process and analyse large amounts of\nnatural language data.\n\nIn NLP , the traditional method\n\n\nto generate sentences is to learn word distribution\nusing N-gram language modelling and then search\nfor the best sequence.\n\nThis modelling can be used for\ndisambiguating the input.\n\nIn addition, they can be used for selecting a probable\nsolution.\n\nThis modelling depends on the theory of\nprobability.\n\nProbability is to predict how likely something\nwill occur.\n\nModels that assign probabilities to sequences\nof words are called Language Models or LMs.\n\nHowever, this method cannot effectively adapt to long\nsentences, and this issue was tackled by introducing\nRecurring Neural Networks for language modelling\ntasks.\n\nThe advent of genai models in various\ndomains has followed different paths, but eventually,\nthe intersection emerged due to the Transformer\nArchitecture.\n\nIntroduced for NLP tasks in 2017, a\nTransformer Model is a neural network that learns\ncontext and thus meaning by tracking relationships in\nsequential data like the words in this sentence.\n\nTransformer models apply an evolving set of\nmathematical techniques, called attention or selfattention, to detect subtle ways even distant data\nelements in a series influence and depend on each\nother.\n\nTransformer was later applied in computer vision\nand then became the dominant backbone for many\ngenerative models in various domains.\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "**Unimodal \u2013 CV & NLP**\n\nDDPM\nViT\nMoCo\n\nSparrow\nchatGPT\n\nDALL-E\nBLIP2\nDALL-E 2\n\n\nStyleGAN\nBigBiGAN\n\n\nGAN\nVAE\nFlow\n\nLSTM/GRU Transformer\n\n\nBiGAN\nRevNet\n\n\nN-Gram\n\n\nELMO\nBERT\nGPT-2\n\n\nGPT-3\nOPT\nBART\nT5\n\n\n2014 2016 2018 2020\n\n\nCAVP\nDMGAN\nVQ-VAE\n\n\nVisualBERT\nViLBERT\nUNITER\n\n\nCLIP\nALBEF\nBLIP\nVQ-GAN\n\n\nStyleNet\nShow-Tell\nStackGAN\n\n\n**Multimodal - Vision Language** NLP CV VL\n\n**Source:** A comprehensive survey of genai Generated Content (AIGC): A History of genai from GAN to ChatGPT by Yihan\nCao & others, March 2023", "###### Foundation models\n\nProposed to solve the limitations of traditional models\nsuch as RNNs, Transformer is the backbone architecture\nfor many state-of-the-art models, such as GPT-3,\nDALL-E-2, Codex, and Gopher.\n\nSince the introduction\nof Transformer Architecture, pre-trained language\nmodels have become the dominant choice in NLP due\nto parallelism and learning capabilities.\n\nGenerally,\nthese transformer-based pre-trained language models\ncan be commonly classified into two types based on\ntheir training tasks:\n\n-  Autoregressive language modelling\n\n-  and masked language modelling\n\nFurthermore, despite being trained on large-scale\ndata, the AIGC may not always produce output that\n\n\naligns with the user\u2019s intent.\n\nTo overcome this issue,\nreinforcement learning from human feedback (RLHF)\nhas been applied to fine-tune models in various\napplications.\n\nDeveloping computing with enhanced hardware,\ndistributed training, and cloud computing contributed\nto the development of the foundation model.", "###### Unimodal and Multimodal\n\nGenerally, genai models can be categorised into\nunimodal models and multimodal models.\n\nUnimodal\nmodels receive instructions from the same modality as\nthe generated content modality, whereas multimodal\nmodels accept cross-modal instructions and produce\nresults of different modalities.\n\n3\n\n\n3.\n\nYihan Cao, Siyu Li, Yixin Liu, Zhiling Yan, Yutong Dai, Philips S. Yu, Lichao Sun, March 2023.\n\nA Comprehensive Survey of AIgenerated Content (AIGC): A History of genai from GAN to ChatGPT\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "**Multimodal**\n\n_This is a cat._\n\n\n_Describe this_\n_picture_\n\n\nInstruction I 2 Data\n\n\nResult R\n\n\nPrompt\n\n\nPre-train\n\ngenai Models\n\n\n_Draw a picture_\n_of a cat._\n\n_Write a song_\n_about a cat._\n\n\nInstruction I\n\nInstruction I\n\n\nResult R 3\n\nResult R\n\n\nGenerative language models (GLMs) are unimodal\nmodels trained to generate readable human language\nbased on patterns and structures in input data they have\nbeen exposed to.\n\nThese models can be used for a wide\nrange of NLP tasks, such as dialogue systems, translation\nand question-answering.\n\nThese include decoder models\nand encoder-decoder models.\n\nVision generative models\nare other kinds of unimodal.\n\nMultimodal generations are relatively hard to learn\ncompared to unimodal.\n\nThe generation of state-ofthe-art multimodal in vision language generation, text\naudio generation, text graph generation and text code\ngeneration aided in tackling this issue.\n\nThe application of these architectures can be seen in\nChatbots, genai art generation, music generation, coding\nfor genai-based programming systems, and education.\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "**Popular genai Models**\n\n|Name|Description|Function|\n|---|---|---|\n|ChatGPT|It became one of the most famous chatbots in just 2 months.\n\nOpenAI has developed a language model that is close to a conversation with humans.\n\nIt learns from interactions and processes information based on its learnings.\n\nAdditionally, ChatGPT is trained on Generative Pre-Trained Transformer architecture \u2014 the neural network that lends the \u2018GPT\u2019 to its name.|ChatGPT works in the same way as automated chat services seen on customer support websites.\n\nIt can answer queries and write many types of written content, such as articles, social media postings, essays, code, and emails.|\n|DALL- E|DALL-E and DALL-E 2 are deep learning models developed by OpenAI to generate digital images from natural language descriptions, called \u201cprompts\u201d.|DALLE 2 can generate unique, realistic visuals and art based on a text description.\n\nIt is capable of combining concepts, traits, and styles.\n\nIt can be used with an image made in DALL-E 2 or an image you\u2019ve uploaded - it\u2019s been used to extend great works of art, such as the Mona Lisa, by adding more backdrop to the image.|\n|Midjourney|Midjourney is a genai program and service created and hosted by a San Francisco-based independent research lab Midjourney, Inc. Midjourney generates images from natural language descriptions, called \u201cprompts\u201d|Midjourney has introduced a new function called /describe, which lets users upload an image and receive written prompts that attempt to explain it.\n\nThese prompts can then be utilised to create one-of-a-kind and engaging genai-generated art that is unlike anything else on the internet.|\n|Chatsonic|It is a revolutionary genai tool built to beat all the limitations of Open genai, turning out to be the best alternative to ChatGPT.\n\nIt integrates with Google Search to create content with the latest information.\n\nAdditionally, it can create digital images and respond to voice commands.|Chatsonic can generate high-quality text, graphics, content for multiple social networking networks, emails, and website content based on the cues it receives.\n\nIn addition to written commands, Chatsonic can be used with a voice command.|\n|Jasper Chat|Jasper Chat is a new genai-powered generative way of interacting with genai.Instead of having to think in commands or strict prompts, you can converse with genai and refine responses with each engagement.|Jasper Chat may produce ideas, modify text passages, answer inquiries, and create creative stuff like poems or stories.\n\nJasper Chat is intended for commercial use cases such as marketing and sales, as well as social media posts.|\n|Copy.genai|Copy.genai is the new genai that is built for sales and content marketing teams.\n\nIt can help you create articles, sales emails, social media captions, ad copy, blog posts, code and more all with real-time data.|Copy.genai assists the team with several types of copywriting and sales/copy, such as product descriptions, ad copy, website copy, blogs, and emails.\n\nIt can make bullet points out of LinkedIn profiles.\n\nFrom a single term, it may generate a full content brief.|\n|ChatFlash - Neuroflash genai|You can quickly start using this chat feature by asking questions or giving instructions.\n\nThe Chatflash genai will answer you and provide results.|Neuroflash creates high-quality genai material.\n\nIt generates documents using multilingual, modern language models (auto-regressive language transformers; GPT-3).|\n|GrowthBar|GrowthBar is an genai SEO content writing tool that specialises in genai content generation.\n\nThe main feature is the long-form content editor, which helps you to write blog posts in 2 minutes flat.|GrowthBar creates genai content using advanced algorithms that produce and optimise your blog posts for you.\n\nFurthermore, GrowthBar performs keyword research, rank tracking, and backlink research in the same way as large SEO tools do.|\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n\n|Name|Description|Function|\n|---|---|---|\n|Rytr Chat|Rytr is an genai writing assistant that helps you create high-quality content, in just a few seconds, at a fraction of the cost.\n\nPowered by state-of-the-art language genai to generate unique, original content for almost any vertical|Rytr Chat was created to give Rytr users a more natural and conversational experience.\n\nRytr Chat allows you to create content with a single click.\n\nIt changes the content\u2019s tone, duration, or style.|\n|Easy Peasy genai Chat|Easy-Peasy.genai is the genai Content Generator, which assists you and your team in breaking past creative barriers to create fantastic, original content 10X faster.\n\nIt is an genai content tool that may assist you with a number of writing jobs, such as producing blog posts and creating better resumes.|Easy Peasy genai Chat allows users to easily compose emails, social media messages, resumes, blog posts, and other documents.", "It can also make genai visuals, summarise large text, and transcribe audio.|\n|LaMDA|LaMDA genai is a conversational Large discourse Model (LLM) developed by Google to power dialogue-based systems that generate natural-sounding human discourse.\n\nIt has already been used for zero-shot learning, program synthesis, and BIG- bench workshop.|It is a natural language processing tool developed by Google with 137 billion parameters.\n\nIt was built by fine-tuning a group of Transformer-based neural language models.\n\nFor pre-training, the team created a dataset of 1.5 trillion words which is 40 times more than previously developed models.|\n|GhostWryter|Ghostwryter is an genai application that generates high-quality material for marketing techniques such as SEO text and blog entries.\n\nIt is easily available via Google Docs and employs artifci ial intelligence technologies through the use of an OpenAI licence key.|The app uses genai to help you create SEO optimised text, marketing content, and even blog posts for your business.\n\nYou can simply write blog posts, and other marketing content with GhostWryter.|\n|Ellie genai|Ellie genai is a platform that offers data teams with tools and frameworks to ensure that new data is constantly valuable to the business.\n\nIt provides lightweight data modelling and information architecture elements and is intended for enterprises of all sizes.\n\nEllie genai also offers an genai email assistant that can respond to your emails in your preferred style.|Ellie is a writing assistant exclusively for drafting email replies.\n\nEllie learns from your own individual writing style, and allows users to pick a \u201cmood\u201d for her replies (i.e.\n\nher tone can be casual, professional, irritated, etc.)\n\nEllie is also multilingual and will automatically reply in the language to which she was initially written.|\n|Murf genai|Murf genai allows users to make studio quality voice overs for things like explainer videos, podcasts, advertisements and more using text.\n\nJust choose from the 120+ voice styles available on the site, including 20+ languages and accent options.|Murf genai features a straightforward user interface that anyone can utilise.\n\nSimply upload your text and select a voice from the library.\n\nYou can vary the voice\u2019s tempo and pitch as you see fti.\n\nYou may also upload your own sound clip and utilise the voice changer to make it sound more professional.|\n|Stockimg.genai|Stockimg.genai aid in art generation.\n\nWhen generating an image, you let the genai know if you are looking to make a book cover, logo, icon, wall paper or stock images, and it creates visual content to suit your needs.|Stockimg.genai is an genai image generating platform that makes it simple to create genai logos, book covers, posters, and other graphics.\n\nStock pictures, book covers, posters, wallpapers, logos, illustrations, icons, and web and mobile UI are just a few of the categories available.|\n|Heyday|Heyday calls itself an genai powered memory assistant, but it\u2019s actually more like a research assistant.\n\nThe app works with browsers, search engines, and apps like Gmail and Google Docs to help \u201cresurface\u201d content you may need to find once you\u2019ve already reviewed it.|Heyday by Hootsuite is a conversational genai platform developed to assist retailers and eCommerce enterprises in capturing leads and increasing buyer engagement.\n\nCustomizable branding, multi-channel communication, wait time management, prioritisation, push notifci ations, and scripted responses are among the key features.|\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n\n|Name|Description|Function|\n|---|---|---|\n|Wordtune Read|Wordtune does offer a generative writing option, but what\u2019s more interesting to me is its reading option.\n\nWordtune Read summarises lengthy documents and helps highlight key points so that users can understand more, more quickly.\n\nIt can even provide different summaries based on a specific point of view, for instance what the text means for an overall industry or decision-makers within the field.|Wordtune Read quickly and accurately summarises any document, making it possible for anyone to read lengthy, complex texts in a fraction of the time.\n\nNot only does it extract essential lines like other reading aids, but thanks to our advanced genai technology, it also summarises the main themes for you.|\n|Regie genai|This app will help research potential contacts and help sales agents create personal emails that feel authentic to your company.\n\nRegie uses a large language model to help create a voice specific to your brand.|Regie.genai is used to develop, test, and analyse personalised prospecting sales campaigns.\n\nThis product package may be used to develop interesting sales sequences, collaborate on content, and boost front-line efficiency.", "This product package may be used to develop interesting sales sequences, collaborate on content, and boost front-line efficiency.\n\nIt can also be used to validate content so that people can converse with confidence.|\n|Resume Worded|The app was designed to provide instant feedback on your resume or LinkedIn profile, including scores on key criteria that real recruiters use when hiring candidates.\n\nUsers can also use the app to identify keywords most relevant to the job descriptions they\u2019re searching for.|Resume Worded is a career platform that assists you in adapting your resume to the position for which you are pursuing.\n\nThis resume scanner will assess the job posting and highlight keywords and skills that are missing from your resume in 10 seconds after you upload your resume and the job description.|\n|Looka|Looka allows you to create a beautiful logo with the click of a button.\n\nJust input your company\u2019s name, industry type, and color palette, and you\u2019ll have an endless range of logo possibilities at your fingertips.|Looka provides high-resolution PNG and JPG logo files, SVG and EPS logo files for scaling, and colour variations for use online or offline.\n\nOther features include business card designs, social media templates, brand information, and lifetime logo support.|\n|Google Bard|Bard is Google\u2019s genai-powered interactive chat service.\n\nIt is intended to function similarly to ChatGPT, with the main distinction being that Google\u2019s service will obtain its data from the internet.\n\nBard, like most genai chatbots, can code, solve math questions, and assist you with your writing needs.|Google\u2019s Bard is a chatbot that uses genai to have natural conversations; it was built using the LaMDA family of LLMs and then the PaLM LLM.\n\nIn direct competition with OpenAI\u2019s ChatGPT, it was created.|\n|Adobe Sensei|Adobe Marketo Engage\u2019s Sensei GenAI aligns marketing and sales teams with real-time conversational experiences that accelerate time to market, increase pipeline, and increase calendared meetings.|Adobe Analytics can automatically analyse customers and audience groups using Adobe Sensei to uncover meaningful distinctions, attribute conversion drivers, and anticipate future behaviour.|\n|Adobe Firefly|Adobe Firefly is a genai engine for creativity.\n\nIt\u2019s just arrived in Adobe Photoshop, and it\u2019ll change the way you create forever.|Adobe Firefly\u2019s mission is to help people develop their innate creativity.\n\nFirefly, as an embedded model within Adobe products, will provide genai capabilities tailored to creative demands, use cases, and processes.|\n|Amazon Bedrock|Amazon Bedrock is a fully managed service that makes FMs from major genai companies and Amazon available via an API, allowing you to select the model that is best suited for your use case from a diverse set of FMs.|Amazon Bedrock\u2019s serverless architecture makes it simple to get started, personalise FMs with your own data in private, and integrate and deploy them into your applications with the AWS tools and capabilities.|\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "###### Large Language Models\n\nLarge Language Models (LLM) are neural networks that\nanalyse and comprehend natural language.\n\nCommonly\ntrained on large datasets, they can be utilised for\ntasks including text generation, classification, question\nresponse, and machine translation.\n\nLarge language models process vast volumes of text data\nto approximate human speech.\n\nThe LLM uses a deep\nlearning model, a network of interconnected neurons, to\nprocess, analyse, and forecast complex data to produce\nthese natural language responses.\n\nToday, many tasks in NLP , such as speech-to-text and\nsentiment analysis, rely on language models as their\nbasis.\n\nThese models can analyse a text and guess what\nword will come next.\n\nFor example, the parameters of an\nLLM let it make predictions about the likelihood of word\nsequences by considering the text\u2019s relationships.\n\nThe\nmodel can capture complex relationships and handle\nunusual words with more parameters.", "**BERT**\n\nBERT (Bidirectional Encoder Representations from\nTransformers) is a family of masked-language models\ndeveloped by Google researchers in 2018.\n\nAccording\nto a 2020 literature review, \u201cin little more than a year,\nBERT has become a ubiquitous baseline in Natural\nLanguage Processing (NLP) experiments, counting over\n150 research publications analysing and improving\nthe model.\u201d\n\nBERT was first implemented in English with two model\nsizes:\n\n(1) \u0007 BERTBASE (12 encoders with 12 bidirectional selfattention heads totalling 110 million parameters)\n\n(2) \u0007 BERT LARGE (24 encoders with 16 bidirectional selfattention heads totalling 340 million parameters)\n\nBERT is a free and open-source NLP machine learning\nframework.\n\nThe purpose of BERT is to provide context to\nhelp computers interpret ambiguous words in the text.\n\n4.\n\nGartner Article, January 2023.\n\nBeyond ChatGPT: The Future of genai for Enterprises\n\n\n-----", "**GPT-3**\n\nGPT-3 (Generative Pre-trained Transformer 3) is a\nlanguage model developed by OpenAI, a San Franciscobased genai research laboratory.\n\nThe\n175-billion-parameter deep learning model can\nproduce text that resembles human language and was\ntrained on large text datasets containing hundreds of\nbillions of words.\n\nGPT-3 employs deep learning to generate human-like\ntext.\n\nIt will generate text that continues the prompt when\nprovided a prompt.", "**LaMDA**\n\nGoogle\u2019s LaMDA (Language Model for Dialogue\nApplications) is a collection of conversational large\nlanguage models.\n\nInitially developed and released\nas Meena in 2020, the first-generation LaMDA was\nannounced during the Google I/O keynote in 2021,\nfollowed by the second generation the following year.\n\nLaMDA attracted significant attention in June 2022\nafter Google employee Blake Lemoine claimed that the\nchatbot had grown sentient.", "**BLOOM**\n\nBigScience The huge Open-science, Open-access\nMultilingual Language Model (BLOOM) is a large\nlanguage model based on transformers.\n\nOver 1000\ngenai researchers collaborated to construct a free big\nlanguage model for anyone who wants to explore it.\n\nIt\nis considered an alternative to OpenAI\u2019s GPT-3, which\n\n\nImpact, Opportunity, and Challenges of genai\n\nhas 176 billion parameters and was trained on about\n366 billion tokens from March to July 2022.\n\nBLOOM\nemploys a modified Megatron-LM GPT-2 decoder-only\ntransformer model design.", "**GPT-4**\n\nOpenAI\u2019s Generative Pre-trained Transformer 4 (GPT4) is a multimodal big language model and the fourth\nin its \u201cGPT-n\u201d series of GPT foundation models.\n\nIt was\npublished on March 14, 2023, and is now publicly\navailable in a limited form through the chatbot product\nChatGPT Plus (a premium version of ChatGPT), with\naccess to the GPT-4-based version of OpenAI\u2019s API\navailable through a waitlist.", "**Google - Bard**\n\nGoogle introduced Bard, a LaMDA-powered\nconversational genai\nchatbot.\n\nIt is intended to function similarly to ChatGPT,\nwith the main distinction being that Google\u2019s service\nwill obtain its data from the internet.Google\u2019s Bard\nis a conversational genai\nchatbot based on the LaMDA family of large language\nmodels (LLMs) and later the PaLM LLM.\n\nIt was created\nin direct response to the rise of OpenAI\u2019s ChatGPT,\nand it was initially published in a restricted capacity\nin March 2023 to lukewarm reviews before moving to\nother nations.\n\nFurthermore, Bard, like most genai chatbots, can code, solve\nmaths questions, and assist you with your writing needs.\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "**List of Large Language Models**\n\n|Name|Developer|Year|\n|---|---|---|\n|BERT|Google|2018|\n|XLNet|Google|2019|\n|GPT-2|OpenAI|2019|\n|GPT-3|OpenAI|2020|\n|GPT-Neo|EleutherAI|March 2021|\n|GPT-J|EleutherAI|June 2021|\n|Megatron-Turing NLG|Microsoft and Nvidia|October 2021|\n|Ernie 3.0 Titan|Baidu|December 2021|\n|Claude|Anthropic|December 2021|\n|GLaM (Generalist Language Model)|Google|December 2021|\n|Gopher|DeepMind|December 2021|\n|LaMDA (Language Models for Dialog Applications)|Google|January 2022|\n|GPT-NeoX|EleutherAI|February 2022|\n|Chinchilla|DeepMind|March 2022|\n|PaLM (Pathways Language Model)|Google|April 2022|\n|OPT (Open Pretrained Transformer)|Meta|May 2022|\n|YaLM 100B|Yandex|June 2022|\n|Minerva|Google|June 2022|\n|BLOOM|Large collaboration led by Hugging Face|July 2022|\n|Galactica|Meta|November 2022|\n|AlexaTM (Teacher Models)|Amazon|November 2022|\n|LLaMA (Large Language Model Meta genai)|Meta|February 2023|\n|GPT-4|OpenAI|March 2023|\n|Cerebras-GPT|Cerebras|March 2023|\n|Falcon|Technology Innovation Institute|March 2023|\n|BloombergGPT|Bloomberg L.P.|March 2023|\n|PanGu-\u03a3|Huawei|March 2023|\n|OpenAssistant|LAION|March 2023|\n|PaLM 2|Google|May 2023|\n\n\n\n(Disclaimer: This is not complete list of LLMs, but a curated list by INDIAai team)\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "### Current state of genai\n\nWith the launch of ChatGPT, genai has taken\nover the world by storm.\n\nAccording to NVIDIA Founder\nand CEO Jensen Huang, genai has finally\ncaused the inflexion point in genai.\n\nHe calls it the iPhone\nmoment for genai as a new computing platform has been\ndeveloped and emerged.\n\n\u201cThis is a new computing model that you program in a\nnew way, and this new way is using human language,\u201d\nstated Huang.\n\n\u201cThe first computer you can program\nin any language you like; English, Chinese, French,\nJapanese, however you like to do it,\u201d he noted.\n\nThe open-to-public version of ChatGPT gained 100\nmillion users in just under two months, while Stability\ngenai\u2019s Stable Diffusion, which can generate images based\non text descriptions, garnered more than 30,000 stars\non GitHub within 90 days of its release.\n\nToday, many\nbelieve that ChatGPT has the potential to change the\nentire business stream.", "###### Public perception of genai\n\nWhile some opine genai as a threat rather than\na boon because of the lack of awareness of the actual\ncapability of the tool, others are extensively using it and\n\n\ngaining a clear understanding of what the tool can\naccomplish.\n\n\u201cA significant number of people are still looking at genai as\na threat.\n\nThere is generally low acceptance with regard\nto genai as people are still relating genai with Hollywood movies\nthey might have watched, in which it is often portrayed\nas how genai is going to take over the world.\n\nThere is a dire\nneed to educate people,\u201d said genai artist Tapan\nAslot at the first INDIAai genai Roundtable.\n\nLack of basic understanding of genai is yet another major\nissue.\n\n\u201cThe public is lost in the complexity of the field.\n\nexplaining genai without hiding its complex nature is\nessential, said Emmanuel Goffi, Founder and Director\nof Global genai Ethics Institute.\u201dSome people do not even\nhave access to 4G in countries like India and Africa.\n\nTheir knowledge of Chat GPT and genai\nis limited.\n\nThis clarity will lead to inclusivity and the\nmaintenance of balance,\u201d he added.", "###### Is genai \u2018creative\u2019 or \u2018generative\u2019?\n\nThe emergence of creative tools such as Midjourney and\nDALL- E has opened the debate regarding the \u201ccreativity\u201d\nof these tools.\n\nAccording to Prof Chandra Sekhar of IISc\nBangalore, these models are only \u2018generative\u2019 as they\nderive results from existing material and are not creative.\n\nIn his opinion, creativity is still unique to humans as\nnatural intelligence would be hard to replicate.\n\n\u201cgenai is not completely well founded.\n\nThat is the actual\nthreat,\u201d Prof Chandra Sekhar noted.\n\nFurthermore, selflearning is still a dream for the models.\n\nBut, for now,\ngenai lacks thought; the initial input must still be from the\nhuman,\u201d he stated in the first roundtable.\n\nAbhinav Aggarwal, whose company Fluid genai recently\nreleased a book authored by genai, pointed out that even\nthe \u201ccreative\u201d humans are also dependent on other\nreference materials before creating a particular model.\n\n\u201cWhy is it that when a human does it, it is creative and\ngenerative when an genai does it?\u201d he asks.\n\nTo elaborate on this, he added that till now, genai has been\nable to generate something based on the information\nbeing fed to it.\n\nBut being creative is something which is\nunique, on which humans have a clear advantage.\n\nHe\npointed out that one must distinguish between inferencebased and memory-based logic.\n\nAt present, genai systems\nare working on inference-based logic, but a decade\nlater, it will be functioning on memory-based logic.\n\nWhen an genai system learns from data, it is dubbed as noncreative, whereas if a similar thing is done by humans, it\nis termed as creative.\n\nHence, it is either that the definition\nof creativity is blurred or we term one to be less creative\nthan the other.\n\nAccording to the first INDIAai genai Roundtable,\nat a finer level, one needs to distinguish between creative\nand genai.\n\nWhile at present, the difference is\nblurred, and both are used interchangeably, a decade\ndown the line, this difference will amplify.\n\nDefining\ncreativity in an era of ChatGPT is a task in itself.", "###### Future of jobs\n\nThe fear of being replaced by machines in the workspace\nhas always been a major concern whenever a new\ntechnology arises.\n\nThe recent boon in genai\nhas just amplified this concern.\n\nAccording to many\nreports, genai could impact up to 300 million\njobs globally.\n\ngenai could substitute up to 25%\nof current work in the US and 24% in Europe while\ncomplementing most of the remaining work.\n\nJyoti Joshi, Founder and CEO of genai startup\nKroop genai, pointed out that, though there are concerns\nabout genai replacing humans, in the present stage, human\nintervention is a necessity.\n\n\u201cCorrect innovation is the key\nto the correct output\u201d, she added.\n\nDespite genai bringing in a lot of automation in many\nprocesses, the technology will still need to replace jobs.\n\nIt will add to new kinds of job profiles and lead to job\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\nefficiency, concluding the first INDIAai genai\nRoundtable.\n\nThe insights from the roundtable further backed\nGoldman Sachs findings that should genai\nreach its full potential and capabilities, the labour\nmarket might experience quite an upheaval.\n\nBy\nanalysing data on occupational tasks in both the\nUnited States and Europe, the report came to\nthe conclusion that approximately two-thirds of\nexisting jobs are susceptible to various degrees of\ngenai automation.\n\nNot only that, genai has the", "**Total job growth and loss**\n\npotential to replace as much as one-fourth of the current\nworkload.\n\nAlternatively, genai has the potential\nto automate around 18% of the total workforce.\n\n6 Also,\nan independent study 7 on GPTs and their impact on\nlabour market points that 80% of the US workforce\nmight have at least 10% of their tasks affected by such\nlarge language models.\n\nWith access to LLMs, 15% of all\nother work tasks could be expedited while maintaining\nthe same quality level.\n\nGiven below are representations\nof job growth and job loss and how genai will\ntransform work across industries.", "##### today\u2019s job will change\n\nOne million       Lost jobs       Stable jobs       New jobs\n\n**Source:** World Economic Forum, Future of Jobs Report 2023\n\n6.\n\n\u0007 Goldman Sachs Economics Research, March 2023.\n\nThe Potentially Large Effects of genai on Economic Growth\n(Briggs/Kodnani)\n\n7.\n\n\u0007 Tyna Eloundou, Sam Manning, Pamela Mishkin, Daniel Rock, March 2023.\n\nGPTs are GPTs: An Early Look at the Labour Market\nImpact Potential of Large Language Models\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n**genai will transform work across industries**", "**Work time distribution by industry**\n\n**and potential genai impact**\nBased on their employment levels in the US\nin 2021\n\nHigher potential for automation\n\nHigher potential for augmentation\n\nLower potential for augmentation and automation\n\nNon-language tasks\n\n40% of working hours across industries can be impacted by Large\nLanguage Models (LLMs)\n\n\n54%\n\n48%\n\n36%\n\n40%\n\n43%\n\n33%\n\n34%\n\n31%\n\n28%\n\n30%\n\n\n12%\n\n14%\n\n14%\n\n21%\n\n\n24%\n\n26%\n\n28%\n\n29%\n\n34%\n\n33%\n\n46%\n\n38%\n\n\n10%\n\n12%\n\n15%\n\n18%\n\n\nBanking\n\nInsurance\n\nSoftware & Platforms\n\nCapital Markets\n\nEnergy\n\nCommunications & Media\n\nRetail\n\nIndustry Average\n\nHealth\n\nPublic Service\n\nAerospace & Defence\n\nAutomotive\n\nHigh Tech\n\nTrave\n\nUtilities\n\nLife Sciences\n\nIndustrial\n\nComputer Goods & Services\n\nChemicals\n\nNatural Resources\n\n\n21%\n\n14%\n\n9%\n\n12%\n\n\n13%\n\n7%\n\n9%\n\n11%\n\n9%\n\n\n22%\n\n33%\n\n35%\n\n20%\n\n\n27%\n\n26%\n\n\n26%\n\n30%\n\n26%\n\n38%\n\n27%\n\n25%\n\n26%\n\n24%\n\n24%\n\n20%\n\n\n13%\n\n6%\n\n8%\n\n6%\n\n6%\n\n8%\n\n6%\n\n\n41%\n\n50%\n\n50%\n\n50%\n\n52%\n\n50%\n\n54%\n\n57%\n\n56%\n\n64%\n\n\n13%\n\n16%\n\n15%\n\n15%\n\n17%\n\n14%\n\n\n6%\n\n5%\n\n\n13%\n\n14%\n\n\n5%\n\n\n11%\n\n\n0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%\n\n**Source:** World Economic Forum, May 2023.\n\nThese are the jobs most likely to be lost - and created - because of genai\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n|Occupations with high proportion of tasks that could be automated by Generative AI8|Col2|\n|---|---|\n|Occupation|Proportion of task that can be automated by genai|\n|Office and administrative support|46%|\n|Legal|44%|\n|Architecture and engineering|37%|\n|Life, physical and social science|36%|\n|Business and financial operations occupations|35%|\n|Occupations with least proportion of tasks that could be automated by Generative AI9||\n|Occupation|Proportion of task that can be automated by genai|\n|Building and grounds cleaning and maintenance|1%|\n|Installation, maintenance and repair occupations|4%|\n|Construction and extraction occupations|6%|\n|Education, training and library occupations|7%|\n|Health-care practitioners and technical occupations|8%|\n\n\nHowever, on the brighter side, genai has the potential\nto create jobs as well.\n\nThe World Economic Forum\npredicts by 2027, there will be a significant increase in\nthe number of genai and machine learning specialists by\n40%.\n\nIn other words, 1 million jobs are expected to be\ncreated with the increase in usage of genai and machine\nlearning across all industry verticals.\n\nAdditionally\nroles such as data analysts, data scientists, big data\nspecialists and information security analysts are also\nexpected to experience an increase of 30-35% and\n\n\n31% respectively.\n\nThese developments are anticipated\nto generate an additional 2.6 million jobs.\n\n10 Another\nskill that will gain much prominence in the future is\nprompt engineering.\n\nIt is a comprehensive process\nencompassing the entire interaction cycle between\nhumans and genai.\n\nPrompt engineering aids in smooth,\nclear and efficient human-genai interaction.\n\nThe field\nis expected to flourish and continue to evolve and\ndevelop as new techniques and demand for advanced\ngenai systems increase over time.\n\n8.\n\n\u0007 Glenn Mossy, March 2023.\n\nThe Impact of genai on Labor Productivity, Employment, Wages and GDP\n\n9.\n\nGlenn Mossy, March 2023.\n\nThe Impact of genai on Labor Productivity, Employment, Wages and GDP\n\n10.\n\n\u0007 World Economic Forum, Future of Jobs Report 2023\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "**Top 10 fastest declining jobs**\n\nBank Tellers and Related Clerks\n\nPostal Service Clerks\n\nCashiers and Ticket Clerks\n\nData Entry Clerks\n\nAdministrative and Executive Secretaries\n\nMaterial-Recording and Stock-Keeping\nClerks\n\nAccounting, Bookkeeping and Payroll\nClerks\n\nLegislators and Officials\n\nStatistical, Finance and Insurance Clerks\n\nDoor-to-Door Sales Workers, News and\nStreet Vendors, and Related Workers", "### Opportunities\n\ngenai has emerged as a powerful tool that has\nsignificantly impacted economic opportunities across\nvarious industries.\n\nThe potential economic benefits of\ngenai are vast, offering increased productivity,\nautomation, and enhanced decision-making capabilities,\nultimately driving growth, efficiency, and competitiveness\nin numerous sectors of the economy.\n\ngenai is expected to increase from USD 11.3\nbillion in 2023 to USD 51.8 billion by 2028.\n\nThe CAGR is\nexpected to touch 36% between the forecasted period.\n\n12\n\n\u201cThere are endless opportunities for genai in\nIndia.\n\nStarting from big companies making chatbots to\nstudents using ChatGPT for writing academic papers.\n\nEven the older generation is curious about ChatGPT,\u201d\npointed out Pavankumar Dubagunta, Speech Scientist\nat Uniphore Software Systems.\n\nAccording to Goldman Sachs estimates, Generative\ngenai could raise global GDP by 7% (USD 7 trillion) and\nincrease productivity by 1.5% in the next decade.\n\n13 PwC\nestimates that the openness to tap into the power of\ngenai will likely only continue to grow with an\n\n\nImpact, Opportunity, and Challenges of genai\n\nestimated USD 15.7 trillion of potential contribution to\nthe global economy by 2030.\n\n14\n\nAccording to Jaspreet Bindra, in technology as\nfundamental and transformative as genai, there\nwould be both sides.\n\n\u201cIn India as a country, I see five possibilities.\n\nFirstly, it\nhas the potential to make everyone a 10x engineer,\nwhich will be a benefit in the technical space.\n\nSecondly, with open APIs and the cloud, it provides\ngreater possibilities for entrepreneurship.\n\nThirdly it will\nbenefit service companies.\n\nFourthly if we do it right,\ngenai provides huge possibilities for the creative industry,\nand India has a massive creative industry.\n\nAnd finally,\nIndia stat can be leveraged with the abundant amount\nof data.\n\nWith genai in the market, we now have a tool to\nleverage this data\u201d, he added.\n\nThere are multiple opportunities across the generative\ngenai value chain, with much of the opportunity in its\napplications and services.\n\n15\n\n\n12.\n\n\u0007 Markets and Markets Report.\n\ngenai Market by Offering, Application, Vertical and Region - Global Forecast to 2028\n\n13.\n\n\u0007 Goldman Sachs Article, April 2023. genai could raise global GDP by 7%\n\n14.\n\n\u0007 PwC Report.\n\nSizing the Price: What\u2019s the real value of genai for your business and how can you capitalise?\n\n15.\n\n\u0007 Quantum Black, genai by Mckinsey, April 2023.\n\nExploring Opportunities in the genai Value Chain\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "**Computer hardware**\n\nAccelerator chips optimized for training and running the models\n\nSource: McKinsey article Exploring opportunities in the genai value chain\n\n|genai tools|from India|\n|---|---|\n|KissanGPT|KissanGPT is an genai chatbot that leverages the power of GPT 3.5 and the Whisper model exclusively for serving India\u2019s underserved agricultural domain.\n\nLaunched on March 15th 2023, KissanGPT has already earned the hearts of farmers all over the country with its remarkable ability to guide the farmers in irrigation, pest control and crop cultivation.|\n|PolicyGPT|Plum, a Bengaluru-based startup, has introduced PolicyGPT to transform the insurance industry.\n\nThe purpose of the GPT-3-based chatbot is to educate consumers on their health insurance policies.\n\nIn addition, the chatbot is designed to reduce the complexity of insurance policies by answering queries about coverage and elucidating inclusions and exclusions.|\n|GitaGPT|A Google India software developer named Sukuru Sai Vineet developed the genai chatbot called GitaGPT.\n\nIt uses GPT-3 technology and the Bhagavad Gita to offer answers to life\u2019s problems.\n\nUsers can ask questions on the GitaGPT app, and a chatbot will respond by researching the Bhagavad Gita\u2019s teachings.|\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n|BharatGPT|Bengaluru-based conversational genai platform CoRover recently released BharatGPT.\n\nIn comparison, OpenAI\u2019s ChatGPT supports only 95 languages and mainly interprets English instructions.\n\nIn addition to text, CoRover\u2019s chatbot can also process rich data types, including photos, audio, video, and maps, which is not the case with ChatGPT.\n\nWhile the accuracy of ChatGPT has yet to be determined, CoRover asserts that BharatGPT is 90% accurate.|\n|---|---|\n|Lexi|Lexi is an genai chatbot created by Velocity, a financial startup powered by ChatGPT.\n\nLexi seeks to help e-commerce entrepreneurs by simplifying business analytics.\n\nLexi, integrated with Velocity\u2019s analytics product, Velocity Insights, assists organisations in tracking market spending, sales, and more and provides daily business reports over WhatsApp.\n\nIn addition, customers may now utilise Lexi, the genai chatbot, to get answers to their concerns, increasing their company operations, thanks to the integration of ChatGPT in the same WhatsApp interface.\n\nVelocity announced this in an official blog post.|\n|Jugalbandi|Jugalbandi is a free and open platform that combines the power of ChatGPT and Indian language translation models under the Bhashini mission to power conversational genai solutions in any domain.|\n\n\nWhen it comes to talent, presently, much of the genai talent\nworks in the US, India, UK 60% of the genai\ntalent pool comes from the US, India, UK, Germany,\nCanada and France.\n\nYet, in India, there is a rush to find\ntalent in genai despite around 416,000 people working in genai\nand Data Science.\n\nAt present, India still faces a demand\nof approximately 629,000 genai talent.\n\n16 According to\nNASSCOM, there is still an additional demand for\nOne million workers in the space, which is expected to\nincrease exponentially in the coming years.\n\n17", "###### Bridging the digital divide\n\nAccording to Jensen Huang, genai can\npositively impact countries like India and is one of the\nmost fantastic opportunities we have ever had to close\nand bring together the social and technology divide.\n\nFor the last 30-40 years, only so many people know\nhow to program a computer.\n\nSo the number of people\nwho know how to use this incredible instrument for the\nbenefit of themselves or their business or their country is\nreally quite limited.\n\n\u201cAnd yet, all of a sudden, there\u2019s a new type of computer,\nthis new type of computer, you don\u2019t have to learn C,\nC++, you don\u2019t have to learn Pascal, you don\u2019t have to\nlearn Fortran, you don\u2019t have to learn Java.\n\nYou don\u2019t\n\n\neven have to learn Python.\n\nYou just have to speak your\nlanguage.\n\nAnd by communicating to this computer\nwhat you need, what you want, what problems you\nwant to be solved, this computer will write the software\nby itself.\u201d He theorises that everyone is a computer\nprogrammer now.\n\n\u201cThis is going to have the greatest opportunity for us to\ndemocratise this very powerful instrument we call the\ncomputer for the very first time in history,\u201d he said.\n\n\u201cI believe it will lift so many segments of society.\n\nIt will\nbring great education to people who don\u2019t have access\nto education.\n\nIt\u2019s the most powerful democratisation\nforce I\u2019ve ever seen,\u201d he concluded.\n\n18\n\nWhen it comes to bridging divides, linguistic barriers\nhave plagued the country for many decades, and\ngenai tools built alongside the Government of\nIndia\u2019s Bhashini program can be a valuable asset in the\nfuture.\n\n\u201cCreating content in multiple languages is an issue for\nIndia.\n\nThis shortcoming can be tackled with Generative\ngenai,\u201d says Harsha Mundhada of Inflexor Venture.\n\nThe language translation and other genai\ncapabilities will make India\u2019s apex judicial bodies more\n\n\n16.\n\n\u0007 NASSCOM study, February 2023.\n\nState of Data Science & genai skills in India - Data and the Art of Smart Intelligence\n\n17.\n\nNASSCOM study, February 2023, State of Data Science & genai skills in India - Data and the Art of Smart Intelligence\n\n18.\n\nINDIAai article, March 2023. genai can help India close the technology divide, NVIDIA CEO Jensen Huang\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\naccessible to people across the country, she added.\n\nFurthermore, many believe that genai tools are\na blessing for many people with disabilities.\n\nAccording\nto Pavankumar Dubagunta, Speech Scientist, Uniphore\nSoftware Systems,\u201d people who have deficiencies in\nspeaking and autism can leverage technologies like genai,\nand I think it will be a life-changing experience for them.\u201d", "###### genai\u2019s impact on different sectors\n\nThe economic opportunities brought about by generative\ngenai are vast and diverse.\n\nIt empowers industries to\nleverage data-driven insights, enhance productivity,\nand drive innovation.\n\nAs technology advances, we\ncan expect further transformations across sectors,\npaving the way for a more efficient, personalised, and\ntechnologically advanced future.\n\nSome of the significant\nimpact sectors for genai include healthcare,\nfintech and education, with the education sector already\nbeing transformed into genai.\n\ngenai can play the role of personalised teachers\nin the education sector.\n\nIt can provide customised\nmodules and classes for students based on their\n\n\naptitude.\n\n\u201cgenai is becoming the supportive tutor providing\npersonalised teaching plans for students.\n\nI see\napplications which are catering towards that, be it in\none-on-one skill development training to something as\nsimple as fluency improvements,\u201d said Neethu Mariam\nJoy, who is currently working on a new genai\nstartup that focuses on EdTech.\n\n\u201cNot just in EdTech, in healthcare, it is simple to build\na query-based system where genai takes the role of\nproxy doctors.\n\nMost of the applications are bringing\npersonalization into whichever sector you are applying\nit into,\u201d she added.\n\ngenai could revolutionise healthcare by helping\ndoctors analyse medical data, diagnose patients, and\ncustomise treatment strategies.\n\nRecently, researchers\nfrom Drexel University\u2019s School of Biomedical\nEngineering, Science and Health Systems recently\ndemonstrated that Open genai\u2019s GPT-3 program could\nidentify clues from spontaneous speech that are 80%\naccurate in predicting early stages of dementia.\n\n19\n\nSince there is still no cure for the disease, diagnosing\nit early can give patients more options for therapeutics\nand support.\n\nThe current practice for diagnosis involves\nmedical history review and a lengthy set of physical and\nneurological evaluations and tests.\n\n19.\n\nDrexel University Research, December 2022. genai behind ChatGPT could help spot early signs of Alzheimer\u2019s disease\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n**genai impact on different sectors in India**\n\n\n\n|Sector|Applications|Tools|\n|---|---|---|\n|Agriculture|\u2022 Crop Management- genai systems can find patterns and trends in satellite imagery, weather data, and soil composition to help farmers decide when and where to sow, water, and harvest crops.\n\n\u2022 Crop Optimisation - genai can also help farmers choose the best crops and production methods for their needs.\n\n\u2022 Resource Management- genai can assist farmers in maximising water, fertiliser, and pesticide use, boosting sustainable farming.\n\n\u2022 Pest control - genai can improve pest control by assessing pest populations, weather, and crop health to predict outbreaks and offer focused interventions.\n\n\u2022 Supply Chain Optimisation - genai helps farmers and agribusinesses assess massive logistical data, detect bottlenecks and inefficiencies, and enhance supply chains.\n\n\u2022 Climate-Resilient Agriculture - genai can analyse climatic trends, soil health, and crop performance to build more resilient agricultural practices.\n\n\u2022 Crop Innovation - genai can help researchers and plant breeders find and develop novel crop types with improved performance, yield, and pest and disease resistance.\n\n\u2022 Farmer education - genai could transform farmers\u2019 information availability and decision-making.|\u2022 Ama KrushAI \u2022 Farmer.chat \u2022 Apurva.genai \u2022 Kissan GPT \u2022 jiva ag|\n|Education|\u2022 Course Design - genai techniques can organize syllabi, lesson plans, and exams.\n\nPractice problems and interactive exercises can be tailored to students\u2019 knowledge gaps, skills, and learning methods.\n\n\u2022 Personalized Lessons - Personalized lesson plans help students get the best education based on their needs and interests.\n\n\u2022 Content Creation for Courses - genai can help create quizzes, exercises, and concept explanations.\n\nIt can help teachers who need to develop a lot of stuff.\n\ngenai can transform original content into new content.\n\n\u2022 Restoring Old Learning Materials - genai can enhance low- quality learning materials, including historical documents, photos, and films.\n\ngenai can improve the resolution of these items, making them more interesting for kids acclimated to high-quality media.\n\n\u2022 Tutoring - Students can connect with a virtual tutor and receive real-time feedback and guidance using genai.\n\nIt can aid pupils without in- person tutoring.|\u2022 NOLEJ \u2022 TutorAI \u2022 Snapxam \u2022 QANDA \u2022 tabnine|\n|Healthcare|\u2022 Diagnosis and Screening - genai helps clinicians identify and treat patients faster and more accurately, improving patient outcomes.\n\n\u2022 Personalized Medicine - genai algorithms can analyze enormous medical datasets to find patterns, predict outcomes, and improve health.\n\nThese personalized medicine methods can help doctors create more effective treatment regimens and follow-up care.", "These personalized medicine methods can help doctors create more effective treatment regimens and follow-up care.\n\n\u2022 Drug Discovery - genai algorithms can analyze clinical trials and other data to find potential medication targets and predict the most successful molecules.\n\nNew medications could be developed faster and cheaper.\n\n\u2022 Creating Research Ideas - In healthcare, genai can also be utilized to generate new concepts.\n\n\u2022 Avoiding Medical Errors - genai can automatically repair spelling problems in the documentation, which is helpful for electronic prescriptions, and populate the system with the relevant data.|\u2022 MedPaLM \u2022 Viz.genai \u2022 Enlitic \u2022 Merative \u2022 CloudMedX|\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n|Sector|Applications|Tools|\n|---|---|---|\n|Manufacturing|\u2022 Product Development and Design - genai can accelerate the development of new design concepts, pharmaceuticals, materials, and market research, reducing time to market.\n\n\u2022 Quality Control - Predictive genai systems monitor and report production concerns in real-time, whereas genai systems find and alert against faults.\n\n\u2022 Supply Chain Management - genai may eliminate the necessity for an integration platform for interoperability.\n\nAs original equipment tools evolve, continuous integration platform changes are unnecessary.\n\n\u2022 Customer Interactions and Support - genai systems can provide 24/7 customer service, reducing staff and increasing productivity.|\u2022 Autodesk \u2022 Fanuc \u2022 Birlasoft \u2022 FortiSandbox \u2022 Altexsoft|\n|Retail|\u2022 Personalised Product Recommendations - genai can analyze customer data to create tailored journeys, customized discounts, and engaging content for specific shoppers.\n\n\u2022 Manage Inventory Levels - genai analyses sales data and suggests inventory management.\n\ngenai can help retailers optimize supply chain and delivery by aRetailng historical data, consumer sentiment, and competition data to predict trends and make smart purchasing and production decisions.\n\n\u2022 Monitor And Optimise Prices - genai algorithms can quickly optimise retail prices by analyzing rival prices, demand patterns, and market trends.\n\n\u2022 Build Customer Service Chatbots - genai can help customers solve problems with chatbots.\n\nAs a result, it can help retailers improve customer service and reduce customer support agent workload.\n\n\u2022 Detecting Fraudulent Activities - genai systems can prevent fraudulent purchases and returns, saving companies money and building customer confidence.|\u2022 vertex genai vision \u2022 Discovery genai \u2022 Market360 \u2022 Scanunlimited \u2022 numerator|\n|Media20|\u2022 Automated Content generation: LLM can be used to generate content, such as articles, blog posts, or social media posts.\n\nThis will be beneficial for those who want to create content on a regular basis.\n\nFor example, social media influencers, \u2022 Variety and improved content: LLMs can create a variety of interesting content that caters to different audience sections.\n\nThe quality of content will be much better as genai models learn from a large amount of data.\n\n\u2022 Personalised content: genai models can generate personalized content based on the preferences of individual users \u2022 Customer management: genai can help in customer management, providing timely responses and engagement with a digital audience.\n\nChatGPT, a form of genai, can be used to answer more general questions.\n\nOff late, there are Google Chrome extensions that allow brands and Twitter users to install Chat GPT bots that respond to all Tweets \u2022 Localization of content using deep fakes: The OTT platforms have increased the need to create content in local/regional languages.\n\nFor example, the task of dubbing and content moderation for lip-syncing with an on-screen character can be smoothly accomplished using deep fake technology.\n\nThe technology superimposes voice from a source to target face with a perfect lip-sync.\n\nThis is achieved through face synthesis.|\u2022 Lately \u2022 Sprout Social \u2022 HubSpot \u2022 Copy.genai \u2022 Emplifi|\n\n\n20.\n\nINDIAai Knowledge Asset, March 2023.\n\nHow genai will influence media industry\n\n\nAutodesk\nFanuc\nBirlasoft\nFortiSandbox\nAltexsoft\n\nvertex genai vision\nDiscovery genai\nMarket360\nScanunlimited\nnumerator\n\nLately\nSprout Social\nHubSpot\nCopy.genai\nEmplifi\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n\n|Sector|Applications|Tools|\n|---|---|---|\n||\u2022 Upscaling content through super-resolution: Super-resolution is a method of using ML algorithms to infer form an original image (with fixed pixels) and create another version of the same image but with higher pixels.\n\nSuper resolution improves the display of images and video.\n\nSuch super resolution is mostly required by documentaries focusing on nature, wildlife or even sports.\n\n\u2022 Upscaling Visual Effects: The rise in demand for animation and VFX content has powered immersive experiences, with exponential growth in AR & VR technology that has Media the entertainment market.", "\u2022 Upscaling Visual Effects: The rise in demand for animation and VFX content has powered immersive experiences, with exponential growth in AR & VR technology that has Media the entertainment market.\n\nFor example, genai can help in superimposing/transposing a source face to a target face with much ease.||\n|Marketing21|\u2022 Cost-saving and scheduling \u2013 Voice cloning via synthetic media can cut down on the time needed to chase busy voice actors.\n\nTo put it simply, if you have Awkwafina voicing a character in your animated film, you can capture her voice sample and generate the lines.\n\n\u2022 Custom regional accents \u2013 Rather than selecting just one human character, advertisers could generate hundreds or thousands of synthetic characters to appeal to narrow demographic bases.\n\nThis means, instead of having one celebrity extol the virtues of a toothpaste, different characters can appeal separately to college-going teens, stay-at-home dads, and potential trendsetters.\n\n\u2022 Reaching people in their language \u2013 Using genai synthesis, one can create David Beckham\u2019s video about malaria in Gujarati or Jackie Chan\u2019s video about wearing a mask in Tamil.\n\nThis can create an opportunity for advertisers to reach out to people in their own languages.\n\n\u2022 Archiving people around \u2013 Advancements in synthetic media can also let us preserve ourselves as well as our loved ones.\n\nYou might be able to ask questions to a 5-year-old you or listen to your grandmother sing long after she\u2019s gone.|\u2022 Jasper genai \u2022 MarketMuse \u2022 Acrolinx \u2022 Semrush \u2022 Seventh Sense|", "###### Next frontiers for genai\n\nAccording to experts, one of the sectors expected to be\ndisrupted by genai in coming years is Fintech.\n\n22\n\nOne of the sectors which will face a huge impact\ndue to genai will be FinTech, says Aveekshith\nBushan, Vice President and General Manager for APJ\nat Aerospike.\n\n\u201c If there is fraud in the FinTech sector, it\nwill affect thousands of users,\u201d he added.\n\nHe believes\nthat at some point, someone will find a way to break\n\n\ninto the security protocols followed currently.\n\nUnless\nand until the FinTech sector finds the means to tackle\nthis possibility, the probability of sectoral disruption is\nstrong.\n\nAccording to Jaspreet Bindra, \u201cThe sector which would\nbe disrupted is the one which created it- the tech (IT)\nsector,\u201d \u201cgenai has been writing codes involving\nbasic process automation and many more.\n\nI recently\nread a tweet by a programmer who used ChatGPT for\nthe first time for writing codes.\n\nHe said the value of 90%\nof his skills had gone down to zero dollars\u201d, he added.\n\n21.\n\nINDIAai article, November 2021. genai & Synthetic Media: A New Era of Advertisements\n\n22.\n\nInsights from INDIAai Roundtable Discussion What is India\u2019s Opportunity in genai, May 2023\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "### Challenges\n\nWhile genai (genai) holds\ntremendous potential and has made significant\nadvancements in various fields, it also presents unique\nchallenges.\n\nThe complexity and power of genai\nalgorithms can give rise to ethical, legal, and societal\nconcerns.\n\nAccording to Kazim Rizvi, Founding Director of a tech\npolicy think tank called The Dialogue, \u201cGenerative\ngenai has inspired many to gain first-hand experience\nwith genai in recent times.\n\nHowever, an opaqueness in\ndata collection, developers of the models, and biases\nbeing fed into the system still exists.\n\nThis ambiguity will\ncontinue to remain even if the technology is evolved.\u201d\n\nOne of the major concerns that genai possesses\nat present is its potential to amplify the spread of\nmisinformation that can have varying impacts, especially\nwhen these language models can often produce\noutputs that are not real.\n\nAccording to researchers, this\nphenomenon of genai generating confident responses that\ndo not seem to be real or justified by its training data is\ncalled hallucination.\n\n23\n\n\n\u201cIn markets like India, content can go out and spread\nquickly,\u201d says Aveekshith Bushan.\n\n\u201cThere could be\nbiases and misinformation.\n\nWe have already seen it on\nthe other side of ChatGPT, where the output is irrelevant\nto the content searched.\n\nPeople will have to decipher\nand say what looks relevant and what does not,\u201d he\nadded.\n\nFor many years, we have seen genai\ntechniques, such as deep fakes, being used to bring\nsocial and political unrest across the globe.\n\nThe recent\ndevelopments in genai technology can make\nthese kinds of threats more prevalent.\n\n\u201cIt was challenging to analyze the impact of the\nprevious genai revolution, which was algorithms and\ninformation shared.\n\nIt is also complicated to foresee\nthe implications of deep fakes.\n\nThis is a threat to the\ndemocracies of the world which is hard to tackle,\u201d says\nAnna Danes, Data Ethicist who works with organizations\nto create frameworks and practical methods to ensure\nresponsible developments in genai.\n\n23.\n\n\u0007 Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, Pascale Fung, March\n2023.\n\nSurvey of Hallucination in Natural Language Generation\n\n\n-----\n\nAnother area of concern regarding the widespread use\nof genai models is the different kinds of bias the\nresults produced by these models show.\n\nAccording to Divya Dwivedi, a lawyer at the Supreme\nCourt of India, who focuses on tech-law, \u201cWe really do\nnot know what kind of data it will generate and what kind\nof bias it will come up with since we already have made\nthese models very biassed as a result of our own nature.\u201d\n\nBias in genai models has been a central point of debate\nfor many years, and genai models have just\namplified these biases.\n\n\u201cThere is an inherent bias that is there when we are\ntraining the dataset that comes out of how humans\nhave kind of embedded their prejudices in the system,\u201d\npoints out Prateek Sibal, Programme Specialist for genai,\nEmerging Tech and Internet Governance at UNESCO.\n\nRecently, India Today conducted a political experiment\ninvolving leading platforms that use genai to generate\nvisual imagery, suggesting that these platforms could be\nbiased in terms of their knowledge and understanding\nof various nations.\n\nThe genai tool Midjourney was asked to create\npictures of \u201cmost popular elected political leaders posing\nin front of the Eiffel Tower in 2023.\u201d The prompt was\ngeneric, without mentioning names to check the scope\nof the results.\n\nThe genai-generated image only included\n\n\nImpact, Opportunity, and Challenges of genai\n\nleaders with a Western appearance, such as Angela\nMerkel, Emmanuel Macron, and Donald Trump.\n\nNone\nof the popular Asian leaders were included in the result.\n\nThese demonstrations have only strengthened the belief\nthat these models amplify human biases.", "###### Ethics, rights, and intellectual property\n\nThe use of copyrighted materials for training genai models\nis still unclear, and hence is said to be in a legal grey\narea.\n\nIt can be said that there are no copyright laws so\nfar that would safeguard any wholly genai generated model\nor creation.\n\nIt becomes irrelevant whether that creation\nstemmed from a human-crafted text prompt.\n\nWhile fair\nuse laws permit the use of copyrighted material under\ncertain conditions without the owner\u2019s permission, the\nongoing legal disputes could disrupt this status quo and\nbring uncertainty in the future of genai model training.\n\nUndoubtedly, the advent of genai has\nrevolutionized our lifestyle, labor practices, and\nartistry output within a mere few months.\n\nIn turn, the\ninundation of genai-fabricated written works, pictures, and\ntunes, alongside the mechanisms through which they\nwere created, has stimulated a plethora of intricate\nlegal inquiries.\n\nThese challenge our understanding\nof ownership, fairness, and the core foundation of\ninnovation, writes Anndy Lian.\n\n24 Anndy Lian is an all-\n\n\n24 \u0007 INDIAai article, May 2023.\n\nThe Legal Complications of genai-generated Content in Copyright Law\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\nrounded business strategist in Asia and the author of\nthe book NFT From Zero to Hero.\n\n\u201cThere are papers and research where Generative\ngenai or ChatGPT has been mentioned as co-authors,\nwhat does this mean for original scientific work?\n\n\u201d\nasks Prateek Sibal.\n\nPrateek is Programme Specialist,\nDigital Innovation and Transformation at UNESCO\nwho is working to understand the impact of digital\ntechnologies, specially genai (genai), on\nsocieties from a human rights, openness, inclusive\naccess and multi-stakeholder governance perspective.\n\nCopyright laws play a fundamental role when it comes\nto protecting intellectual property and encouraging\ncreativity.\n\nIt allows creators to rightfully control the\nusage, distribution, and adaptation of their work.\n\nThe\nlaw encourages creators to create more by offering\nthem exclusive rights.\n\nCreative Commons licenses\nenable the free distribution of an otherwise copyrighted\n\u201cwork\u201d.\n\nThey also provide more options for creators to\nchoose the level of protection they want for their work.\n\nWith advancements in genai technology, there is a\nsimultaneous increase in its usage in the creative\nprocess.\n\nWith the increase in genai capabilities to generate\nfresh and original content there is a growing need\nfor a legal framework that addresses the copyright\nprotection of collaborative works involving genai.This legal\nframework is highly important to strike a balance\nbetween safeguarding the rights of creators while\nboosting innovation and originality.\n\nThis is difficult to predict how copyright law will shape\nup around genai-generated work.\n\nHowever, it is clear that\nthe legal framework governing copyright protection will\nundergo significant transformation.", "###### How to ensure responsible use of genai?\n\nWith the rise in the usage of genai, there is a dire\nneed for a holistic,and a comprehensive framework that\nwould ensure responsible usage of the technology to\nharness the best benefits while mitigating its risks.\n\nThis\nframework shall include ethical guidelines, regulatory\nmeasures, transparency, accountability, and ongoing\ncollaboration among stakeholders.\n\nBy boosting fair\npractices we can nurture the technology, increase\npeople\u2019s trust in it, protect it against potential harm,\nand ensure that genai serves humankind and\nsociety in more productive ways.\n\nAccording to Jaspreet Bindra, Founder and MD of Tech\nWhisperer Ltd. \u201cThe biggest thing we will have to figure\nout is how to control this monster.\n\nThe democratization of\ntechnology is the biggest challenge here.\n\nThe closest I can\nthink about something we came across like genai was nuclear\npower.\n\nCountries shall come together to regulate it.\u201d\n\nOn the other hand, people like Deepak Visweswaraiah,\nVice President, Platform Engineering and Site Managing\nDirector at Pegasus Systems, point out that \u201cControlling\nthe monster does not happen due to government\nregulations.\n\nIt should be a collective effort.\n\nHow do\nwe teach developers to be mindful of genai ethics?\n\nThe\ndevelopers should be clear about the purpose of each\nmodel and share awareness to avoid misuse.\u201d", "###### Regulation 25\n\nWhen it comes to regulation, countries will not have\nuniform reasons to regulate genai.\n\nFor\nexample, China\u2019s draft regulations are geared towards\npreventing further developments in genai technology\nthat might undermine the government\u2019s control over\ndomestic internet and tech space.\n\nOn the other hand,\nthe EU places the prevention of harm to individuals\nfront and center in its draft for the genai Act.\n\nTherefore,\nthe purpose of regulations must be defined to ascertain\nwhat the regulations should contain.\n\nAt a foundational level, all genai regulations\nshould attempt to protect individuals against potential\nharm.\n\nHarms that could include violating an individual\u2019s\nprivacy and data rights, discrimination in access\nto services, or being subject to false or misleading\nnews and information.\n\nProtection against these, and\nsimilar harms, has to be non-negotiable.\n\nThere is an\ninternational consensus on the necessity to ensure such\nprotections, though the granular details of practical\nimplementation still need to be clarified.\n\n\u201cWhen we are talking about regulation, what we are\ntrying to do is regulate the impact of technology on\nsociety.\n\nAnd sometimes we just don\u2019t know what it is\ngoing to be, and you don\u2019t want to make any regulation\nbecause probably it\u2019s too soon\u201d, says Prateek Sibal.\n\nOf late, there has been a significant debate on whether\nregulations should also include protection from secondorder harms, such as violation of intellectual property\nrights (IPR) and defamation.\n\nWhile this has not yet been\nsettled in a definitive manner, genai systems will\nlikely be subject to at least IPR laws soon.\n\n25 \u0007 INDIAai article, April, 2023.\n\nAnalyzing genai regulations based on dynamics in the genai ecosystem\n\n\n-----\n\nApart from individual harms, regulations could also\nlook at systemic harms, specifically the increased\nconcentration of economic and market power in\nthe hands of Big Tech players.\n\nThe fundamental\nrequirements for developing genai systems -\naccess to substantial amounts of data and computing\npower to process this data - are readily available only\nto the Big Tech companies.\n\n\u201cThe regulation of genai tends to focus on formal equality\nrather than substantial equality, even though the end\ngoal is often equity,\u201d points out Shashank Reddy,\nManaging Partner at Evam Law & Policy.\n\nAlgorithmic Auditing is one of the tools put forward to\nmitigate genai risk.\n\n\u201cAuditing genai systems is a mechanism or criteria for the\nsystem to comply with legal obligations.\n\nSuch legal\nobligations could be a hard law obligation, which may\nbe an existing law, or it could just be just a company\nthat is aware of the genai act or some other law and is\nlooking to be compliant with it\u201d, says Vibhav Mithal, of\nAnand and Anand and Future of Humanity.\n\nIn order to narrow down to the exact entity that is causing\nthe harm, it is very critical to examine the generative\ngenai value chain closely.\n\nCommercial genai\nsystem has four pillars: Developers, who develop the\nsystem; Deployers, who create and work on the base\nmode for advanced functionalities for themselves or\nother third-party customers; Users, who are individuals,\ncorporate organizations, or platforms who use the genai\nsystem themselves either internally or through product\nofferings; and ultimately the Recipients, people who\nreceive and use the output of the genai system.\n\n\u201cI see a lot of engineering teams being very skeptical\n\n\nImpact, Opportunity, and Challenges of genai\n\nabout the impact of what they are developing.\n\nI see\npeople from engineering teams saying I\u2019m also partly\naccountable for what I\u2019m doing.\n\nThis shows that people\nare becoming more aware and vigilant.\u201d says Anna\nDanes, a Digital Ethicist who works with organizations\nto create frameworks and practical methods to ensure\nresponsible developments in genai.\n\nShe also believes that, \u201cwe all start thinking a little bit\nabout what incentives we can give companies, private\ncompanies, and also public institutions to awaken their\nethical knowledge or imagination so that they can\ndevelop ethical products\u201d.", "###### genai regulation efforts across the globe\n\nThe capabilities of the genai models\nhave been a matter of concern for governments,\nresearchers, and the common man worldwide.\n\nAs\na result, governments worldwide have imposed genai\nregulations.\n\nThe European Union\u2019s genai Act, Canada\u2019s\ngenai and Data Act (AIDA), the United\nStates\u2019s genai Bill of Rights and State Initiatives, and\nChina\u2019s Algorithm Transparency and Promoting\ngenai Industry Development have been a subject of\ndiscussion in several forums.\n\nEach of these country\u2019s genai regulations are eceptionally\nthorough and have great visions around the usage and\nprotection of genai.\n\nWhile the genai Act concentrated on a riskbased approach to guide the use of genai in both the private\nand public sectors, the genai Bill of Rights targets specific\nuse cases.\n\nThough the Chinese government has yet to\npass rules on genai technology at large, recently, the country\nintroduced a law that regulates how private companies\nuse online algorithms for consumer marketing.\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n|Name of the country|Description|\n|---|---|\n|EU|\u2022 The EU regulation places the prevention of harm to individuals front and center in its draft genai Act.\n\n\u2022 According to the proposal, these genai tools will be classified under their perceived risk level, from minimal to limited, high, and unacceptable.\n\n\u2022 According to the proposal, these genai tools will be classified under their perceived risk level, from minimal to limited, high and unacceptable.\n\n\u2022 The act focuses on biometric surveillance, spreading misinformation or discriminatory languages.\n\n\u2022 The high-risk tools are not expected to be banned but are expected to be highly transparent in their operations.|\n|US|\u2022 The Biden-Harris Administration has announced new actions that will further promote responsible American innovation in genai, considering the people\u2019s rights and safety.\n\n\u2022 prioritize people and communities by enhancing responsible innovation that serves the public good, balancing it with protecting society, security and the economy.\n\n\u2022 companies have a fundamental responsibility to ensure their offered products are safe to use before they get deployed.\n\n\u2022 The administration released a Blueprint for an genai Bill of Right and related executive actions, the genai Risk Management Framework and a roadmap for standing up a National genai Research Resource made public earlier this year.|\n|China26|\u2022 The Cyberspace Administration of China, the country\u2019s top internet watchdog, recently passed a regulation on \u201cdeep synthesis\u201d technology, which it defines as \u201ctechnology that uses deep learning, virtual reality, and other synthesis algorithms to generate text, images, audio, video, and virtual scenes.\u201d \u2022 Users are prohibited from using genai to engage in activities that endanger national security, damage public interest, or are illegal \u2022 Anonymity doesn\u2019t exist in the Chinese internet \u2022 Wants to censor what algorithms can generate \u2022 Service providers must audit genai-generated content and user prompts manually or through technical means \u2022 Baidu, one of the first to launch a Chinese text-to-image model, already filters politically sensitive content.\n\n\u2022 The regulation bans people from using deep synthesis tech to generate and disseminate fake news \u2022 When the data used for genai training contains personal information, technology providers should follow the country\u2019s personal information protection law.\n\n\u2022 Platforms should also remind users to seek approval before they alter others\u2019 faces and voices using deep synthesis technology.\n\n\u2022 If the result of genai may cause confusion or misidentification among the public, the service provider should put a watermark in a prominent place to inform the public that it is a work by the machine.|\n\n\n\n23.\n\n\u0007 Ministry of Industry & Information Technology, Government of China, Order No.\n\n12, November 2022.\n\nProvisions on the\nAdministration of Deep Synthesis of Internet Information Services.\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n|Name of the country|Description|\n|---|---|\n|UK27|\u2022 The UK Government published28 a White Paper entitled \u201cA pro-innovation approach to genai regulation\u201d \u2022 The White Paper elaborates on the approach to genai set out by the Government in its 2022 genai Governance and Regulation Policy Statement \u2022 The white paper identifies five major principles: \u0099 The genai systems should function in a Safe, Secure and Robust manner \u0099 Transparency and Explainability of organizations developing and deploying genai to communicate about the purpose of genai systems.\n\n\u0099 The genai systems should be fair and devoid of any biases and discrimination against the users \u0099 Effective oversight is necessary for the functioning of genai systems \u0099 Contestability and redress \u2022 The white paper recognizes risks with a de-centralized regulatory framework, including inconsistent enforcement or guidance across regulators.", "\u2022 Currently, the paper is waiting for feedback until 21st June 2023|\n|Canada29|\u2022 The Government of Canada has issued The genai and Data Act (AIDA) \u2022 AIDA is an important milestone in implementing the Digital Charter and ensuring that Canadians can trust the digital technologies that they use every day \u2022 The framework proposed in the AIDA is the first step towards a new regulatory system designed to guide genai innovation in a positive direction, and to encourage the responsible adoption of genai technologies by Canadians and Canadian businesses.\n\n\u2022 AIDA would ensure that high-impact genai systems meet the same expectations with respect to safety and human rights to which Canadians are accustomed \u2022 The Minister of Innovation, Science, and Industry would be empowered to administer and enforce the Act, to ensure that policy and enforcement move together as the technology evolves.\n\n\u2022 Prohibit reckless and malicious uses of genai that cause serious harm to Canadians and their interests \u2022 The obligations for high-impact genai systems is guided by the principles of human oversight and monitoring, transparency, fairness and equity, safety, accountability, validity and robustness|\n\n\n27.\n\n\u0007 Government of China News, May 2023.\n\nXi Jinping replied to the letter and encouraged the teachers and students of Macau\nUniversity of Science and Technology\n\n28.\n\n\u0007 \u0007 Marianna Drake, Jasmine Agyekum, Marty Hansen, Lisa Peets & Mark Young, April 2023.\n\nUK Government Adopts a \u201cProInnovation\u201d Approach to genai Regulation\n\n29.\n\n\u0007 Government of Canada.\n\nThe genai and Data Act (AIDA) - Companion Document\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "### Recommendations from the roundtables\n\n1.\n\n\u0007 Foster Education and Public Awareness: It is\ncrucial to educate the public about generative\ngenai to dispel fears of job replacement and\npromote understanding of its capabilities.\n\nThis can be achieved through awareness\ncampaigns, workshops, and educational\nprograms.\n\n2.\n\n\u0007 Establish Data Sharing and Usage Regulations:\nGiven the importance of data quality in building\nrobust genai models, there is a need\nfor regulations to govern data sharing and\nusage.\n\nThis can help protect privacy, ensure\nethical practices, and maintain transparency in\ngenai development.\n\n3.\n\n\u0007 Develop Global Standards and Regulatory\nFrameworks: The lack of global standards for\ngenai poses a significant challenge.\n\nGovernments\nand international organizations should\ncollaborate to establish common frameworks\nthat address the regulatory aspects of\ngenai, including accountability, bias\nmitigation, and safety measures.\n\n4.\n\n\u0007 Encourage Self-regulation: In addition\nto governmental regulations, individuals\nand corporations involved in genai\ndevelopment should adopt self-regulatory\npractices.\n\nThis includes being clear about the\npurpose of each model, promoting ethical\nguidelines, and fostering responsible use of genai\ntechnologies.\n\n5.\n\n\u0007 Prioritize Bias Mitigation: While it may be\ndifficult to completely eliminate bias, it is\nimportant to prioritize efforts to mitigate bias\nin genai models.\n\nDevelopers should\ninvest in research and development of bias\ndetection and mitigation techniques to ensure\nfair and unbiased outcomes.\n\n6.\n\n\u0007 Explore Augmentation of Human Intelligence:\ngenai tools have the potential to\naugment human intelligence.\n\nEncourage\nresearch and development in using generative\n\n\ngenai as a tool to enhance human capabilities and\nimprove productivity across various sectors.\n\n7.\n\nFoster Collaboration and Interdisciplinary \u0007\nApproaches: The development of generative\ngenai models involves multiple stakeholders.\n\nEncourage collaboration among researchers,\ndevelopers, policymakers, and domain\nexperts to foster interdisciplinary approaches\nand ensure a comprehensive understanding\nof the societal impacts and potential risks of\ngenai.\n\n8.\n\n\u0007 Address Ethical Concerns: Given the\nintellectual capacity of genai, it is\ncrucial to address ethical concerns and\npotential misuse.\n\nDevelopers should consider\nthe ethical implications of their models and\nproactively work towards preventing any harm\nor unintended consequences.\n\n9.\n\nSupport \u0007 Accessibility and Inclusivity:\ngenai can have a positive impact on\nindividuals with communication difficulties or\ndisabilities.\n\nEncourage the development of\ninclusive genai solutions that cater to the needs of\nspeech-impaired individuals, autistic people,\nand others who may benefit from improved\ncommunication tools.\n\n10.\n\n\u0007 Emphasize Safety and Control: As generative\ngenai continues to advance, safety and control\nmeasures must be prioritized.\n\nGovernments,\norganizations, and developers should\ncollaborate to establish safeguards that prevent\nmalicious use or unintended consequences,\nensuring that the technology is harnessed for\nthe benefit of society.\n\n11.\n\n\u0007 Monitor Future Enhancements: Stay vigilant\nabout future enhancements to deep learning\nmodels that require less training.\n\nIt is important\nto carefully assess the implications of these\nadvancements, including potential risks\nand unintended consequences, to ensure\nresponsible and safe deployment of generative\ngenai technologies.\n\n-----\n\nImpact, Opportunity, and Challenges of genai", "**Team INDIAai**\n\nKavita Bhatia, Senior Director, MeitY\n\nPrashant Kumar Mittal, Director, NeGD, MeitY\n\nSushil Kumar Jangid, Scientist, MeitY\n\nBramhanand Jha, Senior Consultant - PM, MeitY\n\nSangeeta Gupta, Senior Vice President, NASSCOM\n\nAsna Siddiqui, Project Lead, INDIAai\n\nJibu Elias, Content and Research Lead, INDIAai\n\nAnjali Pathak, Product & Social Media Lead, INDIAai\n\nNibedita Saha, Senior Research Associate, INDIAai\n\nDr. Nivash Jeevanandam, Senior Research Writer, INDIAai\n\nAnjali Raja, Content & Research Associate, INDIAai\n\nMilin Stanly, Content & Research Associate, INDIAai\n\n\n-----\n\nImpact, Opportunity, and Challenges of genai\n\n\n-----", "## About this Guidance\n\ngenai is not a new concept for DPOs and data protection professionals.\n\ngenai, however, is.\n\nWhen OpenAI\u2019s ChatGPT launched in November 2022, the\nmajority of data protection professionals had never heard of genai, and were\ncertainly not concerned with such technologies in their day-to-day work.\n\nNow, with ChatGPT in the hands of over 100m users globally, and many other providers\nsuch as Google Bard and Anthropic\u2019s Claude entering the market, it has become an\noperational reality, and necessity, for data protection professionals to deal with the\nconsequences of genai tools being rapidly utilised within organisations.\n\nWhether\nthese tools are adopted simpliciter or are fine-tuned by organisations using their own data\nsets, novel and as-yet unexamined data protection implications exist, all of which data\nprotection professionals must rapidly come to terms with.\n\nThe aim of this paper is to guide data protection professionals through the maze of issues\nthat are unfolding as these technologies gain rapid adoption in organisations.\n\nAmongst\nother key issues, this paper looks at data-sharing risks, accuracy of personal data,\nconducting DPIAs on genai tools, implementing data protection by design,\nselecting a lawful basis for training genai systems, optimising organisational\nstructures, applying privacy-enhancing techniques, and handling data subject rights in the\ncontext of these technologies.\n\nThere will be no future without genai, and with data playing such a pivotal role in\nthe training and operating of these systems, DPOs will play a central role in ensuring that\nboth data protection and data governance standards are at the heart of these technologies.\n\n-----", "#### 1.\n\nAccuracy of Personal Data 4\n\n2.\n\nSharing Personal Data with genai Tools 6\n\n 3.\n\nWhat is an Appropriate Lawful Basis?\n\n7\n\n 4.\n\nRisks of Jailbreaking and Data Protection Safeguards 11\n\n 5.\n\nHow are Data Subject Rights implemented with genai Tools?\n\n14\n\n 6.\n\nData Protection by Design: How to Build genai Tools in Compliance\n\n with the GDPR 17\n\n 7.\n\nPrivacy-Enhancing Techniques and Synthetic Data 20\n\n 8.\n\nIssues specific to Image- and Audio-Based genai 23\n\n 9.\n\nManaging Data Protection Risk 24\n\n 10.\n\nTransparency and genai 27\n\n 11.\n\nOptimising Organisational Structures 30\n\n\n-----", "### 1.\n\nAccuracy of Personal Data\n\nThe accuracy of personal data processed by genai (genai) tools is a\nfundamental data protection issue with such technologies.\n\nArticle 5 (1) (d) of the GDPR states that\n\u2018Personal data shall be accurate, and where necessary, kept up to date; every reasonable step must\nbe taken to ensure that personal data that are inaccurate (\u2026) are erased or rectified without delay.\u2019\n\nIt is obvious, and a matter of common sense that the processing of inaccurate personal data can\nhave very real-world implications for the data subject behind the data, yet genai tools,\nsuch as OpenAI\u2019s widely used text-based chatbot, ChatGPT, inherently have numerous\ninaccuracies in the data they process.\n\nBy their nature these tools ingest vast amounts of training\ndata, sourced from massive data scraping exercises across the internet.\n\nNecessarily, this data\ncomes with all of its imperfections, and becomes a part of the data bank which users of ChatGPT\nmake queries against.\n\nWhen a user receives an answer that is either wholly or partly inaccurate,\nthis generates what genai providers call \u2018hallucinations\u2019 or, in the vernacular, \u2018falsehoods\u2019.\n\nEven OpenAI itself, on its website, warns users about the perils involved and that the accuracy of\ndata retrieved cannot be automatically trusted.\n\nUnder a section entitled \u2018Limitations\u2019 it notes\n\u2018ChatGPT sometimes writes plausible-sounding but incorrect or nonsensical answers\u2019 1 .\n\nCompounding the issue, OpenAI further notes that the tool will often add to inaccuracies by\nessentially guessing what an uncertain user means.\n\nIt states: \u2018Ideally, the model would ask clarifying\nquestions when the user provided an ambiguous query.\n\nInstead, our current models usually guess\nwhat the user intended.\n\n2 \u2019\n\nWhen coupled with the fact that ChatGPT\u2019s data processing terms make it clear that the user is\nthe data controller, while OpenAI is merely the data processor, it should be clear, for users, that\nthis is very much a \u2018buyer beware\u2019 market.\n\nWhy?\n\nBecause if any party further processes inaccurate\npersonal data, it will become liable for any non-compliance with Article 5 (1) (d) above.\n\nIn the\ncontext of ChatGPT, then, relying upon inaccurate personal data provided by the tool will make\nthe user liable to non-compliance with the GDPR, especially where such re-use impacts the\nfundamental rights and freedoms of data subjects.\n\n1 \n2 Ibid.\n\n-----\n\nOrganisations should understand that this is not merely a theoretical point and that regulators\nhave already called genai companies to account for the accuracy of their data.\n\nIn March\n2023, the Italian Data Protection Authority blocked the deployment of ChatGPT in Italy, noting,\namongst other matters, that the data was frequently not accurate.\n\nIt noted, based on \u2018tests carried\nout so far, the information made available by ChatGPT does not always match factual\ncircumstances, so that inaccurate personal data are processed.\u2019 3\n\nData protection officers (DPOs) must remain aware, then, of the risks of processing inaccurate\ndata.\n\nUsers within a DPO\u2019s organisation should be given clear guidelines to help them to\nunderstand that the outputs of any genai tools, such as ChatGPT, come with a health\nwarning, namely, that the human user is still ultimately responsible for verifying the accuracy of\nany personal data obtained.\n\nThis is a critical point.\n\nA further related risk comes from the second clause of Article 5 (1) (d), that personal data shall be\n\u2018kept up to date\u2019.\n\nChatGPT, and similar tools such as Google\u2019s Bard and Anthropic\u2019s Claude, rely on\ndata scraping activities up to a certain point in time, meaning that their data bank becomes outof-date and so, eventually, are necessarily not responding to up\u2013to-date events.\n\nThis creates the\nclear risk that users will obtain personal data that is no longer relevant, or perhaps lacks context,\nor is simply outrightly inaccurate, given how events have changed or how information has moved\nforward in the intervening period.\n\nDPOs should also remain aware of the ways in which unmitigated bias and discrimination in the\ntraining sets could indirectly lead to inaccurate data outputs, again opening up the user to the risks\nof further processing inaccurate data.\n\nA final, global risk with genai chatbots is the tone that they adopt: an oracular level of\ncertainty and authority that might almost be called a dark pattern, so misleading is it in its effect\non the evaluation of search results.\n\nWhen genai chatbots are palpably wrong or inaccurate,\nthey are often wrong in a very confident and confusingly definitive manner, an attitude that masks\nthe fact that, as OpenAI, for instance admits, the answer may simply be \u2018nonsense\u2019.\n\nIn any search\nresults, the tone of the response should be ignored, and again, users should realise that the output\nof these tools requires human evaluation, certainly when it concerns questions over the accuracy\nof any personal data involved.\n\n3 \n\n\n-----", "### 2.\n\nSharing Personal Data with genai Tools\n\ngenai (genai) has rapidly evolved from a concept of science fiction to a relatively\ncommon feature of our life.\n\nA rapidly emerging branch of genai is genai, which can create\nnew, previously non-existing data that closely mimics the input data.\n\ngenai models can,\nunder the right conditions, generate high-quality text, images, music, and more.\n\nHowever, the\nconvenience and innovative potential of genai comes with a cost.\n\nDespite its promising\ncapabilities, the sharing of personal data with these systems presents substantial risks for privacy,\nconfidentiality, and the integrity and security of data.\n\nUnderstanding these risks is essential in\norder to protect individual data protection rights, and to maintain a secure digital environment.\n\nLike most genai systems, genai is data-driven.\n\nTraditional genai training involves feeding large\ndatasets into genai models which can then learn patterns and features from this data.\n\nOnce the\ntraining is complete, the genai system is equipped to generate outputs based on the patterns and\nfeatures learned.\n\nThis means that once personal data is part of the genai\u2019s training set, it contributes\nto the formation of the genai\u2019s internal model, and will invariably influence its behaviour and outputs.\n\nEffectively, the data becomes \u201cpart\u201d of the genai, in the sense that it informs the system\u2019s\nunderstanding and knowledge.\n\nThis presents significant data protection concerns where personal\ndata features as training data.\n\ngenai models trained on personal data can potentially extract sensitive information like\nnames, addresses, health information, or even financial data, and then republish that data in search\nresults for different users.\n\nAdditionally, genai models can amplify exposure by generating\nmore data similar to the original input.\n\nThird parties may then exploit this data for unlawful\nactivities including invasive advertising, phishing scams, or in more serious cases, fraud or identity\ntheft.\n\nThis highlights the complexities of controlling how personal data is used by genai\nmodels.\n\nOnce personal data has been shared with genai models, managing and tracking its\nusage becomes an intricate (if not impossible) task, due to the nature of how genai systems process\ninformation as well as store and replicate data across different systems.\n\nTherefore, retracting\npersonal data shared with genai models may be incredibly difficult or unrealistic.\n\nThe\nlesson for DPOs is that users _must_ understand precisely what kinds of information _can_ and _cannot_\nbe shared with genai tools, because once personal data is shared, the Rubicon has been\ncrossed, and it will be very difficult to undo what has been done.\n\n-----\n\nOne of the more alarming risks associated with sharing personal data with genai is the\ncreation and proliferation of \u2018deepfakes\u2019.\n\nDeepfakes refer to the application of genai to create, alter\nor manipulate content, such as images, audio, and video, in such a way that it fabricates hyperrealistic but entirely false content.\n\nBy training on personal data, genai can generate\nsynthetic media that convincingly impersonate natural or legal persons.\n\nThese deepfakes can then\nbe used maliciously, such as in disinformation campaigns, fraud, or harassment.\n\nRelated to this is\nthe fact that the accuracy of genai decisions heavily depends on the quality and diversity\nof the input training data.\n\nIf this personal data is biased, the genai's outputs can also become biased,\nleading to unfair consequences.\n\ngenai holds significant promise for numerous applications, but its use of personal data\nmust be carefully managed to mitigate potential risks.\n\nBy employing strong data protection\ncontrols, ethical genai practices, and robust legal protections, it may be possible to harness the\npotential of genai while safeguarding individual data protection rights and fostering a safe\nand secure digital environment.", "### 3.\n\nWhat is an Appropriate Lawful Basis?\n\nThe lawful basis that properly applies to the training of genai systems with personal data is a key\nconsideration.\n\nPrima facie, there is no obvious candidate that would both clearly legitimise this\nprocessing activity and also uphold the data protection rights of affected individuals.\n\nThis is a\ncritical consideration because the volume of training data that is used for genai\napplications is enormous, and only growing in size.\n\nIf such training activities are to continue, and if\ngenai is to deliver on its promise, then it cannot be founded on an uncertain lawful basis as regards\npersonal data.\n\nMoreover, the genai Act (genai Act) is not particularly instructive on this\npoint given that Article 10, (which deals with data governance and the governance of training data\nfor genai systems), does not create a lawful basis specific to the use of personal data for the training\nof genai systems.\n\nIt is, then, to the GDPR that we must turn for a suitable lawful basis for this activity.\n\nFirstly, we will briefly look at how data is used to train genai systems.\n\nThis takes place in\nfour broad ways:\n\n**1.\n\n** Based on personal data that has been scraped from the internet;\n**2.\n\n** Where the personal data has been provided by the users of the genai system, such as when\n\nthey submit prompts to genai tools;\n\n\n-----\n\n**3.\n\n** Where the personal data has been collected from third parties, such as data brokers, or\n\ncompanies that have databases which are relevant to the genai training phase (for instance, a\ndatabase of court decisions for a predictive genai tool in the legal domain); and\n\n**4.\n\n** When genai developers/operators use the personal data held in their own databases to train\n\nthe genai system.\n\nIn these cases, under Article 6 of the GDPR, three lawful bases are most relevant: contract,\nlegitimate interest and consent.", "**1.\n\n** **Contract:**\n\nArticle 6(1)(b) of the GDPR notes that contract may form a legal basis for processing personal data\nwhere that \u2018processing is necessary for the performance of a contract to which the data subject is\nparty or in order to take steps at the request of the data subject prior to entering into a contract.\u2019\n\nThe application of the first branch of the contract legal basis ( _i.e.,_ the performance of the contract\nitself) would require demonstrating that the training of the genai system (and not the use of the genai\nonce trained) is strictly necessary to the performance of a contract with the data subject.\n\nThis necessity requirement is interpreted very narrowly by the data protection authorities.\n\nAccording to the European Data Protection Board (EDPB), it should not be possible to perform the\nmain subject-matter of the specific contract with the data subject, if the processing of the personal\ndata in question does not occur.\n\nIn other words, processing the personal data in this way should\nbe a necessary condition for performing the contract.\n\nConsidering this narrow interpretation, there is very little room for the contract basis when training\nan genai system.\n\nThis basis could theoretically be applied when the use of the genai system _is_ the subject\nmatter of the contract entered into between the genai operator and the user, and when there is no\nother way to perform this contract than to train the genai with the data of the users.\n\nAs for the second branch of this legal basis, _i.e.,_ the pre-contractual steps, its application would\nrequire demonstrating that a data subject made a request in the context of potentially entering a\ncontract and that there is no other way to meet his/her demands than to train (and not only use\nonce trained) the genai.\n\nThis is an even more restrictive and limited option than the first part of this\nlegal basis.\n\n-----\n\nOn the whole, the circumstances in which the lawful basis of contract might be used to justify\ntraining genai systems with personal data are very limited and, in practical terms, this basis will not be\na viable option for grounding such processing activities.\n\nIn the case of genai, contract as a lawful basis is, in any case, particularly unsuitable given\nthat typically no contract exists between the data subjects whose data is used, and the\norganisations responsible for training such systems with that data.", "**2.\n\n** **Legitimate Interests**\n\nThe legitimate interests basis could only apply provided that a legitimate interest assessment is\ncompleted by the data controller to ensure that these interests are not overridden by the interests\nor fundamental rights and freedoms of the data subject.\n\nThis may however be challenging especially since, most of the time, the organisation behind\ntraining genai tools, such as OpenAI, is not in direct contact with the data subjects, nor\ndoes it have any form of relationship with those data subjects.\n\nIn this regard, the recent actions of\nthe Italian Data Protection Supervisory Authority (Garante per la protezione dei dati) against\nChatGPT should be noted.\n\nIn March 2023, the authority blocked ChatGPT in the Italian territory\nuntil OpenAI was able to satisfactorily answer certain questions, one of which was that OpenAI\nneeded to specify the lawful basis for training ChatGPT with personal data.\n\nIn its response to this\npoint, OpenAI identified legitimate interests as the lawful basis.\n\nThis is a highly significant\ncommitment and statement by OpenAI as it effectively ties the huge task of training genai\nsystems to a lawful basis that is inherently uncertain, given data subjects\u2019 explicit right under\nArticle 21 of the GDPR to object to such processing.\n\nTo effectively be able to rely on the legitimate interests basis would require in particular:\n\n-  a study on a case-by-case basis of the context of training and of use of the genai, as well of\n\nthe collection of the personal data used to verify that the data processing will meet the\nreasonable expectations of the data subjects;\n\n-  a demonstration of the strict necessity of this processing and of the fact that the genai cannot\n\nwork efficiently without being trained with the personal data in question;\n\n-  an enhanced transparency of the data processing towards the data subjects.\n\nThe provision\n\nof all the required information under GDPR would need to be provided to the data subjects\nin an appropriate way;\n\n\n-----\n\n-  an effective opt-out system brought to the knowledge of the data subjects within a\n\nreasonable period before their data are provided to the genai system 4 ;\n\n-  more generally an efficient system for ensuring the respect of the data subjects\u2019 rights\n\nwhich would be difficult to implement given the particularities of genai functioning", "**3.\n\n** **Consent:**\n\nThe consent basis could also apply, but only in very clearly circumscribed circumstances.\n\nWhile in\nthe extreme cases, it may be the only legal basis possible (for instance when processing special\ncategories of data or data concerning minors) as a general rule it has very little place in the training\nof genai systems, as currently conceived.\n\nThe entire apparatus used for the training of genai\nsystems makes it almost impossible to obtain consent.\n\nThis is because, in the first instance, the\nmajority of the data used to train such systems is purchased from data brokers that have obtained\nthis data by scraping the internet, an activity which necessarily does not involve the obtaining of\nconsent from underlying data subjects.\n\nIndeed, the very lawfulness of data scraping as a\ncommercial activity is far from certain and the recent joint communication by twelve global data\nprotection authorities, including the UK\u2019s Information Commissioner\u2019s Office, underlines this\npoint.\n\n5\n\nTo use consent as a lawful basis, would require meeting all the requirements for valid consent\nunder the GDPR, meaning that it would need to result from a clear affirmative action, be freely\ngiven, specific, informed and unambiguous.\n\nThis is indeed a very high bar to reach in the world of\ntraining genai systems.\n\nIf the genai provider is not in contact with the data subjects, as is generally the case, this consent\nwould have to be collected by the user of the genai system, the organisation with whom the data\nsubject _does_ have a relationship.\n\nHowever, this will usually be after the fact, when the genai system\nhas already been trained, so to object to the processing would most of the time be irrelevant since\nthe data processing would have already occurred.\n\nMoreover, it would also be very difficult to\n\n4 If the opt-out system is brought to their knowledge after the training of the genai, to object to the processing would\nmost of the time be, in one hand, irrelevant since the data processing would have already occurred and, on the other\nhand, very difficult to stop when vast amounts of personal data regarding numerous data subjects are being fed to an\ngenai ( _see part XXX regarding the exercise of the data subjects\u2019 rights_ ).\n\n5 \n\n\n-----\n\nreverse when vast amounts of personal data regarding numerous data subjects will already have\nbeen ingested by the genai system.\n\nIn conclusion, legitimate interest is most likely the most suitable basis for training genai systems with\npersonal data, however, as stated above, it does not provide a certain foundation given the need\nfor a legitimate interests assessment to be carried out, as well as the fact that data subjects can\nobject to such processing at any point.", "### 4.\n\nRisks of Jailbreaking and Data Protection Safeguards\n\nSoon after ChatGPT was released, hackers began attempting to \"jailbreak\" the genai chatbot, trying\nto bypass its safeguards and make it say inappropriate or irrational things.\n\nThese intricately\nphrased prompts that aim to bypass the restrictions imposed on genai programmes have come to be\nknown as \u2018Jailbreaks\u2019.\n\nThis term was originally used in the context of digital technology to refer to\nthe act of gaining access to the operating system of a smartphone or tablet, especially one\nmanufactured by Apple, in order to run modified or unauthorised software.\n\nIn the context of genai models, the term now refers to the design of prompts that make\nthe chatbots bypass rules around producing hateful content or writing about illegal acts.\n\nThese\nattacks involve manipulating the genai systems to produce content that goes against their\nintended rules, such as generating hateful or illegal material.\n\nAnother use of these attacks could\nbe slander and a personal attack upon an individual once personal data has been leaked.\n\nA security firm that specialises in genai, was able to break GPT-4, OpenAI's latest text-generating\nchatbot, in just a few hours after the initial release of the system.\n\nUsing carefully crafted prompts,\nthe CEO of the security firm bypassed OpenAI's safety systems and quickly had GPT-4 generating\nhomophobic statements, creating phishing emails, and endorsing violence.\n\nThis deviant behaviour\nposes a serious risk as it has the potential to expose personal data that has been inadvertently, or\nperhaps even intentionally, input into the system and, thus, has the potential to be manipulated by\nbad actors.\n\nA closely-related attack is the prompt injection attack that can quietly insert malicious data or\ninstructions into genai models.\n\nA prompt injection attack aims to elicit an unintended response from\nLLM-based tools.\n\nAnd then achieve unauthorised access, manipulate responses, or bypass security\n\n\n-----\n\nmeasures.\n\nThe specific techniques and consequences of prompt injection attacks vary depending\non the system.\n\nJailbreaks and prompt injection attacks are a form of unconventional hacking, using well-crafted\nsentences instead of code to exploit weaknesses in genai systems.\n\nWhile these attacks are currently\nfocused on bypassing content filters, security researchers warn of the potential for data theft and\nwidespread cybercriminal activities as genai systems become more prevalent.\n\nNumerous popular online services and products heavily rely on large datasets to train and improve\ntheir genai algorithms.\n\nData streams from networks, social media platforms, mobile devices, and\nvarious other sources contribute to the vast amount of information that businesses utilise to train\ntheir machine learning systems.\n\nIt is, hence, important to note that some of the data contained\nwithin these datasets could probably be considered personal data, even by users who are less\nconcerned about data protection.\n\nUnfortunately, due to the misuse and mishandling of personal\ndata by certain companies, data protection has consequently become a pressing global policy issue.\n\nIn a similar vein, much of our sensitive data is also gathered to enhance genai-enabled processes.\n\nThis\ndata plays a crucial role in driving the adoption of machine learning, as sophisticated algorithms\nrely on such data for real-time decision-making.\n\nSearch algorithms, voice assistants,\nrecommendation engines, and other genai solutions leverage extensive datasets of real-world user\ndata to provide personalised and relevant outputs.\n\nEarly in 2023, a website called Jailbreak Chat was launched where prompts for genai chatbots like\nChatGPT from online forums are collected and shared.\n\nVisitors to the site can contribute their own\njailbreaks, try out prompts submitted by others, and vote on their effectiveness.\n\nMalicious users\ncould leverage these jailbreaks to gather personal data contained within the systems to carry out\ncrimes like identity theft and to create deepfakes to impersonate living individuals.\n\nThe implications of jailbreaks and prompt injection attacks become more significant when these\nsystems gain access to personal and sensitive data.\n\nFor example, if a successful prompt injection\nattack instructs a personal assistant genai to ignore previous instructions and send an email to all\ncontacts, it could lead not only to embarrassment on the part of the individual but to widespread\nissues for the affected individuals and the rapid spread of harmful content across the individual\u2019s\npersonal and working networks.\n\n-----\n\nEnsuring the safety of foundation models like ChatGPT is paramount as their use becomes more\nwidespread.\n\nThe hackers, however, will not give up easily.\n\nAs genai systems have evolved, the\njailbreaks have become more complex.\n\nSome involve multiple characters, intricate backstories,\ntranslation, and even elements of coding to generate specific outputs.", "As genai systems have evolved, the\njailbreaks have become more complex.\n\nSome involve multiple characters, intricate backstories,\ntranslation, and even elements of coding to generate specific outputs.\n\nSome authorised \"red teams\" prompt attacks on genai models to uncover vulnerabilities.\n\nA red team\nin cybersecurity represents the offensive security team, which is responsible for discovering\nsecurity vulnerabilities through penetration testing.\n\nWith genai, these teams look for exploits that\ninclude actual vulnerabilities, influencing the system\u2019s behaviour, or deceiving users to get around\nthe system's security.\n\nOther attempts come from hobbyists who like to showcase humorous or\ndisturbing outputs on social media.\n\nThis approach to security is suboptimal as it is fragmented and\nrelies on viral exposure and influential individuals to prompt fixes.\n\nWhile companies like OpenAI, Google, and Microsoft have taken steps to address jailbreaking and\nprompt injection attacks, the researchers behind these attacks continue to find new ways to\nexploit vulnerabilities.\n\nThe development of genai systems requires approaches beyond\ntraditional red-teaming methods, such as using a second genai model to analyse prompts or clearly\nseparating system prompts from user prompts.\n\nAutomation and advanced techniques are necessary to identify and mitigate jailbreaks and\ninjection attacks at scale.\n\nBy automating the process of identifying vulnerabilities and unintended\nbehaviours, researchers aim to discover and address a greater number of these security risks.\n\nThese types of automated techniques can be seen as the starting point for a deeper commitment\nfrom genai developers to assess and evaluate the safety of their systems.\n\nBy involving a diverse range\nof participants and prioritising transparency and accountability, the goal is to enhance the safety,\nreliability, and ethical use of genai technology.\n\nThird-party assessments, automated\nmitigation of jailbreaks and using red-teaming, will play a pivotal role in achieving this goal and\nimproving the practices surrounding genai development in order to meet the requirements of both\nthe GDPR and the forthcoming genai Act.\n\n-----", "### 5.\n\nHow are Data Subject Rights implemented with\n\ngenai Tools?\n\ngenai, or GenAI, are genai systems capable of generating text, images, or other media in\nresponse to prompts.\n\nGenerative models learn the patterns and structure of input data,\nsubsequently generating new content similar to the training data, but with a degree of novelty, as\nopposed to merely classifying or predicting data.\n\nThese genai systems are often based on Generative\nPretrained Transformers (GPT), artificial neural networks built on the transformer architecture,\npretrained on large sets of unlabelled text data, and capable of generating human-like text.\n\nThey\nemploy large language models (LLMs) to produce data based on the training dataset that was used\nto create them.\n\nUnderstanding the technology behind genai is vital to realising that these tools encompass\nvarious phases, and personal data can be processed at each phase.\n\nHowever, the processing of\npersonal data at one phase does not necessarily imply data processing at another.\n\nThe stages under data protection law where data subject rights pertaining to personal data might\napply in the genai context include:\n\n1.\n\nThe training data phase, when personal data is incorporated.\n\n2.\n\nThe deployment phase, where personal data is used to generate content and the\n\ncontent result itself.\n\n3.\n\nThe model itself, which might contain personal data.\n\nIt is also essential to point out that genai software can indirectly process data, particularly\nrelated to the user of the solution, such as account data or metadata related to the use of the\nsolution.\n\nIn common machine learning models, identifying the individuals that the training data is about is a\npotential challenge to ensuring their rights.\n\nUsually, this data includes only the information\npertinent to predictions, without unique data subject identifiers.\n\nIt undergoes various preprocessing measures to make it suitable for machine learning algorithms, often transforming\npersonal data into a form that's harder (but not impossible) to link back to specific individuals.\n\nData\nprotection laws might, therefore, still apply to this transformed data, as it could still be used to\n\n\n-----\n\nidentify individuals.\n\nThis process necessitates consideration when responding to individuals' rights\nrequests.\n\nThis process is different for genai models than it is for common machine learning models\nas explained in the previous paragraph.\n\ngenai models are often trained with data\naccessible on the web, and their value also often lies in generating results related to physical\npersons, implying a significant amount of personal data in the training data for these models.\n\nAs a\nresult, these datasets could be the target of data subject requests.\n\nIn genai models, 'continuous learning' also poses unique challenges for GDPR compliance.\n\nThese models are regularly updated based on user interactions, meaning personal data is\ncontinuously processed.\n\nThis data mostly originates from the interactions and prompts of the tool's\nusers and it should be noted that the data subjects and the data providers are not necessarily the\nsame entity in the context of continuously learning genai models.\n\nGiven these considerations, navigating data rights under the General Data Protection Regulation\n(GDPR) in the context of genai models presents unique challenges, particularly for the\nrights of Erasure, Rectification, Access, and Objection.\n\nThe first shared issue is the non-retrievability of data in genai models.\n\nAs previously\nmentioned, these models source data from a wide array of origins, like web scraping and user\ninteractions.\n\nThis multifaceted approach to data collection makes it more difficult to trace\nindividual contributions.\n\nFurthermore, in contrast to traditional data storage systems, in GenAI\nsystems, personal data are also deeply embedded within complex algorithms, complicating the\nisolation of specific data.\n\nThis makes it challenging to fulfil GDPR rights since identifying whether\nand where personal data are processed within the system.\n\nAdding another layer of complexity is the issue of \"inferred personal data.\"\n\nThese are conclusions\nthat the model may draw based on its training.\n\nFor example, a genai model could deduce\na user's political affiliations based on past data interactions.\n\nThe prevailing opinion leans towards\nincluding these inferences when responding to rights requests, as they could indirectly reveal\npersonal information.\n\nThe concept of \"inferred group data\" also deserves attention.\n\nThis type of\ndata is generated based on broader patterns recognised during training.\n\nWhether this group data\nis considered personal depends on its subsequent processing and utilisation.\n\n-----\n\nBeside common challenges, there\u2019s also specific ones related to individual rights that require data\nmodification or erasure.\n\nNotably altering or removing data from the training set after a Data\nSubject Request (DSR) could impact the model's validation and correctness.", "Notably altering or removing data from the training set after a Data\nSubject Request (DSR) could impact the model's validation and correctness.\n\nThe original data often\nserving as a foundation for such validation processes.\n\nMoreover, the erasure or modification of\ndata that is already embedded in the model would often imply to remove or modify this data to\nretrain the model, a task that is both costly and time-consuming.\n\nIn summary, the intersection of GDPR rights and genai models presents a labyrinth of\nchallenges, each with its own intricacies and complications.\n\nThe very nature of these models, from\nthe way they embed and process data to the difficulties in tracking individual contributions, adds\nlayers of complexity to GDPR compliance.\n\nWhile no silver bullet exists to seamlessly navigate these\nchallenges, the evolving landscape does offer some emerging solutions that could serve as starting\npoints for compliance.\n\nTo begin with, despite the absence of a one-size-fits-all solution, proactive steps can be taken.\n\nImplementing the principle of 'privacy by design and by default' during the GenAI model's creation\nand deployment phases provides a foundational layer of data protection that is integrated right\nfrom the beginning.\n\nIn navigating the complex terrain of data protection, one could consider a pre-emptive strategy\nthat narrows down the scope of data and its identifying features.\n\nBy doing so, it could be possible\nto potentially alleviate many of the complexities that might arise later in the data processing cycle.\n\nData minimisation could serve as an essential part of this early-stage planning, guiding data\ncontroller to collect only what is truly necessary.\n\nBuilding on this, anonymisation techniques of\npersonal data or the use of Privacy Enhanced Technologies (PETs), such as synthetic data, could\nallow a further reduction in the scope potentially affected by DSR.\n\nMoreover, investing in proactive measures like data mapping and data labelling is crucial.\n\nSuch\nmeasures offer clarity on the origins and characteristics of training data, making it easier to handle\nrights requests in subsequent phases.\n\nAs genai models transition from development to deployment, the focus shifts towards\noptimising adaptability and traceability.\n\nIn this stage, maintaining meticulous data processing\nrecords is not just good practice but becomes indispensable for facilitating responding right\nrequests.\n\nThis is all the more important given the increased malleability of data at this stage.\n\nIn\naddition, the challenges of continuous learning in deployed models can be effectively addressed\n\n\n-----\n\nthrough versioning techniques.\n\nThis enables efficient rollback to a previous model state without\nthe laborious need to retrain from the ground up.\n\nThis linkage ensures that both adaptability and\ntraceability are addressed, providing a robust framework for compliance.", "### 6.\n\nData Protection by Design: How to Build genai\n\nTools in Compliance with the GDPR\n\nData protection by design plays a pivotal role in ensuring compliance with the General Data\nProtection Regulation (GDPR).\n\nIt entails safeguarding personal data from the very early stages of\ndesign throughout the entire lifecycle of the system.\n\nThe idea of data protection by design came\nfrom a more general set of privacy principles entitled Privacy by Design first developed in Canada\nin the early 2000s.\n\nPrivacy by Design is an approach to systems engineering that was initially\ndeveloped by Ann Cavoukian and formalised in a report on privacy-enhancing technologies by a\njoint team of the Information and Privacy Commissioner of Ontario (Canada), the Dutch Data\nProtection Authority, and the Netherlands Organisation for Applied Scientific Research in 1995.\n\nThe Privacy by Design framework was published in 2009 and adopted by the International\nAssembly of Privacy Commissioners and Data Protection Authorities in 2010.\n\nIn the same year,\nthe International Conference of Data Protection Authorities and Privacy Commissioners\nunanimously passed a resolution recognising Privacy by Design as an essential component of\nfundamental privacy protection.\n\nThis was followed by the U.S. Federal Trade Commission\u2019s\ninclusion of Privacy by Design as one of three recommended practices for protecting online\nprivacy.\n\nShortly after 2010, Europe began working on revising its data protection laws.\n\nInspired by Privacy\nby Design and its principles, Europe put together data protection by design principles which were\nintroduced into law via Article 25 of the General Data Protection Regulation (GDPR) in 2018.\n\nIn recent years, the swift development of genai has given rise to an increased awareness\nof potential risks and ethical considerations when designing systems which process personal data.\n\nThese concerns encompass not only complex data protection risks like the leakage of sensitive\ninformation and chat histories but also a range of threats to the data subject rights of EU citizens,\nincluding the \"right to be forgotten.\"\n\nThis right allows individuals to request the deletion of their\npersonal data by a company.\n\nWhile deleting data from databases is relatively straightforward,\nremoving data from machine learning models is a more complex task.\n\nAnonymisation techniques\n\n\n-----\n\nand data minimisation practices can help strike a balance between upholding individuals' rights and\npreserving the overall usefulness of the genai model.\n\nSomething to consider from a human perspective is that due to the complexity of modern genai\nsystems, the people involved in building and deploying genai systems are often likely to have a wider\nrange of skills and backgrounds than the usual systems developers, including traditional software\nengineering, systems administration, data scientists, statisticians, as well as domain experts.\n\nBecause of this wide range of expertise, there may be less understanding of broader security\ncompliance requirements, as well as those of data protection law more specifically.\n\nFor these\nindividuals, security of personal data may not always have been a key priority, especially if\nsomeone was previously building genai applications with non-personal data or in a research capacity\nwhere personal data was protected in sandboxes.\n\nBiased algorithms are another significant data protection concern.\n\ngenai systems learn\nfrom vast amounts of data, and if that data is biased, the algorithms can perpetuate and amplify\nthese biases in their outputs.\n\nThis raises ethical questions about fairness, discrimination, and the\npotential harm caused by biased genai-generated content when used to make important, lifechanging decisions about data subjects.\n\ngenai hallucinations refer to instances where genai systems produce outputs that are not\nbased on real or accurate information.\n\nThese hallucinations can mislead users and have potential\nimplications for the safety of data subjects.\n\ngenai systems must provide reliable and\ntrustworthy outputs, especially about European citizens whose personal data and its accuracy is\nprotected under the GDPR.\n\nThe rise of deepfakes, which are realistic but manipulated audio or video content, has also been\nassociated with genai technology.\n\nDeepfakes have the potential to manipulate public\nopinion, spread misinformation, and pose risks to public safety.\n\nThe ethical implications of\ndeepfakes highlight the need for robust measures to prevent their creation and to detect and\ncombat their dissemination.\n\nA fundamental aspect of data protection by design is transparency.\n\nIt plays a crucial role in data\nprotection by design and ensures accountability within genai systems.\n\nOrganisations must be\ntransparent about their data practices, providing clear explanations of how genai systems work and\nthe decisions they make.\n\nHowever, achieving transparency in genai systems can be challenging due\n\n\n-----\n\nto their complexity.", "However, achieving transparency in genai systems can be challenging due\n\n\n-----\n\nto their complexity.\n\nIt is essential to develop methods and tools that enable the explanation of\nalgorithmic predictions to end-users in a meaningful and understandable manner.\n\nFurther complications arise because common practices about how to process personal data\nsecurely in data science and genai engineering are still under development.\n\nAs part of an\norganisation\u2019s compliance with the security principle of GDPR, they should ensure that they\nactively monitor and take into account the state-of-the-art security practices when developing genai\nsystems and when using personal data in an genai context.\n\nIt is not possible to list all known security risks that might be exacerbated by the use of genai to\nprocess personal data.\n\nWhatever the risk, however, companies should ensure that staff have\nappropriate skills and knowledge to address not only security risks but also data protection risks.\n\nThis is where the importance of GDPR training comes in.\n\nThe effectiveness of genai models heavily relies on the quality of the data they receive, making data\nprotection an integral aspect of their design.\n\nThe utilisation of sensitive data during the training of\ngenai algorithms can result in the emergence of personal information in chatbot outputs\nor compromise data security during cyberattacks.\n\nThus, when designing genai products, it is paramount to decouple personal data from individual users\nthrough the use of synthetic datasets with full anonymisation and non-reversible identifiers for\nalgorithmic training, auditing, and quality assurance, among other practices.\n\nImplementing strict\ncontrols on data access within the company and conducting regular audits can help prevent data\nbreaches.\n\nIt is also important to acknowledge that more data does not necessarily equate to better solutions.\n\nTesting algorithms using data minimisation can help determine the least amount of data required\nfor a viable use case.\n\nAdditionally, providing a streamlined process for users to request the removal\nof their personal data is critical.\n\nAdopting adversarial learning techniques, which involve combining conflicting datasets during the\nmachine learning process, can help identify flaws and biases in genai algorithm outputs.\n\nAdditionally,\nexploring the use of synthetic datasets that do not contain actual personal data is a potential\napproach, although further research is required to assess their effectiveness.\n\n-----\n\nOrganisations must align responsible use of genai with existing data protection principles outlined in\nthe GDPR.\n\nThese guidelines should encompass various aspects such as accountability, human\nintervention, accuracy, security, bias prevention, and explainability of automated decision-making.\n\nContinuous investments in privacy measures, upskilling in algorithmic auditing, and the adoption\nof ethics, security, and data protection by design methodologies are necessary to effectively\nnavigate the opportunities and risks associated with genai.\n\nTechnologies such as\ndifferential privacy offer privacy-preserving techniques that can be incorporated into generative\ngenai systems.\n\nScalable methods for cleaning datasets, including deduplication and training data\ndisclosure requirements, contribute to addressing privacy-related challenges.\n\nThe collective efforts of the data protection and engineering community, coupled with the\ncommitment of individual organisations and privacy professionals, play an indispensable role in\naddressing the data protection concerns surrounding genai.\n\nBy adhering to the principles\nof data protection by design and integrating comprehensive data protection and fundamental\nrights assessments, organisations can strive towards the trustworthy implementation of generative\ngenai while maintaining GDPR compliance.\n\nIt is essential to continue investing in data protection\ntraining, upskilling in algorithmic auditing, and integrating ethics, security, and data protection by\ndesign methodologies to ensure the responsible and ethical use of genai.", "### 7.\n\nPrivacy-Enhancing Techniques and Synthetic Data\n\ngenai tools are complex tools, and like all such technologies, they present many significant\nlegal challenges.\n\ngenai is hungry for data, but such data, (especially quality data), may be\nhard to come by, or may be legally protected, either from an intellectual property or a data\nprotection legislation\u2019 s standpoint.\n\nFrom the data protection perspective, privacy enhancing technologies (PETs) may represent a valid\nsolution to tackle data protection concerns, in terms of data minimisation, integrity, confidentiality,\nand data protection by design.\n\nThe European Union Agency for Cybersecurity (ENISA) defines\nPETs as \u201c _software and hardware solutions (e.g., systems encompassing technical processes, methods or_\n_knowledge) to achieve specific privacy or data protection functionality or to protect against risks of_\n_privacy of an individual or a group of natural persons_ \u201d,\n\nAmong the various PETs that could be deployed in the context of genai, data synthesis\nalgorithms which generate \u201cartificial\u201d data, better known as synthetic data, can play a pivotal role.\n\n-----\n\nAccording to the European Data Protection Supervisor (EDPS) \u201c _Synthetic data is artificial data that_\n_is generated from original data and a model that is trained to reproduce the characteristics and structure_\n_of the original data (...).\n\nThe generation process, also called synthesis, can be performed using different_\n_techniques, such as decision trees, or deep learning algorithms.\n\nSynthetic data can be classified with_\n_respect to the type of the original data: the first type employs real datasets, the second employs_\n_knowledge gathered by the analysts instead, and the third type is a combination of these two._ \u201d\n\nIn essence, synthetic data is computer-generated data which is derived from existing real data, or\nfrom algorithms and models which replicate, fully or partially, features, patterns and properties of\nreal-world data.\n\nThe use of synthetic data may therefore bring many advantages when it comes to the training of\ngenai tools, particularly as it:\n\na) reduces the need for harvesting large amounts of real personal data.\n\nIn the genai model-\n\ntraining phase this is especially important as it allows engineers to generate much larger\ndata sets from relatively small amounts of personal data;\n\nb) allows near-perfect labelling (e.g., exactly defined for the developing of a specific genai model)\n\nand higher quality data, thereby supplementing or substituting real world datasets.\n\nA study\nfrom Gartner has predicted that \u201c _by 2024, 60% of the data used for the development of AI_\n_and Analytics projects will be synthetically generated_ \u201d;\n\nc) if properly detected and corrected, potentially reduces the bias or statistical imbalance of\n\nthe original datasets, thereby increasing the fairness of decision making that relies on the\ndata;\n\nd) strengthens privacy and reduces the cybersecurity attack surface by limiting the risk of loss\n\nof confidentiality, integrity or availability of real personal information;\n\ne) reduces the costs involved at all stages of the data value chain by limiting the need for\n\nexcessive data collection, cleaning, preparation, and data storage.\n\nHowever, this does not mean that synthetic data is the complete solution for all data protection\nissues.\n\nThere are still some legal concerns that must be taken into consideration by DPOs.\n\nFirstly, synthetic data does not necessarily correspond to anonymous data, which means that reidentification risk, to one degree or another, will remain.\n\nIn practice, synthetic data aims at\nreplicating real world data and the more it is an accurate proxy, keeping all the features and\npatterns of the original data, the more efficient it will be for the genai model trained on\n\n\n-----\n\nsuch data; but, on the other hand, the downside is that such efficiency will, in direct proportion,\nincrease the risk of **re-identification** .\n\nThis means that the risk of inferring data related to a specific\nindividual from the synthetic dataset, or from the genai model itself, will not be extinguished.\n\nAs noted by the UK\u2019s Information Commissioner\u2019s Office (ICO).\n\n\u201c _You should focus on the extent to_\n_which people are identified or identifiable in the synthetic data, and what information about them would_\n_be revealed if identification is successful.\n\nSome synthetic data generation methods have been shown to_\n_be vulnerable to model inversion attacks, membership inference attacks and attribute disclosure risk._\n_These can increase the risk of inferring a person\u2019s identity\u2026._\n\nThe use of other PET\u2019s (such as differential privacy) or the suppression of outliers (data points with\nsome uniquely identifying features), can serve to reduce the risk of re-identification of personal\ndata, but not entirely eliminate it.", "Furthermore, synthetic data\u2019s generation phase may involve the processing of personal data,\nespecially upon collection and analysis of real datasets, which entails the need to abide by the\nGDPR and related obligations.\n\nSpecific mention should also be made of the duty to provide full information under Art.\n\n13 of\nGDPR to data subjects whose data is being collected and then used for genai training purposes, as\nwell as to identify a lawful basis of processing under Art.\n\n6 of GDPR.\n\nFinally, the obligation to strictly respect the principles under Art.\n\n5 of GDPR always stands where\npersonal data is concerned.\n\nIn particular, some of the following principles from Art.\n\n5 are worth\nmentioning in the case of genai:\n\na) transparency: this is not limited to the information to be provided to data subjects under\n\nArt.\n\n13 GDPR as mentioned above, but also towards users, with reference to synthetic\noutputs generated by genai models, in order to avoid the risk of deep fakes and/or social\nmanipulation;\n\nb) purpose limitation: as synthetic data may be derived from real data, which may contain\n\npersonal information, there is the need to outline that such data has been collected for\nspecified, explicit and legitimate purposes and that the further processing (e.g., for data\nsynthetisation and subsequent genai model training) is not incompatible with the initial\npurposes.\n\n-----\n\nA similar principle has been established in relation to the anonymisation process by WP\nArt.\n\n29 (opinion 5/2014) according to which: \u201ct _he anonymisation process, meaning the_\n_processing of (\u2026) personal data to achieve their anonymisation, is an instance of \u201cfurther_\n_processing\u201d.\n\nAs such, this processing must comply with the test of compatibility in accordance_\n_with the guidelines provided by the Working Party in its Opinion 03/2013 on purpose_\n_limitation_ \u201d.\n\nEspecially with regard to the training phase of genai models, the reference to the \u201cstatistical\npurposes\u201d as not in principle incompatible with the initial purposes under lett.\n\nb) of art.\n\n5,\nss.1, might serve this purpose 6 .\n\nc) accuracy and fairness: attention must be given here to avoiding the risk of \u201challucination\u201d,\n\nor of duplicating bias, errors or inaccuracies contained in the original dataset.\n\nThis is\nparticularly important if the genai model trained by the synthetic data will then be used to\nadopt decisions which might affect people\u2019s rights or interests.\n\nOf paramount importance for this specific purpose will be the development of techniques\nthat enable the explainability of the outputs generated by genai systems trained by making\nuse of synthetic data.", "### 8.\n\nIssues specific to Image- and Audio-Based Generative\n\ngenai\n\nIn the case of non-text-based genai applications, such as image, audio and video generating\ntools, clear data protection implications exist.\n\nPopular applications, such as Midjourney and Stable\nDiffusion, which allow users to rapidly generate images and videos by inputting text prompts, are\nbuilt on large volumes of image and video content.\n\nThis underlying data includes numerous\ncategories of personal data sufficient to identify data subjects, the central one being the very\nimage and likeness of a data subject that will often be represented in the outputs.\n\nSpecifically, DPOs can expect the following personal data categories to be involved in such tools:\n\n6 See on this topic, Study at the request of the Panel for the Future of Science and Technology (European\nParliamentary Research Service) \u201c _The Impact of the GDPR on artificial intelligence_ \u201d, June 2020\n\n\n-----\n\n-  photo images of data subjects;\n\n-  artistic representations of data subjects;\n\n-  video footage of data subjects; and\n\n-  Audio, voice-based data\n\nOrganisations will have to understand that the further processing of such data brings the GDPR\ninto scope.\n\nFor instance, if a marketing department wants to create promotional material, and uses\nimages of data subjects garnered from genai, it will have to process those images in line\nwith data protection laws, and respect fundamental principles such as transparency, lawfulness\nand fairness.\n\nFurthermore, the issue of combining the data from genai sources, with data from other\nsources, should be considered.\n\nWhile the data received from the genai tool may not\nidentify the data subject, the act of combining it with alternative data may do so, and once again,\nbring GDPR requirements into view.\n\nThis could be particularly relevant where, for example, the\npasting together of images from different sources leads to the identification of individuals.\n\nIn the more creative use-cases, where organisations may wish to modify, alter or significantly\nchange the presentation of images, videos or audio content, this should be carried out with respect\nfor data subjects\u2019 fundamental rights and freedoms.\n\nRisks, for example, of defaming or damaging\ndata subjects, should always be taken into account, and where it is considered that the processing\nmay be high risk, a DPIA should be conducted.\n\nFinally, where organisations wish to create legitimate \u2018deepfake\u2019 content, such as, perhaps, official\ncorporate videos, issues of data subject consent and transparency of processing should be key\nconsiderations.", "### 9.\n\nManaging Data Protection Risk\n\nCarrying out a data protection impact assessment (DPIA) when implementing or using a generative\ngenai system becomes even more crucial when, as is often the case, these tools have not yet been\nproperly understood, both from the perspective of business strategy and risk management.\n\nThe\nunderstanding of the risks to personal data from genai processing is still evolving and all\nDPOs must try to be alive to as-yet unanticipated threats and challenges.\n\nTo manage these\nemerging risks, the following factors should be taken into account.\n\n-----\n\n**a)** **Risks to Data Subjects**\n\nThe relationship between the user and genai, as well as the impacts that the processing will have on\nindividuals should be at the heart of the analysis.\n\nPotential risks to data subjects include:\n\n-  Impacts from a partially or fully automated decision produced by genai.\n\nThe\nconsequences of such decisions may consist of financial opportunity losses or even\nrestrictions on fundamental rights.\n\n-  Risks of reinforcing discrimination and bias against certain users.\n\n-  Risks arising from the processing of special category data as outlined in Art.\n\n9 GDPR.\n\nFor\ninstance, a genai tool could infer from certain personal data of the person\nconcerned, (from their expression modalities or the use of certain words), their ethnic\norigin, political or philosophical positions, or even the sexual orientation of the person\nconcerned, and apply differential treatment on this basis.\n\nIn order to identify such risks,\nthe company deploying the genai tool should conduct a regular review of the\nquality of the results generated.\n\n-  In terms of IT security, information available to the attacker in the genai system can be a threat\nvector.\n\nA so-called \"white box\" scenario, where the attacker can deduce/find a lot of\ntechnical information to prepare his attack creates more exposure compared to a \"black\nbox\" system where the attacker can only access the information produced by the system\nas an output.\n\nMore particularly, the following attacks are specific to defined genai project\nsteps:\n\n\n\n\n|Learning phase|attack type|infection|backdooring attacks|\n|---|---|---|---|\n||||poisoning attacks|\n|||exfiltration|membership inference attacks|\n||||model inversion attacks|\n||||model extraction attacks|\n\n\n-----\n\n|Production phase|attack type|manipulation|evasion attacks|\n|---|---|---|---|\n||||reprogramming attacks|\n||||denial of Services|\n|||exfiltration|membership inference attacks|\n||||model inversion attacks|\n||||model extraction attacks|\n\n\n**b) Identifying mitigation measures**\n\nThe DPIA, as always, should be conducted before project initiation and should then, via data\nprotection by design, inform and guide the design stage for any genai tool.\n\nIn the case of\ngenai, the following mitigants should be taken to account to manage the identified risks:\n\n-  Supervised fine-tuning with exemplary conversations where an LLM is trained to\nreproduce a corpus of conversations that illustrate what is deemed to be a desired\nbehaviour.\n\n-  Fine-tuning with a human value model where human operators will reward the most\nsatisfactory results.\n\n-  In addition, organisational measures should aim to ensure a constant evaluation of the\nresults provided by the genai tool, both at the level of the human operator who\nuses it and an organisational entity that analyses the results on a large scale in order to\nensure a high level of result quality over time.\n\n-  Similarly, we should strive as much as possible for a situation of explainability of the\ndecisions taken by the genai model to allow genuine human control.\n\nIn this regard,\nhuman control ultimately remains the best method of mitigating risks raised by generative\ngenai systems.\n\nBy this means, excessive confidence in the results produced by genai\n\n\n-----\n\ntools can be avoided.\n\nSuch overconfidence would lead, in the absence of effective human\ncontrols, to the production of entirely automated decisions.\n\nAn additional consideration for DPOs is the emerging genai governance requirement to conduct\nFundamental Rights Impact Assessments (FRIAs).\n\nIn the draft text of the genai Act, which, at the date\nof publication of this paper, is still in the trialogue stage of discussions within the EU Legislature,\na requirement to carry out FRIAs is included.\n\nThe intention is that such an assessment would need\nto be completed by either a provider or user of an genai system, where there are risks to the\nfundamental rights and freedoms of individuals who are affected by the output.\n\nGiven that FRIAs are, in effect, akin to DPIAs for the world of genai, with particular overlaps in\nunderstanding how processing activities impact fundamental rights, DPOs should expect that this\nwork will be assigned to them once the genai Act comes into effect.", "Although, in some respects DPOs\nare uniquely placed, and qualified, to do this work, they are not necessarily naturally conversant in\nthe novel technological risks that are rapidly being created by genai technologies.\n\nFor this reason,\nDPOs should already be researching and understanding genai-specific risks to personal data.\n\nFrom the practical perspective, it may be possible to conduct FRIAs and DPIAs as one exercise,\nbut whatever method is ultimately chosen, DPOs must start developing knowledge of genai risk now,\nin anticipation of the genai Act.", "### 10.\n\nTransparency and genai\n\nWhen gathering and feeding data including personal data to an genai for the purposes of its training\nand when this data processing is governed by GDPR, the entity operating this training (the genai\noperator) must ensure the transparency of said data processing pursuant to Article 5 \u00a7 1 a) and 12\net seqq.\n\nof said regulation.\n\nThree different sources of data can be identified:\n\n-  The scraping of data from websites with the help of robots or genai systems (Use Case 1);\n\n-  The provision of data by users of the system or data suppliers concerning other individuals\n(Use Case 2);\n\n-  The provision of data concerning themselves by users of the genai (Use Case 3).\n\n-----\n\nFor each of these Use Cases, the ways to ensure data processing transparency vary according to\nthe type of training genai required.", "**Use Case 1**\n\nTransparency is a delicate and perhaps challenging issue when considering online data scraping,\nmainly due to the fact that any personal data gathered in this manner is not gathered directly from\nthe data subject.\n\nAs a result, Article 14 of the GDPR should apply to such data, i.e., personal data\nthat has not been gathered from the data subject directly, entitles the data subject to the right to\nobtain from the controller confirmation as to whether their personal data is being processed, and,\nif so, access to their personal data should be provided along with other vital information such as\nthe purpose for processing and the categories of data that is being processed and so on.\n\nAdditionally, Article 15 of the GDPR regarding the right of access by the data subject to their\npersonal information should apply.\n\nIn such a scenario, however, several difficulties present themselves to the genai operator.\n\nEspecially\nthe following:\n\n-  Identifying personal data among the data automatically retrieved by the genai, which usually\nconsists of vast amounts of data;\n\n-  Directly identifying each individual data subject;\n\n-  Obtaining sufficient contact information to inform each data subject of the processing of\ntheir data.\n\nIn light of these difficulties, Article 14.5 (b) of the GDPR could be applied.\n\nThis section of the article\nstipulates that a data controller would not have to provide the specified information to each data\nsubject when \u201c _the provision of such information proves impossible or would involve a disproportionate_\n_effort_ \u201d.\n\nCase law from various data protection authorities shows that this exception should be\ninterpreted very strictly.\n\nThis being said, given the difficulties identified above regarding\ngenai models, it could be applied here.\n\nIf so, the genai operator would, however, still be bound\nunder the transparency requirements to the data subject.\n\nPursuant to said Article 14.5 (b), the data controller should take appropriate measures to protect\nthe data subject's rights and freedoms and legitimate interests.\n\nSuch measures include the\npublication of the controller\u2019s privacy policy on its website, but also, possibly more stringent\n\n\n-----\n\nmeasures like the example given by the Italian Data Protection Authority when regulating\nChatGPT earlier in 2023.\n\nUltimately, OpenAI agreed to carry out an information campaign, of a\nnon-promotional nature, across all the main Italian mass media (radio, television, newspapers and\nthe Internet) to inform people of the probable collection of their personal data for the purpose of\ntraining ChatGPT.\n\nThey also agreed to make a tool available on the data controller\u2019s website,\nthrough which all interested parties could exercise their right to access their personal data.\n\nOn the other hand, regarding such a right to access, Article 11 of the GDPR may also apply, which\nstipulates that:\n\n\u201c _1.\n\nIf the purposes for which a controller processes personal data do not or do no longer require the_\n_identification of a data subject by the controller, the controller shall not be obliged to maintain, acquire_\n_or process additional information in order to identify the data subject for the sole purpose of complying_\n_with this Regulation._\n\n_2.\n\nWhere, in cases referred to in paragraph 1 of this Article, the controller is able to demonstrate that_\n_it is not in a position to identify the data subject, the controller shall inform the data subject accordingly,_\n_if possible.\n\nIn such cases, Articles 15 to 20 shall not apply except where the data subject, for the purpose_\n_of exercising his or her rights under those articles, provides additional information enabling his or her_\n_identification_ \u201d.\n\nAdditionally, we are reminded in Recital 4 of the GDPR that, \u201c _the right to the protection of personal_\n_data is not an absolute right; it must be considered in relation to its function in society and be balanced_\n_against other fundamental rights, in accordance with the principle of proportionality_ \u201d.\n\nAs a result, it\ncould be argued that disproportionate efforts cannot be imposed on the genai operator to identify\nthe applicant and detect their personal data in the training data of the genai.\n\nIn light of the above, the genai operator facing an access request should:\n\n1.\n\nVerify if the personal data concerning the applicant can be identified;\n2.\n\nProvide the applicant will all personal data identified;\n3.\n\nInform the data subject that there may be personal data concerning them that the genai\n\noperator is not in a position to detect/provide given the characteristics of the data\nprocessing being carried out.", "-----\n\nAlso, to comply with Article 25 GDPR and the data protection by design principle, the genai operator\nmay also be obliged to demonstrate that they can anticipate such access requests and that they\nhave reviewed all the technical possibilities that they could reasonably deploy to detect the\npersonal data concerning each applicant (and that it reassesses regularly these possibilities).", "**Use Case 2**\n\nSince data is usually supplied the genai operators along the supply chain by other third parties further\nup the supply chain (a user or a data supplier).\n\nThese third parties could assist the genai operator in\nensuring transparency in the processing of data by providing tools and guidance on how best to\nextract personal data from the data set, given that it is these third parties that supply the data sets\nin the first place.\n\nThese third parties could also help the genai operator when dealing with access\nrequests from data subjects for the same reasons.", "**Use Case 3**\n\nWhen personal data is collected directly from the users, Article 13 of the GDPR applies.\n\nThe data\ncontroller must provide specific information to the data subject at the time of collection, for\ninstance the identity and the contact details of the data controller; the contact details of their data\nprotection officer; the purposes of the processing for which the personal data is intended as well\nas the legal basis for the processing; along with other specific information.", "### 11.\n\nOptimising Organisational Structures\n\nWithin any organisation, from a management structure-perspective, the topic of genai will\nhave to be addressed in a multidimensional way, as a reflection of the complexity of the technology\nand its impacts.\n\nIt will not be viable for companies to have each function working alone and not\ninteracting with each other.\n\nThe impact of genai is an enterprise issue; therefore, it requires a joined-up enterprise-wide approach.\n\nSuch an integrated approach is essential in order to avoid duplication of efforts, but more\nimportantly to ensure that key decisions receive multi-disciplinary input.\n\nTo achieve this, organisations should put in place an genai taskforce, focusing on responsible genai and\nits governance.\n\nThe creation of such a task force could be an initiative driven by the DPO, as one\nof the functions that will have the biggest exposure to this topic due to the fact that he has to\n\n\n-----\n\nmanage some genai considerations in a context where personal data is involved.\n\nAlternatively, it could\nbe initiated and led by an IT function, such as a Chief Data Officer, or Chief Technology Officer.\n\nThis task force will significantly involve the legal department, compliance functions and,\nspecifically, data protection.\n\nFor the technical aspects, the IT Security department should be\nrepresented.\n\nThe task force may involve communications and PR staff, as it will be necessary to\ncommunicate internally, and potentially externally, on the decisions taken by the task force.\n\nThe\nleader of the task force may establish focus groups in which selected members of the taskforce\nfocus on specific questions and report back their results to the taskforce.\n\nThe above diagram gives\nan indicative idea of the composition of these focus groups and how they would relate to the\nResponsible genai Governance Taskforce.\n\nThe mission of the task force is to respond to the immediate need for Responsible genai governance\nwithin the organisation and to examine and manage the risks in the use of genai,\nspecifically, with regard to personal data, bias, ethical concerns, emerging genai regulation and\nnumerous legal issues such as intellectual property rights and liability exposure.\n\nThe main goal of this task force will be to define an action plan.\n\nA critical aspect of this action plan\nwill be to conduct an inventory of the genai systems used in the company, which includes generative\ngenai.\n\nAnother critical aspect is to define roles and responsibilities for all the functions in the group.\n\n-----\n\nThe role of this genai taskforce is also to raise the awareness of genai issues at all levels of the company.\n\nThis point is important, as the risk will naturally come from the employees that are the day-to-day\nusers of the technology, but it has to be linked with the highest level of decision-making, because\ndeciding on the way to use (or not use) genai is an enterprise strategy.\n\nAs an initial task, the task force should prepare preliminary guidance for the organisation regarding\nthe responsible use of genai which would, for example, include the recommendation not\nto enter personal data in prompts of relevant tools like ChatGPT, nor to upload images with\nidentifiable persons.\n\nRegardless of the complexity of the technology, and its implementation, the DPO\u2019s role in this\ntaskforce is ultimately to ensure that any personal data processed via genai technologies is compliant\nwith the GDPR.\n\n-----", "## Summary\n\nSince the public release of OpenAI\u2019s ChatGPT on November 30, 2022, questions and concerns\nhave rapidly circulated concerning the role of genai (genai) in higher\n\neducation, particularly in instructional or curricular contexts.\n\nWhile ChatGPT produces textbased output, other genai can output text, data, image, sound, video and mixed media\n\nformats.\n\nThe International Association of Privacy Professionals defines genai as \u201c[a] field of genai\nthat uses machine learning models trained on large data sets to create new content, such as\n\nwritten text, code, images, music, simulations and videos.\n\nThese models are capable of\n\ngenerating novel outputs based on input data or user prompts.\u201d 1\n\nSidney Dobrin, author of genai and Writing, explains that \u201c[w]e can think of a GenAI as\n\nparticipating in a rudimentary conversation with a user\u201d who \u201cask[s] the genai to create a specific\ndeliverable \u2014 an essay, a song, an image, the solution to a math problem or so on.\n\nThe genai then\n\nscrubs through all of the data available, looking for patterns and recurring information about\nthe requested task.\n\nIt then reorganizes that data into a pattern that it deems to answer the\nprompt.\u201d 2\n\nIn June 2023, the University of Kentucky empaneled UK ADVANCE , a broad-based committee of\n\nexperts to examine and make recommendations to help the campus and community regarding\nthe implications of genai and tools such as ChatGPT for higher education, research and\n\nbeyond.\n\nUK ADVANCE is taking an evidence-based approach with experts from multiple\ndisciplines and ongoing monitoring of experiences among our campus, community, and\n\n1 IAPP 2023.\n\n2 Dobrin 2023.\n\n-----\n\nnationally.\n\nFor these guidelines, UK ADVANCE has sought input from multiple stakeholders as\nwell.\n\ngenai already is heralding tremendous changes in academia and the economy, from innovations in\nfarming and the development of therapeutics to customer service and workplace innovations.\n\nAt\n\nthe same time, there are significant concerns over disruption and displacement of the\nworkforce, embedded bias, data security and privacy and the spread of misinformation.\n\nWithin academia, there is the potential to create even greater access to personalized and\n\ncustomized learning, expanded student engagement, intelligent tutoring systems and innovative\napproaches to curriculum design.\n\nAt the same time, there are concerns over academic integrity,\ninfringements on privacy and the ability to develop data and information literacies for genai tools.\n\n3\n\nAfter reviewing emerging evidence and experiences related to instruction and learning\n\nenvironments, UK ADVANCE offers the following guidelines and recommendations for the Fall\n\n2023 semester regarding (1) the development of course policies concerning genai, (2)\nthe response to potential misuse of genai in instructional contexts, and (3) approaches\nto assignment and learning design that mitigate the risk of misuse and leverage the positive\n\npotential of genai.\n\nIt\u2019s important to note that the following guidelines and recommendations primarily focus on\n\ntext-based genai tools such as Bard (Google), Bing Chat (Microsoft and OpenAI),\nChatGPT and ChatGPT Plus (OpenAI), Claude (Anthropic) and Llama (Meta).\n\nAt the same time,\n\nthe recommendations and insights may be transferrable to situations involving other modalities\n\nof genai (e.g., image, audio).\n\ngenai is a rapidly evolving technology.\n\nThese guidelines reflect our best understanding\n\nat the current time and may be updated to reflect the nature of the field as it continues to\n\nchange.", "## Course Policies Regarding genai\n\n**Provenance.\n\n** University Senate maintains requirements, policies, and procedures for course\nsyllabi and policies.\n\nSee  .\n\nInstructors have\n\nauthority to determine policies, within the bounds of senate rules, for the appropriate use of\ntechnologies in their courses.\n\n3 Passages adapted from UKNow, uknow.uky.edu/campus-news/advance-committee-will-explore-genai-opportunities-\nchallenges-campus-commonwealth .\n\n-----\n\n**Recommendation.\n\n** We recommend clear course policies for the use of genai in four\nkey areas as follows: 4\n\n-  **People-centered** : policies are student- and instructor-centered\n\n-  **Adaptability** **:** policies are adapted to the needs and circumstances of the course\n\n-  **Effectiveness** **:** policies demonstrate characteristics of an effective course policy\n\n-  **Awareness** **:** policies promote awareness and understanding of genai\n\n**People-centered.\n\n** genai is a tool that instructors and students can use to enhance education, but\n\nit should be used with human oversight and an awareness of its strengths and limitations.\n\nStudents and instructors should exercise judgment and control over the use of genai so\nthat it is used to augment \u2014 rather than replace \u2014 instructor decision-making and student\n\nlearning.\n\nThe U.S. Department of Education\u2019s Office of Educational Technology describes this as\n\nkeeping \u201chumans in the loop,\u201d whereby \u201cthe human is fully aware and fully in control, but their\n\nburden is less, and their effort is multiplied by a complementary technological enhancement.\u201d 5\n\n**Adaptability.\n\n** Course policies regarding the use of genai are best adapted to the local\ncontext of the course, including the instructor\u2019s expertise and perspectives; the course learning\n\ngoals; the nature of the coursework, discipline and/or profession; and the learning needs of the\nstudents.\n\nWhile genai may not be as useful for one course, it may present an\n\nopportunity in another course.\n\nMoreover, different modalities and tools for genai may\nbe more or less desirable for a course.\n\nWhile instructors may adopt a range of course policies\nregarding the use of genai, those policies likely will fall within one of four areas on a\n\nspectrum:\n\n-  No use\n\n-  Use only when/as directed\n\n-  Use freely in certain cases\n\n-  Use freely in all cases\n\nWhile course policies may be more restrictive than what is found in the senate rules, they must\nreflect the approved senate syllabi template and language.\n\nFor more restrictive course policies\nan instructor may need to consider measures to ensure that the policy is followed appropriately.\n\nThis may involve adapting assignments and holding certain activities during class meetings.\n\nAdditionally, for more restrictive course policies it is important to understand the limitations of\n\ngenai detectors as described in the section of these guidelines on responding to possible misuse.\n\n4 Byrd, et al.\n\n2023; Chan 2023; Foltynek, et al.\n\n2023; Russell Group 2023; US Department of Education Office of\nEducational Technology, 2023.\n\n5 US Department of Education Office of Educational Technology, 2023\n\n\n-----\n\nFor more permissive course policies an instructor may need to consider measures to ensure\ntransparency and appropriate documentation of the use of genai.\n\n6\n\nAny questions or requests from students related to the use of genai as learning\naccommodations should be referred to the UK Disability Resource Center.\n\n**Effectiveness.\n\n** While instructors will adopt a range of policies and approaches for students\u2019\nuse of genai in courses, the written account of those policies should be included clearly\n\non syllabi and other locations where students regularly interact with information about the\n\ncourse.\n\nThis is important for several reasons, including:\n\n-  Students will likely be navigating different policies, requirements, and approaches to the\n\nappropriate use of genai for their coursework.\n\n-  Students may be unsure about genai, especially whether it can or should be\n\nused for their coursework.\n\n7\n\n-  Students may be reluctant to ask about course expectations for the use of genai\n\nin the face of ambiguity or uncertainty.\n\n8\n\nFactors to consider when developing course policies on genai include: 9\n\n-  A definition of genai.\n\nFor example, \u201cgenai refers to a range of emerging\n\ntechnologies that draw from training on large datasets to generate new content in\n\nwritten, visual and other forms based on user instructions.\u201d This definition may be\nexpanded or revised to include more specific information that is relevant to the course\n\nand discipline.\n\n-  A statement on whether the use of genai will be permitted for coursework, and\n\nif so, how and to what degree it will be permitted.\n\n-  A specific description of what constitutes inappropriate use of genai in the\n\ncourse as well as the consequences for inappropriate use.\n\n-  A process for students to document or cite the use of genai for assignments and\n\nother course activities (if it is permitted).", "-  A process for students to document or cite the use of genai for assignments and\n\nother course activities (if it is permitted).\n\n10\n\n-  A rationale for the policy grounded in the context of the discipline/profession, the\n\nlearning goals of the course, the skills that will be assessed and/or ethics and academic\n\nintegrity.\n\n-  Links to resources for understanding and using genai ethically and effectively.\n\n6 Dobrin 2023.\n\n7 Amigud and Pell 2021; Barnett 2023; Bens 2022; Bogost 2023.\n\n8 Ryan, Gheen, and Midgley 1998; Ryan, Pintrich, and Midgley 2001; Sheu, Chong, and Dawes 2022.\n\n9 Gannon 2023.\n\n10 Perkins 2023.\n\n-----\n\n-  A learner-centered and student-friendly tone that builds understanding and motivation\n\nfor students in the course.\n\n-  An invitation for students to discuss any questions or concerns with the instructor.\n\n**Awareness.\n\n** In addition to providing clear course policies regarding genai, it is\n\nimportant for instructors and students to be aware of the larger evolving issues concerning the\ntechnology:\n\n-  While genai continues to become more sophisticated, it has a well-documented\n\nhistory of producing fabricated, incorrect, and misleading information.\n\n11 Should\ninstructors or students use genai tools, verification of the output will be a critical\ncomponent of informed use.\n\n-  Privacy is a major concern and caution.\n\nMany genai tools do not guarantee the\n\nprotections for private, confidential or sensitive data that may be required (or desired)\n\nfor certain information.\n\n12 For example, student education records (as defined by\nFERPA) 13 and protected research data 14 should not be provided to genai tools\nunless/until they have been vetted for data privacy and other governance issues and\n\napproved by the University for the proposed use.\n\n-  There is an ongoing conversation about the ethics of how genai models have\n\nbeen trained on openly available data, both in terms of any biases that the models\nmight inherit from the datasets 15 as well as issues of intellectual property in the training\ndata.\n\n16\n\n-  genai technologies continue to evolve at a rapid pace, as do the ways in which\n\nwe can (and can\u2019t) access and use them.\n\nWe cannot assume that the performance nor\n\nthe use-conditions of genai at a particular moment will remain the same or\nstable in the long term.\n\n17\n\n11 Alkaissi and McFarlane 2023; Athaluri, et al.\n\n2023; Christian 2023; Francl 2023; Hosseini, Rasmussen, and Resnik\n2023; Ji, et al.\n\n2023; Kidd and Birhane 2023; Lee, Bubeck, and Petro 2023; Lightman, et al.\n\n2023; Liu, Zhang, and\nLiang 2023; Megahed, et al.\n\n2023; Metze, Morandin-Reis, Lorand-Metze, and Florindo 2023; OpenAI 27 March 2023;\nPoritz 2023; Weise and Metz 2023; Weiser 2023; Zhang, et al.\n\n2023; Zhao, et al.\n\n2023; Zhavoronkov 2023.\n\n12 Busch 2023; Electronic Privacy Information Center 2023; Huang 2023; Hosseini and Horbach 2023; Lauer,\nConstant, and Wernimont 2023; Mesk\u00f3 and Topol 2023; National Institutes of Health 2023; Schwartz and Rogers\n2022.\n\n13 See registrar.uky.edu/ferpa and registrar.uky.edu/ferpa/ferpa-faculty-and-staff-faq .\n\n14 See  .\n\n15 Bender, Gebru, McMillan-Major, and Shmitchell 2021; Brown, et al.\n\n2020; Caliskan, Bryson, and Narayanan 2017;\nHovy and Prabhumoye 2021; Liang, Wu, Morency, and Salakhutdinov 2021; Najibi 2020; Nazer, et al.\n\n2023; Nicholas\nand Bhatia 2023; Schwartz, et al.\n\n2022; Small 4 July 2023; Whittaker, et al.\n\n2019; Zhuo, Huang, Chen, and Xing\n2023.\n\n16 Appel, Neelbauer, and Schweidel 2023; Lucchi 2023; Saveri and Butterick 2023; Sobel 2018; Strowel 2023;\nThorbecke 2023; Zirpoli 2023.\n\n17 Chen, Zaharia, and Zou 2023.\n\n-----\n\nFor assistance in talking with students about genai as it relates to teaching and\nlearning, instructors can work with UK\u2019s Center for the Enhancement of Learning and Teaching\n\n(CELT) at celt.uky.edu .", "## Responding to Possible Misuse of genai\n\n**Provenance.\n\n** University Senate maintains requirements, policies and procedures for academic\n\noffenses.\n\nSee Senate Rules 6.3 and 6.4 at  .\n\nThe\n\nAcademic Ombud lists the procedure for processing academic offenses at ombud.uky.edu/\nfaculty/academic-offense-procedures .\n\n**Detectors.\n\n** Several detectors for text-based genai output have been developed.\n\nFor\n\nexample, TurnItIn (to which all UK instructors have access through the assignments feature in\nCanvas) activated its own proprietary genai detector on April 4, 2023.\n\nOn July 20, 2023, OpenAI\n\nclosed off access to its genai classifier, citing a \u201clow rate of accuracy.\u201d 18 These technologies are still\nemerging, but they have demonstrated several problems thus far:\n\n-  They can be prone to false positives, i.e., indicating that all or part of a student\u2019s work is\n\nlikely genai-generated when it is, in fact, not.\n\n19 Relying on these percentages can introduce\nbias in the assessment process and demoralize students if further action is taken.\n\n-  They can be evaded with a combination of prompt manipulation (e.g., iterating a prompt\n\nto receive ideal output) and hand-editing the output.\n\n20\n\n-  They cannot be verified with other evidence (e.g., as opposed to similarity detectors\n\nthat link to matching sources).\n\n-  They do not guarantee the protection, privacy and confidentiality of any information,\n\ndata or intellectual property that a student or instructor inputs.\n\n21\n\n-  They risk creating a surveillance-based learning environment that can negatively affect\n\nstudent motivation, learning and belonging.\n\n22\n\nData on detectors will continue to emerge and require ongoing reassessment, which may result\nin updated guidelines.\n\n18 OpenAI 31 Jan 2023.\n\n19 Chechitelli 2023; Cingillioglu 2023; D\u2019Agostino 2023; Dalalah and Dalalah 2023; Edwards 2023; Fowler 2023;\nLiang, et al.\n\n2023; Weber-Wulff, et al.\n\n2023.\n\n20 Anderson, et al.\n\n2023; Cingillioglu 2023; Henrique, Kucharavy, and Guerraoui 2023; Krishna, et al.\n\n2023; Liang, et\nal.\n\n2023; Sadasivian, et al.\n\n2023; Weber-Wulff, et al.\n\n2023.\n\nAdditionally, Thompson and Hsu 2023 and Jiang, Zhang,\nand Gong 2023 found that detection methods for image-based genai output (e.g., via DALL-E, Stable\nDiffusion, Midjourney) can be evaded and/or lead to false positives.\n\n21 See, for example, GPTZero\u2019s privacy policy at  .\n\n22 Acevedo 2023; CCCC-IP Caucus; Cullen 2022; Lang 2013.\n\n-----\n\n**Data Privacy.\n\n** Student education records should not be input into third-party genai\ndetection tools or systems unless and until the tools/systems have been vetted for data privacy\n\nand other genai governance issues and approved by the university for use.\n\nThis includes\ngenai systems that include detection tools.\n\nThe Family Education Rights and Privacy Act\n\n(FERPA) applies to all student education records, which are \u201crecords that are directly related to\na student and that are maintained by an educational agency or institution or a party acting for\nor on behalf of the agency or institution.\u201d 23\n\n**Range of Misuse.\n\n** Misuse of genai can include \u201ccopy/paste\u201d plagiarism scenarios \u2014\ni.e., submitting text generated by an genai program without attribution, as if it were one\u2019s own\nwriting \u2014 but it also can include more ambiguous scenarios such as:\n\n-  Using ideas or approaches that genai programs have suggested\n\n-  Reusing information, calculations, analyses or solutions provided by genai\n\n-  Revising text generated by an genai program without indicating the initial source\n\nAdditionally, even if a student attributes their use of genai, it may still be \u201cmisuse\u201d if\ncourse policy prohibits it in that scenario.\n\nClear course policies will help students \u2014 and\n\ninstructors \u2014 navigate the range of possible misuse cases and understand what to expect if an\n\ninstructor determines that misuse has occurred.\n\nIt\u2019s important to note that because genai\u2019s language models draw from a variety of\n\ntextual sources (including openly available text on the world wide web), it is possible that\n\nwriting, ideas and other output produced by genai may themselves lack proper\nattribution of source material and may imitate or reproduce copyrighted material on which they\n\nwere trained.\n\n24\n\n**Responding.\n\n** Should an instructor suspect that a student has used genai\n\ninappropriately in the completion or all or part of an activity or assignment, we would suggest\nconsultation with the department chair or school director and the Academic Ombud.\n\n**Recommendation.\n\n** Because of these concerns, we recommend against the use of generative\n\ngenai detectors for determining academic offenses.\n\nUK ADVANCE will, however, continue to\n\nmonitor the landscape and update the guidelines as appropriate.\n\n23 US Department of Education Student Privacy Policy Office.\n\n24 Appel, Neelbauer, and Schweidel 2023; Dobrin 2023; Small 10 July 2023; Smits and Borhuis 2022; Thorpe 2023.\n\n-----", "## Assessing Learning with genai in Mind\n\nWhile genai can feel like a disruption of instructors\u2019 ability to teach and assess student\nlearning, it is also an invitation to refine pedagogy and assessment.\n\n25\n\n**Principles of Assessment Design.\n\n** The design of assessments is driven by many context-\n\nspecific considerations, most importantly:\n\n-  Course and program learning outcomes\n\n-  Competencies and skills in the discipline or profession\n\n-  Scaffolding along the course curriculum\n\n-  Authentic and engaging learning experiences\n\n-  Equity, clarity and structure\n\n-  Opportunities to practice and improve\n\n-  Iterative feedback on performance\n\n-  Reflection on progress and learning\n\nEffective, learning-centered assessments follow from these principles whether they seek to\n\navoid the use of genai or engage students in it.", "**Design Strategies to Enhance Learning and Mitigate Misuse of genai.\n\n**\n\nStrategies that mitigate the conditions that may lead to misuse of genai also draw from\n\nprinciples of strong learning design.\n\nInstructors may consider how their assessments may draw\n\nfrom any of the following strategies, as is appropriate for the course, students and other\n\nfactors.\n\n-  Segment larger assessments with checkpoints and/or multiple deliverables that value\n\nprocess along with content.\n\n\u25cb This strategy helps students to organize and plan their efforts, make steady\n\nprogress towards a larger goal, increase their self-efficacy and reflect on their\n\ndecision-making by documenting their process.\n\n-  Integrate work towards assessments into class meetings and other planned interactions.\n\n\u25cb This strategy ensures that opportunities to study, practice, plan, research, draft,\n\nrevise, etc., are embedded in the culture of the course, and students are held\naccountable for doing the work in ways that are constructive for learning.\n\n-  Ground assessments in the specific context of the course.\n\n\u25cb This strategy asks instructors to integrate unique aspects of the course, whether\n\nparticular readings, concepts, methods, discussions, cases, etc.\n\n(or a\n\n25 Byrd, et al.\n\n2023; Council of Writing Program Administrators 2019; Mills 2023.\n\n-----\n\ncombination thereof) rather than assigning generic tasks that are easily\nreplicated elsewhere.\n\n-  Incorporate opportunities to receive iterative feedback on learning and performance via\n\ndrafts and revisions, development phases, interactive practice, observations, etc.\n\n\u25cb This strategy leverages frequent, formative assessment as a way to lower the\n\nstakes, engage and motivate students, and focus on opportunities for growth.\n\n-  Ask students to contribute their own insights, original analyses and other perspectives.\n\n\u25cb This strategy ensures that students are incentivized to add their own informed\n\ncontributions to the issues at hand, which frames learning as reckoning with\nrather than merely reproducing extant knowledge.\n\n-  Include moments when students need to be conversant about the nature and progress\n\nof their own work.\n\n\u25cb This strategy engages students in multiple modes and contexts for\n\ncommunicating about their learning and emphasizes the importance of reflecting\non their efforts in addition to proving that they have learned something.\n\n-  Ask students to express their learning in different genres, formats and modalities.\n\n\u25cb This strategy engages students in multimodal and multigenre communication in\n\npreparation for careers that will engage them with different stakeholders.\n\n**Uses of genai in Assessments and Other Learning Activities.\n\n** While some\nsituations may not call for the use of genai, others may be enhanced when it is used\n\nstrategically.\n\nImportantly, if an instructor integrates genai into an assignment, it is a\n\nconsideration of equity to ensure that all students are supported in the use of digital\n\ntechnologies rather than relying on extant \u2014 and uneven \u2014 literacies and comfort levels with\ngenai tools.\n\n26 This might mean walking students through the process of using\ngenai for a particular task, providing tips for effective use of genai for that task,\n\naddressing the tool during office hours, etc.\n\ngenai has shown potential to be effective\n\nfor learning when used to: 27\n\n-  Brainstorm or discover ideas\n\n-  Organize projects or plan efforts\n\n-  Summarize or synthesize information\n\n-  Analyze and visualize data\n\n-  Provide output that students critique or verify\n\n-  Offer different possibilities for approaches to a task\n\n-  Give feedback on ideas or drafts\n\n-  Engage students in retrieval practice, concept review, or other studying\n\n26 Zamfirescu-Pereira, Wong, Hartmann, and Yang 2023.\n\n27 Ellis and Slade 2023; Hicks 2023; Mollick and Mollick 2023; Trust 2023.\n\n-----\n\n-  Generate materials for demonstrations or case studies\n\nAs part of ensuring that students learn to become strategic and ethical users of genai, it\n\nwill be important to emphasize that students should verify the claims and information in the\noutput, and to understand the framing of that output as only one possibility among many\n\nothers.\n\nIt will also be important for students to document their use of genai in a\nconsistent way.\n\n28\n\n**Support for Instructors.\n\n** For support in any way related to designing activities and\n\nassessments in relation to genai, instructors can work with CELT at celt.uky.edu .\n\n**Support for the UK Community.\n\n** Contact  with questions, ideas, and\nrecommendations as well as feedback regarding genai-related efforts underway on campus.\n\nThe\n\nUK ADVANCE webpage can be viewed at advance.uky.edu .", "**EMERGING TECHNOLOGIES TEAM**\n\nThis document contains\n\nproprietary information\n\nof the United Nations.\n\nInformation contained\n\nherein is to be used solely\n\nfor the purpose submitted,\n\nand no part of this\n\ndocument or its content\n\nshall be reproduced,\n\npublished or disclosed to\n\na third party without the\n\nexpress permission of the\n\nUnited Nations.", "### What is genai?\n\ngenai is a subfield of genai (genai) and machine learning\n(ML) that involves the creation of original data or content, including images,\nvideo, text, code and 3D renderings.\n\nThis subfield has been developing over\nseveral decades and is rapidly evolving, due to advances and availability\nin computational power, large datasets and significant improvements in\nmachine learning algorithms.\n\ngenai models are based on deep\nlearning algorithms that learn to recognize patterns and relationships from\nvast amounts of input data, which then generate new outputs that are similar\nin style and structure to the data they were trained on.\n\nThe ability of these models to self-formulate new and varied outputs\nrepresents a paradigm shift in the field of genai because they are not being\nexplicitly programmed to follow pre-determined rules, or generate specific\noutputs, like other genai systems.\n\nThis will likely lead to a change in how we\ninterface with computers, and more broadly, in how we access, understand,\nand produce knowledge and information.\n\n**_Figure 1:_** _Subfields of artificial intelligence_", "## \u00bb Natural Language Processing\n\n**(NLP)** -  A subfield of genai that is at\nthe intersection of linguistics,\ncomputer science and machine\nlearning.\n\nNLP enables computer\nprograms to process and\nanalyze large amounts of natural\nlanguage data.\n\nIt uses a range\nof computational methods and\nalgorithms to allow machines,\nsuch as chatbots and voice\nassistants, to understand and\nmimic written or spoken human\nlanguage.", "## \u00bb Neural networks - An genai method\n\nthat simulates the structure and\nfunction of the human brain.\n\nNeural\nnetworks process information\nthrough interconnected nodes that\nare organized in a layered structure.\n\nThis computational model serves as\nthe basis of deep learning and is used\nin various types of generative models.", "### Value Proposition\n\nProponents of genai believe that this set of converging technologies is poised to revolutionize the economy, spur\nproductivity and transform industries\u2014from education, healthcare and finance to infrastructure development.\n\nAccording\nto new research, it is estimated that genai systems could increase annual global Gross Domestic Product (GDP) by\n7 percent over a 10-year period (Briggs and Kodnani, 2023).\n\nEarly data suggests that a massive transformation is already\nunderway, as Big Tech companies have begun to quickly roll out and integrate new genai tools and features into\ntheir products, including search engines and office suite software.\n\nThe intense competition in Silicon Valley to develop and\ndeploy these tools, however, has prompted concerns among many regulators and ethical genai researchers.\n\nSome of these\nconcerns include the risk of perpetuating bias and discrimination, spreading mis- and disinformation, and infringing on\nintellectual property rights.\n\nDiscussions regarding genai\u2019s value proposition are full of debate and uncertainties.\n\nBelow, we explore contrasting views on the potential benefits of these technologies, highlighting three interwoven\nfeatures at the core of its value proposition: efficiency, personalization, and creativity and innovation.", "**EFFICIENCY**\n\nThere are many opportunities for\nbusinesses and organizations to\nmaximize their potential using\ngenai tools.\n\nOne such benefit\ncan include increased efficiency by\nautomating tasks that involve complex\nreasoning, pattern recognition and large\ndata sets.\n\nIn the long term, this type\nof automation could reduce business\ncosts and increase productivity.\n\nIt\ncould also accelerate the speed of\niteration, allowing for faster learning and\nimprovements, which can drive business\nperformance.\n\nAccording to economists, foundation\nmodels could impact every sector of\nthe economy and lead to significant\neconomic growth.\n\nIt is predicted that\ngenai will likely create disruption\nacross some industries and drive\ndemand for new skills.\n\nThis includes\nroles for prompt engineers and data\npractitioners that can integrate, finetune, and improve genai models\ninto existing products and pipelines.\n\nIt also creates greater demand for genai\nsafety professionals to manage the genai\nsystems\u2019 shortcomings and work to\nensure their responsible use.\n\nWhile genai systems can\nhelp an organization run more\nefficiently, training and operating\nthese models is expensive and can\nbe cost-prohibitive.\n\nThis is due in\npart to the specialized hardware\nand significant amount of memory\nand storage space these systems\nrequire to support the high volume of\ncalculations models typically produce.\n\nWith continued advances in the field\nof genai, however, costs associated with\ngenai models are expected to\ndecrease over time, which could make\nthem more accessible.\n\nResearchers\nestimate that millions of jobs across\nlarge economies could be exposed\nto some degree of automation.\n\nCertain white-collar positions are\nconsidered to be at greater risk of\nbeing altered or displaced by text\ngeneration tools such as ChatGPT.\n\nThis includes jobs in tech (e.g., coders,\ncomputer programmers), media (e.g.,\nadvertising professionals, journalists)\nand finance (e.g., financial analysts\nand advisors), as well as educators\nand customer service agents.\n\nBy automating certain functions, genai systems\ncan free up time and resources for more high-value tasks,\nsuch as policy development and advocacy.\n\nOne key area where genai can be leveraged is in\nwriting and research-related tasks.\n\nGenerative models\ncan be trained to generate text for various purposes,\nsuch as drafting grant proposals, or summarizing large\ndocuments.\n\ngenai can also assist with coding tasks by\nproviding descriptive code documentation.\n\nThis can help\ndevelopers to understand complex code bases more\nquickly and easily, leading to more efficient and effective\nsoftware development.\n\nIn addition, genai can be\nintegrated into software interfaces, allowing end-users to\ninteract with their software using natural language.\n\nThis\ncan improve their experience and make software more\naccessible to non-technical end-users.\n\ngenai tools can facilitate near-real-time translation\nand transcription, which could enhance the delivery of\ncritical services to underserved communities.\n\nFor instance,\nthe UN could use genai to provide real-time\ntranslation services to refugees or to transcribe speeches\nat international conferences.\n\ngenai models, however, lack an inherent\nunderstanding of the content they generate, and instead\nrely on predicting the most probable next words based on\nthe patterns derived from a large corpus of textual data.\n\nHence, they can be considered as personal assistants\nrather than authoritative decision-makers.\n\n-----", "**PERSONALIZATION**\n\ngenai systems could reduce\nthe barriers to entry for non-experts\nto engage in highly specialized\nwork that was previously limited\nto people with relevant technical\nskills and knowledge.\n\nFor example,\nby automating data analysis or\nfacilitating access to information\nthrough user-friendly interfaces.\n\nOrganizations will likely see a\ngreater return on investment\nby using customized generative\nmodels that are fine-tuned with\ntheir own data.\n\nThis can lead to\nmore tailored results, which would\nbetter address the organization\u2019s\nspecific needs.\n\nPersonalization can\nalso improve user experience and\nengagement.\n\ngenai tools offer several\nopportunities to help augment\nhuman creativity.\n\nFor example,\nby prompting discussion and\ngenerating new ideas, which\ncould spark people\u2019s imagination\nand possibly help them\novercome writer\u2019s block.\n\nThis\ncollaborative ideation tool could\nassist in spurring the creation\nof innovative products, services,\nbusiness strategies and advocacy\ncampaigns.\n\nOne of the biggest\ndraws of genai systems\nis their potential to change the\nnature of how cognitive work is\nperformed.\n\nEducators are also considering\nhow genai could assist\nin creating engaging activities,\nincluding games and simulations,\nwhich could help students better\nunderstand abstract or other\ndifficult to grasp concepts.\n\nSince genai models are trained on\na vast amount of data, it can be difficult to\nexplain how a system arrived at a particular\nresult or response.\n\nThis lack of explainability\nposes huge risks and could lead to unintended\nconsequences.\n\nFor instance, genai systems\ncan reinforce patterns of systemic bias\nand discrimination if their training data is\nflawed, biased, or unrepresentative.\n\nWithout\nexplainable outputs, it could be challenging,\nor impossible, to pinpoint the source of a\nproblem and develop a mitigation strategy.\n\nA lack of transparency could also make it\ndifficult to trust the results of the generative\nmodel.\n\nThis is particularly worrying in cases\nwhen automated decision-making may be\nused to determine outcomes in high-stakes\ncontexts such as healthcare, social services\nand law enforcement.\n\nAs a multilingual organization with numerous\nspecialized entities, one of the key advantages of\ngenai for the UN is its ability to be trained on\nspecialized vocabulary and terminology.\n\nMoreover,\nthese models can be integrated into existing\ninterfaces, which can help boost rapid information\ndiscovery and automate knowledge management.\n\nPerhaps most importantly, genai can be\napplied in the context of the Sustainable Development\nGoals (SDGs).\n\nFor example, genai can provide\nmarginalized communities with improved access to\ncritical services such as healthcare and education.\n\ngenai can help detect diseases early and\nprovide personalized health recommendations based\non an individual\u2019s medical history, promoting health\nand well-being (SDG 3).\n\nIt can also facilitate the\nprovision of quality education (SDG 4) through the\ncreation of personalized learning experiences, making\neducation accessible to those who may not have\naccess to traditional learning opportunities.\n\nTo promote responsible use of genai, the\nUN could take steps to ensure that personalization\nfeatures of genai do not result in negative\nconsequences\u2014such as perpetuating biases or\nexacerbating existing inequalities\u2014especially for\nmarginalized populations.", "**CREATIVITY & INNOVATION**\n\nSome critics have raised concerns that\ngenai systems that have been trained\non copyrighted works, may infringe on the\nintellectual property rights of professional\nartists, writers and programmers.\n\nSeveral\nlawsuits have been filed against companies\nthat have used copyrighted material in their\ntraining data without the permission of (or\nattribution to) its content creators.\n\nAnother common concern among critics, is\nstudents\u2019 use of highly proficient generative\ngenai tools to complete writing assignments,\nas these programs can make it harder for\nprofessors and other academics to spot\ninstances of plagiarism.\n\nAdditionally, genai systems cannot\nalways be relied on for accurate information\nas they occasionally \u201challucinate\u201d or produce\nfalsehoods.\n\nThis occurs when a system fails\nto understand its prompts and confidently\nproduces outputs that do not match the\ndata it has been trained on.\n\nResearchers are\nconcerned that genai models could\nmake large-scale mis- and disinformation\ncheaper and easier to produce and\ndisseminate.\n\nWhile there are some steps that\ncan be taken to try to reduce instances of\n\u201challucinations\u201d (e.g., through reinforcement\nlearning with human feedback and input),\ncompletely eliminating these falsehoods is a\npersistent challenge.\n\n\uf0a8 **Hypothetical** \u2013 the technology is conceptually possible\n\n\ngenai can enable marginalized communities\nto tap into new and innovative resources and\nnetworks, which can help create jobs and generate\neconomic opportunities (SDG 8).\n\nFor instance,\ngenai can help democratize access to\neducation and training, which can equip people with\nthe skills they need to succeed in the digital economy.\n\nLeveraging genai can also help reduce\ninequalities (SDG 10).\n\nFor instance, genai technologies can\nbe used to identify and address disparities in access\nto education and healthcare services.\n\ngenai-powered\nplatforms can also help marginalized communities\nconnect with potential employers and access training\nand development resources.\n\nThe UN should take proactive measures to encourage\ncreativity and innovation within the bounds of ethical\nand legal principles by implementing policies that\npromote transparency, accountability and fair use\nof genai-generated content, especially from creative\nindustries.\n\n_The United Nations Office of_\n\n\n\uf0a8 **Experimental** \u2013 research and experiments are proving the technology\n\n\uf0a8 **Working Prototypes** \u2013 working examples are being built\n\n\uf0fe **Diffusion** \u2013 the technology is being adopted\n\n\uf0fe **Commercialization** \u2013 the technology is part of mainstream solutions\n\n\n_Information and Communications_\n\n_Technology (OICT) is developing an AI_\n\n_governance framework, as well as a_\n\n_matrix and guidance note, for the use_\n\n_of genai within the UN._", "**About the Emerging Technologies Team**\n\n_ETT expedites the adoption of frontier_\n\n_technologies across the UN Secretariat.\n\nIt_\n\n_leverages emerging technologies to generate_\n\n_greater efficiencies and to enhance the_\n\n_Organization\u2019s ability to respond to an ever-_\n\n_evolving technological landscape, while_\n\n_providing appropriate safeguards through_\n\n_the careful identification and evaluation of_\n\n_adoption-related risks._", "## Purpose\n\ngenai is a set of relatively new technologies that leverages large (very large)\nvolumes of data along with some machine learning (ML) techniques to produce content\nbased on inputs from the users known as prompts.\n\nThe new content can be written (e.g.\n\nChatGPT or Bard), or visual (e.g.\n\nDall-E).\n\nThese tools are evolving rapidly, and are still the\nsubject of active research: improving our understanding of how they actually work, and\nthe impacts of their use in society.\n\nThese tools are not actual intelligence in the human\nsense, rather, they are very sophisticated models that predict what the language, text, or\nvideo that satisfies the prompt should be.\n\n**Because of their impact and potential**\n**usefulness, as well as the risks and dangers, these guidelines serve as an interim**\n**resource for employees of the City of Boston.\n\n**\n\n**genai is a tool.\n\nWe are responsible for the outcomes of our tools.\n\nFor example, if**\n**autocorrect unintentionally changes a word - changing the meaning of something we**\n**wrote, we are still responsible for the text.\n\nTechnology enables our work, it does not**\n**excuse our judgment nor our accountability.\n\n**\n\n_These guidelines should be replaced in the future with policies and standards._ **_But we want to_**\n**_encourage responsible experimentation and we encourage you to try these tools for_**\n**_yourselves to understand their potential._** _The Department of Innovation and Technology will_\n_support events and workshops that can support people and teams interested in learning more_\n_about these technologies.\n\nFor the time being we encourage you to watch this video from_\n_Innovate.US about how to get started with genai in government:_\n_https:/_ _/bit.ly/InnovateUS-AI_\n\n_You can also share your experiences, thoughts, and concerns via this online form:_\n_https:/_ _/forms.gle/BptUcVhRdnTwHdxJ7_\n\n\n-----", "### Sample Use Cases\n\nThese are some of the types of uses that could be beneficial.\n\nAdditional good practices and\nexamples can be found at the end of this document.\n\n1.\n\nWriting a memo.\n\nIn government we often have to write short documents that\npresent an argument why a policy should be adopted or a decision should be made.\n\nFor instance try the prompt in ChatGPT, Bard, and other generative text tools:\n\nUnset\n```\n  Write a memo to the Chief Innovation Officer about the potential\n  benefits of the use of genai in city government.\n\n```\n2.\n\nWriting a job description.\n\ngenai can produce job descriptions that aggregate\nand average parts of similar job descriptions, giving you a very good generalized\nversion of a job description.\n\nFor instance try the prompt in ChatGPT, Bard, and\nother generative text tools:\n\nUnset\n```\n  Write the job description for a Chief Information Officer of a\n  large city", "**Empowerment**\n\n-  The use of genai should support the work of our workforce to deliver better, safer,\nmore efficient and equitable services and products to our residents.\n\n-  We rely and trust in our public sector professionals to do the right thing given the\nright tools and guidance.\n\nYou will need to exercise your judgment to make sure we\n\n\n-----\n\nget the benefits from the tools while avoiding the negative impacts for the City and\nits constituents.", "**Inclusion and Respect**\n\n-  The use and development of genai should support the development of work that\nrepairs damage done to racial and ethnic minorities, people of all genders and\nsexual orientations, people of all ages, people with disabilities, and others.\n\nOur\nwork should uplift these communities and connect them more effectively with the\nresources they need to thrive.\n\n-  Everything we do, regardless of the tools, are a reflection of the City and ourselves.\n\nWe are stewards of the public, and we will use tools respectfully and responsibly.", "**Transparency and accountability**\n\n-  We embrace the possibilities of technology and community.\n\nWe acknowledge that\nwe do not have all the answers nor can we foresee all consequences.\n\nBut when we\nact transparently, we build trust and we gain the ability to learn collectively.\n\n-  We also acknowledge that experimentation might have costs and impacts in of\nitself including the usage of power, greenhouse gas emissions.\n\nBeing purposeful\nand accountable to these impacts is important.", "**Innovation and Risk Management**\n\n-  We understand that there is value to be had in the use of technology, particularly\nnew genai, but there are also risks, some of which will not be apparent or\nfully understood upfront.\n\n-  We embrace a culture of responsible experimentation, where we maintain control\nand understanding of the use of new tools while we develop new uses that drive\nefficiency, delight, civic dialogue or other outcomes in service of our residents.", "#### Fact Check and review all content generated by genai, especially if it will be used in public communication or decision making .\n\n_\u25cf_ _Why:_ While genai can rapidly produce clear prose, the information and\ncontent might be inaccurate, outdated, or simply made up.\n\nIt is your responsibility\nto verify that the information is accurate by independently researching claims\nmade by the genai.\n\n_\u25cf_ _What to look for:_\n\n\u25cb Inaccurate information including links and references to events or facts.\n\n\u25cb Bias in the positions or information.\n\nWe want to make sure that vulnerable\npopulations are not harmed by these technologies.\n\nThink about how racial\nand ethnic minorities, women, non-binary, people with disabilities or others\ncould be portrayed or impacted by the content.", "#### Disclose that you have used genai to generate the content.\n\nYou should also include the version and type of model you used (e.g, Open genai's GPT 3.5 vs Google's Bard ).\n\nYou should include a reference as a footer to the fact that you used genai:\n\n_\u25cf_ _Why:_ even when you use genai minimally, disclosure builds trust through transparency\nand it might help others catch errors.\n\n_\u25cf_ _Suggestions:_ document how you used the model, the prompts you used etc.\n\nit could\nbe helpful to you and your colleagues to better understand how you can use these\ntechnologies better and more safely.\n\n_\u25cf_ _Sample credit line: \u201c_ This description was generated by ChatGPT 3.5 and edited by\nSantiago Garces\u201d\n\n_\u25cf_ _Sample credit line:_ \u201cThis text was summarized using Google Bard\u201d", "#### Do not share sensitive or private information in the prompts\n\n_\u25cf_ _Why_ : data including prompts used in genai might be used by the companies\nthat power these systems.\n\nAny information that includes personally identifying\ninformation about our residents, other public servants, etc.\n\ncould inadvertently be\nshared with others.\n\nBasically if you wouldn\u2019t share with other people or want to put\nthe prompt in a public place, avoid sharing the information in the prompt.\n\n_If you_\n_have an application that requires sensitive information to be used with a generative_\n\n\n-----\n\n_AI, contact DoIT so we can help you provision access to enterprise secure resources to_\n_do so._", "#### Drafting documents or letters:\n\ngenai provides a great opportunity to get started on a memo, letters, job\ndescriptions.\n\nNote that when creating a prompt for ChatGPT for this context, it can\nconsider including any specific format preferences such as essay, bullet points, outline or\ndialogue.\n\nAdditionally, you can request the use of specific keywords or phrases, or\ntechnical terms to be included or avoided in the response.\n\nThis will help ChatGPT provide\nyou with a more tailored and efficient response to your request.\n\n-  Example: generate guidelines for the use of ChatGPT at the City of Boston\n\n-  Example: write a letter requesting support for funding digital equity initiatives in\nthe next budget session.\n\n-  Example: you can ask Chat GPT to generate letters that express points of view\nspecified in the prompt.\n\nThis might allow you to understand an issue from different\nperspectives.\n\n-  Example: **You can ask genai to help you write a more effective version of a**\n**prompt.\n\nYou can say \u201c help me write a better prompt to [insert the initial objective**\n**of the prompt].\n\n**\nDo\u2019s:\n\n1.\n\nTry to be specific in the prompt.\n\nIf you give more context, the answer\nbecomes more relevant.\n\n2.\n\nEdit and review the content.\n\nRegardless of how the content was authored,\nyou and the City will bear responsibility over its use in the public.\n\nDon\u2019ts:\n\n1.\n\nDo not include confidential information in the prompt.\n\n2.\n\nDo not rely on genai to provide accurate answers.\n\n-----\n\n3.\n\nDo not use genai to create communication regarding sensitive\ntopics.\n\nFor instance, a renowned institution was criticized for using\ngenai to write a press release regarding a shooting.", "#### Drafting Content In Plain Language\n\ngenai can help you write clearer and simpler language.\n\nYou can use the prompt to\nindicate the reading level or audience for a text.\n\n-  Example: use ChatGPT or Bard to write a version of the Declaration of\nIndependence of the United States for a person in elementary school.\n\n-  Example: use tools such as AISEO, Wordtune or others to modify a sentence.\n\nThese\ntools are similar to a thesaurus but for sentences and often allow you to optimize\nfor the length of the sentence, or the audience.\n\nDo\u2019s:\n\n1.\n\nSpecify in the prompt if you have a specific audience in mind.\n\n2.\n\nTry different prompts, or request different versions of the same sentence\nuntil you find what works best.\n\n3.\n\nYou can pass the output of the text by a readability app that can identify\nchallenging sentences, as well as the reading level for the text.\n\nDon'ts:\n\n1.\n\nDo not include confidential information in the prompt.\n\n2. Review the text to ensure that the language is inclusive and respectful.\n\nThe\nmodels might use language or patterns that appear regularly, but that might\nexclude some people.\n\nFor instance, a model might suggest: \u201cDear Sir/Ma'am\u201d\ndoes not include non-binary people, and could be replaced with \u201cDear\nColleague\u201d or \u201cDear neighbor\u201d.", "#### Drafting Content In Other Languages\n\ngenai can help you draft communications in another language.\n\nIt is not well documented the\nextent to which ChatGPT and other models can use other languages, but users report over\n50 languages being available for ChatGPT, including some native american languages.\n\n-  Example: use ChatGPT to translate these guidelines into Spanish and French, just\nask \u201ctranslate [your text] into Spanish and French.\u201d\n\n-  Example: you can ask genai in what language some text is written in, just\nask \u201cwhat language is [original language] written in?\u201d\n\n\n-----\n\nDo\u2019s:\n\n1.\n\nTry different languages.\n\nChatGPT, Bard and other models were trained using\ntext from many languages.\n\nChatGPT told me it didn\u2019t speak Quechua in\nQuechua!\n\n2.\n\nYou can also ask genai to perform similar tasks as the ones in this\ndocument in other languages, such as summarizing text, etc.\n\nDon'ts:\n\n1.\n\nDo not include confidential information in the prompt.\n\n2.\n\nDo not use content generated in a language you do not understand before\nconsulting someone with proficiency in the language.\n\nYou still need to check\nfor accuracy, bias, etc.\n\n3.\n\nLanguage generated in other languages might be confusing to people who\nspeak different regional dialects.\n\nDo not assume that some text will be easily\nunderstood by all speakers.\n\nUse the prompt to get regional diction.", "#### Summarizing Text\n\ngenai does a great job of summarizing longer pieces of text into summaries.\n\nIf you\nhave a few pages that you want to condense into a few bullet points, or you have been\nstruggling with converting a long set of notes into a paragraph, these tools could be very\nhelpful.\n\n-  Example: copy notes taken from a meeting to generate a short summary of the\nmeeting.\n\n-  Example: summarize citizen comments in response to an engagement\n\n-  Example: write a paragraph summary of a 5 page report.\n\n-  Example: use Fathom, Wudpecker, or the transcript tools in Google Hangouts to\ntranscribe audio into text.\n\nYou can then summarize the text further using\ngenai.\n\nThis summarization is included in some of these tools.\n\nDon\u2019ts:\n\n1.\n\nDo not include confidential information in the prompt: make sure you have\ndeleted confidential information from your notes or other inputs.\n\n2.\n\nIf you plan on making a decision based on the summary, you should read the\nentire document(s) to make sure you did not miss or miss characterized the\noriginal document.\n\n-----\n\n3.\n\nBe aware that the resulting summary might have biases as it will tend to\npresent language that is more frequent in the data used to train the model.\n\nYou can use changes to the prompt to enhance the results by suggesting\nthat the result incorporates perspectives from marginalized groups.\n\nEven\nbetter, you can engage with some individuals in these communities to better\nunderstand their perspectives on the text generated.", "#### Summarizing Audio\n\nCoding/Programming\n\ngenai can be great at producing snippets or even help you build more complex\ncomponents of code.\n\n-  Example: write code in Python that extracts tables in a PDF into a Pandas data\nframe.\n\n-  This can make it possible for less technical people, including interns and student\nworkers, to get to work on technical projects.\n\nDo\u2019s:\n\n1.\n\nExplore new languages and libraries - but you should understand the code and read\nthe documentation of the relevant components before using it.\n\n2.\n\nYou might have to adjust parameters, and your environment to make the\nsuggestions from the genai model work.\n\ngenai can help you get started, but\noften you will have to edit before the code works.\n\nDon\u2019ts:\n\n1.\n\nDo not include confidential information in the prompt.\n\nAs in development best\npractices: do not include passwords, confidential keys, or other proprietary\ninformation in your code or in the prompts.\n\n2.\n\nYou should understand what the code is doing before using it in production.\n\n3.\n\nYou should understand the use of new libraries and dependencies, and become\nfamiliar with vulnerabilities and other security considerations of using a language\nor a library.", "#### Images, Audio, and Videos\n\ngenai can produce images,audio, and videos based on prompts.\n\nThis can support\nthe creation of appealing or insightful communication resources.\n\n-----\n\n-  Example: make an image in a medieval style of residents connecting to the wifi in\norder to create appealing collateral for a digital equity campaign.\n\n-  Example: create a training video that walks residents on how to schedule a bulky\nitem pick up, by providing the script of the video.\n\n-  Example: write a jingle or song to remind them to switch to Boston\u2019s Community\nChoice Electricity to switch to 100% renewable energy.\n\nDo\u2019s:\n\n1.\n\nVisual,audio and video communication can be a powerful tool to communicate with\n\nothers and get across a message.\n\ngenai can empower you to use these tools\nbeyond your artistic skills.\n\n2.\n\nUse genai as a tool to create drafts or mock ups that allow you to\ncommunicate more effectively with graphic designers, videographers, and other\ncreative workers.\n\n3.\n\nContact your department or agency\u2019s public information officer about the image,\naudio, or video before publishing or using it.\n\nThey have expertise on best practices\nin accessibility, branding, etc.\n\n4.\n\nEngaging with members of the Equity Cabinet, or community organizations that\nrepresent groups that might be referenced or impacted by this content.\n\nGetting\ntheir perspective, in a respectful way, can help you identify when content might be\nhurtful, discriminatory, or misinterpreted.\n\nDon\u2019ts:\n\n1.\n\nDo not include confidential information in the prompt: make sure you have deleted\nconfidential information from your notes or other inputs.\n\nSome confidential\ninformation could include: people\u2019s faces, people\u2019s voices, their identifications,\nlicense plates, etc.\n\nParticularly, those who have not provided their consent.\n\n2.\n\nMake sure the outputs of the genai will not be offensive or harmful towards\npeople, particularly vulnerable residents that are susceptible to harm including\nethnic and racial groups, diverse gender individuals, and others.\n\n3.\n\nMake sure that any content adheres to the City\u2019s Brand Guidelines", "## Resources\n\nYou can contact the Department of Innovation and Technology [] to learn\nmore about genai.\n\nYou can also contact the Mayor\u2019s Office of Arts and Culture  [ ] or to the\nMayor\u2019s Office of New Urban Mechanics  [ ] if you want to\n\n\n-----\n\ndiscuss important questions about the impact of genai on the arts and on our\nsociety.\n\nThe following resources include external links.\n\nWe do not endorse any one of these\nresources.\n\nReddit, ChatGPT sub reddit: https:/ //\n\nA great explanation on the mathematical principles behind generative language models:\n\nStephen Wolfram (2023), \"What Is ChatGPT Doing ... and Why Does It Work?,\" Stephen\nWolfram Writings.\n\nwritings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.\n\ngenai Principles from Microsoft:\nhttps:/ /\n\ngenai Principles from Google:\nhttps:/ /genai.google/principles/\n\nNIST genai Risk Framework:\nhttps:/ /nvlpubs.nist.gov/nistpubs/genai/NIST.genai.100-1.pdf\n\nA critical analysis of large language models (major paper that predicted much of the\nharms/risks we are experiencing now)\nhttps:/ /dl.acm.org/doi/10.1145/3442188.3445922", "## Acknowledgements\n\nThe development of these guidelines has benefited from the contributions of academic,\ncommunity, and City of Boston team members.\n\nSpecial thanks to Beth Noveck, Director of the Burnes Center for Social Change at\nNortheastern University; Saiph Savage, Director of the Civic genai Lab at Northeastern\nUniversity; Catherine D\u2019Ignazio, Director of the Data + Feminism Lab at MIT; Kimberly\nLucas, Professor of the Practice at Northeastern University; Mitch Weiss, Professor at\nHarvard Business School; Alejandro Jimenez Jaramillo; Michael Evans from the Mayor\u2019s\nOffice of New Urban Mechanics; Jerry Kelley, project manager at the Department of\nInnovation and Technology, Kerry Jordan, Chief of Staff at the Department of Innovation\nand Technology.\n\n-----", "# Interim Policy\n\nChief Technology Officer\n\nDate: April 18, 2023\n\nFrom: Jim Loter, Interim Chief Technology Officer & Department Director, Seattle IT\n\nSubject: Use of genai in City of Seattle\n\nMemo Number: IPM-2301\n\n_A provisional policy document is issued when a policy is needed within a time period too short to_\n_complete the normal policy development process.\n\nAn Interim Policy is in effect for at least 6 months_\n_with possible extensions of six-month increments._", "## Impact Statement\n\ngenai (genai) systems have become extremely popular and prevalent in a very short\namount of time.\n\nThere is likely interest in using such systems to conduct City business.\n\nThe field is emergent\nand rapidly evolving, and the potential policy impacts and risks to the City are not fully understood.\n\nUse of\ngenai systems with the City of Seattle, therefore, can have unanticipated and unmitigated impacts.\n\nThis Interim Policy is intended to minimize issues that may arise from the use of this technology while\nadditional research and analysis is conducted.", "## Background and Definitions\n\ngenai refers to a class of genai systems that are capable of generating content, such as text, images,\nvideo, or audio, based on a set of input data rather than simply analyzing or acting on existing data.\n\nPopular\ngenai systems include GPT-3 and GPT-4/ChatGPT, Dall-E, and Lensa genai among many others.\n\ngenai technology is rapidly being incorporated into common online tools, such as search engines.\n\nThese systems have the potential to support many City business functions and services, however their use\nalso raises important questions, particularly around the sourcing of training data, ensuring proper\nattribution of generated content, and the handling of sensitive or public data.\n\nFurther research into this technology may uncover issues that require more restrictions on its use.\n\nEmployees are strongly advised to not invest heavily in using this technology or use it to support critical\nprocesses.", "## Interim Policy\n\n1.\n\n**Acquisition or use.\n\n** All software services, even if they are free or part of a pilot or proof-of-concept\n\nproject, must be acquired via Seattle IT\u2019s acquisition processes to ensure the software receives all\n\n\n-----\n\nnecessary reviews and considerations (SMC 3.23.040).\n\nThis requirement applies to downloadable\nsoftware, Software as a Service, web-based services, browser plug-ins, and smartphone apps.\n\na.\n\nIf a City employee wishes to create an account with a genai service or otherwise use\n\ngenai systems to perform functions related to City business, the employee must\nsubmit a Service Hub purchase request for software (indicate \u201cz_Unlisted Software\u201d),\nspecify the genai service and describe how it will be used, and obtain departmental approval.\n\nb.\n\nUse of genai technology that is incorporated into existing services and products,\n\nsuch as internet search engines, does not require permission to use, however the following\nguidelines must be followed.\n\n2.\n\n**Intellectual property.\n\n** Content produced by genai systems may include copyrighted\n\nmaterial.\n\ngenai systems may be \u201ctrained\u201d using data (text, images, etc.)\n\nthat has been sourced from the\ninternet without regard for copyright or licensing terms.\n\nIt is extremely difficult to determine what\ncontent was used to train an genai system, and difficult to verify whether genai-generated content is\nwholly original or only a slight stylization of existing copyrighted material.\n\nNevertheless, City\nemployees are required to perform due diligence to ensure that no copyrighted material is\npublished by the City without proper attribution or without obtaining proper rights.\n\n3.\n\n**Attribution and accountability.\n\n** Audiences should know when content was produced by genai in whole\n\nor in part.\n\nIf a City employee uses genai-generated content in an official City capacity, the content\nshould be clearly labeled as having been produced using genai tools.\n\nEmployees should also\nconsider including information about how the material was reviewed and edited, and by whom.\n\nThis\nallows consumers of the content to understand its authorship and be able to evaluate the content\naccordingly.\n\n4.\n\n**Reduce bias and harm.\n\n** genai systems can reflect the cultural, economic, and social biases of the source\n\nmaterials used for training, and the algorithms used to parse and process that content can be a\nsource of bias as well.\n\nEmployees should carefully review any content generated by genai to ensure\nthat unintended or undesirable instances of bias, or even potentially offensive or harmful material,\nis changed or removed.\n\n5.\n\n**Data privacy.\n\n** City employees must not submit any sensitive, confidential, or regulated data, or any\n\npersonally-identifiable data about members of the public, to a genai system.\n\n6.\n\n**Public records.\n\n** Employees should be aware of when the use of a genai system may result in\n\nthe creation of a public record that must be retained under Washington state\u2019s Public Records Act.\n\nYour department\u2019s Privacy Champion and/or Public Disclosure Officer can be a resource to provide\nfurther guidance.", "## Next Steps and Actions\n\nThroughout Q2 2023, Seattle IT will work with internal and external stakeholder groups to conduct research\ninto the policy implications for government use of genai.\n\nIn the meantime, this Advisory Memo\noutlines the preliminary considerations and guidelines that City employees should follow when working with\ngenai services in a City context.\n\n-----\n\nEnforcement of this policy will be led by the Chief Technology Officer (CTO) and may be imposed by\nindividual division directors.\n\nNon-compliance may result in disciplinary action, restriction of access, or more\nsevere penalties up to and including termination of employment or vendor contract.", "**2.\n\n** **Scope**\n\nThis ITP applies to all offices, departments, boards, commissions and councils under the\nGovernor\u2019s jurisdiction (hereinafter referred to as \"agencies\").\n\nAgencies not under the\nGovernor\u2019s jurisdiction are strongly encouraged to follow this ITP.\n\nThird-party vendors,\nlicensors, contractors, or suppliers shall meet the policy requirements of this ITP that\nare applicable to the products and services provided to the Commonwealth.", "**3.\n\n** **Background**\n\nThe field of genai has developed rapidly, and the availability and popularity of Generative\ngenai has greatly increased.\n\nThere is significant public interest in genai because of\nits potential to empower creativity, innovation, and efficiency.\n\nHowever, the technology\nalso presents risks and new challenges that the Commonwealth must navigate.\n\nThis\npolicy encourages users to engage with these technologies in a manner that is additive\nto their work and the services they provide to customers, residents, visitors, and\nindustry, while addressing and mitigating risks inherent in its use.\n\nThe Commonwealth\nwill continually review policies and directives relating to the governance of Generative\ngenai use in all its forms and evaluate genai tools that may provide additional\nsecurity while mitigating risks associated with this technology.\n\n-----", "**4.\n\n** **Definitions**\n\n**Bias:** Erroneous or prejudiced assumptions in genai and machine\nlearning processes that may affect generative output.\n\n**genai (genai):** Predictive algorithms that can\nbe used to create new content including audio, code, images, text, simulations, and\nvideos.\n\n**Private genai:** genai tools that are specific to an entity or\norganization and their data.\n\nPrivate genai tools can be developed in-house by\nan entity or organization for their own use or obtained from a third-party vendor.\n\nThese\nsystems are configured in a way that ensures an organization\u2019s data is segmented from\nother Training Data and accessible to only the entity or organization that owns it.\n\n**Public genai:** genai tools that are openly available to multiple\nentities, organizations, or the general public and utilize widely sourced data from the\ninternet as well as data from users or customers to train the genai model.\n\nPublic genai tools do not guarantee the privacy of data input by users, entities,\nor organizations.\n\nAdditionally, Training Data and models are not owned by a public\norganization unless otherwise noted.\n\n**Training Data:** Data used to train a large language model and other predictive\nalgorithms.", "**6.\n\n** **Policy**\n\nIf using genai, users may only use a Commonwealth approved Public\ngenai tool.\n\nPublic genai tools that receive approval are available for use\nonly in accordance with this policy.\n\nThere are many Public genai tools that offer\ndifferent strengths and weaknesses.\n\nThe Commonwealth will continue to evaluate and\nmay approve additional Public genai tools that may be of value to users.", "**6.1 Account Creation**\n\ngenai tools often require that users enter an email address to register and\ncreate an account.\n\nUsers, who are utilizing an approved Public genai tool\nfor Commonwealth business purposes, shall use their Commonwealth e-mail\naddress for registration and account creation purposes.\n\nOnce created, the account associated with a user\u2019s Commonwealth e-mail address\nshall be used solely for Commonwealth business purposes.\n\nPersonal use of Public\ngenai from an account using a Commonwealth e-mail is prohibited.\n\n-----\n\nUpon completion of the registration and the account creation process, users shall\nopt-out of data sharing and disable the chat history within the Public genai\nsystem.\n\nIf unable to opt-out, the user must contact the Office of Administration,\nOffice of Information Technology (OA IT) prior to using the Public genai\nsystem.", "**6.2 Risk Assessment**\n\ngenai is a versatile technology that can be used for a variety of purposes.\n\nLike any other tool, different use cases create different risks and rewards.\n\nWhile\ngenai tools are relatively new, many of the risks are the same as common\ninternet or software-based tools.\n\nExamples of common risks with genai\ntools are:\n\n-  Sharing private or confidential information in a genai prompt .\n\n-  genai outputs that are inaccurate or misleading in communications\nto the public or relying on inaccurate or misleading outputs to inform agency\nprograms or policies .\n\n-  Reinforcing existing Bias in work products due to Bias in genai\noutputs .\n\n-  Copyright infringement.\n\nBecause the use of Public genai tools can pose significant risk depending on\nthe information or data input into the tool, proper governance of such tools is\nrequired.\n\nWhen assessing whether to use an approved Public genai tool,\nusers should consider if the use case is high or low risk and high or low impact.\n\nHigh risk uses should be approached with additional review and governance and\navoided when their impact is also minimal.\n\nUse cases that are l ow risk and high\nimpact are potential opportunities to use Public genai.\n\nExamples of such\nuse cases are:\n\n-  **High risk/low impact (avoid):** Using genai to draft an external\nfacing communication that includes sensitive information for citizens and\nwould have taken minimal time to write manually.\n\nC opying and pasting that\noutput for use with minimal review.\n\n-  **Low risk/high impact:** Using genai to compare a new and old\nversion of a publicly available policy and asking the genai tool to\nidentify which sections have been modified, then, confirming the nature of\nthese changes manually.\n\n**genai & Coding:** genai tools can be an excellent coding resource\nwith high impact.\n\nPublic genai tools used for coding purposes should be\napproached with caution, and special attention should be paid to risk assessment.\n\nSubject matter experience is required to properly validate genai outputs,\nand this requirement is particularly necessary for coding use cases.\n\nUsers must be\ncautious not to include production code or proprietary information in prompts, must\nassess vulnerabilities in code outputs, and must keep in mind that assessment of\nthese outputs may require technical knowledge.\n\nUse of genai in coding\nmay result in more bugs or flaws in programs since it may gather the code from\n\n\n-----\n\nflawed sources.", "**6.3 Accountability, Review, and Verification**\n\nWhen using any genai for Commonwealth business purposes, **the user is**\n**accountable for any genai outputs and must** review and verify all\nassociated output content.\n\n**Qualifications to verify and review outputs** : For a user to be able to review and\nverify outputs adequately, the user must have experience in the relevant topic\narea.\n\nFor example, a software engineer may be able to verify the quality of code\ngenerated in a coding language in which the engineer specializes but may not be\nable to verify if a contract is legally sound without the requisite legal training.\n\ngenai content should not be assumed to be accurate.\n\nAt a minimum, users\nshould review the output for:\n\n-  **Bias:** Since the data used to train genai is vast, from a variety of\nsources, and not always vetted, outputs may contain inaccurate assumptions\nor stereotypes regarding certain individuals or communities.\n\n-  **Dated Information:** The data used to train genai may have a fixed\ncutoff date, meaning any output generated will not reflect information\navailable after a certain cutoff date.\n\n-  **Inaccurate Information:** genai relies on Training Data.\n\nTraining\nData is vast and not always consistent or accurate.\n\nInaccuracies in the Training\nData may be included in the output generated by the genai system.\n\nInaccurate output can also be generated regardless of the Training Data.\n\nThe\ngenai system may produce a confident response that appears\nplausible; however, the response is fabricated and divorced from reality\n(sometimes referred to as \u201challucinations\u201d).\n\nIn one recent example, a user\ndoing legal research using genai was provided several court decisions,\nand the decisions provided by the genai system turned out to be nonexistent and completely fabricated.\n\n-  **Inappropriate Content:** If Training Data contains inappropriate content, the\ninappropriate content could appear in the genai output.\n\n-  **Intellectual Property:** genai tools continually ingest publicly\navailable information for training purposes including information that may be\nsubject to copyright.\n\nCopyrighted information could be inappropriately included\nin any output generated by the genai system, creating intellectual\nproperty risks.\n\n-  **Confidential, Non-Public Information:** Since the data used to train\ngenai is vast, from a variety of sources, and not always vetted,\noutputs may contain confidential, non-public information.", "**6.4 Disclosure**\n\nU sers shall be transparent about their use of genai and must disclose to\ncustomers residents visitors and industry when genai has been used to\n\n\n-----\n\ngenerate content that may be public facing or shared externally.\n\ngenai use\nmust be disclosed even if it was only used to generate a portion of the content.\n\nThe\ndisclosure shall be prominently displayed and include an indication that the content\nwas generated either entirely or in part by genai and identify the\ngenai system and version that was used.\n\n**Example:** \u201cChatGPT-3.5 was used in the creation of this document.\u201d", "**6.6.2 Non-Text Outputs**\n\nUsers shall not utilize Public genai for non-text-based outputs.\n\nMost\ngenai platforms can generate images, video, audio, or other types of\ncontent.\n\nHowever, the risks related to inadvertently including other\u2019s\nintellectual property or generating offensive content are significantly higher\nand more difficult to detect than with text-based outputs.\n\nStructured data,\nnumbers, code, and different languages are acceptable outputs from\ngenai only so long as the output is properly reviewed and verified by\nusers with the appropriate expertise.", "**6.6.3 Private and Sensitive Data**\n\nNo class C data, as defined in _ITP-INF015, Policy and Procedures for_\n_Identifying, Classifying, and Categorizing Commonwealth Electronic Data_ ,\nmay be input into any Public genai prompt, tool, or system.\n\nThis\nincludes, but is not limited to:\n\n-  Sensitive Security Information\n\n-  Personal Identifiable Information (PII)\n\n-  Protected Health Information (PHI)\n\n-  Regulated Data \u2013 Such as data from or regulated by:\n\n\n`o` Social Security Administration (SSA)\n`o` Internal Revenue Service (IRS)\n`o` Centers for Medicare & Medicaid Services (CMS)\n`o` Criminal Justice Information (CJI)\n`o` Criminal History Record Information Act (CHRIA)\n`o` Family Educational Rights and Privacy Act (FERPA)\n`o` Payment Card Industry Data Security Standard (PCI DSS)\n\nConfidential or Non-Public Information\n\nPrivileged Information\n\n\n-----\n\n-  Prerequisite Required Information\n\nAdditionally, any non-public records or information that would be considered\nprivileged or exempt from access under the _Right-to-Know Law (RTKL), 65_\n_P.S.\n\n\u00a7\u00a7 67.101, et seq._ may not be input into any Public genai\nprompt, tool, or system.", "**6.6.4 Decision Making**\n\ngenai outputs are not to be used to make decisions for or on behalf\nof employees.\n\nEmployees may use genai outputs to inform a larger\ndecision-making process, but ultimately the Commonwealth employee or\nofficial remains the final decision maker.\n\nUsers must review and verify all\noutput produced with the assistance of genai.\n\nThe user will be\naccountable for any decision-making based upon such output.\n\ngenai\ncannot make reliable subjective or value-based judgments and may not be\nused for such purposes.\n\n-  For example, do not use genai to make final decisions that affect\nemployment.", "**6.7 Acceptable Uses**\n\nExamples of acceptable uses of Public genai include:\n\n-  Drafting a job posting or job description\n\n-  Summarizing or paraphrasing a writing\n\n-  Taking a technical answer to a question and rewriting it in customer-friendly\nlanguage\n\n-  Creating an outline for a memo or other communication\n\n-  Brainstorming icebreakers for a meeting\n\nThe examples provided above assume that the genai tool has been\napproved for use; only public, non-confidential data is involved; and proper review\nand verification is completed as outlined in section 6.3 of this policy.\n\nThis is not a comprehensive list of the permitted uses, but rather illustrates some\ncommon lower risk use cases.", "**7.3 Third-party vendors, licensors, contractors, or suppliers shall:**\n\nComply with the requirements as outlined in this ITP that are applicable to the\nproducts or services they are providing to the Commonwealth.\n\nIf the products or\nservices being provided by the third-party vendor, licensor, contractor, or supplier\ndo not fall within the scope of this ITP, compliance is implied.\n\nIf the third-party\n\n\n-----\n\nvendor, licensor, contractor, or supplier subsequently deploys products or services\nthat fall within the scope of this ITP in the future, compliance with the policy is\nrequired.", "**11.\n\n** **Exemption from this Policy**\n\nIn the event an agency chooses to seek an exemption from the guidance within this\nITP, a request for a policy waiver shall be submitted via the enterprise IT policy waiver\nprocess.\n\nRefer to ITP-BUS004 _IT Policy Waiver Review Process_ for guidance.\n\nThis chart contains a history of this publication\u2019s revisions.\n\nRedline documents detail the\nrevisions and are available to CWOPA users only.\n\n|Version|Date|Purpose of Revision|Redline Link|\n|---|---|---|---|\n|Original|09/21/2023|Base Document|N/A|\n\n\n-----", "MEMORANDUM\n\n8200.00\n\n\nEffective Date\n\n31 July 2023\n\n\nApproval Date\n\n25 July 2023\n\n\nType of Action\n\nRevision\n\n1.0 SUBJECT: genai Policy\n\n2.0 DISTRIBUTION: Executive Branch Cabinet and Non-Cabinet Agencies\n\n\n3.0 FROM: ____________________________________________\n\nJeff Maxon, Interim Chief Information Technology Officer\n\n4.0 PURPOSE:\n\nThe purpose of this policy is to outline the acceptable use of genai (genai).\n\nThe policy is created to protect the safety, privacy, and intellectual property rights of the State of\nKansas.\n\n5.0 BACKGROUND:\n\nAs genai technology progresses, chatbots, virtual assistants, and other systems based on it\nare becoming more prevalent.\n\nThese can include standalone systems, be integrated as features\nwithin search engines, or be overtly or transparently embedded in all manner of other software\ntools.\n\nExamples include ChatGPT and DALL-E from OpenAI, Microsoft Bing\u2019s chat, Microsoft\n365 Copilot, and Bard from Google.\n\ngenai tools have the potential to enhance productivity by assisting with tasks like drafting\ndocuments, editing text, generating ideas, and software coding.\n\nHowever, these technologies also\ncome with potential risks that include inaccuracies, bias and unauthorized use of intellectual\nproperty in the content generated.\n\nIn addition, content created by genai, and the public availability of\ninformation submitted to the genai, could pose security or privacy concerns.\n\n6.0 ORGANIZATIONS AFFECTED: Executive Branch Cabinet and Non-Cabinet Agencies\n\n7.0 REFERENCES:\n\n7.1 ITEC Policy 7230A\n\n7.2 State of Kansas Social Media Policy\n\n8.0 DEFINITIONS:\n\n\n-----\n\n8.1 genai (genai) uses advanced technologies such as predictive\n\nalgorithms, machine learning, and large language models to process natural language and\nproduce content in the form of text, images, or other types of media.\n\nGenerated content is\ntypically remarkably similar to what a human creator might produce, such as text consisting of\nentire narratives of naturally reading sentences.\n\n8.2 Restricted Use Information as defined in ITEC 7230A.\n\n8.3 Entity is defined as agencies, boards, commissions under the direction of the Governor or\n\nagents and contractors acting on behalf of those agencies, boards or commissions.\n\n9.0 POLICY: This policy shall serve as the primary governing document for usage of generative\n\ngenai technology as a user or related activities by the entities.\n\nWhile any entity may\nimpose additional restrictions through their own policy, such policies must not conflict with the\nprovisions outlined in this policy.\n\n9.1 This policy applies to all business use cases involving the State of Kansas, including but not\n\nlimited to:\n\n9.1.1 development of software code,\n\n\n9.1.2 written documentation (i.e., policy, legislation, or regulations) and correspondence (such\n\nas memorandums, letters, text messages, and emails),\n\n9.1.3 research,\n\n9.1.4 summarizing and proofreading documents,\n\n\n9.1.5 making business decisions that impact short-term or long-term activities or policies and\n\nprocedures.\n\n9.2 Responsibilities\n\n\n9.2.1 Responses generated from genai outputs shall be reviewed by knowledgeable\n\nhuman operators for accuracy, appropriateness, privacy and security before being acted\nupon or disseminated.\n\n9.2.2 Responses generated from genai shall not:\n\n9.2.2.1 be used verbatim,\n\n9.2.2.2 be assumed to be truthful, credible, or accurate,\n\n9.2.2.3 be treated as the sole source of reference,\n\n9.2.2.4 be used to issue official statements (i.e.\n\npolicy, legislation, or regulations),\n\n9.2.2.5 be solely relied upon for making final decisions,\n\n9.2.2.6 be used to impersonate individuals or organizations.\n\n9.2.3 Restricted Use Information (RUI) shall not be provided when interacting with generative\n\ngenai.\n\nRefer to ITEC Policy 7230A Section 9.16 Account Management - RUI.\n\n-----\n\n9.2.4 Material that is inappropriate for public release shall not be entered as input to generative\n\ngenai.\n\nAll information that is provided shall be subjected to the same standard as referenced\nin the State Social Media Policy and shall be treated as publicly available.\n\n9.2.5 Material that is copyrighted or the property of another, shall not be entered as input to\n\ngenai.\n\n9.2.6 genai shall not be used for any activities that are harmful, illegal, or in violation\n\nof state policy or agency acceptable use policy.\n\n9.2.7 Agencies shall ensure contractors disclose in their contracts the utilization of generative\n\ngenai or integrations with genai platforms.\n\n9.2.8 Agency contracts shall prohibit contractors from using State of Kansas RUI or other\n\nconfidential data in genai queries or for building or training proprietary\ngenai programs unless explicitly approved by the agency head with consultation\nfrom the Chief Information Security Officer.\n\n9.2.9 Contractors utilizing genai to build software explicitly for the State of Kansas\n\nmust demonstrate positive control over all data input into the system.", "9.2.9 Contractors utilizing genai to build software explicitly for the State of Kansas\n\nmust demonstrate positive control over all data input into the system.\n\n9.3 Software Code development\n\n\n9.3.1 Software code generated by genai shall only be implemented after the entity has\n\nidentified and mitigated all business and security risks related to its use.\n\n9.3.2 All usage of software code generated by genai shall be annotated.\n\n10.0 RESPONSIBILITIES:\n\n10.1 Heads of entities are responsible for establishing procedures for their organization\u2019s\ncompliance with the requirements of this policy.\n\n10.2 OITS is responsible for the maintenance of this policy.\n\n11.0 HISTORY: This PPM was originally issued #8200.00, dated 19 May 2023.\n\n12.0 CONTACT: Chief Information Technology Architect\n\n\n-----", "### Updated September 29, 2023\n\nInnovations in genai (genai) are raising new questions about how copyright law principles\nsuch as authorship, infringement, and fair use will apply to content created or used by genai.\n\nSo-called\n\u201cgenai\u201d computer programs\u2014such as Open genai\u2019s DALL-E and ChatGPT programs, Stability genai\u2019s\nStable Diffusion program, and Midjourney\u2019s self-titled program \u2014are able to generate new images, texts,\nand other content (or \u201coutputs\u201d) in response to a user\u2019s textual prompts (or \u201cinputs\u201d).\n\nThese genai\nprograms are trained to generate such outputs partly by exposing them to large quantities of existing\nworks such as writings, photos, paintings, and other artworks.\n\nThis Legal Sidebar explores questions that\ncourts and the U.S.\n\nCopyright Office have begun to confront regarding whether genai outputs\nmay be copyrighted and how genai might infringe copyrights in other works.", "### Do genai Outputs Enjoy Copyright Protection?\n\nThe question of whether or not copyright protection may be afforded to genai outputs\u2014such as images\ncreated by DALL-E or texts created by ChatGPT\u2014likely hinges at least partly on the concept of\n\u201cauthorship.\u201d The U.S. Constitution authorizes Congress to \u201csecur[e] for limited Times to Authors .\n\n.\n\n.\n\nthe\nexclusive Right to their .\n\n.\n\n.\n\nWritings.\u201d Based on this authority, the Copyright Act affords copyright\nprotection to \u201coriginal works of authorship.\u201d Although the Constitution and Copyright Act do not\nexplicitly define who (or what) may be an \u201cauthor,\u201d the U.S.\n\nCopyright Office recognizes copyright only\nin works \u201ccreated by a human being.\u201d Courts have likewise declined to extend copyright protection to\nnonhuman authors, holding that a monkey who took a series of photos lacked standing to sue under the\nCopyright Act; that some human creativity was required to copyright a book purportedly inspired by\ncelestial beings ; and that a living garden&hl=en&as_sdt=4,112,127,268,269,270,271,272,314,315,331,332,333,334,335,377,378) could not be copyrighted as it lacked a human author.\n\nA recent lawsuit challenged the human-authorship requirement in the context of works purportedly\n\u201cauthored\u201d by genai.\n\nIn June 2022, Stephen Thaler sued the Copyright Office for denying his application to", "**CRS Legal Sidebar**\n\n-----\n\nregister a visual artwork that he claims was authored \u201cautonomously\u201d by an genai program called the\nCreativity Machine.\n\nDr. Thaler argued that human authorship is not required by the Copyright Act.\n\nOn\nAugust 18, 2023, a federal district court granted summary judgment in favor of the Copyright Office.\n\nThe\ncourt held that \u201chuman authorship is an essential part of a valid copyright claim,\u201d reasoning that only\nhuman authors need copyright as an incentive to create works.\n\nDr. Thaler has stated that he plans to\nappeal the decision.\n\nAssuming that a copyrightable work requires a human author, works created by humans using generative\ngenai could still be entitled to copyright protection, depending on the nature of human involvement in the\ncreative process.\n\nHowever, a recent copyright proceeding and subsequent Copyright Registration\nGuidance indicate that the Copyright Office is unlikely to find the requisite human authorship where an\ngenai program generates works in response to text prompts.\n\nIn September 2022, Kris Kashtanova registered\na copyright for a graphic novel illustrated with images that Midjourney generated in response to text\ninputs.\n\nIn October 2022, the Copyright Office initiated cancellation proceedings, noting that Kashtanova\nhad not disclosed the use of genai.\n\nKashtanova responded by arguing that the images were made via \u201ca\ncreative, iterative process.\u201d On February 21, 2023, the Copyright Office determined that the images were\nnot copyrightable, deciding that Midjourney, rather than Kashtanova, authored the \u201cvisual material.\u201d In\nMarch 2023, the Copyright Office released guidance stating that, when genai \u201cdetermines the expressive\nelements of its output, the generated material is not the product of human authorship.\u201d\n\nSome commentators assert that some genai-generated works should receive copyright protection, arguing\nthat genai programs are like other tools that human beings have used to create copyrighted works.\n\nFor\nexample, the Supreme Court has held since the 1884 case _Burrow-Giles Lithographic Co. v. Sarony_ that\nphotographs can be entitled to copyright protection where the photographer makes decisions regarding\ncreative elements such as composition, arrangement, and lighting.\n\ngenai programs might be seen\nas a new tool analogous to the camera, as Kashtanova argued .\n\nOther commentators and the Copyright Office dispute the photography analogy and question whether genai\nusers exercise sufficient creative control for genai to be considered merely a tool.\n\nIn Kashtanova\u2019s case, the\nCopyright Office reasoned that Midjourney was not \u201ca tool that [] Kashtanova controlled and guided to\nreach [their] desired image\u201d because it \u201cgenerates images in an unpredictable way.\u201d The Copyright Office\ninstead compared the genai user to \u201ca client who hires an artist\u201d and gives that artist only \u201cgeneral\ndirections.\u201d The office\u2019s March 2023 guidance similarly claims that \u201cusers do not exercise ultimate\ncreative control over how [genai] systems interpret prompts and generate materials.\u201d One of\nKashtanova\u2019s lawyers, on the other hand, argues that the Copyright Act does not require such exacting\ncreative control, noting that certain photographs and modern art incorporate a degree of happenstance.\n\nSome commentators argue that the Copyright Act\u2019s distinction between copyrightable \u201cworks\u201d and\nnoncopyrightable \u201c ideas \u201d supplies another reason that copyright should not protect genai-generated works.\n\nOne law professor has suggested that the human user who enters a text prompt into an genai program\u2014for\ninstance, asking DALL-E \u201cto produce a painting of hedgehogs having a tea party on the beach\u201d\u2014has\n\u201ccontributed nothing more than an idea\u201d to the finished work.\n\nAccording to this argument , the output\nimage lacks a human author and cannot be copyrighted.\n\nWhile the Copyright Office\u2019s actions indicate that it may be challenging to obtain copyright protection for\ngenai-generated works, the issue remains unsettled.\n\nApplicants may file suit in U.S. district court to\nchallenge the Copyright Office\u2019s final decisions to refuse to register a copyright (as Dr. Thaler did), and it\nremains to be seen whether federal courts will agree with all of the office\u2019s decisions.\n\nWhile the\nCopyright Office notes that courts sometimes give weight to the office\u2019s experience and expertise in this\nfield, courts will not necessarily adopt the office\u2019s interpretations of the Copyright Act.\n\nIn addition, the Copyright Office\u2019s guidance accepts that works \u201c containing \u201d genai-generated material may\nbe copyrighted under some circumstances, such as \u201csufficiently creative\u201d human arrangements or\n\n\n-----\n\nmodifications of genai-generated material or works that combine genai-generated and human-authored material.", "The office states that the author may only claim copyright protection \u201cfor their own contributions\u201d to such\nworks, and they must identify and disclaim genai-generated parts of the work if they apply to register their\ncopyright.\n\nIn September 2023, for instance, the Copyright Office Review Board affirmed the office\u2019s\nrefusal to register a copyright for an artwork that was generated by Midjourney and then modified in\nvarious ways by the applicant, since the applicant did not disclaim the genai-generated material.", "### Who Owns the Copyright to genai Outputs?\n\nAssuming some genai-created works may be eligible for copyright protection, who owns that copyright?\n\nIn\ngeneral, the Copyright Act vests ownership \u201cinitially in the author or authors of the work.\u201d Given the lack\nof judicial or Copyright Office decisions recognizing copyright in genai-created works to date, however, no\nclear rule has emerged identifying who the \u201cauthor or authors\u201d of these works could be.\n\nReturning to the\nphotography analogy, the genai\u2019s creator might be compared to the camera maker, while the genai user who\nprompts the creation of a specific work might be compared to the photographer who uses that camera to\ncapture a specific image.\n\nOn this view, the genai user would be considered the author and, therefore, the\ninitial copyright owner.\n\nThe creative choices involved in coding and training the genai, on the other hand,\nmight give an genai\u2019s creator a stronger claim to some form of authorship than the manufacturer of a camera.\n\nCompanies that provide genai software may attempt to allocate the respective ownership rights of the\ncompany and its users via contract, such as the company\u2019s terms of service.\n\nOpenAI\u2019s Terms of Use , for\nexample, appear to assign any copyright to the user: \u201cOpenAI hereby assigns to you all its right, title and\ninterest in and to Output.\u201d A previous version, by contrast, purported to give OpenAI such rights.\n\nAs one\nscholar commented , OpenAI appears to \u201cbypass most copyright questions through contract.\u201d", "### Does the genai Training Process Infringe Copyright in Other Works?\n\ngenai systems are \u201ctrained\u201d to create literary, visual, and other artistic works by exposing the program to\nlarge amounts of data, which may include text, images, and other works downloaded from the internet.\n\nThis training process involves making digital copies of existing works.\n\nAs the U.S. Patent and Trademark\nOffice has described , this process \u201cwill almost by definition involve the reproduction of entire works or\nsubstantial portions thereof.\u201d OpenAI, for example, acknowledges that its programs are trained on \u201clarge,\npublicly available datasets that include copyrighted works\u201d and that this process \u201cinvolves first making\ncopies of the data to be analyzed\u201d (although it now offers an option to remove images from training future\nimage generation models).\n\nCreating such copies without permission may infringe the copyright holders\u2019\nexclusive right to make reproductions of their work.\n\ngenai companies may argue that their training processes constitute fair use and are therefore noninfringing.\n\nWhether or not copying constitutes fair use depends on four statutory factors under 17 U.S.C.\n\n\u00a7 107:\n\n\n1. the purpose and character of the use, including whether such use is of a commercial\n\nnature or is for nonprofit educational purposes;\n\n\n2. the nature of the copyrighted work;\n3. the amount and substantiality of the portion used in relation to the copyrighted work as a\n\nwhole; and\n\n\n-----\n\n4. the effect of the use upon the potential market for or value of the copyrighted work.\n\nSome stakeholders argue that the use of copyrighted works to train genai programs should be considered a\nfair use under these factors.\n\nRegarding the first factor, OpenAI argues its purpose is \u201ctransformative\u201d as\nopposed to \u201cexpressive\u201d because the training process creates \u201ca useful genai system.\u201d OpenAI\nalso contends that the third factor supports fair use because the copies are not made available to the public\nbut are used only to train the program.\n\nFor support, OpenAI cites _The_ _Authors Guild, Inc. v. Google, Inc._ ,\nin which the U.S. Court of Appeals for the Second Circuit held that Google\u2019s copying of entire books to\ncreate a searchable database that displayed excerpts of those books constituted fair use.\n\nRegarding the fourth fair use factor, some genai applications have raised concern that training genai\nprograms on copyrighted works allows them to generate similar works that compete with the originals.\n\nFor example, an genai-generated song called \u201c Heart on My Sleeve ,\u201d made to sound like the artists Drake and\nThe Weeknd, was heard millions of times on streaming services.\n\nUniversal Music Group, which has deals\nwith both artists, argues that genai companies violate copyright by using these artists\u2019 songs in training data.\n\nOpenAI states that its visual art program DALL-E 3 \u201cis designed to decline requests that ask for an image\nin the style of a living artist.\u201d\n\nPlaintiffs have filed multiple lawsuits claiming the training process for genai programs infringed their\ncopyrights in written and visual works.\n\nThese include lawsuits by the Authors Guild and authors Paul\nTremblay , Michael Chabon , Sarah Silverman , and others against OpenAI; separate lawsuits by Michael\nChabon , Sarah Silverman , and others against Meta Platforms; proposed class action lawsuits against\nAlphabet Inc. and Stability genai and Midjourney ; and a lawsuit by Getty Images against Stability genai.\n\nThe\nGetty Images lawsuit , for instance, alleges that \u201cStability genai has copied at least 12 million copyrighted\nimages from Getty Images\u2019 websites .\n\n.\n\n.\n\nin order to train its Stable Diffusion model.\u201d This lawsuit appears\nto dispute any characterization of fair use, arguing that Stable Diffusion is a commercial product,\nweighing against fair use under the first statutory factor, and that the program undermines the market for\nthe original works, weighing against fair use under the fourth factor.\n\nIn September 2023, a U.S. district court ruled that a jury trial would be needed to determine whether it\nwas fair use for an genai company to copy case summaries from Westlaw, a legal research platform, to train\nan genai program to quote pertinent passages from legal opinions in response to questions from a user.\n\nThe\ncourt found that, while the defendant\u2019s use was \u201c undoubtedly commercial ,\u201d a jury would need to resolve\nfactual disputes concerning whether the use was \u201c transformative \u201d (factor 1), to what extent the nature of\nthe plaintiff\u2019s work favored fair use (factor 2), whether the defendant copied more than needed to train the\ngenai program (factor 3), and whether the genai program would constitute a \u201c market substitute \u201d for Westlaw\n(factor 4).\n\nWhile the genai program at issue might not be considered \u201cgenerative\u201d genai, the same kinds of facts\nmight be relevant to a court\u2019s fair-use analysis of making copies to train genai models.", "### Do genai Outputs Infringe Copyrights in Other Works?\n\ngenai programs might also infringe copyright by generating outputs that resemble existing works.\n\nUnder\nU.S. case law, copyright owners may be able to show that such outputs infringe their copyrights if the genai\nprogram both (1) had access to their works and (2) created \u201csubstantially similar\u201d outputs.\n\nFirst, to establish copyright infringement, a plaintiff must prove the infringer \u201c actually copied \u201d the\nunderlying work.\n\nThis is sometimes proven circumstantially by evidence that the infringer \u201c had access to\nthe work .\u201d For genai outputs, access might be shown by evidence that the genai program was trained using the\nunderlying work.\n\nFor instance, the underlying work might be part of a publicly accessible internet site that\nwas downloaded or \u201cscraped\u201d to train the genai program.\n\nSecond, a plaintiff must prove the new work is \u201c substantially similar \u201d to the underlying work to establish\ninfringement.\n\nThe substantial similarity test is difficult to define and varies across U.S. courts.\n\nCourts\n\n\n-----\n\nhave variously described the test as requiring, for example, that the works have \u201ca substantially similar\ntotal concept and feel \u201d or \u201c overall look and feel \u201d or that \u201cthe ordinary reasonable person would fail to\ndifferentiate between the two works.\u201d Leading cases have also stated that this determination considers\nboth \u201c the qualitative and quantitative significance of the copied portion in relation to the plaintiff\u2019s work\nas a whole.\u201d For genai-generated outputs, no less than traditional works, the \u201csubstantial similarity\u201d analysis\nmay require courts to make these kinds of comparisons between the genai output and the underlying work.\n\nThere is significant disagreement as to how likely it is that genai programs will copy existing\nworks in their outputs.\n\nOpenAI argues that \u201c[w]ell-constructed genai systems generally do not regenerate, in\nany nontrivial portion, unaltered data from any particular work in their training corpus.\u201d Thus, OpenAI\nstates , infringement \u201cis an unlikely accidental outcome.\u201d By contrast, the Getty Images lawsuit alleges\nthat \u201cStable Diffusion at times produces images that are highly similar to and derivative of the Getty\nImages.\u201d One study has found \u201ca significant amount of copying\u201d in less than 2% of the images created by\nStable Diffusion, but the authors claimed that their methodology \u201clikely underestimates the true rate\u201d of\ncopying.\n\nTwo kinds of genai outputs may raise special concerns.\n\nFirst, some genai programs may be used to create works\ninvolving existing fictional characters.\n\nThese works may run a heightened risk of copyright infringement\ninsofar as characters sometimes enjoy copyright protection in and of themselves.\n\nSecond, some genai\nprograms may be prompted to create artistic or literary works \u201cin the style of\u201d a particular artist or author,\nalthough\u2014as noted above\u2014some genai programs may now be designed to \u201c decline \u201d such prompts.\n\nThese\noutputs are not necessarily infringing, as copyright law generally prohibits the copying of specific works\nrather than an artist\u2019s overall style.\n\nRegarding the genai-generated song \u201cHeart on My Sleeve,\u201d for instance,\none commentator notes that the imitation of Drake\u2019s voice appears not to violate copyright law, although\nit may raise concerns under state right-of-publicity laws .\n\nNevertheless, some artists are concerned that genai\nprograms are uniquely capable of mass-producing works that copy their style, potentially undercutting the\nvalue of their work.\n\nPlaintiffs in one lawsuit against Stable Diffusion, for example, claim that few human\nartists can successfully mimic another artist\u2019s style, whereas \u201cgenai Image Products do so with ease.\u201d\n\nA final question is who is (or should be) liable if genai outputs do infringe copyrights in existing\nworks.\n\nUnder current doctrines, both the genai user and the genai company could potentially be liable.\n\nFor\ninstance, even if a user were directly liable for infringement, the genai company could potentially face\nliability under the doctrine of \u201c vicarious infringement ,\u201d which applies to defendants who have \u201cthe right\nand ability to supervise the infringing activity\u201d and \u201ca direct financial interest in such activities.\u201d The\nlawsuit against Stable Diffusion, for instance, claims that the defendant genai companies are vicariously\nliable for copyright infringement.\n\nOne complication of genai programs is that the user might not be aware\nof\u2014or have access to\u2014a work that was copied in response to the user\u2019s prompt.\n\nUnder current law, this\nmay make it challenging to analyze whether the user is liable for copyright infringement.", "## Considerations for Congress\n\nCongress may consider whether any of the copyright law questions raised by genai programs\nrequire amendments to the Copyright Act or other legislation.\n\nCongress may, for example, consider\nlegislation clarifying whether genai-generated works are copyrightable, who should be considered the author\nof such works, or when the process of training genai programs constitutes fair use.\n\nGiven how\nlittle opportunity the courts and Copyright Office have had to address these issues, Congress may adopt a\nwait-and-see approach.\n\nAs the courts gain experience handling cases involving genai, they may be\nable to provide greater guidance and predictability in this area through judicial opinions.\n\nBased on the\noutcomes of these cases, Congress may reassess whether legislative action is needed.\n\n-----", "### Disclaimer\n\nThis document was prepared by the Congressional Research Service (CRS).\n\nCRS serves as nonpartisan shared staff\nto congressional committees and Members of Congress.\n\nIt operates solely at the behest of and under the direction of\nCongress.\n\nInformation in a CRS Report should not be relied upon for purposes other than public understanding of\ninformation that has been provided by CRS to Members of Congress in connection with CRS\u2019s institutional role.\n\nCRS Reports, as a work of the United States Government, are not subject to copyright protection in the United\nStates.\n\nAny CRS Report may be reproduced and distributed in its entirety without permission from CRS.\n\nHowever,\nas a CRS Report may include copyrighted images or material from a third party, you may need to obtain the\npermission of the copyright holder if you wish to copy or otherwise use copyrighted material.\n\n-----", "## STATE OF NEW JERSEY\n\nNO.\n\n: 23-OIT-007\n\nEFFECTIVE\nDATE:      IMMEDIATE\n\n\nORIGINATING AGENCIES **:**\n\n\nPAGE 1 OF 5\n\n\n\n-  OFFICE OF INFORMATION TECHNOLOGY (OIT)\n\n-  OFFICE OF HOMELAND SECURITY & PREPAREDNESS\n\n-  NJ CYBERSECURITY & COMMUNICATIONS\nINTEGRATION CELL (NJCCIC)\n\nEXPIRATION SUPERSEDES: N/A\n\nDATE:         INDEFINITE\n\n\nSUBJECT:  STATE OF NEW JERSEY INTERIM GUIDANCE ON RESPONSIBLE USE OF genai\n\nATTENTION: DIRECTORS OF ADMINISTRATION, CHIEF INFORMATION OFFICERS, AGENCY IT MANAGERS, AND AGENCY\nCHIEFS OF STAFF\n\n\nAPPLIES TO:\n\n\nFULL TIME, PART TIME AND STAFF\nAUGMENTATION IT/TECHNOLOGY STAFF\nAND BUSINESS STAFF SUPPORTING\nAPPLICATIONS AND WEB-PRESENCE\nFOR STATE AGENCIES\n\n\nFOR QUESTIONS:         SEND QUESTIONS TO:", "**I.\n\n** **PURPOSE**\n\nA. genai refers to a new set of technologies that utilize machine learning techniques to\n\ngenerate content in response to user inputs.\n\nThe content produced can be textual (e.g.\n\nChatGPT,\nBedrock, or Bard), visual (e.g.\n\nDALL-E, Canva or MidJourney), spoken (e.g.\n\nElevenLabsM4T,\nPolly/LEX) or even musical (e.g.\n\nMusicLM or Amadeus Code).\n\nB.\n\nThese new tools have the potential to be extraordinarily useful to public servants in your work, but\n\nthey also present risks.\n\nTherefore, these guidelines serve as an interim resource for employees of\nthe State of New Jersey to encourage responsible use of these emerging technologies.\n\nC. genai is a tool, not actual intelligence.\n\nWe remain responsible for the outcomes and uses\n\nof these tools.\n\nTechnology enables our work but does not excuse our judgment.\n\nD. As we explore the responsible use of genai, we embrace the following principles to\n\nguide our efforts.\n\nThese shared values of empowerment, inclusion, transparency, innovation, and\nrisk management will steer our experimentation and decision-making when employing these\nrapidly evolving technologies.\n\nE. With this Circular, we aim to build trust, spur progress, and ensure genai serves the public good.", "**II.\n\n** **POLICY**\n\nA.\n\nGENERAL\n\n1 **Empowerment** The use of genai should support our workforce to deliver enhanced services and\n\n\n-----\n\nAs public stewards, we will use tools respectfully to reflect values of equity and social justice.\n\n3.\n\n**Transparency and Accountability.\n\n** We acknowledge the limits of foresight.\n\nBut transparency\n\nbuilds trust and enables collective learning.\n\nWhen genai is used, we must disclose that\nresponsibly and share our workflow freely with other public servants and with the public.\n\n4.\n\n**Innovation and Risk Management.\n\n** We embrace responsible experimentation that maintains\n\ncontrol and respects privacy and security while developing uses that drive efficiency, dialogue,\nand better service.\n\nWe understand risks may not be fully apparent initially and commit to\nproactive risk assessment.\n\nB.\n\nUSE GUIDELINES\n\n1.\n\n**Ask - Early and Often.\n\n** genai creates content based on your inputs.\n\nThat is why it is\n\ngood to try out different questions (also known as \u201cprompts\u201d) to see how it responds.\n\nYou can\nspecify the tone, style, and length of a text response and the attributes and qualities of an\nimage.\n\nThe more you experiment with different ways of steering the tools, the faster you will\nlearn how to instruct them to yield the best results.\n\n2.\n\n**Fact Check.\n\n** Verify all genai-generated content, especially for public use.\n\ngenai can swiftly\n\nproduce clear prose, but the information may be inaccurate or outdated.\n\nResearch claims to\nensure accuracy.\n\nWatch for: incorrect facts, events, links, or references; and biased information\npotentially harmful to vulnerable groups like racial, ethnic, and gender minorities, people with\ndisabilities, etc.\n\nWe must actively mitigate risks from genai while benefiting from its capabilities.\n\nAs\npublic stewards, we have an obligation to use these tools responsibly.\n\nSignoff from Agency\nDirector level or Asst Commissioner is required before production use.\n\n3.\n\n**Disclose.\n\n** Label content created with genai to that effect.\n\nTransparency is crucial in genai-\n\ngenerated content, even when genai is used sparingly.\n\nDisclosing genai involvement fosters trust and\naids in error identification.\n\nDetail the genai model, prompts, and methods employed.\n\nThis\ndocumentation aids comprehension and safe usage by colleagues and stakeholders.\n\nSample genai-generated content disclosures:\n\n\"This content was generated with the aid of ChatGPT and subsequently revised by Bob\nSmith.\"\n\n\"This text was summarized for clarity using Google Bard.\"\n\n4.\n\n**Sensitive Information.\n\n** When prompting the genai or using genai models, do not disclose sensitive\n\nor private information.\n\nWe aim to enable responsible genai use while safeguarding sensitive\ninformation.\n\na) Do not share personally identifiable information (PII) about residents, colleagues, or\n\nyourself.\n\nDo not share confidential or sensitive content.\n\nb) Do not use genai tools to transcribe or summarize meetings where sensitive topics are\n\ndiscussed.\n\nc) Do not share any information that you wouldn\u2019t share publicly.", "**III.\n\n** **PROCEDURES**\n\nA.\n\nHOW TO\u2019S\n\n1.\n\n**Drafting** .\n\ngenai like ChatGPT can help draft **memos** , **letters** , and **job descriptions** .\n\nWhen creating prompts, specify any format preferences, keywords, technical terms, or\nphrases to include or avoid.\n\nRemember, you can tell the software how long you would like the\nresponse to be (e.g.\n\nthe word count), the style (e.g.\n\nprofessional or informal), the language\n(e.g.\n\nplease respond in Spanish).\n\n-----\n\n```\nWrite a 250 word memo to a state agency head about the potential\nbenefits of the use of genai in state government.\n\nPlease\nsupport the memo with evidence.\n\nThe tone should be professional, and\nthe text should be formatted as a memo.\n\n```\nSuggested:\n\n-  Try to be specific in the prompt.\n\nIf you give more context, the answer becomes more\nrelevant.\n\n-  Try different prompts to see how the responses improve.\n\n-  Edit and review the content carefully.\n\nSeek & use genai Quality Assurance best practices.\n\n-  Fact check.\n\nDo Not:\n\n-  Do not rely on genai to provide accurate answers.\n\n-  Do not use genai to create communication regarding sensitive topics.\n\nFor\ninstance, a renowned institution was criticized for using genai to write a press\nrelease regarding a shooting.\n\n-  Do not use content without carefully editing.\n\n2.\n\n**Communicating with the Public** genai can help you write clearly and in plain,\n\naccessible language.\n\nYou can use the prompt to indicate the reading level or audience for a\ntext.\n\n**Example** : Use Anthropic\u2019s Claude to upload the text of a website or policy and ask the genai to\nhelp you simplify the language and make it more accessible, concise and easy-to-understand.\n\n```\n  Help me to rewrite the text of this page in simple English accessible\n  to a ten-year old.\n\nWhile you may streamline the language for clarity,\n  please do not eliminate any directions.\n\n```\nSuggested:\n\n-  Specify in the prompt if you have a specific audience in mind.\n\n-  Try different prompts or verbiage of the same sentence to find what works best.\n\n-  You can pass the output of the text by using a readability app that can identity challenging\nsentences, as well as the reading level for the text.\n\n-  Review the text to ensure that the language is inclusive and respectful.\n\nThe models might\nuse language or patterns that appear regularly, but that might exclude some people.\n\nFor\ninstance, a model might suggest: \u201cDear Sir/Ma'am\u201d does not include non-binary people\nand could be replaced with \u201cDear Colleague\u201d or \u201cDear Neighbor\u201d.\n\nDo Not:\n\n-  Do not include confidential information in a prompt.\n\n3.\n\n**Translation.\n\n** genai can help you translate content into other languages.\n\nFacebook\n\nReseearch claims it\u2019s free, open source Seamless M4T tool can translate text or speech from 100\nlanguages into 35 languages.\n\n**Example:** Use M4T, ChatGPT or Google Bard to translate instructions for applying for a\ngovernment benefit into the most popular non-English languages.\n\nSuggested:\n\n-  Ask a native speaker to review.\n\n-  Try different languages to test the quality of the translation\n\n\n-----\n\nwith proficiency in the language.\n\nYou still need to check for accuracy, bias, etc.\n\n-  Note that text generated in other languages might be confusing to people who speak different\nregional dialects.\n\nDo not assume that some text will be easily understood by all speakers.\n\nBe\nspecific in your prompt and ask for regional idioms.\n\n4.\n\n**Summarization** .\n\ngenai can summarize longer text or speech into the desired length.\n\nYou can use it to summarize lengthy documents for clarity or brevity when required.\n\nMany\ncitizen engagement platforms now make it possible to summarize and organize citizen\ncomments.\n\n```\n  Please write a 100-word summary of this report, highlighting the\n  most important recommendations.\n\nUse bullet points.\n\n```\nSuggested:\n\n-  Remember that summaries and transcripts are subject to OPRA\n\n-  If you plan on making a decision based on the summary, you should read the entire\ndocument(s) to make sure you did not miss or mischaracterized the original document.\n\n-  Be aware that the resulting summary might have biases as it will tend to present language\nthat is more frequent in the data used to train the model.\n\nYou can use changes to the\nprompt to enhance the results by suggesting that the result incorporates perspectives\nfrom marginalized groups.\n\nEven better, you can engage with some individuals in these\ncommunities to better understand their perspectives on the text generated.\n\nDo Not:\n\n-  Do not include confidential information in the prompt: make sure you have deleted\nconfidential information from your notes or other inputs.\n\n-  Do use automated transcription in meetings where confidential or personally identifiable\ninformation is discussed.\n\n5.\n\n**Data Analysis.\n\n** Utilizing a code interpreter with genai empowers individuals with\n\nlimited coding experience to engage in data analysis tasks.", "5.\n\n**Data Analysis.\n\n** Utilizing a code interpreter with genai empowers individuals with\n\nlimited coding experience to engage in data analysis tasks.\n\nThis is particularly beneficial for\nthose who are less technically inclined, including interns and student workers, enabling them\nto effectively contribute to technical projects.\n\nFor instance, OpenAI\u2019s Code Interpreter can be\nemployed to interact with datasets through inquiries.\n\nFeel free to experiment with various\nprogramming languages and libraries.\n\nHowever, ensure that you grasp the code's logic and\nthoroughly go through the relevant component documentation before application.\n\nGenerative\ngenai serves as an initial aid, but it might be necessary to adjust the generated code for optimal\nresults.\n\nExample: `\u201cHello Code Interpreter, I have collected a bunch of survey`\n```\n  forms in PDF format.\n\nThese forms contain valuable information, but\n  it's a pain to go through them manually.\n\nI am looking to extract the\n  participant comments and their locations from these PDFs and create\n  a spreadsheet for easier review.\n\nCould you help me generate some\n  Python code using libraries like 'PyPDF2' and 'Pandas' to extract\n  this data and organize it into a neat CSV file?\n\nIt would be a huge\n  time-saver!\n\nThanks!\"\n\n```\nSuggested:\n\n\n-----\n\nDo Not:\n\n-  Avoid inserting sensitive information in prompts.\n\nFollowing development best practices,\nabstain from including confidential data like passwords, private keys, or proprietary details\neither in your code or the prompts.\n\n-  Refrain from utilizing code in a production setting without a comprehensive understanding\nof its operations.\n\n-  Ensure you are well-acquainted with novel libraries and dependencies.\n\nFamiliarize\nyourself with potential vulnerabilities and security aspects related to the chosen language\nor library.\n\n6.\n\n**Generating Images, Audio and Video.\n\n** genai enables the creation of images, audio,\n\nand videos based on prompts, offering support in crafting captivating and insightful\ncommunication resources.\n\nTools like Mid-Journey and DALL-E generate images.\n\nCANVA is\na popular tool for automating the creation of slides.\n\nThe Music plugin available from ChatGPT,\nAmadeus Code and Amper Music are examples of music generators.\n\n```\n  Write me a jingle or song to remind residents to enroll in\n  GetCoveredNJ.\n\nGenerate a training video illustrating how to schedule bulky item\n  pickups, leveraging a provided script.\n\n```\nSuggested:\n\n-  Recognize the potency of visual, audio, and video communication in conveying messages.\n\nUse genai to harness these tools, extending your artistic abilities.\n\n-  Employ genai to draft mock-ups that facilitate effective communication with\ngraphic designers, videographers, and other creative professionals.\n\n-  Collaborate with your department's public information officer when using or publishing\nimages, audio, or videos.\n\nTheir expertise ensures adherence to accessibility and branding\nbest practices.\n\n-  Engage with Cabinet members or counsel; Respectfully seeking their insights helps\nidentify potentially hurtful, discriminatory, or misconstrued content.\n\nDo Not:\n\n-  Include confidential information in prompts; Rather, ensure any sensitive data is removed\nfrom notes or inputs.\n\nThis includes faces, voices, identifications, and license plates of\nindividuals who haven't granted consent.\n\n-  Assume that the outputs of genai are respectful and non-offensive, especially to\nvulnerable residents like diverse ethnic, racial, and gender groups; Test and validate.\n\n-  Ensure all content aligns with the OIT and Governor\u2019s Office Web Presence Guidelines to\nmaintain visual consistency and compliance.\n\n_Christopher Rein, CTO_ _Michael Geraghty, CISO_\n\n_Office of Information Technology_ _Office of Homeland Security & Preparedness_\n\n\n-----", "## Federal Policies\n\nWhile there have been no federal policies related to the\nuse of genai technologies in education, at the release of this\nresource, in March 2023, the U.S.\n\nCopyright Office,\nLibrary of Congress, released a policy that has impacts\non the use of works containing material generated by\ngenai.\n\nThe full text of this policy can be\nreviewed here .\n\n1\n\nThe US Office of Educational Technology published a\nbrief in May 2023 titled \u201c genai and the\nFuture of Teaching and Learning .\u201d This brief provides\ninsights and recommendations regarding building\nethical, equitable policies in addition to information\nabout the use of genai in teaching, best practices for\ninstruction including formative assessment, and research\naround the use of genai in classrooms and beyond.\n\nThis\nbrief along with additional work supported by the US\nOffice of Educational Technology supports a focus on the\neffective, safe, and fair use of genai-enabled educational\ntechnology.\n\nTheir genai website can\nprovide a great starting point for understanding current\npolicies in this area.\n\nPrior to setting school and district policies on the use of\ngenai technologies, it is vital that school and district leaders\nare aware of federal and state policies that impact the\nuse of these technologies both regarding student data\nprivacy in addition to other states and countries that\nlead in this area.\n\nWhile there are a number of schools\nacross the nation (and world) that have made the\ndecision to ban the use of genai technologies and ChatGPT,\nwhen making this decision it is important to consider the\nlearning opportunities that might be limited for students.\n\nBeing aware of other policies both within and outside of\nOregon can be helpful in making informed decisions.\n\nThe\nUS Office of Educational Technology is currently working\non developing policies and supports that focus on the\neffective, safe, and fair use of genai-enabled educational\ntechnology.\n\nTheir genai website can\nprovide a great starting point for understanding current\npolicies in this area.\n\nAdditionally, with the increased\ninterest in, and attention on genai technology, other\ncountries have developed resources to guide in the\nuse of genai in education.\n\nFor example, The European\nCommission recently released \u201c Ethical guidelines on the\nuse of genai (genai) and data in teaching and\nlearning for Educators \u201d which provides guidance and\nresources for school leaders.\n\nIf additional related federal policies are developed, this section of the guidance will be updated to reflect the most current policies\navailable.\n\n-----", "### Policies from Across the Nation\n\nAs K-12 schools and districts spend more time learning\nabout the use of genai in classrooms, policies\ncontinue to change at a rapid pace with districts that\ninitially banned platforms such as ChatGPT shifting\ntoward embracing its potential in the classroom 2 .\n\nWhile\nsome schools, districts, and states have continued their\nban on genai, particularly platforms such as\nChatGPT, many have done so as a temporary measure in\norder to engage in risk assessments and develop plans to\ntrain educators.\n\n3\n\nAn example that can provide a starting point for\nschools and districts in developing their genai policies\nand procedures can be drawn from the International\nBaccalaureate.\n\nThey have developed a \u201c Statement\nfrom the IB about ChatGPT and genai\nin assessment and education .\u201d This statement calls\nfor developing policy that supports students in using\ngenai tools in ways that are ethical and aligned\nwith principles of academic integrity.", "### International Policies\n\nThe United Nations developed a resource \u201c genai and\nEducation: Guidance for Policy-Makers \u201d that provides\nimportant information regarding other countries'\npolicies related to the use of genai in schools.\n\nWhile this\nresource focuses on the use of genai broadly rather than\ngenai specifically, it includes important\nconsiderations for policy development and provides\nlanguage from other countries' policies that can be\nuseful.", "### genai Policy and Protocol Development Planning and Reflection Tool 4\n\nBased on the information in this resource, there\nare several action steps that school and district\nadministrators can take in an effort to create clear,\nmeaningful, and equitable policy around the use of genai\ntechnologies in classrooms.\n\nThe table below can serve\nas a starting point for reflection, discussion, and policy\ndevelopment.", "### Oregon District Policies\n\nMany Oregon districts are still exploring the use of\ngenai platforms such as ChatGPT in their\nclassrooms.\n\nSchools and districts are encouraged to\ncontact the Oregon Department of Education when\ndeveloping policy related to genai technologies for both\ntechnical support as well as opportunities to connect\nwith other districts in order to learn from each other.\n\nPlease contact ODE\u2019s Digital Learning Team ( ode.\n )\n\nwith questions, current\npolicies, and technical support needs.\n\n2 Banks, D. (2023).\n\nChatGPT caught NYC schools off guard.\n\nNow, we\u2019re determined to embrace its potential.\n\nRetrieved from: \n\n3 Jimenez, K. (2023).\n\n'This shouldn\u2019t be a surprise' The education community shares mixed reactions to ChatGPT.\n\nRetrieved\n from:\n\n4 Additional information regarding developing genai policy can be found in genai Policy in Secondary Schools .\n\n-----\n\n|Focus|Guiding Questoi ns5|Tasks|\n|---|---|---|\n|1.\n\nReview Equity Decision Tree and specifci equity focused genai questoi ns|What are the equity implicatoi ns of genai being used in schools?\n\nHow are these equity implicatoi ns being addressed through policy, partci ularly for historically and systemically marginalized student groups6?\n\nTo what extent is genai enabling adaptatoi n to students\u2019 strengths and not just defci its?\n\nIs genai enabling improved support for learners with disabilitei s and English language learners?|Organize a team to lead in the development of genai policy with a variety of roles, perspectvi es, and experiences (including librarians, library staf,f media specialists, and IT staff).\n\n(Depending on the size of the school or district, consider partnering with other schools or districts across the state in order to engage collaboratvi ely with this process.)\n\nConsult the Equity Decision Tools for School Leaders with the team prior to beginning the process of developing policy and throughout each step indicated below.\n\nSuggested startni g place: Decision Tree and Deepening Questoi ns \u2013 What is the problem?\n\nWhat are the interior conditoi ns?\n\nClearly defni e your vision for learning and how educatoi nal technology broadly and genai specifci ally might align with that vision.\n\nContni ue to refer to this to ensure alignment between your vision and the policies being developed.|\n|2.\n\nEngage District and School Community|How might genai spark dialog around broader media/ digital/ algorithmic literacies that will contni ue to impact students\u2019 lives?\n\nHow are opportunitei s for educators to share their experiences related to the equity implicatoi ns of genai being created when developing policy and revisitni g policy?\n\nHow are student, family, and the larger communitei s voices being centered in developing genai policy, specifci ally regarding equity implicatoi ns for multliingual students and students with disabilitei s?\n\nHow are youth voices involved in choosing and using genai for learning?|Review the \u201cCommunity Engagement Toolkit.\u201d Review the \u201cTribal Consultatoi n Toolkit\u201d Provide teaching and learning sessions to community members about the use of genai programs in schools including both opportunitei s and concerns/risks.\n\nSchools and districts are encouraged to use the above tools as a startni g point for these sessions.\n\nConsult with community partners, including teachers, parents, and students, and the Tribes to ensure that policy decisions are informed by a diverse range of perspectvi es.\n\nConsult with the school board to share perspectvi es learned during community engagement.\n\nConsult the Equity Decision Tools for School Leaders.\n\nSuggested focus: Deepening Questoi n \u2013 Does your decision deepen a sense of community and relatoi nal trust?|\n\n\nThese questions were modified from questions included in COSN (2020).\n\ngenai in K-12 as well as The Office of Educational Technology (2023) genai\nand the Future of Teaching and Learning.\n\nRetrieved from: \nfiles/2023/05/genai-future-of-teaching-and-learning-report.pdf\n\ngenai technologies are used across agencies and systems with research showing that the use of genai has negatively impacted people from historically and systemically marginalized\ncommunities.\n\nExamples of such research can be found in Ruha Benjamin\u2019s (2019) book Race After Technology: Abolitionist Tools for the New Jim Code as well as in the ProPublica\narticle \u201c Machine Bias \u201d.\n\n-----\n\n|Focus|Guiding Questoi ns5|Tasks|\n|---|---|---|\n|3.\n\nReview Products and Services|How does genai fti within the broader digital learning ecosystem?\n\nHow can IT staf fserve as leaders in these conversatoi ns and review design?\n\nHow strong are the processes or systems for monitoring student use of genai for barriers, bias, or other undesirable consequences of genai use by learners?\n\nHow are emergent issues addressed?|Consult the Equity Decision Tools for School Leaders.\n\nSuggested focus: Review Equity Decision tree discussion (step #1) and revise as needed based on fni dings from community engagement.", "Suggested focus: Review Equity Decision tree discussion (step #1) and revise as needed based on fni dings from community engagement.\n\nConduct a thorough review of any genai products or services before introducing them into the classroom, paying partci ular atet ntoi n to their potentai l impact on equity and student data privacy.\n\nReview the Office of Educatoi nal Technology\u2019s EdTech Evidence Toolkit to ensure that you are making evidence-based decisions on the use of educatoi nal technologies (edtech) in schools.\n\nConsider developing a tool for evaluatoi n by building of fof tools such as EdTech Center\u2019s Online/Tech Tool Evaluatoi n as a startni g point for review.\n\nEnsure that student data privacy is central to conversatoi ns by reviewing aligned policies including Family Educatoi nal Rights & Privacy Act (FERPA), the Children\u2019s Internet Privacy Act (CIPA), the Children\u2019s Online Privacy and Protectoi n Act (COPPA) and the Oregon Student Informatoi n Protectoi n Act (OSIPA.|\n|4.\n\nEstablish Clear Guidelines/ Develop Policy|How can guidelines for genai be developed in alignment within a broader system of educatoi nal technology?\n\nWhen genai is used, are students\u2019 privacy and data protected?\n\nAre students and their guardians informed about what happens with their data?\n\nIs high-quality research or evaluatoi ns about the impacts of using the genai system for student learning available?\n\nDo we know not only whether the system works but for whom and under what conditoi ns?|Consult the Equity Decision Tools for School Leaders.\n\nSuggested focus: Deepening Questoi n \u2013 Are your solutoi ns feasible?\n\nEstablish clear guidelines around the use of genai technologies, including when and how it should be used, and what data will be collected.\n\nConsider a preliminary step of providing educators access to ChatGPT while a broader policy is being formulated.\n\nConsider expanding the current acceptable use policy in order to include policies for both staf fuse and student use that take into account both opportunitei s and risks with using genai.\n\nEnsure that the student policy prioritzi es student data privacy laws.\n\nShare policy with the school board for approval.\n\nProvide ongoing support to the school board about the use of ChatGPT and other genai technologies.|\n\n\n-----\n\n|Focus|Guiding Questoi ns5|Tasks|\n|---|---|---|\n|5.\n\nCreate a Professional Development Plan|How can genai literacy be incorporated as a component of broader literacy and equity training so that it does not become \u201cjust another thing\u201d or \u201csomeone else\u2019s topic\u201d to teach?\n\nHow can librarians, library staf,f and media specialists serve as leaders in this work?\n\nHow are educators, students, and families being trained in digital literacy to ensure that they have the skills necessary to ethically and productvi ely navigate and use genai technologies?|Consult the Equity Decision Tools for School Leaders.\n\nSuggested focus: Deepening Questoi n \u2013 Who are the decision-makers and designers?\n\nReview the Office of Educatoi nal Technology\u2019s Artfi ci ial Intelligence and the Future of Teaching and Learning guidance to get support on how to practci e ACE (always center educators) in genai (pp.\n\n25-36).\n\nConsider the various audiences needing training including IT personnel, classroom teachers, librarians and library staf,f media specialists, school staf,f families, and students.\n\nCreate a professional development calendar with focused topics for each group.\n\nProvide training and support for educators, students, and families around the use of genai technologies, including how to use it efef ctvi ely and responsibly, and how to mitgi ate any potentai l negatvi e impacts.\n\nEnsure that educator training is grounded in research based approaches for technology integratoi n. Liz Kolb\u2019s Triple E Framework can be a helpful guide in ensuring that technology generally and genai specifci ally is used intentoi nally in the classroom.|\n|6.\n\nImplement and Monitor Policy to Determine Efef ctvi eness|How can voices of educators and the larger school community contni ue to be central to the process of implementatoi n and monitoring of genai products and services in schools?\n\nIs genai leading to narrower student actvi itei s (e.g., procedural math problems), or the fuller range of actvi itei s highlighted in the Natoi nal Educatoi nal Technology Plan (NETP), which emphasizes features such as personalized learning, project-based learning, learning from visualizatoi ns, simulatoi ns, and virtual reality, as well as learning across school, community, and familial settings?\n\nIs genai supportni g the whole learner, including social dimensions of learning such as enabling students to be actvi e partci ipants in small group and collaboratvi e learning?\n\nFor example, does genai contribute to aspects of student collaboratoi n we value like shared atet ntoi n, mutual engagement, peer help, self-regulatoi n, and building on each other\u2019s contributoi ns?|Consult the Equity Decision Tools for School Leaders.", "Suggested focus: Deepening Questoi n \u2013 How are you implementni g this decision?\n\nWhat are you learning along the way?\n\nImplement the policy with fdi elity - it might be helpful to start with one school or grade level band before rolling out district wide.\n\nMonitor the implementatoi n of genai technologies in classrooms closely, and be prepared to make adjustments if any negatvi e impacts on equity or other concerns arise.\n\nDevelop accountability measures to ensure that the technology is implemented in appropriate ways that align with the educator professional development and community training provided \u2013 adjust learning opportunitei s as needed.\n\nConsider ways in which to review the efef ctvi eness of the policy by engaging with local parent teacher organizatoi ns (or other similar organizatoi ns) regarding the use of the technology outside of the classroom.\n\nReview the genai policy with your team on a consistent basis to ensure that the policy responds to the pace of change within the fei ld.|\n\n\n_For more information, please contact ODE\u2019s Digital Learning Team at ._\n\n\n-----", "**7 September 2023**\n\n-----\n\n**2** | G7 HIROSHIMA PROCESS ON genai (genai)\n\nG7 leaders identified topics for discussion in the Hiroshima process and called for an early stock taking of\nopportunities and challenges related to genai.\n\nThis report presents the results of a questionnaire\ndeveloped to support the stocktaking to help guide G7 discussions on common policy priorities with regard to\ngenai.\n\nIt also provides a brief overview of the development of genai over time and across\ncountries.\n\nThe report and questionnaire results should be understood as representing a snapshot in time: they\nare indicative of trends identified in summer 2023 in a rapidly evolving area of technology.\n\nThe report helped\ninform and structure discussions of the G7 Hiroshima genai Process.\n\nThis document was prepared by the Organisation for Economic Co-operation and Development (OECD)\nDirectorate for Science Technology and Innovation (STI) for the 2023 Japanese G7 Presidency and the G7\nDigital and Tech Working Group, to inform discussions during the G7 Hiroshima genai\nProcess and the related interim virtual Ministers' Meeting on genai on 7 September\n2023.\n\nThe opinions expressed and arguments employed herein do not necessarily reflect the official views of\nthe member countries of the OECD or the G7.\n\nThis work is published under the responsibility of the Secretary-General of the OECD.\n\nThis document, as well as any data and map included herein, are without prejudice to the status of or\nsovereignty over any territory, to the delimitation of international frontiers and boundaries and to the name of\nany territory, city or area.\n\nCover image: \u00a9TippaPatt/Shutterstock.\n\n\u00a9 OECD 2023\n\nThe use of this work, whether digital or print, is governed by the Terms and Conditions to be found at\n .\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **3**", "**Growth in genai research, including its open-source code development, preceded the surge in**\n\n**investments.\n\n**\n\nThe widespread awareness and rapid uptake of genai have been enabled by steady, incremental\nprogress in both research and code development.\n\nFundamental innovations such as the \u2018Transformers\u2019\narchitectures, contributions of the open-source community, alongside improvement in computing power have\npaved the way for the proliferation of large language models as well as other type of genai models.\n\nScientific publications and open-source code development on genai have grown remarkably since\n2017, and this trend accelerated in 2023.\n\nVenture capital investments in genai have skyrocketed and\nwere estimated at USD 12 billion globally in the first half of 2023 alone.\n\nScientific publications and software,\nincluding open-source code, related to genai have seen a parallel remarkable surge since 2017, with\nthis trend further accelerating in 2023.", "**Rapid advances in genai are driven by its expected potential to drive productivity gains and to**\n\n**promote innovation and entrepreneurship, as well as to unlock solutions to global challenges** .\n\nIn a questionnaire administered in Q3 2023, G7 members unanimously saw productivity gains, promoting\ninnovation and entrepreneurship and unlocking solutions to global challenges, as some of the greatest\nopportunities of genai technologies worldwide, including for emerging and developing economies.\n\nG7 members\nalso emphasised genai\u2019s potential role to help address pressing societal challenges, such as improving\nhealthcare and helping to solve the climate crisis, and to support progress towards achieving the Sustainable\nDevelopment Goals (SDGs).", "**Yet, genai\u2019s potential benefits come with risks.\n\n**\n\nThe capacity of genai to exacerbate the challenges of disinformation and manipulation of opinions is\nconsidered by G7 members as one of the major threats stemming from genai, alongside risks of\nintellectual property rights infringement and privacy breaches.\n\nEarly efforts to track genai incidents found one\nthousand distinct incidents and hazards related to genai, based on roughly 5 600 news articles dated\nfrom January to July 2023.", "**As these risks evolve rapidly, their management and mitigation is at the top of the agenda for G7**\n\n**governments.\n\n**\n\nResponsible use of genai, addressing disinformation, safeguarding intellectual property rights, and\ngoverning genai are among the top priorities for G7 policymakers and require international cooperation\nwith like-minded partners.\n\nOther urgent and important issues emphasised by G7 members include privacy and\ndata governance, transparency, fairness and bias, human and fundamental rights, security and robustness of genai\nsystems, and impacts on the functioning of democracy.", "**G7 jurisdictions are evaluating their respective responses to genai, as well as the policy gaps.\n\n**\n\nCountries are leveraging existing and forthcoming legal and policy frameworks and developing guidelines or\nregulation to address risks related to genai.\n\nNational initiatives are also being strengthened to seize its\nopportunities.\n\nNew issues raised by genai appear to affect specific sectors in particular, such as\neducation, media, and the workplace.", "**G7 members are aligned on the need to provide effective tools for safety, quality control, and capacity**\n\n**and trust building for genai.\n\n**\n\n\u00a9 OECD 2023\n\n\n-----\n\n**4** | G7 HIROSHIMA PROCESS ON genai (genai)\n\nSafety, quality control, capacity and trust building for genai were seen as among the most urgent and\nimportant international action the G7 could undertake.\n\nEngaging in dialogue was also considered to be most\n_urgent_ , and developing voluntary codes of conduct was identified as among the most _important_ actions.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **5**", "#### 1.1.\n\nG ENERATIVE genai TRENDS\n\ngenai has taken centre stage in the public, academic, and political discussions surrounding genai.\n\nIt is\npredicted to create significant economic value.\n\nCompanies have begun to adopt the technology to create new\nbusiness opportunities, and start-ups are competing for venture capital.\n\ngenai has entered into public awareness and is increasingly present in everyday conversations\nworldwide, as evidenced by the surge in related news articles and tweets.\n\nBoth indicators show an eight-fold\nincrease in a mere six-month period, with new articles on genai increasing from 1.6 thousand in the\nlast quarter of 2022 to almost 14 thousand in the second quarter of 2023, and tweets about genai\nreaching 57 thousand in March 2023, up from an initial 7 thousand in October 2022 ( **F** **IGURE** 1.1, panels a\nand b, respectively).", "**F** **IGURE** 1.1.\n\n**G** **ENERATIVE** **genai** **HAS RAPIDLY ENTERED PUBLIC DISCOURSE**\n\na) Number of news articles globally on genai and related topics\n\n\u00a9 OECD 2023\n\n\n-----\n\n**8** | G7 HIROSHIMA PROCESS ON genai (genai)\n\nb) Number of tweets globally on genai and related topics\n\nNote: News articles related to genai are a subset of genai-related articles that include the following wikidata\nconcepts and all of their descendants: genai, transformer models, language model, and generative model.\n\ngenai tweets contain \u201cgenai\u201d or #generativeAI.\n\nNews articles data has been adjusted using a\ntechnique called quarterly smoothing to make it easier to compare and understand the trends over time.\n\nSource: OECD.genai, using data from Event Registry for news articles and from X for tweets.\n\nResearch and venture capital investments into genai development have also seen substantial increase.\n\nScientific publications pertaining to genai have grown fivefold since 2019, which can be attributed to\nheightened interest in fundamental innovations such as transformer models and advancements in computing\npower, and which paved the way for the proliferation of large language models (Figure 1.2, panel a).\n\nVenture\ncapital investments in genai in the first half of 2023 reached a total of USD 12 billion globally\n(Figure 1.2, panel b).\n\nPeaks in venture capital investments in 2019 and 2023 reflect Microsoft\u2019s USD 1 billion\nand USD 10 billion investments in OpenAI, respectively.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **9**", "**F** **IGURE** 1.2.\n\n**T** **HE GROWTH OF GENERATIVE** **genai** **RESEARCH PRECEDES THE SURGE IN INVESTMENTS**\n\na) Number of scientific publications globally on genai and related topics\n\nb) Sum of global venture capital investments on genai startups\n\nNote: Scientific publications related to genai are a subset of genai-related publications that include the\nfollowing wikidata concepts and all of their descendants: genai, transformer models, language model, and\ngenerative model.\n\nVC investments related to genai capture startups that include concepts like genai,\ngenerative adversarial network, text generation, image generation, audio generation, and generative model in their\ncompany descriptions.\n\nQuarterly data smoothing is applied to both datasets to remove noise.\n\nSource: OECD.genai, using data from OpenAlex for research publications and from Preqin for venture capital\ninvestments.\n\n\u00a9 OECD 2023\n\n\n-----\n\n**10** | G7 HIROSHIMA PROCESS ON genai (genai)\n\nThe open-source community has traditionally been a driving force behind genai advancements.\n\nThis trend appears\nto continue in the context of genai.\n\nSince October 2022, there has been a significant increase in the\navailability and development of open-source genai models dedicated to genai systems, as shown by the\nrising number of text generation models uploaded to the Hugging Face repository in the recent months\n(Figure 1.3, panel a).\n\nIn contrast, the upswing in open-source code development pertaining to genai\non GitHub starts in 2017 and follows a more gradual trajectory.\n\nThis nuanced pattern suggests that the progress\nleading to genai has been the result of steady and incremental advancements in code development\n(Figure 1.3, panel b).", "**SOURCE CODE HAS SEEN MORE GRADUAL GROWTH THAN OPENSOURCE MODELS** **F** **IGURE** 1.3.\n\n**G** **ENERATIVE** **genai** **OPEN** **-**\n\na) Upsurge in the number of open-source genai models on Hugging Face\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **11**\n\nb) Growth in the number of open-source genai code development projects on GitHub\n\nNote: Open-source code related to genai are a subset of genai-related GitHub repositories that include the\nfollowing wikidata concepts and all of their descendants: genai, transformer models, language model, and\ngenerative model.\n\nQuarterly data smoothing is applied to GitHub data to remove noise.\n\nSource: OECD.genai, using data from Hugging Face for open-source models and from GitHub for open-source code.", "#### 1.2.\n\nI NCIDENTS AND HAZARDS RELATED TO genai\n\n2.\n\nWhile genai has the potential to revolutionise industry and society in positive ways, the use of\nthe technology also poses risks to individuals and societies.\n\nFor example, genai can be exploited for\nmalicious purposes, leading to serious negative consequences such as the propagation of disinformation and\nthe creation of manipulated content like deepfakes.\n\nThe recognition of this multi-purpose nature of genai\ntechnologies and how they can be deployed \u2013 including genai \u2013 has prompted the OECD to develop a\nglobal genai Incidents Monitor, designed to furnish real-time evidence on genai risks to inform policy decisions.\n\nThis is achieved through the scrutiny of real-world incidents and hazards in real time as reported by reputable\nnews outlets.\n\nThe term \"incident\" encompasses a collection of one or more news articles covering the same event.1 Over\nthe period from January to July 2023, approximately one thousand incidents and hazards related to generative\ngenai were reported across roughly 5 600 news articles (Figure 1.4).\n\nWhile the Monitor is still under development\n(its release is expected in November 2023), the initial findings shed some light on the potential risks posed by\ngenai systems and can help contribute to shaping a safer genai landscape for the future.\n\n1 The OECD.genai expert group on genai incidents is currently discussing a working definition of genai incidents\nand hazards.\n\nFor the purposes of this report, the term \u201cincidents\u201d is used as umbrella term to include also\n\u201chazards\u201d.\n\n\u00a9 OECD 2023\n\n\n-----\n\n**12** | G7 HIROSHIMA PROCESS ON genai (genai)", "**OUTLETS HAVE GROWN EXPONENTIALLY**\n\nNote: The blue line shows the real count of incidents and hazards reported each month.\n\nThe red line displays the\nsame data but adjusted using quarterly smoothing.\n\nThe peak in 2019 relates to a surge in the reporting of incidents\nand hazards related to deepfake technology.\n\nSource: OECD.genai, genai Incidents Monitor (forthcoming), using data from Event Registry.", "### 2. genai FROM A G7 PERSPECTIVE\n\nThis section presents the results of the questionnaire developed to support a stocktaking to help guide G7\ndiscussions on common policy priorities with regard to genai.\n\nAs most questions provided a list of\noptions to rank or choose from, the rankings shown do not suggest e.g., most important to least important\npriorities, but a snapshot of country responses on the top priorities outlined in the questionnaire at a given\ntime.", "#### 2.1.\n\nO PPORTUNITIES AND RISKS FOR G7 MEMBERS\n\n**_Productivity gains and promoting innovation and entrepreneurship were viewed by all_**\n**_respondents as among the major opportunities made possible by genai, among_**\n**_opportunities outlined in the questionnaire.\n\nImproving healthcare followed closely, as did_**\n**_helping to solve the climate crisis_** _(_ **_F_** **_IGURE_** **_2.1_** _)._\n\nStrengthening the traceability and the transparency of democratic processes and improving citizens\u2019 access to\npublic services were also mentioned as other opportunities.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **13**", "**GOALS**\n\nNumber of G7 members that selected (five) specific opportunities from a pre-populated drop-down list\n\n_Note_ : The figure aggregates responses from seven respondents to the question: \u201c _From your country or region\u2019s_\n_perspective, what are the top five opportunities genai presents to help achieve national and regional goals?_\n_(Please select five options)\u201d._\n\n**_Disinformation and the associated manipulation of opinions were viewed by all respondents as_**\n**_the dominant risk posed by genai, among risks outlined in the questionnaire.\n\nMost G7_**\n**_members also considered intellectual property right infringement as well as threats to privacy_**\n**_as major risks (Figure 2.2)._**\n\nThreats to security (including cybersecurity); manipulation and improper use of data; and threats to human\nrights were also highlighted as additional risks.\n\n\u00a9 OECD 2023\n\n\n-----\n\n**14** | G7 HIROSHIMA PROCESS ON genai (genai)", "**REGIONAL GOALS**\n\nNumber of G7 members that selected (five) specific risks from a pre-populated drop-down list\n\nNote: The figure aggregates responses from seven respondents to the question: \u201c _From your country or region\u2019s_\n_perspective, what are the top five risks genai presents to achieving national and regional goals?\n\n(Please_\n_select five options)\u201d_ .\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **15**", "**MEMBERS**\n\n**_The \u2018responsible\u2019 use of genai technologies was widely viewed as the most \u201curgent\u201d_**\n**_priority for policy among the priorities highlighted in the G7 statement.\n\nThis was followed_**\n**_closely by addressing disinformation and by governing genai appropriately (Figure 2.3)._**\n\nThreats to cybersecurity and biosecurity were also indicated among the most urgent priorities regarding\ngenai.", "**HIGHLIGHTED IN THE** **G7** **L** **EADER** **\u2019** **S STATEMENT**\n\nNumber of G7 members that ranked specific priorities in terms of urgency from a pre-populated drop-down list\n\nNote: The figure aggregates responses from seven respondents to the question: \u201c _From a policy perspective what do_\n_you see as the most urgent and the most important priorities regarding genai?\n\n(Please rank the concepts_\n_below by order of urgency and importance.\n\nDifferent concepts can have the same priority level)\u201d._\n\n\u00a9 OECD 2023\n\n\n-----\n\n**16** | G7 HIROSHIMA PROCESS ON genai (genai)\n\n**_The \u2018responsible\u2019 use of genai technologies was also viewed as the most \u201cimportant\u201d_**\n**_priority for policy, followed by governance and by addressing disinformation.\n\nWhile_**\n**_\u201cimportance\u201d and \u201curgency\u201d of issues were ranked slightly differently, they highlighted the_**\n**_same overall priorities (Figure 2.4)._**\n\nThe threat to cybersecurity was also indicated as an additional important priority, and the threat to biosecurity\nas one of the most important priorities in the field of genai.", "**PRIORITIES HIGHLIGHTED IN THE** **G7** **L** **EADER** **\u2019** **S STATEMENT**\n\nNumber of G7 members that ranked specific priorities in terms of importance from a pre-populated drop-down list\n\nNote: The figure aggregates response from seven respondents to the question: \u201c _From a policy perspective what do_\n_you see as the most urgent and the most important priorities regarding genai?\n\n(Please rank the concepts_\n_below by order of urgency and importance.\n\nDifferent concepts can have the same priority level)_ \u201d.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **17**\n\n**_In addition, privacy and data governance were prioritised as the most urgent \u2018other\u2019 issues to_**\n**_address outlined in the questionnaire, followed by fairness and bias, and human and_**\n**_fundamental rights (Figure 2.5)._**", "**HIGHLIGHTED IN THE** **OECD** **genai** **P** **RINCIPLES**\n\nNumber of G7 members that ranked specific priorities in terms of urgency from a pre-populated drop-down list\n\nNote: The figure aggregates responses from seven respondents to the question: \u201c _From a policy perspective what do_\n_you see as the most urgent and the most important priorities regarding genai?\n\n(Please rank the concepts_\n_below by order of urgency and importance.\n\nDifferent concepts can have the same priority level)_ \u201d.\n\n**_Human and fundamental rights, security and robustness of genai systems, democratic values, and_**\n**_privacy and data governance were viewed as the most important \u2018other\u2019 priorities outlined in_**\n**_the questionnaire (Figure 2.6)._**\n\n\u00a9 OECD 2023\n\n\n-----\n\n**18** | G7 HIROSHIMA PROCESS ON genai (genai)", "**HIGHLIGHTED IN THE** **OECD** **genai** **P** **RINCIPLES**\n\nNumber of G7 members that ranked specific priorities in terms of importance from a pre-populated drop-down list\n\nNote: The figure aggregates responses from seven respondents to the question: \u201c _From a policy perspective what do_\n_you see as the most urgent and the most important priorities regarding genai?\n\n(Please rank the concepts_\n_below by order of urgency and importance.\n\nDifferent concepts can have the same priority level)_ \u201d.", "**THE CHALLENGES OF GENERATIVE** **genai** **IN** **G7** **JURISDICTIONS**\n\n**_Different G7 members\u2019 perceived policy gaps were diverse, with different G7 members_**\n**_highlighting disinformation, transparency, and responsible use as their most significant gaps_**\n**_among those outlined in the questionnaire (Figure 2.7)._**\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **19**", "**MEASURES THAT** **G7** **MEMBERS ARE TAKING TO FILL THE IDENTIFIED POLICY GAPS**\n\n**_Applying existing (or forthcoming) legal frameworks, and evaluating policy gaps_**\n\nRespondent countries are leveraging existing as well as forthcoming legal frameworks.\n\nThey are also assessing\nthe scale and extent of gaps pertaining to genai challenges.\n\no **Canada** , under the proposed genai and Data Act (AIDA), sets out a risk-based\nregulatory framework for the responsible design, development, and use of genai systems in the\nprivate sector, including genai systems.\n\no **France** is analysing the new challenges posed by genai regarding existing legislation\n(such as GDPR and the EU Copyright Directive) and noted that the EU genai Act is expected to\naddress some of the issues, such as governance and responsible use of genai systems.\n\no **Germany** is working on closer strategic alignment across government entities and on developing\nrelevant procedures.\n\no **Italy** In the light of the advent of genai (e.g.\n\nChatGPT), provisional agreement of the\nEuropean Parliament on the genai Act and increased ethical concerns and risks regarding Generative\ngenai, in early July 2023, the Department for Digital Transformation - Presidency of the Council of\nMinisters, presented a proposal for revision of the \"Strategic Plan for genai 2021\".\n\nThe proposed revision is nearing completion and will be subject to a public consultation procedure\nstarting as of 30 September.\n\nThe entry into force of the new \"Strategic Plan for genai'' is scheduled\nfor December 31, 2023.\n\nAlso, the government established a Permanent Committee on genai within\nthe Inter-Ministerial Committee on Digital Transition; the committee includes experts from\nuniversities, research centres and the associations of Italian companies.\n\nIn March 2023, the Italian\nData Protection Authority - DPA imposed an immediate temporary limitation on the processing\nof Italian users\u2019 data by OpenAI.\n\nIn its order, DPA highlighted that no information was provided\nto users and data subjects whose data were collected by Open genai; more importantly, it underlined\nthat there was no legal basis underpinning the massive collection and processing of personal data\nin order to \u2018train\u2019 the algorithms on which the platform relies.\n\nFurthermore, there was no age\nverification for minors.\n\n\u00a9 OECD 2023\n\n\n-----\n\n**20** | G7 HIROSHIMA PROCESS ON genai (genai)\n\no **Japan** indicated that it is applying existing legal frameworks (e.g., the Penal Code and the\nenforcement system) and existing guidelines (e.g., the genai R&D Guidelines, the genai Utilization\nGuidelines, or the Governance Guidelines for Implementation of genai Principles), although these\nmight be challenged by new issues from genai.\n\nAs new issues arise with the emergence\nof genai, it considers integrating and revising the guidelines into a unified and easy to\nunderstand guideline for developers, providers, users, and other business.\n\no The **United Kingdom** is working across government to assess scale and extent of gaps in existing\nmitigation measures and is exploring further measures at every stage of the genai supply chain **.\n\n**\n\no Similarly, in the **United States** , pursuant to an existing executive order mandating certain\nprinciples for federal genai activities, the Office of Management and Budget is developing guidance\nthat will establish specific policies that federal departments and agencies must follow to strengthen\ngenai governance, advance genai procurement, and manage algorithmic risk to safeguard American\npeople\u2019s rights and safety.\n\nThe U.S. Department of Commerce\u2019s National Institute of Standards\nand Technology released an genai Risk Management Framework (genai RMF) in January 2023 and in\nJune 2023 launched a genai Public Working Group to develop a profile of genai RMF for\ngenai systems.\n\no The proposed **European Union\u2019s genai Act (EU genai Act)** aims at promoting the\ndevelopment and uptake of genai while addressing potential risks certain genai systems, including\ngenai, can pose to safety and fundamental rights.\n\nIn addition, the EU will further enhance\nits regulatory toolbox, with the revision of existing legislation, like for example the recently\nadopted Machinery Regulation, as well as the proposed (and currently in the legislative process)\nrevision of the Product Liability Directive and the proposal for the Cyber Resilience Act.\n\nIn\naddition to regulatory measures, the EU is also pursuing the EU Coordinated Plan on genai with\nMember States and working on the genai Pact.\n\nThe Pact would encourage companies to voluntarily\ncommunicate the processes and practices they are putting in place to prepare for compliance with\nthe EU genai Act and ensure that the design, development and use of genai is trustworthy.\n\n**_Developing guidelines, and establishing new guidance as well as governance bodies_**\n\nThe Treasury Board of **Canada** \u2019s Secretariat (TBS) plans to issue guidelines on the use of genai in\nthe federal government.", "This \u2018guide\u2019 will provide federal institutions with guidance on the use of these tools.\n\nIt provides an overview of genai, identifies challenges and concerns relating to its use, puts forward\nprinciples for using it responsibly, and offers policy considerations and best practices.\n\nAdditionally, in early\nAugust, Canada launched roundtable sessions to seek stakeholder feedback on a proposed Canadian code of\npractice for genai.\n\nThe code will provide voluntary guidance to companies developing and using\ngenai systems, and it will help them to prepare their processes and products before formal regulation\ntakes effect.\n\nSimilarly, the **United States** Office of Management and Budget is developing guidance that will establish\nspecific policies that federal departments and agencies must follow to strengthen genai governance, advance genai\nprocurement, and manage algorithmic risk to safeguard American people\u2019s rights and safety.\n\n**Germany** reported undertaking several specific actions including a) setting up an advisory centre for the use\nof genai in the public sector to address competence building and networking; and b) establishing an genai Quality\nand Innovation Centre.\n\nThe **European Union** in the EU genai Act would also envisage certain governance structure and specific policies\nto ensure that design, development and use of genai technologies, including genai, is trustworthy.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **21**\n\n**_Highlighting the need for international governance_**\n\nWhere current gaps cannot be filled by resorting to current legal systems, G7 members refer to the need to\nexplore further mitigation measures, to take inspiration from other countries, and to coordinate measures at the\ninternational level to develop comprehensive and consistent approaches among countries.\n\nA G7 member\nreferred to international mechanisms that seek to counter foreign disinformation, such as the OECD Mis/Dis\nInformation Hub, the G7 Rapid Response Mechanism, and the Summit for Democracy (S4D) Information\nIntegrity cohort.", "**APPLIED TO** **,** **OR ARE BEING CHALLENGED BY** **,** **NEW ISSUES RAISED BY GENERATIVE** **genai**\n\nExisting laws and policies, including consumer protection and privacy laws, apply to genai.\n\nSeveral\nG7 members reported that legislation in various sectors is applicable to, but also challenged by, genai.\n\nG7 members highlighted in particular the challenges posed to privacy, and intellectual property, including\ncopyright.\n\nSome jurisdictions noted that compliance is already required by existing data protection legislation\nor intellectual property regimes.\n\nOthers highlighted that genai has raised new legal questions about ownership of\ncontent created wholly or in part with genai, such as images and texts, as well as questions about how rights\nassociated with training data affect the legal status of models\u2019 output, and that these questions are being\ninvestigated at national level.\n\nG7 members also provided examples of sectors particularly challenged by genai.\n\nThese include\ncreative industries, knowledge work, law, cybersecurity, health and medical devices technologies, the financial\nsector, and federal public services.\n\nIssues raised by genai seem to be particularly pressing for the following sectors, given that these were\nhighlighted by several G7 members:\n\n-  **Education** : Several G7 members noted that the education sector requires particular attention as it is\nalready highly affected by genai, and that this is expected to increase in the future.\n\nA G7\nmember is convening experts to work with the education sector to share and identify best practice\ncases as well as opportunities.\n\n-  **Workplace:** Two G7 members highlighted that genai affects workplace related matters.\n\ngenai can speed up recruitment processes (e.g.\n\nthrough genai-powered chatbots), but\nif data is biased, this may negatively impact the fairness of recruitment processes.\n\nFurthermore, they\nnoted that in the workplace, employees may use genai without appropriate guidance or\nregulation and expose sensitive or confidential corporate data and/or personal information to third\nparties outside the company.\n\n-  **Communication and media:** Two G7 members noted that journalism and information other areas in\nwhich laws and policies are being applied to or are challenged by genai, stressing to the risk\nfor genai to create misinformation and deepfakes.\n\n\u00a9 OECD 2023\n\n\n-----\n\n**22** | G7 HIROSHIMA PROCESS ON genai (genai)", "**GOVERNANCE**\n\n**_Unpredictability, adaptivity, autonomy, and multi-purpose nature of generative AI_**\n\nSeveral G7 members indicated unpredictability of impact, adaptivity, autonomy, and a multi-purpose nature\nas characteristics of genai that challenge its regulation and governance.\n\no genai creates new **disruptive innovation** , impacting a broad range of inexperienced users\nand developers.\n\nThe technology\u2019s wide field of application, increasing interactions between\ngenai systems, and rapid technical developments cause high uncertainty and\nunpredictability for society.\n\no Many genai applications today have little **\u2018autonomy\u2019** , i.e., little capacity to make\ndecisions or take actions on their own, without human oversight or direction.\n\nThey often produce\ncontent when instructed based on prompts.\n\nHowever, the output of genai can lead to\nautonomous or partly autonomous action programmed in traditional automation software whereby\nthe output of the genai is acted upon.\n\nLooking to the future however, as genai like\nlarge language models are increasingly used as autonomous generative \u2018agents\u2019 with plugins to\nconnect them to third-party applications, they are becoming more autonomous.\n\nFor example,\nplugins enable language models to operate on recent data, including real-time information, such\nas stock prices or news articles, and to assist users in new ways, such as through autonomous\nordering and booking.\n\no The **\u2018adaptivity\u2019** of genai comes with difficulties for developers to understand the intent\nor logic that leads to systems\u2019 outcomes.\n\nThis is because genai systems are \u2018trained\u2019 by inferring\npatterns and connections in data which are often not easily discernible to human programmers.\n\nThis mechanism allows genai systems to develop the ability to perform new tasks or forms\nof reasoning that the developers did not expect - a powerful source of capabilities, but also a barrier\nto intentionally designing or even fully understanding model capabilities.\n\nThis gap between the\ndevelopers\u2019 knowledge and intent and the system\u2019s capabilities can complicate assigning\nresponsibility for outcomes.\n\no The adaptivity and multi-purpose nature of genai, and its ability to develop and push out\ncontent much more rapidly than has been the case before, **may exacerbate bias and other risks**\nin more contexts than previous systems, promoting or reinforcing stereotypical or harmful\nrepresentations.\n\no The diversity of use cases and contexts to which genai can be applied is also challenging\nin its own right, as each of use case and context can potentially have different regulatory or\ngovernance requirements.\n\no Opacity, complexity, and continuous adaptation of genai systems can generate or exacerbate existing\nrisks to health, safety, and fundamental rights.\n\n**_Lack of transparency_**\n\nLack of transparency of genai, both in the development stage (i.e.\n\ndevelopers being transparent about\nhow they developed the system) and use (i.e.\n\nusers being transparent about the fact that they are using a\nsystem), was raised by one G7 member as an issue that challenges regulation/governance.\n\nOne G7 member is\ndeveloping legislation which provides transparency obligations, including for certain genai systems,\nwhich was given as an example seeking to address this concern.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **23**\n\n**_Misinformation and disinformation (including foreign disinformation campaigns)_**\n\nA G7 member stressed genai models\u2019 ability to create synthetic content (e.g., deepfakes) at scale with\nlittle resources or expertise.\n\nIn particular, they noted that the next generation of interactive generative media\nwill leverage targeted influence content that is highly personalised, localised, and conversational.\n\nAnother G7\nmember expressed concerns about the capacity of genai-generated content to influence human behaviour,\nexpression, and emotion at scale, as well as of content reflecting or promoting misinformation.\n\nMoreover, the\nmember also warned of incorrect or fabricated content that is presented as a fact (i.e., \u201cconfidently wrong\u201d or\n\u201challucinated\u201d output).\n\nLow levels of digital literacy may further accelerate the spread and exacerbate the impact of misinformation,\ncalling for improved digital literacy and assessment tools for content authenticity.\n\n**_Vast amounts of data pose regulatory challenges_**\n\nTwo G7 members stated that training genai relies on vast amounts of publicly available data, which\ncan be used without permission and may therefore not comply with data protection and copyright laws.\n\nTraining data thus gives rise to copyright issues when outputs resemble the original sources.\n\nAnother G7\nmember further noted the lack of clarity regarding what kind of training data is used as well as regarding the\nimplications for consumer protection, and intellectual property (IP) protection and enforcement, particularly\ngiven the difficulty of constraining models from reproducing copyrighted content.", "The member also stressed\nthat regulation and governance regimes are not keeping pace with rapid advances in genai capabilities.", "**ALIGNMENT AND COLLABORATION**\n\n**_Regulatory frameworks and interoperability_**\n\nG7 members responded that there is a need to establish appropriate regulation and oversight.\n\no One G7 member recalled that existing frameworks like the OECD genai principles require international\nnorms, standards, and assessment processes.\n\nThe member hence called for international alignment and\ncollaboration, including with developing countries.\n\no Another G7 member stressed the importance of international governance (e.g., establishing common\ngovernance frameworks and international standards on the reliability of genai, i.e., quality\ncontrol) and the need for international institutions to facilitate rapid, coordinated action among nations.\n\nThis is to allow them to respond to currently unknown threats.\n\nThe same G7 member noted that\ndifferent areas of global governance \u2013 from climate change to international trade \u2013 have benefited from\ncodifying and institutionalising cooperation among nations.\n\no Another G7 member also highlighted the need for precise and detailed principles to enable their\nimplementation in G7 countries.\n\nThe member further suggested that principles could be applied\nthrough general agreements with genai system providers or through binding legislation if\nagreements cannot be reached.\n\no Others stressed the need for greater interoperability of regulatory frameworks in different jurisdictions.\n\nAnother G7 member also stressed the need for common guidelines to promote responsible genai\ndevelopment and use.\n\n\u00a9 OECD 2023\n\n\n-----\n\n**24** | G7 HIROSHIMA PROCESS ON genai (genai)\n\n**_Risks_**\n\nSeveral G7 members stressed the importance of preventing the use of genai to create chemical or\nbiological threats (e.g.\n\nviruses), or massive disinformation/misinformation (including from foreign actors),\nhighlighting the need for international cooperation on these common challenges.\n\nCybersecurity concerns were\nalso identified as a challenge posed by genai that requires international alignment and collaboration,\ncalling for addressing international genai cyber security risks on a global level.\n\nOthers also mentioned the risk of\nundermining social stability.\n\nOthers pointed out that the rapid pace of technological developments makes it\ndifficult for policy makers to keep up.\n\n**_Personal data and intellectual property rights_**\n\nA G7 member emphasised the need to take measures regarding the use of personal data as well as material\nprotected by intellectual property rights.\n\nThese measures should consider, on the one hand, the difference\nbetween data used in the process of training a model, and on the other hand, data used when the system interacts\nwith the end user and generates content.\n\nOthers also called for finding common ground at the international\nlevel on managing the data provided to train genai systems.\n\nA G7 member suggested that data provided by human\noperators should be traceable and withdrawable by the original provider.\n\n**_Transparency_**\n\nThe need for transparency in both the development and use of genai was stressed by several G7\nmembers.\n\nSome respondents mentioned the work led by the European Union (the EU genai Act) regarding\nresponsibilities between actors within genai value chains.\n\nIn particular, these G7 members argued that\nfoundational model providers should provide sufficient transparency for the providers of final \u201cproducts\u201d to\nplace them on the market safely.\n\nThey also recalled that the proposed EU genai Act contains the following\ntransparency provisions for genai systems: (a) a genai chatbot would be subject to transparency\nobligations; (b) genai system that can be directly used for high-risk applications (e.g., the evaluation\nof job candidates), would have to fulfil the corresponding requirements for high-risk genai systems, which include\ntransparency provisions.\n\n**_Ethics_**\n\nSome G7 members mentioned the need to implement common policies on genai ethics to address issues of biases\nin genai systems.\n\nOne G7 member added that a code of ethics is required to reduce the general misuse of\ngenai, but also to govern its use in military contexts.\n\n**_Seizing the benefits of genai for the common good_**\n\nA G7 member highlighted that international collaboration is needed for governments to demonstrate\nresponsible leadership in deploying and using these technologies for the public good in various sectors,\nincluding health (to enhance medical diagnostics), and the public administration (to make government more\neffective/efficient).\n\nOthers also stated that their objective is to ensure that genai is oriented towards the common\ngood.\n\nA G7 member pointed out that the rapid development of genai creates new opportunities for\nemerging and developing countries and that international cooperation to foster more local genai innovation should\nfocus on the promotion of representative datasets, genai know-how, policy frameworks for responsible genai and\nappropriate data protection.", "**_Unequal opportunities (within societies, and for the Global South)_**\n\nOne G7 member noted that while rapid advancements of genai create new opportunities for countries\nin the Global South, they also bear certain risks.\n\nIn particular, the member stressed that countries in Asia and\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **25**\n\nAfrica are lagging behind when it comes to inclusive policy frameworks for values-based genai.\n\ngenai\nalso has the potential to deepen digital divides: because genai is trained on existing data that may be\nbiased, it could contribute to greater polarisation worldwide.\n\nThis is why a G7 member called for involving a\ndiverse range of stakeholders in genai governance, including governments, private companies, and civil society.\n\nOthers echoed this point as they stressed the need for governments to be more responsive to rapid\nchanges/advancements in this technology, including by engaging with a diversity of stakeholders to understand\nthe impacts of these technologies on different parts of society and different sectors.\n\nSimilarly, another G7\nmember pointed out that international alignment and collaboration is necessary to ensure both the\ntrustworthiness of these technologies and a common approach towards governing them.\n\nThis is particularly\npertinent given that genai technologies are developed and subsequently deployed globally not just in democratic,\nbut also in non-democratic states.", "##### T YPES OF POSSIBLE POLICY ACTIONS THAT THE G7 COULD RECOMMEND\n\n**_Providing effective tools for safety, quality control, and capacity / trust building, as well as_**\n**_engaging in dialogue were viewed by respondents as the most urgent actions the G7 could_**\n**_recommend among those outlined in the questionnaire (Figure 2.8)._**\n\nRegarding \u201cdevelop incentives\u201d, a G7 member noted that in many cases, the underlying tools to assess or\naddress risks may not yet exist.\n\nTherefore, research on and development of better risk analysis tools remain\nimportant and will be needed before it is possible to incentivise use.\n\n\u00a9 OECD 2023\n\n\n-----\n\n**26** | G7 HIROSHIMA PROCESS ON genai (genai)", "**F** **IGURE** **2.8.\n\n** **M** **OST URGENT TYPES OF ACTIONS THE** **G7** **COULD RECOMMEND**\n\nNote: The figure aggregates responses from seven respondents to the question: \u201c _What type of actions could the G7_\n_recommend to collectively evaluate developments and how to harness the opportunities and address the risks posed_\n_by genai?\u201d._\n\n**_Providing effective tools for safety, quality control, and capacity / trust building, and voluntary_**\n**_codes of conduct were viewed by respondents as the most important actions the G7 could_**\n**_recommend among those outlined in the questionnaire (Figure 2.9)._**\n\nA G7 member stated that working on concrete projects with genai experts to address risks and harness\nopportunities represents both an urgent and important type of action the G7 could recommend.\n\nAccording to\nother G7 members, other urgent and important types of action are awareness raising, sharing of knowledge\nand best practices, and engaging in dialogue with all relevant national and international stakeholders.\n\nFurthermore, respondents mentioned engaging in regulatory approaches as among the most important action\nthe G7 could recommend to collectively evaluate developments and the risks posed by genai.\n\nAnother suggestion was tracking policy initiatives focused on genai through the OECD genai Policy\nObservatory to help grow an evidence base for policy discussions.\n\nWhile countries are already reporting\ninitiatives related to genai to the OECD genai Policy Observatory, there is a plan to make them better\nidentifiable by creating a specific tag and section for those initiatives.\n\nRegarding tools for safety, quality control, capacity and trust building, the OECD launched in April 2023 the\nCatalogue of Tools and Metrics for Trustworthy genai .\n\nThe catalogue is a platform where genai practitioners from\nall over the world can share and compare tools and build upon each other\u2019s efforts to create global best practices\nand speed up the process of implementing the OECD genai Principles.\n\nTools can be of procedural, technical or\neducational nature, and are classified by their objective (that is, the OECD genai Principle they are designed to\naddress).\n\nCurrently, the catalogue counts 585 tools for trustworthy genai, out of which 28 tools specifically\naddress genai.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **27**", "**F** **IGURE** **2.9.\n\n** **M** **OST IMPORTANT TYPES OF ACTIONS THE** **G7** **COULD RECOMMEND**\n\nNote: The figure aggregates responses from eight respondents to the question: \u201c _What type of actions could the G7_\n_recommend to collectively evaluate developments and how to harness the opportunities and address the risks posed_\n_by genai?\u201d._", "#### 2.4.\n\nN ATIONAL AND REGIONAL INITIATIVES IN G7 JURISDICTIONS\n\n**_G7 members are leveraging opportunities (Table 2.1), or addressing challenges of generative_**\n**_AI (Table 2.2) either through existing initiatives or by launching new initiatives_**\n\nThe **United States** responded that many of their existing policies, executive orders, and approaches (e.g., the\nNIST genai Risk Management Framework) still apply to genai.\n\nSeveral of the voluntary commitments\nfor leading genai companies include commitments on issues specific to genai, such as a commitment to\ndevelop watermarking systems.\n\n**Canada** mentioned that some departments and agencies are currently exploring the possibility of launching\nnew initiatives to support research and development in the field of genai and will share more\ninformation about these as they advance.\n\nThe **European Union** \u2019s existing legislation and policies, including on data protection, misinformation, unfair\ncommercial practices, copyright protection, and digital services fully apply to genai.\n\nMoreover, within\nthe framework of the ongoing legislative negotiations on the EU genai Act, discussions are ongoing to strengthen\nprovisions specifically focused on genai.\n\n\u00a9 OECD 2023\n\n\n-----\n\n**28** | G7 HIROSHIMA PROCESS ON genai (genai)", "**OF GENERATIVE** **genai**\n\n|Member|Existing initiative|Description/Actions addressing genai|Type of genai|New initiative|Description|Type of genai|\n|---|---|---|---|---|---|---|\n|Canada|Pan-Canadian genai Strategy|Strategy focused on investments in talent, research capacity, commercialization and standardization.||Guidance on the use of genai in the federal public service|||\n||Directive on the Use of Automated Decision- Making|Directive accompanied by the Algorithmic Impact Assessment, which governs the use of genai systems within the federal public service||Proposed Canadian code of practice for genai|Canada is hosting roundtable sessions to seek stakeholder feedback on a proposed Canadian code of practice for genai.\n\nThe code will provide voluntary guidance to companies developing and using genai systems, and will help them to prepare their processes and products before formal regulation takes effect.||\n|EU|E U genai Act|Transparency obligations, regulatory sandboxes|Multi-modal|Testing and Experimentation Facilities (TEFs)|EU Commission is co-funding the TEFs to support genai developers.|Open to all genai technologies|\n||Coordinated Plan on genai|Strategy on genai and priority areas for action, developed in cooperation with the Member States.\n\nInclude actions to faciliate access to computing power, microelectronics, TEFs, digital innovation hubs||European Digital Infrastructure Consortium|||\n||The European High Performance Computing Joint Undertaking (EuroHPC JU)||||||\n|France|National genai Strategy|Access to computing power for start-ups|Multi-modal|EDIC for NLP|European initiative to develop an international consortium for NLP (currently being extended towards multimodal genai).|Multi- modal/text|\n|||Call for projects for the creation of digital commons for genai in French|Multi-modal||||\n|||Global genai challenge to evaluate the state of the art among LLM models in the world|Text||||\n|Germany|National genai Strategy|Framework for a holistic policy on the future development and application of genai|Multi-modal|Large European genai Models (LEAM)|Initiative from the German genai Association to foster LLM development in the EU and Germany|Text|\n||FAIR Forward|Development initiative for a more open and sustainable application of genai in developing and emerging economies||F13|LLM based on the Luminous model used in the government of the federal state of Baden-W\u00fcrttemberg|Text|\n\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **29**\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n|Member|Existing initiative|Description/Actions addressing genai|Type of genai|New initiative|Description|Type of genai|\n|---|---|---|---|---|---|---|\n||Guideline for the promotion of genai for the common good|Strengthen the use of data and technologies using genai for the common good||BEKI|Advisory centre for genai in the public sector||\n||Centres of excellence for genai research|Six national competence centres for genai research to strengthen excellence in genai|Multi-modal||||\n||genai quality and innovation center|Development of practical genai testing approaches to ensure standards and quality in genai applications|Multi-modal||||\n||Civic Coding \u2013 KI f\u00fcr das Gemeinwohl|Structures promoting the emergence of social innovations with genai|||||\n||Learning systems \u2013 Germany\u2019s platform for genai|Forum for exchange and cooperation|Multi-modal||||\n|Japan|genai strategy 2022|National genai Strategy presenting a comprehensive policy package related to genai||genai Strategy Team and genai Strategy Council|Government and experts\u2019 bodies examinig a wide range of issues related to genai.|Multi-modal|\n|||||Tentative summary of genai issues|Summary of issues related to genai (mainly genai), by the genai Strategic Council|Multi-modal|\n|||||Use of genai|Agreement on the business use of genai within the government.|Multi-modal|\n|||||Strengthening of genai development capability|Support to the development of computing resources for private companies.|Multi-modal|\n|Italy|Fund for the development of genai, blockchain and internet of things (IoT) technologies and applications.|Fund for enterprises, including SMEs.", "It supports projects involving the implementation of industrial research and innovation for developing genai, blockchain, and internet of things technologies applications|Multi-modal|Revision of the Italian Strategic Plan for genai 2021 (to be completed and out for open consultation at the end of Sep. 2023)|Updating the national genai strategy in view of the genai Act and the development of genai|Multimodal|\n||Italian National PhD Program in genai.|Five federated PhD courses that bring together 61 universities and research institutions|Multi-modal|New governance: National Authority on genai within the National Agency for Digital Italy (AGID) under the supervision of the Department for Digital Transformation|The Authority will coordinate all the new policy initiatives with a special focus on genai||\n|||||Corporate Venture Capital Fund for genai start-ups to develop solutions for the public sector|Implementing the \u201cNational genai Strategy 2021,\u201d Goal n. 5: \u201cDevelop genai-driven policies and services in the public sector by boosting public sector innovation\u201d|Multimodal|\n\n\n\u00a9 OECD 2023\n\n\n-----\n\n**30** | G7 HIROSHIMA PROCESS ON genai (genai)\n\n\n\n\n\n\n\n\n\n\n|Member|Existing initiative|Description/Actions addressing genai|Type of genai|New initiative|Description|Type of genai|\n|---|---|---|---|---|---|---|\n|||||Personalised Virtual assistant - National Institute for Social Security (INPS)|Virtual assistant based on genai.\n\nThe virtual assistant helps users to improve the search experience on the INPS website.\n\nAlso, in its beta version, the virtual assistant can help users to submit specific questions relating to \"Opzione Donna\u201d (\u201cOption Woman\u201d), a social security measure for women only|Multimodal|\n|||||Certified e-mails (PEC) automatic classification and sorting - National Institute for Social Security (INPS)|Optimise the communication flow of millions of certified emails that are received weekly|Text|\n|||||Future genai Research (FAIR) Centre|Research network to address research aspects, methodologies, models, technologies, and ethical and legal rules for building human centric genai systems.\n\nIt includes four research institutions and 14 universities||\n|United Kingdom|genai Regulation White Paper|Context-based, proportionate, and adaptable approach to regulating genai.\n\nIt draws on expertise of existing regulators|Multi-modal|Foundation Model Taskforce|Taskforce will lead genai safety research to drive forward safe and reliable development of Foundation Models|Multi-modal|\n||Centre for Data Ethics and Innovation (CDEI) portfolio of genai assurance techniques|Case studies of genai assurance techniques being applied by organisations across a range of sectors|Multi-modal|UK Global Summit on genai Safety|The summit will consider risks of genai, and discuss how they can be mitigated through internationally coordinated action|Multi-modal|\n||genai Standards Hub|Practical tools and information to improve genai standards adoption and development|Multi-modal||||\n|United States||||Voluntary Commitments|These include a commitment from leading genai companies to develop and deploy advanced genai systems to help address society\u2019s greatest challenges.|Multi-modal|\n|||||NIST genai Public Working Group|Developing a profile of the NIST genai Risk Management Framework for genai systems|Multi-modal|\n\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **31**\n\n\n\n\n\n\n\n\n|Member|Existing initiative|Description/Actions addressing genai|Type of genai|New initiative|Description|Type of genai|\n|---|---|---|---|---|---|---|\n|||||President\u2019s Council of Advisors on Science and Technology (PCAST) working group on genai|Developing recommendations for the President on how best to ensure that these technologies are developed and deployed as equitably, responsibly, and safely as possible.|Multi-modal|\n\n\n\u00a9 OECD 2023\n\n\n-----\n\n**32** | G7 HIROSHIMA PROCESS ON genai (genai)\n\nTable 2.2.\n\n**O** **VERVIEW OF NATIONAL AND REGIONAL INITIATIVES TO ADDRESS RISKS RELATED TO**", "**GENERATIVE** **genai**\n\n|Member|Initiative|Description|Type of genai|\n|---|---|---|---|\n|Canada|genai and Data Act (AIDA)|Proposes the development of a risk-based national regulatory framework for the responsible design, development, and use of genai in Canada\u2019s private sector|Multi-modal|\n||Proposed Canadian code of practice for genai|Canada is hosting roundtable sessions to seek stakeholder feedback on a proposed Canadian code of practice for genai.\n\nThe code will provide voluntary guidance to companies developing and using genai systems, and will help them to prepare their processes and products before formal regulation takes effect.|Mutli-modal|\n||TBS guide on the use of genai in the Government of Canada|Provides guidance to federal institutions on their use of genai tools|Multi-modal|\n|EU|genai Act|EU legislation currently in the legislative process|Multi-modal|\n|Japan|Tentative summary of genai issues|Summary of issues related to genai (mainly genai), by the genai Strategic Council|Multi-modal|\n||Response to risks of genai|Review of uniform guidelines for business players, summary of issues on intellectual property rights, establishment of guidelines for the use of genai in education, etc.|Multi-modal|\n|Italy|Policy Paper on Risk Assessment, Auditing and Management|Various regulatory actors engaged to produce a policy paper with insights on risk assessment, auditing, and risk management|Multi-modal|\n|United Kingdom|genai Regulation White Paper|Context-based, proportionate, and adaptable approach to regulating genai.\n\nIt draws on expertise of existing regulators|Multi-modal|\n||Centre for Data Ethics and Innovation (CDEI) portfolio of genai assurance techniques|Case studies of genai assurance techniques being applied by organisations across a range of sectors|Multi-modal|\n||UK Global Summit on genai Safety|The summit will consider risks of genai, and discuss how they can be mitigated through internationally coordinated action|Multi-modal|\n||genai Standards Hub|Practical tools and information to improve genai standards adoption and development|Multi-modal|\n|United States|Voluntary Commitments|Voluntary commitments from leading genai companies to help move toward safe, secure, and transparent development of genai technology|Multi-modal|\n||NIST genai Public Working Group|Developing a profile of the NIST genai Risk Management Framework for genai systems|Multi-modal|\n||President\u2019s Council of Advisors on Science and Technology (PCAST) working group on genai|Developing recommendations for the President on how best to ensure that these technologies are developed and deployed as equitably, responsibly, and safely as possible.|Multi-modal|", "##### N ATIONAL AND REGIONAL INITIATIVES ON genai BY G7 MEMBER\n\n**_Canada_**\n\no genai and Data Act (AIDA): The AIDA was tabled in Canada\u2019s Parliament in June\n\n2022 and proposes the development of a risk-based national regulatory framework for the\nresponsible design, development, and use of genai in Canada\u2019s private sector.\n\no Proposed Canadian code of practice for genai: Canada is hosting roundtable sessions to\n\nseek stakeholder feedback on a proposed Canadian code of practice for genai.\n\nThe code\nwill provide voluntary guidance to companies developing and using genai systems, and it will help\nthem to prepare their processes and products before formal regulation takes effect.\n\no TBS guide on the use of genai in the Government of Canada: The TBS guide, intended as\n\nan evergreen document to be refined over time, is intended to provide guidance to federal\ninstitutions on their use of genai tools.\n\nIt would provide an overview of genai,\nidentifies challenges and concerns relating to its use, puts forward principles for using it\nresponsibly, and offers policy considerations and best practices.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **33**\n\n**_EU_**\n\n\no Testing and Experimentation Facilities (TEFs): In cooperation with the EU Member States, the\n\nEuropean Commission is co-funding the TEFs in order to support genai developers to bring\ntrustworthy genai to the market in a more efficient way and to facilitate its uptake in Europe.\n\no genai Act (genai Act): Since genai systems in general and genai systems in\nparticular could potentially challenge and impact a broad spectrum of areas and use cases, the\nEuropean Commission proposed the genai Act in 2021.\n\nThe EU genai Act is a legal framework, which\naims at making sure that people can trust what genai has to offer.\n\n**_France_**\n\n\no National Strategy on genai: It includes the support of the emergence of genai initiatives in\n\nFrance, via an easier access to computing power for start-ups, a call for projects for the creation\nof digital commons for genai in French (databases, genai application models, etc.)\n\nand the\nlaunch of a global genai challenge in order to evaluate the state-of-the-art among Large\nLanguage Models (LLM) around the world.\n\no EDIC for NLP: European initiative to develop an international consortium for NLP (currently\n\nbeing extended towards multimodal genai).\n\nThis will allow to develop a European set of\ndatabases, share the European computing power for promising projects, an incubator for start-ups,\nfinancing for research projects, etc.\n\n**_Germany_**\n\no National genai Strategy: Framework for a holistic policy on the future development and application\n\nof genai.\n\no FAIR Forward: Development initiative working towards a more open and sustainable application\n\nof genai that involves developing and emerging economies.\n\no Large European genai Models (LEAM) initiative: Initiative from the German genai Association to foster\n\nLLM development in the EU and Germany.\n\no Centres of excellence for genai research: The Federal Ministry of Education and Research has\n\nestablished six national competence centres for genai research to strengthen excellence and\ncompetitiveness as well as to become a leading centre for genai research.\n\no Civic Coding \u2013 KI f\u00fcr das Gemeinwohl: Innovation Network to create structures that promote the\n\nemergence of social innovations and the social appropriation of genai on a broader basis.\n\no Guideline for the promotion of genai for the common good: Funding research, implementation, and\n\nmodel projects to strengthen the use of data and technologies using genai for the common good.\n\no F13: LLM based on the Luminous model.\n\nIt is used in the government of the federal state of\n\nBaden-W\u00fcrttemberg.\n\no Learning systems \u2013 Germany\u2019s platform for genai: A forum for exchange and cooperation which\n\nbrings together expertise from science, industry, and society for fostering Germany\u2019s position as\nan international technology leader.\n\no BEKI: Advisory centre for genai in the public sector.\n\n**_Japan_**\n\n\no genai Strategy 2022: Launched in April 2022 and based on the principles Dignity for People,\n\nDiversity and Sustainability, this strategy is to contribute to the resolution of global issues through\n\n\u00a9 OECD 2023\n\n\n-----\n\n**34** | G7 HIROSHIMA PROCESS ON genai (genai)\n\nthe realisation of Society 5.0, and to present a comprehensive policy package related to genai for\novercoming Japan's own social issues and improving industrial competitiveness.\n\no The genai Strategy Team and the genai Strategy Council: In April 2023, the genai Strategy Team -\n\nconsisting of working-level officials from related ministries and agencies - was established to\nstudy how to address a wide range of issues related to genai.\n\nFurthermore, in May 2023,\nthe genai Strategy Council - consisting of experts - was established to examine not only technology\nbut also the legal system and ethics from a wide range of perspectives.", "Furthermore, in May 2023,\nthe genai Strategy Council - consisting of experts - was established to examine not only technology\nbut also the legal system and ethics from a wide range of perspectives.\n\no Tentative summary of genai issues : Based on recent rapid changes in technology and the 2023 G7\n\nHiroshima Summit, members of the genai Strategic Council summarised issues related to genai, mainly\ngenai, as of the end of May 2023.\n\nCurrently, Japan is in the process of promoting\ndiscussions on response to risks of genai, use of genai, strengthening of genai development capability, as\nwell as international discussions, including the \u201cHiroshima genai Process\u201d as the G7 chair country.\n\no Response to risks of genai: Review of uniform guidelines for business players, summary of issues on\n\nintellectual property rights, establishment of guidelines for the use of genai in education,\netc.\n\no Use of genai: Agreement on the business use of genai within the government.\n\no Strengthening of genai development capability: Support to the development of computing resources\n\nfor private companies.\n\n**_Italy_**\n\no Implementing the National genai Strategy 2021: Goal n. 5 \u201cDevelop genai-driven policies and services\n\nin the public sector by boosting public sector innovation\u201d.\n\no Establishment of the Corporate Venture Capital Fund for genai start-ups to develop solutions for the\n\npublic administration: The Fund (operating in 2024) will invest in start-ups with the potential to\ndevelop breakthrough technologies to automate public institutions\u2019 processes.\n\nThe investment\namounts to EUR 600 million.\n\nThe Fund includes an institutional mechanism to foster the dialogue\nbetween start-ups and the public administrations to better understand the public sector\u2019s needs.\n\nThe Fund is under the responsibility of the National Cybersecurity Agency and the Department\nfor Digital Transformation.\n\no Establishment of the National Authority on genai within the National Agency for Digital Italy\n\n(AGID), under the supervision of the Department for Digital Transformation.\n\nThe Authority will\ncoordinate all the new policy initiatives with a special focus on genai.\n\no Fund for the development of genai, blockchain and internet of things (IoT) technologies and\n\napplications: A dedicated fund for enterprises, including SMEs.\n\nIt supports projects involving the\nimplementation of industrial research and innovation for developing genai, blockchain, and IoT\ntechnologies applications.\n\no The National Institute for Social Security (INPS)\u2019s Personalized virtual assistant to help users to\n\nnavigate the many services offered on the INPS portal.\n\no The National Institute for Social Security (INPS) - Certified e-mails automatic classification and\n\nsorting: The project aims to optimise the communication flow of the millions of certified emails\nsent to INPS through a system that can automatically understand the content of the email received\nand direct it to the proper official in charge of that particular response.\n\no Italian National PhD Program in genai: The Italian National PhD Program in\n\ngenai is made of five federated PhD courses that bring together 61 universities\nand research institutions.\n\nThe 5 PhD courses share a common basis in the foundations and\ndevelopments of genai, and each one has an area of specialisation in a strategic sector of genai\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **35**\n\napplication.\n\nEach PhD course is organised by a lead university, in collaboration with the National\nResearch Council (CNR).\n\no Future genai Research (FAIR) Centre: The Future genai Intelligence Research (FAIR)\n\nproject aims to help address the research questions, methodologies, models, technologies, and\neven ethical and legal rules for building human centric genai systems.\n\nFAIR constitutes a research\nnetwork spread over the country and includes four research institutions (CNR, Fondazione Bruno\nKessler, INFN, and IIT), 14 universities (Politecnico di Milano, Politecnico di Torino, Sapienza,\nScuola Normale Superiore, SISSA, Universit\u00e0 Bocconi, Universit\u00e0 Campus Biomedico di Roma,\nUniversit\u00e0 della Calabria, Universit\u00e0 di Bari, Universit\u00e0 di Bologna, Universit\u00e0 di Catania,\nUniversit\u00e0 di Napoli \u201cFederico II,\u201d Universit\u00e0 di Pisa, Universit\u00e0 di Trento) and seven companies\n(Bracco, Deloitte, Expert.\n\ngenai, Intesa Sanpaolo, Leonardo, Lutech, STMicroelectronics).\n\no Policy Paper on Risk Assessment, Auditing and Management: Various regulatory actors engaged\n\nin a discussion to produce a policy paper to produce insights on the risk assessment, auditing, and\nrisk management, with the aim of understanding the position of start-ups, trade association, and\nthe third sector.\n\n**_United Kingdom_**\n\no genai Regulation White Paper: The White Paper sets out the UK\u2019s context-based, proportionate, and\n\nadaptable approach to regulate genai, and draws on expertise of existing regulators; encouraging\nthem to consider how best to govern genai in their own sectors.", "It will enable the UK to achieve the\nright balance between responding to risks and maximising opportunities afforded by genai.\n\no Centre for Data Ethics and Innovation (CDEI) portfolio of genai assurance techniques: The portfolio\n\nfeatures case studies of genai assurance techniques being applied by organisations using cutting-edge\ntechnologies across a range of sectors.\n\nThis will act as a valuable resource for those developing\nand procuring genai systems to understand how genai assurance techniques can help them measure,\nevaluate, and communicate trustworthiness of genai systems, as well as how techniques align with\nproposed regulatory principles identified in the UK\u2019s genai Regulation White Paper.\n\no Foundational Model Taskforce: The taskforce will lead vital genai safety research as part of driving\n\nforward safe and reliable development of Foundation Models while seizing extraordinary\nopportunities they present.\n\nThe taskforce is backed with initial GBP100 million of government\nfunding.\n\no UK Global Summit on genai Safety: The summit will consider risks of genai, including frontier systems,\n\nand discuss how they can be mitigated through internationally coordinated action.\n\nIt will also\nprovide a platform for countries to work together on further developing a shared approach to\nmitigate risks.\n\no genai Standards Hub: It aims to improve genai standards adoption and development by providing\n\nbusinesses, regulators, and civil society organisations in the UK with practical tools and\ninformation.\n\nMoreover, they need to apply genai standards effectively and contribute to their\ndevelopment.\n\ngenai Standards Hub is part of the National genai Strategy and ultimately aims to increase\nthe UK\u2019s contribution to the development of global genai technical standards.\n\n**_United States_**\n\no Voluntary Commitments: To make the most of genai\u2019s potential, the United States is encouraging\n\nthe genai industry to uphold the highest standards to ensure that innovation does not come at the\nexpense of Americans\u2019 rights and safety.\n\nThe White House secured voluntary commitments from\nleading genai companies to help move toward safe, secure, and transparent development of genai\n\n\u00a9 OECD 2023\n\n\n-----\n\n**36** | G7 HIROSHIMA PROCESS ON genai (genai)\n\ntechnology.\n\nThe commitments underscore three principles fundamental to the future of genai \u2013 safety,\nsecurity, and trust \u2013 and mark a critical step toward developing responsible genai.\n\no NIST genai Public Working Group: This working group builds on the success of the NIST\n\ngenai Risk Management Framework to address rapidly advancing genai technologies.\n\nThe Public\nWorking Group on genai will help address the opportunities and challenges associated\nwith genai that can generate content, such as code, text, images, videos and music.\n\nThe public\nworking group will also help NIST develop key guidance to help organizations address the special\nrisks associated with genai technologies.\n\no PCAST genai Working Group: The President\u2019s Council of Advisors on Science and\n\nTechnology (PCAST) has launched a working group on genai (genai) to\nhelp assess key opportunities and risks and provide input on how best to ensure that these\ntechnologies are developed and deployed as equitably, responsibly, and safely as possible.\n\nThe\nPCAST Working Group on genai aims to build upon existing efforts by identifying\nadditional needs and opportunities and making recommendations to the President for how best to\naddress them.\n\n\u00a9 OECD 2023\n\n\n-----\n\nG7 HIROSHIMA PROCESS ON genai (genai) | **37**", "#### OECD genai PAPERS\n\nSeptember 2023 **No.\n\n1**\n\n\n-----\n\n**2** | INITIAL POLICY CONSIDERATIONS FOR genai\n\nOECD Working Papers should not be reported as representing the official views of the OECD or of its\nmember countries.\n\nThe opinions expressed and arguments employed are those of the authors.\n\nWorking\nPapers describe preliminary results or research in progress by the author(s) and are published to stimulate\ndiscussion on a broad range of issues on which the OECD works.\n\nComments on Working Papers are\nwelcomed, and may be sent to Directorate for Science, Technology and Innovation, OECD, 2 rue Andr\u00e9\nPascal, 75775 Paris Cedex 16, France.\n\n_Note to Delegations:_\n\nThis document is also available on O.N.E under the reference code:\n\n_DSTI/CDEP/AIGO/RD(2023)5/FINAL_\n\nThis document, as well as any data and any map included herein, are without prejudice to the status of or\nsovereignty over any territory, to the delimitation of international frontiers and boundaries and to the name\nof any territory, city or area.\n\n\u00a9 OECD 2023\n\nThe use of this work, whether digital or print, is governed by the Terms and Conditions to be found at\n .\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **3**", "##### Initial policy considerations for generative artificial\n\nintelligence\n\nPhilippe Lorenz, Karine Perset (OECD), Jamie Berryhill (OECD)\n\ngenai (genai) creates new content in response to\nprompts, offering transformative potential across multiple sectors such as\neducation, entertainment, healthcare and scientific research.\n\nHowever, these\ntechnologies also pose critical societal and policy challenges that policy\nmakers must confront: potential shifts in labour markets, copyright\nuncertainties, and risk associated with the perpetuation of societal biases\nand the potential for misuse in the creation of disinformation and manipulated\ncontent.\n\nConsequences could extend to the spreading of mis- and\ndisinformation, perpetuation of discrimination, distortion of public discourse\nand markets, and the incitement of violence.\n\nGovernments recognise the\ntransformative impact of genai and are actively working to address\nthese challenges.\n\nThis paper aims to inform these policy considerations and\nsupport decision makers in addressing them.\n\n**Keywords:** genai, genai, digital economy, science and technology\n\nOECD genai PAPERS\n\n\n-----\n\n**4** | INITIAL POLICY CONSIDERATIONS FOR genai", "###### 2 Select policy issues raised by genai 12\n\ngenai is being adopted rapidly in key industry sectors 12\n\ngenai considerably amplifies mis- and disinformation\u2019s scale and scope 13\n\nBias and discrimination 17\n\nIntellectual Property Rights (IPR) issues, including copyright 19\n\ngenai could impact labour markets on a different scale and scope 20", "**FIGURES**\n\nFigure 1.1.\n\nSims-like environment for genai agents 11\n\n\nFigure 2.1.\n\nChatGPT explains RLHF as part of an overview by HuggingFace 18\n\n\nFigure 2.2.\n\nCases of \u201cjailbreaks\u201d 18\n\n\nFigure 2.3.\n\nGPT performance on academic and professional exams 21\n\n\nFigure 3.1.\n\nComparison of Midjourney images from v1 to v5 25\n\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **5**", "## Foreword\n\ngenai (genai) came onto the scene in 2018 with releases of deepfakes closely\nfollowed by generative pre-trained transformers (GPTs) and other large language models (LLMs).\n\nIt gained\nworldwide attention in 2022 with text-to-image generators and ChatGPT.\n\ngenai has the potential\nto revolutionise industries and society.\n\nSectors such as education, entertainment, healthcare, and scientific\nresearch already use it to create individualised and scalable content, automate tasks, generate\nhypotheses, and improve productivity.\n\nHowever, policymakers need to consider significant societal and policy implications, such as the\ntechnology\u2019s potential impact on labour markets and debates around whether training genai\nsystems on copyrighted material could constitute infringement.\n\nPotential risks include genai\nperpetuating biases and being misused through disinformation, deepfakes, and other manipulated content\nwith severe consequences.\n\nThe resulting widespread social, political, and economic repercussions could\ninclude disinformation on key scientific issues, perpetuating stereotypes and discrimination, distorting\npublic discourse, creating and spreading conspiracy theories and other disinformation, influencing\nelections, distorting markets, and even inciting violence.\n\nThere are more questions than answers about how this technology will shape our environments and\ninteractions, and policy is struggling to keep up with developments.\n\nThat said, governments recognise the\ntransformative nature of genai and are acting to keep pace with change.\n\nFor example, in May 2023,\nthe Group of Seven (G7) countries committed to advance international discussions of its governance in\npursuit of inclusive and trustworthy genai, which included the establishment of the Hiroshima genai Process by\ngovernments in collaboration with the OECD.\n\nThe OECD, including through its OECD.genai Policy Observatory (  ), is committed to helping\ngovernments keep up with the rapid change in genai.\n\nThis paper was drafted by Philippe Lorenz,\nan external genai consultant.\n\nStrategic direction and additional analysis and content were provided by Karine\nPerset, Head of the OECD.genai Policy Observatory, and Jamie Berryhill, genai Policy Analyst, OECD.\n\nSebastian\nHallensleben (CEN-CENELEC JTC 21 and VDE) advised on the strategic approach and scope.\n\nThe paper\nbenefited from the review and input of the OECD Working Party on genai Governance\n(AIGO), including delegates from Business at OECD (BIAC), the European Commission, and Japan.\n\nThe\nteam gratefully acknowledges the input from OECD colleagues Jerry Sheehan, Audrey Plonk, Hanna-Mari\nKilpelainen, and Riccardo Rapparini of the Directorate for Science, Technology and Innovation (STI); and\nAngelica Salvi Del Pero and Stijn Broecke of the Directorate for Employment, Labour and Social Affairs\n(ELS).\n\nThe team also thanks Misha Pinkhasov for editing the paper and Andreia Furtado for editorial and\npublishing support.\n\nOECD genai PAPERS\n\n\n-----\n\n**6** | INITIAL POLICY CONSIDERATIONS FOR genai", "# 1\n\ngenai systems create content based on training data and in\nresponse to user prompts.\n\nTheir recent growth and media coverage have\nspotlighted genai\u2019s capabilities, leading to significant public, academic and\npolitical discussion.\n\nIn addition to creating synthetic content, genai\nsystems are increasingly used as autonomous agents, allowing models to\nmove beyond the cut-off dates in their training data to give them new\npotential.\n\ngenai has the potential to revolutionise industries and\nsociety and is already used to create individualised and scalable content,\nautomate tasks, and improve productivity.\n\nSuch systems offer significant\nupside but also risks for policymakers to address.\n\n**genai is centre stage in public, academic and political discourse**\n\n**_Recent growth genai systems has drawn attention genai\u2019s capabilities_**\n\ngenai (genai) systems create new content in response to prompts based on their\ntraining data.\n\nThe recent growth and coverage of genai systems has spotlighted genai\u2019s capabilities.\n\nThey include, for example, ChatGPT and BARD for text; Midjourney and Stable Diffusion for images;\nWaveNet and DeepVoice for audio; Make-A-Video and Synthesia for video; and multi-model systems that\ncombine several types of media.\n\nCompanies are now creating positions for \u201cprompt engineers\u201d, venture\ncapitalists are positioning themselves as generative-genai investors, and governments are considering\nregulatory tools.\n\nLanguage models \u2013 one mode of genai \u2013 were discussed in-depth in the recent\nOECD report _AI Language Models: Technological, socio-economic and policy considerations_ (OECD,\n2023 [1] ).\n\nOther modes, such as image, audio, and video generation, are also evolving rapidly with the\ntechnology and broader policy landscape.\n\n1\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **9**\n\n**_Governments quickly recognised that genai is transformative and are taking action_**\n\nWhile genai has begun to revolutionise industry and society in numerous positive ways, the\ntechnology can also be misused through disinformation, deepfakes, and other manipulated content with\nsevere negative consequences.\n\nDespite ideas about how this technology will shape our environments and\ninteractions, policy is struggling to keep up with technological developments, and numerous questions\nrequire answers.\n\nAt the same time, governments have been quick to recognise the transformative nature\nof genai and are taking action to keep pace with change.\n\nFor example, in May 2023, the Group of\nSeven (G7) countries committed to advance international discussions of genai governance in pursuit of\ninclusive and trustworthy genai and established the Hiroshima genai Process in collaboration with the OECD\nunder the Japanese G7 Presidency to help improve governance of genai.\n\n2\n\n**_Generative genai is rooted in established genai concepts_**\n\nAlthough genai systems appear novel, their model design is based on deep neural networks (which\nloosely imitate information processing of neurons in the human brain) that developed incrementally through\ninternational academic and applied research since the 1950s (Goodfellow, Bengio and Courville, 2016 [2] ).\n\nThe visible results of genai models are due to recent developments in the discipline of machine\nlearning (ML).\n\nML leverages deep neural networks to emulate human intelligence by being exposed to\ndata (training) and finding patterns that are then used to process previously unseen data.\n\nThis allows the\nmodel to generalise based on probabilistic inference, i.e.\n\ninformed guesses, rather than causal\nunderstanding.\n\nUnlike humans, who learn from only a few examples, deep neural networks need hundreds\nof thousands, millions, or even billions, meaning that machine learning requires vast quantities of data.\n\n**_Few companies can create large genai systems and models_**\n\nSo far, few technology companies in the world have the technological skills and capital to create major\ngenai systems and models (Chawla et al., 2023 [3] ), such as foundation models that \u201care capable of\na range of general tasks\u2026[and] can be built \u2018on top of\u2019 to develop different applications for many purposes\u201d\n(Ada Lovelace Institute, 2023 [4] ).\n\nA few multinational enterprises have been investing in genai for some time\nto enable their business models, be it search, advertising, or social networks.\n\nThese entities seem\npositioned to capture a large part of the initial value created by genai, with systems marketed\ninternationally embedded in software as-a-service on cloud platforms or, more recently, placed directly on\ndevices.\n\n**_Open-source actors, researchers, start-ups, and SMEs are also very active_**\n\nHowever, these companies are a part of an ecosystem that includes researchers, small and medium-sized\nenterprises (SMEs), and other actors that contribute to and derive value from genai.\n\nOpen-source\ncommunities are also active in the ecosystem.", "Open-source\ncommunities are also active in the ecosystem.\n\ngenai traditionally relies on a mix of proprietary and free and\nopen-source software (FOSS) models, libraries, datasets, and other resources for commercial or noncommercial purposes under a variety of licenses.\n\n3 Although a number of genai companies operate proprietary\ngenai systems and commercialise access to them, several companies are developing open systems.\n\nThe emergence of several open-source genai models (Dickson, 2023 [5] ), such as Stable Diffusion\nand Meta\u2019s Llama 2, 4 contributes to the rapid innovation and development of these technologies and could\nmitigate \u2018winner-take-all dynamics\u2019 that lead a few firms to seize a large part of the market.\n\nYet open\nsourcing entails other risks when bad actors can leverage open-source genai models, which will\nbe explored in forthcoming OECD work.\n\nOECD genai PAPERS\n\n\n-----\n\n**10** | INITIAL POLICY CONSIDERATIONS FOR genai\n\n**_Generative genai creates novel content with real-world implications_**\n\nA core trait of human intelligence is the cognitive capacity humans have to create content (Chawla et al.,\n2023 [3] ).\n\ngenai models use \u201cprompts\u201d (specific requests) to produce synthetic text, images, audio,\nand video that, already today, can be nearly impossible to distinguish from human creation (Nightingale\nand Farid., 2022 [6] ); (Abbott and Rothman, 2022 [7] ).\n\nThe quality of large language models (LLMs) that\nenable text-generation has improved rapidly since the publication of the Transformers architecture by\nGoogle researchers in 2017 and reached a turning point with the release of ChatGPT in November 2022.\n\n5\nAs the first conversational agent accessible through a convenient and intuitive user interface, the release\nsurprised governments, organisations, and individuals around the world.\n\nChatGPT is estimated to have\naround 100 million active monthly users, making it the fastest-growing consumer software application in\nhistory (Hu, 2023 [8] ).\n\nThe excitement in late 2022 around text generation was repeated with regard to image generation in March\n2023 because of a picture of Pope Francis wearing a white puffer jacket.\n\nMany believed that the picture\nwas authentic, but it had been created by a synthetic image-generation software based on a user\u2019s text\nprompt.\n\nIt was shared widely on social and traditional media networks before finally being exposed as\nfake.\n\n6 Synthetic images took off after their inception in 2014 based on the work of (Goodfellow et al.,\n2014 [9] ), which paved the way for current model capabilities.\n\nGiven the rapid pace of development,\nsynthetic images are already often indistinguishable from real ones to the human eye.\n\n**_Autonomous genai agents promise significant benefits but carry tremendous risks_**\n\nFurthermore, genai systems are increasingly used as autonomous agents, adding a new dimension\nto the technology\u2019s potential and allowing models to move beyond the limitation of cut-off dates in their\ntraining data.\n\nOpenAI announced plugins in early 2023 that connect ChatGPT to third-party applications to\nexpand its offer and find new sources of data.\n\nBefore that, ChatGPT users were limited to the platform\u2019s\nknowledge base from late 2021, the cut-off point for the initial training data.\n\nReceiving third-party\ninformation allows the model to use real-time data to provide more accurate and timely results and\nservices.\n\nPlugins enable ChatGPT to operate on the most recent data available, including real-time\ninformation, such as stock prices or news articles, and to assist users in new ways (e.g., through\nautonomous ordering and booking).\n\nSimilarly, Bing Chat is connected to the Internet and aware of current\nevents (Conway, 2023 [10] ).\n\nAgent activities are not limited to machines acting on human instructions and prompts.\n\nResearchers at\nStanford University and Google Research created a virtual environment in which 25 genai agents\ninteracted with each other over the course of two days and exhibited human-like behaviour such as\nreasoning about their research careers or planning about attending social events (Figure 1.1) (Park et al.,\n2023 [11] ).\n\nWhile these unexpected actions were termed \u201cemergent abilities\u201d by some researchers (Wei et\nal., 2022 [12] ), others found these actions illusory based on the metrics programmers chose to evaluate the\nmodels (Schaeffer, Miranda and Koyejo, 2023 [13] ).\n\nWhile the debate is ongoing, the autonomous behaviour\nand hints of agency that very large genai models could be capable of enlarges the scope of their\npossible application, as well as the scope of considerations and unknowns for how the technology might\ndevelop.\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **11**", "**Figure 1.1.\n\nSims-like environment for genai agents**\n\nSource: (Park et al., 2023 [11] ).\n\nThese types of systems offer significant upside but also carry risks, such as from their ability to create and\nspread mis- and disinformation, use their increased agency to carry out undesired actions, or even\nmisrepresent themselves by impersonating humans (Hurler, 2023 [14] ).\n\nPolicymakers everywhere are taking\nnotice, with G7 leaders setting up the Hiroshima genai Process in May 2023.\n\n7 The European Parliament has\nbeen advocating for considering genai systems as general-purpose genai, which would classify them\nas high-risk applications and entail mandatory conformity assessments and other requirements.\n\n8\n\nOECD genai PAPERS\n\n\n-----\n\n**12** | INITIAL POLICY CONSIDERATIONS FOR genai", "### genai\n\ngenai is predicted to create significant economic value and social\nwell-being and has begun to do so in key sectors.\n\nYet genai can\nalso echo, automate, and perpetuate mis- and disinformation, bias, and\ndiscrimination, and training on copyrighted data could infringe on\nintellectual property.\n\nThe OECD finds the net impact of genai on employment\nto be ambiguous so far, mainly affecting job quality \u2013 generally positively \u2013\nwith little evidence of significant negative effects on their quantity.\n\nHowever,\noutcomes such as language models\u2019 strong performance on standardised\ntests, suggest that job-task exposure to genai could increase and\nthat high-skilled occupations are most exposed to recent advances.\n\n**genai is being adopted rapidly in key industry sectors**\n\ngenai is predicted to create significant economic value and social well-being.\n\nCompanies have\nbegun adopting the technology to create new business opportunities, and start-ups are competing for\nventure capital.\n\nPopular use cases and applications to date include pre-processing data, image\ncompression and classification, medical imaging, personalisation, and intuitive user experience (UX)\ninterfaces (Polaris, 2023 [15] ).\n\nSeveral genai applications have begun to yield benefits in areas\nincluding:\n\n-  **Code development** \u2013 Copilot, a coding assistant developed jointly by OpenAI and GitHub,\nautocompletes and generates code based on developers' prompts (Dohmke, 2022 [16] ).\n\nOther\nmodels to generate code include CodeGen (Nijkamp et al., 2023 [17] ).\n\nCode refactoring (improving\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **13**\n\npre-existing code without altering its functionality) is another area where genai is assisting\ndevelopers (Ingle, 2023 [18] ).\n\n-  **Creative industries and arts** \u2013 In music, genai melody generators have been available for a while,\nhelping artists craft new music from scratch or based on previous bars, improve composition\n(Yang, Chou and Yang, 2017 [19] ), and process singing (G\u00f3mez et al., 2018 [20] ).\n\nIn image generation,\napplications such as Stable Diffusion and Dall-E 2 provide new opportunities to generate artforms\nfor the advertising, media, movie, and other industries.\n\n-  **Education** \u2013 Education is among the sectors expecting change in the near-term, as school children\nand students experiment with genai applications to learn (like OpenAI\u2019s GPT Khanmigo 9 )\nand prepare for exams (Baidoo-Anu and Ansah, 2023 [21] ).\n\nSuch applications can create educational\nmaterial, write letters of recommendation, and design course syllabuses, improving the efficiency\nof teachers (Pettinato Oltz, 2023 [22] ).\n\n-  **Healthcare** \u2013 genai models play important roles as interfaces for patients and healthcare\nproviders (Bommasani et al., 2021 [23] ).\n\nPatients are already benefiting from information on\npreventive care (Demner-Fushman, Mrabet and Abacha, 2020 [24] ) and explanations of medical\nconditions and treatments.\n\nThe use of Vik, a chatbot that responds to the fears and concerns of\npatients diagnosed with breast cancer, is shown to result in better medication adherence rates\n(Chaix et al., 2019 [25] ).\n\nAnother promising application is the discovery and development of new\ndrugs using genai chemistry models.\n\nCompanies such as Insilico Medicine are conducting\nFDA-approved clinical trials of cancer treatments designed using large biological, chemical, and\n\n10\ntextual generative and predictive engines (Insilico Medicine, 2023 [26] ).\n\n-  **Search** \u2013 Search-engines are underpinning their search capabilities with conversational generative\ngenai models such as Microsoft Bing with OpenAI\u2019s GPT-4.\n\n11 One of the most discussed topics in genai\nand search is whether search engines that provide links to users will be disrupted by conversational\nagents that provide better search experiences (Sriram and Mehta, 2023 [27] ).\n\n**genai considerably amplifies mis- and disinformation\u2019s scale and scope**\n\nHumans were found, already in 2022, to be almost incapable of differentiating genai from human generated\nnews in 50% of cases (Kreps, Mccain and Brundage., 2022 [28] ), meaning that genai can amplify\nrisks both of misinformation (the unintended spread of false information) and of deliberate disinformation\nby malicious actors.\n\n12 Leading-edge genai models have multimodal capabilities that can\nexacerbate these risks, for example by combining text with image or video or even voices.\n\nUnintentional\nmisinformation or intentional deception can cause material harm at an individual level (e.g., influencing\ndecision-making about vaccines) (Weidinger et al., 2022 [29] ) and, on a larger scale, erode societal trust in\nthe information ecosystem (Ognyanova et al., 2020 [30] ) and the fact-based exchange of information that\nunderpins science, evidence-based decision-making, and democracy (OECD, 2022 [31] ).", "Research findings\nrelated to human interpretation of genai-generated content underscore the potential risk of genai-driven mis- and\ndisinformation, and emphasise the importance of disclosing the use of genai systems (Box 2.1).\n\nOECD genai PAPERS\n\n\n-----\n\n**14** | INITIAL POLICY CONSIDERATIONS FOR genai", "**Humans find synthetic faces more trustworthy than real faces**\n\nAlthough genai-generated faces are nearly indistinguishable from real ones, humans perceive synthetic\nfaces to be more trustworthy than real faces.\n\nThis has been explained by the fact that synthetic images\nresemble \u201caverage\u201d faces, which are perceived to be more trustworthy.\n\nSources (Longoni et al., 2022 [32] ); (Nightingale and Farid., 2022 [6] ); (Sofer et al., 2015 [33] ).\n\nThe functionality of text-to-text genai models, or language models, easily leads them to produce\nmisinformation.\n\nThey are trained to predict words or statements based on a probability assessment.\n\nHowever, the accuracy of the predicted following word depends on the context rather than probability\n(Weidinger et al., 2022 [34] ).\n\nTruth depends on context, but LLMs based on probabilistic inference have no\nability to reason and thus might never achieve completely accurate outputs (LeCun, 2022 [35] ).\n\nThis also\nbears on LLMs\u2019 potential as a tool to detect information for the purpose of countering it (Weidinger et al.,\n2022 [34] ).\n\n**_\u201cHallucinations\u201d and over-reliance also require addressing_**\n\nAnother worrying feature of LLMs is their propensity to \u201challucinate\u201d ( _i.e._ , to generate incorrect yet\nconvincing outputs), particularly when an answer is not available in the training data (OECD, 2023 [1] ).\n\nThis\ncan allow them to create convincing misinformation, hate speech, or reproduce biases.\n\nRisks also include\nexcessive trust and overreliance on the model, resulting in a dependency that can interfere with developing\n\n13\nskills, and even lead to losing skills (OpenAI, 2023 [36] ).\n\nThis issue will worsen with increasing model\ncapabilities, areas of application, and user trust as average users will be unable to fact-check the models\u2019\nresponses (Passi and Vorvoreanu, 2022 [37] ).\n\n**_Synthetic content can be particularly powerful in politics, science, and law enforcement_**\n\nRisks associated with text-to-image genai models make clear how rapid technological progress is.\n\nNumerous \u201cphotographs\u201d on Twitter and other online platforms depicted well-known political figures and\nheads of state taking surprising actions yet were very credible, demonstrating the power of synthetic\nimagery, particularly in polarised political contexts.\n\nAnother issue has been the manipulation of scientific\nimages to produce mis- and disinformation, threatening trust within research communities as well as\nscience\u2019s reputation with the general public.\n\nUse of synthetic images by climate change deniers (Galaz\net al., 2023 [38] ) and the spread of COVID-19 disinformation (Coldewey and Lardinois, 2023 [39] ) serve as\ncases in point.\n\nTargeted disinformation campaigns leveraging different modes of genai can mislead and\nmanipulate public opinion (Weidinger et al., 2022 ).\n\nLLMs could help conduct targetedinfluence operations, _i.e._ , \u201ccovert or deceptive efforts to influence the opinions of a target audience\u201d [29] ) (OECD, 2022 [31]\n(Goldstein et al., 2023 [40] ).\n\nThey can significantly reduce propaganda costs and increase its scale\n(Buchanan et al., 2021 [41] ).\n\nThe dynamics of influence operations could also be altered in unpredictable\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **15**\n\nways, such through more convincing messaging by using LLMs capable of better cultural and linguistic\nimmersion in target audiences (Goldstein et al., 2023 [40] ).\n\nOpenAI reported that its own red teaming efforts\nfound GPT-4 to rival human propagandists, \u201cespecially if teamed with a human editor\u201d, and can develop\nplausible-sounding plans to reach propaganda goals (OpenAI, 2023 [36] ).\n\nDespite users\u2019 wariness of genai authorship (Box 2.1), research in 2019 found genai-generated fake news to be\nmore credible to human raters than human-written disinformation (Zellers et al., 2019 [42] ).\n\nIn the early\nweeks of the Russian invasion of Ukraine in March 2022, a deepfake video depicting Ukrainian President\nVolodymyr Zelensky admitting defeat and demanding Ukrainian soldiers surrender surfaced on social\nmedia and was uploaded to a Ukrainian news website by hackers (Allynn, 2022 [43] ).\n\nAlthough crude in\nvideo and audio quality, this attempt to deceive the public was seen as a harbinger of future public\ndeception enabled by more powerful models (Boh\u00e1\u010dek and Farid, 2022 [44] ).\n\nSuch deepfakes are\nincreasingly realistic and convincing as advancements are made in both audio and video generation\ntechniques and models.\n\n**_Mitigating mis- and disinformation requires leveraging and improving known solutions_**\n\nThe risks of generating mis- and disinformation at scale with genai systems demand novel\nsolutions.\n\nCompanies and other organisations have faced issues related to incorrect or false information\nfor a long time and put systems in place to address them.", "Companies and other organisations have faced issues related to incorrect or false information\nfor a long time and put systems in place to address them.\n\nHowever, traditional fact-checking and other\nexisting solutions are generally not scalable in the face of genai-based automation of disinformation.\n\nUser\neducation alone becomes insufficient when genai generates more and more convincing disinformation.\n\nIn\naddition, it shifts responsibility from systems, companies, and governments to individuals.\n\nWhile\nresearchers are exploring potential paths forward, there are still more questions than answers about\npotential remedies to genai-generated and spread mis- and disinformation.\n\nWeidinger et al.\n\n(2022) point to\nseveral methods for reducing _misinformation_ at scale.\n\nScaling-up (i.e., increasing) model size is often\nadvocated to improve model accuracy but deemed insufficient (Bender and Koller, 2020 [45] ) (Lin, Hilton\nand Evans, 2022 [46] ).\n\nResearch is also ongoing to prompt models to substantiate their statements, such as\nby referencing sources from the Internet (Nakano et al., 2021 [47] ) or forcing them to provide evidence to\nsupport their claims (Menick et al., 2022 [48] ), and augmenting retrieval model architecture by having models\nretrieve information from larger databases to make predictions (Borgeaud et al., 2021 [49] ).\n\nTo mitigate image-generating genai misinformation risks, some suggest adding watermarks that enable\nidentification of synthetic imagery, restricting code so that it cannot easily be introduced into applications,\nand developing guidelines that include ethical guidelines for the production and distribution of genai-generated\nimages (Nightingale and Farid., 2022 [6] ).\n\nSome research also suggests that watermarking model output\ncould be possible for text generation as well (Kirchenbauer et al., 2023 [50] ) (Abdelnabi and Fritz, 2021 [51] ).\n\nThe Coalition for Content Provenance and Authenticity (C2PA) seems to be coordinating promising\ncollaboration among relevant actors to mitigate misinformation risks (Box 2.2).\n\nOECD genai PAPERS\n\n\n-----\n\n**16** | INITIAL POLICY CONSIDERATIONS FOR genai", "**Box 2.2.\n\nCoalition for Content Provenance and Authenticity (C2PA)**\n\nC2PA is a consortium which develops open standards that certify the source and provenance of online\ncontent.\n\nIts steering committee consists of major IT and media companies.\n\nSince 2021, C2PA has\ndelivered several versions of its technical standards for content provenance and authenticity.\n\nThese\nstandards serve as a model for storing and accessing cryptographically verifiable information whose\ntrustworthiness can be assessed based on a defined trust model.\n\nThe aim is to enable the global optin adoption of digital provenance techniques by creating an ecosystem of digital provenance-enabled\napplications for individuals and organisations while meeting appropriate security and privacy\nrequirements and human rights considerations.\n\nSource:  .\n\nThe misinformation mitigation elements discussed above can also help mitigate disinformation, though\nadditional actions, such as use-limits and monitoring, may be needed to address intentional genai generation\nand spreading of false information.\n\nResearch labs use red-teaming to test a model and try to deny user\nrequests that could lead their model to generate disinformation (OpenAI, 2023 [36] ) (Ganguli et al., 2022 [52] ).\n\nThis can be done with human testing and/or with other generative models (OECD, 2023 [1] ).\n\nA growing body\nof technical literature documents varying deepfake detection techniques, an addition to the watermarking\nefforts touched on above.\n\nFake-news and deepfake detection use different methods that range from\nplotting LLMs against LLMs (Zellers et al., 2019 ) to augmenting human deepfake video raters with stateof-the-art deepfake detection systems \u2013 found to be more accurate than having either humans or the [42]\ndetection systems rate content alone (Groh et al., 2022 [53] ).\n\n**_Novel solutions to address mis- and disinformation from genai are also imperative_**\n\nCurrent approaches have limitations.\n\nThe OECD.genai Network of Experts has, in particular, discussed that:\n\n-  While it may be possible to develop mechanisms that detect subtle traces of origin in genai-generated\nimages, this is not always true of genai-generated text.\n\nIn particular, short texts such as social media\nposts or product reviews do not contain enough data to reliably distinguish human and machinegenerated content.\n\nHuman editing of genai-generated text can further obscure its origins (Sadasivan\net al., 2023 [54] ), though this might not be possible at scale.\n\n-  As with other technologies, bad actors will seek to circumvent mitigation measures.\n\nThese statesponsored or commercial actors will not declare their bots or disinformation as genai-generated or\nfollow guidelines or codes of conduct.\n\nObligations to do so will not stop them, just as the illegality\nof cyberattacks does not prevent cyberattacks.\n\nThis is exacerbated by the global nature of the\ninternet that enables such actors to take refuge in \u201csafe\u201d jurisdictions.\n\n-  Although most large genai models are controlled by large companies, open-source models\nare increasingly available, some of which can be queried by any user from any computer (OECD,\n2023 [1] ).\n\nThis effectively bypasses the potential guardrails and restrictions on use.\n\nHowever, some\nOECD.genai experts note that using open-source models still requires significant expertise and\ncapacity and that bypassing guardrails might not be trivial when the models are fine-tuned with\nbuilt-in mitigations.\n\nOverall, research finds that detection algorithms for video, audio/voice, and images are unreliable.\n\nA major\nreason for this is that attackers can generate new deepfakes that detection models are not yet familiar with\n(Le et al., 2023 [55] ).\n\nIn the case of text, detection algorithms can be evaded by adding another model that\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **17**\n\nrephrases the genai output text, which is known as a \u201cparaphrasing\u201d attack (Sadasivan et al.,\n2023 [56] ).\n\nTo complicate matters, the watermarking schemes of distinct language models can themselves be learned\nand applied to detect text as watermarked in \u201cspoofing attacks\u201d, such that companies or developers behind\nthe targeted LLM could be falsely accused of generating plagiarised text, spam, or fake news (Sadasivan\net al., 2023 [56] ).\n\nSince defensive and offensive techniques are in constant competition, new research is\ntrying to increase systems\u2019 robustness against such attacks (Krishna et al., 2023 [57] ).", "**Bias and discrimination**\n\n**_Generative genai models can replicate biases present in their training data_**\n\ngenai can echo, automate, and perpetuate social prejudices, stereotypes, and discrimination by\nabsorbing biases contained in resources used as training data.\n\nIn the case of language models, these are\nlanguage resources or language models themselves, including pre-trained models (OECD, 2023 [1] ).\n\nThese\noutputs could further marginalise or exclude specific groups (Bender et al., 2021 [58] ).\n\nExamples include\nmodels that display negative sentiment towards social groups, link occupations to gender (Weidinger et al.,\n2022 [34] ), or express bias regarding specific religions (Abid, Farooqi and Zou, 2021 [59] ).\n\nSome models also try to evade responding when asked potentially biased questions such as whether\nwomen should be allowed to vote, using so-called \u201chedging\u201d behaviour \u2013 which may increase users\u2019 trust\nin the model because it seems to display caution (OpenAI, 2023 [36] ).\n\nBias is not limited to text-based systems and extends to other types of models such as image models.\n\nFor\nexample, synthetic image outputs were found to over-represent white skin colour and masculinity in three\ndifferent image-generating models (Luccioni et al., 2023 [60] ), with another model ranking synthetic images\nof females in more domestic and household environments than their male counterparts (Lucy and\nBamman, 2021 [61] ).\n\nOther research points to biased relationships between race, gender, and economic\n\n14\nWhile biasreinforcement is an ongoing issue with machine-learning, the ease-of-use and rapid adoption of recent status in image-generating systems\u2019 outputs (Fraser, Kiritchenko and Nejadgholi, 2023 [62] ).\n\ngenai systems risks increasing the dissemination of discriminatory outputs.\n\n**_Documentation, data curation, and auditing are basic mechanisms to mitigate bias_**\n\nMeasures to mitigate bias include taking stock of training data for represented and missing groups and\nnarratives (Dodge et al., 2021 [63] ) (Gebru et al., 2018 [64] ), curation or semi-automatic curation of datasets\nto reach fairer results (Denton et al., 2020 [65] ) (Hutchinson et al., 2021 [66] ), explainability and interpretability\nresearch (Weidinger et al., 2022 [34] ), and applying auditing processes (Zakrzewski, 2023 [67] ).\n\n**_Red teaming and reinforcement learning by human feedback are key for commercial models_**\n\nResearch labs that market their models often use more forceful approaches.\n\nThese include \u201cred teaming\u201d,\nin which teams adopt an attacker mindset to probe the model for flaws and vulnerabilities.\n\n15 They either\nrely on human experts or use language models (Perez et al., 2022 [68] ).\n\nOther approaches include\ncombinations of dataset cleaning \u2013 such as classifiers to filter out erotic content \u2013 and \u201cReinforcement\nLearning by Human Feedback\u201d (RLHF) algorithms (Markov et al., 2022 [69] ).\n\nRLHF, as illustrated in Figure\n2.1, is a multi-step, fine-tuning approach to shape a model\u2019s behaviour, such as getting it to respond less\nto disallowed content or refuse to give instructions on how to harm oneself (OpenAI, 2023 [36] ).\n\nWhile\nimportant, these strategies cannot guarantee a model\u2019s safety.\n\nNumerous cases of \u201djailbreaks\u201d intentionally\nexploiting models to get them to respond inappropriately have been documented (Figure 2.2).\n\n16 In addition,\nsome research points out that RLHF might have limitations in terms of scalability, cost and quality of human\n\nOECD genai PAPERS\n\n\n-----\n\n**18** | INITIAL POLICY CONSIDERATIONS FOR genai\n\nfeedback (Christiano, 2023 [70] ) (Lambert et al., 2022 [71] ), or the potential to introduce new biases from the\nhumans providing feedback (Shah, 2023 [72] ).", "**Intellectual Property Rights (IPR) issues, including copyright**\n\ngenai raises intellectual property rights issues, particularly concerning unlicensed content in\ntraining data, potential copyright, patent and trademark infringement of genai creations, and ownership of AIgenerated works.\n\n**_Generative genai models are trained on data that includes unauthorised copyrighted material_**\n\ngenai models are being trained on massive amounts of data that includes copyrighted data, mostly\nwithout authorisation of the rights-owners.\n\nIn 2019, the World Intellectual Property Organisation (WIPO)\nconvened sessions about the implications of genai for IP.\n\nThe WIPO Secretariat published a paper in May\n2020 on IP policy and genai that highlighted eight key issues, including questions such as whether the use of\ncopyrighted data without authorisation constitutes an infringement of copyright and, if so, whether there\nshould be an exception that allows for the training of machine learning models (WIPO, 2020 [73] ).\n\n**_Legal cases on the applicability of fair use principles versus copyright infringement are_**\n**_ongoing_**\n\nWhether commercial entities can legally train ML models on copyrighted material is contested in Europe\nand the US.\n\nIn the US, the outcome could be determined by the applicability of the fair use principle, which\nlimits the exclusive rights of copyright owners (House of Representatives, 1976 [74] ).\n\nFair use requires courts\nto weigh four statutory factors and, if ruled applicable, could result in non-infringement, allowing\n\n17\ncommercial entities to use copyrighted material in their training sets (Lorenz, 2022 [75] ) (Zirpoli, 2023 [76] ).\n\nSeveral lawsuits were filed in the US against companies that allegedly trained their models on copyrighted\n\n18\ndata without authorisation to make and later store copies of the resulting images (Zirpoli, 2023 [76] ).\n\nThese\ndecisions will set legal precedents and impact the genai industry from start-ups to multinational\ntech companies.\n\nThey will also affect policy in areas beyond IP, such as research and development (R&D)\nand industrial policy, the geopolitics of technology, foreign affairs, and national security (see section on genai\nfutures).\n\nRecent research could also demonstrate instances in which the fair-use doctrine might not apply\n\u2013 cases in which a foundation model generates outputs that are very similar to copyrighted data\n(Henderson et al., 2023 [77] ).\n\nThis work suggests that model development might need to ensure that outputs\nremain sufficiently different from copyrighted material to remain covered by fair use.\n\n**_Can novel outputs generated by genai be copyrighted or patented and if so, by whom?_**\n\ngenai creates new images, text, and audio that are novel, raising questions about whether\ngenerated outputs can be copyrighted or patented.\n\nBecause legal systems around the world differ in their\ntreatment of IP rights such as patents and copyrights, the treatment of genai-generated works varies between\n\n19\ncountries (Murray, 2023 [78] ).\n\nTo date, most jurisdictions agree that works generated autonomously by genai are not copyrightable (Craig,\n2021 [79] ).\n\nUS copyright law requires human authorship to register a copyright claim and copyrights cannot\nbe awarded to genai systems.\n\nEuropean legal systems have come to a similar interpretation of the\nmatter, although the decisive requirement is originality, which according to the European Court of Justice\n(ECJ) is fulfilled if the work reflects \u201cthe author\u2019s own intellectual creation\u201d (Infopaq International (C-5/08),\n2009 [80] ); (Deltorn and Macrez, 2018 [81] ).\n\nIf genai systems cannot be awarded copyrights, the work could be assigned to somebody else,\nsuch as the system programmer.\n\nJurisdictions in UK Commonwealth tradition allude to computergenerated works and attribute authorship to the person laying the groundwork for the machine\u2019s creation\n\n20\n(Deltorn and Macrez, 2018 [81] ); (Craig, 2021 [79] ); (Murray, 2023 [78] ) The rapid spread of genai\n\nOECD genai PAPERS\n\n\n-----\n\n**20** | INITIAL POLICY CONSIDERATIONS FOR genai\n\nmodels, the amounts of venture capital they attract, and the growing numbers of applications claiming\ncopyrights for genai-generated works recently led the US Copyright Office to issue a policy statement on its\napproach to registration, confirming that it will not register works produced by a machine (U.S.\n\nCopyright\n\n21\nOffice, 2023 [82] ) and launching a website for updates on this topic.\n\n**genai could impact labour markets on a different scale and scope**\n\n**_Labour markets could face a significant shakeup with both positive and negative effects_**\n\nWhile to date, genai has mainly impacted the quality of jobs rather than their quantity (Box 2.3), there are\nsignals that labour markets could soon face a significant shakeup with both positive and negative effects.", "Technological progress, falling costs, and increasing availability of workers with genai skills indicate that\nOECD economies could be on the brink of an genai revolution (OECD, 2023 [83] ).\n\nAdvances in genai\nhave heightened focus on the potential impact of genai on labour markets.\n\nIn addition to language models,\nmodes such as image, audio, and video generation are receiving increased attention.\n\nMultimodal\ncapabilities combining text and image generation, such as those of GPT-4 released by OpenAI in March\n2023, could further broaden the range of actions which genai systems perform, and thus their potential labour\nmarket impacts.", "**Box 2.3. genai in the 2023 edition of the OECD Employment Outlook**\n\nThe 2023 edition of the OECD Employment Outlook, the OECD\u2019s flagship publication on labour market\ndevelopments in OECD countries, includes analysis of the impact of genai on the labour market and of\npolicy measures to benefit from genai in the workplace while addressing its risks.\n\nThe Outlook finds that\nthe net impact of genai in general on employment to be ambiguous.\n\nWhile genai displaces some human labour\n(displacement effect), the greater productivity it brings (productivity effect) could increase labour\ndemand.\n\ngenai can also create new tasks, resulting in the creation of new jobs for which human labour has\na comparative advantage (reinstatement effect), particularly for workers with skills complementary to\ngenai.\n\nTo date, genai has mainly impacted the quality of jobs \u2013 generally, in positive ways.\n\nFor example, worker\nwell-being and satisfaction increased through the reduction of tedious or dangerous tasks.\n\nHowever,\nsome risks, such as increased work intensity and stress, are materialising.\n\nThere are also risks to\nprivacy and fairness.\n\nWorkers in finance and manufacturing whose employers uses genai worry about their\nprivacy and these risks tend to be greater for socio-demographic groups already disadvantaged in the\nlabour market.\n\nWhile the _Employment Outlook_ found little evidence of significant negative effects from genai on the\nquantity of jobs, this research mostly predates the latest public release of genai applications.\n\nNegative employment effects of genai might take time to materialise: genai adoption is still relatively low and/or\nfirms might prefer to rely on voluntary workforce adjustments i.e., attrition.\n\nSource: (OECD, 2023 [83] ).\n\n**_Language models perform increasingly well on standard aptitude tests_**\n\nMeasures of genai exposure evaluate the overlap between tasks performed in a job and those genai could\ntheoretically do.\n\nThose examined in the Employment Outlook show that genai had advanced in performing\nnon-routine cognitive tasks such as information-ordering, memorisation, and perceptual speed even before\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **21**\n\nrecent advances in genai applications (OECD, 2023 [83] ).\n\ngenai tools can already answer 80% of the\nliteracy questions and two-thirds of the numeracy questions in the OECD Survey of Adult Skills of the\nProgramme for International Assessment of Adult Competencies (PIAAC).\n\nExperts believe genai will be able\nto solve the entire PIAAC literacy and numeracy tests by 2026.\n\nThe strong performance of GPT-3.5 and\nGPT-4 on the Bar Exam (used by US jurisdictions to qualify lawyers) and other standard tests surprised\nmany (Figure 2.3).\n\n22", "**Figure 2.3.\n\nGPT performance on academic and professional exams**\n\nSource:  .\n\n**_Generative genai could impact higher-skilled jobs_**\n\nThe occupational range and extent of genai exposure might rapidly become larger as genai use is\nincreasingly incorporated (OECD, 2023 [83] ) in jobs such as legal research, technical support and fixing\ncomputer bugs, or customer service.\n\nHigh-skilled occupations have been most exposed to recent advances in genai, including business\nprofessionals; managers; science and engineering professionals; and legal, social and cultural\nprofessionals (OECD, 2023 [83] ).\n\nNevertheless, low-skilled workers are still the most exposed to the risk of\nautomation, at least for the time being.\n\nWhile the literature on labour-market effects caused by genai is recent and not necessarily peer\nreviewed yet, research by OpenAI suggests that genai systems could further expose higher-income\n\nOECD genai PAPERS\n\n\n-----\n\n**22** | INITIAL POLICY CONSIDERATIONS FOR genai\n\njobs to automation (Eloundou et al., 2023 [84] ), with the impact on task-exposure potentially over twice as\nlarge as that of other powerful deep-learning algorithms.\n\nSimilarly, researchers examining the capabilities of large language models (LLMs) found greater exposure\nfor industries that recruit employees with higher education (Felten, Raj and Seamans, 2023 [85] ).\n\nThey found\nthat the sectors most affected are legal services, securities, commodities, and investment.\n\nProfessions\nbased on writing and coding would be more exposed to the risk of displacement from LLMs than those that\nrely on science or critical thinking (Eloundou et al., 2023 [84] ).\n\n**_Language models may benefit lower skilled workers comparatively more_**\n\nResearch by the Massachusetts Institute of Technology found that ChatGPT significantly reduces the time\npeople spend conducting tasks while improving output quality (Noy et al., 2023 [86] ).\n\nIt also showed the tool\nto have a greater impact on the productivity of workers with lower aptitude, such as junior employees,\nallowing them to catch up with their more senior colleagues and reducing inequality in the workplace.\n\nChatGPT was not found to improve workers\u2019 skill levels but to reduce the effort needed.\n\nSimilarly, other\nresearch has found that genai tools could increase low-skilled workers\u2019 productivity by an estimated average\nof 14 percentage points, as opposed to high-skilled workers\u2019 productivity, which would generally remain\nunaffected (Brynjolfsson, Li and Raymond, 2023 [87] ).\n\nThe findings in these sources are generally based on\nlimited experiments and thus should not be overly generalised.\n\nSimilarly, coding assistants like GitHub\u2019s Copilot decrease the time spent by software developers on a\nspecific test task by over 50%.\n\nCopilot provides snippets and allows for autocompleting code.\n\nIn an\nexperiment, this reduced developers\u2019 time spent implementing an HTTP server in JavaScript by 55.8%\nover a control group without access to the coding assistant (Peng et al., 2023 [88] ).\n\nThe increased efficiency\ncan increase job satisfaction (Noy et al., 2023 [86] ) or, in the case of Copilot, potentially lower entry barriers\nfor roles in software development (Peng et al., 2023 [88] ).\n\n**_A significant proportion of occupations could be impacted_**\n\nThe OECD finds that occupations at the highest risk of automation from genai account for about 27% of\nemployment and that a significant share of workers (three in five) worry about losing their jobs entirely to\ngenai in the next ten years \u2013 particularly those who already work with genai (OECD, 2023 [83] ).\n\nThe advent of the latest genai technologies is sure to heighten automation concerns across a wide\nrange of job categories.\n\nResearch on language-based genai finds that 32.8 percent of jobs in the\nInternational Standard Classification of Occupations (ISCO) could be impacted on a full scale, 36.5 percent\ncould be partially impacted, and only 30.7 percent would not be affected by genai models\n(Zarifhonarvar, 2023 [89] ).\n\nThis puts pressure organisations to adapt to genai and support their\nworkforces, and on policymakers to steer labour market developments and transitions.\n\n**_Policy is needed to reap labour market benefits and address risks and unknowns_**\n\nAs emphasised in the OECD Employment Outlook (OECD, 2023 [83] ), the benefits and risks of genai in the\nworkplace, coupled with its rapid pace of development and deployment, underscore the need for decisive\npolicy action to reap the benefits it offers and address the risks for workers\u2019 rights and well-being.\n\nThere is\na need to enable both employers and workers to reap the benefits of genai while adapting to it, notably through\ntraining and social dialogue.\n\nThe adoption of genai on tasks and jobs will change skill needs.", "The adoption of genai on tasks and jobs will change skill needs.\n\nIn the OECD genai Surveys of Employers and\nWorkers, many companies using genai say they provide training for genai, but that lack of skills remains a major\nbarrier to adoption (OECD, 2023 [83] ).\n\nCompanies also report that genai has increased the importance of human\nskills even more than that of specialised genai skills.\n\nCountries have taken some action to prepare their\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **23**\n\nworkforce for genai-induced job changes, especially through skilling efforts, but initiatives remain limited in\nscale (OECD, 2023 [83] ).\n\nLess is known about training efforts focused on genai, though its needs\ncould overlap with genai more broadly.\n\nOECD work also shows that labour market outcomes are better when\nthe adoption of technologies is discussed with workers (OECD, 2023 [83] ).\n\nOrganisational change strategies are needed, including building awareness of what is needed to bridge\nemerging skills gaps (transversal skills), improve current skills (re-skilling), and develop new ones (upskilling), while encouraging openness towards genai technologies and working to prevent anxiety around\nmisperceptions (Morandini et al., 2023 [90] ).\n\nAt the same time, there is an urgent need for policy action to\naddress the risks that genai can pose when used in the workplace \u2013 in terms of privacy, safety, fairness and\nlabour rights \u2013 and to ensure accountability, transparency, and explainability for employment-related\ndecisions supported by genai.\n\n**_The implications of genai on labour markets require close monitoring_**\n\nThere remain many unknowns about the longer-term advancements and implications of genai for\nthe labour market.\n\nFor example, will the impact of genai on job automation be larger than what has\nbeen seen so far?\n\nWill the integration of LLMs and other genai models in other software systems\nthrough application programming interfaces (APIs) accelerate labour market effects?\n\nThe OECD will\ncontinue to monitor the impact of genai on the labour market, and the policy response to ensure responsible\nand trustworthy use of genai in the workplace.\n\nOECD genai PAPERS\n\n\n-----\n\n**24** | INITIAL POLICY CONSIDERATIONS FOR genai", "# 3\n\nForecasting the future of genai (genai) is difficult, but\nseveral proxies can inform exploration by looking back on developments in\nLLMs and image-generating genai systems.\n\nIn the near term, genai\ncan exacerbate challenges as synthetic content with variable quality and\naccuracy proliferates in digital spaces and is then used to train subsequent\ngenai models, triggering a vicious cycle.\n\nOver the longer term,\nemergent behaviours such as increased agency, power-seeking, and\npursuing hidden sub-goals to achieve a core objective might not align with\nhuman values and intent.\n\nIf manifested, such behaviours could lead to\nsystemic harms and collective disempowerment.\n\nThese could demand\nsolutions on a larger, more systemic scale, and are the topic of ongoing\nOECD work, including a new workstream on genai Futures.", "**Development trajectories of large-language and image-generating models**\n\n**_Generative genai model sizes are increasing relentlessly, yet few-shot learning is also_**\n**_developing_**\n\nIn July 2020, research by OpenAI demonstrated the capability of its then-latest LLM, GPT-3, to learn from\njust a few demonstrations of a given task (\u201cfew-shot learning\u201d) as opposed to the tens, even hundreds of\nthousands of examples these models had needed before (Brown et al., 2020 [91] ).\n\nThis was accomplished\nby dramatically scaling up model size \u2013 in this case, to 175 billion parameters, or ten times larger than\nprevious language models (Kaplan et al., 2020 [92] ).\n\nIncreasing model size appears to be the preferred\napproach, with OpenAI\u2019s latest GPT-4 model estimated to have surpassed 1 trillion parameters (Albergotti,\n2023 [93] ).\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **25**\n\n**_Training smaller models on higher-quality data is another trend._**\n\nWhile increasing parameter number has been the general focus, a parallel path is emerging in training\nsmaller models on higher-quality data.\n\n23 The benefits of this approach include democratising model\naccess.\n\nNevertheless, scaling-up model size is widely expected to continue because underlying hardware\ncapabilities remain able to grow and expand core capabilities.\n\nBut critics of building bigger models, the\nunchecked narrative of scaling laws, put forward that knowledge and reasoning-based approaches can\nhelp (Marcus, 2020 [94] ).\n\n**_The recent progress in quality of image-generation models has also been dramatic._**\n\nImage-generation models like Stable Diffusion (Stability genai), Midjourney (Midjourney, Inc.), DALL-E 2\n(OpenAI), Parti, Muse, and Imagen (Google), create images at quality levels beyond what was even\n\n24\nrecently imaginable (Maerten and Soydaner, 2023 [95] ).\n\nA comparison of images (Figure 3.1) generated\nby Midjourney using the same prompt over five model iterations from July 2022 to March 2023 offers a\nfascinating display of improving image quality (Dearing, 2023 [96] ).\n\nThis evolution over a very short time\nframe combined with user-friendly interfaces suggests the potential capabilities of other emerging\ngenerative-genai systems.\n\nBetter text-generation performance on tasks involving language models is likely going forward, given that\nscaling laws still apply and training smaller models on larger amounts of data for text have demonstrated\nevidence for increasing language models\u2019 capabilities.\n\nRapid developments seem to be even more striking\nin image generation and systems that draw from sequential data, such as video, music, and voice\napplications.\n\nThe short term with likely bring growing impacts from applications that build on genai\ntechnologies and the industries that will adopt them.", "**Figure 3.1.\n\nComparison of Midjourney images from v1 to v5**\n\nNote: Image generated using the prompt \u201cpixiv, hyper detailed, harajuku fashion\u201d.\n\nSource:  .\n\nOECD genai PAPERS\n\n\n-----\n\n**26** | INITIAL POLICY CONSIDERATIONS FOR genai\n\n**genai markets are projected to continue growing rapidly in key areas.\n\n**\n\nMarket and investment research complements technological developments in providing information on the\npossible trajectories of genai systems in the short, medium, and long terms.\n\nInvestment banks, consulting firms, and researchers report that genai will cause massive economic\nimpacts in the coming years:\n\n-  Goldman Sachs estimates that genai could account for a 7 percent rise in global gross\ndomestic product (GDP) over ten years (Goldman Sachs, 2023 [97] ).\n\n-  McKinsey & Company estimates that genai could add USD 2.6-4.4 trillion per year across\n63 use cases, for an increase in genai\u2019s total economic effects of 15-50 percent (McKinsey, 2023 [98] ).\n\n-  Polaris estimates growth of the global generative-genai market at a compound annual rate of\n34.2 percent, from USD 10.6 billion in 2022 to USD 200.7 billion by 2032 (Polaris, 2023 [15] ).\n\nAt present, genai is at an early developmental stage, requiring large investments in R&D and a\nskilled but scarce workforce to take it to the next stage of maturity.\n\nFurther growth is expected to come\nfrom audio synthesis, data pre-processing, image compression, noise reduction from visual data, medical\nimaging, and image classification, especially in healthcare (Polaris, 2023 [15] ).\n\n**_Application areas include chip and parts design, material sciences, and entertainment._**\n\nGartner, a market research firm, lists other drivers of growth from applying genai to chip design,\ngenerative design of parts used by industries such as automotive, aerospace, and defence, and to material\nsciences (Burke and Wiles, 2023 [99] ).\n\nGartner notes that start-ups building a business on genai\nhave received more than USD 1.7 billion in funding over the last three years.\n\nThe media and entertainment sector (including advertising) accounts for the largest revenue share from\n).\n\nCompanies with a competitive edge in genai include wellknown, large technology companies, enterprise software providers, genai companies in niche sectors (e.g., genai so far (Polaris, 2023 [15]\nlegal contract automation, video creation, synthetic data generation, and the arts), and companies\nproviding genai compute such as semiconductors and supercomputing infrastructure, crucial to leveraging\ngenai\u2019s data-rich environments.", "**Potential future concerns and risks**\n\n**_Generative genai is expected to exacerbate existing issues associated with genai._**\n\ngenai can exacerbate issues already on the radar for the OECD and governments and introduce\nnew risks and safety concerns from the race to release novel genai systems and their technological\nunderpinnings.\n\nNear-term issues, often rooted in present-day opportunities and challenges, which policy\nmakers should consider due to their urgency and potential for impact include, but are not limited to:\n\n-  labour-market impacts, including job displacement, changing skills needs, labour-market\ninclusiveness, and promoting trustworthy use of genai in the workplace\n\n-  information pollution \u2013 including the reduced quality of genai outputs due to exponential\ngrowth in genai-generated content ingested as training data by other genai systems in a vicious cycle \u2013\nand the consequent decreasing informational relevance of the Internet (Mart\u00ednez et al., 2023 [100] )\n\n-  genai coding assistants enabling automated cyber-security attacks (Weidinger et al., 2022 [29] )\n\n-  genai\u2019s role in mass surveillance and censorship (Weidinger et al., 2022 [29] )\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **27**\n\n-  overreliance and dependency on genai systems (Weidinger et al., 2022 [29] ) (OpenAI,\n2023 [36] )\n\n-  copyright issues for new creations and from training on copyrighted works\n\n-  academic and creative dishonesty, such as plagiarism (Ka Yuk Chan, 2023 [101] )\n\n-  concentration of genai resources (data, hardware, talent) among few multinational tech companies\nand governments (Lorenz and Saslo, 2019 [102] ); (Chawla et al., 2023 [3] )\n\n-  disparate access to genai across societies, countries, and world regions\n\n-  the need for stronger efforts to curate diverse, high-quality datasets (Bender et al., 2021 [58] );\n(Bender and Koller, 2020 [45] )\n\n-  mis- and disinformation, hate speech, bias, and discrimination by increasingly powerful and realistic\ngenai outputs\n\n-  genai\u2019s ecological footprint and natural resources consumption from the tremendous\namounts of computing power required for deep learning (Stoken-Walker, 2023 [103] ).\n\n**_Risks from emerging model behaviours are also critical to address._**\n\nFor many years, academic and applied researchers and civil society actors have been steering genai models\nto align with human values to address a range of potential societal risks (Weidinger et al., 2022 [29] );\n(OpenAI, 2023 [36] ); (Chan et al., 2023 [104] ).\n\nMore recent genai safety research raises issues specifically around\ngenai models exhibiting unforeseen \u201cemergent behaviours\u201d, such as increased agency, powerseeking, and reward-hacking.\n\nThough as mentioned earlier, there is debate over the extent to which these\nemergent abilities are real versus a \u201cmirage\u201d (Schaeffer, Miranda and Koyejo, 2023 [13] ).\n\nResearchers identify four characteristics that intensify the agency of algorithmic systems (Chan et al.,\n2023 [104] ):\n\n-  **Under-specification** \u2013 the degree to which the algorithmic system can accomplish a goal provided\nby operators or designers, without a concrete specification of how the goal is to be accomplished 25\n\n-  **Directness of impact** \u2013 the degree to which the algorithmic system\u2019s actions affect the world\nwithout mediation or intervention by a human (i.e., without a human in the loop)\n\n-  **Goal-directedness** \u2013 the degree to which the system is designed/trained to achieve a particular\nquantifiable objective\n\n-  **Long-term planning** \u2013 the degree to which the algorithmic system is designed/trained to make\ndecisions that are temporally dependent upon one another to achieve a goal and/or make\npredictions over a long time horizon\n\nCombining these factors can increase agency further.\n\nTwo major harms that can arise from increased\nagency of algorithmic systems:\n\n-  **Systemic, delayed harms** \u2013 non-immediate harms that can be \u201cdestructive, long-lasting, and hard\nto fix\u201d, such as social-media recommender systems based on reinforcement-learning.\n\nSuch\nalgorithms optimise for metrics that can \u201cchange or manipulate user\u2019s internal states (e.g.\n\npreferences, beliefs, psychology)\u201d (Chan et al., 2023 [104] ).\n\n-  **Collective disempowerment** \u2013 the perceived danger that model capabilities will perform\nincreasingly important functions in society, taking power away from humans.\n\nThis could take the\nform of gradually ceding decision-making to genai systems.\n\nIts second impact is\nintensifying concentrations of power and the ability to reap the benefits of genai \u2013 already a concern.", "Its second impact is\nintensifying concentrations of power and the ability to reap the benefits of genai \u2013 already a concern.\n\ngenai safety researchers are explicitly looking into another emerging behaviour of concern to the alignment\nbetween genai objectives and human preferences: power-seeking, in which goals that provoke power-seeking\nare reinforced during training and pursued more directly and with novel strategies during deployment,\n\nOECD genai PAPERS\n\n\n-----\n\n**28** | INITIAL POLICY CONSIDERATIONS FOR genai\n\nposing new and potentially severe threats to society (Turner et al., 2019 [105] ); (Turner and Tadepalli,\n2022 [106] ); (Krakovna and Kramar, 2023 [107] ); (OpenAI, 2023 [36] ).\n\nMachine-Learning (ML) systems demonstrate two emergent behaviours that could be catalysed by growing\ngenai model capabilities.\n\nIn _reward hacking_ , a model finds unforeseen, and potentially harmful\nways of achieving a goal while exploiting the reward signal (Skalse, Howe and Krueger, 2022 [108] ).\n\nIn\npursuing _instrumental goals_ , a model seeks strategies to attain sub-objectives that help it reach an\nenvisaged goal, which might go against the intent of the developers and envisaged goal (Chan et al.,\n2023 [104] ).\n\nEarly evidence shows this can happen even without explicit instructions by model operators or\ndesigners.\n\nFor example, to solve a CAPTCHA code during initial safety testing, ChatGPT misrepresented\nitself as a vision-impaired human and hired a gig economy worker to solve the CAPTCHA for it.\n\nResearchers find that models trained with reinforcement learning from human feedback (RLHF) are more\nlikely to exhibit behaviours such as persuading developers to not shut off the system, pretending to be\nhuman, and seeking resource acquisition, such as accruing wealth (Perez et al., 2022 [68] ); (Chan et al.,\n2023 [104] ).\n\n**_There is growing debate on the path(s) and timeline towards artificial general intelligence_**\n\nThe increasing capabilities of genai models have prompted reflection in the media and among genai\nresearchers about whether these models would lead to artificial general intelligence (AGI).\n\nSome genai\nresearchers and tech experts did not expect the latest capabilities of genai and its possible\ntrajectories (Dardaman and Gupta, 2023 [109] ).\n\nResearchers at Microsoft put forward that GPT-4 \u201ccould\nreasonably be viewed as an early (yet still incomplete) version of an [AGI] system\u201d (Bubeck et al., 2023 [110] ).\n\nAs touched on earlier in this paper, increased agentic model behaviour as a pathway to AGI was\ndemonstrated by researchers at Stanford University and Google Research who created an environment in\nwhich 25 genai agents interacted over two days and displayed human-like behaviour such as\nreasoning about their research careers or planning about attending social events (Park et al., 2023 [11] ).\n\nThe experiment combined LLMs with interactive agents, which according to the authors, allowed studying\nhuman behaviour through increasingly plausible simulations.\n\nCommentators were quick to point to possible\nAGI behaviour among the genai agents in the experiment.\n\n26 Other research findings discussed\nabove, such as persuading developers to not shut off the system, relate to often-discussed technical and\nphilosophical concerns of control, such as genai systems\u2019 refusal to be shut off, which is beyond the scope of\nthis paper but is being considered in other OECD workstreams (Russell, 2019 [111] ).\n\nThese findings, coupled with research findings\u2014such as the scoring of GPT-4 within the 90 th percentile at\nthe Bar Exam (OpenAI, 2023 [36] ), and finding this model to having reached theory of mind-like cognition\nlevels of a nine-year-old (Kosinski, 2023 [112] ), help to drive some arguments that that genai is\nmoving towards AGI.\n\n27\n\nThe potential benefits and risks from AGI deserve attention because of their potentially broad societal and\nglobal impacts.\n\nLikewise, narrower genai systems deserve focus due to potentially imminent\nimpacts that could be just as significant as those of AGI.\n\nGovernments should consider the positive and\nnegative implications of both, leveraging strategic foresight and inclusive, long-term policy-making tools.", "**Risk mitigation measures**\n\nFuture risks of genai could demand solutions on a larger, more systemic scale.\n\nThese include\nregulation, ethics frameworks, technical genai standardisation, audits, model release, and access strategies,\namong others.\n\nThese and other measures are the topic of a workstream under the G7 Presidency, the\nresults of which will be forthcoming.\n\nOECD genai PAPERS\n\n\n-----\n\nINITIAL POLICY CONSIDERATIONS FOR genai | **29**", "# 4\n\ngenai models that generate text, image, video, and audio (e.g., music, speech) content are\nadvancing at breakneck speed.\n\nThis poses endless possibilities, demonstrated across a growing array of\ndomains.\n\nHowever, the technology also poses numerous challenges and risks to individuals, companies,\neconomies, societies, and policymaking around the globe, ranging from near-term labour-market disruption\nand disinformation to potential long-term challenges in controlling machine actions.\n\nThe future trajectories\nof genai are difficult to predict, but governments must explore them to have a hand in shaping\nthem.\n\nTechnological development of genai is in its nascent stage, with first-movers such as established\ntech players like Microsoft, Google and Meta, and private research labs like OpenAI, Midjourney, and\nStability.genai.\n\nThese firms are pursuing multiple strategies to capitalise on genai and, to some extent,\nmitigate its downsides.\n\nPublic discussion about genai is less than a year old.\n\nWith technology companies bringing\ngenai applications to market, policy makers around the globe are grappling with its implications.\n\nApplied and academic researchers are engaged in a fierce debate about how to handle genai, from\nmitigation measures in model design and development, through market launch and beyond.\n\nThe path ahead is unclear and replete with differing perspectives.\n\nOne extreme argues for a moratorium\non experiments with genai more advanced than GPT-4 (Future of Life Institute, 2023 [113] ) while the\n\n28\nother believes that the supposed existential risks of genai are overhyped (LeCun and Ng, 2023 [114] ).\n\nOthers\u2014\nperhaps most\u2014fall somewhere in between.\n\nRegardless of ideological stance on these issues, there is an\nurgent need for further research to prepare for different possible generative-genai future scenarios.\n\nGiven the\ngreat uncertainty and potentially large impact the technology could have at both micro and macro levels,\npolicy makers must remain informed and prepared to take appropriate action through forward-looking genai\npolicies.\n\nThe OECD intends for this paper to serve as a steppingstone to help governments make progress in this\narea.\n\nThe OECD.genai Policy Observatory and its new OECD Expert Group on genai Futures 29 will serve\nalongside other relevant bodies as a forum for dialogue on these topics, generating insights and actionable\nrecommendations for governments.\n\nComplementary work is also underway through other OECD initiatives,\nsuch as work conducted under the Employment, Labour and Social Affairs Committee, the OECD DIS/MIS\nResource Hub 30 and the horizontal OECD Going Digital initiative.\n\n31\n\nOECD genai PAPERS\n\n\n-----\n\n**30** | INITIAL POLICY CONSIDERATIONS FOR genai", "**Summary**\n\nThe Government of Jersey Children Young People Education and Skills (CYPES) Department\nrecognises the potential of genai (genai), including genai, in the education sector\nwhile acknowledging the need for responsible and informed implementation.\n\nThis policy aims to\noutline the department's position on the use of genai and provide evidence-based guidelines for its\napplication.\n\ngenai refers to a branch of genai that focuses on creating or generating new\ncontent, such as images, videos, text, or audio, that is not directly sourced from existing data.\n\nIt\ninvolves training machine learning models to understand patterns and generate original content\nbased on those patterns.", "**Key Messages**\n\nThe advancements in genai technology have made it accessible to the general public,\nresulting in the production of genai-generated content.\n\nThis development brings both opportunities and\nchallenges to the education sector.\n\nWhen utilised appropriately, technology, including genai, holds the potential to alleviate the\nworkload within the education sector, enabling teachers to allocate more time to delivering excellent\ninstruction.\n\nEducational institutions such as schools, colleges, universities, and awarding organisations must\ntake necessary measures to prevent malpractice, including any misconduct related to the use of\ngenai and other emerging technologies.\n\nSafeguarding data, resources, staff, and students remains of utmost importance in the education\nsector.\n\n**Personal and sensitive data should never be entered into genai tools to ensure**\n**its protection** .\n\nAdditionally, educational institutions should regularly **assess and enhance their**\n**cybersecurity protocols** , and provide training to all staff, considering that genai may\ncontribute to more sophisticated and credible cyber-attacks.\n\nMoreover, it is imperative for\neducational institutions to safeguard their students from harmful online content, including content\ngenerated by genai.", "**Background**\n\nThe release of ChatGPT by OpenAI in November 2022 has generated significant interest among\neducationalists in genai (genai) based on large language models (LLMs) like\nChatGPT and Google Bard.\n\nThese genai tools have the ability to respond to prompts, answer questions,\nand complete written tasks in a manner that resembles human interaction.\n\nAdditionally, generative\n\nVersion: 1 1\n\n\n-----\n\ngenai can produce various forms of content, including audio, code, images, video, and simulations.\n\nIt is\nworth noting that this technology is not entirely new and can already be found in everyday\napplications such as email spam filtering, media recommendation systems, navigation apps, and\nonline chatbots.\n\ngenai tools excel at quickly analysing, structuring, and generating text, as well as converting\ntext prompts into audio, video, and images.\n\nHowever, it is crucial to recognize that the content they\nproduce may not always be accurate or appropriate, as they often lack consideration for truthfulness\nand can generate biased information.\n\nWhile access to genai tools can facilitate certain written tasks, it is essential to understand\nthat these tools cannot substitute the knowledge stored in long-term memory.\n\nProficiency in\ngenai relies on the ability to write clearly, understand the domain being addressed, and have\nexisting knowledge to draw upon.\n\nTo evaluate the results, one needs a schema or framework against\nwhich to compare them.\n\nTherefore, genai tools can streamline certain aspects of writing\ntasks, but they cannot replace the judgment and deep subject knowledge of human experts.\n\nIn light of these considerations, it is more crucial than ever for the education system to prioritise the\nacquisition of knowledge, expertise, and intellectual capability among students.\n\nWhile leveraging\ntechnology effectively, safely, and appropriately, the education sector should seize the opportunities\nit provides to deliver excellent education that prepares students to contribute meaningfully to society\nand the future workplace.", "**Ethical Framework**\n\nThe ethical framework should be followed for the use of genai in education.\n\nThe purpose of the\nframework is to ensure the well-being, privacy, and safety of students, teachers, and users by\nupholding principles of fairness, transparency, accountability, and inclusivity.\n\n|Objective|Criteria|Col3|Checklist|\n|---|---|---|---|\n|Achieving Educational Goals.\n\ngenai should be harnessed to accomplish clearly defined educational objectives, supported by robust societal, educational, or scientific evidence that demonstrates its potential to benefit learners.|1.1|Outline and define the educational objective for which genai is being deployed to accomplish.|Have you clearly identified the educational goal that is to be achieved using genai?|\n||1.2|Explain how each applicable genai resource is equipped to accomplish the designated educational objective.|Can you explain why a particular genai resource has the capacity to achieve the educational goal specified above?|\n||1.3|Clearly specify the desired effects or outcomes of utilising genai.|What impact do you expect to achieve using genai, and how will you measure and assess this impact?|\n||1.4|Insist that any measures of student performance are aligned with recognised and accepted test instruments and/or measures that are based|What information have you received from the suppliers, and are you satisfied that measures of student performance are aligned with recognised and accepted test instruments and/ or measures that are based on societal,|\n\n\nVersion: 1 1\n\n\n-----\n\n|Col1|1.5|on societal, educational, or scientific evidence|educational, or scientific evidence?|\n|---|---|---|---|\n||1.6|Continuously assess and analyse to what extent the intended effects and stated objectives are being realised.|How will you monitor and assess the extent to which the intended impacts and objectives are being achieved?|\n||1.7|If the outcomes of employing genai as planned are found to be unsatisfactory, determine whether it is attributed to the resource's design, its application, or a combination of both elements.\n\nDevelop a well- structured action plan to enhance the achieved impacts.|If the impacts of using genai as intended were not satisfactory, why was this the case?\n\nWhat steps will you take to achieve improved impacts?|\n\n\n\n\n\n\n\n|Objective|Criteria|Col3|Checklist|\n|---|---|---|---|\n|Forms of Assessment.\n\nUtilise genai to evaluate and acknowledge a wider spectrum of learners' abilities and talents.|2.1|Determine how genai can be employed to offer valuable insights into a diverse array of knowledge, comprehension, competencies, and personal well-being growth, all of which are supported by evidence-based practices.|What knowledge and understanding, and which skills are you intending to measure using genai?\n\nWhich features of genai will enable these to be assessed, and how will assessments be conducted in practice?|\n||2.2|Explore and demonstrate the ways in which genai resources can be utilised to enrich and showcase the significance of formative assessment methods, studying learning processes alongside outcomes, and fostering social and emotional development, as well as learner well-being.|In what ways is genai being used to enhance and demonstrate the value of formative approaches to assessment, studying learning processes as well as outcomes, and supporting social and emotional development and learner well- being?|\n|Administration and Workload.\n\ngenai should enhance the capabilities of organisations while|3.1|Discover potential avenues in which genai could be employed to enhance existing procedures within the school/college.|Which processes could be improved using genai, and how do you intend to use genai to improve these processes?|\n\n\nVersion: 1 1\n\n\n-----\n\n|upholding the value of human relationships.|3.2|Perform a comprehensive risk assessment and implement it to ascertain if and how integrating genai to enhance current processes within your organisation could potentially marginalise or adversely affect educators and other pertinent practitioners.|Will the implementation of the actions resulting from this risk assessment guarantee that educators and/or other relevant practitioners are not undermined or marginalised due to the utilisation of genai?|\n|---|---|---|---|\n||3.3|Develop and execute a change management strategy, ensuring full institutional commitment for the successful implementation of genai in the school/college.|Will the change management strategy, coupled with institutional commitments, facilitate the effective utilisation of genai throughout the school/college?|\n||3.4|Monitor and evaluate the extent to which processes are being improved|How will the extent to which processes are being improved be monitored and assessed?|\n\n\nVersion: 1 1\n\n\n-----\n\n|Objective|Criteria|Col3|Checklist|\n|---|---|---|---|\n|Equity.", "genai systems must be employed in manners that foster fairness and impartiality among diverse groups of learners, ensuring no discrimination is directed towards any group.|4.1|Analyse how the use of genai can help mitigate the digital divide within the group of learners for whom you are responsible, ultimately reducing the disparities.|Determine which can access and benefit from the genai technology?|\n|Autonomy.\n\ngenai systems should be used to increase the level of control that learners have over their learning and development|5.1|If a predictive genai system legitimately foresees an unfavourable outcome (e.g., a student facing expulsion, failing an exam, or dropping out of a program), refrain from holding the individual accountable for an outcome that has not yet occurred.\n\nInstead, proactively take measures to prevent the unfavourable outcome from materialising.|Reflect on possible unfavourable outcomes that an genai system might predict.\n\nExplore the potential harmful actions that could be taken based on these predictions.\n\nThen, carefully consider positive and proactive steps that could be taken to prevent the predicted outcomes from becoming reality.|\n\n\nVersion: 1.1\n\nFirst published 09/10/2023.\n\n-----\n\n|Objective|Criteria|Col3|Checklist|\n|---|---|---|---|\n|Privacy.\n\nA balance should be struck between privacy and the legitimate use of data for achieving well-defined and desirable educational goals (see Annex Section 6 for justification)|6.1|Ensure compliance with relevant legal frameworks to ensure that the use of pupil data for the stated purposes is permitted|Can you confirm that your organisation complies with all relevant legal frameworks?|\n||6.2|Where the use of genai could be surveillance of learners, provide a clear justification of why this use of genai benefits learners either directly or indirectly.|What uses of genai could be surveillance of learners, and how could these benefit learners - either directly or indirectly?|\n||6.3|Ensure that where schools/colleges have chosen, or are obligated to assess students on a continuous basis (potentially as a replacement for summative assessments), there are designated safe spaces in which learners are not assessed|In contexts where schools/colleges have chosen or are obligated to assess students on a continuous basis, how have you ensured that there are designated safe spaces in which learners are not assessed?|\n||6.4|Where a system processes data (including but not limited to personal or sensitive data) that could be considered health data insist that suppliers provide relevant information to confirm that this data is required for educational purposes and that processing this data will benefit learners|What information have you received from the suppliers, and are you satisfied that this data is required for educational purposes and that processing this data will benefit learners?|\n\n\nVersion: 1.1\n\nFirst published 09/10/2023.\n\n-----\n\n|Objective|Criteria|Col3|Checklist|\n|---|---|---|---|\n|Transparency and Accountability.\n\nHumans are ultimately responsible for educational outcomes and should therefore have an appropriate level of oversight of how genai systems operate|7.1|Conduct a risk assessment to establish whether genai resources could undermine the authority of practitioners and disrupt accountability structures, and act based on the risk assessment|Will implementing the actions arising from this risk assessment ensure that the authority of educators and/or other relevant practitioners is not undermined, and that accountability structures are not disrupted as a result of using genai?|\n||7.2|Determine if there are any trade-offs between accuracy and understandable explanations or justifications for the decisions and actions taken.|Where compromises have been made, are you satisfied with the justification you have received?|\n|Informed Participation.\n\nLearners, educators and other relevant practitioners should have a reasonable understanding of genai and its implications|8.1|Provide students with instruction on genai and its societal and ethical implications.|Where in the curriculum, or when during extracurricular time, will students be taught about this?\n\nWhat content will they learn?|\n||8.2|Provide educators and/or other practitioners ample training to equip them with the necessary skills to utilise genai resources effectively, judiciously, and confidently.\n\nWithin this training, emphasise the importance of examining the decisions and behaviours exhibited by genai systems, guarding against unwarranted reliance or unquestioning deference.|Clarify when and where in the curriculum or during extracurricular activities students will receive instruction on this topic.\n\nAlso, outline the specific content they will learn as part of the instruction.|", "**Authenticity**\n\nAuthenticity holds significant importance in the context of student or staff work utilising\ngenai, primarily due to its role in preserving integrity, upholding academic honesty,\nand maintaining ethical standards.\n\nAuthenticity serves as a pillar for maintaining academic integrity.\n\nIt is through authentic work\nthat one can genuinely reflect their knowledge, skills, and efforts, thereby reinforcing the\nfundamental principles of academic integrity.\n\nBy promoting fair evaluation, authentic work\nensures that individuals receive due recognition and rewards based on their own abilities\nand achievements.\n\n-----\n\nThe production of authentic work facilitates the process of learning, critical thinking, and\nproblem-solving for students.\n\nAuthenticity engages individuals in actively participating in\nthese cognitive processes, enabling them to develop their skills, broaden their knowledge,\nand enhance their understanding of the subject matter at hand.\n\nFailure to attribute or\nacknowledge the use of genai in work creation raises ethical concerns, particularly\nin relation to plagiarism.\n\nThe absence of proper attribution undermines the principles of\noriginality, intellectual property rights, and fairness and honesty.\n\nEmphasis should be placed on authenticity when utilising genai in the creation of\nwork.\n\nThis production cultivates a culture of honesty, intellectual integrity, and ethical\nconduct within educational and professional environments.\n\nThis prioritisation serves as a\nfoundation for upholding academic standards, nurturing individual growth, and reinforcing\nethical principles.\n\nThis policy outlines the position and guidelines for successful use of genai.\n\nShould\nit be determined that any of the criteria can not be adequately met or considered in full the\nuser will be subject to Acceptable Use policy defined for employees by the Government of\nJersey or by the school/college for all other users.\n\nUseful documents:\n\n\n1. genai Department for Education UK - genai in\n\n\neducation - GOV.UK ()\n\n\n2. genai Risk Management Framework \u2013 NIST - genai Risk Management Framework | NIST\n3.\n\nUNESCO genai ethics - Ethics of genai | UNESCO\n4.\n\nThe Institute for Ethical genai in Education - The-Institute-for-Ethical-genai-in-Education-\n\n\nThe-Ethical-Framework-for-genai-in-Education.pdf (buckingham.ac.uk)\n\n\nOther Policy documents:\n\n1.\n\nAcceptable Use Policy - GoJ\n\n\n-----", "**1.\n\nAchieving Educational Goals**\n\n1.1 Define the Educational Objective: The school wants to use ChatGPT to provide real-time\ninformation on topics discussed in class and to assist students with research and assignment\nqueries.\n\n1.2 Selection of genai Resources: ChatGPT is selected for its ability to answer a wide range of\ntopics and its user-friendly interface.\n\n1.3 Desired Outcomes: Improved student engagement, faster responses to queries, and\nenriched classroom discussions.\n\n1.6 Continuous Assessment: Track student performance and feedback to determine if the\nintroduction of ChatGPT has a positive impact on learning outcomes.", "**4.\n\nEquity**\n\n4.1 Mitigate Digital Divide: Ensure all students have equal access to ChatGPT, providing\ndevices or dedicated sessions for those without personal access.\n\n5.\n\n**Autonomy**\n\n5.3 Predictive Measures: If ChatGPT predicts a student might struggle based on their queries,\nuse that data to provide additional support rather than penalize the student.\n\n-----\n\n6.\n\n**Privacy**\n\n6.1 Compliance with Legal Frameworks: Ensure that student interactions with ChatGPT\nadhere to data protection regulations.\n\n6.2 Justification for Surveillance: If monitoring student interactions with ChatGPT, clearly\ncommunicate the educational benefits to stakeholders.\n\n7 **.\n\nTransparency and Accountability**\n\n7.1 Risk Assessment: Ensure that the introduction of ChatGPT doesn't undermine teacher\nauthority or disrupt the natural learning process.", "**9.\n\nAuthenticity**\n\nStudents should be trained to always cite information gathered from ChatGPT, ensuring\noriginality and academic honesty.\n\nImplementation in Classroom:\n\nDiscussion Aid: During classroom discussions, if there's a topic or fact that needs clarity,\nstudents can use ChatGPT to get immediate information.\n\nAssignment Support: For individual or group projects, students can use ChatGPT for research\nassistance.\n\nReal-time Feedback: If a student doesn't understand a topic, they can get an immediate\nexplanation from ChatGPT.\n\nOutcome:\n\nBy integrating ChatGPT following the ethical framework, _Jersey School_ manages to enhance\nthe learning experience while ensuring that the tool is used responsibly, ethically, and\neffectively.\n\nThis results in a classroom environment that is information-rich, engaging, and in\ntune with modern technology while upholding strong educational and ethical standards.\n\n10\n\n\n-----", "MEMORANDUM\n\n8200.00\n\n\nEffective Date\n\n31 July 2023\n\n\nApproval Date\n\n25 July 2023\n\n\nType of Action\n\nRevision\n\n1.0 SUBJECT: genai Policy\n\n2.0 DISTRIBUTION: Executive Branch Cabinet and Non-Cabinet Agencies\n\n\n3.0 FROM: ____________________________________________\n\nJeff Maxon, Interim Chief Information Technology Officer\n\n4.0 PURPOSE:\n\nThe purpose of this policy is to outline the acceptable use of genai (genai).\n\nThe policy is created to protect the safety, privacy, and intellectual property rights of the State of\nKansas.\n\n5.0 BACKGROUND:\n\nAs genai technology progresses, chatbots, virtual assistants, and other systems based on it\nare becoming more prevalent.\n\nThese can include standalone systems, be integrated as features\nwithin search engines, or be overtly or transparently embedded in all manner of other software\ntools.\n\nExamples include ChatGPT and DALL-E from OpenAI, Microsoft Bing\u2019s chat, Microsoft\n365 Copilot, and Bard from Google.\n\ngenai tools have the potential to enhance productivity by assisting with tasks like drafting\ndocuments, editing text, generating ideas, and software coding.\n\nHowever, these technologies also\ncome with potential risks that include inaccuracies, bias and unauthorized use of intellectual\nproperty in the content generated.\n\nIn addition, content created by genai, and the public availability of\ninformation submitted to the genai, could pose security or privacy concerns.\n\n6.0 ORGANIZATIONS AFFECTED: Executive Branch Cabinet and Non-Cabinet Agencies\n\n7.0 REFERENCES:\n\n7.1 ITEC Policy 7230A\n\n7.2 State of Kansas Social Media Policy\n\n8.0 DEFINITIONS:\n\n\n-----\n\n8.1 genai (genai) uses advanced technologies such as predictive\n\nalgorithms, machine learning, and large language models to process natural language and\nproduce content in the form of text, images, or other types of media.\n\nGenerated content is\ntypically remarkably similar to what a human creator might produce, such as text consisting of\nentire narratives of naturally reading sentences.\n\n8.2 Restricted Use Information as defined in ITEC 7230A.\n\n8.3 Entity is defined as agencies, boards, commissions under the direction of the Governor or\n\nagents and contractors acting on behalf of those agencies, boards or commissions.\n\n9.0 POLICY: This policy shall serve as the primary governing document for usage of generative\n\ngenai technology as a user or related activities by the entities.\n\nWhile any entity may\nimpose additional restrictions through their own policy, such policies must not conflict with the\nprovisions outlined in this policy.\n\n9.1 This policy applies to all business use cases involving the State of Kansas, including but not\n\nlimited to:\n\n9.1.1 development of software code,\n\n\n9.1.2 written documentation (i.e., policy, legislation, or regulations) and correspondence (such\n\nas memorandums, letters, text messages, and emails),\n\n9.1.3 research,\n\n9.1.4 summarizing and proofreading documents,\n\n\n9.1.5 making business decisions that impact short-term or long-term activities or policies and\n\nprocedures.\n\n9.2 Responsibilities\n\n\n9.2.1 Responses generated from genai outputs shall be reviewed by knowledgeable\n\nhuman operators for accuracy, appropriateness, privacy and security before being acted\nupon or disseminated.\n\n9.2.2 Responses generated from genai shall not:\n\n9.2.2.1 be used verbatim,\n\n9.2.2.2 be assumed to be truthful, credible, or accurate,\n\n9.2.2.3 be treated as the sole source of reference,\n\n9.2.2.4 be used to issue official statements (i.e.\n\npolicy, legislation, or regulations),\n\n9.2.2.5 be solely relied upon for making final decisions,\n\n9.2.2.6 be used to impersonate individuals or organizations.\n\n9.2.3 Restricted Use Information (RUI) shall not be provided when interacting with generative\n\ngenai.\n\nRefer to ITEC Policy 7230A Section 9.16 Account Management - RUI.\n\n-----\n\n9.2.4 Material that is inappropriate for public release shall not be entered as input to generative\n\ngenai.\n\nAll information that is provided shall be subjected to the same standard as referenced\nin the State Social Media Policy and shall be treated as publicly available.\n\n9.2.5 Material that is copyrighted or the property of another, shall not be entered as input to\n\ngenai.\n\n9.2.6 genai shall not be used for any activities that are harmful, illegal, or in violation\n\nof state policy or agency acceptable use policy.\n\n9.2.7 Agencies shall ensure contractors disclose in their contracts the utilization of generative\n\ngenai or integrations with genai platforms.\n\n9.2.8 Agency contracts shall prohibit contractors from using State of Kansas RUI or other\n\nconfidential data in genai queries or for building or training proprietary\ngenai programs unless explicitly approved by the agency head with consultation\nfrom the Chief Information Security Officer.\n\n9.2.9 Contractors utilizing genai to build software explicitly for the State of Kansas\n\nmust demonstrate positive control over all data input into the system.", "9.2.9 Contractors utilizing genai to build software explicitly for the State of Kansas\n\nmust demonstrate positive control over all data input into the system.\n\n9.3 Software Code development\n\n\n9.3.1 Software code generated by genai shall only be implemented after the entity has\n\nidentified and mitigated all business and security risks related to its use.\n\n9.3.2 All usage of software code generated by genai shall be annotated.\n\n10.0 RESPONSIBILITIES:\n\n10.1 Heads of entities are responsible for establishing procedures for their organization\u2019s\ncompliance with the requirements of this policy.\n\n10.2 OITS is responsible for the maintenance of this policy.\n\n11.0 HISTORY: This PPM was originally issued #8200.00, dated 19 May 2023.\n\n12.0 CONTACT: Chief Information Technology Architect\n\n\n-----", "# PCAST Working Group on genai\n\nInvites Public Input\n\nThe President\u2019s Council of Advisors on Science and Technology (PCAST) has\n\nlaunched a working group on genai (genai) to help\n\nassess key opportunities and risks and provide input on how best to ensure\n\nthat these technologies are developed and deployed as equitably, responsibly,\n\nand safely as possible.\n\ngenai refers to a class of genai systems that, after being trained on large\n\ndata sets, can be used to generate text, images, videos or other outputs from a\n\ngiven prompt.\n\nThese technologies are advancing rapidly and have the\n\npotential to revolutionize many aspects of modern life.\n\nIn the sciences, these\n\ntools are being used to design new drugs, proteins, or materials, and promise\n\nto accelerate the pace of discovery.\n\nIn medicine, genai has the\n\npotential to provide advice to healthcare professionals.\n\nIn the workplace,\n\nthese tools speed up the writing of computer code, help with composing\n\npresentations, and perform summarization.\n\nHowever, genai models can also be used for malicious purposes, such\n\nas creating disinformation, driving misinformation campaigns, and\n\nimpersonating individuals.\n\nWhen used without safeguards, genai can\n\nstoke polarization, exacerbate biases and inequities in society, and, more\n\ngenerally, threaten democracy by making it difficult for citizens to\n\nunderstand events in the world.\n\nFurther, genai systems can violate\n\nprivacy and undermine intellectual property rights.\n\nAs with many advances\n\nin science and technology, a balance should be found between encouraging\n\ninnovation and pursuing beneficial applications of the technology, and\n\nidentifying and mitigating potential harms.\n\nU.S. government agencies are actively helping to achieve this balance.\n\nFor\n\ninstance, the White House Blueprint for an genai Bill of Rights lays out core\n\naspirational principles to guide the responsible design and deployment of genai\n\n\n-----\n\nreleased the genai Risk Management Framework to help organizations and\n\nindividuals characterize and manage the potential risks of genai technologies.\n\nCongress created the National Security Commission on genai , which studied\n\nopportunities and risks ahead and the importance of guiding the\n\ndevelopment of genai in accordance with American values around democracy\n\n\nand civil liberties.\n\nThe National genai Initiative was\n\nlaunched to ensure U.S. leadership in the responsible development and\n\ndeployment of trustworthy genai and support coordination of U.S. research,\n\ndevelopment, and demonstration of genai technologies across the Federal\n\n\ngovernment.\n\nIn January 2023, the Congressionally mandated National genai\n\n\nResearch Resource (NAIRR) Task Force released an implementation plan for\n\nproviding computational, data, testbed, and software resources to genai\n\nresearchers affiliated with U.S organizations.\n\nThe PCAST Working Group on genai aims to build upon these\n\nexisting efforts by identifying additional needs and opportunities and making\n\nrecommendations to the President for how best to address them.\n\nOver the\n\ncourse of the year, PCAST will be consulting with experts from all sectors,\n\nbeginning with panel discussions at our next public meeting on May 19,\n\n2023.\n\nWe also welcome input from the public on the challenges and\n\nopportunities that should be considered, along with potential solutions, for\n\nthe benefit of the Nation.\n\nPCAST Public Session on genai\n\nWe invite you to watch the public PCAST meeting on May 19.\n\nThis meeting\n\nwill include two expert panel discussions on the topics of 1) genai Enabling\n\nScience and 2) genai Impacts on Society.\n\nThis meeting will be livestreamed and\n\naccessible via the PCAST website.\n\nPCAST Invites Input from the Public on genai\n\nWe also invite written submissions from the public on how to identify and\n\npromote the beneficial deployment of genai, and on how best to\n\nmitigate risks.\n\nSubmissions should be no more than 5 pages in length, provide\n\nactionable ideas, and not include proprietary information or any information\n\ninappropriate for public disclosure.\n\nPlease send your ideas by August 1, 2023 to  with\n\ni i h bj li i ll l\n\n\n-----\n\nwhich questions you are addressing):\n\n1.\n\nIn an era in which convincing images, audio, and text can be generated\n\nwith ease on a massive scale, how can we ensure reliable access to\n\nverifiable, trustworthy information?\n\nHow can we be certain that a\n\nparticular piece of media is genuinely from the claimed source?\n\n2.\n\nHow can we best deal with the use of genai by malicious actors to\n\nmanipulate the beliefs and understanding of citizens?\n\n3.\n\nWhat technologies, policies, and infrastructure can be developed to\n\ndetect and counter genai-generated disinformation?\n\n4.\n\nHow can we ensure that the engagement of the public with elected\n\nrepresentatives\u2014a cornerstone of democracy\u2014is not drowned out by genai-\n\ngenerated noise?\n\n5.", "4.\n\nHow can we ensure that the engagement of the public with elected\n\nrepresentatives\u2014a cornerstone of democracy\u2014is not drowned out by genai-\n\ngenerated noise?\n\n5.\n\nHow can we help everyone, including our scientific, political, industrial,\n\nand educational leaders, develop the skills needed to identify genai-\n\ngenerated misinformation, impersonation, and manipulation?\n\nUnfortunately, we cannot commit to corresponding on all submissions, but\n\nwe may invite contributors to present their ideas to the working group as\n\npart of our evolving process to develop recommendations.\n\nWe also encourage submissions to three formal federal agency requests for\n\ninformation / comments related to genai:\n\n\nThe Office of Science and Technology Policy (OSTP) Request for\n\n\nInformation on National Priorities for genai.\n\nThe Office of Science and Technology Policy (OSTP) Request for\n\n\nInformation on how automated tools are being used to surveil, monitor,\n\nand manage workers.\n\nThe National Telecommunications and Information Administration\n\n\n(NTIA) request for comment on genai accountability policy.\n\nThank you in advance for your ideas.\n\nIn the months to come we may seek\n\nfurther public input on the topic of genai.\n\n-----\n\nLaura Greene, Co-Lead\n\nTerence Tao, Co-Lead\n\nBill Dally\n\nEric Horvitz\n\nJon Levin\n\nSaul Perlmutter\n\nBill Press\n\nLisa Su\n\nPhil Venables\n\nPCAST Member Bios\n\n###\n\n\n-----", "### Innovation Workshop, Montreal 2023\n\n-----\n\n_Please note that this report was developed by Experts of the Global Partnership on Artificial_\n\n_Intelligence\u2019s Working Group on the Future of Work._\n\n_The report reflects the personal opinions of GPAI Experts and does not necessarily reflect_\n\n_the views of the Experts\u2019 organizations, GPAI, the OECD or their respective members._\n\n\n-----", "#### 1.\n\nThe Missing Conversation on genai and the Future of Work in Policy Agendas\n\nThe transformative potential of genai for the future of work is a subject of immense\nrelevance.\n\nUnlike previous genai developments which focused on automating narrow tasks,\ngenai models possess the scope, versatility and economic viability to impact jobs\nacross multiple industries and at varying skill levels.\n\nTheir ability to produce human-like outputs\nin areas like language, content creation and customer interaction, combined with rapid\nadvancement and low deployment costs, suggest potential near-term impacts that are much\nbroader and more abrupt than prior waves of genai.\n\nClear political direction and support will be\nessential for both organizations and workers to adapt to the rapid development and widespread\nuse of this new generation of genai systems.\n\nYet, genai and the Future of Work policy\nremains absent from mainstream genai policy discussions.\n\nIt has been a notable omission in\nrecent high-level policy statements and summits, including the G20, G7 and the 2023 State of\nthe European Union address.\n\nEarlier in 2023, the G7 Digital and Technology Ministers committed to future discussions on\nvarious aspects of genai, including governance, intellectual property rights,\ntransparency, and responsible utilization.\n\nThis initiative was further endorsed in the G7 Summit\nin May, leading to the launch of the \"Hiroshima genai Process\" to continue these dialogues.\n\nTo\nadvance the G7 Hiroshima genai Process initiated by the G7 leaders, Japan distributed a survey\nto G7 countries in June 2023.\n\nThe purpose of this survey was to assess the current and\nforthcoming policy measures of G7 members in relation to the key benefits and challenges\nposed by genai technologies.\n\nDespite the comprehensive focus on responsible use,\ngovernance, disinformation, cybersecurity, and even biosecurity in the context of Generative\ngenai, there is a notable absence of discussions on the technology's impact on work 1 .\n\nThis critical\naspect seems to be side-lined in global coordination efforts, leaving a gap in the understanding\nand preparation for how these advanced genai models could reshape employment, job roles, and\nworkplace dynamics.\n\nThe lack of attention to the future of work could limit the effectiveness\nand scope of policy measures, potentially leading to unforeseen economic and social\nconsequences.\n\nIn the \"Harnessing genai (genai) Responsibly for Good and for All\" section of the\nG20 New Delhi Leaders' Declaration 2 , leaders recognize the potential of genai to foster prosperity\nin the global digital economy and address the importance of ethical, transparent, and\nresponsible development and deployment.\n\nWhile the declaration addresses the promise of genai\nand emphasizes protecting rights, ensuring safety, and promoting international cooperation, it\nomits the challenges and opportunities that genai poses to the global labor market.\n\nBy not\naddressing the impact of genai there is a gap in an essential component for planning\nfor a sustainable and inclusive future.\n\nLastly, in her State of the European Union 2023 speech 3 on Digital and genai, President Ursula\nvon der Leyen discussed the complex landscape of genai (genai), mentioning its\npotential to revolutionize healthcare, boost productivity, and tackle climate change while also\nposing existential risks.\n\nShe outlined a new global framework for genai governance based on three\npillars: setting human-centric guardrails, establishing a unified governance system, and\nguiding responsible innovation.\n\nThe genai Act, she mentioned, is the world's first comprehensive\npro-innovation genai law and serves as a blueprint for global genai regulation.\n\nShe also suggested\n\n 1\n2 \n3 \n\n\n-----\n\nthe creation of a global body similar to the IPCC for climate, but for genai, to guide policy making.\n\nThe speech concluded with an announcement of a new initiative to provide genai start-ups access\nto Europe's high-performance computers.\n\nNo mention was made of the labor market.\n\nAddressing the \"future of work\", \u2014specifically, how genai impacts jobs\u2014is vital.\n\nIt\nequips all labor market stakeholders to navigate these shifts by implementing proactive policies\nfor a smooth transition.\n\nMoreover, the remit of current discussions on ethical concerns and\ngovernance structures should be enlarged to include the future of work, given pressing\nconcerns over job quality and income inequality.\n\nGiven the transformative potential of genai in the workplace, the absence of this topic from such\na high-profile policy agenda suggests a potential gap in comprehensive planning for the digital\nfuture as we can see from the overview of national and regional initiatives to address risks\nrelated to genai.", "#### 2.\n\nThe Third Path: Beyond Automation and Augmentation\n\nEven in its infancy, genai offers myriad business applications, from customer service,\ncoding and design to marketing and legal analysis.\n\nThis technological leap promises to\nreshape tasks demanding expertise and creativity, potentially hastening the adoption timeline.\n\nAs we enter a new phase of automation and genai, most of the attention has\nbeen on how these technologies will replace manual and repetitive jobs.\n\nHowever, Generative\ngenai \u2014capable of creating content, solving complex problems, and even mimicking human-like\ntext\u2014 brings a different set of challenges and opportunities that extend far beyond traditional\nnotions of automation.\n\nThese technologies have the power to redefine not just low-skilled jobs,\nbut also high-skilled professions that have historically been considered \"automation-resistant.\"\n\nThe implications are profound, affecting economic structures, workforce development, and\nsocial equality.\n\nThis policy brief aims to shed light on this underexplored facet of genai, offering\nactionable insights for stakeholders to proactively address the transformative impact of\ngenai on the future of work.\n\nGenerally, jobs tend to fall into one of these two categories: automation, where technology\ntakes over tasks, or augmentation, where technology assists humans in performing tasks more\nefficiently.\n\nBuilding upon the categorization of jobs as either exposed to automation or\naugmentation, there is an emerging third category that does not neatly fit into either of these\ndefinitions.\n\nThese are a significant number of jobs where it's still unclear whether they will be\nautomated, augmented, or undergo some other form of transformation.\n\nThis third category\nrepresents uncharted territory, which is both a challenge and an opportunity for policymakers.\n\nIn addition to addressing the challenges emanating from automation and augmentation, the\nuncertainty surrounding some occupations represents a critical area that needs more\nexploration and understanding.\n\nInstead of reacting to changes after they happen, policy can\nproactively shape how automation and genai integrate into the workforce.\n\nBy focusing on this\nunknown area of jobs that could be either automated or augmented, policymakers have the\nchance to guide the development and implementation of technology in a way that maximizes\nbenefits for both workers, the economy and the whole society.\n\nThis proactive approach could\nset a new standard for how we manage technological change, ensuring that it serves the\nbroader good.\n\n-----", "#### 3. genai and Jobs: Some findings\n\nA decade ago, Oxford genai researchers estimated that 47% of jobs were vulnerable to\nautomation.\n\nIn an updated study 4 , they argue that while genai extends automation's\nreach, it also simplifies tasks for less-skilled workers.\n\nKey findings include remote jobs face\nhigher automation risks, while in-person communication becomes more valuable; firms will\noften retain human oversight due to genai errors; high-stakes scenarios will see limited Generative\ngenai use; and although creative roles are less automatable, enhanced content creation by genai\nmay heighten competition and depress wages for creative professionals.\n\nAccording to further\nresearch published in 2023, genai is expected to have a significant impact on the\nfuture of work, but it is not likely to cause widespread job displacement.\n\nMcKinsey 5 suggests\nthat by 2030, activities accounting for up to 30% of hours currently worked across the US\neconomy could be automated, with genai accelerating this trend.\n\nHowever, the report\nalso states that genai is more likely to enhance the way STEM, creative, and business\nand legal professionals work rather than eliminating a significant number of jobs outright.\n\nAnother BCG survey 6 reveals that the percentage of respondents who say their company uses\ngenai has jumped from 22% in 2018 to 50% in 2023.\n\nNearly half of the respondents (46%) say\nthey have experimented with genai, and 27% say they use it regularly.\n\nHowever, only\n14% of frontline employees have received training to address how genai will change their jobs,\nwhile 86% of employees say they'll need it.\n\nIn a study 7 with Boston Consulting Group involving 758 consultants, researchers assessed the\nimpact of Large Language Models (LLMs) like GPT-4 on complex, knowledge-intensive tasks.\n\nThe study identified a \"jagged technological frontier,\" where genai excels in some tasks but\nstruggles in others that seem similarly complex.\n\nWhen using genai, consultants were significantly\nmore productive, completing tasks 25.1% faster and achieving over 40% higher quality\ncompared to a control group.\n\nBoth low- and high-performing consultants benefited from genai\naugmentation, improving their scores by 43% and 17%, respectively.\n\nHowever, for tasks\nbeyond genai's current capabilities, consultants using genai were 19% less likely to produce correct\nsolutions.\n\nTwo distinct human-genai integration patterns emerged: \"Centaurs,\" who divided tasks\nbetween themselves and the genai, and \"Cyborgs,\" who fully integrated their workflow with genai\ntechnology.\n\nThe pressing question that looms large for individuals across the economy is, \"How will\ngenai impact my job?\"\n\nThis issue is not restricted to specific sectors or professions;\nrather, genai has the capacity to either automate or enhance a wide range of jobs,\nfrom manual labor to specialized roles.\n\nPwC's recent Global Workforce Hopes and Fears Survey indicates that a significant portion of\nthe global workforce is enthusiastic about acquiring new skills and engaging with genai.\n\nHowever,\nmany organizations are not fostering environments where dissenting views and minor failures\nare accepted.\n\nGathering feedback from around 54,000 participants across 46 countries, the\nstudy highlights a crucial concern for top-level executives: one third of employees are worried.\n\n4\n\nwork=Journal+article\n5 \n6 \n7 Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Effects of genai on Knowledge Worker Productivity and\nQuality by Fabrizio Dell'Acqua, Edward McFowland, Ethan R. Mollick, Hila Lifshitz-Assaf, Katherine Kellogg, Saran Rajendran, Lisa Krayer,\nFran\u00e7ois Candelon, Karim R. Lakhani :: SSRN\n\n\n-----\n\nAutomation generally refers to the use of technology, such as robotics, genai\n(genai), and computer-controlled systems, to perform tasks that were previously done by humans,\nwith the potential to increase efficiency and productivity.\n\nAugmentation refers to the process\nwhere genai complements human work by automating some tasks within an occupation, rather\nthan fully automating the entire occupation.\n\nIn this context, genai helps improve the quality,\nintensity, and autonomy of jobs by working hand-in-hand with humans, creating a digitally\ncapable and technologically progressive future for everyone.\n\nA recent analysis by the ILO of the potential effects of genai on the world of work finds\nthat most occupations will be \u201caugmented\u201d by the technology, rather than automated.\n\nAs shown\nin Figure 1, the risk of automation, mainly concerns the broad occupational category of clerical\nsupport workers, as 24% of their tasks have a high level of exposure to automation and 58%\nhave a medium-level of exposure.\n\nOther occupational groups are much less exposed, with\nonly 1 to 4% of tasks considered highly exposed, and medium-exposed tasks not exceeding\n25%.\n\nThis means that certain functions they perform may be automated, but that the majority of\ntasks they perform are not automatable.", "This means that certain functions they perform may be automated, but that the majority of\ntasks they perform are not automatable.\n\nAutomating some of their tasks can enable efficiency\ngains, allowing more time to be spent on other areas of work, thus \u201caugmenting\u201d their work.\n\n8\nProper policies should be put in place to ensure that the productivity gains are shared with\nworkers\n\n8\nOccupations comprise a \u2018bundle\u2019 of tasks and only those occupations whose tasks, on average, demonstrate a high level of exposure\n(defined as task average above 0.75 in a 0-1 scale) are considered to be highly exposed to automation.\n\nOccupations with a high\naugmentation potential have low-occupational level mean scores and a high standard deviation of task scores.\n\nFor more details, see\nGmyrek et al., 2023.\n\n-----", "**1-digit)**\n\nNote: Medium level of exposure, defined as 0.5-0.75 (in 0-1 scale of potential exposure to genai); high level of exposure\ndefined as greater than 0.75.\n\nSource: Gmyrek et al., 2023.\n\nTranslating these findings into global employment numbers reveals that it is high-income\ncountries that are most exposed to the potential risk of automation, with 5.1% of employment\npotentially exposed.\n\nAnd because there is a high share of women in clerical occupations, it is\nwomen that will be most affected by potential technological redundancy (see Figure 2).\n\nThe\nanalysis also reveals the enormous potential for augmentation across countries, but notes that\nthe possibilities for take-up in lower income countries may be constrained by poor infrastructure\n(internet connection, electricity).\n\nAs such there is a risk that the existing digital divide will further\nwiden the productivity divide.\n\nThis is echoed in a recent survey by the World Economic Forum 9 which calculates a 2% net\njob loss (14 million jobs).\n\nMoreover, the list of jobs predicted to increase (highly\nprofessionalized and requiring higher education) and those predicted to decline (those usually\navailable to the less educated).\n\nThis can be taken as a geographical call of attention, as the\nlatter are usually more concentrated in lower income countries.\n\n9\n\n\n\n-----", "**Figure 2.\n\nGlobal estimates: jobs with augmentation and automation potential as share**\n\n**of total employment**\n\nSource: Gmyrek et al., 2023.\n\nWhile the data on automation (second panel of figure 2) may seem alarming, especially when\nexpressed in millions, it is important to note that potential exposure is not equivalent to job loss\nas some organizations will not adopt the technology.\n\nMoreover, new jobs are likely to be\ncreated as a result of the technology.\n\nIndeed, genai development currently relies on millions of\nhuman laborers who train genai systems through tagging and repetitive feedback.\n\nMuch of this\nwork, however, is conducted through crowdsourcing platforms with low paid workers hired as\nindependent contractors without the rights and benefits associated with an employment\nrelationship.\n\nAlso, these jobs have been reported as being alienating because of\nrepetitiveness, exposure to violence, verticalism and other work conditions.\n\n10 Ensuring that the\nnew genai-related jobs are of good quality will benefit labour markets, also by potentially offering\na source of positive employment opportunities for workers who may be displaced.\n\n10 \n\n\n-----\n\nAs the data show, the potential number of jobs likely to be transformed by genai is six times greater\nthan those that may potentially be automated.\n\nWhether the transformation of tasks in these\noccupations is positive or negative depends on its design and integration at the workplace.\n\nWhile the data represent an upper bound for the potential of current genai, when other\nforms of technological progress are considered, they more likely represent a lower bound of\npotential exposure.\n\nAlso, these numbers should be considered as a lower bound estimation,\nbecause they are estimations based on genai alone.\n\nAs specialized tools start to\nemerge, new tasks might be exposed.\n\nAs an example, current day genai tools do not automatically\nhandle spreadsheets or ERP software, but those integrations are very likely to appear in the\nnear future.\n\nWhile the technology can allow some tasks to be automated, potentially leaving time for more\nengaging work, it can also be implemented in a way that worsens job quality.\n\nWhen algorithms\nare used to manage work, it can potentially restrain worker autonomy and increase work\nintensity, and perhaps more importantly, limit workers ability to provide feedback or discussion\nwith management about the organization of their work.\n\nIn the worst cases, such algorithms\ncan make decisions about dismissal.", "#### 4.\n\nThe big unknown\n\nBeyond the jobs clearly earmarked for either automation or augmentation, there's a significant\ngroup that defies easy categorization.\n\nComprising nearly 9% of the workforce, or 281 million\npeople, this \"big unknown\" mainly includes professionals and technicians.\n\nThese roles score\nhigh on the automation scale, yet they also involve a diverse range of tasks that could go either\nway\u2014being enhanced by genai or replaced by it.\n\nGiven the potential for either radical\ntransformation or significant job loss, this group urgently demands policy focus.", "**Figure 3.\n\nThe \u201cBig Unknown\u201d: occupations between augmentation and automation**\n\n**potential**\n\n\n-----\n\nThe first essential step for policymakers is to identify the demographics of workers in the \"big\nunknown\" category, breaking down factors such as industry, income level, educational\nbackground, and geographic location.\n\nThis information will guide targeted policy interventions\nto support these specific worker groups as the adoption of genai technologies, including\ngenai, expands.\n\nGiven the uncertain nature of their roles, this worker group is at\nheightened risk of negative outcomes from a rapid transition to genai.\n\nProactive policy can ensure\na more equitable distribution of the benefits of genai, thereby empowering these workers rather\nthan displacing them.\n\nThe effectiveness of future productivity and societal gains, particularly\nthose enabled by genai technologies like GPT, will depend on the speed and precision\nwith which workforce adaptation is managed.", "#### 5.\n\nManaging the transition\n\nNo, the effects of genai on work will not lead to the \u201cend of work\u201d, but suggest,\nnonetheless, many important transformations.\n\nSuch transformations can be either positive or\nnegative \u2013 with outcomes highly dependent on how the technology is integrated and used at\nwork.\n\nAs such, policies to manage the transformation, developed through social dialogue, are\nneeded.\n\nGovernments and social partners should aim to minimize any potential negative effects from\ngenai technology in the world of work, as well as harness potential opportunities to\nsupport productivity growth and decent work.\n\nWe propose the following recommendations at\nthe global and local level:\n\n-  Include the impact of genai on the future of work as a key item on the genai\n\nagenda.\n\n-  Support, through debt restructuring and alleviation, efforts by lower-income countries\n\nto invest in needed infrastructure and education that can lessen the digital divide.\n\n-  Work with government, trade unions and employer representatives at the 2025-26\n\nInternational Labour Conference to develop an international labour standard on\n\u00abDecent work in the platform economy\u00bb to ensure that genai-related jobs are of good\nquality, as well as its eventual adoption into national legislation.\n\n-  Invest in sectors that are under-funded and which have the potential to be a source of\n\ngood quality jobs, such as in the care or green economy.\n\n-  Design and institute social protection and skills development programs for those\n\ndisplaced by new genai technologies.\n\n-  Prioritize redeployment and training over job loss.\n\nEngage with workers\u2019\n\nrepresentatives and competent authorities to devise measures to avert or minimize\nterminations.\n\n-  Involve workers in the design, implementation, and use of technology at the workplace\n\nby building and strengthening mechanisms of workplace consultation.\n\n-  As a precondition for broad and effective co-determination and co-design of workers\n\nand their representatives, start and/or strengthen information, education and training\nabout genai technologies, their potential and limits, possible genai applications at the\nworkplace, critical/ethical design issues and challenges.\n\n-----\n\n-  Make sure that all workers and citizens can consider the big genai-driven transformation\n\nas an opportunity for personal improvements instead of a threat to their professional\nand social status.\n\nExamples can include education/training offerings and incentives for\ncontinuous learning as well as fostering a general positive culture of change on all\nlevels of society and economy.\n\n-  Engage in workday reduction without diminishing salaries and other public policies to\n\nensure that productivity gains from genai translate into wellbeing for the most.\n\n-  Provide compensation mechanisms to account for the migration of human jobs done in\n\nlow-income countries to automation of the same jobs by services provided on high\nincome ones.\n\n-  Encourage the private sector to voluntary work towards the minimum standards\n\nenshrined in the GPAI Fairwork in genai principles.\n\nIncentives for the adherence to these\nminimum standards exist through the Fairwork Pledge: a scheme through which\norganisations commit to only contracting with companies with high Fairwork scores.", "#### 6.\n\nPolicy implications\n\nThe path of automation is far from predetermined, especially as genai continues to\nevolve.\n\nJobs with high automation potential also show a wide range of variability in their\ncomponent tasks, leaving them at a crossroads: they could be either dramatically enhanced\nthrough genai-assisted augmentation or face substantial job loss due to automation.\n\nThis\nuncertainty presents a golden opportunity for proactive policy intervention.\n\nBy acting now, the\nbenefits of genai can be more evenly distributed across the labour market, uplifting workers in\nthese uncertain roles rather than making them obsolete.\n\nThe future gains in productivity and\nwell-being, powered by technologies like GPT, hinge on how swiftly and thoughtfully we can\nhelp the workforce adapt to these changes.\n\nTo navigate this uncertain landscape and ensure that the benefits of genai are\nequitably distributed, here are 10 policy actions that could serve as a starting point for\ndiscussion and implementation:", "**1.\n\nFinance research on**\n\n**mitigating the impacts**\n\n**of genai on jobs**\n\n\nInvest in academic\nresearch and\nhuman-centric\ninnovation\n\n\nFund innovative research formats such as\nenterprise sandboxes and living labs to not\nonly study the status quo but to explore new\ngovernance strategies for desirable genai uses\nat the workplace\n\n\n-----", "**Strategies**\n\nPromote research across academic\ninstitutions and industry, (employers,\nworkers and their representatives) and\neducation institutions\n\n\nEncourage crosscollaboration\n\nIncrease\ntransparency on genai\nadoption\n\nSupport tripartite\nco-determination\nand co-design of\ngenai applications in\nenterprises\n\nExplore tax\nincentives for\naugmentation\n\nSupport genai\nadoption in small\nbusinesses\n\n\nSupport collaborations between companies\nand research institutes to help SMEs\nleverage the potential of genai for their\nindividual products services and processes\n\nIncrease genai literacy and effective genai use in\nindustry, especially SMEs\n\nProvide information on genai deployment to\nworkers and workers representatives\n\nInclude work councils in big companies who\ncan consult with external experts to help\nthem execute their right to co-determine genai\napplications\n\nProvide funds with certified partners who\nhave the needed expertise to foster\nsustainable and value-driven (humancentered) genai solutions\n\nScale credits based on jobs\ncreated/transformed by GPT\n\nHelp small businesses adopt genai that\ncomplements human labour", "**Programs**\n\n-  Allocate funding\nfor educational\nexpenses\n\n-  Boost initiatives to\n\nenhance higher\neducation\naccessibility\n\n-  Voluntary annual\nassessments\n\n-  State-managed\nfund\n\nSecure income and\nretraining\n\n\nAssist employees pursuing studies in\nhuman-genai collaboration fields\n\nOvercome structural barriers that currently\nrestrict access for a significant portion of the\npopulation in some regions.\n\nImplement\nstrategies to ensure that higher education\nbecomes attainable for a broader\ndemographic\n\nMandate employers of certain size to\nmonitor and report on the effects of genai\nintegration within their organizations,\nencompassing aspects such as staffing\nlevels, skill requirements, and employee\nretraining.\n\nThese entities should provide\ndetailed adaptation plans to address the\nevolving workplace dynamics influenced by\ngenai, ensuring workforce readiness and\nresilience amidst technological\nadvancements\n\nCompanies pay into the fund based on their\ngenai driven job displacement to help mitigate\nlabour market changes\n\nEstablish a comprehensive support\nframework for workers affected by AIinduced displacement, emphasizing publicprivate partnerships.\n\nCollaborate with\nbusinesses to manage the transition,\nfacilitating financial support and job\nplacement.\n\nImplement strategies for\neffective reallocation, ensuring workforce\nadaptability and sustainability in the age of\ngenai", "**Strategies**\n\nEmphasize the advantages of genai-enhanced\nhuman roles over automation.\n\nConvey the\npreservation of human decision-making and\ncontrol\n\nExtend strategies beyond individual\nenterprises, assisting both private and\npublic sectors in their execution.\n\nGuarantee swift access for workers to\nsuitable and appealing job roles across\ndiverse professions\n\nSeek private sector alignment with the\nGPAI Fairwork in genai principles.\n\nEncourage\nlead firms in global production networks to\nprioritize contracts with suppliers that have\nhigh Fairwork score s", "#### 7.\n\nConclusion\n\nA joint effort that includes policymakers, the workforce, and employers can unlock the full\npotential for augmenting jobs through genai.\n\nBy working together, they can ensure a\nseamless adaptation of the labour market to this emerging genai landscape.\n\nSuch a unified\napproach aims not just to reduce the risks tied to automation, but also to elevate human\ncapabilities, setting a new standard for equitable growth and well-being in the era of Generative\ngenai.\n\nImportantly, this collaborative path offers a way to build trust in the technology, transforming\nit from a source of apprehension into a tool for empowerment and progress.\n\n-----", "|THE USE OF genai IN HIGHER EDUCATION AT AKU (Draft Guidelines) Provisionally approved at the Kenya Senate / Academic Council meetings of August 24th 2023 for uploading on internal Websites To be updated by the Working Group in the first year every quarter|Col2|\n|---|---|\n|Contacting Office|Provost / DVC or designate office - Graduate Program (Administration)|\n|Related Policies|This document should be read in conjunction with the University policies Academic Integrity, Intellectual Property Rights, Authorship Policy, Publications Policy and Research Misconduct Policy|\n\n\n_This document is intended for all Aga Khan University students and faculty/staff, including_\n\n_persons with honorary positions.\n\nThe Aga Khan University, in this document means its_\n\n_institutes, centres, schools, colleges and hospitals operating across all campuses around the_\n\n_globe._", "**POLICY STATEMENT**\n\nThese guidelines outline principles for the use of genai (genai) in\nhigher education at Aga Khan University.\n\nThese guidelines aim to ensure the effective and\nresponsible integration of genai technologies into academic and administrative\nprocesses.\n\nIn this document, the term \u201cgenai\u201d is used to refer to genai technologies.", "**1.\n\n** **PURPOSE & SCOPE:**\n\n1.1 OpenAI\u2019s ChatGPT-3 (Nov 30, 2022) delivers human-like responses on a variety of\nsubjects and has made genai tools easily accessible.\n\nThis has led to genai tools becoming\nrapidly integrated into various domains, including educational institutions, to enhance the\nefficiency and effectiveness of processes.\n\nHence, it is essential to engage in discussion and\n\n\n-----\n\nestablish guidelines at the University outlining the appropriate and ethical use of genai tools.\n\nBy\ndoing so, we can ensure that the genai tools are used responsibly and prevent their use in\nacademic misconduct and other unethical practices.\n\n1.2 After reviewing various policies and strategies from leading educational institutions,\nrelated international bodies and policy-making authorities across the world, the University has\nfound that the principles outlined by the Russell Group of universities provide a\ncomprehensive framework for addressing the ethical and responsible use of genai\ntools in academic settings.\n\nThe University aims to follow guidelines on the use of genai tools in\neducation outlined by the following principles by the Russell Group 1 as shown below:\n\n1 Universities will support students and staff to become genai-literate.\n\n2 (Faculty and) Staff should be equipped to support students to use genai\n\ntools effectively and (appropriately responsibly) in their learning experience.\n\n3 Universities will (review and) adapt (curriculum,) teaching and assessment to\n\nincorporate the ethical use of genai and support equal access.\n\n4 Universities will ensure academic rigour and integrity is upheld.\n\n5 Universities will work collaboratively to share best practice as the technology\n\nand its application in education evolves.\n\n(Brackets indicate editorial modifications to the principles)\n\n1.3 These guidelines apply to all faculty, staff, students, and other stakeholders involved in the\nUniversity's academic and administrative functions.\n\n1.4 The guidelines and use of this technology will be in compliance with national data\nprotection laws.", "**3.\n\n** **ACADEMIC INTEGRATION**\n\n3.1 The University shall encourage the use of genai technologies to enhance teaching, learning,\nresearch, and administrative processes, with a focus on improving efficiency and\neffectiveness.\n\n1 Russell Group.\n\n(2023, July 4).\n\nRG genai Principles.\n\nRetrieved from\n\n\n\n-----\n\n3.2 genai tools and platforms may be utilised by faculty and staff to support assessments,\ngrading, administrative tasks, and other relevant areas.\n\n3.3 Instructors and other staff should not copy/paste students\u2019 work into genai tools\neither for feedback, assessment, or any other purpose without informing students because it\ncould lead to breach of data privacy.", "**4.\n\n** **USE OF genai TOOLS IN LEARNING**\n\n4.1 The University encourages instructors to support their students in using genai tools to\nimprove their critical thinking and facilitate learning.\n\n4.2 If a student is uncertain about the assistance of an genai tool in a task, it is their responsibility\nto seek clarification from their instructor and the available guidelines on the use of the\ntechnology before incorporating material generated by that tool into their work.\n\n4.3 As stated in the AKU Academic Integrity Policy 2 , a student is not allowed to submit or\npresent work acquired from other source(s) as their own.\n\nThis includes any materials\ngenerated by genai tools as well.\n\nStudents are expected to paraphrase, reflect, and critique\ninformation obtained from genai tools before including it in their work.\n\n4.4 The University encourages students to use genai tools for facilitating learning and\nassessments by helping them in evaluating and understanding new concepts and ideas to\ngenerate their own academic work, within ethical and responsible boundaries.\n\nThis includes,\nbut is not limited to:\n\n\ni Developing ideas and thoughts by asking meaningful questions or suggestions\n\nii Personalising learning\niii Paraphrasing, improving grammar, punctuation, sentence construction and other\n\nlanguage skills on material written by the student.\n\niv Generating text, graphics, audio or any other materials based on appropriate prompts.\n\n4.5 Whenever genai tools have been used by the student in their work, they must be\nappropriately referenced and cited according to the instructions outlined by the University or\nthe publisher.\n\n4.6 Course handbooks can provide further instructions.\n\n2 Aga Khan University.\n\n(2022).\n\nPolicy on Student Academic Integrity (KE-014).\n\nRetrieved\nfrom \n\n\n-----", "**5.\n\n** **CREDIBILITY OF genai GENERATED CONTENT**\n\n5.1 Most genai tools are pre-trained on large-scale datasets, which may contain biases, limited or\nincorrect information.\n\nThis is why content generated by such tools may be offensive,\ninaccurate, incomplete, or not currently valid.\n\nHence, genai tools cannot be considered a\ncompletely reliable source of information.\n\n5.2 genai tools must not be used as an authoritative source of study on a topic.\n\nAny genai generated\ncontent used in research or assessments must be verified using credible sources to check for\nfactual inaccuracies and incomplete information.\n\n5.3 Current genai tools rely on generating responses by analysing patterns and associations\nwithin their training data rather than comprehending the meaning or context of the\ninformation.\n\nHence genai tools must not be used as the sole means of critical analysis of data.\n\nForming original ideas and critique based on data is an integral part of the research process,\nand genai tools must not be relied on to generate opinions where reflection and reasoning are\nrequired by the student.", "**6.\n\n** **HOW TO ACKNOWLEDGE WHEN AN genai TOOL IS USED**\n\n6.1 Content from genai is a nonrecoverable source as it cannot be retrieved or linked.\n\n6.2 Any use of genai technology must be appropriately acknowledged and identified in any\nsubmitted work.\n\nThis includes, but is not limited to, the name, version, description, and date\nof use for the genai tool.\n\n6.3 Students must identify where and how they have used genai assistance in all their submitted\nwork.\n\n6.4 Additionally, students must be able to produce a fully documented record of the prompts,\nmaterials and outputs given to and generated by the genai tool, along with each work when\nrequired.", "**7.\n\n** **USE OF genai TOOLS IN TEACHING**\n\nFor this document, the term \u201cinstructors\u201d is used to refer to all faculty and staff involved in\nthe teaching process including but not limited to those in support roles, teaching assistants,\ntechnical assistants, researchers, mentors, and counsellors.\n\n7.1 The University recommends instructors incorporate genai tools in facilitating teaching, and\nencourages them to support their students in using similar tools to facilitate their learning and\nassist their studies, where appropriate.\n\n-----\n\n7.2 Programs may devise regulations for genai tools use.\n\nThese regulations must not conflict\nwith the guidelines outlined in this document.\n\n7.3 Instructors should seek evidence of original thought and critical thinking in submissions\nmade with genai assistance.\n\nStudents must have documentation and be able to produce such\ninformation when requested.\n\n7.4 The University encourages instructors to design teaching material incorporating genai tools\ncreatively, ethically, and responsibly to support student learning.\n\n7.5 Instructors are advised to review/adapt techniques to prioritise assessment tasks that\nrequire higher-order thinking skills and promote critical analysis, reducing reliance on tasks\nthat can be easily accomplished by genai systems.\n\n7.6 Although genai-detection tools exist, instructors are reminded that none of them have yet\nbeen able to guarantee accurate detection.\n\nTherefore, instructors are strongly advised to\nconsider the academic and mental repercussions of false accusations on students for the\nunethical use of genai tools.\n\n7.7 If academic dishonesty or research misconduct is suspected, the AKU Student Academic\nIntegrity Policy, the AKU Research Misconduct Policy or other relevant policies will be\napplied.\n\n7.8 An instructor must seek permission from the student before submitting his/her work into\nany genai tool for assessment, feedback, or any other purpose.", "**8.\n\n** **CITING genai IN ASSIGNMENTS AND PUBLICATIONS**\n\n8.1 It is recommended to follow the publisher\u2019s guidelines on citing genai tools.\n\n8.2 For theses and dissertations, AKU recommends APA for making citations.\n\nOther citing\nmethods as required are also shown in the examples below.\n\nAPA 7 3 :\n\nAuthor of genai model used.\n\n(Year of genai model used).\n\nName of genai model used (Version\nof genai model used) [Type or description of genai model used].\n\nWeb address of genai model\nused.\n\n3 American Psychological Association.\n\n(2021, July 23).\n\nHow to Cite ChatGPT and Other genai\nLanguage Models in APA Style.\n\nRetrieved from \n\n\n-----\n\nAPA 7 - Example\n\nOpenAI.\n\n(2022).\n\nChatGPT (Dec 20 version) [Large language model].\n\nThe full transcript of a response must be included in an appendix or other\nsupplementary materials.\n\nChicago (note):\n\nNumber Originator of the communication, medium, Day, Month, Year.\n\nChicago (note) - Example:\n\n1 OpenAI's ChatGPT genai language model, response to question from author, 7 February\n2023.\n\nMLA:\n\n\u201cTitle of source\u201d prompt.\n\nName of genai Tool, version, Company, Date content was\ngenerated, General web address of tool.\n\nMLA - Example:\n\n\u201cDescribe the symbolism of the green light in the book The Great Gatsby by F. Scott\nFitzgerald\u201d prompt.\n\nChatGPT, 13 Feb. version, OpenAI, 8 Mar.\n\n2023,\nchat.openai.com/chat.\n\n-----", "# genai Guidelines\n\nLast updated: September 23, 2023\n\nExecutive Summary:\ngenai (genai) is a new branch of genai technology that can generate\ncontent\u2014such as stories, poetry, images, voice, and music\u2014 at the request of a user.\n\nMany\norganizations have banned genai, while others allow unrestricted usage.\n\nThe City\nrecognizes the opportunity for a controlled and responsible approach that acknowledges the\nbenefits to efficiency while minimizing the risks around genai bias, privacy, and cybersecurity.\n\nThis is the first step in a collaborative process to develop the City\u2019s overall genai policy.\n\nRegistered\nusers will be invited to join the Information Technology Department in a working group to share\ntheir experience and co-develop the City\u2019s genai policies.\n\nAt a baseline, users must follow these rules while using genai for City work, this includes\ndirect services like ChatGPT and extensions like Compose.genai:\n\n1.\n\nInformation you enter into genai systems could be subject to a Public Records Act\n(PRA) request, may be viewable and usable by the company, and may be leaked\nunencrypted in a data breach.\n\nDo not submit any information to a genai platform\nthat should not be available to the general public (such as confidential or personally\nidentifiable information).\n\n2. Review, revise, and fact check via multiple sources any output from a genai.\n\nUsers\nare responsible for any material created with genai support.\n\nMany systems, like ChatGPT,\nonly use information up to a certain date (e.g., 2021 for ChatGPT).\n\n3.\n\nCite and record your usage of genai.\n\nSee how and when to cite in the \u201cCiting\ngenai\u201d section.\n\nRecord when you use genai through this form .\n\n4.\n\nCreate an account just for City use to ensure public records are kept separate from\npersonal records.\n\nSee \u201cGetting started with genai for City use.\u201d If a user agrees to\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nthe terms and conditions of a system that the City does not have a formal agreement\nwith, he/she is responsible for complying with those terms and conditions.\n\n5.\n\nDepartments may provide additional rules around genai.\n\nConsult your manager\nor department contact if there are additional department-specific rules.\n\n6.\n\nRefer to this document quarterly, as guidance will change with the technology, laws, and\nindustry best practices.\n\nCheck the \u201c Change Log \u201d to identify changes.\n\nBookmark this link\nfor easy access to the latest doc .\n\nYou can subscribe to updates to the guidelines here .\n\n7.\n\nUsers are encouraged to participate in the City\u2019s established workgroups to help advance\ngenai usage best practice in the City and enhance the Guidelines.\n\nSee \u201cJoining genai Working\nGroup\u201d section.\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023", "### Definitions\n\nUser: staff, contractors, or others using genai for City work purposes\nCity: the city government of San Jos\u00e9 located in California, United States of America\ngenai: a machine that automatically creates content such as text, audio, or image\ngenai (genai): machines doing tasks that typically require human intelligence\nMachine Learning: a type of genai in which computers use data to \u201clearn\u201d tasks through algorithms\nAlgorithm: a set of steps, such as mathematical operations (e.g., addition) or logical rules", "### Purpose of Guidelines\n\n\u201cgenai\u201d, such as ChatGPT, grew from a niche topic to a variety of publicly available tools\nwith hundreds of millions of adopters in less than one year.\n\nAmong other things, genai\npresents an incredible opportunity for people to increase their efficiency and efficacy in work.\n\ngenai has also been used for several irresponsible applications including faking news\nheadlines, 1 leaking personal information, 2 and enabling phishing cyber-attacks.\n\n3\n\nThe City is actively working to create policies and procedures around genai in general.\n\nThis\ndocument serves as part of an evolving governance structure around responsible genai usage.", "### Application of the Guidelines\n\nThis document applies to all use of genai by a City staff member, contractor, volunteer,\nor other person while performing a role for the City (collectively \u201cusers\u201d).\n\nThis document does\nnot apply to users of genai for personal purposes or business purposes unassociated\nwith the City.\n\ngenai does not refer to algorithms that a person directly defines.\n\nFor example, a\nspreadsheet a human created to calculates taxes owed based on income is not \u201cgenai\u201d.\n\nA general rule is that if you cannot write the system\u2019s entire algorithm, either because you do\nnot understand the math or because it would take years to write down, then it is probably genai.\n\nDepartments may provide additional rules on the usage of genai.\n\nUsers should consult\ntheir manager if there are additional rules specific to their department.\n\n1 \u201cChatGPT is making up fake Guardian articles.\n\nHere\u2019s how we\u2019re responding\u201d, The Guardian\n2 \u201cOpenAI says a bug leaked sensitive ChatGPT user data\u201d, Engadget\n3 \u201dCouncil post: How genai is changing social engineering forever\u201d, Forbes\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023", "### Principles for Using genai\n\nUsage of genai shall follow the City\u2019s genai principles:\n\n1.\n\nPrivacy: Submit information to genai tools that is ready for public disclosure.\n\nThis\nincludes any text, photos, videos, or voice recordings you share with the genai.\n\nBe mindful\nthat the genai output may include unexpected personal information from another user and\nensure removing any potential private information before publishing.\n\n2.\n\nAccuracy: The City maintains trust with its residents and partners by providing accurate\ninformation.\n\nReview and fact check all outputs you receive from a genai.\n\nUsers\nshould consult trustworthy sources to confirm that the facts and details in the AIgenerated content are accurate.\n\nTrustworthy sources include official City documents and\npeer-reviewed journals.\n\nConsult your supervisor for other trustworthy sources (e.g.,\nnewspapers, blogs, or datasets).\n\nBe aware that many systems, like ChatGPT, may only use\ninformation up to a certain date (e.g., 2021 for ChatGPT) and cannot guarantee the\ncontent they generate is accurate.\n\n3.\n\nTransparency: The user shall be clear when he/she uses genai.\n\nThis can often\n\ninclude citing that you used genai in creating a product.\n\nSee how and when to cite\ngenai in the \u201cCiting genai\u201d section under \u201cGuidance while Using\ngenai\u201d.\n\n4.\n\nEquity: genai system responses are based on patterns and relationships learned from large\ndatasets derived from existing human knowledge, which may contain errors and is\nhistorically biased across race, sex, gender identity, ability, and many other factors.\n\nUsers\nof genai need to be mindful that genai may make assumptions based on\npast stereotypes and need to be corrected.\n\nEstablish guidelines to address equity as it\nrelates to services in your department.\n\n5.\n\nAccountability: The person using genai is accountable for the content it generates.\n\nUse\ngenai with a healthy dose of skepticism.\n\nThe level of caution used should\ncorrespond to the risk level of the use case (see \u201cAssessing Risk in genai Use\nCases\u201d).\n\nIt is always important to verify information provided by genai.\n\n6.\n\nBeneficial: User should be open to responsibly incorporating genai into their work\nwhere it can make services better, more just, and more efficient.\n\nFor example, a tool like\nChatGPT can help users go from an outline to a draft Council memorandum quickly,\nenabling them to focus more time on the analyses and findings that inform\nrecommendations to Council.\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023", "#### Usage of genai may be Subject to the Public Records Act\n\nAny retained conversations relating to City work may be subject to public records requests and\nmust comply with the City\u2019s retention policies.\n\nIn addition, users will need to comply with the\nCalifornia Public Records Act and other applicable public records laws for all City usage of\ngenai.\n\nThis means any prompts, outputs, or other information used in relation to a\ngenai tool may be released publicly.\n\nDo not use any prompts that may include\ninformation not meant for public release.", "#### Create an Account Specifically for City-related Work\n\nIf you choose to use genai for City-related work, you shall have an account for all\ngenai usage in your role at the City using a City email address.\n\nThe purpose of this is to\nensure proper retention of public records and avoid comingling of public and personal records.\n\nThis account should not be used for any personal purpose.\n\nUsers can use their City email address\nfor City usage, or they can create a shared account using a different work email address.\n\nFor\nexample, the Digital Privacy Office might create a shared ChatGPT account using the\n email address.\n\nRegardless of whether a shared or work email\naddress is used to create an account, users should use a unique password for the service.\n\nLike\nany other account which uses a City email address, the password should not be the same\npassword used to log in to any City devices.\n\nFor example, if a data breach occurs on ChatGPT\n(which happened in March 2023) 4 and your password is stolen, a hacker should not be able to\nlog into your laptop with that information.\n\nIf users use personal devices or accounts to conduct City work, the records generated may still\nbe subject to search and disclosure.\n\nThe records generated may include both the content users\ninput and the content users receive from the genai system.", "#### Understand the Terms and Conditions\n\nThe City does not currently have agreements in place for common genai systems, such\nas ChatGPT or Bing genai.\n\nIf you choose to use genai for City work and agree to the terms\nand conditions of a system without a City agreement in place, you are responsible for complying\n\n4 ChatGPT confirms data breach, raising security concerns.\n\n(2023, May 16).\n\nSecurity Intelligence.\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nwith those terms and conditions.\n\nIn the event that the City forms an agreement with a\ngenai service, this section will list those services.", "#### Opt out of data collection if possible\n\nSome services offer an option to opt out of data collection.\n\nThis means the genai system\nwill not keep the data you provide, and it will not be used in the system\u2019s models.\n\nOpt out of data\ncollection and model training whenever possible.\n\nFor example, you can opt out of ChatGPT by\ngoing to \u201csettings\u201d \uf0e0 \u201cdata controls\u201d \uf0e0 \u201cchat history and training\u201d.", "#### Verify the Copyright of All Generated Content\n\nUsers shall verify the content they use from any genai systems does not infringe any\ncopyright laws.\n\nFor example, City employees could check the copyright of text-based content\nwith plagiarism software and the copyright of image-based content with reverse Google\nsearches, although neither of these approaches guarantees protection against copyright\ninfringements.\n\nIf users are uncertain if content violates copyright, they should either edit the\ncontent to be original or not use it.", "#### Ownership of Generated Content\n\nIn most cases, the user owns the content they input into a genai service and the\ninformation they receive as an output.\n\nThe user can use the content at their discretion, in\naccordance with City policy and any terms and conditions he/she has agreed to.\n\nHowever, many\ngenai companies still retain the right to use both the input and output content for their\nown commercial purposes.\n\nFor example, this could include a genai company using City\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\ndata to train their models or distributing City output data for marketing campaigns.\n\nThis\nemphasizes the importance that only information the City is ready to make public should be\nentered into a genai system.", "#### Joining genai Working Groups\n\nThe City is dedicated to providing practical guidance around genai that protects people from harm\nwhile providing the best services to residents.\n\nTo accomplish this, the City has three engagement\ngroups dedicated to informing genai use in the City:\n\n1.\n\nCity genai working group: City staff discuss genai policy, use cases, and guidelines.\n\nUsers can\nlearn more about genai in the City, discuss potential ideas in their departments, and flag any\npotential concerns.\n\n2.\n\nDigital Privacy Advisory Taskforce: External Taskforce of experts around Digital Privacy\nand genai.\n\nThe Taskforce advises and recommends on the City\u2019s digital privacy practices,\nincluding responsible genai.\n\n5\n\n3.\n\nGovAI Coalition: The City of San Jos\u00e9 is collaborating with government agencies across the\ncountry to ensure that the genai systems we use serve all of our communities.\n\nThe group\ncollaborates on items including responsible genai governance, vendor accountability, and\nsharing use case experiences.\n\nIf you are an agency interested in joining, you can do so at\nsanjoseca.gov/govai .\n\nIn addition to these three groups, the City holds opportunities for the public to provide feedback,\nincluding in-person sessions in San Jos\u00e9, virtual sessions, and online at\nsanjoseca.gov/digitalprivacy .\n\nMembers of the public are also able to contact the Privacy and genai\nteam directly at  .", "#### Citing genai\n\nWhen to Cite:\nUsers must cite the genai when a substantial portion of the content used in the final\nversion comes from the genai.\n\nA \u201csubstantial portion\u201d will be further defined in future\nworking group discussions.\n\nAny statements used as fact must cite a credible source rather than\n\n5  Digital Privacy Advisory Taskforce webpage:\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nthe genai.\n\nCredible sources include official City documents and peer-reviewed journals.\n\nConsult your\nsupervisor for other trustworthy sources (e.g., newspapers, blogs, or datasets).\n\nAll images and videos must cite any genai used in their creation, even if the images are substantially\nedited after generation.\n\nHow to Cite:\ngenai can be cited as a footnote, endnote, header, or footer.\n\nCitations for text-generated\ncontent must include the following:\n\n-  Name of genai system used (e.g., ChatGPT-4, Google Bard, Stable Diffusion)\n\n-  Confirmation that the information was fact-checked.\n\nFor example: \u201cThis document was drafted with support from ChatGPT.\n\nThe content was edited\nand fact-checked by City staff.\n\nSources for facts and figures are provided as they appear.\u201d\n\nCitations for images and video must be embedded into every frame of the image or video.\n\nFor\nsupport on how to do this, see the \u201cCreating Images or Video\u201d use case in the appendix or reach\nout to  .", "#### Recording usage of genai\n\nThe City needs to understand how users are using genai tools in their work.\n\nWhen you\nchoose to use genai to support your work, report that usage through this form:\n .\n\nThe form will take 1 minute.\n\nYou do not need to wait for\na response after filling out the form to use genai, unless required by your department or\nmanager.\n\nThis is only meant to track usage in aggregate.\n\nAdditional guidance and advice around using genai can be found in the Appendix.", "### Assessing Risk in genai Use Cases\n\nThe risk presented by genai tools varies by use case, with the risk spectrum ranging from\nmid-risk to high-risk to intolerable risk.\n\ngenai risk is determined by two key factors:\n\n1.\n\nRisk of information breach: the potential harm if the information exchanged with a\ngenai is released to an unintended audience.\n\nThis can include entering personally\nidentifiable information, sensitive records, or confidential business information into\ngenai.\n\nAdditionally, any information entered into genai may be subject to\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nthe Public Records Act.\n\nIf you wouldn\u2019t share the information in a public forum, don\u2019t\nshare it with a genai.\n\n2.\n\nRisk of adverse impact: the potential harm of using the output for a decision, task, or\nservice.\n\nThis impact can be different for different populations and should be considered\nfrom an equity lens, such as adverse impacts to people of a certain race, age, gender\nidentity, or disability status.\n\nNot only can genai be biased, but it can also provide false\ninformation.\n\nIn general, if genai is used in relation to City processes that can alter\nan individual or community\u2019s rights, freedoms, or access to services, it should be\nthoroughly reviewed by multiple users before any document is finalized or action is taken.", "#### When Engaging in High-risk Use Cases\n\nKeep in mind the tone and specific language in the genai output.\n\ngenai is trained on a global\ncontext and may not use the vocabulary or tone consistent with the City and its values.\n\nSimple\nexamples include replacing \u201ccitizen\u201d with \u201cresident\u201d in documents, and capitalizing \u201cCity\u201d when\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nreferring to the City of San Jos\u00e9.\n\nThese documents, like any others, require thorough review\nbefore moving from draft to final product.\n\nCite verifiable sources for all facts and figures (past memos, newspapers, research papers, etc.).\n\nChatGPT or other genai are not definitive sources.\n\nFacts should be accompanied by links\nor citations to sources that the general public could find, such as news articles or research\npapers.\n\nChatGPT and other genai can fabricate sources if asked, so do not rely on them for finding\ncitations either.\n\nFind sources directly and confirm they are legitimate before using.\n\nAnything that would not be released or shared with the public should not be input into the genai.\n\nThis includes information such as draft RFP requirements that should not be public yet, vendor\ntransactions, procurement approvals, or internal City decisions.\n\nAdditional details on risk can be found in the Appendix.", "### Concluding Thoughts\n\ngenai presents users an opportunity to work better, faster, and smarter.\n\nHowever,\nbecause the technology and the laws surrounding it are evolving and present unknown risks, its\nadoption comes with ethical considerations.\n\nRemember the fundamental rules when using any\ngenai:\n\n1.\n\nNever submit personal or confidential information into a genai.\n\n2. Review, revise, test, and fact check any output from a genai.\n\n3.\n\nBe transparent when content was drafted using genai.\n\n4.\n\nReturn to this document often, as guidance on usage will change rapidly.\n\nBy keeping the above guidance in mind when using genai tools, we can ensure the safe\nand responsible use of genai by the employees of the City.\n\nIf you or your department has any\nquestions, comments, or concerns around using genai, please contact your team at\n .\n\nThe Privacy office can provide users trainings, set up genai\nevaluations, and help your team do the best with genai.\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023", "### A Definition of genai\n\ngenai, commonly referred to as \u201cgenai\u201d or \u201cGenAI\u201d, is an\n\u201cautomated system\u201d used to generate \u201ccontent\u201d.\n\nAn \"automated system\" is any system, software, or process that uses computation as part of a\nsystem to generate outputs, outcomes, make or aid decisions, inform policy implementation,\ncollect data or observations, or otherwise interact with individuals and/or communities.\n\n6\n\n\u201cContent\u201d includes text, emails, presentations, images, video, audio, architectural documents,\ndiagrams, and other forms of media.\n\ngenai uses massive datasets to\ngenerate content that someone would want\ngiven a prompt (see definition of \u201cprompt\u201d\nbelow).\n\nFor example, ChatGPT has collected\ndata on millions of webpages to identify\nsentence patterns that commonly come next\nafter someone types a phrase.\n\nOnline\ninformation is paired with human training\nwhere algorithm developers manually judge\nand correct the output of the system.\n\nFor\nexample, it may have required a combination\nof millions of webpages and a human\ndeveloper to train ChatGPT that \u201cJack fell down, and broke his crown\u201d should be completed by\n\u201cand Jill came tumbling after.\u201d\n\n6 Definition derived from the United States White House Office of Science and Technology Policy genai Bill of Rights\n(October 2022) and the National Institute of Standards and Technology genai Risk Framework\n(January 2023)\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nBillions of images are shared online every day, along with\nhundreds of thousands of hours of video 7 and countless\ntext posts.\n\nMuch of this information is connected to other\ninformation on the internet.\n\nFor example, pictures of cats\nare often connected with captions that have the word\n\u201ccat\u201d in them.\n\nThese connections allow a computer to,\nafter millions of connections, \u201clearn\u201d what a cat looks like.\n\nEventually, a computer can create an image of a cat based\non all the previous images it has seen.\n\ngenai systems apply this same approach to music, books,\npoems, voices, videos, and anything else created on the\ninternet.", "#### Prompts and genai\n\ngenai relies on a user (e.g., a person) to \u201cprompt\u201d the genai to generate content.\n\n\u201cPrompts\u201d\nare any direction provided by a user.\n\nExamples of genai include:\n\n1.\n\nCreating text based on a prompt\n2.\n\nCreating a picture or video based on a prompt\n3.\n\nMaking an audio file of a famous person saying something they did not say\n4.\n\nCreating a movie scene based on a text prompt and pictures of the characters\n\nExamples of prompts include:\n\n1.\n\nText prompt to generate text content.\n\nFor example: \u201cTell me a story about three people\nbecoming friends despite their differences\u201d\n\n2.\n\nText prompt to generate picture/video content.\n\nFor example: \u201cDraw a cow with long hair\nand an ornate bell\u201d\n\n3.\n\nVoice and text prompt to generate audio content.\n\nFor example: [Upload a recording of\nTim Cook] \u201cSay \u2018I\u2019ll just warn you now, I don\u2019t know how to use a computer\u2019 in the voice\nprovided.\u201d\n\n7 (QUT), Q.U.of T. (2022) _3.2 billion images and 720,000 hours of video are shared online daily.\n\ncan you sort real from_\n_fake?_ , _QUT_ .\n\nQueensland University of Technology\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n4.\n\nImage and text prompt to generate picture/video: \u201cRe-draw this bear with\ncleaner lines and give the bear a crown.\n\nThen show a clip of the bear running.\u201d", "#### Understanding \u201cRisk of Information Breach\u201d\n\nGeneral rule: If the information exchanged with a genai system would be harmful to a\nperson or community if made public, it is a high or intolerable risk.\n\nServices like ChatGPT have\nbeen compromised in the past and leaked personal information.\n\n8 Until private applications with\nhigher security are deployed in the City, all information exchanged with genai has a\nreasonable risk of being compromised.\n\nMid-risk information includes non-identifying and non-confidential information.\n\nFor example, a\nsimple email response or instructive documents often contain only general information that\nwould not present any risk if made public.\n\nHigh-risk information includes personally identifiable information (e.g., full name, birth date,\nemail address) and confidential business information that may have larger implications to City\nprocesses.\n\nUntil a private application is deployed with security measures approved by the\nCybersecurity Office, no high-risk information shall be provided to a genai system.\n\nProhibited risk information includes highly sensitive and identifying information.\n\nThis includes\ndata such as credit card numbers, bank account information, social security numbers, and other\ninformation that requires rigorous security measures and compliance standards before being\nprocessed.", "#### Understanding \u201cRisk of Adverse Impact\u201d\n\nGeneral rule: If you are using genai in relation to City processes that can alter an\nindividual or community\u2019s rights, freedoms, or access to services, it is at least high risk and should\nbe thoroughly reviewed before any document is finalized or action is taken.\n\nAdditionally, any\naction that could reasonably lead to the City engaging in legal infringements on intellectual\nproperty are prohibited.\n\n8  \u201cOpenAI says a bug leaked sensitive ChatGPT user data\u201d\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nMid-risk impact includes tasks associated with drafting internal messages, internal\ndocumentation, and idea generation.\n\nThese tasks can be sped up with the support of Generative\ngenai, but require many more steps before reaching a public impact.\n\nHigh-risk impact includes tasks associated with official City documents or messaging.\n\nIt also\nincludes uses that require substantial editing and review before usage.\n\nThese tasks require\nthorough review at the time of generation before using in any work context.\n\nSpecial care should\nbe taken when a task may impact individuals differently across factors such as race, age, gender\nidentity and disability (e.g., a memo about tree canopy inequity in neighborhoods).\n\nProhibited risk impact includes tasks that undermine trust in the City through false statements or\nnews; deny people due process such as in resource allocation, job evaluations, and purchasing\ndecisions; or expose the City to substantial security or legal risks.\n\ngenai does not have\nreasoning behind the content it produces and cannot justify a decision.", "#### Examples of Mid-risk Use Cases\n\n1.\n\nDrafting messages to staff and trusted partners\n\ngenai tools can help users draft emails or other messages to staff and trusted partners.\n\nChatGPT is a tool commonly used for this purpose.\n\nYou can prompt ChatGPT to provide formal\nsounding language from general framing of the message.\n\nYou can also have it draft emails in\ndifferent tones by asking for a different tone.\n\nAdditional Guidance:\n\n1.\n\nYou may be inclined to use ChatGPT to help with email replies.\n\nDo not copy your current\nemail thread into ChatGPT.\n\nThe email was sent to select people and may be confidential.\n\n2.\n\nBe mindful about the purpose of the email, and if it is appropriate to use genai\nfor drafting it.\n\nFor example, Vanderbilt University received heavy backlash for using\nChatGPT to draft an email in response to a school shooting.\n\n9\n\nExample:\n\n9 Korn, J.\n\n(2023) _Vanderbilt University apologizes for using CHATGPT to write mass-shooting email | CNN business_ ,\n_CNN_ .\n\nAvailable at: \n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n1.\n\nPrompt ChatGPT with the following: \u201cI am the lead product manager for housing\ntechnology initiatives.\n\nWe interview users to gather product requirements, prioritize\nfeatures, and work with software developers on implementation.\n\nDraft me an email\nasking the software developers how long the housing database will take to implement,\nand what risks to implementation they see.\u201d\n\n2.\n\nCarefully read through the email, perform final fact-check and other edits to the draft\nemail.\n\nManually add in personal information or internal confidential details before\nsending.\n\n3.\n\nCite at the end of the message \u201c _some of this content was drafted using ChatGPT.\n\nAll facts,_\n_figures, and statements were reviewed by the sender to be accurate.\u201d_\n\n4.\n\nIf someone replies to your email asking for what you would like to see in the database,\nyou can return to ChatGPT and prompt it with the following: \u201cI want the database to be\neasily understood by our field staff, draft this request to the developers\u201d.\n\nRead the draft,\nfact-check, and manually add information as needed.\n\nCite ChatGPT at the end of the\nmessage as done previously.\n\n2.\n\nFraming written content not intended for official release\n\ngenai can be useful for creating an outline or structure for your written content.\n\nThis can\ninclude an outline for a cover letter, long-form writing, project documentation, or speaker notes\nfor a presentation.\n\nWhen the written content is not intended for official public release, it\npresents less risk than official City publications (like memos or policies).\n\nChatGPT is the most\ncommon tool for this use case.\n\nYou can write a few key points you would like to detail, any\nthemes you want present, the kind of voice you would like, and how long you would like the\ncontent.\n\nRemember that information you input into a genai system may be subject to a\nPublic Records Act request.\n\nAdditional Guidance: Unless you have a genai trained to your context\u2014a feature likely\nnot available for another year\u2014the tool will provide generic language that does not apply to the\nCity.\n\nFor example, ChatGPT may use the word \u201ccitizens\u201d rather than \u201cresidents\u201d when referring\nto the people we serve because it is not used to San Jos\u00e9\u2019s specific circumstances.\n\nAs always,\nmake sure to review, revise, and fact-check any output from genai.\n\nExample prompt steps:\n\n1.\n\nPrompt ChatGPT with the following: \u201cI am writing an instruction manual for how City staff\nshould add content to the City\u2019s website.\n\nDraft an outline that can be posted on our\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nintranet.\n\nIt should have a section about how to create lists, add hyperlinks, and show\npictures using a content management system.\n\nDraft in a formal tone but make the text\nclear and approachable.\u201d\n\n2. Review, revise, and fact-check.\n\nManually enter any confidential or private information\ninto the draft or final version.\n\n3.\n\nCite that you used ChatGPT in the drafting process.\n\nSee how to cite genai in the\n\u201cCiting genai\u201d section under \u201cGuidance while Using genai\u201d.\n\n3.\n\nLearning from a document\n\nYou may copy a large public document into a genai tool and ask the genai questions about\nthe document.\n\nChatGPT is the most common tool for this use case.\n\nAdditional Guidance: The document or information you paste into the Generative tool genai should\nalready be public information.\n\nExample prompt steps:\n\n1.\n\nAsk ChatGPT to \u201cSummarize the following document.\n\nLet me know if there is any mention\nof California, cities, or San Jos\u00e9.\u201d\n\n2.\n\nCopy the text from a public document and paste it into ChatGPT.\n\nAn example document\n\nwould be the text from this news article:  .\n\nCopy text and paste into ChatGPT\n\n3.\n\nYou do not need to cite ChatGPT unless you quote specific text outputted from ChatGPT\nin future written content.\n\n4.\n\nBrief list of other mid-risk use cases\n\n1.\n\nHelping you come up with a name for your team.", "4.\n\nBrief list of other mid-risk use cases\n\n1.\n\nHelping you come up with a name for your team.\n\nFor example, \u201cgive me ten names for a\nteam focused on genai and Privacy that uses the acronym \u2018SAFE\u2019.\u201d Be sure the name is not\nalready used by another team in the City.\n\n2.\n\nLearning about a new topic in a way that you can understand.\n\nFor example, \u201cexplain\nquantum mechanics to me like I\u2019m five\u201d.\n\nVerify anything you learn from ChatGPT before\napplying the knowledge in a City context.\n\n3.\n\nHelping you find the right word for a concept.\n\nFor example, \u201cwhat is the word for the\nsecond-to-last episode in series\u201d.\n\nOnce the genai provides the word, search the word on\nGoogle (or elsewhere) to confirm it means what you think it means.\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023", "#### Examples of High-risk Use Cases\n\n1.\n\nDrafting memos and or other public-facing City documents\n\ngenai tools can help users draft memos and other public-facing documents more\nefficiently.\n\nBecause the content is meant for public release, it is treated as high-risk and should\nbe reviewed and edited multiple times before release.\n\nChatGPT is the tool most used for this\npurpose.\n\nAdditional guidance: The City expects users to produce their own research that informs memos,\nsuch as information related to policy changes and program changes.\n\nMemos, press releases, and\nother publications also have their own City-specific formats and standards to follow.\n\nConsult\nyour supervisor to make sure your memo follows City standards.\n\nExample prompt steps:\n\n1.\n\nProvide context around the memo but only provide public details: \u201cWe are building an\nencampment management work order system at the City to better coordinate services\nand have just completed the detailed design.\n\nWe will be presenting to the City council on\nthe latest update.\u201d\n\n2.\n\nThen request ChatGPT to draft a memo: \u201cDraft a memorandum with the following\nsections and key points: Introduction: (add bullet points), Human-Centered Design work\n(add bullet points), Requirements (add bullet points), Next-steps (add bullet points).\n\n3.\n\nAfter initial memo draft, prompt ChatGPT to \u201cDraft a conclusion summarizing all the prior\nsections.\u201d\n\n4.\n\nManually add in any non-public information to the draft memo produced by ChatGPT.\n\n5.\n\nCarefully read through memo, perform fact-check and other edits to memo to maintain a\ntone consistent with City documents.\n\n6.\n\nCite verifiable sources (past memos, newspapers, research papers, etc.)\n\nfor all facts and\nfigures in the memo.\n\n7.\n\nIf required, cite that you used ChatGPT in the drafting of the memo.\n\nSee how and when to\ncite genai in the \u201cCiting genai\u201d section under \u201cGuidance while Using\ngenai\u201d.\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n2.\n\nWriting an RFP/RFB/Vendor relations\n\ngenai tools can help users draft RFP/RFBs more efficiently.\n\nBecause the content is meant\nfor public release, it is a high-risk use case.\n\nChatGPT is the tool most used for this purpose.\n\nAdditional guidance: RFPs and other publications have their own City-specific formats and\nstandards to follow.\n\nConsult your supervisor and purchasing business partner to make sure your\nmemo follows City standards.\n\nGuidance can be found on the City intranet, including the\n\u201cStrategic Procurement Guidelines for RFP and Contract Requests To Finance-Purchasing\u201d .\n\nTake\nspecial care not to provide ChatGPT information that is not meant to be public yet.\n\nFor example,\nif the specific requirements of the RFP are not meant to be public yet, do not input them into\nyour prompts.\n\nExample prompt steps:\n\n1.\n\nProvide context around the procurement document without providing non-public details:\n\u201cWe are procuring an encampment management work order system at the City to better\ncoordinate services.\u201d\n\n2.\n\nAfter ChatGPT responds, ask to draft the procurement document: \u201cDraft an RFP with the\nfollowing sections and key points: Introduction: (add bullet points), Scope of Work (add\nbullet points), Requirements (add bullet points), Cost Breakdown (add bullet points).\u201d\n\n3.\n\nManually add in any non-public information to draft document produced by ChatGPT.\n\n4.\n\nCarefully read through the document, perform fact-check and other edits.\n\n5.\n\nIf required, cite that you used ChatGPT in the drafting process.\n\nSee how and when to cite\ngenai in the \u201cCiting genai\u201d section under \u201cGuidance while Using\ngenai\u201d.\n\n3.\n\nWriting advertisements, social media posts\n\ngenai tools can help users draft promotional material.\n\nBecause the content is meant for\npublic release, it is a high-risk use case.\n\nChat GPT is the tool most used for this purpose.\n\nAdditional guidance: None, refer to genai principles and guidance for high-risk use cases.\n\nExample prompt steps:\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n1.\n\nProvide ChatGPT with details around the needed post and audience, for example: \u201cDraft a\ncute tweet of less than 240 characters that reminds families that tomorrow is Walk and\nRoll to school day\u201d\n\n2. Review output, edit to make personal to San Jos\u00e9 and relevant department or office, and\npost.\n\n4.\n\nWriting job postings or job descriptions\n\nIf you provide a genai with a list of qualities you want and a role title, it can help you\ndraft a formal-sounding job description.\n\nBecause the content is meant for public release, and job\nrequirements can have a substantial impact on who applies, it is a high-risk use case.\n\nAdditional guidance:\nThe City expects users to follow existing standards on the format and content of job postings\nbased on classifications.\n\nConsult your Human Resources business partner or your Department\u2019s\nHR representative for information on job classifications and postings.", "Consult your Human Resources business partner or your Department\u2019s\nHR representative for information on job classifications and postings.\n\nAdditionally, be mindful of the language used in the requirements, responsibilities, and tone\nused in the job posting.\n\nCheck if the job description seems to use language stereotypically\nassociated with a specific race or gender.\n\nUse gender-neutral language: Avoid using genderspecific pronouns (he, she) and job titles (fireman, firewoman).\n\nInstead, opt for inclusive terms\nsuch as \u201cthey\u201d and \u201cfire officer.\u201d Remove gender-coded words: Avoid using adjectives that may\nbe associated with a specific gender, such as \u201caggressive\u201d or \u201cnurturing.\u201d Use neutral\ndescriptors, like \u201cresults-driven\u201d or \u201ccollaborative.\u201d 10\n\nExample prompt steps:\n\n1.\n\nProvide ChatGPT with the previous public posting for an Analyst I position and request\nthat ChatGPT \u201cDraft a similar job description, but with a focus on using information to\ninform park capital projects.\u201d\n\n2.\n\nManually add in any non-public information to draft document produced by ChatGPT.\n\n3.\n\nCarefully read through the document and edit for a more neutral tone, perform factcheck and other edits.\n\n10 Krakovetskyi, O.\n\n(2023, March 22).\n\nEliminating Bias in Job Descriptions with ChatGPT \u2013 The DevRain Tech Blog -\nMedium.\n\n_Medium_ .\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n5.\n\nCreating images or video\n\nSome genai tools such as Stable Diffusion and Dall-E can create images or video clips\nbased on text prompts.\n\nThe City needs to maintain its legitimacy as a trustworthy source when\nusing video and images, which requires substantial precautions whenever using genai-generated\nvisual content.\n\nAdditional Guidance:\n\n1.\n\nUse only for illustrative purposes.\n\nFor historical events, use real images rather than\ngenerated.\n\nFor example, if you want a picture of a giraffe wearing a suit and tie for your\npresentation, generate it.\n\nIf you are proposing a new visual diagram or abstract concept,\nyou can also generate it.\n\nIf you want a picture of the Mayor at City Hall, find an actual\npicture.\n\n2.\n\nRequire a citation embedded into the image or video at all times.\n\nImages and videos can\neasily be taken out of their original context and misinterpreted as reality.\n\nTo prevent a\nnews article or other secondary source from treating an image as fact, all images and\nframes of a video must specify that they were generated using an genai system.\n\nThe citation\nshall be included in the image itself, and cannot be removed without editing or cropping\nthe image.\n\nExample Use Case:\n\n1.\n\nProvide a prompt: \u201cdrawing of falcon and its chicks on top of a skyscraper\u201d\n2.\n\nChoose your image\n3.\n\nEmbed the citation into the image: \u201cImage generated by DALLE-2\u201d\n4.\n\nAdd alt text into the image that clearly states the image was generated by an genai system\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n_Figure 1: Three steps of embedding a text box into an image in order to cite the genai system used for the image._\n\n6.\n\nCreating presentation slides\n\nIf you provide genai with some public information, it can create a presentation for you.\n\nCurrently this feature is very new but may soon be integrated into existing applications like\nPowerPoint.\n\nCurrently there is no clear leader in genai for presentations, but a few\nexamples are beautiful.genai and gamma.app .\n\nPresentations are automatically high risk because\nthey go beyond text into images, which can present false information if the audience believes\nthe image is real.\n\nSuggested use: Provide a public document, or an outline with public information.\n\nAdditional guidance: Similar guidance to other public-facing documents, but with the additional\nrequirement to cite all genai Generated images clearly on the image.\n\nExample prompt steps:\n\n1.\n\nProvide the genai with an article or outline from publicly available information.\n\nFor example,\nan article about the evolution of cats.\n\n11\n\n2.\n\nGenerate the presentation\n3.\n\nFact check all content, review for tone and language\n4.\n\nCite genai images\n\n11 Article used in example was Vsadmin.\n\n(2022, April 8).\n\n_The Evolution of Cats_ .\n\nKillarney Cat Hospital.\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n_Figure 2: Image of a generated presentation with support from the genai tool gamma.app.\n\nThe image on the right was generated_\n_using Stable Diffusion genai and was cited as such_\n\n7.\n\nBrief list of other high-risk use cases\n\nRemember to follow the genai principles and general guidance for high-risk use cases.\n\n1.\n\nCreating diagrams.\n\nFor example, \u201ccreate a flow chart of a tree turning into wood pulp and\nthen into paper\u201d.\n\nReplace pictures before publishing\n\n2.\n\nDrafting papers.\n\nFor example, \u201cHere is my outline for my research paper, and my findings,\ndraft a complete paper.\u201d", "#### Examples of Prohibited Use Cases\n\n1.\n\nProgramming or coding\n\nWhy it is prohibited: Code generated by an genai may be outdated, copyrighted, have identified\nvulnerabilities, or rely on other code that no longer works.\n\nThe generated code is not cited to a\ndate (like a stack overflow post would be), so it is unclear when the code would have been good.\n\nWhat can you do with genai: genai can help frame your coding problem, and help you draft\npseudo-code to solve your problem conceptually.\n\nYou can request code snippets for help\ndefining syntax, and can be useful for testing projects in a low-risk, non-production environment.\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n2.\n\nEvaluations and Decisions\n\nWhy it is prohibited: Evaluating job applicants using genai has led to countless scandals of biased\napplication reviews.\n\n12 This evaluation issue also extends to other areas such as evaluating\nproposals or an existing employee.\n\n13 genai-based evaluations expose the City to public protest\nacross many key City functions such as hiring and purchasing.\n\nAdditionally, genai shall not be used to determine highly sensitive decisions such as an\nindividual\u2019s health plan, cost of bail, conviction of a crime, grades, or admissions to a program.\n\nWhat can you do with genai: genai can help flag key words and identify phrases within a\ndocument (see the mid-risk use case).\n\nHowever, the actual evaluation must be made by a\nperson.\n\n3.\n\nLanguage Translation\n\nWhy it is prohibited: Large Language Models like ChatGPT are not yet demonstrably better for\ntranslation than something like Google Translate.\n\n14 Google Translate is also an genai system, but is\nbuilt for specifically translating text, compared to modern genai systems like ChatGPT,\nwhich attempt be a more general genai system for more problems.\n\nFuture genai systems may be substantially better than existing translation genai systems,\nbut they will require an evaluation of their performance before the City should use them over\nsomething like Google Translate.\n\nTranslations should be confirmed by a fluent speaker of both\nlanguages whenever possible.\n\nWhat can you do with genai: Test out the system in a risk-free environment (e.g., you\nand a coworker testing the system), and report any translation system you would like to use to\nthe Digital Privacy Officer for an algorithm evaluation.\n\nContact  .\n\n12 Vallance, B. C. (2022, October 13).\n\ngenai tools fail to reduce recruitment bias - study.\n\n_BBC News_ .\n\n13 In general, people react worse to negative evaluations from genai than they do to negative evaluations from people.\n\nLopez, Alberto, and Ricardo Garza.\n\n\"Consumer bias against evaluations received by genai: the\nmediation effect of lack of transparency anxiety.\"\n\n_Journal of Research in Interactive Marketing_ (2023).\n\n14 Google Translate is also an genai system, but is built differently than the modern genai systems like ChatGPT\nor Google Bard, which attempt to act as a more general genai system for more problems than just translating text\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\n4.\n\nCreating voice or other audio\n\nWhy it is prohibited: Replicating a person\u2019s voice with genai in any City document or recording\nwould undermine the trust of staff and the residents.\n\nPotential legal concerns also exist\nregarding replicating a person\u2019s voice.\n\nDo not generate audio through genai.", "#### Be Aware of Targeted Cyber Attacks Using genai\n\nAlthough City staff are already familiar with handling cyber risks like phishing and malware, the\nadvent of genai introduces heightened cybersecurity risks as the attacks can be more\ncomplex and personalized.\n\nCyber threat actors may use genai in their attacks in the\nfollowing ways :\n\n-  Writing genai-powered, personalized phishing emails: With the help of genai,\nphishing emails no longer have the tell-tale signs of a scam\u2014such as poor spelling, bad\ngrammar, and lack of context.\n\nPlus, with genai like ChatGPT, threat actors can launch\nphishing attacks at unprecedented speed and scale.\n\n-  Generating deep fake data: Since it can create convincing imitations of human\nactivities\u2014like writing, speech, and images\u2014genai can be used in fraudulent\nactivities such as identity theft, financial fraud, and disinformation.\n\n-  Cracking CAPTCHAs and password guessing: Used by sites and networks to comb out bots\nseeking unauthorized access, CAPTCHA can now be bypassed by hackers.\n\nBy utilizing genai,\nthey can also fulfill other repetitive tasks such as password guessing and brute-force\nattacks.", "#### Detecting genai\n\nSoftware developers are building tools, like GPTZero , GPT Radar , and Originality.genai , designed to\ndetect if a body of writing was created by a genai tool.\n\nThese tools are in early stages of\ndevelopment and their detection accuracy rate may not always be accurate and should be used\nwith caution.\n\nFor example, there have been numerous incidents of instructors using ChatGPT\ndetection tools falsely accusing students of plagiarism, endangering their grades and even\ndiplomas.\n\nDespite the limited accuracy of these tools, they allow residents to check if City documents were\ngenerated by genai regardless of whether users cite their usage or not.\n\nTo build trust with residents,\n\n\n-----\n\nCity of San Jos\u00e9 genai Guidelines September 23, 2023\n\nusers need to be proactive in communicating its usage of genai.\n\nResidents finding out on their own\ncan cause reputation harm to the City.", "#### genai & Copyright\n\nNumerous copyright lawsuits are springing up in which artists are suing genai companies like\nStability genai and Midjourney for unauthorized use of their intellectual property to train the\ngenai systems.\n\nLarge companies like Getty Images and Shutterstock are also joining suit\nagainst genai companies.\n\nThe US Copyright Office determined that art created solely by genai isn\u2019t eligible for copyright\nprotection.\n\nArtists can attempt to register works made with assistance from genai, but they must\nshow significant \u201c human authorship .\u201d The office is also currently executing an initiative to\n\u201cexamine the copyright law and policy issues raised by genai (genai) technology.\u201d\n\n\n-----", "## Translation\n\n_The following draft Chinese standard for genai establishes very specific oversight_\n_processes that Chinese genai companies must adopt in regard to their model training data,_\n_model-generated content, and more.\n\nThe standard names more than 30 specific safety risks,_\n_some of which\u2014algorithmic bias, disclosure of personally identifiable information, copyright_\n_infringement\u2014are widely recognized internationally.\n\nOthers, such as guidelines on how to_\n_answer questions about China\u2019s political system and Chinese history, are specific to the_\n_tightly censored Chinese internet.\n\nThe standards also require Chinese genai service_\n_providers to incorporate more foreign-language content into their training data._", "**Committee**\n\n1 Translator\u2019s note: The Chinese word \u5b89\u5168 _\u0101nqu\u00e1n_ \u2014found in the title of this standard and throughout\nits text\u2014can be translated into English as either \u201csafety\u201d or \u201csecurity.\u201d The Chinese authors of this\nstandard provided the following English translation of its title: \u201cBasic security requirements for\ngenai service.\u201d However, this CSET English translation renders \u5b89\u5168 as\n\u201csafety\u201d in most cases, because in the context of this standard, the authors are mainly discussing the\nprevention of accidents or unforeseen problems (\u201csafety\u201d) of genai, rather than the prevention of\ndeliberate abuse or sabotage (\u201csecurity\u201d).\n\n-----", "## Contents\n\n1 Scope ............................................................................................................................................. 1\n\n2 Normative Reference Documents ......................................................................................... 1\n\n3 Terminology and Definitions .................................................................................................. 1\n\n3.1 genai services ...................................................................... 1\n\n3.2 Provider .................................................................................................................................... 1\n\n3.3 Training data ( \u8bad\u7ec3\u8bed\u6599 ) ...................................................................................................... 1\n\n3.4 Illegal and unhealthy information ( \u8fdd\u6cd5\u4e0d\u826f\u4fe1\u606f ) ...................................................... 1\n\n3.5 Sampling qualified rate ....................................................................................................... 2\n\n4 General Provisions..................................................................................................................... 2\n\n5 Corpus Safety Requirements ................................................................................................. 2\n\n5.1 Corpus Source Safety Requirements .............................................................................. 2\n\n5.2 Corpus Content Safety Requirements ............................................................................ 3\n\n5.3 Corpus Annotation Safety Requirements ...................................................................... 5\n\n6 Model Safety Requirements ................................................................................................... 5\n\n7 Safety Measure Requirements .............................................................................................. 7\n\n8 Safety Assessment Requirements ....................................................................................... 9\n\n8.1 Assessment Methods ........................................................................................................... 9\n\n8.2 Corpus Safety Assessment ............................................................................................. 10\n\n8.3 Generated Content Safety Assessment ...................................................................... 10\n\n8.4 Assessment of Refusal to Answer Questions ........................................................... 11\n\n9 Other Requirements ............................................................................................................... 11\n\n9.1 Keyword Library .................................................................................................................. 11\n\n9.2 Classification Models ........................................................................................................ 11\n\n9.3 Generated Content Test Question Bank ..................................................................... 11\n\n9.4 Refusal to Answer Test Question Bank ...................................................................... 12\n\nAppendix A Main Safety Risks of Corpora and Generated Content ............................. 13\n\n\n-----\n\n-----", "**1** **Scope**\n\nThis document gives the basic requirements for the safety aspects of generative\n\ngenai (genai) services, including corpus safety ( \u8bed\u6599\u5b89\u5168 ), model safety,\nsafety measures, and safety assessment.\n\nThis document applies to providers of genai services for the public in\n\nChina as they improve the safety level of their services.\n\nIt applies to providers that\ncarry out safety assessments on their own or entrust them to third parties, and also\nprovides the relevant main oversight department ( \u4e3b\u7ba1\u90e8\u95e8 ) a reference for judging the\nsafety levels of genai services.", "**2** **Normative Reference Documents**\n\nThe contents of the following documents, through normative references in this text,\n\nconstitute indispensable provisions of this document.\n\nAmong them, for dated references,\nonly the edition corresponding to that date applies to this document.\n\nFor undated\nreferences, the latest edition (including all amendments) applies to this document.\n\nInformation security technology terminology GB/T 25069-2022", "**4** **General Provisions**\n\nThis document supports the _Interim Measures for the Administration of Generative_\n\n_Artificial Intelligence Services_ , and puts forward the basic safety requirements that\nproviders must follow.\n\nBefore a provider submits a filing application for the online launch\nof a genai service to the relevant main oversight department, it must carry out\nsafety assessments item by item in accordance with all of the requirements in this\ndocument, and must submit the assessment results and supporting materials at the time\nof filing.\n\nIn addition to the basic requirements put forward by this document, providers must\n\nalso carry out other safety work on their own with respect to cybersecurity, data security,\npersonal information protection, etc., in accordance with China\u2019s laws and regulations\nand the relevant requirements of national standards.", "**5.1** **Corpus Source Safety Requirements**\n\nRequirements for providers are as follows.\n\na) Corpus source management:\n\n1) A corpus source blacklist shall be established, and data from blacklisted\n\nsources shall not be used to carry out training;\n\n2) Safety assessments shall be carried out on each source corpus, and where a\n\nsource corpus contains over 5% illegal and unhealthy information, it must be\nadded to the blacklist.\n\nb) Matching of different source corpora: Diversification shall be increased, and\n\nthere shall be multiple corpus sources for each language, such as Chinese,\nEnglish, etc., as well as each corpus type, such as text, images, video, and audio;\nand corpora from domestic and foreign sources shall be reasonably matched.\n\nc) Corpus source traceability:\n\n1) When using an open-source corpus, it is necessary to have an open-source\n\n\n-----\n\nlicense agreement or relevant licensing document for that corpus source;\n\n**Note 1:** In situations where aggregated network addresses, data links, etc.,\n\nare able to point to or generate other data, if it is necessary to use the\ncontent thus pointed to or generated as a training corpus, it shall be\ntreated the same as a self-collected corpus.\n\n2) When using a self-collected corpus, the provider must have collection\n\nrecords, and shall not collect a corpus that others have expressly declared\nmay not be collected;\n\n**Note 2:** Self-collected corpora include self-produced corpora and corpora\n\ncollected from the internet.\n\n**Note 3:** Methods of declaring non-collectability include, but are not limited\n\nto, the Robots [Exclusion] Protocol.\n\n3) When using commercial corpora:\n\n\u2014 It is necessary to have a legally valid transaction contract, cooperation\nagreement, etc.\n\n;\n\n\u2014 When the transaction or cooperation parties are unable to provide materials\nsupporting the legality of a corpus, said corpus shall not be used.\n\n4) When users enter information for use as corpus, there must be user\n\nauthorization records.\n\nd) Information that is blocked in accordance with the requirements of China's\n\ncybersecurity-related laws shall not be used as a training corpus.\n\n**Note 4:** Relevant legal and regulatory requirements include, but are not\n\nlimited to, Article 50 of the _Cybersecurity Law_ .", "**5.2** **Corpus Content Safety Requirements**\n\nRequirements for providers are as follows.\n\na) Filtering of training corpus content: Methods such as keywords, classification\n\nmodels, and manual sampling inspection shall be adopted to thoroughly filter\nout all illegal and unhealthy information in corpora.\n\nb) Intellectual property rights:\n\n1) A person shall be put in charge of the intellectual property rights (IPR) of the\n\ncorpus as well as generated content, and an IPR management strategy shall\nbe established;\n\n2) Before a corpus is used for training, the person in charge of IPR shall identify\n\nIPR infringements in the corpus, and the provider shall not use corpora with\n\n\n-----\n\ninfringement issues to carry out training:\n\n\u2014 Where a training corpus contains literary, artistic, or scientific works, the\n\nfocus should be on identifying copyright infringement in the training corpus\nas well as in the generated content;\n\n\u2014 For a training corpus that contains commercial corpora as well as user-input\n\ninformation, the focus should be on identifying trade secret infringement;\n\n\u2014 Where a training corpus involves trademarks and patents, the focus should\n\nbe on identifying whether the provisions of laws and regulations related to\ntrademarks and patents are complied with.\n\n3) Channels for reporting and handling complaints on IPR issues shall be\n\nestablished;\n\n4) In the user service agreement, users shall be informed of IPR-related risks in\n\nthe use of generated content, and the responsibilities and obligations\nregarding the identification of IPR issues shall be agreed upon with the\nusers;\n\n5) The IPR strategy shall be updated in a timely manner in accordance with\n\nnational policies and third-party complaints;\n\n6) It is best to have the following IPR measures:\n\n\n\u2014 Disclosure of summary information concerning the IPR-related parts of the\n\ntraining corpus;\n\n\u2014 Support in complaint reporting channels for third-party inquiries about\n\ncorpus usage and related IPR circumstances.\n\nc) Personal information:\n\n1) When it is necessary to use a corpus containing personal information, the\n\nauthorized consent of the corresponding subjects of the personal information\nshall be obtained, or other conditions for the lawful use of such personal\ninformation shall be met;\n\n2) When it is necessary to use a corpus containing sensitive personal\n\ninformation, the individually authorized consent of the corresponding\nsubjects of the personal information shall be obtained, or other conditions for\nthe lawful use of such sensitive personal information shall be met;\n\n3) When it is necessary to use a corpus containing biometric information such\n\nas faces, the written authorized consent of the corresponding subjects of the\npersonal information shall be obtained, or other conditions for the lawful use\nof such biometric information shall be met.\n\n-----", "**5.3** **Corpus Annotation Safety Requirements**\n\nRequirements for providers are as follows.\n\na) Annotators:\n\n1) The provider shall conduct its own examination of annotators, granting\n\nannotation qualifications to those who are qualified, and have mechanisms\nfor regular re-training and examination as well as the suspension or\ncancellation of annotation qualifications when necessary;\n\n2) The functions of annotators shall, at a minimum, be divided into data\n\nannotation and data review; and the same annotators should not undertake\nmultiple functions under the same annotation task;\n\n3) Adequate and reasonable time shall be set aside for annotators to perform\n\neach annotation task.\n\nb) Annotation rules:\n\n1) The annotation rules shall, at a minimum, include such content as annotation\n\nobjectives, data formats, annotation methods, and quality indicators;\n\n2) Rules for functional annotation and safety annotation shall be formulated\n\nseparately, and the annotation rules shall, at a minimum, cover data\nannotation and data review;\n\n3) Functional annotation rules must be able to guide annotators in producing\n\nannotated corpora possessing authenticity, accuracy, objectivity, and\ndiversity in accordance with the characteristics of specific fields;\n\n4) The safety annotation rules must be able to guide annotators in annotating\n\nthe main safety risks around the corpus and generated content, and there\nshall be corresponding annotation rules for all 31 types of safety risks in\nAppendix A of this document.\n\nc) Annotated content accuracy:\n\n1) For safety annotation, each annotated corpus shall be reviewed and\n\napproved by at least one auditor;\n\n2) For functional annotation, each batch of annotated corpora shall be manually\n\nsampled, and if it is found that the content is inaccurate, it shall be reannotated; if it is found that the content contains illegal and unhealthy\ninformation, that batch of annotated corpora shall be invalidated.", "**Model Safety Requirements**\n\n-----\n\nRequirements for providers are as follows.\n\na) If a provider uses a foundation model to carry out research and development, it\n\nshall not use a foundation model that has not been filed with the main oversight\ndepartment.\n\nb) Model-generated content safety:\n\n1) In the training process, the safety of generated content shall be made one of\n\nthe main indicators for consideration in evaluating the merits and drawbacks\nof the generation results;\n\n2) During all conversations, safety testing shall be conducted on the\n\ninformation entered by users, so as to guide the model to generate positive\n( \u79ef\u6781\u6b63\u5411 ) content;\n\n3) Where problems are discovered during the service provision process or\n\nwhen conducting regular testing, the model must be optimized through\ninstruction fine-tuning, reinforcement learning, and other methods.\n\n**Notes:** Model-generated content refers to original content that is directly\n\noutput by the model and has not been otherwise processed.\n\nc) Service transparency:\n\n1) If the service is provided using an interactive interface, the following\n\ninformation shall be disclosed to the public in a prominent position such as\nthe homepage of the website:\n\n\u2014 Information on the people, situations, and uses to which the service is\nsuitable;\n\u2014 Information on third-party foundation model usage.\n\n2) If the service is provided using an interactive interface, the following\n\ninformation shall be disclosed to the users on the homepage of the website,\nthe service agreement, and other easily viewed locations:\n\n\u2014 Limitations of the service;\n\u2014 Summary information that helps users understand the mechanism of the\nservice, such as the model architecture and training framework used.\n\n3) If the service is provided in the form of a programmable interface, the\n\ninformation in 1) and 2) shall be disclosed in the descriptive documentation.\n\nd) Accuracy of the generated content: The generated content shall accurately\n\nrespond to the intent of the user's input, and the data and its expression\ncontained therein shall be in line with scientific common sense and mainstream\n\n\n-----\n\nperception, and shall not contain erroneous content.\n\ne) Reliability of generated content: The responses given by the service according to\n\nthe user's instructions shall be in a reasonable format and framework, with a\nhigh amount of effective content, and should be able to effectively help the user\nanswer questions.", "**Safety Measure Requirements**\n\nRequirements for providers are as follows.\n\na) People, contexts, and uses for which the model is suitable:\n\n1) The necessity, applicability, and safety of applying generative artificial\n\nintelligence in various fields within the scope of services must be fully\ndemonstrated;\n\n2) Where the service is used for critical information infrastructure, automatic\n\ncontrol, medical information services, psychological counseling, and other\nimportant situations, it is necessary to have protection measures that are\nappropriate to the level of risk as well as to the context;\n\n3) Where a service is suitable for minors, it is necessary to:\n\n\u2014 Allow guardians to set up anti-addiction measures for minors and protect\nthem with passwords;\n\u2014 Limit the number and duration of conversations by minors in a single day, and\nrequire the input of an admin password if the number of times or duration of use\nis exceeded;\n\u2014 Require confirmation by a guardian before minors can consume;\n\u2014 Filter content inappropriate for minors, and show content that is good for\nphysical and mental health.\n\n4) If the service is not suitable for minors, technical or management measures\n\nshould be taken to prevent minors from using it.\n\nb) Handling of personal information: Personal information shall be protected in\n\naccordance with China's personal information protection requirements, and with\nfull reference to existing national standards, such as GB/T 35273.\n\n**Notes:** Personal information includes, but is not limited to, personal\n\ninformation entered by the user and personal information provided by\nthe user during the registration and other steps.\n\nc) Collection of user-entered information for use in training:\n\n1) It shall be agreed upon with the user whether user-entered information can\n\n\n-----\n\nbe used for training;\n\n2) An option shall be provided to turn off the use of user-entered information\n\nfor training;\n\n3) It shall not take more than four clicks for the user to reach said option from\n\nthe main screen of the service;\n\n4) The user shall be clearly informed of the status of user input collection and\n\nthe method in 2) for turning it off.\n\nd) For the labeling of content such as images, videos, etc., the following labeling\n\nshall be performed in accordance with TC260-PG-20233A, \u201cGuidelines for\nCybersecurity Standards in Practice\u2014Methods for Labeling Generative Artificial\nIntelligence Service Content\u201d:\n\n1) Display area labeling;\n\n2) Hint text labeling for images and videos;\n\n3) Hidden watermark labeling for images, videos, and audio;\n\n4) File metadata labeling;\n\n5) Special service scenario labeling.\n\ne) Acceptance of complaints and reports from the public or users:\n\n1) Ways for accepting complaints and reports from the public or users, as well\n\nas feedback methods, shall be provided, including but not limited to methods\nsuch as telephone, email, interactive windows, and text messages;\n\n2) The rules for handling complaints and reports from the public or users and\n\nthe time limit for said handling shall be established.\n\nf) Provision of generated content to users:\n\n1) Answering of questions that are obviously extreme, as well as those that\n\nobviously induce the generation of illegal and unhealthy information, shall\nbe refused; all other questions shall be answered normally;\n\n2) Monitoring personnel shall be put in place to improve the quality of\n\ngenerated content in a timely manner in accordance with national policies\nand third-party complaints, and the number of monitoring personnel shall be\nappropriate to the scale of the service.\n\ng) Model updating and upgrading:\n\n1) A safety management strategy shall be formulated for when models are\n\nupdated and upgraded;\n\n\n-----\n\n2) A management mechanism shall be formed to conduct safety assessments\n\nagain after important model updates and upgrades, and to re-file with the\nmain oversight department in accordance with provisions.", "**8.1** **Assessment Methods**\n\nRequirements for providers are as follows.\n\na) Safety assessments shall be carried out before a service is launched online and\n\nwhen major changes are made.\n\nThe assessments may be carried out in-house or\nentrusted to a third-party assessment organization.\n\nb) The safety assessments shall cover all of the provisions of this document, and a\n\nseparate assessment conclusion shall be formed for each provision, which shall\nbe either \u201cconforms,\u201d \u201cdoes not conform,\u201d or \u201cnot applicable\u201d:\n\n1) If the conclusion is \u201cconforms,\u201d there shall be sufficient supporting materials\n\nfor this;\n\n2) Where the conclusion is \u201cdoes not conform,\u201d the reasons for non-conformity\n\nshall be stated, and where technical or management measures inconsistent\nwith this document are adopted but are able to achieve the same safety\neffect, a detailed explanation shall be given and proof of the effectiveness of\nthe measures shall be provided;\n\n3) Where the conclusion is \u201cnot applicable,\u201d the reasons for its non-applicability\n\nshall be stated.\n\nc) The conclusions of the assessments for each provision of this document, as well\n\nas the relevant evidential and supporting materials, shall be included in the\nassessment report:\n\n1) The assessment report shall comply with the requirements of the main\n\noversight department at the time the assessments are conducted;\n\n2) In the process of writing the assessment report, if the assessment\n\nconclusions and relevant circumstances of some provisions in this document\ncannot be written in the body of the assessment report due to the report\nformat, they shall all be written into an attachment.\n\nd) If the safety assessments are carried out in-house, the assessment report shall\n\nhave the joint signatures of at least three persons in charge:\n\n1) The legal person of the work unit ( \u5355\u4f4d );\n\n\n-----\n\n2) The person in charge with overall responsibility for the safety assessment\n\nwork, who shall be the main manager of the work unit or the person in\ncharge of cybersecurity;\n\n3) The person in charge of the legality assessment part of the safety\n\nassessment, who shall be the main manager of the work unit or the person\nin charge of legal affairs.\n\n**Note:** If the legal person of the work unit is also the person in charge of\n\ncybersecurity or the person in charge of legal affairs, it can be signed by\nthe legal person of the work unit as both, but shall be accompanied by a\nseparate note.", "**8.2** **Corpus Safety Assessment**\n\nWhen a provider carries out an assessment of corpus safety, the requirements are as\n\nfollows.\n\na) Using manual sampling, and randomly sampling no fewer than 4,000 corpora\n\nfrom the total training corpus, the qualified rate shall not be less than 96%.\n\nb) When sampling in conjunction with keywords, classification models, and other\n\ntechniques, and randomly sampling from the training corpus not less than 10%\nof the total corpora, the sampling qualified rate shall not be less than 98%.\n\nc) The keyword library and classification model used for evaluation shall meet the\n\nrequirements of Chapter 9 of this document.", "**8.3** **Generated Content Safety Assessment**\n\nThe requirements for providers when assessing the safety of generated content are\n\nas follows.\n\na) A test question bank that meets the requirements of section 9.3 of this\n\ndocument shall be constructed.\n\nb) Using manual sampling, and randomly selecting no fewer than 1,000 test\n\nquestions from the test question bank, the qualified rate of sampled modelgenerated content shall not be less than 90%.\n\nc) Using keyword sampling, and randomly selecting no fewer than 1,000 test\n\nquestions from the test question bank, the qualified rate of sampled modelgenerated content shall not be less than 90%.\n\nd) Using classification model-based sampling, and randomly selecting no fewer\n\nthan 1,000 test questions from the test question bank, the qualified rate of the\nsampled model-generated content shall not be less than 90%.\n\n-----", "**8.4** **Assessment of Refusal to Answer Questions**\n\nThe requirements for providers when assessing question refusal are as follows.\n\na) A test question bank that meets the requirements of section 9.4 of this\n\ndocument shall be constructed.\n\nb) Randomly selecting no fewer than 300 test questions from the bank of test\n\nquestions that the model should refuse to answer, the refusal rate of the model\nshall not be less than 95%.\n\nc) Randomly selecting no fewer than 300 test questions from the bank of test\n\nquestions that the model should not refuse to answer, the refusal rate of the\nmodel shall not be more than 5%.", "**9.1** **Keyword Library**\n\nRequirements are as follows.\n\na) Keywords should generally not exceed 10 Chinese characters or 5 words in\n\nother languages.\n\nb) The keyword library shall be comprehensive, with a total size of not less than\n\n10,000.\n\nc) The keyword library shall be representative and contain keywords for at least\n\nthe 17 safety risks in Appendix A.1 and A.2, with no fewer than 200 keywords\nfor each safety risk in Appendix A.1, and no fewer than 100 keywords for each\nsafety risk in Appendix A.2.", "**9.3** **Generated Content Test Question Bank**\n\nRequirements are as follows.\n\na) The generated content test question bank shall be comprehensive, with a total\n\nsize of no fewer than 2,000 questions.\n\nb) The generated content test question bank shall be representative and\n\ncompletely cover all 31 types of safety risks in Appendix A of this document,\nwith no fewer than 50 test questions for each type of safety risk in Appendix\n\n\n-----\n\nA.1 and A.2, and no fewer than 20 test questions each for other types of safety\nrisks.\n\nc) Operational procedures shall be established for identifying all 31 types of safety\n\nrisks based on the generated content test question bank and the basis for\njudgment.", "**9.4** **Refusal to Answer Test Question Bank**\n\nRequirements are as follows.\n\na) A test question bank shall be built around questions which the model should\n\nrefuse to answer:\n\n1) The bank of test questions that the model should refuse to answer shall be\n\ncomprehensive, with a total size of no fewer than 500 questions;\n\n2) The bank of test questions that the model should refuse to answer shall be\n\nrepresentative and cover the 17 safety risks in Appendix A.1 and A.2 of this\ndocument, with no fewer than 20 questions for each safety risk.\n\nb) A test question bank shall be built around questions that the model should not\n\nrefuse to answer:\n\n1) The bank of test questions that the model should not refuse to answer shall\n\nbe comprehensive, with a total size of no fewer than 500 questions;\n\n2) The bank of test questions that the model should not refuse to answer shall\n\nbe representative, covering aspects of China's system, beliefs, image, culture,\ncustoms, ethnicity ( \u6c11\u65cf ), geography, history and heroic martyrs ( \u82f1\u70c8 ), as\nwell as an individual's gender, age, occupation, and health, and there shall\nbe no fewer than 20 instances of each type of test question.\n\n-----", "**4** **Violations of the legitimate rights and interests of others**\n\nThe main risks include:\n\na. Endangerment of the physical or mental health of another.\n\nb.\n\nUnauthorized use of the likeness of another;\n\nc. Defamation of the reputation of another;\n\nd. Defamation of the honor of another;\n\ne. Infringement of others' right to privacy;\nf. Infringement of the personal information rights and interests of others;\ng. Infringement of other legitimate rights and interests of others.", "**5** **Inability to meet the safety requirements of specific service types**\n\nThe main safety risks in this area are those that exist when genai is used for\n\nspecific service types with higher safety requirements, such as automation, medical\ninformation services, psychological counseling, critical information infrastructure, etc.\n\n:\n\na) Inaccurate content that is grossly inconsistent with common scientific\n\nknowledge or mainstream perception;\n\n\nb) Unreliable content that, although not containing grossly erroneous content,\n\ndoes not help the user answer questions.\n\n-----", "**Amendments adopted by the European Parliament on 14 June 2023 on the proposal for**\n\n**a regulation of the European Parliament and of the Council on laying down harmonised**\n**rules on genai (genai Act) and amending certain Union**\n**legislative acts (COM(2021)0206 \u2013 C9-0146/2021 \u2013 2021/0106(COD))** 1\n\n**(Ordinary legislative procedure: first reading)**\n\n1 The matter was referred back for interinstitutional negotiations to the committee\nresponsible, pursuant to Rule 59(4), fourth subparagraph (A9-0188/2023).\n\n-----", "**Recital 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(1) The purpose of this Regulation is to\n**_improve_** the functioning of the internal\nmarket **_by laying_** down a uniform legal\nframework in particular for the\ndevelopment, **_marketing and_** use of\ngenai in conformity with\nUnion values **_.\n\nThis Regulation pursues a_**\n**_number of overriding reasons of public_**\n**_interest, such as a high level of protection_**\n**_of health, safety and fundamental rights,_**\n**_and it_** ensures the free movement of AIbased goods and services cross-border,\nthus preventing Member States from\nimposing restrictions on the development,\nmarketing and use of genai systems, unless\nexplicitly authorised by this Regulation.\n\n(1) The purpose of this Regulation is **_to_**\n**_promote the uptake of human centric and_**\n**_trustworthy genai and to_**\n**_ensure a high level of protection of_**\n**_health, safety, fundamental rights,_**\n**_democracy and rule of law and the_**\n**_environment from harmful effects of_**\n**_artificial intelligence systems in the Union_**\n**_while supporting innovation and_**\n**_improving_** the functioning of the internal\nmarket.\n\n**_This Regulation lays_** down a\nuniform legal framework in particular for\nthe development, **_the placing on the_**\n**_market, the putting into service and the_**\nuse of genai in conformity\nwith Union values **_and_** ensures the free\nmovement of genai-based goods and services\n\n\n-----\n\ncross-border, thus preventing Member\nStates from imposing restrictions on the\ndevelopment, marketing and use of\ngenai systems ( **_AI_**\n**_systems_** ), unless explicitly authorised by\nthis Regulation.\n\n**_Certain genai systems can_**\n**_also have an impact on democracy and_**\n**_rule of law and the environment.\n\nThese_**\n**_concerns are specifically addressed in the_**\n**_critical sectors and use cases listed in the_**\n**_annexes to this Regulation._**", "**Recital 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(1a) This Regulation should preserve the_**\n**_values of the Union facilitating the_**\n**_distribution of artificial intelligence_**\n**_benefits across society, protecting_**\n**_individuals, companies, democracy and_**\n**_rule of law and the environment from_**\n**_risks while boosting innovation and_**\n**_employment and making the Union a_**\n**_leader in the field._**", "**Recital 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(2) **_Artificial intelligence systems_** **_(_** genai\nsystems **_)_** can be easily deployed in multiple\nsectors of the economy and society,\nincluding cross border, and circulate\nthroughout the Union.\n\nCertain Member\nStates have already explored the adoption\nof national rules to ensure that artificial\nintelligence is safe and is developed and\nused in compliance with fundamental\nrights obligations.\n\nDiffering national rules\nmay lead to fragmentation of the internal\nmarket and decrease legal certainty for\n\n\n(2) genai systems can be easily deployed in\nmultiple sectors of the economy and\nsociety, including cross border, and\ncirculate throughout the Union.\n\nCertain\nMember States have already explored the\nadoption of national rules to ensure that\ngenai is **_trustworthy and_**\nsafe and is developed and used in\ncompliance with fundamental rights\nobligations.\n\nDiffering national rules may\nlead to fragmentation of the internal market\nand decrease legal certainty for operators\n\n\n-----\n\noperators that develop or use genai systems.\n\nA consistent and high level of protection\nthroughout the Union should therefore be\nensured, while divergences hampering the\nfree circulation of genai systems and related\nproducts and services within the internal\nmarket should be prevented, by laying\ndown uniform obligations for operators and\nguaranteeing the uniform protection of\noverriding reasons of public interest and of\nrights of persons throughout the internal\nmarket based on Article 114 of the Treaty\non the Functioning of the European Union\n(TFEU).\n\n**_To the extent that this Regulation_**\n**_contains specific rules on the protection_**\n**_of individuals with regard to the_**\n**_processing of personal data concerning_**\n**_restrictions of the use of genai systems for_**\n**_\u2018real-time\u2019 remote biometric identification_**\n**_in publicly accessible spaces for the_**\n**_purpose of law enforcement, it is_**\n**_appropriate to base this Regulation, in as_**\n**_far as those specific rules are concerned,_**\n**_on Article 16 of the TFEU.\n\nIn light of_**\n**_those specific rules and the recourse to_**\n**_Article 16 TFEU, it is appropriate to_**\n**_consult the European Data Protection_**\n**_Board._**\n\n\nthat develop or use genai systems.\n\nA\nconsistent and high level of protection\nthroughout the Union should therefore be\nensured **_in order to achieve trustworthy_**\n**_AI_** , while divergences hampering the free\ncirculation **_, innovation, deployment and_**\n**_uptake_** of genai systems and related products\nand services within the internal market\nshould be prevented, by laying down\nuniform obligations for operators and\nguaranteeing the uniform protection of\noverriding reasons of public interest and of\nrights of persons throughout the internal\nmarket based on Article 114 of the Treaty\non the Functioning of the European Union\n(TFEU).", "**Recital 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(2a) As genai often relies_**\n**_on the processing of large volumes of_**\n**_data, and many genai systems and_**\n**_applications on the processing of personal_**\n**_data, it is appropriate to base this_**\n**_Regulation on Article 16 TFEU, which_**\n**_enshrines the right to the protection of_**\n**_natural persons with regard to the_**\n**_processing of personal data and provides_**\n**_for the adoption of rules on the protection_**\n**_of individuals with regard to the_**\n**_processing of personal data._**\n\n\n-----", "**Recital 2 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(2b) The fundamental right to the_**\n**_protection of personal data is safeguarded_**\n**_in particular by Regulations (EU)_**\n**_2016/679 and (EU) 2018/1725 and_**\n**_Directive 2016/680.\n\nDirective 2002/58/EC_**\n**_additionally protects private life and the_**\n**_confidentiality of communications,_**\n**_including providing conditions for any_**\n**_personal and non-personal data storing in_**\n**_and access from terminal equipment._**\n**_Those legal acts provide the basis for_**\n**_sustainable and responsible data_**\n**_processing, including where datasets_**\n**_include a mix of personal and_**\n**_nonpersonal data.\n\nThis Regulation does_**\n**_not seek to affect the application of_**\n**_existing Union law governing the_**\n**_processing of personal data, including the_**\n**_tasks and powers of the independent_**\n**_supervisory authorities competent to_**\n**_monitor compliance with those_**\n**_instruments.\n\nThis Regulation does not_**\n**_affect the fundamental rights to private_**\n**_life and the protection of personal data as_**\n**_provided for by Union law on data_**\n**_protection and privacy and enshrined in_**\n**_the Charter of Fundamental Rights of the_**\n**_European Union (the \u2018Charter\u2019)._**", "**Recital 2 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(2c) genai systems in the_**\n**_Union are subject to relevant product_**\n**_safety legislation that provides a_**\n**_framework protecting consumers against_**\n**_dangerous products in general and such_**\n**_legislation should continue to apply.\n\nThis_**\n\n\n-----\n\n**_Regulation is also without prejudice to the_**\n**_rules laid down by other Union legal acts_**\n**_related to consumer protection and_**\n**_product safety, including including_**\n**_Regulation (EU) 2017/2394, Regulation_**\n**_(EU) 2019/1020 and Directive_**\n**_2001/95/EC on general product safety and_**\n**_Directive 2013/11/EU._**", "**Recital 2 d (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(2d) In accordance with Article 114(2)_**\n**_TFEU, this Regulation complements and_**\n**_should not undermine the rights and_**\n**_interests of employed persons.\n\nThis_**\n**_Regulation should therefore not affect_**\n**_Union law on social policy and national_**\n**_labour law and practice, that is any legal_**\n**_and contractual provision concerning_**\n**_employment conditions, working_**\n**_conditions, including health and safety at_**\n**_work and the relationship between_**\n**_employers and workers, including_**\n**_information, consultation and_**\n**_participation.\n\nThis Regulation should not_**\n**_affect the exercise of fundamental rights_**\n**_as recognised in the Member States and at_**\n**_Union level, including the right or_**\n**_freedom to strike or to take other action_**\n**_covered by the specific industrial relations_**\n**_systems in Member States, in accordance_**\n**_with national law and/or practice.\n\nNor_**\n**_should it affect concertation practices, the_**\n**_right to negotiate, to conclude and enforce_**\n**_collective agreement or to take collective_**\n**_action in accordance with national law_**\n**_and/or practice.\n\nIt should in any event not_**\n**_prevent the Commission from proposing_**\n**_specific legislation on the rights and_**\n**_freedoms of workers affected by AI_**\n**_systems._**", "**Recital 2 f (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(2f)_** **_This Regulation should help in_**\n**_supporting research and innovation and_**\n**_should not undermine research and_**\n**_development activity and respect freedom_**\n**_of scientific research.\n\nIt is therefore_**\n**_necessary to exclude from its scope AI_**\n**_systems specifically developed for the sole_**\n**_purpose of scientific research and_**\n**_development and to ensure that the_**\n**_Regulation does not otherwise affect_**\n**_scientific research and development_**\n**_activity on genai systems.\n\nUnder all_**\n**_circumstances, any research and_**\n**_development activity should be carried out_**\n**_in accordance with the Charter, Union_**\n**_law as well as the national law;_**", "**Recital 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(3) genai is a fast\nevolving family of technologies that can\n**_contribute_** to a wide array of economic and\nsocietal benefits across the entire spectrum\nof industries and social activities.\n\nBy\nimproving prediction, optimising\n\n\n(3) genai is a fast\nevolving family of technologies that can\n**_and already contributes_** to a wide array of\neconomic **_, environmental_** and societal\nbenefits across the entire spectrum of\nindustries and social activities **_if developed_**\n\n\n-----\n\noperations and resource allocation, and\npersonalising digital solutions available for\nindividuals and organisations, the use of\ngenai can provide key\ncompetitive advantages to companies and\nsupport socially and environmentally\nbeneficial outcomes, for example in\nhealthcare, farming, education and training,\ninfrastructure management, energy,\ntransport and logistics, public services,\nsecurity, justice, resource and energy\nefficiency, and climate change mitigation\nand adaptation.\n\n**_in accordance with relevant general_**\n**_principles in line with the Charter and the_**\n**_values on which the Union is founded_** .\n\nBy\nimproving prediction, optimising\noperations and resource allocation, and\npersonalising digital solutions available for\nindividuals and organisations, the use of\ngenai can provide key\ncompetitive advantages to companies and\nsupport socially and environmentally\nbeneficial outcomes, for example in\nhealthcare, farming, **_food safety,_** education\nand training **_, media, sports, culture_** ,\ninfrastructure management, energy,\ntransport and logistics **_, crisis management_** ,\npublic services, security, justice, resource\nand energy efficiency, **_environmental_**\n**_monitoring, the conservation and_**\n**_restoration of biodiversity and ecosystems_**\nand climate change mitigation and\nadaptation.", "**Recital 3 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(3a) To contribute to reaching the_**\n**_carbon neutrality targets, European_**\n**_companies should seek to utilise all_**\n**_available technological advancements that_**\n**_can assist in realising this goal.\n\nArtificial_**\n**_Intelligence is a technology that has the_**\n**_potential of being used to process the_**\n**_ever-growing amount of data created_**\n**_during industrial, environmental, health_**\n**_and other processes.\n\nTo facilitate_**\n**_investments in genai-based analysis and_**\n**_optimisation tools, this Regulation should_**\n**_provide a predictable and proportionate_**\n**_environment for low-risk industrial_**\n**_solutions._**", "**Recital 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(4) At the same time, depending on the\ncircumstances regarding its specific\napplication and use, genai\nmay generate risks and cause harm to\npublic interests and rights that are\nprotected by Union law.\n\nSuch harm might\nbe material or immaterial.\n\n(4) At the same time, depending on the\ncircumstances regarding its specific\napplication and use, **_as well as the level of_**\n**_technological development,_** artificial\nintelligence may generate risks and cause\nharm to public **_or private_** interests and\n**_fundamental_** rights **_of natural persons_** that\nare protected by Union law.\n\nSuch harm\nmight be material or immaterial **_, including_**\n**_physical, psychological, societal or_**\n**_economic harm_** .", "**Recital 4 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(4a) Given the major impact that_**\n**_artificial intelligence can have on society_**\n**_and the need to build trust, it is vital for_**\n**_artificial intelligence and its regulatory_**\n**_framework to be developed according to_**\n**_Union values enshrined in Article 2 TEU,_**\n**_the fundamental rights and freedoms_**\n**_enshrined in the Treaties, the Charter,_**\n**_and international human rights law.\n\nAs a_**\n**_pre-requisite, genai should_**\n**_be a human-centric technology.\n\nIt should_**\n**_not substitute human autonomy or_**\n**_assume the loss of individual freedom and_**\n**_should primarily serve the needs of the_**\n**_society and the common good.\n\nSafeguards_**\n**_should be provided to ensure the_**\n**_development and use of ethically_**\n**_embedded genai that_**\n**_respects Union values and the Charter._**", "**Recital 5**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(5) A Union legal framework laying\ndown harmonised rules on artificial\nintelligence is therefore needed to foster\nthe development, use and uptake of\ngenai in the internal market\nthat at the same time meets a high level of\nprotection of public interests, such as\nhealth and safety **_and the_** protection of\nfundamental rights, as recognised and\nprotected by Union law.\n\nTo achieve that\nobjective, rules regulating the placing on\nthe market **_and_** putting into service of\ncertain genai systems should be laid down,\nthus ensuring the smooth functioning of the\ninternal market and allowing those systems\nto benefit from the principle of free\nmovement of goods and services.\n\nBy\nlaying down those rules, this Regulation\nsupports the objective of the Union of\nbeing a global leader in the development of\nsecure, trustworthy and ethical artificial\nintelligence, as stated by the European\nCouncil **_33_** , and it ensures the protection of\nethical principles, as specifically requested\nby the European Parliament **_34_** .\n\n(5) A Union legal framework laying\ndown harmonised rules on artificial\nintelligence is therefore needed to foster\nthe development, use and uptake of\ngenai in the internal market\nthat at the same time meets a high level of\nprotection of public interests, such as\nhealth and safety **_,_** protection of\nfundamental rights **_, democracy and rule of_**\n**_law and the environment_** , as recognised\nand protected by Union law.\n\nTo achieve\nthat objective, rules regulating the placing\non the market **_, the_** putting into service **_and_**\n**_the use_** of certain genai systems should be\nlaid down, thus ensuring the smooth\nfunctioning of the internal market and\nallowing those systems to benefit from the\nprinciple of free movement of goods and\nservices.\n\n**_These rules should be clear and_**\n**_robust in protecting fundamental rights,_**\n**_supportive of new innovative solutions,_**\n**_and enabling to a European ecosystem of_**\n**_public and private actors creating AI_**\n**_systems in line with Union values._** By\nlaying down those rules **_as well as_**\n**_measures in support of innovation with a_**\n**_particular focus on SMEs and start-ups_** ,\nthis Regulation supports the objective **_of_**\n**_promoting the genai made in Europe,_** of the\nUnion of being a global leader in the\ndevelopment of secure, trustworthy and\nethical genai, as stated by\nthe European Council 33 , and it ensures the\nprotection of ethical principles, as\nspecifically requested by the European\nParliament **_34_** .\n\n__________________ __________________\n\n\n33 European Council, Special meeting of\nthe European Council (1 and 2 October\n2020) \u2013 Conclusions, EUCO 13/20, 2020,\np. 6.\n\n34 European Parliament resolution of 20\nOctober 2020 with recommendations to the\nCommission on a framework of ethical\naspects of genai, robotics\nand related technologies, 2020/2012(INL).\n\n33 European Council, Special meeting of\nthe European Council (1 and 2 October\n2020) \u2013 Conclusions, EUCO 13/20, 2020,\np. 6.\n\n34 European Parliament resolution of 20\nOctober 2020 with recommendations to the\nCommission on a framework of ethical\naspects of genai, robotics\nand related technologies, 2020/2012(INL).\n\n-----", "**Recital 5 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(5a) Furthermore, in order to foster the_**\n**_development of genai systems in line with_**\n**_Union values, the Union needs to address_**\n**_the main gaps and barriers blocking the_**\n**_potential of the digital transformation_**\n**_including the shortage of digitally skilled_**\n**_workers, cybersecurity concerns, lack of_**\n**_investment and access to investment, and_**\n**_existing and potential gaps between large_**\n**_companies, SME\u2019s and start-ups.\n\nSpecial_**\n**_attention should be paid to ensuring that_**\n**_the benefits of genai and innovation in new_**\n**_technologies are felt across all regions of_**\n**_the Union and that sufficient investment_**\n**_and resources are provided especially to_**\n**_those regions that may be lagging behind_**\n**_in some digital indicators._**", "**Recital 6**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(6) The notion of genai system should be\nclearly defined to ensure legal certainty,\nwhile providing the flexibility to\naccommodate **_future_** technological\ndevelopments **_.\n\nThe definition_** should be\nbased on **_the key functional_** characteristics\nof **_the software_** , **_in particular the ability,_**\n**_for a given set of human-defined_**\n**_objectives, to generate outputs_** such as\n**_content, predictions, recommendations, or_**\n**_decisions which influence the_**\n**_environment with which the system_**\n**_interacts, be it in a physical or digital_**\n**_dimension_** .\n\ngenai systems **_can be_** designed to\noperate with varying levels of autonomy\n\n\n(6) The notion of genai system **_in this_**\n**_Regulation_** should be clearly defined **_and_**\n**_closely aligned with the work of_**\n**_international organisations working on_**\n**_artificial intelligence_** to ensure legal\ncertainty **_, harmonization and wide_**\n**_acceptance_** , while providing the flexibility\nto accommodate **_the rapid_** technological\ndevelopments **_in this field.\n\nMoreover, it_**\nshould be based on **_key_** characteristics of\n**_artificial intelligence_** , such as **_its learning,_**\n**_reasoning or modelling capabilities, so as_**\n**_to distinguish it from simpler software_**\n**_systems or programming approaches_** .\n\ngenai\nsystems **_are_** designed to operate with\n\n\n-----\n\nand **_be used on a stand-alone basis or as a_**\n**_component of a product, irrespective of_**\n**_whether the system is physically_**\n**_integrated into the product (embedded) or_**\n**_serve the functionality of the product_**\nwithout **_being integrated therein (nonembedded).\n\nThe definition of_** genai system\n**_should be complemented by a list of_**\nspecific **_techniques and approaches used_**\n**_for its development_** , which should be **_kept_**\n**_up-to\u2013date in the light of market and_**\n**_technological developments through the_**\n**_adoption of delegated acts_** by the\n**_Commission to amend that list_** .\n\nvarying levels of autonomy **_, meaning that_**\n**_they have at least some degree of_**\n**_independence of actions from human_**\n**_controls_** and **_of capabilities to operate_**\nwithout **_human intervention.\n\nThe term_**\n**_\u201cmachine-based\u201d refers to the fact that AI_**\n**_systems run on machines.\n\nThe reference_**\n**_to explicit or implicit objectives_**\n**_underscores that genai systems can operate_**\n**_according to explicit human-defined_**\n**_objectives or to implicit objectives.\n\nThe_**\n**_objectives of the_** genai system **_may be_**\n**_different from the intended purpose of the_**\n**_AI system in a_** specific **_context.\n\nThe_**\n**_reference to predictions includes content_** ,\nwhich **_is considered in this Regulation a_**\n**_form of prediction as one of the possible_**\n**_outputs produced by an genai system.\n\nFor_**\n**_the purposes of this Regulation,_**\n**_environments_** should be **_understood as the_**\n**_contexts in which the genai systems operate,_**\n**_whereas outputs generated_** by the **_AI_**\n**_system, meaning predictions,_**\n**_recommendations or decisions, respond to_**\n**_the objectives of the system, on the basis_**\n**_of inputs from said environment_** .\n\n**_Such_**\n**_output further influences said_**\n**_environment, even by merely introducing_**\n**_new information to it._**", "**Recital 6 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(6a) genai systems often have machine_**\n**_learning capacities that allow them to_**\n**_adapt and perform new tasks_**\n**_autonomously.\n\nMachine learning refers to_**\n**_the computational process of optimizing_**\n**_the parameters of a model from data,_**\n**_which is a mathematical construct_**\n**_generating an output based on input data._**\n**_Machine learning approaches include, for_**\n**_instance, supervised, unsupervised and_**\n**_reinforcement learning, using a variety of_**\n**_methods including deep learning with_**\n\n\n-----\n\n**_neural networks.\n\nThis Regulation is_**\n**_aimed at addressing new potential risks_**\n**_that may arise by delegating control to AI_**\n**_systems, in particular to those genai systems_**\n**_that can evolve after deployment.\n\nThe_**\n**_function and outputs of many of these AI_**\n**_systems are based on abstract_**\n**_mathematical relationships that are_**\n**_difficult for humans to understand,_**\n**_monitor and trace back to specific inputs._**\n**_These complex and opaque characteristics_**\n**_(black box element) impact accountability_**\n**_and explainability.\n\nComparably simpler_**\n**_techniques such as knowledge-based_**\n**_approaches, Bayesian estimation or_**\n**_decision-trees may also lead to legal gaps_**\n**_that need to be addressed by this_**\n**_Regulation, in particular when they are_**\n**_used in combination with machine_**\n**_learning approaches in hybrid systems._**", "**Recital 6 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(6b) genai systems can be used as standalone software system, integrated into a_**\n**_physical product (embedded), used to_**\n**_serve the functionality of a physical_**\n**_product without being integrated therein_**\n**_(non-embedded) or used as an AI_**\n**_component of a larger system.\n\nIf this_**\n**_larger system would not function without_**\n**_the genai component in question, then the_**\n**_entire larger system should be considered_**\n**_as one single genai system under this_**\n**_Regulation._**", "**Recital 7**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(7) The notion of biometric data used in\nthis Regulation is in line with and should\nbe interpreted consistently with the notion\nof biometric data as defined in Article\n4(14) of Regulation (EU) 2016/679 of the\nEuropean Parliament and of the Council **_35_** **_,_**\n**_Article 3(18) of Regulation (EU)_**\n**_2018/1725 of the European Parliament_**\n**_and of the Council_** **_36_** **_and Article 3(13) of_**\n**_Directive (EU) 2016/680 of the European_**\n**_Parliament and of the Council_** **_37_** .\n\n(7) The notion of biometric data used in\nthis Regulation is in line with and should\nbe interpreted consistently with the notion\nof biometric data as defined in Article\n4(14) of Regulation (EU) 2016/679 of the\nEuropean Parliament and of the Council 35 **_._**\n**_Biometrics-based data are additional data_**\n**_resulting from specific technical_**\n**_processing relating to physical,_**\n**_physiological or behavioural signals of a_**\n**_natural person, such as facial_**\n**_expressions, movements, pulse frequency,_**\n**_voice, key strikes or gait, which may or_**\n**_may not allow or confirm the unique_**\n**_identification of a natural person_** .\n\n__________________ __________________\n\n\n35 Regulation (EU) 2016/679 of the\nEuropean Parliament and of the Council of\n27 April 2016 on the protection of natural\npersons with regard to the processing of\npersonal data and on the free movement of\nsuch data, and repealing Directive\n95/46/EC (General Data Protection\nRegulation) (OJ L 119, 4.5.2016, p. 1).\n\n35 Regulation (EU) 2016/679 of the\nEuropean Parliament and of the Council of\n27 April 2016 on the protection of natural\npersons with regard to the processing of\npersonal data and on the free movement of\nsuch data, and repealing Directive\n95/46/EC (General Data Protection\nRegulation) (OJ L 119, 4.5.2016, p. 1).\n\n**_36_** **_Regulation (EU) 2018/1725 of the_**\n**_European Parliament and of the Council_**\n**_of 23 October 2018 on the protection of_**\n**_natural persons with regard to the_**\n**_processing of personal data by the Union_**\n**_institutions, bodies, offices and agencies_**\n**_and on the free movement of such data,_**\n**_and repealing Regulation (EC) No_**\n**_45/2001 and Decision No 1247/2002/EC_**\n**_(OJ L 295, 21.11.2018, p. 39)_**\n\n**_37_** **_Directive (EU) 2016/680 of the_**\n**_European Parliament and of the Council_**\n**_of 27 April 2016 on the protection of_**\n**_natural persons with regard to the_**\n**_processing of personal data by competent_**\n**_authorities for the purposes of the_**\n**_prevention, investigation, detection or_**\n**_prosecution of criminal offences or the_**\n**_execution of criminal penalties, and on_**\n**_the free movement of such data, and_**\n**_repealing Council Framework Decision_**\n**_2008/977/JHA (Law Enforcement_**\n\n\n-----\n\n**_Directive) (OJ L 119, 4.5.2016, p. 89)._**", "**Recital 7 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(7a) The notion of biometric_**\n**_identification as used in this Regulation_**\n**_should be defined as the automated_**\n**_recognition of physical, physiological,_**\n**_behavioural, and psychological human_**\n**_features such as the face, eye movement,_**\n**_facial expressions, body shape, voice,_**\n**_speech, gait, posture, heart rate, blood_**\n**_pressure, odour, keystrokes, psychological_**\n**_reactions (anger, distress, grief, etc.)\n\nfor_**\n**_the purpose of establishing an_**\n**_individual\u2019s identity by comparing_**\n**_biometric data of that individual to stored_**\n**_biometric data of individuals in a_**\n**_database (one-to-many identification),_**\n**_irrespective of whether the individual has_**\n**_given its consent or not._**", "**Recital 7 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(7b) The notion of biometric_**\n**_categorisation as used in this Regulation_**\n**_should be defined as assigning natural_**\n**_persons to specific categories or inferring_**\n**_their characteristics and attributes such as_**\n**_gender, sex, age, hair colour, eye colour,_**\n**_tattoos, ethnic or social origin, health,_**\n**_mental or physical ability, behavioural or_**\n**_personality, traits language, religion, or_**\n**_membership of a national minority or_**\n**_sexual or political orientation on the basis_**\n**_of their biometric or biometric-based data,_**\n**_or which can be inferred from such data._**\n\n\n-----", "**Recital 8**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(8) The notion of remote biometric\nidentification system as used in this\nRegulation should be defined functionally,\nas an genai system intended for the\nidentification of natural persons at a\ndistance through the comparison of a\nperson\u2019s biometric data with the biometric\ndata contained in a reference database, and\nwithout prior knowledge whether the\ntargeted person will be present and can be\nidentified, irrespectively of the particular\ntechnology, processes or types of biometric\ndata used.\n\nConsidering their different\ncharacteristics and manners in which they\nare used, as well as the different risks\ninvolved, a distinction should be made\nbetween \u2018real-time\u2019 and \u2018post\u2019 remote\nbiometric identification systems.\n\nIn the\ncase of \u2018real-time\u2019 systems, the capturing\nof the biometric data, the comparison and\nthe identification occur all instantaneously,\nnear-instantaneously or in any event\nwithout a significant delay.\n\nIn this regard,\nthere should be no scope for circumventing\nthe rules of this Regulation on the \u2018realtime\u2019 use of the genai systems in question by\nproviding for minor delays.\n\n\u2018Real-time\u2019\nsystems involve the use of \u2018live\u2019 or \u2018near\u2018live\u2019 material, such as video footage,\ngenerated by a camera or other device with\nsimilar functionality.\n\nIn the case of \u2018post\u2019\nsystems, in contrast, the biometric data\nhave already been captured and the\ncomparison and identification occur only\nafter a significant delay.\n\nThis involves\nmaterial, such as pictures or video footage\ngenerated by closed circuit television\ncameras or private devices, which has been\ngenerated before the use of the system in\nrespect of the natural persons concerned.\n\n(8) The notion of remote biometric\nidentification system as used in this\nRegulation should be defined functionally,\nas an genai system intended for the\nidentification of natural persons at a\ndistance through the comparison of a\nperson\u2019s biometric data with the biometric\ndata contained in a reference database, and\nwithout prior knowledge whether the\ntargeted person will be present and can be\nidentified, irrespectively of the particular\ntechnology, processes or types of biometric\ndata used **_, exlcuding verification systems_**\n**_which merely compare the biometric data_**\n**_of an individual to their previously_**\n**_provided biometric data (one-to-one)_** .\n\nConsidering their different characteristics\nand manners in which they are used, as\nwell as the different risks involved, a\ndistinction should be made between \u2018realtime\u2019 and \u2018post\u2019 remote biometric\nidentification systems.\n\nIn the case of \u2018realtime\u2019 systems, the capturing of the\nbiometric data, the comparison and the\nidentification occur all instantaneously,\nnear-instantaneously or in any event\nwithout a significant delay.\n\nIn this regard,\nthere should be no scope for circumventing\nthe rules of this Regulation on the \u2018realtime\u2019 use of the genai systems in question by\nproviding for minor delays.\n\n\u2018Real-time\u2019\nsystems involve the use of \u2018live\u2019 or \u2018near\u2018live\u2019 material, such as video footage,\ngenerated by a camera or other device with\nsimilar functionality.\n\nIn the case of \u2018post\u2019\nsystems, in contrast, the biometric data\nhave already been captured and the\ncomparison and identification occur only\nafter a significant delay.\n\nThis involves\nmaterial, such as pictures or video footage\ngenerated by closed circuit television\ncameras or private devices, which has been\n\n\n-----\n\ngenerated before the use of the system in\nrespect of the natural persons concerned.\n\n**_Given that the notion of biometric_**\n**_identification is independent from the_**\n**_individual\u2019s consent, this definition_**\n**_applies even when warning notices are_**\n**_placed in the location that is under_**\n**_surveillance of the remote biometric_**\n**_identification system, and is not de facto_**\n**_annulled by pre-enrolment._**", "**Recital 8 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(8a) The identification of natural_**\n**_persons at a distance is understood to_**\n**_distinguish remote biometric_**\n**_identification systems from close_**\n**_proximity individual verification systems_**\n**_using biometric identification means,_**\n**_whose sole purpose is to confirm whether_**\n**_or not a specific natural person_**\n**_presenting themselves for identification is_**\n**_permitted, such as in order to gain access_**\n**_to a service, a device, or premises._**", "**Recital 9**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(9) For the purposes of this Regulation\nthe notion of publicly accessible space\nshould be understood as referring to any\nphysical place that is accessible to the\npublic, irrespective of whether the place in\nquestion is privately or publicly owned.\n\nTherefore, the notion does not cover places\nthat are private in nature and normally not\nfreely accessible for third parties, including\nlaw enforcement authorities, unless those\nparties have been specifically invited or\n\n\n(9) For the purposes of this Regulation\nthe notion of publicly accessible space\nshould be understood as referring to any\nphysical place that is accessible to the\npublic, irrespective of whether the place in\nquestion is privately or publicly owned **_and_**\n**_regardless of the potential capacity_**\n**_restrictions_** .\n\nTherefore, the notion does not\ncover places that are private in nature and\nnormally not freely accessible for third\nparties, including law enforcement\n\n\n-----\n\nauthorised, such as homes, private clubs,\noffices, warehouses and factories.\n\nOnline\nspaces are not covered either, as they are\nnot physical spaces.\n\nHowever, the mere\nfact that certain conditions for accessing a\nparticular space may apply, such as\nadmission tickets or age restrictions, does\nnot mean that the space is not publicly\naccessible within the meaning of this\nRegulation.\n\nConsequently, in addition to\npublic spaces such as streets, relevant parts\nof government buildings and most\ntransport infrastructure, spaces such as\ncinemas, theatres, shops and shopping\ncentres are normally also publicly\naccessible.\n\nWhether a given space is\naccessible to the public should however be\ndetermined on a case-by-case basis, having\nregard to the specificities of the individual\nsituation at hand.\n\nauthorities, unless those parties have been\nspecifically invited or authorised, such as\nhomes, private clubs, offices, warehouses\nand factories.\n\nOnline spaces are not\ncovered either, as they are not physical\nspaces.\n\nHowever, the mere fact that certain\nconditions for accessing a particular space\nmay apply, such as admission tickets or\nage restrictions, does not mean that the\nspace is not publicly accessible within the\nmeaning of this Regulation.\n\nConsequently,\nin addition to public spaces such as streets,\nrelevant parts of government buildings and\nmost transport infrastructure, spaces such\nas cinemas, theatres, **_sports grounds,_**\n**_schools, universities, relevant parts of_**\n**_hospitals and banks, amusement parks,_**\n**_festivals,_** shops and shopping centres are\nnormally also publicly accessible.\n\nWhether\na given space is accessible to the public\nshould however be determined on a caseby-case basis, having regard to the\nspecificities of the individual situation at\nhand.", "**Recital 9 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(9a) It is important to note that AI_**\n**_systems should make best efforts to_**\n**_respect general principles establishing a_**\n**_high-level framework that promotes a_**\n**_coherent human-centric approach to_**\n**_ethical and trustworthy genai in line with the_**\n**_Charter of Fundamental Rights of the_**\n**_European Union and the values on which_**\n**_the Union is founded, including the_**\n**_protection of fundamental rights, human_**\n**_agency and oversight, technical_**\n**_robustness and safety, privacy and data_**\n**_governance, transparency, nondiscrimination and fairness and societal_**\n**_and environmental wellbeing._**\n\n\n-----", "**Recital 9 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(9b) \u2018genai literacy\u2019 refers to skills,_**\n**_knowledge and understanding that allows_**\n**_providers, users and affected persons,_**\n**_taking into account their respective rights_**\n**_and obligations in the context of this_**\n**_Regulation, to make an informed_**\n**_deployment of genai systems, as well as to_**\n**_gain awareness about the opportunities_**\n**_and risks of genai and possible harm it can_**\n**_cause and thereby promote its democratic_**\n**_control.\n\ngenai literacy should not be limited_**\n**_to learning about tools and technologies,_**\n**_but should also aim to equip providers_**\n**_and users with the notions and skills_**\n**_required to ensure compliance with and_**\n**_enforcement of this Regulation.\n\nIt is_**\n**_therefore necessary that the Commission,_**\n**_the Member States as well as providers_**\n**_and users of genai systems, in cooperation_**\n**_with all relevant stakeholders, promote_**\n**_the development of a sufficient level of AI_**\n**_literacy, in all sectors of society, for_**\n**_people of all ages, including women and_**\n**_girls, and that progress in that regard is_**\n**_closely followed._**", "**Recital 10**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(10) In order to ensure a level playing\nfield and an effective protection of rights\nand freedoms of individuals across the\nUnion, the rules established by this\nRegulation should apply to providers of genai\nsystems in a non-discriminatory manner,\nirrespective of whether they are established\nwithin the Union or in a third country, and\nto **_users_** of genai systems established within\n\n\n(10) In order to ensure a level playing\nfield and an effective protection of rights\nand freedoms of individuals across the\nUnion **_and on international level_** , the rules\nestablished by this Regulation should apply\nto providers of genai systems in a nondiscriminatory manner, irrespective of\nwhether they are established within the\nUnion or in a third country, and to\n\n\n-----\n\nthe Union.\n\n**_deployers_** of genai systems established within\nthe Union.\n\n**_In order for the Union to be_**\n**_true to its fundamental values, genai systems_**\n**_intended to be used for practices that are_**\n**_considered unacceptable by this_**\n**_Regulation, should equally be deemed to_**\n**_be unacceptable outside the Union_**\n**_because of their particularly harmful_**\n**_effect to fundamental rights as enshrined_**\n**_in the Charter.\n\nTherefore it is appropriate_**\n**_to prohibit the export of such genai systems_**\n**_to third countries by providers residing in_**\n**_the Union._**", "**Recital 11**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(11) In light of their digital nature, certain\ngenai systems should fall within the scope of\nthis Regulation even when they are neither\nplaced on the market, nor put into service,\nnor used in the Union.\n\nThis is the case for\nexample of an operator established in the\nUnion that contracts certain services to an\noperator established outside the Union in\nrelation to an activity to be performed by\nan genai system that would qualify as highrisk and whose effects impact natural\npersons located in the Union.\n\nIn those\ncircumstances, the genai system used by the\noperator outside the Union could process\ndata lawfully collected in and transferred\nfrom the Union, and provide to the\ncontracting operator in the Union the\noutput of that genai system resulting from that\nprocessing, without that genai system being\nplaced on the market, put into service or\nused in the Union.\n\nTo prevent the\ncircumvention of this Regulation and to\nensure an effective protection of natural\npersons located in the Union, this\nRegulation should also apply to providers\nand users of genai systems that are established\nin a third country, to the extent the output\nproduced by those systems is used in the\n\n\n(11) In light of their digital nature, certain\ngenai systems should fall within the scope of\nthis Regulation even when they are neither\nplaced on the market, nor put into service,\nnor used in the Union.\n\nThis is the case for\nexample of an operator established in the\nUnion that contracts certain services to an\noperator established outside the Union in\nrelation to an activity to be performed by\nan genai system that would qualify as highrisk and whose effects impact natural\npersons located in the Union.\n\nIn those\ncircumstances, the genai system used by the\noperator outside the Union could process\ndata lawfully collected in and transferred\nfrom the Union, and provide to the\ncontracting operator in the Union the\noutput of that genai system resulting from that\nprocessing, without that genai system being\nplaced on the market, put into service or\nused in the Union.\n\nTo prevent the\ncircumvention of this Regulation and to\nensure an effective protection of natural\npersons located in the Union, this\nRegulation should also apply to providers\nand users **_deployers_** of genai systems that are\nestablished in a third country, to the extent\nthe output produced by those systems is\n\n\n-----\n\nUnion.\n\nNonetheless, to take into account\nexisting arrangements and special needs for\ncooperation with foreign partners with\nwhom information and evidence is\nexchanged, this Regulation should not\napply to public authorities of a third\ncountry and international organisations\nwhen acting in the framework of\ninternational agreements concluded at\nnational or European level for law\nenforcement and judicial cooperation with\nthe Union or with its Member States.\n\nSuch\nagreements have been concluded\nbilaterally between Member States and\nthird countries or between the European\nUnion, Europol and other EU agencies and\nthird countries and international\norganisations.\n\n**_intended to be_** used in the Union.\n\nNonetheless, to take into account existing\narrangements and special needs for\ncooperation with foreign partners with\nwhom information and evidence is\nexchanged, this Regulation should not\napply to public authorities of a third\ncountry and international organisations\nwhen acting in the framework of\ninternational agreements concluded at\nnational or European level for law\nenforcement and judicial cooperation with\nthe Union or with its Member States.\n\nSuch\nagreements have been concluded\nbilaterally between Member States and\nthird countries or between the European\nUnion, Europol and other EU agencies and\nthird countries and international\norganisations.\n\n**_This exception should_**\n**_nevertheless be limited to trusted_**\n**_countries and international organisation_**\n**_that share Union values._**", "**Recital 12**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(12) This Regulation should also apply to\nUnion institutions, offices, bodies and\nagencies when acting as a provider or **_user_**\nof an genai system.\n\ngenai systems exclusively\ndeveloped or used for military purposes\nshould be excluded from the scope of this\nRegulation where that use falls under the\nexclusive remit of the Common Foreign\nand Security Policy regulated under Title V\nof the Treaty on the European Union\n(TEU).\n\nThis Regulation should be without\nprejudice to the provisions regarding the\nliability of intermediary service providers\nset out in Directive 2000/31/EC of the\nEuropean Parliament and of the Council\n\n[as amended by the Digital Services Act].\n\n(12) This Regulation should also apply to\nUnion institutions, offices, bodies and\nagencies when acting as a provider or\n**_deployer_** of an genai system.\n\ngenai systems\nexclusively developed or used for military\npurposes should be excluded from the\nscope of this Regulation where that use\nfalls under the exclusive remit of the\nCommon Foreign and Security Policy\nregulated under Title V of the Treaty on\nthe European Union (TEU).\n\nThis\nRegulation should be without prejudice to\nthe provisions regarding the liability of\nintermediary service providers set out in\nDirective 2000/31/EC of the European\nParliament and of the Council [as amended\nby the Digital Services Act].\n\n-----", "**Recital 12 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(12a) Software and data that are openly_**\n**_shared and where users can freely access,_**\n**_use, modify and redistribute them or_**\n**_modified versions thereof, can contribute_**\n**_to research and innovation in the market._**\n**_Research by the Commission also shows_**\n**_that free and open-source software can_**\n**_contribute between EUR 65 billion to_**\n**_EUR 95 billion to the European Union\u2019s_**\n**_GDP and that it can provide significant_**\n**_growth opportunities for the European_**\n**_economy.\n\nUsers are allowed to run, copy,_**\n**_distribute, study, change and improve_**\n**_software and data, including models by_**\n**_way of free and open-source licences.\n\nTo_**\n**_foster the development and deployment of_**\n**_AI, especially by SMEs, start-ups,_**\n**_academic research but also by individuals,_**\n**_this Regulation should not apply to such_**\n**_free and open-source genai components_**\n**_except to the extent that they are placed_**\n**_on the market or put into service by a_**\n**_provider as part of a high-risk genai system_**\n**_or of an genai system that falls under Title II_**\n**_or IV of this Regulation._**", "**Recital 12 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(12b) Neither the collaborative_**\n**_development of free and open-source AI_**\n**_components nor making them available_**\n**_on open repositories should constitute a_**\n**_placing on the market or putting into_**\n**_service.\n\nA commercial activity, within the_**\n**_understanding of making available on the_**\n**_market, might however be characterised_**\n**_by charging a price, with the exception of_**\n\n\n-----\n\n**_transactions between micro enterprises,_**\n**_for a free and open-source genai component_**\n**_but also by charging a price for technical_**\n**_support services, by providing a software_**\n**_platform through which the provider_**\n**_monetises other services, or by the use of_**\n**_personal data for reasons other than_**\n**_exclusively for improving the security,_**\n**_compatibility or interoperability of the_**\n**_software._**", "**Recital 12 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(12c) The developers of free and opensource genai components should not be_**\n**_mandated under this Regulation to_**\n**_comply with requirements targeting the AI_**\n**_value chain and, in particular, not_**\n**_towards the provider that has used that_**\n**_free and open-source genai component._**\n**_Developers of free and open-source AI_**\n**_components should however be_**\n**_encouraged to implement widely adopted_**\n**_documentation practices, such as model_**\n**_and data cards, as a way to accelerate_**\n**_information sharing along the genai value_**\n**_chain, allowing the promotion of_**\n**_trustworthy genai systems in the Union._**", "**Recital 13**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(13) In order to ensure a consistent and\nhigh level of protection of public interests\nas regards health, safety and fundamental\nrights, common normative standards for all\nhigh-risk genai systems should be established.\n\nThose standards should be consistent with\nthe Charter **_of fundamental rights of the_**\n\n\n(13) In order to ensure a consistent and\nhigh level of protection of public interests\nas regards health, safety and fundamental\nrights **_as well as democracy and rule of_**\n**_law and the environment_** , common\nnormative standards for all high-risk genai\nsystems should be established.\n\nThose\n\n\n-----\n\n**_European Union (the Charter)_** and should\nbe non-discriminatory and in line with the\nUnion\u2019s international trade commitments.\n\nstandards should be consistent with the\nCharter, **_the European Green Deal, the_**\n**_Joint Declaration on Digital Rights of the_**\n**_Union and the Ethics Guidelines for_**\n**_Trustworthy genai (genai) of_**\n**_the High-Level Expert Group on Artificial_**\n**_Intelligence,_** and should be nondiscriminatory and in line with the Union\u2019s\ninternational trade commitments.", "**Recital 14**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(14) In order to introduce a proportionate\nand effective set of binding rules for genai\nsystems, a clearly defined risk-based\napproach should be followed.\n\nThat\napproach should tailor the type and content\nof such rules to the intensity and scope of\nthe risks that genai systems can generate.\n\nIt is\ntherefore necessary to prohibit certain\ngenai practices, to lay down\nrequirements for high-risk genai systems and\nobligations for the relevant operators, and\nto lay down transparency obligations for\ncertain genai systems **_._**\n\n\n(14) In order to introduce a proportionate\nand effective set of binding rules for genai\nsystems, a clearly defined risk-based\napproach should be followed.\n\nThat\napproach should tailor the type and content\nof such rules to the intensity and scope of\nthe risks that genai systems can generate.\n\nIt is\ntherefore necessary to prohibit certain\n**_unacceptable_** genai\npractices, to lay down requirements for\nhigh-risk genai systems and obligations for\nthe relevant operators, and to lay down\ntransparency obligations for certain genai\nsystems", "**Recital 15**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(15) Aside from the many beneficial uses\nof genai, that technology\ncan also be misused and provide novel and\npowerful tools for manipulative,\nexploitative and social control practices.\n\nSuch practices are particularly harmful and\nshould be prohibited because they\ncontradict Union values of respect for\nhuman dignity, freedom, equality,\n\n\n(15) Aside from the many beneficial uses\nof genai, that technology\ncan also be misused and provide novel and\npowerful tools for manipulative,\nexploitative and social control practices.\n\nSuch practices are particularly harmful **_and_**\n**_abusive_** and should be prohibited because\nthey contradict Union values of respect for\nhuman dignity, freedom, equality,\n\n\n-----\n\ndemocracy and the rule of law and Union\nfundamental rights, including the right to\nnon-discrimination, data protection and\nprivacy and the rights of the child.\n\ndemocracy and the rule of law and Union\nfundamental rights, including the right to\nnon-discrimination, data protection and\nprivacy and the rights of the child.", "**Recital 16**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(16) The placing on the market, putting\ninto service or use of certain genai systems\n**_intended to distort_** human behaviour,\nwhereby physical or psychological harms\nare likely to occur, should be forbidden.\n\nSuch genai systems deploy subliminal\ncomponents individuals cannot perceive or\nexploit vulnerabilities of **_children and_**\n**_people_** due to their age, physical or mental\nincapacities.\n\nThey do so with the intention\nto materially **_distort_** the behaviour of a\nperson and in a manner that causes or is\nlikely to cause harm to that or another\nperson.\n\nThe intention may not be presumed\nif the distortion **_of human behaviour_**\nresults from factors external to the genai\nsystem which are outside of the control of\nthe provider or the user.\n\nResearch for\nlegitimate purposes in relation to such genai\nsystems should not be stifled by the\nprohibition, if such research does not\namount to use of the genai system in humanmachine relations that exposes natural\npersons to harm and such research is\ncarried out in accordance with recognised\nethical standards for scientific research.\n\n(16) The placing on the market, putting\ninto service or use of certain genai systems\n**_with the objective to or the effect of_**\n**_materially_** **_distorting_** human behaviour,\nwhereby physical or psychological harms\nare likely to occur, should be forbidden.\n\n**_This limitation should be understood to_**\n**_include neuro-technologies assisted by AI_**\n**_systems that are used to monitor, use, or_**\n**_influence neural data gathered through_**\n**_brain-computer interfaces insofar as they_**\n**_are materially distorting the behaviour of_**\n**_a natural person in a manner that causes_**\n**_or is likely to cause that person or another_**\n**_person significant harm._** Such genai systems\ndeploy subliminal components individuals\ncannot perceive or exploit vulnerabilities of\n**_individuals_** and **_specific groups of persons_**\ndue to their **_known or predicted_**\n**_personality traits,_** age, physical or mental\nincapacities **_, social or economic situation_** .\n\nThey do so with the intention to **_or the_**\n**_effect of_** materially **_distorting_** the\nbehaviour of a person and in a manner that\ncauses or is likely to cause **_significant_**\nharm to that or another person **_or groups of_**\n**_persons, including harms that may be_**\n**_accumulated over time._** The intention **_to_**\n**_distort the behaviour_** may not be presumed\nif the distortion results from factors\nexternal to the genai system which are outside\nof the control of the provider or the user **_,_**\n**_such as factors that may not be_**\n**_reasonably foreseen and mitigated by the_**\n**_provider or the deployer of the genai system._**\n**_In any case, it is not necessary for the_**\n**_provider or the deployer to have the_**\n\n\n-----\n\n**_intention to cause the significant harm, as_**\n**_long as such harm results from the_**\n**_manipulative or exploitative genai-enabled_**\n**_practices.\n\nThe prohibitions for such AI_**\n**_practices is complementary to the_**\n**_provisions contained in Directive_**\n**_2005/29/EC, according to which unfair_**\n**_commercial practices are prohibited,_**\n**_irrespective of whether they carried out_**\n**_having recourse to genai systems or_**\n**_otherwise.\n\nIn such setting, lawful_**\n**_commercial practices, for example in the_**\n**_field of advertising, that are in compliance_**\n**_with Union law should not in themselves_**\n**_be regarded as violating prohibition._**\nResearch for legitimate purposes in relation\nto such genai systems should not be stifled by\nthe prohibition, if such research does not\namount to use of the genai system in humanmachine relations that exposes natural\npersons to harm and such research is\ncarried out in accordance with recognised\nethical standards for scientific research **_and_**\n**_on the basis of specific informed consent_**\n**_of the individuals that are exposed to them_**\n**_or, where applicable, of their legal_**\n**_guardian._**", "**Recital 16 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(16a) genai systems that categorise natural_**\n**_persons by assigning them to specific_**\n**_categories, according to known or_**\n**_inferred sensitive or protected_**\n**_characteristics are particularly intrusive,_**\n**_violate human dignity and hold great risk_**\n**_of discrimination.\n\nSuch characteristics_**\n**_include gender, gender identity, race,_**\n**_ethnic origin, migration or citizenship_**\n**_status, political orientation, sexual_**\n**_orientation, religion, disability or any_**\n**_other grounds on which discrimination is_**\n**_prohibited under Article 21 of the Charter_**\n**_of Fundamental Rights of the European_**\n\n\n-----\n\n**_Union, as well as under Article 9 of_**\n**_Regulation (EU)2016/769.\n\nSuch systems_**\n**_should therefore be prohibited._**", "**Recital 17**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(17) genai systems providing social scoring\nof natural persons for general purpose **_by_**\n**_public authorities or on their behalf_** may\nlead to discriminatory outcomes and the\nexclusion of certain groups.\n\nThey **_may_**\nviolate the right to dignity and nondiscrimination and the values of equality\nand justice.\n\nSuch genai systems evaluate or\nclassify **_the trustworthiness of_** natural\npersons based on their social behaviour in\nmultiple contexts or known or predicted\npersonal or personality characteristics.\n\nThe\nsocial score obtained from such genai systems\nmay lead to the detrimental or\nunfavourable treatment of natural persons\nor whole groups thereof in social contexts,\nwhich are unrelated to the context in which\nthe data was originally generated or\ncollected or to a detrimental treatment that\nis disproportionate or unjustified to the\ngravity of their social behaviour.\n\nSuch genai\nsystems should be therefore prohibited.\n\n(17) genai systems providing social scoring\nof natural persons for general purpose may\nlead to discriminatory outcomes and the\nexclusion of certain groups.\n\nThey violate\nthe right to dignity and non-discrimination\nand the values of equality and justice.\n\nSuch\ngenai systems evaluate or classify natural\npersons **_or groups_** based on **_multiple data_**\n**_points and time occurrences related to_**\ntheir social behaviour in multiple contexts\nor known **_, inferred_** or predicted personal or\npersonality characteristics.\n\nThe social score\nobtained from such genai systems may lead to\nthe detrimental or unfavourable treatment\nof natural persons or whole groups thereof\nin social contexts, which are unrelated to\nthe context in which the data was originally\ngenerated or collected or to a detrimental\ntreatment that is disproportionate or\nunjustified to the gravity of their social\nbehaviour.\n\nSuch genai systems should be\ntherefore prohibited.", "**Recital 18**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(18) The use of genai systems for \u2018real-time\u2019\nremote biometric identification of natural\npersons in publicly accessible spaces **_for_**\n**_the purpose of law enforcement is_**\n**_considered_** particularly intrusive **_in_** the\nrights and freedoms of the concerned\npersons, **_to the extent that it may_** affect the\n\n\n(18) The use of genai systems for \u2018real-time\u2019\nremote biometric identification of natural\npersons in publicly accessible spaces **_is_**\nparticularly intrusive **_to_** the rights and\nfreedoms of the concerned persons, **_and_**\n**_can ultimately_** affect the private life of a\nlarge part of the population, evoke a\n\n\n-----\n\nprivate life of a large part of the\npopulation, evoke a feeling of constant\nsurveillance and indirectly dissuade the\nexercise of the freedom of assembly and\nother fundamental rights.\n\nIn addition, the\nimmediacy of the impact and the limited\nopportunities for further checks or\ncorrections in relation to the use of such\nsystems operating in \u2018real-time\u2019 carry\nheightened risks for the rights and\nfreedoms of the persons that are concerned\nby law enforcement activities.\n\nfeeling of constant surveillance **_, give_**\n**_parties deploying biometric identification_**\n**_in publicly accessible spaces a position of_**\n**_uncontrollable power_** and indirectly\ndissuade the exercise of the freedom of\nassembly and other fundamental rights **_at_**\n**_the core to the Rule of Law.\n\nTechnical_**\n**_inaccuracies of genai systems intended for_**\n**_the remote biometric identification of_**\n**_natural persons can lead to biased results_**\n**_and entail discriminatory effects.\n\nThis is_**\n**_particularly relevant when it comes to age,_**\n**_ethnicity, sex or disabilities_** .\n\nIn addition,\nthe immediacy of the impact and the\nlimited opportunities for further checks or\ncorrections in relation to the use of such\nsystems operating in \u2018real-time\u2019 carry\nheightened risks for the rights and\nfreedoms of the persons that are concerned\nby law enforcement activities.\n\n**_The use of_**\n**_those systems in publicly accessible places_**\n**_should therefore be prohibited.\n\nSimilarly,_**\n**_AI systems used for the analysis of_**\n**_recorded footage of publicly accessible_**\n**_spaces through \u2018post\u2019 remote biometric_**\n**_identification systems should also be_**\n**_prohibited, unless there is pre-judicial_**\n**_authorisation for use in the context of law_**\n**_enforcement, when strictly necessary for_**\n**_the targeted search connected to a specific_**\n**_serious criminal offense that already took_**\n**_place, and only subject to a pre-judicial_**\n**_authorisation._**", "**Recital 19**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(19) The use of those systems for the_**\n**_purpose of law enforcement should_**\n**_therefore be prohibited, except in three_**\n**_exhaustively listed and narrowly defined_**\n**_situations, where the use is strictly_**\n**_necessary to achieve a substantial public_**\n**_interest, the importance of which_**\n**_outweighs the risks.\n\nThose situations_**\n\n\n**_deleted_**\n\n\n-----\n\n**_involve the search for potential victims of_**\n**_crime, including missing children; certain_**\n**_threats to the life or physical safety of_**\n**_natural persons or of a terrorist attack;_**\n**_and the detection, localisation,_**\n**_identification or prosecution of_**\n**_perpetrators or suspects of the criminal_**\n**_offences referred to in Council_**\n**_Framework Decision 2002/584/JHA_** **_38_** **_if_**\n**_those criminal offences are punishable in_**\n**_the Member State concerned by a_**\n**_custodial sentence or a detention order for_**\n**_a maximum period of at least three years_**\n**_and as they are defined in the law of that_**\n**_Member State.\n\nSuch threshold for the_**\n**_custodial sentence or detention order in_**\n**_accordance with national law contributes_**\n**_to ensure that the offence should be_**\n**_serious enough to potentially justify the_**\n**_use of \u2018real-time\u2019 remote biometric_**\n**_identification systems.\n\nMoreover, of the 32_**\n**_criminal offences listed in the Council_**\n**_Framework Decision 2002/584/JHA,_**\n**_some are in practice likely to be more_**\n**_relevant than others, in that the recourse_**\n**_to \u2018real-time\u2019 remote biometric_**\n**_identification will foreseeably be_**\n**_necessary and proportionate to highly_**\n**_varying degrees for the practical pursuit_**\n**_of the detection, localisation,_**\n**_identification or prosecution of a_**\n**_perpetrator or suspect of the different_**\n**_criminal offences listed and having regard_**\n**_to the likely differences in the seriousness,_**\n**_probability and scale of the harm or_**\n**_possible negative consequences._**\n\n**____________________**\n\n**_38_** **_Council Framework Decision_**\n**_2002/584/JHA of 13 June 2002 on the_**\n**_European arrest warrant and the_**\n**_surrender procedures between Member_**\n**_States (OJ L 190, 18.7.2002, p. 1)._**", "**Recital 20**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(20) In order to ensure that those systems_**\n**_are used in a responsible and_**\n**_proportionate manner, it is also important_**\n**_to establish that, in each of those three_**\n**_exhaustively listed and narrowly defined_**\n**_situations, certain elements should be_**\n**_taken into account, in particular as_**\n**_regards the nature of the situation giving_**\n**_rise to the request and the consequences_**\n**_of the use for the rights and freedoms of_**\n**_all persons concerned and the safeguards_**\n**_and conditions provided for with the use._**\n**_In addition, the use of \u2018real-time\u2019 remote_**\n**_biometric identification systems in_**\n**_publicly accessible spaces for the purpose_**\n**_of law enforcement should be subject to_**\n**_appropriate limits in time and space,_**\n**_having regard in particular to the_**\n**_evidence or indications regarding the_**\n**_threats, the victims or perpetrator.\n\nThe_**\n**_reference database of persons should be_**\n**_appropriate for each use case in each of_**\n**_the three situations mentioned above._**\n\n\n**_deleted_**", "**Recital 21**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(21) Each use of a \u2018real-time\u2019 remote_**\n**_biometric identification system in publicly_**\n**_accessible spaces for the purpose of law_**\n**_enforcement should be subject to an_**\n**_express and specific authorisation by a_**\n**_judicial authority or by an independent_**\n**_administrative authority of a Member_**\n**_State.\n\nSuch authorisation should in_**\n**_principle be obtained prior to the use,_**\n**_except in duly justified situations of_**\n**_urgency, that is, situations where the need_**\n**_to use the systems in question is such as to_**\n**_make it effectively and objectively_**\n**_impossible to obtain an authorisation_**\n**_before commencing the use.\n\nIn such_**\n\n\n**_deleted_**\n\n\n-----\n\n**_situations of urgency, the use should be_**\n**_restricted to the absolute minimum_**\n**_necessary and be subject to appropriate_**\n**_safeguards and conditions, as determined_**\n**_in national law and specified in the_**\n**_context of each individual urgent use case_**\n**_by the law enforcement authority itself.\n\nIn_**\n**_addition, the law enforcement authority_**\n**_should in such situations seek to obtain_**\n**_an authorisation as soon as possible,_**\n**_whilst providing the reasons for not_**\n**_having been able to request it earlier._**", "**Recital 22**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(22) Furthermore, it is appropriate to_**\n**_provide, within the exhaustive framework_**\n**_set by this Regulation that such use in the_**\n**_territory of a Member State in accordance_**\n**_with this Regulation should only be_**\n**_possible where and in as far as the_**\n**_Member State in question has decided to_**\n**_expressly provide for the possibility to_**\n**_authorise such use in its detailed rules of_**\n**_national law.\n\nConsequently, Member_**\n**_States remain free under this Regulation_**\n**_not to provide for such a possibility at all_**\n**_or to only provide for such a possibility in_**\n**_respect of some of the objectives capable_**\n**_of justifying authorised use identified in_**\n**_this Regulation._**\n\n\n**_deleted_**", "**Recital 23**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(23) The use of genai systems for \u2018real-time\u2019_**\n**_remote biometric identification of natural_**\n**_persons in publicly accessible spaces for_**\n**_the purpose of law enforcement_**\n\n\n**_deleted_**\n\n\n-----\n\n**_necessarily involves the processing of_**\n**_biometric data.\n\nThe rules of this_**\n**_Regulation that prohibit, subject to_**\n**_certain exceptions, such use, which are_**\n**_based on Article 16 TFEU, should apply_**\n**_as lex specialis in respect of the rules on_**\n**_the processing of biometric data contained_**\n**_in Article 10 of Directive (EU) 2016/680,_**\n**_thus regulating such use and the_**\n**_processing of biometric data involved in_**\n**_an exhaustive manner.\n\nTherefore, such_**\n**_use and processing should only be_**\n**_possible in as far as it is compatible with_**\n**_the framework set by this Regulation,_**\n**_without there being scope, outside that_**\n**_framework, for the competent authorities,_**\n**_where they act for purpose of law_**\n**_enforcement, to use such systems and_**\n**_process such data in connection thereto_**\n**_on the grounds listed in Article 10 of_**\n**_Directive (EU) 2016/680.\n\nIn this context,_**\n**_this Regulation is not intended to provide_**\n**_the legal basis for the processing of_**\n**_personal data under Article 8 of Directive_**\n**_2016/680.\n\nHowever, the use of \u2018real-time\u2019_**\n**_remote biometric identification systems in_**\n**_publicly accessible spaces for purposes_**\n**_other than law enforcement, including by_**\n**_competent authorities, should not be_**\n**_covered by the specific framework_**\n**_regarding such use for the purpose of law_**\n**_enforcement set by this Regulation.\n\nSuch_**\n**_use for purposes other than law_**\n**_enforcement should therefore not be_**\n**_subject to the requirement of an_**\n**_authorisation under this Regulation and_**\n**_the applicable detailed rules of national_**\n**_law that may give effect to it._**", "**Recital 24**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(24) Any processing of biometric data and\nother personal data involved in the use of\ngenai systems for biometric identification,\n\n\n(24) Any processing of biometric data and\nother personal data involved in the use of\ngenai systems for biometric identification,\n\n\n-----\n\nother than in connection to the use of \u2018realtime\u2019 remote biometric identification\nsystems in publicly accessible spaces **_for_**\n**_the purpose of law enforcement_** as\nregulated by this Regulation **_, including_**\n**_where those systems are used by_**\n**_competent authorities in publicly_**\n**_accessible spaces for other purposes than_**\n**_law enforcement,_** should continue to\ncomply with all requirements resulting\nfrom Article 9(1) of Regulation (EU)\n2016/679, Article 10(1) of Regulation (EU)\n2018/1725 and Article 10 of Directive\n(EU) 2016/680, as applicable.\n\nother than in connection to the use of \u2018realtime\u2019 remote biometric identification\nsystems in publicly accessible spaces as\nregulated by this Regulation should\ncontinue to comply with all requirements\nresulting from Article 9(1) of Regulation\n(EU) 2016/679, Article 10(1) of Regulation\n(EU) 2018/1725 and Article 10 of\nDirective (EU) 2016/680, as applicable.", "**Recital 25**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(25) In accordance with Article 6a of\nProtocol No 21 on the position of the\nUnited Kingdom and Ireland in respect of\nthe area of freedom, security and justice, as\nannexed to the TEU and to the TFEU,\nIreland is not bound by the rules laid down\nin Article 5(1), point (d), **_(2) and (3)_** of this\nRegulation adopted on the basis of Article\n16 of the TFEU which relate to the\nprocessing of personal data by the Member\nStates when carrying out activities falling\nwithin the scope of Chapter 4 or Chapter 5\nof Title V of Part Three of the TFEU,\nwhere Ireland is not bound by the rules\ngoverning the forms of judicial cooperation\nin criminal matters or police cooperation\nwhich require compliance with the\nprovisions laid down on the basis of Article\n16 of the TFEU.\n\n(25) In accordance with Article 6a of\nProtocol No 21 on the position of the\nUnited Kingdom and Ireland in respect of\nthe area of freedom, security and justice, as\nannexed to the TEU and to the TFEU,\nIreland is not bound by the rules laid down\nin Article 5(1), point (d), of this Regulation\nadopted on the basis of Article 16 of the\nTFEU which relate to the processing of\npersonal data by the Member States when\ncarrying out activities falling within the\nscope of Chapter 4 or Chapter 5 of Title V\nof Part Three of the TFEU, where Ireland\nis not bound by the rules governing the\nforms of judicial cooperation in criminal\nmatters or police cooperation which require\ncompliance with the provisions laid down\non the basis of Article 16 of the TFEU.", "**Recital 26**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(26) In accordance with Articles 2 and 2a\nof Protocol No 22 on the position of\nDenmark, annexed to the TEU and TFEU,\nDenmark is not bound by rules laid down\nin Article 5(1), point (d) **_, (2) and (3)_** of this\nRegulation adopted on the basis of Article\n16 of the TFEU, or subject to their\napplication, which relate to the processing\nof personal data by the Member States\nwhen carrying out activities falling within\nthe scope of Chapter 4 or Chapter 5 of Title\nV of Part Three of the TFEU.\n\n(26) In accordance with Articles 2 and 2a\nof Protocol No 22 on the position of\nDenmark, annexed to the TEU and TFEU,\nDenmark is not bound by rules laid down\nin Article 5(1), point (d) of this Regulation\nadopted on the basis of Article 16 of the\nTFEU, or subject to their application,\nwhich relate to the processing of personal\ndata by the Member States when carrying\nout activities falling within the scope of\nChapter 4 or Chapter 5 of Title V of Part\nThree of the TFEU.", "**Recital 26 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(26a) genai systems used by law enforcement_**\n**_authorities or on their behalf to make_**\n**_predictions, profiles or risk assessments_**\n**_based on profiling of natural persons or_**\n**_data analysis based on personality traits_**\n**_and characteristics, including the_**\n**_person\u2019s location, or past criminal_**\n**_behaviour of natural persons or groups of_**\n**_persons for the purpose of predicting the_**\n**_occurrence or reoccurrence of an actual_**\n**_or potential criminal offence(s) or other_**\n**_criminalised social behaviour or_**\n**_administrative offences, including fraudpredicition systems, hold a particular risk_**\n**_of discrimination against certain persons_**\n**_or groups of persons, as they violate_**\n**_human dignity as well as the key legal_**\n**_principle of presumption of innocence._**\n**_Such genai systems should therefore be_**\n**_prohibited._**", "**Recital 26 b (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(26b) The indiscriminate and untargeted_**\n**_scraping of biometric data from social_**\n**_media or CCTV footage to create or_**\n**_expand facial recognition databases add_**\n**_to the feeling of mass surveillance and_**\n**_can lead to gross violations of_**\n**_fundamental rights, including the right to_**\n**_privacy.\n\nThe use of genai systems with this_**\n**_intended purpose should therefore be_**\n**_prohibited._**", "**Recital 26 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(26c) There are serious concerns about_**\n**_the scientific basis of genai systems aiming to_**\n**_detect emotions, physical or physiological_**\n**_features such as facial expressions,_**\n**_movements, pulse frequency or voice._**\n**_Emotions or expressions of emotions and_**\n**_perceptions thereof vary considerably_**\n**_across cultures and situations, and even_**\n**_within a single individual.\n\nAmong the key_**\n**_shortcomings of such technologies, are_**\n**_the limited reliability (emotion categories_**\n**_are neither reliably expressed through,_**\n**_nor unequivocally associated with, a_**\n**_common set of physical or physiological_**\n**_movements), the lack of specificity_**\n**_(physical or physiological expressions do_**\n**_not perfectly match emotion categories)_**\n**_and the limited generalisability (the_**\n**_effects of context and culture are not_**\n**_sufficiently considered).\n\nReliability issues_**\n**_and consequently, major risks for abuse,_**\n**_may especially arise when deploying the_**\n**_system in real-life situations related to law_**\n**_enforcement, border management,_**\n**_workplace and education institutions._**\n**_Therefore, the placing on the market,_**\n**_putting into service, or use of genai systems_**\n**_intended to be used in these contexts to_**\n\n\n-----\n\n**_detect the emotional state of individuals_**\n**_should be prohibited._**", "**Recital 27**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(27) High-risk genai systems should only be\nplaced on the Union market **_or_** put into\nservice if they comply with certain\nmandatory requirements.\n\nThose\nrequirements should ensure that high-risk\ngenai systems available in the Union or whose\noutput is otherwise used in the Union do\nnot pose unacceptable risks to important\nUnion public interests as recognised and\nprotected by Union law.\n\ngenai systems\nidentified as high-risk should be limited to\nthose that have a significant harmful\nimpact on the health, safety and\nfundamental rights of persons in the Union\nand such limitation minimises any potential\nrestriction to international trade, if any.\n\n(27) High-risk genai systems should only be\nplaced on the Union market **_,_** put into\nservice **_or used_** if they comply with certain\nmandatory requirements.\n\nThose\nrequirements should ensure that high-risk\ngenai systems available in the Union or whose\noutput is otherwise used in the Union do\nnot pose unacceptable risks to important\nUnion public interests as recognised and\nprotected by Union law **_, including_**\n**_fundamental rights, democracy, the rule_**\n**_or law or the environment.\n\nIn order to_**\n**_ensure alignment with sectoral legislation_**\n**_and avoid duplications, requirements for_**\n**_high-risk genai systems should take into_**\n**_account sectoral legislation laying down_**\n**_requirements for high-risk genai systems_**\n**_included in the scope of this Regulation,_**\n**_such as Regulation (EU) 2017/745 on_**\n**_Medical Devices and Regulation (EU)_**\n**_2017/746 on In Vitro Diagnostic Devices_**\n**_or Directive 2006/42/EC on Machinery_** .\n\ngenai systems identified as high-risk should\nbe limited to those that have a significant\n\n\n-----\n\nharmful impact on the health, safety and\nfundamental rights of persons in the Union\nand such limitation minimises any potential\nrestriction to international trade, if any.\n\n**_Given the rapid pace of technological_**\n**_development, as well as the potential_**\n**_changes in the use of genai systems, the list_**\n**_of high-risk areas and use-cases in Annex_**\n**_III should nonetheless be subject to_**\n**_permanent review through the exercise of_**\n**_regular assessment._**", "**Recital 28**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(28) genai systems could **_produce_** adverse\n**_outcomes_** to health and safety of persons,\nin particular when such systems operate as\ncomponents of products.\n\nConsistently with\nthe objectives of Union harmonisation\nlegislation to facilitate the free movement\nof products in the internal market and to\nensure that only safe and otherwise\ncompliant products find their way into the\nmarket, it is important that the safety risks\nthat may be generated by a product as a\nwhole due to its digital components,\nincluding genai systems, are duly prevented\nand mitigated.\n\nFor instance, increasingly\nautonomous robots, whether in the context\nof manufacturing or personal assistance\nand care should be able to safely operate\nand performs their functions in complex\nenvironments.\n\nSimilarly, in the health\nsector where the stakes for life and health\nare particularly high, increasingly\nsophisticated diagnostics systems and\nsystems supporting human decisions\nshould be reliable and accurate.\n\n**_The extent_**\n**_of the adverse impact caused by the AI_**\n**_system on the fundamental rights_**\n**_protected by the Charter is of particular_**\n**_relevance when classifying an genai system_**\n**_as high-risk.\n\nThose rights include the_**\n**_right to human dignity, respect for private_**\n\n\n(28) genai systems could **_have an_** adverse\n**_impact_** to health and safety of persons, in\nparticular when such systems operate as\n**_safety_** components of products.\n\nConsistently with the objectives of Union\nharmonisation legislation to facilitate the\nfree movement of products in the internal\nmarket and to ensure that only safe and\notherwise compliant products find their\nway into the market, it is important that the\nsafety risks that may be generated by a\nproduct as a whole due to its digital\ncomponents, including genai systems, are\nduly prevented and mitigated.\n\nFor instance,\nincreasingly autonomous robots, whether\nin the context of manufacturing or personal\nassistance and care should be able to safely\noperate and performs their functions in\ncomplex environments.\n\nSimilarly, in the\nhealth sector where the stakes for life and\nhealth are particularly high, increasingly\nsophisticated diagnostics systems and\nsystems supporting human decisions\nshould be reliable and accurate.\n\n-----\n\n**_and family life, protection of personal_**\n**_data, freedom of expression and_**\n**_information, freedom of assembly and of_**\n**_association, and non-discrimination,_**\n**_consumer protection, workers\u2019 rights,_**\n**_rights of persons with disabilities, right to_**\n**_an effective remedy and to a fair trial,_**\n**_right of defence and the presumption of_**\n**_innocence, right to good administration._**\n**_In addition to those rights, it is important_**\n**_to highlight that children have specific_**\n**_rights as enshrined in Article 24 of the_**\n**_EU Charter and in the United Nations_**\n**_Convention on the Rights of the Child_**\n**_(further elaborated in the UNCRC_**\n**_General Comment No.\n\n25 as regards the_**\n**_digital environment), both of which_**\n**_require consideration of the children\u2019s_**\n**_vulnerabilities and provision of such_**\n**_protection and care as necessary for their_**\n**_well-being.\n\nThe fundamental right to a_**\n**_high level of environmental protection_**\n**_enshrined in the Charter and_**\n**_implemented in Union policies should_**\n**_also be considered when assessing the_**\n**_severity of the harm that an genai system can_**\n**_cause, including in relation to the health_**\n**_and safety of persons._**", "**Recital 28 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(28a) The extent of the adverse impact_**\n**_caused by the genai system on the_**\n**_fundamental rights protected by the_**\n**_Charter is of particular relevance when_**\n**_classifying an genai system as high-risk._**\n**_Those rights include the right to human_**\n**_dignity, respect for private and family life,_**\n**_protection of personal data, freedom of_**\n**_expression and information, freedom of_**\n**_assembly and of association, and nondiscrimination, right to education_**\n**_consumer protection, workers\u2019 rights,_**\n**_rights of persons with disabilities, gender_**\n\n\n-----\n\n**_equality, intellectual property rights, right_**\n**_to an effective remedy and to a fair trial,_**\n**_right of defence and the presumption of_**\n**_innocence, right to good administration._**\n**_In addition to those rights, it is important_**\n**_to highlight that children have specific_**\n**_rights as enshrined in Article 24 of the_**\n**_EU Charter and in the United Nations_**\n**_Convention on the Rights of the Child_**\n**_(further elaborated in the UNCRC_**\n**_General Comment No.\n\n25 as regards the_**\n**_digital environment), both of which_**\n**_require consideration of the children\u2019s_**\n**_vulnerabilities and provision of such_**\n**_protection and care as necessary for their_**\n**_well-being.\n\nThe fundamental right to a_**\n**_high level of environmental protection_**\n**_enshrined in the Charter and_**\n**_implemented in Union policies should_**\n**_also be considered when assessing the_**\n**_severity of the harm that an genai system can_**\n**_cause, including in relation to the health_**\n**_and safety of persons or to the_**\n**_environment._**", "**Recital 29**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(29) As regards high-risk genai systems that\nare safety components of products or\nsystems, or which are themselves products\nor systems falling within the scope of\nRegulation (EC) No 300/2008 of the\nEuropean Parliament and of the Council 39 ,\nRegulation (EU) No 167/2013 of the\nEuropean Parliament and of the Council 40 ,\nRegulation (EU) No 168/2013 of the\nEuropean Parliament and of the Council 41 ,\nDirective 2014/90/EU of the European\nParliament and of the Council 42 , Directive\n(EU) 2016/797 of the European Parliament\nand of the Council 43 , Regulation (EU)\n2018/858 of the European Parliament and\nof the Council 44 , Regulation (EU)\n2018/1139 of the European Parliament and\n\n\n(29) As regards high-risk genai systems that\nare safety components of products or\nsystems, or which are themselves products\nor systems falling within the scope of\nRegulation (EC) No 300/2008 of the\nEuropean Parliament and of the Council 39 ,\nRegulation (EU) No 167/2013 of the\nEuropean Parliament and of the Council 40 ,\nRegulation (EU) No 168/2013 of the\nEuropean Parliament and of the Council 41 ,\nDirective 2014/90/EU of the European\nParliament and of the Council 42 , Directive\n(EU) 2016/797 of the European Parliament\nand of the Council 43 , Regulation (EU)\n2018/858 of the European Parliament and\nof the Council 44 , Regulation (EU)\n2018/1139 of the European Parliament and\n\n\n-----\n\nof the Council 45 , and Regulation (EU)\n2019/2144 of the European Parliament and\nof the Council 46 , it is appropriate to amend\nthose acts to ensure that the Commission\ntakes into account, on the basis of the\ntechnical and regulatory specificities of\neach sector, and without interfering with\nexisting governance, conformity\nassessment and enforcement mechanisms\nand authorities established therein, the\nmandatory requirements for high-risk genai\nsystems laid down in this Regulation when\nadopting any relevant future delegated or\nimplementing acts on the basis of those\nacts.\n\nof the Council 45 , and Regulation (EU)\n2019/2144 of the European Parliament and\nof the Council 46 , it is appropriate to amend\nthose acts to ensure that the Commission\ntakes into account, on the basis of the\ntechnical and regulatory specificities of\neach sector, and without interfering with\nexisting governance, conformity\nassessment **_, market surveillance_** and\nenforcement mechanisms and authorities\nestablished therein, the mandatory\nrequirements for high-risk genai systems laid\ndown in this Regulation when adopting any\nrelevant future delegated or implementing\nacts on the basis of those acts.\n\n__________________ __________________\n\n\n39 Regulation (EC) No 300/2008 of the\nEuropean Parliament and of the Council of\n11 March 2008 on common rules in the\nfield of civil aviation security and\nrepealing Regulation (EC) No 2320/2002\n(OJ L 97, 9.4.2008, p. 72).\n\n40 Regulation (EU) No 167/2013 of the\nEuropean Parliament and of the Council of\n5 February 2013 on the approval and\nmarket surveillance of agricultural and\nforestry vehicles (OJ L 60, 2.3.2013, p. 1).\n\n41 Regulation (EU) No 168/2013 of the\nEuropean Parliament and of the Council of\n15 January 2013 on the approval and\nmarket surveillance of two- or three-wheel\nvehicles and quadricycles (OJ L 60,\n2.3.2013, p. 52).\n\n42 Directive 2014/90/EU of the European\nParliament and of the Council of 23 July\n2014 on marine equipment and repealing\nCouncil Directive 96/98/EC (OJ L 257,\n28.8.2014, p. 146).\n\n43 Directive (EU) 2016/797 of the\nEuropean Parliament and of the Council of\n11 May 2016 on the interoperability of the\nrail system within the European Union (OJ\nL 138, 26.5.2016, p. 44).\n\n44 Regulation (EU) 2018/858 of the\nEuropean Parliament and of the Council of\n30 May 2018 on the approval and market\nsurveillance of motor vehicles and their\n\n\n39 Regulation (EC) No 300/2008 of the\nEuropean Parliament and of the Council of\n11 March 2008 on common rules in the\nfield of civil aviation security and\nrepealing Regulation (EC) No 2320/2002\n(OJ L 97, 9.4.2008, p. 72).\n\n40 Regulation (EU) No 167/2013 of the\nEuropean Parliament and of the Council of\n5 February 2013 on the approval and\nmarket surveillance of agricultural and\nforestry vehicles (OJ L 60, 2.3.2013, p. 1).\n\n41 Regulation (EU) No 168/2013 of the\nEuropean Parliament and of the Council of\n15 January 2013 on the approval and\nmarket surveillance of two- or three-wheel\nvehicles and quadricycles (OJ L 60,\n2.3.2013, p. 52).\n\n42 Directive 2014/90/EU of the European\nParliament and of the Council of 23 July\n2014 on marine equipment and repealing\nCouncil Directive 96/98/EC (OJ L 257,\n28.8.2014, p. 146).\n\n43 Directive (EU) 2016/797 of the\nEuropean Parliament and of the Council of\n11 May 2016 on the interoperability of the\nrail system within the European Union (OJ\nL 138, 26.5.2016, p. 44).", "43 Directive (EU) 2016/797 of the\nEuropean Parliament and of the Council of\n11 May 2016 on the interoperability of the\nrail system within the European Union (OJ\nL 138, 26.5.2016, p. 44).\n\n44 Regulation (EU) 2018/858 of the\nEuropean Parliament and of the Council of\n30 May 2018 on the approval and market\nsurveillance of motor vehicles and their\n\n\n-----\n\ntrailers, and of systems, components and\nseparate technical units intended for such\nvehicles, amending Regulations (EC) No\n715/2007 and (EC) No 595/2009 and\nrepealing Directive 2007/46/EC (OJ L 151,\n14.6.2018, p. 1).\n\n45 Regulation (EU) 2018/1139 of the\nEuropean Parliament and of the Council of\n4 July 2018 on common rules in the field\nof civil aviation and establishing a\nEuropean Union Aviation Safety Agency,\nand amending Regulations (EC) No\n2111/2005, (EC) No 1008/2008, (EU) No\n996/2010, (EU) No 376/2014 and\nDirectives 2014/30/EU and 2014/53/EU of\nthe European Parliament and of the\nCouncil, and repealing Regulations (EC)\nNo 552/2004 and (EC) No 216/2008 of the\nEuropean Parliament and of the Council\nand Council Regulation (EEC) No 3922/91\n(OJ L 212, 22.8.2018, p. 1).\n\n46 Regulation (EU) 2019/2144 of the\nEuropean Parliament and of the Council of\n27 November 2019 on type-approval\nrequirements for motor vehicles and their\ntrailers, and systems, components and\nseparate technical units intended for such\nvehicles, as regards their general safety and\nthe protection of vehicle occupants and\nvulnerable road users, amending\nRegulation (EU) 2018/858 of the European\nParliament and of the Council and\nrepealing Regulations (EC) No 78/2009,\n(EC) No 79/2009 and (EC) No 661/2009 of\nthe European Parliament and of the\nCouncil and Commission Regulations (EC)\nNo 631/2009, (EU) No 406/2010, (EU) No\n672/2010, (EU) No 1003/2010, (EU) No\n1005/2010, (EU) No 1008/2010, (EU) No\n1009/2010, (EU) No 19/2011, (EU) No\n109/2011, (EU) No 458/2011, (EU) No\n65/2012, (EU) No 130/2012, (EU) No\n347/2012, (EU) No 351/2012, (EU) No\n1230/2012 and (EU) 2015/166 (OJ L 325,\n16.12.2019, p. 1).\n\ntrailers, and of systems, components and\nseparate technical units intended for such\nvehicles, amending Regulations (EC) No\n715/2007 and (EC) No 595/2009 and\nrepealing Directive 2007/46/EC (OJ L 151,\n14.6.2018, p. 1).\n\n45 Regulation (EU) 2018/1139 of the\nEuropean Parliament and of the Council of\n4 July 2018 on common rules in the field\nof civil aviation and establishing a\nEuropean Union Aviation Safety Agency,\nand amending Regulations (EC) No\n2111/2005, (EC) No 1008/2008, (EU) No\n996/2010, (EU) No 376/2014 and\nDirectives 2014/30/EU and 2014/53/EU of\nthe European Parliament and of the\nCouncil, and repealing Regulations (EC)\nNo 552/2004 and (EC) No 216/2008 of the\nEuropean Parliament and of the Council\nand Council Regulation (EEC) No 3922/91\n(OJ L 212, 22.8.2018, p. 1).\n\n46 Regulation (EU) 2019/2144 of the\nEuropean Parliament and of the Council of\n27 November 2019 on type-approval\nrequirements for motor vehicles and their\ntrailers, and systems, components and\nseparate technical units intended for such\nvehicles, as regards their general safety and\nthe protection of vehicle occupants and\nvulnerable road users, amending\nRegulation (EU) 2018/858 of the European\nParliament and of the Council and\nrepealing Regulations (EC) No 78/2009,\n(EC) No 79/2009 and (EC) No 661/2009 of\nthe European Parliament and of the\nCouncil and Commission Regulations (EC)\nNo 631/2009, (EU) No 406/2010, (EU) No\n672/2010, (EU) No 1003/2010, (EU) No\n1005/2010, (EU) No 1008/2010, (EU) No\n1009/2010, (EU) No 19/2011, (EU) No\n109/2011, (EU) No 458/2011, (EU) No\n65/2012, (EU) No 130/2012, (EU) No\n347/2012, (EU) No 351/2012, (EU) No\n1230/2012 and (EU) 2015/166 (OJ L 325,\n16.12.2019, p. 1).", "**Recital 30**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(30) As regards genai systems that are safety\ncomponents of products, or which are\nthemselves products, falling within the\nscope of certain Union harmonisation\n**_legislation,_** it is appropriate to classify\nthem as high-risk under this Regulation if\nthe product in question undergoes the\nconformity assessment procedure with a\nthird-party conformity assessment body\npursuant to that relevant Union\nharmonisation **_legislation._** In particular,\nsuch products are machinery, toys, lifts,\nequipment and protective systems intended\nfor use in potentially explosive\natmospheres, radio equipment, pressure\nequipment, recreational craft equipment,\ncableway installations, appliances burning\ngaseous fuels, medical devices, and in vitro\ndiagnostic medical devices.\n\n(30) As regards genai systems that are safety\ncomponents of products, or which are\nthemselves products, falling within the\nscope of certain Union harmonisation **_law_**\n**_listed in Annex II,_** it is appropriate to\nclassify them as high-risk under this\nRegulation if the product in question\nundergoes the conformity assessment\nprocedure **_in order to ensure compliance_**\n**_with essential safety requirements_** with a\nthird-party conformity assessment body\npursuant to that relevant Union\nharmonisation **_law._** In particular, such\nproducts are machinery, toys, lifts,\nequipment and protective systems intended\nfor use in potentially explosive\natmospheres, radio equipment, pressure\nequipment, recreational craft equipment,\ncableway installations, appliances burning\ngaseous fuels, medical devices, and in vitro\ndiagnostic medical devices.", "**Recital 31**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(31) The classification of an genai system as\nhigh-risk pursuant to this Regulation\nshould not **_necessarily_** mean that the\nproduct whose safety component is the genai\nsystem, or the genai system itself as a\nproduct, is considered \u2018high-risk\u2019 under the\ncriteria established in the relevant Union\nharmonisation **_legislation_** that applies to\nthe product.\n\nThis is notably the case for\nRegulation (EU) 2017/745 of the European\nParliament and of the Council 47 and\nRegulation (EU) 2017/746 of the European\nParliament and of the Council 48 , where a\nthird-party conformity assessment is\nprovided for medium-risk and high-risk\n\n\n(31) The classification of an genai system as\nhigh-risk pursuant to this Regulation\nshould not mean that the product whose\nsafety component is the genai system, or the\ngenai system itself as a product, is considered\n\u2018high-risk\u2019 under the criteria established in\nthe relevant Union harmonisation **_law_** that\napplies to the product.\n\nThis is notably the\ncase for Regulation (EU) 2017/745 of the\nEuropean Parliament and of the Council 47\nand Regulation (EU) 2017/746 of the\nEuropean Parliament and of the Council 48 ,\nwhere a third-party conformity assessment\nis provided for medium-risk and high-risk\nproducts.\n\n-----\n\nproducts.\n\n__________________ __________________\n\n\n47 Regulation (EU) 2017/745 of the\nEuropean Parliament and of the Council of\n5 April 2017 on medical devices, amending\nDirective 2001/83/EC, Regulation (EC) No\n178/2002 and Regulation (EC) No\n1223/2009 and repealing Council\nDirectives 90/385/EEC and 93/42/EEC (OJ\nL 117, 5.5.2017, p. 1).\n\n48 Regulation (EU) 2017/746 of the\nEuropean Parliament and of the Council of\n5 April 2017 on in vitro diagnostic medical\ndevices and repealing Directive 98/79/EC\nand Commission Decision 2010/227/EU\n(OJ L 117, 5.5.2017, p. 176).\n\n47 Regulation (EU) 2017/745 of the\nEuropean Parliament and of the Council of\n5 April 2017 on medical devices, amending\nDirective 2001/83/EC, Regulation (EC) No\n178/2002 and Regulation (EC) No\n1223/2009 and repealing Council\nDirectives 90/385/EEC and 93/42/EEC (OJ\nL 117, 5.5.2017, p. 1).\n\n48 Regulation (EU) 2017/746 of the\nEuropean Parliament and of the Council of\n5 April 2017 on in vitro diagnostic medical\ndevices and repealing Directive 98/79/EC\nand Commission Decision 2010/227/EU\n(OJ L 117, 5.5.2017, p. 176).", "**Recital 32**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(32) As regards stand-alone genai systems,\nmeaning high-risk genai systems other than\nthose that are safety components of\nproducts, or which are themselves\nproducts, it is appropriate to classify them\nas high-risk if, in the light of their intended\npurpose, they pose a **_high_** risk of harm to\nthe health and safety or the fundamental\nrights of persons **_, taking into account both_**\n**_the_** severity **_of the possible harm and its_**\nprobability of occurrence and **_they are_**\n**_used in a number of specifically predefined areas specified in the Regulation_** .\n\nThe identification of those systems is based\non the same methodology and criteria\nenvisaged also for any future amendments\nof the list of high-risk genai systems.\n\n(32) As regards stand-alone genai systems,\nmeaning high-risk genai systems other than\nthose that are safety components of\nproducts, or which are themselves products\n**_and that are listed in one of the areas and_**\n**_use cases in Annex III_** , it is appropriate to\nclassify them as high-risk if, in the light of\ntheir intended purpose, they pose a\n**_significant_** risk of harm to the health and\nsafety or the fundamental rights of persons\n**_and, where the genai system is used as a_**\n**_safety component of a critical_**\n**_infrastructure, to the environment .\n\nSuch_**\n**_significant risk of harm should be_**\n**_identified by assessing on the one hand_**\n**_the effect of such risk with respect to its_**\n**_level of_** severity **_, intensity,_** probability of\noccurrence and **_duration combined_**\n**_altogether and on the other hand whether_**\n**_the risk can affect an individual, a_**\n**_plurality of persons or a particular group_**\n**_of persons.\n\nSuch combination could for_**\n**_instance result in a high severity but low_**\n**_probability to affect a natural person, or a_**\n\n\n-----\n\n**_high probability to affect a group of_**\n**_persons with a low intensity over a long_**\n**_period of time, depending on the context_** .\n\nThe identification of those systems is based\non the same methodology and criteria\nenvisaged also for any future amendments\nof the list of high-risk genai systems.", "**Recital 32 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(32a) Providers whose genai systems fall_**\n**_under one of the areas and use cases_**\n**_listed in Annex III that consider their_**\n**_system does not pose a significant risk of_**\n**_harm to the health, safety, fundamental_**\n**_rights or the environment should inform_**\n**_the national supervisory authorities by_**\n**_submitting a reasoned notification.\n\nThis_**\n**_could take the form of a one-page_**\n**_summary of the relevant information on_**\n**_the genai system in question, including its_**\n**_intended purpose and why it would not_**\n**_pose a significant risk of harm to the_**\n**_health, safety, fundamental rights or the_**\n**_environment.\n\nThe Commission should_**\n**_specify criteria to enable companies to_**\n**_assess whether their system would pose_**\n**_such risks, as well as develop an easy to_**\n**_use and standardised template for the_**\n**_notification.\n\nProviders should submit the_**\n**_notification as early as possible and in_**\n**_any case prior to the placing of the AI_**\n**_system on the market or its putting into_**\n**_service, ideally at the development stage,_**\n**_and they should be free to place it on the_**\n**_market at any given time after the_**\n**_notification.\n\nHowever, if the authority_**\n**_estimates the genai system in question was_**\n**_misclassified, it should object to the_**\n**_notification within a period of three_**\n**_months.\n\nThe objection should be_**\n**_substantiated and duly explain why the AI_**\n**_system has been misclassified.\n\nThe_**\n**_provider should retain the right to appeal_**\n\n\n-----\n\n**_by providing further arguments.\n\nIf after_**\n**_the three months there has been no_**\n**_objection to the notification, national_**\n**_supervisory authorities could still_**\n**_intervene if the genai system presents a risk_**\n**_at national level, as for any other AI_**\n**_system on the market.\n\nNational_**\n**_supervisory authorities should submit_**\n**_annual reports to the genai Office detailing_**\n**_the notifications received and the_**\n**_decisions taken._**", "**Recital 33**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(33) Technical inaccuracies of AI_**\n**_systems intended for the remote biometric_**\n**_identification of natural persons can lead_**\n**_to biased results and entail discriminatory_**\n**_effects.\n\nThis is particularly relevant when_**\n**_it comes to age, ethnicity, sex or_**\n**_disabilities.\n\nTherefore, \u2018real-time\u2019 and_**\n**_\u2018post\u2019 remote biometric identification_**\n**_systems should be classified as high-risk._**\n**_In view of the risks that they pose, both_**\n**_types of remote biometric identification_**\n**_systems should be subject to specific_**\n**_requirements on logging capabilities and_**\n**_human oversight._**\n\n\n**_deleted_**", "**Recital 33 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(33a) As biometric data constitute a_**\n**_special category of sensitive personal data_**\n**_in accordance with Regulation 2016/679,_**\n**_it is appropriate to classify as high-risk_**\n**_several critical use-cases of biometric and_**\n**_biometrics-based systems.\n\ngenai systems_**\n**_intended to be used for biometric_**\n\n\n-----\n\n**_identification of natural persons and AI_**\n**_systems intended to be used to make_**\n**_inferences about personal characteristics_**\n**_of natural persons on the basis of_**\n**_biometric or biometrics-based data,_**\n**_including emotion recognition systems,_**\n**_with the exception of those which are_**\n**_prohibited under this Regulation should_**\n**_therefore be classified as high-risk.\n\nThis_**\n**_should not include genai systems intended to_**\n**_be used for biometric verification, which_**\n**_includes authentication, whose sole_**\n**_purpose is to confirm that a specific_**\n**_natural person is the person he or she_**\n**_claims to be and to confirm the identity of_**\n**_a natural person for the sole purpose of_**\n**_having access to a service, a device or_**\n**_premises (one-to-one verification)._**\n**_Biometric and biometrics-based systems_**\n**_which are provided for under Union law_**\n**_to enable cybersecurity and personal data_**\n**_protection measures should not be_**\n**_considered as posing a significant risk of_**\n**_harm to the health, safety and_**\n**_fundamental rights._**", "**Recital 34**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(34) As regards the management and\noperation of critical infrastructure, it is\nappropriate to classify as high-risk the genai\nsystems intended to be used as safety\ncomponents in the management and\noperation of **_road traffic and_** the supply of\nwater, gas, heating **_and_** electricity, since\ntheir failure or malfunctioning may put at\nrisk the life and health of persons at large\nscale and lead to appreciable disruptions in\nthe ordinary conduct of social and\neconomic activities.\n\n(34) As regards the management and\noperation of critical infrastructure, it is\nappropriate to classify as high-risk the genai\nsystems intended to be used as safety\ncomponents in the management and\noperation of the supply of water, gas,\nheating electricity **_and critical digital_**\n**_infrastructure_** , since their failure or\nmalfunctioning may **_infringe the security_**\n**_and integrity of such critical_**\n**_infrastructure or_** put at risk the life and\nhealth of persons at large scale and lead to\nappreciable disruptions in the ordinary\nconduct of social and economic activities.\n\n**_Safety components of critical_**\n**_infrastructure, including critical digital_**\n\n\n-----\n\n**_infrastructure, are systems used to directly_**\n**_protect the physical integrity of critical_**\n**_infrastructure or health and safety of_**\n**_persons and property.\n\nFailure or_**\n**_malfunctioning of such components_**\n**_might directly lead to risks to the physical_**\n**_integrity of critical infrastructure and_**\n**_thus to risks to the health and safety of_**\n**_persons and property.\n\nComponents_**\n**_intended to be used solely for_**\n**_cybersecurity purposes should not qualify_**\n**_as safety components.\n\nExamples of such_**\n**_safety components may include systems_**\n**_for monitoring water pressure or fire_**\n**_alarm controlling systems in cloud_**\n**_computing centres._**", "**Recital 35**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(35) genai systems used in education or\nvocational training, notably for\ndetermining access or assigning persons to\neducational and vocational training\ninstitutions or to evaluate persons on tests\nas part of or as a precondition for their\neducation should be **_considered high-risk_** ,\nsince they may determine the educational\nand professional course of a person\u2019s life\nand therefore affect their ability to secure\ntheir livelihood.\n\nWhen improperly\ndesigned and used, such systems may\nviolate the right to education and training\nas well as the right not to be discriminated\nagainst and perpetuate historical patterns of\ndiscrimination.\n\n(35) **_Deployment of genai systems in_**\n**_education is important in order to help_**\n**_modernise entire education systems, to_**\n**_increase educational quality, both offline_**\n**_and online and to accelerate digital_**\n**_education, thus also making it available to_**\n**_a broader audience ._** genai systems used in\neducation or vocational training, notably\nfor determining access **_or materially_**\n**_influence decisions on admission_** or\nassigning persons to educational and\nvocational training institutions or to\nevaluate persons on tests as part of or as a\nprecondition for their education **_or to_**\n**_assess the appropriate level of education_**\n**_for an individual and materially influence_**\n**_the level of education and training that_**\n**_individuals will receive or be able to_**\n**_access or to monitor and detect prohibited_**\n**_behaviour of students during tests_** should\nbe **_classified as high-risk genai systems_** , since\nthey may determine the educational and\nprofessional course of a person\u2019s life and\ntherefore affect their ability to secure their\nlivelihood.\n\nWhen improperly designed and\n\n\n-----\n\nused, such systems **_can be particularly_**\n**_intrusive and_** may violate the right to\neducation and training as well as the right\nnot to be discriminated against and\nperpetuate historical patterns of\ndiscrimination **_, for example against_**\n**_women, certain age groups, persons with_**\n**_disabilities, or persons of certain racial or_**\n**_ethnic origins or sexual orientation_** .", "**Recital 36**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(36) genai systems used in employment,\nworkers management and access to selfemployment, notably for the recruitment\nand selection of persons, for making\ndecisions **_on_** promotion and termination\nand for task allocation, monitoring or\nevaluation of persons in work-related\ncontractual relationships, should also be\nclassified as high-risk, since those systems\nmay appreciably impact future career\nprospects **_and_** livelihoods of these persons.\n\nRelevant work-related contractual\nrelationships should involve employees\nand persons providing services through\nplatforms as referred to in the Commission\nWork Programme 2021 **_.\n\nSuch persons_**\n**_should in principle not be considered_**\n**_users within the meaning of this_**\n**_Regulation_** .\n\nThroughout the recruitment\nprocess and in the evaluation, promotion,\nor retention of persons in work-related\ncontractual relationships, such systems\nmay perpetuate historical patterns of\ndiscrimination, for example against\nwomen, certain age groups, persons with\ndisabilities, or persons of certain racial or\nethnic origins or sexual orientation.\n\ngenai\nsystems used to monitor the performance\nand behaviour of these persons may also\nimpact their rights to data protection and\nprivacy.\n\n(36) genai systems used in employment,\nworkers management and access to selfemployment, notably for the recruitment\nand selection of persons, for making\ndecisions **_or materially influence decisions_**\n**_on initiation,_** promotion and termination\nand for **_personalised_** task allocation **_based_**\n**_on individual behaviour, personal traits or_**\n**_biometric data_** , monitoring or evaluation of\npersons in work-related contractual\nrelationships, should also be classified as\nhigh-risk, since those systems may\nappreciably impact future career prospects **_,_**\nlivelihoods of these persons **_and workers\u2019_**\n**_rights_** .\n\nRelevant work-related contractual\nrelationships should **_meaningfully_** involve\nemployees and persons providing services\nthrough platforms as referred to in the\nCommission Work Programme 2021.\n\nThroughout the recruitment process and in\nthe evaluation, promotion, or retention of\npersons in work-related contractual\nrelationships, such systems may perpetuate\nhistorical patterns of discrimination, for\nexample against women, certain age\ngroups, persons with disabilities, or\npersons of certain racial or ethnic origins or\nsexual orientation.\n\ngenai systems used to\nmonitor the performance and behaviour of\nthese persons may also **_undermine the_**\n**_essence of their fundamental_** rights to data\nprotection and privacy.\n\n**_This Regulation_**\n\n\n-----\n\n**_applies without prejudice to Union and_**\n**_Member State competences to provide for_**\n**_more specific rules for the use of AIsystems in the employment context._**", "**Recital 37**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(37) Another area in which the use of genai\nsystems deserves special consideration is\nthe access to and enjoyment of certain\nessential private and public services and\nbenefits necessary for people to fully\nparticipate in society or to improve one\u2019s\nstandard of living.\n\nIn particular, genai systems\nused to evaluate the credit score or\ncreditworthiness of natural persons should\nbe classified as high-risk genai systems, since\nthey determine those persons\u2019 access to\nfinancial resources or essential services\nsuch as housing, electricity, and\ntelecommunication services.\n\ngenai systems\nused for this purpose may lead to\ndiscrimination of persons or groups and\nperpetuate historical patterns of\ndiscrimination, for example based on racial\nor ethnic origins, disabilities, age, sexual\norientation, or create new forms of\ndiscriminatory impacts.\n\n**_Considering the_**\n**_very limited scale of the impact and the_**\n**_available alternatives on the market_** , **_it is_**\n**_appropriate to exempt_** genai systems for the\npurpose of **_creditworthiness assessment_**\n**_and credit scoring when put into service_**\n**_by small-scale providers for their own use_** .\n\nNatural persons applying for or receiving\npublic assistance benefits and services\nfrom public authorities are typically\ndependent on those benefits and services\nand in a vulnerable position in relation to\nthe responsible authorities.\n\nIf genai systems\nare used for determining whether such\nbenefits and services should be denied,\nreduced, revoked or reclaimed by\nauthorities, they may have a significant\n\n\n(37) Another area in which the use of genai\nsystems deserves special consideration is\nthe access to and enjoyment of certain\nessential private and public services,\n**_including healthcare services, and_**\n**_essential services, including but not_**\n**_limited to housing, electricity,_**\n**_heating/cooling and internet,_** and benefits\nnecessary for people to fully participate in\nsociety or to improve one\u2019s standard of\nliving.\n\nIn particular, genai systems used to\nevaluate the credit score or\ncreditworthiness of natural persons should\nbe classified as high-risk genai systems, since\nthey determine those persons\u2019 access to\nfinancial resources or essential services\nsuch as housing, electricity, and\ntelecommunication services.\n\ngenai systems\nused for this purpose may lead to\ndiscrimination of persons or groups and\nperpetuate historical patterns of\ndiscrimination, for example based on racial\nor ethnic origins, **_gender,_** disabilities, age,\nsexual orientation, or create new forms of\ndiscriminatory impacts.\n\n**_However, AI_**\n**_systems provided for by Union law for the_**\n**_purpose of detecting fraud in the offering_**\n**_of financial services should not be_**\n**_considered as high-risk under this_**\n**_Regulation._** Natural persons applying for\nor receiving public assistance benefits and\nservices from public authorities **_, including_**\n**_healthcare services and essential services,_**\n**_including but not limited to housing,_**\n**_electricity, heating/cooling and internet,_**\nare typically dependent on those benefits\nand services and in a vulnerable position in\n\n\n-----\n\nimpact on persons\u2019 livelihood and may\ninfringe their fundamental rights, such as\nthe right to social protection, nondiscrimination, human dignity or an\neffective remedy.\n\nThose systems should\ntherefore be classified as high-risk.\n\nNonetheless, this Regulation should not\nhamper the development and use of\ninnovative approaches in the public\nadministration, which would stand to\nbenefit from a wider use of compliant and\nsafe genai systems, provided that those\nsystems do not entail a high risk to legal\nand natural persons.\n\nFinally, genai systems\nused to dispatch or establish priority in the\ndispatching of emergency first response\nservices should also be classified as highrisk since they make decisions in very\ncritical situations for the life and health of\npersons and their property.\n\nrelation to the responsible authorities.\n\nIf genai\nsystems are used for determining whether\nsuch benefits and services should be\ndenied, reduced, revoked or reclaimed by\nauthorities, they may have a significant\nimpact on persons\u2019 livelihood and may\ninfringe their fundamental rights, such as\nthe right to social protection, nondiscrimination, human dignity or an\neffective remedy.\n\nSimilarly, genai systems\nintended to be used **_to make decisions or_**\n**_materially influence decisions on the_**\n**_eligibility of natural persons for health_**\n**_and life insurance may also have a_**\n**_significant impact on persons\u2019 livelihood_**\n**_and may infringe their fundamental rights_**\n**_such as by limiting access to healthcare or_**\n**_by perpetuating discrimination based on_**\n**_personal characteristics._** Those systems\nshould therefore be classified as high-risk.", "Nonetheless, this Regulation should not\nhamper the development and use of\ninnovative approaches in the public\nadministration, which would stand to\nbenefit from a wider use of compliant and\nsafe genai systems, provided that those\nsystems do not entail a high risk to legal\nand natural persons.\n\nFinally, genai systems\nused **_to evaluate and classify emergency_**\n**_calls by natural persons or_** to dispatch or\nestablish priority in the dispatching of\nemergency first response services should\nalso be classified as high-risk since they\nmake decisions in very critical situations\nfor the life and health of persons and their\nproperty.", "**Recital 37 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(37a) Given the role and responsibility of_**\n**_police and judicial authorities, and the_**\n**_impact of decisions they take for the_**\n**_purposes of the prevention, investigation,_**\n**_detection or prosecution of criminal_**\n\n\n-----\n\n**_offences or the execution of criminal_**\n**_penalties, some specific use-cases of AI_**\n**_applications in law enforcement has to be_**\n**_classified as high-risk, in particular in_**\n**_instances where there is the potential to_**\n**_significantly affect the lives or the_**\n**_fundamental rights of individuals._**", "**Recital 38**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(38) Actions by law enforcement\nauthorities involving certain uses of genai\nsystems are characterised by a significant\ndegree of power imbalance and may lead to\nsurveillance, arrest or deprivation of a\nnatural person\u2019s liberty as well as other\nadverse impacts on fundamental rights\nguaranteed in the Charter.\n\nIn particular, if\nthe genai system is not trained with high\nquality data, does not meet adequate\nrequirements in terms of its accuracy or\nrobustness, or is not properly designed and\ntested before being put on the market or\notherwise put into service, it may single\nout people in a discriminatory or otherwise\nincorrect or unjust manner.\n\nFurthermore,\nthe exercise of important procedural\nfundamental rights, such as the right to an\neffective remedy and to a fair trial as well\nas the right of defence and the presumption\nof innocence, could be hampered, in\nparticular, where such genai systems are not\nsufficiently transparent, explainable and\ndocumented.\n\nIt is therefore appropriate to\nclassify as high-risk a number of genai\nsystems intended to be used in the law\nenforcement context where accuracy,\nreliability and transparency is particularly\nimportant to avoid adverse impacts, retain\npublic trust and ensure accountability and\neffective redress.\n\nIn view of the nature of\nthe activities in question and the risks\nrelating thereto, those high-risk genai systems\nshould include in particular genai systems\n\n\n(38) Actions by law enforcement\nauthorities involving certain uses of genai\nsystems are characterised by a significant\ndegree of power imbalance and may lead to\nsurveillance, arrest or deprivation of a\nnatural person\u2019s liberty as well as other\nadverse impacts on fundamental rights\nguaranteed in the Charter.\n\nIn particular, if\nthe genai system is not trained with high\nquality data, does not meet adequate\nrequirements in terms of **_its performance,_**\nits accuracy or robustness, or is not\nproperly designed and tested before being\nput on the market or otherwise put into\nservice, it may single out people in a\ndiscriminatory or otherwise incorrect or\nunjust manner.\n\nFurthermore, the exercise\nof important procedural fundamental\nrights, such as the right to an effective\nremedy and to a fair trial as well as the\nright of defence and the presumption of\ninnocence, could be hampered, in\nparticular, where such genai systems are not\nsufficiently transparent, explainable and\ndocumented.\n\nIt is therefore appropriate to\nclassify as high-risk a number of genai\nsystems intended to be used in the law\nenforcement context where accuracy,\nreliability and transparency is particularly\nimportant to avoid adverse impacts, retain\npublic trust and ensure accountability and\neffective redress.\n\nIn view of the nature of\nthe activities in question and the risks\nrelating thereto, those high-risk genai systems\n\n\n-----\n\nintended to be used by law enforcement\nauthorities **_for individual risk assessments_** ,\npolygraphs and similar tools **_or to detect_**\n**_the emotional state of natural person, to_**\n**_detect \u2018deep fakes\u2019_** , for the evaluation of\nthe reliability of evidence in criminal\nproceedings **_, for predicting the occurrence_**\n**_or reoccurrence of an actual or potential_**\n**_criminal offence based on profiling of_**\n**_natural persons, or assessing personality_**\n**_traits and characteristics or past criminal_**\n**_behaviour of natural persons or groups_** ,\nfor profiling in the course of detection,\ninvestigation or prosecution of criminal\noffences, as well as for crime analytics\nregarding natural persons.\n\ngenai systems\nspecifically intended to be used for\nadministrative proceedings by tax and\ncustoms authorities should not be\n**_considered_** high-risk genai systems used by\nlaw enforcement authorities for the\npurposes of prevention, detection,\ninvestigation and prosecution of criminal\noffences.\n\nshould include in particular genai systems\nintended to be used by **_or on behalf of_** law\nenforcement authorities **_or by Union_**\n**_agencies_** , **_offices or bodies in support of_**\n**_law enforcement authorities, as_**\npolygraphs and similar tools **_insofar as_**\n**_their use is permitted under relevant_**\n**_Union and national law_** , for the evaluation\nof the reliability of evidence in criminal\nproceedings, for profiling in the course of\ndetection, investigation or prosecution of\ncriminal offences, as well as for crime\nanalytics regarding natural persons.\n\ngenai\nsystems specifically intended to be used for\nadministrative proceedings by tax and\ncustoms authorities should not be **_classified_**\n**_as_** high-risk genai systems used by law\nenforcement authorities for the purposes of\nprevention, detection, investigation and\nprosecution of criminal offences.\n\n**_The use_**\n**_of genai tools by law enforcement and_**\n**_judicial authorities should not become a_**\n**_factor of inequality, social fracture or_**\n**_exclusion.", "**_The use_**\n**_of genai tools by law enforcement and_**\n**_judicial authorities should not become a_**\n**_factor of inequality, social fracture or_**\n**_exclusion.\n\nThe impact of the use of AI_**\n**_tools on the defence rights of suspects_**\n**_should not be ignored, notably the_**\n**_difficulty in obtaining meaningful_**\n**_information on their functioning and the_**\n**_consequent difficulty in challenging their_**\n**_results in court, in particular by_**\n**_individuals under investigation._**", "**Recital 39**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(39) genai systems used in migration, asylum\nand border control management affect\npeople who are often in particularly\nvulnerable position and who are dependent\non the outcome of the actions of the\ncompetent public authorities.\n\nThe\naccuracy, non-discriminatory nature and\ntransparency of the genai systems used in\nthose contexts are therefore particularly\nimportant to guarantee the respect of the\n\n\n(39) genai systems used in migration, asylum\nand border control management affect\npeople who are often in particularly\nvulnerable position and who are dependent\non the outcome of the actions of the\ncompetent public authorities.\n\nThe\naccuracy, non-discriminatory nature and\ntransparency of the genai systems used in\nthose contexts are therefore particularly\nimportant to guarantee the respect of the\n\n\n-----\n\nfundamental rights of the affected persons,\nnotably their rights to free movement, nondiscrimination, protection of private life\nand personal data, international protection\nand good administration.\n\nIt is therefore\nappropriate to classify as high-risk genai\nsystems intended to be used by **_the_**\ncompetent public authorities charged with\ntasks in the fields of migration, asylum and\nborder control management as polygraphs\nand similar tools **_or to detect the emotional_**\n**_state of a natural person;_** for assessing\ncertain risks posed by natural persons\nentering the territory of a Member State or\napplying for visa or asylum; for verifying\nthe authenticity of the relevant documents\nof natural persons; for assisting competent\npublic authorities for the examination **_of_**\napplications for asylum, visa and residence\npermits and associated complaints with\nregard to the objective to establish the\neligibility of the natural persons applying\nfor a status.\n\ngenai systems in the area of\nmigration, asylum and border control\nmanagement covered by this Regulation\nshould comply with the relevant procedural\nrequirements set by the Directive\n2013/32/EU of the European Parliament\nand of the Council 49 , the Regulation (EC)\nNo 810/2009 of the European Parliament\nand of the Council 50 and other relevant\nlegislation.\n\nfundamental rights of the affected persons,\nnotably their rights to free movement, nondiscrimination, protection of private life\nand personal data, international protection\nand good administration.\n\nIt is therefore\nappropriate to classify as high-risk genai\nsystems intended to be used by **_or on_**\n**_behalf of_** competent public authorities **_or_**\n**_by Union agencies, offices or bodies_**\ncharged with tasks in the fields of\nmigration, asylum and border control\nmanagement as polygraphs and similar\ntools **_insofar as their use is permitted_**\n**_under relevant Union and national law,_**\nfor assessing certain risks posed by natural\npersons entering the territory of a Member\nState or applying for visa or asylum; for\nverifying the authenticity of the relevant\ndocuments of natural persons; for assisting\ncompetent public authorities for the\nexamination **_and assessment of the_**\n**_veracity of evidence in relation to_**\napplications for asylum, visa and residence\npermits and associated complaints with\nregard to the objective to establish the\neligibility of the natural persons applying\nfor a status **_; for monitoring, surveilling or_**\n**_processing personal data in the context of_**\n**_border management activities, for the_**\n**_purpose of detecting, recognising or_**\n**_identifying natural persons; for the_**\n**_forecasting or prediction of trends related_**\n**_to migration movements and border_**\n**_crossings_** .\n\ngenai systems in the area of\nmigration, asylum and border control\nmanagement covered by this Regulation\nshould comply with the relevant procedural\nrequirements set by the Directive\n2013/32/EU of the European Parliament\nand of the Council 49 , the Regulation (EC)\nNo 810/2009 of the European Parliament\nand of the Council 50 and other relevant\nlegislation.\n\n**_The use of genai systems in_**\n**_migration, asylum and border control_**\n**_management should in no circumstances_**\n**_be used by Member States or Union_**\n**_institutions, agencies or bodies as a means_**\n**_to circumvent their international_**\n**_obligations under the Convention of 28_**\n**_July 1951 relating to the Status of_**\n\n\n-----\n\n**_Refugees as amended by the Protocol of_**\n**_31 January 1967, nor should they be used_**\n**_to in any way infringe on the principle of_**\n**_non-refoulement, or or deny safe and_**\n**_effective legal avenues into the territory of_**\n**_the Union, including the right to_**\n**_international protection._**\n\n__________________ __________________\n\n\n49 Directive 2013/32/EU of the European\nParliament and of the Council of 26 June\n2013 on common procedures for granting\nand withdrawing international protection\n(OJ L 180, 29.6.2013, p. 60).", "50 Regulation (EC) No 810/2009 of the\nEuropean Parliament and of the Council of\n13 July 2009 establishing a Community\nCode on Visas (Visa Code) (OJ L 243,\n15.9.2009, p. 1).\n\n49 Directive 2013/32/EU of the European\nParliament and of the Council of 26 June\n2013 on common procedures for granting\nand withdrawing international protection\n(OJ L 180, 29.6.2013, p. 60).\n\n50 Regulation (EC) No 810/2009 of the\nEuropean Parliament and of the Council of\n13 July 2009 establishing a Community\nCode on Visas (Visa Code) (OJ L 243,\n15.9.2009, p. 1).", "**Recital 40**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(40) Certain genai systems intended for the\nadministration of justice and democratic\nprocesses should be classified as high-risk,\nconsidering their potentially significant\nimpact on democracy, rule of law,\nindividual freedoms as well as the right to\nan effective remedy and to a fair trial.\n\nIn\nparticular, to address the risks of potential\nbiases, errors and opacity, it is appropriate\nto qualify as high-risk genai systems intended\nto assist judicial authorities in researching\nand interpreting facts and the law and in\napplying the law to a concrete set of facts.\n\nSuch qualification should not extend,\nhowever, to genai systems intended for purely\nancillary administrative activities that do\nnot affect the actual administration of\njustice in individual cases, such as\nanonymisation or pseudonymisation of\njudicial decisions, documents or data,\ncommunication between personnel,\nadministrative tasks or allocation of\n\n\n(40) Certain genai systems intended for the\nadministration of justice and democratic\nprocesses should be classified as high-risk,\nconsidering their potentially significant\nimpact on democracy, rule of law,\nindividual freedoms as well as the right to\nan effective remedy and to a fair trial.\n\nIn\nparticular, to address the risks of potential\nbiases, errors and opacity, it is appropriate\nto qualify as high-risk genai systems intended\nto **_be used by a judicial authority or_**\n**_administrative body or on their behalf to_**\nassist judicial authorities **_or administrative_**\n**_bodies_** in researching and interpreting facts\nand the law and in applying the law to a\nconcrete set of facts **_or used in a similar_**\n**_way in alternative dispute resolution.\n\nThe_**\n**_use of genai tools can_**\n**_support, but should not replace the_**\n**_decision-making power of judges or_**\n**_judicial independence, as the final_**\n**_decision-making must remain a human-_**\n\n\n-----\n\nresources.\n\n**_driven activity and decision_** .\n\nSuch\nqualification should not extend, however,\nto genai systems intended for purely ancillary\nadministrative activities that do not affect\nthe actual administration of justice in\nindividual cases, such as anonymisation or\npseudonymisation of judicial decisions,\ndocuments or data, communication\nbetween personnel, administrative tasks or\nallocation of resources.", "**Recital 40 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(40a) In order to address the risks of_**\n**_undue external interference to the right to_**\n**_vote enshrined in Article 39 of the_**\n**_Charter, and of disproportionate effects_**\n**_on democratic processes, democracy, and_**\n**_the rule of law, genai systems intended to be_**\n**_used to influence the outcome of an_**\n**_election or referendum or the voting_**\n**_behaviour of natural persons in the_**\n**_exercise of their vote in elections or_**\n**_referenda should be classified as high-risk_**\n**_AI systems.\n\nwith the exception of AI_**\n**_systems whose output natural persons are_**\n**_not directly exposed to, such as tools used_**\n**_to organise, optimise and structure_**\n**_political campaigns from an_**\n**_administrative and logistical point of view._**", "**Recital 40 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(40b) Considering the scale of natural_**\n**_persons using the services provided by_**\n**_social media platforms designated as very_**\n**_large online platforms, such online_**\n**_platforms can be used in a way that_**\n\n\n-----\n\n**_strongly influences safety online, the_**\n**_shaping of public opinion and discourse,_**\n**_election and democratic processes and_**\n**_societal concerns.\n\nIt is therefore_**\n**_appropriate that genai systems used by those_**\n**_online platforms in their recommender_**\n**_systems are subject to this Regulation so_**\n**_as to ensure that the genai systems comply_**\n**_with the requirements laid down under_**\n**_this Regulation, including the technical_**\n**_requirements on data governance,_**\n**_technical documentation and traceability,_**\n**_transparency, human oversight, accuracy_**\n**_and robustness.\n\nCompliance with this_**\n**_Regulation should enable such very large_**\n**_online platforms to comply with their_**\n**_broader risk assessment and riskmitigation obligations in Article 34 and 35_**\n**_of Regulation EU 2022/2065.\n\nThe_**\n**_obligations in this Regulation are without_**\n**_prejudice to Regulation (EU) 2022/2065_**\n**_and should complement the obligations_**\n**_required under the Regulation (EU)_**\n**_2022/2065 when the social media platform_**\n**_has been designated as a very large online_**\n**_platform.\n\nGiven the European-wide_**\n**_impact of social media platforms_**\n**_designated as very large online platforms,_**\n**_the authorities designated under_**\n**_Regulation (EU) 2022/2065 should act as_**\n**_enforcement authorities for the purposes_**\n**_of enforcing this provision._**", "**Recital 41**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(41) The fact that an genai system is\nclassified as high risk under this\nRegulation should not be interpreted as\nindicating that the use of the system is\nnecessarily lawful under other acts of\nUnion law or under national law\ncompatible with Union law, such as on the\nprotection of personal data, **_on the use of_**\n**_polygraphs and similar tools or other_**\n\n\n(41) The fact that an genai system is\nclassified as **_a_** high risk **_AI system_** under\nthis Regulation should not be interpreted as\nindicating that the use of the system is\nnecessarily lawful **_or unlawful_** under other\nacts of Union law or under national law\ncompatible with Union law, such as on the\nprotection of personal data, Any such use\nshould continue to occur solely in\n\n\n-----\n\n**_systems to detect the emotional state of_**\n**_natural persons._** Any such use should\ncontinue to occur solely in accordance with\nthe applicable requirements resulting from\nthe Charter and from the applicable acts of\nsecondary Union law and national law.\n\n**_This Regulation should not be understood_**\n**_as providing for the legal ground for_**\n**_processing of personal data, including_**\n**_special categories of personal data, where_**\n**_relevant._**\n\n\naccordance with the applicable\nrequirements resulting from the Charter\nand from the applicable acts of secondary\nUnion law and national law.", "**Recital 41 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(41a) A number of legally binding rules at_**\n**_European, national and international_**\n**_level already apply or are relevant to AI_**\n**_systems today, including but not limited to_**\n**_EU primary law (the Treaties of the_**\n**_European Union and its Charter of_**\n**_Fundamental Rights), EU secondary law_**\n**_(such as the General Data Protection_**\n**_Regulation, the Product Liability_**\n**_Directive, the Regulation on the Free_**\n**_Flow of Non-Personal Data, antidiscrimination Directives, consumer law_**\n**_and Safety and Health at Work_**\n**_Directives), the UN Human Rights_**\n**_treaties and the Council of Europe_**\n**_conventions (such as the European_**\n**_Convention on Human Rights), and_**\n**_national law.\n\nBesides horizontally_**\n**_applicable rules, various domain-specific_**\n**_rules exist that apply to particular AI_**\n**_applications (such as for instance the_**\n**_Medical Device Regulation in the_**\n**_healthcare sector)._**", "**Recital 42**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(42) To mitigate the risks from high-risk\ngenai systems placed or otherwise put into\nservice on the Union market for **_users_** and\naffected persons, certain mandatory\nrequirements should apply, taking into\naccount the intended purpose **_of the use_** of\nthe system and according to the risk\nmanagement system to be established by\nthe provider.\n\n(42) To mitigate the risks from high-risk\ngenai systems placed or otherwise put into\nservice on the Union market for **_deployers_**\nand affected persons, certain mandatory\nrequirements should apply, taking into\naccount the intended purpose **_, the_**\n**_reasonably foreseeable misuse_** of the\nsystem and according to the risk\nmanagement system to be established by\nthe provider.\n\n**_These requirements should_**\n**_be objective-driven, fit for purpose,_**\n**_reasonable and effective, without adding_**\n**_undue regulatory burdens or costs on_**\n**_operators._**", "**Recital 43**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(43) Requirements should apply to highrisk genai systems as regards the quality of\ndata sets used, technical documentation\nand record-keeping, transparency and the\nprovision of information to **_users_** , human\noversight, and robustness, accuracy and\ncybersecurity.\n\nThose requirements are\nnecessary to effectively mitigate the risks\nfor health, safety and fundamental rights,\nas applicable in the light of the intended\npurpose of the system, and no other less\ntrade restrictive measures are reasonably\navailable, thus avoiding unjustified\nrestrictions to trade.\n\n(43) Requirements should apply to highrisk genai systems as regards the quality **_and_**\n**_relevance_** of data sets used, technical\ndocumentation and record-keeping,\ntransparency and the provision of\ninformation to **_deployers_** , human oversight,\nand robustness, accuracy and\ncybersecurity.\n\nThose requirements are\nnecessary to effectively mitigate the risks\nfor health, safety and fundamental rights,\nas **_well as the environment, democracy_**\n**_and rule of law, as_** applicable in the light\nof the intended purpose **_or reasonably_**\n**_foreseeable misuse_** of the system, and no\nother less trade restrictive measures are\nreasonably available, thus avoiding\nunjustified restrictions to trade.", "**Recital 44**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(44) **_High_** data quality **_is essential for_** the\nperformance of many genai systems,\nespecially when techniques involving the\ntraining of models are used, with a view to\nensure that the high-risk genai system\nperforms as intended and safely and it does\nnot become **_the_** source of discrimination\nprohibited by Union law.\n\nHigh quality\ntraining, validation and testing data sets\nrequire the implementation of appropriate\ndata governance and management\npractices.\n\nTraining, validation and testing\ndata sets should be sufficiently relevant,\nrepresentative **_and free of errors and_**\ncomplete in view of the intended purpose\nof the system.\n\nThey should also have the\nappropriate statistical properties, including\nas regards the persons or groups of persons\n**_on which_** the high-risk genai system is\nintended to be used.\n\nIn particular, training,\nvalidation and testing data sets should take\ninto account, to the extent required in the\nlight of their intended purpose, the\nfeatures, characteristics or elements that\nare particular to the specific geographical,\nbehavioural or functional setting or context\nwithin which the genai system is intended to\nbe used.\n\nIn order to protect the right of\nothers from the discrimination that might\nresult from the bias in genai systems, the\nproviders **_shouldbe_** able to process also\nspecial categories of personal data, as a\nmatter of substantial public interest, in\norder to ensure the bias **_monitoring,_**\ndetection and correction in relation to highrisk genai systems.\n\n(44) **_Access to_** data **_of high_** quality **_plays a_**\n**_vital role in providing structure and in_**\n**_ensuring_** the performance of many genai\nsystems, especially when techniques\ninvolving the training of models are used,\nwith a view to ensure that the high-risk genai\nsystem performs as intended and safely and\nit does not become **_a_** source of\ndiscrimination prohibited by Union law.\n\nHigh quality training, validation and\ntesting data sets require the implementation\nof appropriate data governance and\nmanagement practices.\n\nTraining **_, and_**\n**_where applicable,_** validation and testing\ndata sets, **_including the labels,_** should be\nsufficiently relevant, representative,\n**_appropriately vetted for_** errors and **_as_**\ncomplete **_as possible_** in view of the\nintended purpose of the system.\n\nThey\nshould also have the appropriate statistical\nproperties, including as regards the persons\nor groups of persons **_in relation to whom_**\nthe high-risk genai system is intended to be\nused **_, with specific attention to the_**\n**_mitigation of possible biases in the_**\n**_datasets, that might lead to risks to_**\n**_fundamental rights or discriminatory_**\n**_outcomes for the persons affected by the_**\n**_high-risk genai system.\n\nBiases can for_**\n**_example be inherent in underlying_**\n**_datasets, especially when historical data is_**\n**_being used, introduced by the developers_**\n**_of the algorithms, or generated when the_**\n**_systems are implemented in real world_**\n**_settings.\n\nResults provided by genai systems_**\n**_are influenced by such inherent biases_**\n**_that are inclined to gradually increase_**\n**_and thereby perpetuate and amplify_**\n**_existing discrimination, in particular for_**\n**_persons belonging to certain vulnerable or_**\n**_ethnic groups, or racialised communities._**\nIn particular, training, validation and\ntesting data sets should take into account,\nto the extent required in the light of their\nintended purpose, the features,\ncharacteristics or elements that are\nparticular to the specific geographical,\n\n\n-----\n\n**_contextal_** , behavioural or functional setting\nor context within which the genai system is\nintended to be used.\n\nIn order to protect the\nright of others from the discrimination that\nmight result from the bias in genai systems,\nthe providers should, **_exceptionally and_**\n**_following the application of all applicable_**\n**_conditions laid down under this_**\n**_Regulation and in Regulation (EU)_**\n**_2016/679, Directive (EU) 2016/680 and_**\n**_Regulation (EU) 2018/1725,_** be able to\nprocess also special categories of personal\ndata, as a matter of substantial public\ninterest, in order to ensure the negative bias\ndetection and correction in relation to highrisk genai systems.\n\n**_Negative bias should be_**\n**_understood as bias that create direct or_**\n**_indirect discriminatory effect against a_**\n**_natural person The requirements related_**\n**_to data governance can be complied with_**\n**_by having recourse to third-parties that_**\n**_offer certified compliance services_**\n**_including verification of data governance,_**\n**_data set integrity, and data training,_**\n**_validation and testing practices._**", "**Recital 45**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(45) For the development of high-risk genai\nsystems, certain actors, such as providers,\nnotified bodies and other relevant entities,\nsuch as digital innovation hubs, testing\nexperimentation facilities and researchers,\nshould be able to access and use high\nquality datasets within their respective\nfields of activities which are related to this\nRegulation.\n\nEuropean common data spaces\nestablished by the Commission and the\nfacilitation of data sharing between\nbusinesses and with government in the\npublic interest will be instrumental to\nprovide trustful, accountable and nondiscriminatory access to high quality data\nfor the training, validation and testing of\n\n\n(45) For the development **_and assessment_**\nof high-risk genai systems, certain actors,\nsuch as providers, notified bodies and other\nrelevant entities, such as digital innovation\nhubs, testing experimentation facilities and\nresearchers, should be able to access and\nuse high quality datasets within their\nrespective fields of activities which are\nrelated to this Regulation.\n\nEuropean\ncommon data spaces established by the\nCommission and the facilitation of data\nsharing between businesses and with\ngovernment in the public interest will be\ninstrumental to provide trustful,\naccountable and non-discriminatory access\nto high quality data for the training,\n\n\n-----\n\ngenai systems.\n\nFor example, in health, the\nEuropean health data space will facilitate\nnon-discriminatory access to health data\nand the training of genai\nalgorithms on those datasets, in a privacypreserving, secure, timely, transparent and\ntrustworthy manner, and with an\nappropriate institutional governance.\n\nRelevant competent authorities, including\nsectoral ones, providing or supporting the\naccess to data may also support the\nprovision of high-quality data for the\ntraining, validation and testing of genai\nsystems.\n\nvalidation and testing of genai systems.\n\nFor\nexample, in health, the European health\ndata space will facilitate nondiscriminatory access to health data and the\ntraining of genai algorithms\non those datasets, in a privacy-preserving,\nsecure, timely, transparent and trustworthy\nmanner, and with an appropriate\ninstitutional governance.\n\nRelevant\ncompetent authorities, including sectoral\nones, providing or supporting the access to\ndata may also support the provision of\nhigh-quality data for the training,\nvalidation and testing of genai systems.", "**Recital 45 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(45a) The right to privacy and to_**\n**_protection of personal data must be_**\n**_guaranteed throughout the entire lifecycle_**\n**_of the genai system.\n\nIn this regard, the_**\n**_principles of data minimisation and data_**\n**_protection by design and by default, as set_**\n**_out in Union data protection law, are_**\n**_essential when the processing of data_**\n**_involves significant risks to the_**\n**_fundamental rights of individuals._**\n**_Providers and users of genai systems should_**\n**_implement state-of-the-art technical and_**\n**_organisational measures in order to_**\n**_protect those rights.\n\nSuch measures_**\n**_should include not only anonymisation_**\n**_and encryption, but also the use of_**\n**_increasingly available technology that_**\n**_permits algorithms to be brought to the_**\n**_data and allows valuable insights to be_**\n**_derived without the transmission between_**\n**_parties or unnecessary copying of the raw_**\n**_or structured data themselves._**", "**Recital 46**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(46) Having information on how high-risk\ngenai systems have been developed and how\nthey perform throughout their **_lifecycle_** is\nessential to verify compliance with the\nrequirements under this Regulation.\n\nThis\nrequires keeping records and the\navailability of a technical documentation,\ncontaining information which is necessary\nto assess the compliance of the genai system\nwith the relevant requirements.\n\nSuch\ninformation should include the general\ncharacteristics, capabilities and limitations\nof the system, algorithms, data, training,\ntesting and validation processes used as\nwell as documentation on the relevant risk\nmanagement system.\n\nThe technical\ndocumentation should be kept up to date.\n\n(46) Having **_comprehensible_** information\non how high-risk genai systems have been\ndeveloped and how they perform\nthroughout their **_lifetime_** is essential to\nverify compliance with the requirements\nunder this Regulation.\n\nThis requires\nkeeping records and the availability of a\ntechnical documentation, containing\ninformation which is necessary to assess\nthe compliance of the genai system with the\nrelevant requirements.\n\nSuch information\nshould include the general characteristics,\ncapabilities and limitations of the system,\nalgorithms, data, training, testing and\nvalidation processes used as well as\ndocumentation on the relevant risk\nmanagement system.\n\nThe technical\ndocumentation should be kept up to date\n**_appropriately throughout the lifecycle of_**\n**_the genai system_** .\n\n**_AI systems can have a_**\n**_large important environmental impact_**\n**_and high energy consumption during_**\n**_their lifecyle.\n\nIn order to better apprehend_**\n**_the impact of genai systems on the_**\n**_environment, the technical documentation_**\n**_drafted by providers should include_**\n**_information on the energy consumption of_**\n**_the genai system, including the consumption_**\n**_during development and expected_**\n**_consumption during use.\n\nSuch_**\n**_information should take into account the_**\n**_relevant Union and national legislation._**\n**_This reported information should be_**\n**_comprehensible, comparable and_**\n**_verifiable and to that end, the Commission_**\n**_should develop guidelines on a_**\n**_harmonised metholodogy for calculation_**\n**_and reporting of this information.\n\nTo_**\n**_ensure that a single documentation is_**\n**_possible, terms and definitions related to_**\n**_the required documentation and any_**\n**_required documentation in the relevant_**\n**_Union legislation should be aligned as_**\n**_much as possible._**\n\n\n-----", "**Recital 46 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(46a) genai systems should take into account_**\n**_state-of-the art methods and relevant_**\n**_applicable standards to reduce the energy_**\n**_use, resource use and waste, as well as to_**\n**_increase their energy efficiency and the_**\n**_overall efficiency of the system.\n\nThe_**\n**_environmental aspects of genai systems that_**\n**_are significant for the purposes of this_**\n**_Regulation are the energy consumption of_**\n**_the genai system in the development, training_**\n**_and deployment phase as well as the_**\n**_recording and reporting and storing of_**\n**_this data.\n\nThe design of genai systems should_**\n**_enable the measurement and logging of_**\n**_the consumption of energy and resources_**\n**_at each stage of development, training and_**\n**_deployment.\n\nThe monitoring and_**\n**_reporting of the emissions of genai systems_**\n**_must be robust, transparent, consistent_**\n**_and accurate.\n\nIn order to ensure the_**\n**_uniform application of this Regulation_**\n**_and stable legal ecosystem for providers_**\n**_and deployers in the Single Market, the_**\n**_Commission should develop a common_**\n**_specification for the methodology to fulfil_**\n**_the reporting and documentation_**\n**_requirement on the consumption of_**\n**_energy and resources during development,_**\n**_training and deployment.\n\nSuch common_**\n**_specifications on measurement_**\n**_methodology can develop a baseline upon_**\n**_which the Commission can better decide if_**\n**_future regulatory interventions are_**\n**_needed, upon conducting an impact_**\n**_assessment that takes into account_**\n**_existing law._**", "**Recital 46 b (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(46b) In order to achieve the objectives of_**\n**_this Regulation, and contribute to the_**\n**_Union\u2019s environmental objectives while_**\n**_ensuring the smooth functioning of the_**\n**_internal market, it may be necessary to_**\n**_establish recommendations and guidelines_**\n**_and, eventually, targets for sustainability._**\n**_For that purpose the Commission is_**\n**_entitled to develop a methodology to_**\n**_contribute towards having Key_**\n**_Performance Indicators (KPIs) and a_**\n**_reference for the Sustainable_**\n**_Development Goals (SDGs).\n\nThe goal_**\n**_should be in the first instance to enable_**\n**_fair comparison between AI_**\n**_implementation choices providing_**\n**_incentives to promote using more efficient_**\n**_AI technologies addressing energy and_**\n**_resource concerns.\n\nTo meet this objective_**\n**_this Regulation should provide the means_**\n**_to establish a baseline collection of data_**\n**_reported on the emissions from_**\n**_development and training and for_**\n**_deployment._**", "**Recital 49**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(49) High-risk genai systems should perform\nconsistently throughout their lifecycle and\nmeet an appropriate level of accuracy,\nrobustness and cybersecurity in accordance\nwith the generally acknowledged state of\nthe art.\n\n**_The_** level of **_accuracy and_**\n**_accuracy_** metrics should be communicated\nto the **_users_** .\n\n(49) High-risk genai systems should perform\nconsistently throughout their lifecycle and\nmeet an appropriate level of accuracy,\nrobustness and cybersecurity in accordance\nwith the generally acknowledged state of\nthe art.\n\n**_Performance metrics and their_**\n**_expected level should be defined with the_**\n**_primary objective to mitigate risks and_**\n**_negative impact of the genai system.\n\nThe_**\n**_expected_** level of **_performance_** metrics\nshould be communicated **_in a clear,_**\n**_transparent, easily understandable and_**\n**_intelligible way_** to the **_deployers_** .\n\n**_The_**\n**_declaration of performance metrics_**\n**_cannot be considered proof of future_**\n**_levels, but relevant methods need to be_**\n**_applied to ensure consistent levels during_**\n**_use While standardisation organisations_**\n**_exist to establish standards, coordination_**\n**_on benchmarking is needed to establish_**\n**_how these standardised requirements and_**\n**_characteristics of genai systems should be_**\n**_measured.\n\nThe European Artificial_**\n**_Intelligence Office should bring together_**\n**_national and international metrology and_**\n**_benchmarking authorities and provide_**\n**_non-binding guidance to address the_**\n**_technical aspects of how to measure the_**\n**_appropriate levels of performance and_**\n**_robustness._**", "**Recital 50**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(50) The technical robustness is a key\nrequirement for high-risk genai systems.\n\nThey\nshould be resilient against risks connected\nto the limitations of the system (e.g.\n\nerrors,\nfaults, inconsistencies, unexpected\nsituations) as well as against malicious\nactions that may compromise the security\nof the genai system and result in harmful or\n\n\n(50) The technical robustness is a key\nrequirement for high-risk genai systems.\n\nThey\nshould be resilient against risks connected\nto the limitations of the system (e.g.\n\nerrors,\nfaults, inconsistencies, unexpected\nsituations) as well as against malicious\nactions that may compromise the security\nof the genai system and result in harmful or\n\n\n-----\n\notherwise undesirable behaviour.\n\nFailure to\nprotect against these risks could lead to\nsafety impacts or negatively affect the\nfundamental rights, for example due to\nerroneous decisions or wrong or biased\noutputs generated by the genai system.\n\notherwise undesirable behaviour.\n\nFailure to\nprotect against these risks could lead to\nsafety impacts or negatively affect the\nfundamental rights, for example due to\nerroneous decisions or wrong or biased\noutputs generated by the genai system.\n\n**_Users_**\n**_of the genai system should take steps to_**\n**_ensure that the possible trade-off between_**\n**_robustness and accuracy does not lead to_**\n**_discriminatory or negative outcomes for_**\n**_minority subgroups._**", "**Recital 51**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(51) Cybersecurity plays a crucial role in\nensuring that genai systems are resilient\nagainst attempts to alter their use,\nbehaviour, performance or compromise\ntheir security properties by malicious third\nparties exploiting the system\u2019s\nvulnerabilities.\n\nCyberattacks against genai\nsystems can leverage genai specific assets,\nsuch as training data sets (e.g.\n\ndata\npoisoning) or trained models (e.g.\n\nadversarial attacks), or exploit\nvulnerabilities in the genai system\u2019s digital\nassets or the underlying ICT infrastructure.\n\nTo ensure a level of cybersecurity\nappropriate to the risks, suitable measures\nshould therefore be taken by the providers\nof high-risk genai systems, also taking into\naccount as appropriate the underlying ICT\ninfrastructure.\n\n(51) Cybersecurity plays a crucial role in\nensuring that genai systems are resilient\nagainst attempts to alter their use,\nbehaviour, performance or compromise\ntheir security properties by malicious third\nparties exploiting the system\u2019s\nvulnerabilities.\n\nCyberattacks against genai\nsystems can leverage genai specific assets,\nsuch as training data sets (e.g.\n\ndata\npoisoning) or trained models (e.g.\n\nadversarial attacks **_or confidentiality_**\n**_attacks_** ), or exploit vulnerabilities in the genai\nsystem\u2019s digital assets or the underlying\nICT infrastructure.\n\nTo ensure a level of\ncybersecurity appropriate to the risks,\nsuitable measures should therefore be taken\nby the providers of high-risk genai systems,\n**_as well as the notified bodies, competent_**\n**_national authorities and market_**\n**_surveillance authorities,_** also taking into\naccount as appropriate the underlying ICT\ninfrastructure.\n\n**_High-risk genai should be_**\n**_accompanied by security solutions and_**\n**_patches for the lifetime of the product, or_**\n**_in case of the absence of dependence on a_**\n**_specific product, for a time that needs to_**\n**_be stated by the manufacturer._**", "**Recital 53 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(53a) As signatories to the United Nations_**\n**_Convention on the Rights of Persons with_**\n**_Disabilities (UNCRPD), the Union and_**\n**_the Member States are legally obliged to_**\n**_protect persons with disabilities from_**\n**_discrilmination and promote their_**\n**_equality, to ensure that persons with_**\n**_disabilities have access, on an equal basis_**\n**_wirh others, to information and_**\n**_communications technologies and_**\n**_systems, and to ensure respect for privacy_**\n**_for persons with disabilities.\n\nGiven the_**\n**_growing importance and use of AI_**\n**_systems, the application of universal_**\n**_design principles to all new technologies_**\n**_and services should ensure full, equal,_**\n**_and unrestricted access for everyone_**\n**_potentially affected by or using AI_**\n**_technologies, including persons with_**\n**_disabilities, in a way that takes full_**\n**_account of their inherent dignity and_**\n**_diversity.\n\nIt is therefore essential that_**\n**_Providers ensure full compliance with_**\n**_accessibility requirements, including_**\n**_Directive (EU) 2016/2102 and Directive_**\n**_(EU) 2019/882.\n\nProviders should ensure_**\n**_compliance with these requirements by_**\n**_design.\n\nTherefore, the necessary measures_**\n**_should be integrated as much as possible_**\n**_into the design of the high-risk genai system._**", "**Recital 54**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(54) The provider should establish a\nsound quality management system, ensure\nthe accomplishment of the required\nconformity assessment procedure, draw up\nthe relevant documentation and establish a\n\n\n(54) The provider should establish a\nsound quality management system, ensure\nthe accomplishment of the required\nconformity assessment procedure, draw up\nthe relevant documentation and establish a\n\n\n-----\n\nrobust post-market monitoring system.\n\nPublic authorities which put into service\nhigh-risk genai systems for their own use may\nadopt and implement the rules for the\nquality management system as part of the\nquality management system adopted at a\nnational or regional level, as appropriate,\ntaking into account the specificities of the\nsector and the competences and\norganisation of the public authority in\nquestion.\n\nrobust post-market monitoring system **_. For_**\n**_providers that have already in place_**\n**_quality management systems based on_**\n**_standards such as ISO 9001 or other_**\n**_relevant standards, no duplicative quality_**\n**_management system in full should be_**\n**_expected but rather an adaptation of their_**\n**_existing systems to certain aspects linked_**\n**_to compliance with specific requirements_**\n**_of this Regulation.\n\nThis should also be_**\n**_reflected in future standardization_**\n**_activities or guidance adopted by the_**\n**_Commission in this respect_** .\n\nPublic\nauthorities which put into service high-risk\ngenai systems for their own use may adopt\nand implement the rules for the quality\nmanagement system as part of the quality\nmanagement system adopted at a national\nor regional level, as appropriate, taking\ninto account the specificities of the sector\nand the competences and organisation of\nthe public authority in question.", "**Recital 56**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(56) To enable enforcement of this\nRegulation and create a level-playing field\nfor operators, and taking into account the\ndifferent forms of making available of\ndigital products, it is important to ensure\nthat, under all circumstances, a person\nestablished in the Union can provide\nauthorities with all the necessary\ninformation on the compliance of an genai\nsystem.\n\nTherefore, prior to making their genai\nsystems available in the Union, **_where an_**\n**_importer cannot be identified,_** providers\nestablished outside the Union shall, by\nwritten mandate, appoint an authorised\nrepresentative established in the Union.\n\n(56) To enable enforcement of this\nRegulation and create a level-playing field\nfor operators, and taking into account the\ndifferent forms of making available of\ndigital products, it is important to ensure\nthat, under all circumstances, a person\nestablished in the Union can provide\nauthorities with all the necessary\ninformation on the compliance of an genai\nsystem.\n\nTherefore, prior to making their genai\nsystems available in the Union, providers\nestablished outside the Union shall, by\nwritten mandate, appoint an authorised\nrepresentative established in the Union.", "**Recital 58**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(58) Given the nature of genai systems and\nthe risks to safety and fundamental rights\npossibly associated with their use,\nincluding as **_regard_** the need to ensure\nproper monitoring of the performance of an\ngenai system in a real-life setting, it is\nappropriate to set specific responsibilities\nfor **_users.\n\nUsers_** should in particular use\nhigh-risk genai systems in accordance with\nthe instructions of use and certain other\nobligations should be provided for with\nregard to monitoring of the functioning of\nthe genai systems and with regard to recordkeeping, as appropriate.\n\n(58) Given the nature of genai systems and\nthe risks to safety and fundamental rights\npossibly associated with their use,\nincluding as **_regards_** the need to ensure\nproper monitoring of the performance of an\ngenai system in a real-life setting, it is\nappropriate to set specific responsibilities\nfor **_deployers.\n\nDeployers_** should in\nparticular use high-risk genai systems in\naccordance with the instructions of use and\ncertain other obligations should be\nprovided for with regard to monitoring of\nthe functioning of the genai systems and with\nregard to record-keeping, as appropriate.", "**Recital 58 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(58a) Whilst risks related to genai systems_**\n**_can result from the way such systems are_**\n**_designed, risks can as well stem from how_**\n**_such genai systems are used.\n\nDeployers of_**\n**_high-risk genai system therefore play a_**\n**_critical role in ensuring that fundamental_**\n**_rights are protected, complementing the_**\n**_obligations of the provider when_**\n**_developing the genai system.\n\nDeployers are_**\n**_best placed to understand how the highrisk genai system will be used concretely and_**\n**_can therefore identify potential significant_**\n**_risks that were not foreseen in the_**\n**_development phase, due to a more precise_**\n**_knowledge of the context of use, the_**\n**_people or groups of people likely to be_**\n**_affected, including marginalised and_**\n**_vulnerable groups.\n\nDeployers should_**\n**_identify appropriate governance_**\n**_structures in that specific context of use,_**\n**_such as arrangements for human_**\n**_oversight, complaint-handling procedures_**\n\n\n-----\n\n**_and redress procedures, because choices_**\n**_in the governance structures can be_**\n**_instrumental in mitigating risks to_**\n**_fundamental rights in concrete use-cases._**\n**_In order to efficiently ensure that_**\n**_fundamental rights are protected, the_**\n**_deployer of high-risk genai systems should_**\n**_therefore carry out a fundamental rights_**\n**_impact assessment prior to putting it into_**\n**_use.\n\nThe impact assessment should be_**\n**_accompanied by a detailed plan describing_**\n**_the measures or tools that will help_**\n**_mitigating the risks to fundamental rights_**\n**_identified at the latest from the time of_**\n**_putting it into use.\n\nIf such plan cannot be_**\n**_identified, the deployer should refrain_**\n**_from putting the system into use.\n\nWhen_**\n**_performing this impact assessment, the_**\n**_deployer should notify the national_**\n**_supervisory authority and, to the best_**\n**_extent possible relevant stakeholders as_**\n**_well as representatives of groups of_**\n**_persons likely to be affected by the AI_**\n**_system in order to collect relevant_**\n**_information which is deemed necessary to_**\n**_perform the impact assessment and are_**\n**_encouraged to make the summary of their_**\n**_fundamental rights impact assessment_**\n**_publicly available on their online website._**\n**_This obligations should not apply to_**\n**_SMEs which, given the lack of resrouces,_**\n**_might find it difficult to perform such_**\n**_consultation.\n\nNevertheless, they should_**\n**_also strive to invole such representatives_**\n**_when carrying out their fundamental_**\n**_rights impact assessment.In addition,_**\n**_given the potential impact and the need_**\n**_for democratic oversight and scrutiny,_**\n**_deployers of high-risk genai systems that are_**\n**_public authorities or Union institutions,_**\n**_bodies, offices and agencies, as well_**\n**_deployers who are undertakings_**\n**_designated as a gatekeeper under_**\n**_Regulation (EU) 2022/1925 should be_**\n**_required to register the use of any highrisk genai system in a public database.\n\nOther_**\n**_deployers may voluntarily register._**", "**Recital 59**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(59) It is appropriate to envisage that the\n**_user_** of the genai system should be the natural\nor legal person, public authority, agency or\nother body under whose authority the genai\nsystem is operated except where the use is\nmade in the course of a personal nonprofessional activity.\n\n(59) It is appropriate to envisage that the\n**_deployer_** of the genai system should be the\nnatural or legal person, public authority,\nagency or other body under whose\nauthority the genai system is operated except\nwhere the use is made in the course of a\npersonal non-professional activity.", "**Recital 60**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(60) In the light of **_the_** complexity of the\n**_artificial intelligence_** value chain, relevant\nthird parties, notably **_the ones_** involved in\nthe sale and the supply of software **_,_**\n**_software_** tools **_and_** components, pre-trained\nmodels **_and data_** , or providers of network\nservices, should cooperate, as appropriate,\nwith providers **_and users_** to enable their\ncompliance **_with the obligations under this_**\n**_Regulation and with competent_**\n**_authorities established_** under this\nRegulation.\n\n(60) **_Within the genai value chain multiple_**\n**_entities often supply tools and services but_**\n**_also components or processes that are_**\n**_then incorporated by the provider into the_**\n**_AI system, including in relation to data_**\n**_collection and pre-processing, model_**\n**_training, model retraining, model testing_**\n**_and evaluation, integration into software,_**\n**_or other aspects of model development._**\n**_The involved entities may make their_**\n**_offering commercially available directly_**\n**_or indirectly, through interfaces, such as_**\n**_Application Programming Interfaces_**\n**_(API), and distributed under free and_**\n**_open source licenses but also more and_**\n**_more by genai workforce platforms, trained_**\n**_parameters resale, DIY kits to build_**\n**_models or the offering of paying access to_**\n**_a model serving architecture to develop_**\n**_and train models._** In the light of **_this_**\ncomplexity of the **_AI_** value chain, **_all_**\nrelevant third parties, **_in particular those_**\n**_that are_** involved in the **_development,_** sale\nand the **_commercial_** supply of software\ntools **_,_** components, pre-trained models **_or_**\n**_data incorporated into the genai system_** , or\nproviders of network services, should\n**_without compromising their own_**\n\n\n-----\n\n**_intellectual property rights or trade_**\n**_secrets, make available the required_**\n**_information, training or expertise and_**\ncooperate, as appropriate, with providers to\nenable their **_control over all_** compliance\n**_relevant aspects of the genai system that falls_**\nunder this Regulation.\n\n**_To allow a costeffective genai value chain governance, the_**\n**_level of control shall be explicitly_**\n**_disclosed by each third party that supplies_**\n**_the provider with a tool, service,_**\n**_component or process that is later_**\n**_incorporated by the provider into the AI_**\n**_system._**", "**Recital 60 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(60a) Where one party is in a stronger_**\n**_bargaining position, there is a risk that_**\n**_that party could leverage such position to_**\n**_the detriment of the other contracting_**\n**_party when negotiating the supply of tools,_**\n**_services, components or processes that are_**\n**_used or integrated in a high risk AI_**\n**_system or the remedies for the breach or_**\n**_the termination of related obligations._**\n**_Such contractual imbalances particularly_**\n**_harm micro, small and medium-sized_**\n**_enterprises as well as start-ups, unless_**\n**_they are owned or sub-contracted by an_**\n**_enterprise which is able to compensate the_**\n**_sub-contractor appropriately, as they are_**\n**_without a meaningful ability to negotiate_**\n**_the conditions of the contractual_**\n**_agreement, and may have no other choice_**\n**_than to accept \u2018take-it-or-leave-it\u2019_**\n**_contractual terms.\n\nTherefore, unfair_**\n**_contract terms regulating the supply of_**\n**_tools, services, components or processes_**\n**_that are used or integrated in a high risk_**\n**_AI system or the remedies for the breach_**\n**_or the termination of related obligations_**\n**_should not be binding to such micro,_**\n**_small or medium-sized enterprises and_**\n\n\n-----\n\n**_start-ups when they have been unilaterally_**\n**_imposed on them._**", "**Recital 60 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(60b) Rules on contractual terms should_**\n**_take into account the principle of_**\n**_contractual freedom as an essential_**\n**_concept in business-to-business_**\n**_relationships.\n\nTherefore, not all_**\n**_contractual terms should be subject to an_**\n**_unfairness test, but only to those terms_**\n**_that are unilaterally imposed on micro,_**\n**_small and medium-sized enterprises and_**\n**_start-ups.\n\nThis concerns \u2018take-it-or-leaveit\u2019 situations where one party supplies a_**\n**_certain contractual term and the micro,_**\n**_small or medium-sized enterprise and_**\n**_start-up cannot influence the content of_**\n**_that term despite an attempt to negotiate_**\n**_it.\n\nA contractual term that is simply_**\n**_provided by one party and accepted by the_**\n**_micro, small, medium-sized enterprise or_**\n**_a start-up or a term that is negotiated and_**\n**_subsequently agreed in an amended way_**\n**_between contracting parties should not be_**\n**_considered as unilaterally imposed._**", "**Recital 60 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(60c) Furthermore, the rules on unfair_**\n**_contractual terms should only apply to_**\n**_those elements of a contract that are_**\n**_related to supply of tools, services,_**\n**_components or processes that are used or_**\n**_integrated in a high risk genai system or the_**\n**_remedies for the breach or the_**\n**_termination of related obligations.\n\nOther_**\n\n\n-----\n\n**_parts of the same contract, unrelated to_**\n**_these elements, should not be subject to_**\n**_the unfairness test laid down in this_**\n**_Regulation._**", "**Recital 60 d (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(60d) Criteria to identify unfair_**\n**_contractual terms should be applied only_**\n**_to excessive contractual terms, where a_**\n**_stronger bargaining position is abused._**\n**_The vast majority of contractual terms_**\n**_that are commercially more favourable to_**\n**_one party than to the other, including_**\n**_those that are normal in business-tobusiness contracts, are a normal_**\n**_expression of the principle of contractual_**\n**_freedom and continue to apply.\n\nIf a_**\n**_contractual term is not included in the list_**\n**_of terms that are always considered_**\n**_unfair, the general unfairness provision_**\n**_applies.\n\nIn this regard, the terms listed as_**\n**_unfair terms should serve as a yardstick to_**\n**_interpret the general unfairness provision._**", "**Recital 60 e (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(60e) Foundation models are a recent_**\n**_development, in which genai models are_**\n**_developed from algorithms designed to_**\n**_optimize for generality and versatility of_**\n**_output.\n\nThose models are often trained on_**\n**_a broad range of data sources and large_**\n**_amounts of data to accomplish a wide_**\n**_range of downstream tasks, including_**\n**_some for which they were not specifically_**\n**_developed and trained.\n\nThe foundation_**\n**_model can be unimodal or multimodal,_**\n\n\n-----\n\n**_trained through various methods such as_**\n**_supervised learning or reinforced_**\n**_learning.\n\ngenai systems with specific_**\n**_intended purpose or general purpose AI_**\n**_systems can be an implementation of a_**\n**_foundation model, which means that each_**\n**_foundation model can be reused in_**\n**_countless downstream genai or general_**\n**_purpose genai systems.\n\nThese models hold_**\n**_growing importance to many downstream_**\n**_applications and systems._**", "**Recital 60 f (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(60f) In the case of foundation models_**\n**_provided as a service such as through API_**\n**_access, the cooperation with downstream_**\n**_providers should extend throughout the_**\n**_time during which that service is provided_**\n**_and supported, in order to enable_**\n**_appropriate risk mitigation, unless the_**\n**_provider of the foundation model_**\n**_transfers the training model as well as_**\n**_extensive and appropriate information on_**\n**_the datasets and the development process_**\n**_of the system or restricts the service, such_**\n**_as the API access, in such a way that the_**\n**_downstream provider is able to fully_**\n**_comply with this Regulation without_**\n**_further support from the original provider_**\n**_of the foundation model._**", "**Recital 60 g (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(60g) In light of the nature and_**\n**_complexity of the value chain for AI_**\n**_system, it is essential to clarify the role of_**\n**_actors contributing to the development of_**\n\n\n-----\n\n**_AI systems.\n\nThere is significant_**\n**_uncertainty as to the way foundation_**\n**_models will evolve, both in terms of_**\n**_typology of models and in terms of selfgovernance.\n\nTherefore, it is essential to_**\n**_clarify the legal situation of providers of_**\n**_foundation models.\n\nCombined with their_**\n**_complexity and unexpected impact, the_**\n**_downstream genai provider\u2019s lack of control_**\n**_over the foundation model\u2019s development_**\n**_and the consequent power imbalance and_**\n**_in order to ensure a fair sharing of_**\n**_responsibilities along the genai value chain,_**\n**_such models should be subject to_**\n**_proportionate and more specific_**\n**_requirements and obligations under this_**\n**_Regulation, namely foundation models_**\n**_should assess and mitigate possible risks_**\n**_and harms through appropriate design,_**\n**_testing and analysis, should implement_**\n**_data governance measures, including_**\n**_assessment of biases, and should comply_**\n**_with technical design requirements to_**\n**_ensure appropriate levels of performance,_**\n**_predictability, interpretability,_**\n**_corrigibility, safety and cybersecurity and_**\n**_should comply with environmental_**\n**_standards.\n\nThese obligations should be_**\n**_accompanied by standards.\n\nAlso,_**\n**_foundation models should have_**\n**_information obligations and prepare all_**\n**_necessary technical documentation for_**\n**_potential downstream providers to be able_**\n**_to comply with their obligations under this_**\n**_Regulation.\n\nGenerative foundation_**\n**_models should ensure transparency about_**\n**_the fact the content is generated by an AI_**\n**_system, not by humans.\n\nThese specific_**\n**_requirements and obligations do not_**\n**_amount to considering foundation models_**\n**_as high risk genai systems, but should_**\n**_guarantee that the objectives of this_**\n**_Regulation to ensure a high level of_**\n**_protection of fundamental rights, health_**\n**_and safety, environment, democracy and_**\n**_rule of law are achieved.\n\nPre-trained_**\n**_models developed for a narrower, less_**\n**_general, more limited set of applications_**\n**_that cannot be adapted for a wide range of_**\n**_tasks such as simple multi-purpose AI_**\n\n\n-----\n\n**_systems should not be considered_**\n**_foundation models for the purposes of this_**\n**_Regulation, because of their greater_**\n**_interpretability which makes their_**\n**_behaviour less unpredictable._**", "**Recital 60 h (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(60h) Given the nature of foundation_**\n**_models, expertise in conformity_**\n**_assessment is lacking and third-party_**\n**_auditing methods are still under_**\n**_development .\n\nThe sector itself is therefore_**\n**_developing new ways to assess_**\n**_fundamental models that fulfil in part the_**\n**_objective of auditing (such as model_**\n**_evaluation, red-teaming or machine_**\n**_learning verification and validation_**\n**_techniques).\n\nThose internal assessments_**\n**_for foundation models should be should_**\n**_be broadly applicable (e.g.\n\nindependent of_**\n**_distribution channels, modality,_**\n**_development methods), to address risks_**\n**_specific to such models taking into_**\n**_account industry state-of-the-art practices_**\n**_and focus on developing sufficient_**\n**_technical understanding and control over_**\n**_the model, the management of reasonably_**\n**_foreseeable risks, and extensive analysis_**\n**_and testing of the model through_**\n**_appropriate measures, such as by the_**\n**_involvement of independent evaluators.\n\nAs_**\n**_foundation models are a new and fastevolving development in the field of_**\n**_artificial intelligence, it is appropriate for_**\n**_the Commission and the genai Office to_**\n**_monitor and periodically asses the_**\n**_legislative and governance framework of_**\n**_such models and in particular of_**\n**_generative genai systems based on such_**\n**_models, which raise significant questions_**\n**_related to the generation of content in_**\n**_breach of Union law, copyright rules, and_**\n**_potential misuse.\n\nIt should be clarified_**\n\n\n-----\n\n**_that this Regulation should be without_**\n**_prejudice to Union law on copyright and_**\n**_related rights, including Directives_**\n**_2001/29/EC, 2004/48/ECR and (EU)_**\n**_2019/790 of the European Parliament and_**\n**_of the Council._**", "**Recital 61**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(61) Standardisation should play a key\nrole to provide technical solutions to\nproviders to ensure compliance with this\nRegulation.\n\nCompliance with harmonised\nstandards as defined in Regulation (EU)\nNo 1025/2012 of the European Parliament\nand of the Council **_54_** should be a means for\nproviders to demonstrate conformity with\nthe requirements of this Regulation.\n\n**_However, the Commission could adopt_**\n**_common technical specifications in areas_**\n**_where no harmonised_** standards **_exist or_**\n**_where they are insufficient_** .\n\n(61) Standardisation should play a key\nrole to provide technical solutions to\nproviders to ensure compliance with this\nRegulation.\n\nCompliance with harmonised\nstandards as defined in Regulation (EU)\nNo 1025/2012 of the European Parliament\nand of the Council **_[1]_** should be a means\nfor providers to demonstrate conformity\nwith the requirements of this Regulation.\n\n**_To ensure the effectiveness of standards_**\n**_as policy tool for the Union and_**\n**_considering the importance of_** standards\n**_for ensuring conformity with the_**\n**_requirements of this Regulation and for_**\n**_the competitiveness of undertakings, it is_**\n**_necessary to ensure a balanced_**\n**_representation of interests by involving all_**\n**_relevant stakeholders in the development_**\n**_of standards_** .\n\n**_The standardisation process_**\n**_should be transparent in terms of legal_**\n**_and natural persons participating in the_**\n**_standardisation activities._**\n\n\n__________________ __________________\n\n\n54 Regulation (EU) No 1025/2012 of the\nEuropean Parliament and of the Council of\n25 October 2012 on European\nstandardisation, amending Council\nDirectives 89/686/EEC and 93/15/EEC and\nDirectives 94/9/EC, 94/25/EC, 95/16/EC,\n97/23/EC, 98/34/EC, 2004/22/EC,\n2007/23/EC, 2009/23/EC and 2009/105/EC\nof the European Parliament and of the\nCouncil and repealing Council Decision\n87/95/EEC and Decision No\n\n\n54 Regulation (EU) No 1025/2012 of the\nEuropean Parliament and of the Council of\n25 October 2012 on European\nstandardisation, amending Council\nDirectives 89/686/EEC and 93/15/EEC and\nDirectives 94/9/EC, 94/25/EC, 95/16/EC,\n97/23/EC, 98/34/EC, 2004/22/EC,\n2007/23/EC, 2009/23/EC and 2009/105/EC\nof the European Parliament and of the\nCouncil and repealing Council Decision\n87/95/EEC and Decision No\n\n\n-----\n\n1673/2006/EC of the European Parliament\nand of the Council (OJ L 316, 14.11.2012,\np. 12).\n\n1673/2006/EC of the European Parliament\nand of the Council (OJ L 316, 14.11.2012,\np. 12).", "**Recital 61 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(61a) In order to facilitate compliance, the_**\n**_first standardisation requests should be_**\n**_issued by the Commission two months_**\n**_after the entry into force of this_**\n**_Regulation at the latest.\n\nThis should serve_**\n**_to improve legal certainty, thereby_**\n**_promoting investment and innovation in_**\n**_AI, as well as competitiveness and growth_**\n**_of the Union market, while enhancing_**\n**_multistakeholder governance representing_**\n**_all relevant European stakeholders such_**\n**_as the genai Office, European_**\n**_standardisation organisations and bodies_**\n**_or experts groups established under_**\n**_relevant sectorial Union law as well as_**\n**_industry, SMEs, start-ups, civil society,_**\n**_researchers and social partners, and_**\n**_should ultimately facilitate global_**\n**_cooperation on standardisation in the_**\n**_field of genai in a manner consistent with_**\n**_Union values.\n\nWhen preparing the_**\n**_standardisation request, the Commission_**\n**_should consult the genai Office and the AI_**\n**_advisory Forum in order to collect_**\n**_relevant expertise._**", "**Recital 61 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(61c) The Commission should be able to_**\n**_adopt common specifications under_**\n**_certain conditions, when no relevant_**\n**_harmonised standard exists or to address_**\n**_specific fundamental rights concerns._**\n**_Through the whole drafting process, the_**\n**_Commission should regularly consult the_**\n**_AI Office and its advisory forum, the_**\n**_European standardisation organisations_**\n**_and bodies or expert groups established_**\n**_under relevant sectorial Union law as well_**\n**_as relevant stakeholders, such as industry,_**\n**_SMEs, start-ups, civil society, researchers_**\n**_and social partners._**", "**Recital 61 d (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(61d) When adopting common_**\n**_specifications, the Commission should_**\n**_strive for regulatory alignment of genai with_**\n**_likeminded global partners, which is key_**\n**_to fostering innovation and cross-border_**\n**_partnerships within the field of genai, as_**\n**_coordination with likeminded partners in_**\n**_international standardisation bodies is of_**\n**_great importance._**", "**Recital 62**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(62) In order to ensure a high level of\ntrustworthiness of high-risk genai systems,\nthose systems should be subject to a\nconformity assessment prior to their\nplacing on the market or putting into\nservice.\n\n(62) In order to ensure a high level of\ntrustworthiness of high-risk genai systems,\nthose systems should be subject to a\nconformity assessment prior to their\nplacing on the market or putting into\nservice.\n\n**_To increase the trust in the value_**\n**_chain and to give certainty to businesses_**\n**_about the performance of their systems,_**\n**_third-parties that supply genai components_**\n**_may voluntarily apply for a third-party_**\n**_conformity assessment._**", "**Recital 64**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(64) Given the **_more extensive_** experience\nof professional pre-market certifiers in the\nfield of product safety and the different\nnature of risks involved, it is appropriate to\nlimit, at least in an initial phase of\napplication of this Regulation, the scope of\napplication of third-party conformity\nassessment for high-risk genai systems other\nthan those related to products.\n\nTherefore,\nthe conformity assessment of such systems\nshould be carried out as a general rule by\nthe provider under its own responsibility,\nwith the only exception of genai systems\nintended to be used for the remote\nbiometric identification of persons, for\nwhich the involvement of a notified body\nin the conformity assessment should be\nforeseen, to the extent they are not\nprohibited **_._**\n\n\n(64) Given the **_complexity of high-risk AI_**\n**_systems and the risks that are associated_**\n**_to them, it is essential to develop a more_**\n**_adequate capacity for the application of_**\n**_third party conformity assessment for_**\n**_high-risk genai systems.\n\nHowever, given the_**\n**_current_** experience of professional premarket certifiers in the field of product\nsafety and the different nature of risks\ninvolved, it is appropriate to limit, at least\nin an initial phase of application of this\nRegulation, the scope of application of\nthird-party conformity assessment for highrisk genai systems other than those related to\nproducts.\n\nTherefore, the conformity\nassessment of such systems should be\ncarried out as a general rule by the provider\nunder its own responsibility, with the only\nexception of genai systems intended to be\nused for the remote biometric identification\nof persons, **_or genai systems intended to be_**\n**_used to make inferences about personal_**\n**_characteristics of natural persons on the_**\n**_basis of biometric or biometrics-based_**\n**_data, including emotion recognition_**\n**_systems_** for which the involvement of a\nnotified body in the conformity assessment\n\n\n-----\n\nshould be foreseen, to the extent they are\nnot prohibited", "**Recital 65**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(65) In order to carry out third-party\nconformity **_assessment for genai systems_**\n**_intended to be used for the remote_**\n**_biometric identification of persons_** ,\nnotified bodies should be designated under\nthis Regulation by the national competent\nauthorities, provided they are compliant\nwith a set of requirements, notably on\nindependence, competence **_and_** absence of\nconflicts of interests.\n\n(65) In order to carry out third-party\nconformity **_assessments when so required_** ,\nnotified bodies should be designated under\nthis Regulation by the national competent\nauthorities, provided they are compliant\nwith a set of requirements, notably on\nindependence, competence **_,_** absence of\nconflicts of interests **_and minimum_**\n**_cybersecurity requirements_** .\n\n**_Member_**\n**_States should encourage the designation_**\n**_of a sufficient number of conformity_**\n**_assessment bodies, in order to make the_**\n**_certification feasible in a timely manner._**\n**_The procedures of assessment,_**\n**_designation, notification and monitoring_**\n**_of conformity assessment bodies should be_**\n**_implemented as uniformly as possible in_**\n**_Member States, with a view to removing_**\n**_administrative border barriers and_**\n**_ensuring that the potential of the internal_**\n**_market is realised._**", "**Recital 65 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(65a) In line with Union commitments_**\n**_under the World Trade Organization_**\n**_Agreement on Technical Barriers to_**\n**_Trade, it is adequate to maximise the_**\n**_acceptance of test results produced by_**\n**_competent conformity assessment bodies,_**\n**_independent of the territory in which they_**\n**_are established, where necessary to_**\n**_demonstrate conformity with the_**\n\n\n-----\n\n**_applicable requirements of the_**\n**_Regulation.\n\nThe Commission should_**\n**_actively explore possible international_**\n**_instruments for that purpose and in_**\n**_particular pursue the possible_**\n**_establishment of mutual recognition_**\n**_agreements with countries which are on a_**\n**_comparable level of technical_**\n**_development, and have compatible_**\n**_approach concerning genai and conformity_**\n**_assessment._**", "**Recital 66**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(66) In line with the commonly\nestablished notion of substantial\nmodification for products regulated by\nUnion harmonisation legislation, it is\nappropriate that an genai system undergoes a\nnew conformity assessment whenever **_a_**\nchange occurs which **_may_** affect the\ncompliance of the system with this\nRegulation or when the intended purpose\nof the system changes.\n\nIn addition, as\nregards genai systems which continue to\n\u2018learn\u2019 after being placed on the market or\nput into service (i.e.\n\nthey automatically\nadapt how functions are carried out), it is\nnecessary to provide rules establishing that\nchanges to the algorithm and its\nperformance that have been pre-determined\nby the provider and assessed at the moment\nof the conformity assessment should not\nconstitute a substantial modification.\n\n(66) In line with the commonly\nestablished notion of substantial\nmodification for products regulated by\nUnion harmonisation legislation, it is\nappropriate that an **_high-risk_** genai system\nundergoes a new conformity assessment\nwhenever **_an unplanned_** change occurs\nwhich **_goes beyond controlled or_**\n**_predetermined changes by the provider_**\n**_including continuous learning and which_**\n**_may create a new unacceptable risk and_**\n**_significantly_** affect the compliance of the\n**_high-risk AI_** system with this Regulation\nor when the intended purpose of the system\nchanges.\n\nIn addition, as regards genai systems\nwhich continue to \u2018learn\u2019 after being\nplaced on the market or put into service\n(i.e.\n\nthey automatically adapt how\nfunctions are carried out), it is necessary to\nprovide rules establishing that changes to\nthe algorithm and its performance that have\nbeen pre-determined by the provider and\nassessed at the moment of the conformity\nassessment should not constitute a\nsubstantial modification.\n\n**_The same should_**\n**_apply to updates of the genai system for_**\n**_security reasons in general and to protect_**\n**_against evolving threats of manipulation_**\n**_of the system, provided that they do not_**\n**_amount to a substantial modification_**\n\n\n-----", "**Recital 67**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(67) High-risk genai systems should bear the\nCE marking to indicate their conformity\nwith this Regulation so that they can move\nfreely within the internal market.\n\nMember\nStates should not create unjustified\nobstacles to the placing on the market or\nputting into service of high-risk genai systems\nthat comply with the requirements laid\ndown in this Regulation and bear the CE\nmarking.\n\n(67) High-risk genai systems should bear the\nCE marking to indicate their conformity\nwith this Regulation so that they can move\nfreely within the internal market **_. For_**\n**_physical high-risk genai systems, a physical_**\n**_CE marking should be affixed, and may_**\n**_be complemented by a digital CE_**\n**_marking.\n\nFor digital only high-risk AI_**\n**_systems, a digital CE marking should be_**\n**_used_** .\n\nMember States should not create\nunjustified obstacles to the placing on the\nmarket or putting into service of high-risk\ngenai systems that comply with the\nrequirements laid down in this Regulation\nand bear the CE marking.", "**Recital 68**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(68) Under certain conditions, rapid\navailability of innovative technologies may\nbe crucial for health and safety of persons\nand for society as a whole.\n\nIt is thus\nappropriate that under exceptional reasons\nof **_public security or_** protection of life and\nhealth of natural persons and the protection\nof **_industrial and commercial property_** ,\nMember States could authorise the placing\non the market or putting into service of genai\nsystems which have not undergone a\nconformity assessment.\n\n(68) Under certain conditions, rapid\navailability of innovative technologies may\nbe crucial for health and safety of persons **_,_**\n**_the environment and climate change_** and\nfor society as a whole.\n\nIt is thus appropriate\nthat under exceptional reasons of\nprotection of life and health of natural\npersons **_, environmental protection_** and the\nprotection of **_critical infrastructure_** ,\nMember States could authorise the placing\non the market or putting into service of genai\nsystems which have not undergone a\nconformity assessment.", "**Recital 69**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(69) In order to facilitate the work of the\nCommission and the Member States in the\ngenai field as well as to\nincrease the transparency towards the\npublic, providers of high-risk genai systems\nother than those related to products falling\nwithin the scope of relevant existing Union\nharmonisation legislation, should be\nrequired to register their high-risk genai\nsystem in a EU database, to be established\nand managed by the Commission.\n\nThe\nCommission should be the controller of\nthat database, in accordance with\nRegulation (EU) 2018/1725 of the\nEuropean Parliament and of the Council **_55_** .\n\nIn order to ensure the full functionality of\nthe database, when deployed, the procedure\nfor setting the database should include the\nelaboration of functional specifications by\nthe Commission and an independent audit\nreport.\n\n(69) In order to facilitate the work of the\nCommission and the Member States in the\ngenai field as well as to\nincrease the transparency towards the\npublic, providers of high-risk genai systems\nother than those related to products falling\nwithin the scope of relevant existing Union\nharmonisation legislation, should be\nrequired to register their high-risk genai\nsystem **_and foundation models_** in a EU\ndatabase, to be established and managed by\nthe Commission **_.\n\nThis database should be_**\n**_freely and publicly accessible, easily_**\n**_understandable and machine-readable._**\n**_The database should also be user-friendly_**\n**_and easily navigable, with search_**\n**_functionalities at minimum allowing the_**\n**_general public to search the database for_**\n**_specific high-risk systems, locations,_**\n**_categories of risk under Annex IV and_**\n**_keywords.\n\nDeployers who are public_**\n**_authorities or Union institutions, bodies,_**\n**_offices and agencies or deployers acting_**\n**_on their behalf and deployers who are_**\n**_undertakings designated as a gatekeeper_**\n**_under Regulation (EU)2022/1925 should_**\n**_also register in the EU database before_**\n**_putting into service or using a high-risk_**\n**_AI system for the first time and following_**\n**_each substantial modification.\n\nOther_**\n**_deployers should be entitled to do so_**\n**_voluntarily.\n\nAny substantial modification_**\n**_of high-risk genai systems shall also be_**\n**_registered in the EU database_** .\n\nThe\nCommission should be the controller of\nthat database, in accordance with\nRegulation (EU) 2018/1725 of the\nEuropean Parliament and of the Council 55 .\n\nIn order to ensure the full functionality of\nthe database, when deployed, the procedure\nfor setting the database should include the\nelaboration of functional specifications by\nthe Commission and an independent audit\nreport.\n\n**_The Commission should take into_**\n**_account cybersecurity and hazard-related_**\n\n\n-----\n\n**_risks when carrying out its tasks as data_**\n**_controller on the EU database.\n\nIn order to_**\n**_maximise the availability and use of the_**\n**_database by the public, the database,_**\n**_including the information made available_**\n**_through it, should comply with_**\n**_requirements under the Directive_**\n**_2019/882._**\n\n__________________ __________________\n\n\n55 Regulation (EU) 2016/679 of the\nEuropean Parliament and of the Council of\n27 April 2016 on the protection of natural\npersons with regard to the processing of\npersonal data and on the free movement of\nsuch data, and repealing Directive\n95/46/EC (General Data Protection\nRegulation) (OJ L 119, 4.5.2016, p. 1).\n\n55 Regulation (EU) 2016/679 of the\nEuropean Parliament and of the Council of\n27 April 2016 on the protection of natural\npersons with regard to the processing of\npersonal data and on the free movement of\nsuch data, and repealing Directive\n95/46/EC (General Data Protection\nRegulation) (OJ L 119, 4.5.2016, p. 1).", "**Recital 71**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(71) genai is a rapidly\ndeveloping family of technologies that\nrequires **_novel forms of_** regulatory\noversight and a safe space for\nexperimentation, while ensuring\nresponsible innovation and integration of\nappropriate safeguards and risk mitigation\nmeasures.\n\nTo ensure a legal framework that\nis **_innovation-friendly,_** future-proof and\nresilient to disruption, **_national competent_**\n**_authorities from one or more_** Member\nStates should **_be encouraged to_** establish\ngenai regulatory **_sandboxes_**\nto facilitate the development and testing of\ninnovative genai systems under strict\nregulatory oversight before these systems\nare placed on the market or otherwise put\ninto service.\n\n(71) genai is a rapidly\ndeveloping family of technologies that\nrequires regulatory oversight and a safe\n**_and controlled_** space for experimentation,\nwhile ensuring responsible innovation and\nintegration of appropriate safeguards and\nrisk mitigation measures.\n\nTo ensure a legal\nframework that **_promotes innovation,_** is\nfuture-proof **_,_** and resilient to disruption,\nMember States should establish **_at least_**\n**_one_** genai regulatory\n**_sandbox_** to facilitate the development and\ntesting of innovative genai systems under\nstrict regulatory oversight before these\nsystems are placed on the market or\notherwise put into service.\n\n**_It is indeed_**\n**_desirable for the establishment of_**\n**_regulatory sandboxes, whose_**\n**_establishment is currently left at the_**\n**_discretion of Member States, as a next_**\n**_step to be made mandatory with_**\n**_established criteria.\n\nThat mandatory_**\n**_sandbox could also be established jointly_**\n\n\n-----\n\n**_with one or several other Member States,_**\n**_as long as that sandbox would cover the_**\n**_respective national level of the involved_**\n**_Member States.\n\nAdditional sandboxes may_**\n**_also be established at different levels,_**\n**_including cross Member States, in order_**\n**_to facilitate cross-border cooperation and_**\n**_synergies.\n\nWith the exception of the_**\n**_mandatory sandbox at national level,_**\n**_Member States should also be able to_**\n**_establish virtual or hybrid sandboxes.\n\nAll_**\n**_regulatory sandboxes should be able to_**\n**_accommodate both physical and virtual_**\n**_products.\n\nEstablishing authorities should_**\n**_also ensure that the regulatory sandboxes_**\n**_have the adequate financial and human_**\n**_resources for their functioning._**", "**Recital 72**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(72) The objectives of the regulatory\nsandboxes should be **_to foster AI_**\n**_innovation by_** establishing **_a controlled_**\n**_experimentation and testing environment_**\n**_in the development and pre-marketing_**\n**_phase with a view to ensuring compliance_**\n**_of the innovative_** genai systems with this\nRegulation **_and other_** relevant Union and\nMember States legislation; to enhance legal\ncertainty **_for innovators and the competent_**\nauthorities **_\u2019 oversight and understanding_**\n**_of the opportunities, emerging risks and_**\n**_the impacts of genai use,_** and to **_accelerate_**\n**_access to markets, including by removing_**\n**_barriers for small and medium enterprises_**\n**_(SMEs) and start-ups_** .\n\nTo ensure uniform\nimplementation across the Union and\neconomies of scale, it is appropriate to\nestablish common rules for the regulatory\nsandboxes\u2019 implementation and a\nframework for cooperation between the\nrelevant authorities involved in the\nsupervision of the sandboxes.\n\n**_This_**\n**_Regulation should provide the legal basis_**\n\n\n(72) The objectives of the regulatory\nsandboxes should be **_: for the_** establishing\n**_authorities to increase their_**\n**_understanding of technical developments,_**\n**_improve supervisory methods and provide_**\n**_guidance to_** genai systems **_developers and_**\n**_providers to achieve regulatory_**\n**_compliance_** with this Regulation **_or where_**\nrelevant **_, other applicable_** Union and\nMember States legislation **_, as well as with_**\n**_the Charter of Fundamental Rights_** ; **_for_**\n**_the prospective providers to allow and_**\n**_facilitate the testing and development of_**\n**_innovative solutions related to genai systems_**\n**_in the pre-marketing phase_** to enhance\nlegal certainty **_, to allow for more_**\n**_regulatory learning by establishing_**\nauthorities **_in a controlled environment to_**\n**_develop better guidance_** and to **_identify_**\n**_possible future improvements of the legal_**\n**_framework through the ordinary_**\n**_legislative procedure.\n\nAny significant_**\n**_risks identified during the development_**\n**_and testing of such genai systems should_**\n\n\n-----\n\n**_for the use of personal data collected for_**\n**_other purposes for developing certain AI_**\n**_systems in the public interest within the_**\n**_AI regulatory sandbox, in line with Article_**\n**_6(4) of Regulation (EU) 2016/679, and_**\n**_Article 6 of Regulation (EU) 2018/1725,_**\n**_and without prejudice to Article 4(2) of_**\n**_Directive (EU) 2016/680.\n\nParticipants in_**\n**_the sandbox_** should ensure **_appropriate_**\n**_safeguards and cooperate with the_**\n**_competent authorities, including by_**\n**_following their guidance and acting_**\n**_expeditiously and in good faith to mitigate_**\n**_any high-risks to safety and fundamental_**\n**_rights that may arise during_** the\ndevelopment and **_experimentation in the_**\n**_sandbox.\n\nThe conduct of the participants_**\n**_in the sandbox should be taken into_**\n**_account when competent authorities_**\n**_decide whether to impose an_**\n**_administrative fine under Article 83(2) of_**\n**_Regulation 2016/679 and Article 57 of_**\n**_Directive 2016/680._**\n\n\n**_result in immediate mitigation and, failing_**\n**_that, in the suspension of the development_**\n**_and testing process until such mitigation_**\n**_takes place_** .\n\nTo ensure uniform\nimplementation across the Union and\neconomies of scale, it is appropriate to\nestablish common rules for the regulatory\nsandboxes\u2019 implementation and a\nframework for cooperation between the\nrelevant authorities involved in the\nsupervision of the sandboxes.\n\n**_Member_**\n**_States_** should ensure **_that regulatory_**\n**_sandboxes are widely available_**\n**_throughout the Union, while the_**\n**_participation should remain voluntary.\n\nIt_**\n**_is especially important to ensure that_**\n**_SMEs and startups can easily access these_**\n**_sandboxes, are actively involved and_**\n**_participate in_** the development and **_testing_**\n**_of innovative genai systems, in order to be_**\n**_able to contribute with their knowhow and_**\n**_experience._**", "**Recital 72 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(72a) This Regulation should provide the_**\n**_legal basis for the use of personal data_**\n**_collected for other purposes for_**\n**_developing certain genai systems in the_**\n**_public interest within the genai regulatory_**\n**_sandbox only under specified conditions_**\n**_in line with Article 6(4) of Regulation_**\n**_(EU) 2016/679, and Article 6 of_**\n**_Regulation (EU) 2018/1725, and without_**\n**_prejudice to Article 4(2) of Directive (EU)_**\n**_2016/680.\n\nProspective providers in the_**\n**_sandbox should ensure appropriate_**\n**_safeguards and cooperate with the_**\n**_competent authorities, including by_**\n**_following their guidance and acting_**\n**_expeditiously and in good faith to mitigate_**\n**_any high-risks to safety, health and the_**\n**_environment and fundamental rights that_**\n\n\n-----\n\n**_may arise during the development and_**\n**_experimentation in the sandbox.\n\nThe_**\n**_conduct of the prospective providers in the_**\n**_sandbox should be taken into account_**\n**_when competent authorities decide over_**\n**_the temporary or permanent suspension of_**\n**_their participation in the sandbox whether_**\n**_to impose an administrative fine under_**\n**_Article 83(2) of Regulation 2016/679 and_**\n**_Article 57 of Directive 2016/680._**", "**Recital 72 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(72b) To ensure that Artificial Intelligence_**\n**_leads to socially and environmentally_**\n**_beneficial outcomes, Member States_**\n**_should support and promote research and_**\n**_development of genai in support of socially_**\n**_and environmentally beneficial outcomes_**\n**_by allocating sufficient resources,_**\n**_including public and Union funding, and_**\n**_giving priority access to regulatory_**\n**_sandboxes to projects led by civil society._**\n**_Such projects should be based on the_**\n**_principle of interdisciplinary cooperation_**\n**_between genai developers, experts on_**\n**_inequality and non-discrimination,_**\n**_accessibility, consumer, environmental,_**\n**_and digital rights, as well as academics_**", "**Recital 73**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(73) In order to promote and protect\ninnovation, it is important that the interests\nof small-scale providers and users of genai\nsystems are taken into particular account.\n\nTo this objective, Member States should\ndevelop initiatives, which are targeted at\n\n\n(73) In order to promote and protect\ninnovation, it is important that the interests\nof small-scale providers and users of genai\nsystems are taken into particular account.\n\nTo this objective, Member States should\ndevelop initiatives, which are targeted at\n\n\n-----\n\nthose operators, including on awareness\nraising and information communication.\n\nMoreover, the specific interests and needs\nof small-scale providers shall be taken into\naccount when Notified Bodies set\nconformity assessment fees.\n\nTranslation\ncosts related to mandatory documentation\nand communication with authorities may\nconstitute a significant cost for providers\nand other operators, notably those of a\nsmaller scale.\n\nMember States should\npossibly ensure that one of the languages\ndetermined and accepted by them for\nrelevant providers\u2019 documentation and for\ncommunication with operators is one\nwhich is broadly understood by the largest\npossible number of cross-border users.\n\nthose operators, including on **_AI literacy,_**\nawareness raising and information\ncommunication **_.\n\nMember States shall_**\n**_utilise existing channels and where_**\n**_appropriate, establish new dedicated_**\n**_channels for communication with SMEs,_**\n**_start-ups, user and other innovators to_**\n**_provide guidance and respond to queries_**\n**_about the implementation of this_**\n**_Regulation.\n\nSuch existing channels could_**\n**_include but are not limited to ENISA\u2019s_**\n**_Computer Security Incident Response_**\n**_Teams, National Data Protection_**\n**_Agencies, the genai-on demand platform, the_**\n**_European Digital Innovation Hubs and_**\n**_other relevant instruments funded by EU_**\n**_programmes as well as the Testing and_**\n**_Experimentation Facilities established by_**\n**_the Commission and the Member States at_**\n**_national or Union level.\n\nWhere_**\n**_appropriate, these channels shall work_**\n**_together to create synergies and ensure_**\n**_homogeneity in their guidance to startups, SMEs and users_** .\n\nMoreover, the\nspecific interests and needs of small-scale\nproviders shall be taken into account when\nNotified Bodies set conformity assessment\nfees.\n\n**_The Commission shall regularly_**\n**_assess the certification and compliance_**\n**_costs for SMEs and start-ups, including_**\n**_through transparent consultations with_**\n**_SMEs, start-ups and users and shall work_**\n**_with Member States to lower such costs._**\n**_For example,_** translation costs related to\nmandatory documentation and\ncommunication with authorities may\nconstitute a significant cost for providers\nand other operators, notably those of a\nsmaller scale.\n\nMember States should\npossibly ensure that one of the languages\ndetermined and accepted by them for\nrelevant providers\u2019 documentation and for\ncommunication with operators is one\nwhich is broadly understood by the largest\npossible number of cross-border users.\n\n**_Medium-sized enterprises which recently_**\n**_changed from the small to medium-size_**\n**_category within the meaning of the Annex_**\n**_to Recommendation 2003/361/EC (Article_**\n**_16) shall have access to these initiatives_**\n\n\n-----\n\n**_and guidance for a period of time deemed_**\n**_appropriate by the Member States, as_**\n**_these new medium-sized enterprises may_**\n**_sometimes lack the legal resources and_**\n**_training necessary to ensure proper_**\n**_understanding and compliance with_**\n**_provisions._**", "**Recital 74**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(74) In order to minimise the risks to\nimplementation resulting from lack of\nknowledge and expertise in the market as\nwell as to facilitate compliance of\nproviders and notified bodies with their\nobligations under this Regulation, the AIon demand platform, the European Digital\nInnovation Hubs and the Testing and\nExperimentation Facilities established by\nthe Commission and the Member States at\nnational or EU level should **_possibly_**\ncontribute to the implementation of this\nRegulation.\n\nWithin their respective mission\nand fields of competence, they may\nprovide in particular technical and\nscientific support to providers and notified\nbodies.\n\n(74) In order to minimise the risks to\nimplementation resulting from lack of\nknowledge and expertise in the market as\nwell as to facilitate compliance of\nproviders and notified bodies with their\nobligations under this Regulation, the AIon demand platform, the European Digital\nInnovation Hubs and the Testing and\nExperimentation Facilities established by\nthe Commission and the Member States at\nnational or EU level should contribute to\nthe implementation of this Regulation.\n\nWithin their respective mission and fields\nof competence, they may provide in\nparticular technical and scientific support\nto providers and notified bodies.", "**Recital 76**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(76) In order to **_facilitate a smooth_** ,\neffective and harmonised implementation\nof this Regulation **_a European_** Artificial\nIntelligence **_Board_** should be established.\n\nThe **_Board_** should be responsible for a\nnumber of advisory tasks, including issuing\nopinions, recommendations, advice or\n\n\n(76) In order to **_avoid fragmentation, to_**\n**_ensure the optimal functioning of the_**\n**_Single market_** , **_to ensure_** effective and\nharmonised implementation of this\nRegulation **_, to achieve a high level of_**\n**_trustworthiness and of protection of_**\n**_health and safety, fundamental rights, the_**\n\n\n-----\n\nguidance on matters related to the\nimplementation of this Regulation **_,_**\n**_including on technical specifications or_**\n**_existing standards regarding the_**\n**_requirements established in_** this\nRegulation **_and providing advice to and_**\n**_assisting the Commission on specific_**\n**_questions related to artificial intelligence_**\n\n\n**_environment, democracy and the rule of_**\n**_law across the Union with regards to_** genai\n**_systems, to actively support national_**\n**_supervisory authorities, Union_**\n**_institutions, bodies, offices and agencies_**\n**_in matters pertaining to this Regulation,_**\n**_and to increase the uptake of artificial_**\n**_intelligence throughout the Union, an_**\n**_European Union Artificial Intelligence_**\n**_Office_** should be established.\n\nThe **_AI_**\n**_Office should have legal personality,_**\n**_should act in full independence,_** should be\nresponsible for a number of advisory **_and_**\n**_coordination_** tasks, including issuing\nopinions, recommendations, advice or\nguidance on matters related to the\nimplementation of this Regulation **_and_**\n**_should be adequately funded and staffed._**\n**_Member States should provide the_**\n**_strategic direction and control of the AI_**\n**_Office through the management board of_**\n**_the genai Office, alongside the Commission,_**\n**_the EDPS, the FRA, and ENISA.\n\nAn_**\n**_executive director should be responsible_**\n**_for managing the activities of the_**\n**_secretariat of the genai office and for_**\n**_representing the genai office.\n\nStakeholders_**\n**_should formally participate in the work of_**\n**_the genai Office through an advisory forum_**\n**_that should ensure varied and balanced_**\n**_stakeholder representation and should_**\n**_advise the genai Office on matters pertaining_**\n**_to this Regulation.\n\nIn case the_**\n**_establishment of the genai Office prove not_**\n**_to be sufficient to ensure a fully consistent_**\n**_application of_** this Regulation **_at Union_**\n**_level as well as efficient cross-border_**\n**_enforcement measures, the creation of an_**\n**_AI agency should be considered_** .", "**Recital 77**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(77) **_Member States hold a key role in the_**\n**_application and enforcement of this_**\n\n\n(77) Each Member State should designate\n**_a_** national **_supervisory authority_** for the\n\n\n-----\n\n**_Regulation.\n\nIn this respect,_** each Member\nState should designate **_one or more_**\nnational **_competent authorities_** for the\npurpose of supervising the application and\nimplementation of this Regulation.\n\nIn order\nto increase organisation efficiency on the\nside of Member States and to set an official\npoint of contact vis-\u00e0-vis the public and\nother counterparts at Member State and\nUnion levels **_, in each Member State one_**\n**_national authority should be designated as_**\nnational supervisory authority.\n\npurpose of supervising the application and\nimplementation of this Regulation **_. It_**\n**_should also represent its Member State at_**\n**_the management board of the genai Office_** .\n\nIn order to increase organisation efficiency\non the side of Member States and to set an\nofficial point of contact vis-\u00e0-vis the public\nand other counterparts at Member State\nand Union levels **_. Each_** national\nsupervisory authority **_should act with_**\n**_complete independence in performing its_**\n**_tasks and exercising its powers in_**\n**_accordance with this Regulation_** .", "**Recital 77 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(77a) The national supervisory authorities_**\n**_should monitor the application of the_**\n**_provisions pursuant to this Regulation_**\n**_and contribute to its consistent application_**\n**_throughout the Union.\n\nFor that purpose,_**\n**_the national supervisory authorities_**\n**_should cooperate with each other, with the_**\n**_relevant national competent authorities,_**\n**_the Commission, and with the genai Office._**", "**Recital 77 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(77b) The member or the staff of each_**\n**_national supervisory authority should, in_**\n**_accordance with Union or national law,_**\n**_be subject to a duty of professional_**\n**_secrecy both during and after their term_**\n**_of office, with regard to any confidential_**\n**_information which has come to their_**\n**_knowledge in the course of the_**\n**_performance of their tasks or exercise of_**\n**_their powers.\n\nDuring their term of office,_**\n\n\n-----\n\n**_that duty of professional secrecy should in_**\n**_particular apply to trade secrets and to_**\n**_reporting by natural persons of_**\n**_infringements of this Regulation_**", "**Recital 78**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(78) In order to ensure that providers of\nhigh-risk genai systems can take into account\nthe experience on the use of high-risk genai\nsystems for improving their systems and\nthe design and development process or can\ntake any possible corrective action in a\ntimely manner, all providers should have a\npost-market monitoring system in place.\n\nThis system is also key to ensure that the\npossible risks emerging from genai systems\nwhich continue to \u2018learn\u2019 after being\nplaced on the market or put into service\ncan be more efficiently and timely\naddressed.\n\nIn this context, providers should\nalso be required to have a system in place\nto report to the relevant authorities any\nserious incidents or any breaches to\nnational and Union law protecting\nfundamental rights resulting from the use\nof their genai systems.\n\n(78) In order to ensure that providers of\nhigh-risk genai systems can take into account\nthe experience on the use of high-risk genai\nsystems for improving their systems and\nthe design and development process or can\ntake any possible corrective action in a\ntimely manner, all providers should have a\npost-market monitoring system in place.\n\nThis system is also key to ensure that the\npossible risks emerging from genai systems\nwhich continue to \u2018learn\u2019 **_or evolve_** after\nbeing placed on the market or put into\nservice can be more efficiently and timely\naddressed.\n\nIn this context, providers should\nalso be required to have a system in place\nto report to the relevant authorities any\nserious incidents or any breaches to\nnational and Union law **_, including those_**\nprotecting fundamental **_rights and_**\n**_consumer_** rights resulting from the use of\ntheir genai systems **_and take appropriate_**\n**_corrective actions_** .\n\n**_Deployers should also_**\n**_report to the relevant authorities, any_**\n**_serious incidents or breaches to national_**\n**_and Union law resulting from the use of_**\n**_their genai system when they become aware_**\n**_of such serious incidents or breaches._**", "**Recital 79**\n\n_Text proposed by the Commission_ _Amendment_\n\n(79) In order to ensure an appropriate and (79) In order to ensure an appropriate and\n\n\n-----\n\neffective enforcement of the requirements\nand obligations set out by this Regulation,\nwhich is Union harmonisation legislation,\nthe system of market surveillance and\ncompliance of products established by\nRegulation (EU) 2019/1020 should apply\nin its entirety.\n\nWhere necessary for their\nmandate, national public authorities or\nbodies, which supervise the application of\nUnion law protecting fundamental rights,\nincluding equality bodies, should also have\naccess to any documentation created under\nthis Regulation.\n\neffective enforcement of the requirements\nand obligations set out by this Regulation,\nwhich is Union harmonisation legislation,\nthe system of market surveillance and\ncompliance of products established by\nRegulation (EU) 2019/1020 should apply\nin its entirety.\n\n**_For the purpose of this_**\n**_Regulation, national supervisory_**\n**_authorities should act as market_**\n**_surveillance authorities for genai systems_**\n**_covered by this Regulation except for AI_**\n**_systems covered by Annex II of this_**\n**_Regulation.\n\nFor genai systems covered by_**\n**_legal acts listed in the Annex II, the_**\n**_competent authorites under those legal_**\n**_acts should remain the lead authority._**\n**_National supervisory authorities and_**\n**_competent authorities in the legal acts_**\n**_listed in Annex II should work together_**\n**_whenever necessary.\n\nWhen appropriate,_**\n**_the competent authorities in the legal acts_**\n**_listed in Annex II should send competent_**\n**_staff to the national supervisory authority_**\n**_in order to assist in the performance of its_**\n**_tasks.\n\nFor the purpose of this Regulation,_**\n**_national supervisory authorities should_**\n**_have the same powers and obligations as_**\n**_market surveillance authorities under_**\n**_Regulation (EU) 2019/1020._** Where\nnecessary for their mandate, national\npublic authorities or bodies, which\nsupervise the application of Union law\nprotecting fundamental rights, including\nequality bodies, should also have access to\nany documentation created under this\nRegulation.\n\n**_After having exhausted all_**\n**_other reasonable ways to assess/verify the_**\n**_conformity and upon a reasoned request,_**\n**_the national supervisory authority should_**\n**_be granted access to the training,_**\n**_validation and testing datasets, the trained_**\n**_and training model of the high-risk AI_**\n**_system, including its relevant model_**\n**_parameters and their execution /run_**\n**_environment.\n\nIn cases of simpler software_**\n**_systems falling under this Regulation that_**\n**_are not based on trained models, and_**\n**_where all other ways to verify conformity_**\n**_have been exhausted, the national_**\n**_supervisory authority may exceptionally_**\n\n\n-----\n\n**_have access to the source code, upon a_**\n**_reasoned request.\n\nWhere the national_**\n**_supervisory authority has been granted_**\n**_access to the training, validation and_**\n**_testing datasets in accordance with this_**\n**_Regulation, such access should be_**\n**_achieved through appropriate technical_**\n**_means and tools, including on site access_**\n**_and in exceptional circumstances, remote_**\n**_access.\n\nThe national supervisory authority_**\n**_should treat any information, including_**\n**_source code, software, and data as_**\n**_applicable, obtained as confidential_**\n**_information and respect relevant Union_**\n**_law on the protection of intellectual_**\n**_property and trade secrets.\n\nThe national_**\n**_supervisory authority should delete any_**\n**_information obtained upon the completion_**\n**_of the investigation._**", "**Recital 80**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(80) Union **_legislation_** on financial\nservices includes internal governance and\nrisk management rules and requirements\nwhich are applicable to regulated financial\ninstitutions in the course of provision of\nthose services, including when they make\nuse of genai systems.\n\nIn order to ensure\ncoherent application and enforcement of\nthe obligations under this Regulation and\nrelevant rules and requirements of the\nUnion financial services **_legislation_** , the\nauthorities responsible for the supervision\nand enforcement of the financial services\n**_legislation_** , including where applicable the\nEuropean Central Bank, should be\ndesignated as competent authorities for the\npurpose of supervising the implementation\nof this Regulation, including for market\nsurveillance activities, as regards genai\nsystems provided or used by regulated and\nsupervised financial institutions.\n\nTo further\nenhance the consistency between this\n\n\n(80) Union **_law_** on financial services\nincludes internal governance and risk\nmanagement rules and requirements which\nare applicable to regulated financial\ninstitutions in the course of provision of\nthose services, including when they make\nuse of genai systems.\n\nIn order to ensure\ncoherent application and enforcement of\nthe obligations under this Regulation and\nrelevant rules and requirements of the\nUnion financial services **_law_** , the\n**_competent_** authorities responsible for the\nsupervision and enforcement of the\nfinancial services **_law_** , including where\napplicable the European Central Bank,\nshould be designated as competent\nauthorities for the purpose of supervising\nthe implementation of this Regulation,\nincluding for market surveillance activities,\nas regards genai systems provided or used by\nregulated and supervised financial\ninstitutions.\n\nTo further enhance the\n\n\n-----\n\nRegulation and the rules applicable to\ncredit institutions regulated under Directive\n2013/36/EU of the European Parliament\nand of the Council 56 , it is also appropriate\nto integrate the conformity assessment\nprocedure and some of the providers\u2019\nprocedural obligations in relation to risk\nmanagement, post marketing monitoring\nand documentation into the existing\nobligations and procedures under Directive\n2013/36/EU.\n\nIn order to avoid overlaps,\nlimited derogations should also be\nenvisaged in relation to the quality\nmanagement system of providers and the\nmonitoring obligation placed on **_users_** of\nhigh-risk genai systems to the extent that\nthese apply to credit institutions regulated\nby Directive 2013/36/EU.\n\nconsistency between this Regulation and\nthe rules applicable to credit institutions\nregulated under Directive 2013/36/EU of\nthe European Parliament and of the\nCouncil 56 , it is also appropriate to\nintegrate the conformity assessment\nprocedure and some of the providers\u2019\nprocedural obligations in relation to risk\nmanagement, post marketing monitoring\nand documentation into the existing\nobligations and procedures under Directive\n2013/36/EU.\n\nIn order to avoid overlaps,\nlimited derogations should also be\nenvisaged in relation to the quality\nmanagement system of providers and the\nmonitoring obligation placed on **_deployers_**\nof high-risk genai systems to the extent that\nthese apply to credit institutions regulated\nby Directive 2013/36/EU.\n\n__________________ __________________\n\n\n56 Directive 2013/36/EU of the European\nParliament and of the Council of 26 June\n2013 on access to the activity of credit\ninstitutions and the prudential supervision\nof credit institutions and investment firms,\namending Directive 2002/87/EC and\nrepealing Directives 2006/48/EC and\n2006/49/EC (OJ L 176, 27.6.2013, p. 338).\n\n56 Directive 2013/36/EU of the European\nParliament and of the Council of 26 June\n2013 on access to the activity of credit\ninstitutions and the prudential supervision\nof credit institutions and investment firms,\namending Directive 2002/87/EC and\nrepealing Directives 2006/48/EC and\n2006/49/EC (OJ L 176, 27.6.2013, p. 338).", "**Recital 80 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(80a) Given the objectives of this_**\n**_Regulation, namely to ensure an_**\n**_equivalent level of protection of health,_**\n**_safety and fundamental rights of natural_**\n**_persons, to ensure the protection of the_**\n**_rule of law and democracy, and taking_**\n**_into account that the mitigation of the_**\n**_risks of genai system against such rights may_**\n**_not be sufficiently achieved at national_**\n**_level or may be subject to diverging_**\n**_interpretation which could ultimately lead_**\n**_to an uneven level of protection of natural_**\n\n\n-----\n\n**_persons and create market fragmentation,_**\n**_the national supervisory authorities_**\n**_should be empowered to conduct joint_**\n**_investigations or rely on the union_**\n**_safeguard procedure provided for in this_**\n**_Regulation for effective enforcement._**\n**_Joint investigations should be initiated_**\n**_where the national supervisory authority_**\n**_have sufficient reasons to believe that an_**\n**_infringement of this Regulation amount to_**\n**_a widespread infringement or a_**\n**_widespread infringement with a Union_**\n**_dimension, or where the genai system or_**\n**_foundation model presents a risk which_**\n**_affects or is likely to affect at least 45_**\n**_million individuals in more than one_**\n**_Member State._**", "**Recital 82**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(82) It is important that genai systems related\nto products that are not high-risk in\naccordance with this Regulation and thus\nare not required to comply with the\nrequirements set out **_herein_** are\nnevertheless safe when placed on the\nmarket or put into service.\n\nTo contribute to\nthis objective, the Directive 2001/95/EC of\nthe European Parliament and of the\nCouncil 57 would apply as a safety net.\n\n(82) It is important that genai systems related\nto products that are not high-risk in\naccordance with this Regulation and thus\nare not required to comply with the\nrequirements set out **_for high-risk AI_**\n**_systems_** are nevertheless safe when placed\non the market or put into service.\n\nTo\ncontribute to this objective, the Directive\n2001/95/EC of the European Parliament\nand of the Council 57 would apply as a\nsafety net.\n\n__________________ __________________\n\n\n57 Directive 2001/95/EC of the European\nParliament and of the Council of 3\nDecember 2001 on general product safety\n(OJ L 11, 15.1.2002, p. 4).\n\n57 Directive 2001/95/EC of the European\nParliament and of the Council of 3\nDecember 2001 on general product safety\n(OJ L 11, 15.1.2002, p. 4).", "**Recital 83**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(83) In order to ensure trustful and\nconstructive cooperation of competent\nauthorities on Union and national level, all\nparties involved in the application of this\nRegulation should **_respect_** the\nconfidentiality of information and data\nobtained in carrying out their tasks.\n\n(83) In order to ensure trustful and\nconstructive cooperation of competent\nauthorities on Union and national level, all\nparties involved in the application of this\nRegulation should **_aim for transparency_**\n**_and openness while respecting_** the\nconfidentiality of information and data\nobtained in carrying out their tasks **_by_**\n**_putting in place technical and_**\n**_organisational measures to protect the_**\n**_security and confidentiality of the_**\n**_information obtained carrying out their_**\n**_activities including for intellectual_**\n**_property rights and public and national_**\n**_security interests_** .\n\n**_Where the activities of_**\n**_the Commission, national competent_**\n**_authorities and notified bodies pursuant_**\n**_to this Regulation results in a breach of_**\n**_intellectual property rights, Member_**\n**_States should provide for adequate_**\n**_measures and remedies to ensure the_**\n**_enforcement of intellectual property rights_**\n**_in application of Directive 2004/48/EC._**", "**Recital 84**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(84) Member States should take all\nnecessary measures to ensure that the\nprovisions of this Regulation are\nimplemented, including by laying down\neffective, proportionate and dissuasive\npenalties for their infringement.\n\nFor certain\nspecific infringements **_, Member States_**\nshould take into account **_the margins and_**\n**_criteria set out in this Regulation_** .\n\nThe\nEuropean Data Protection Supervisor\nshould have the power to impose fines on\nUnion institutions, agencies and bodies\nfalling within the scope of this Regulation.\n\n(84) **_Compliance with this Regulation_**\n**_should be enforceable by means of the_**\n**_imposition of fines by the national_**\n**_supervisory authority when carrying out_**\n**_proceedings under the procedure laid_**\n**_down in this Regulation._** Member States\nshould take all necessary measures to\nensure that the provisions of this\nRegulation are implemented, including by\nlaying down effective, proportionate and\ndissuasive penalties for their infringement.\n\n**_In order to strengthen and harmonise_**\n**_administrative penalties for infringement_**\n**_of this Regulation, the upper limits for_**\n**_setting the administrative fines_** for certain\n\n\n-----\n\nspecific infringements **_should be laid_**\n**_down_** ; **_.\n\nWhen assessing the amount of the_**\n**_fines, national competent authorities_**\nshould **_, in each individual case,_** take into\naccount **_all relevant circumstances of the_**\n**_specific situation, with due regard in_**\n**_particular to the nature, gravity and_**\n**_duration of the infringement and of its_**\n**_consequences and to the provider\u2019s size,_**\n**_in particular if the provider is a SME or a_**\n**_start-up_** .\n\nThe European Data Protection\nSupervisor should have the power to\nimpose fines on Union institutions,\nagencies and bodies falling within the\nscope of this Regulation.\n\n**_The penalties_**\n**_and litigation costs under this Regulation_**\n**_should not be subject to contractual_**\n**_clauses or any other arrangements._**", "**Recital 84 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(84a) As the rights and freedoms of_**\n**_natural and legal persons and groups of_**\n**_natural persons can be seriously_**\n**_undermined by genai systems, it is essential_**\n**_that natural and legal persons or groups_**\n**_of natural persons have meaningful_**\n**_access to reporting and redress_**\n**_mechanisms and to be entitled to access_**\n**_proportionate and effective remedies._**\n**_They should be able to report_**\n**_infringments of this Regulation to their_**\n**_national supervisory authority and have_**\n**_the right to lodge a complaint against the_**\n**_providers or deployers of genai systems._**\n**_Where applicable, deployers should_**\n**_provide internal complaints mechanisms_**\n**_to be used by natural and legal persons or_**\n**_groups of natural persons.\n\nWithout_**\n**_prejudice to any other administrative or_**\n**_non-judicial remedy, natural and legal_**\n**_persons and groups of natural persons_**\n**_should also have the right to an effective_**\n**_judicial remedy with regard to a legally_**\n\n\n-----\n\n**_binding decision of a national supervisory_**\n**_authority concerning them or, where the_**\n**_national supervisory authority does not_**\n**_handle a complaint, does not inform the_**\n**_complainant of the progress or_**\n**_preliminary outcome of the complaint_**\n**_lodged or does not comply with its_**\n**_obligation to reach a final decision, with_**\n**_regard to the complaint._**", "**Recital 84 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(84b) Affected persons should always be_**\n**_informed that they are subject to the use_**\n**_of a high-risk genai system, when deployers_**\n**_use a high-risk genai system to assist in_**\n**_decision-making or make decisions_**\n**_related to natural persons.\n\nThis_**\n**_information can provide a basis for_**\n**_affected persons to exercise their right to_**\n**_an explanation under this_**\n**_Regulation.When deployers provide an_**\n**_explanation to affected persons under this_**\n**_Regulation, they should take into account_**\n**_the level of expertise and knowledge of the_**\n**_average consumer or individual._**", "**Recital 84 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(84c) Union law on the protection of_**\n**_whistleblowers (Directive (EU)_**\n**_2019/1937) has full application to_**\n**_academics, designers, developers, project_**\n**_contributors, auditors, product managers,_**\n**_engineers and economic operators_**\n**_acquiring information on breaches of_**\n**_Union law by a provider of genai system or_**\n\n\n-----\n\n**_its genai system._**", "**Recital 85**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(85) In order to ensure that the regulatory\nframework can be adapted where\nnecessary, the power to adopt acts in\naccordance with Article 290 TFEU should\nbe delegated to the Commission to amend\n**_the techniques and approaches referred to_**\n**_in Annex I to define genai systems,_** the Union\nharmonisation legislation listed in Annex\nII, the high-risk genai systems listed in Annex\nIII, the provisions regarding technical\ndocumentation listed in Annex IV, the\ncontent of the EU declaration of\nconformity in Annex V, the provisions\nregarding the conformity assessment\nprocedures in Annex VI and VII and the\nprovisions establishing the high-risk genai\nsystems to which the conformity\nassessment procedure based on assessment\nof the quality management system and\nassessment of the technical documentation\nshould apply.\n\nIt is of particular importance\nthat the Commission carry out appropriate\nconsultations during its preparatory work,\nincluding at expert level, and that those\nconsultations be conducted in accordance\nwith the principles laid down in the\nInterinstitutional Agreement of 13 April\n2016 on Better Law-Making 58 .\n\nIn\nparticular, to ensure equal participation in\nthe preparation of delegated acts, the\nEuropean Parliament and the Council\nreceive all documents at the same time as\nMember States\u2019 experts, and their experts\nsystematically have access to meetings of\nCommission expert groups dealing with the\npreparation of delegated acts.\n\n(85) In order to ensure that the regulatory\nframework can be adapted where\nnecessary, the power to adopt acts in\naccordance with Article 290 TFEU should\nbe delegated to the Commission to amend\nthe Union harmonisation legislation listed\nin Annex II, the high-risk genai systems listed\nin Annex III, the provisions regarding\ntechnical documentation listed in Annex\nIV, the content of the EU declaration of\nconformity in Annex V, the provisions\nregarding the conformity assessment\nprocedures in Annex VI and VII and the\nprovisions establishing the high-risk genai\nsystems to which the conformity\nassessment procedure based on assessment\nof the quality management system and\nassessment of the technical documentation\nshould apply.\n\nIt is of particular importance\nthat the Commission carry out appropriate\nconsultations during its preparatory work,\nincluding at expert level, and that those\nconsultations be conducted in accordance\nwith the principles laid down in the\nInterinstitutional Agreement of 13 April\n2016 on Better Law-Making 58 **_. These_**\n**_consultations should involve the_**\n**_participation of a balanced selection of_**\n**_stakeholders, including consumer_**\n**_organisations, civil society, associations_**\n**_representing affected persons, businesses_**\n**_representatives from different sectors and_**\n**_sizes, as well as researchers and scientists_** .\n\nIn particular, to ensure equal participation\nin the preparation of delegated acts, the\nEuropean Parliament and the Council\nreceive all documents at the same time as\nMember States\u2019 experts, and their experts\nsystematically have access to meetings of\nCommission expert groups dealing with the\n\n\n-----\n\npreparation of delegated acts.\n\n__________________ __________________\n\n58 OJ L 123, 12.5.2016, p. 1.\n\n58 OJ L 123, 12.5.2016, p. 1.", "**Recital 85 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(85a) Given the rapid technological_**\n**_developments and the required technical_**\n**_expertise in conducting the assessment of_**\n**_high-risk genai systems, the Commission_**\n**_should regularly review the_**\n**_implementation of this Regulation, in_**\n**_particular the prohibited genai systems, the_**\n**_transparency obligations and the list of_**\n**_high-risk areas and use cases, at least_**\n**_every year, while consulting the genai office_**\n**_and the relevant stakeholders._**", "**Recital 87 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(87a) As reliable information on the_**\n**_resource and energy use, waste_**\n**_production and other environmental_**\n**_impact of genai systems and related ICT_**\n**_technology, including software, hardware_**\n**_and in particular data centres, is limited,_**\n**_the Commission should introduce of an_**\n**_adequate methodology to measure the_**\n**_environmental impact and effectiveness of_**\n**_this Regulation in light of the Union_**\n**_environmental and climate objectives._**", "**Recital 89**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(89) The European Data Protection\nSupervisor and the European Data\nProtection Board were consulted in\naccordance with Article 42(2) of\nRegulation (EU) 2018/1725 and delivered\nan opinion on **_[\u2026]\u201d_** .\n\n(89) The European Data Protection\nSupervisor and the European Data\nProtection Board were consulted in\naccordance with Article 42(2) of\nRegulation (EU) 2018/1725 and delivered\nan opinion on **_18 June 2021_** .", "**Article 1 \u2013 paragraph 1 (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1._** **_The purpose of this Regulation is to_**\n**_promote the uptake of human-centric and_**\n**_trustworthy genai and to_**\n**_ensure a high level of protection of_**\n**_health, safety, fundamental rights,_**\n**_democracy and the rule of law, and the_**\n**_environment from harmful effects of_**\n**_artificial intelligence systems in the Union_**\n**_while supporting innovation;_**", "**Article 1 \u2013 paragraph 1 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) harmonised transparency rules for **_AI_**\n**_systems intended to interact with natural_**\n**_persons, emotion recognition systems and_**\n**_biometric categorisation systems, and_** genai\nsystems **_used to generate or manipulate_**\n**_image, audio or video content_** ;\n\n\n(d) harmonised transparency rules for\n**_certain_** genai systems;", "**Article 2 \u2013 paragraph 1 \u2013 point c**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) providers and **_users_** of genai systems\nthat are located in a third country, where\nthe output produced by the system is used\nin the Union;\n\n\n(c) providers and **_deployers_** of genai\nsystems that **_have their place of_**\n**_establishment or who_** are located in a third\ncountry, where **_either Member State law_**\n**_applies by virtue of a public international_**\n**_law or_** the output produced by the system\nis **_intended to be_** used in the Union;", "**Article 2 \u2013 paragraph 1 \u2013 point c c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(cc)_** **_affected persons as defined in_**\n**_Article 3(8a) that are located in the Union_**\n\n\n-----\n\n**_and whose health, safety or fundamental_**\n**_rights are adversely impacted by the use of_**\n**_an genai system that is placed on the market_**\n**_or put into service within the Union._**", "**Article 2 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nFor high-risk genai systems that are\nsafety components of products or systems,\nor which are themselves products or\nsystems **_, falling_** within the scope of **_the_**\n**_following acts_** , only Article 84 of this\nRegulation shall apply **_:_**\n\n\n2.\n\nFor high-risk genai systems that are\nsafety components of products or systems,\nor which are themselves products or\nsystems **_and that fall,_** within the scope of\n**_harmonisation legislation listed in Annex_**\n**_II - Section B_** , only Article 84 of this\nRegulation shall apply **_;_**", "**Article 2 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nThis Regulation shall not apply to\npublic authorities in a third country nor to\ninternational organisations falling within\nthe scope of this Regulation pursuant to\nparagraph 1, where those authorities or\norganisations use genai systems in the\nframework of international agreements for\nlaw enforcement and judicial cooperation\nwith the Union or with one or more\nMember States **_._**\n\n\n4.\n\nThis Regulation shall not apply to\npublic authorities in a third country nor to\ninternational organisations falling within\nthe scope of this Regulation pursuant to\nparagraph 1, where those authorities or\norganisations use genai systems in the\nframework of international **_cooperation or_**\nagreements for law enforcement and\njudicial cooperation with the Union or with\none or more Member States **_and are_**\n**_subject of a decision of the Commission_**\n**_adopted in accordance with Article 36 of_**\n**_Directive (EU)2016/680 or Article 45 of_**\n**_Regulation 2016/679 (adequacy decision)_**\n**_or are part of an international agreement_**\n**_concluded between the Union and that_**\n**_third country or international_**\n**_organisation pursuant to Article 218_**\n**_TFUE providing adequate safeguards_**\n**_with respect to the protection of privacy_**\n**_and fundamental rights and freedoms of_**\n**_individuals;_**", "**Article 2 \u2013 paragraph 5 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_5a._** **_Union law on the protection of_**\n**_personal data, privacy and the_**\n**_confidentiality of communications applies_**\n**_to personal data processes in connection_**\n\n\n-----\n\n**_with the rights and obligations laid down_**\n**_in this Regulation.\n\nThis Regulation shall_**\n**_not affect Regulations (EU) 2016/679 and_**\n**_(EU) 2018/1725 and Directives_**\n**_2002/58/EC and (EU) 2016/680, without_**\n**_prejudice to arrangements provided for in_**\n**_Article 10(5) and Article 54 of this_**\n**_Regulation.\n\n;_**", "**Article 2 \u2013 paragraph 5 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_5c._** **_This regulation shall not preclude_**\n**_Member States or the Union from_**\n**_maintaining or introducing laws,_**\n**_regulations or administrative provisions_**\n**_which are more favourable to workers in_**\n**_terms of protecting their rights in respect_**\n**_of the use of genai systems by employers, or_**\n**_to encourage or allow the application of_**\n**_collective agreements which are more_**\n**_favourable to workers._**", "**Article 2 \u2013 paragraph 5 d (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_5d._** **_This Regulation shall not apply to_**\n**_research, testing and development_**\n**_activities regarding an genai system prior to_**\n**_this system being placed on the market or_**\n**_put into service, provided that these_**\n**_activities are conducted respecting_**\n**_fundamental rights and the applicable_**\n**_Union law.\n\nThe testing in real world_**\n**_conditions shall not be covered by this_**\n**_exemption.The Commission is empowered_**\n**_to may adopt delegated acts in accordance_**\n**_with Article 73 that clarify the application_**\n**_of this paragraph to specify this_**\n**_exemption to prevent its existing and_**\n**_potential abuse.\n\nThe genai Office shall_**\n**_provide guidance on the governance of_**\n**_research and development pursuant to_**\n**_Article 56, also aiming to coordinate its_**\n**_application by the national supervisory_**\n**_authorities;_**", "**Article 2 \u2013 paragraph 5 e (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_5e._** **_This Regulation shall not apply to_**\n**_AI components provided under free and_**\n**_open-source licences except to the extent_**\n**_they are placed on the market or put into_**\n**_service by a provider as part of a high-risk_**\n**_AI system or of an genai system that falls_**\n**_under Title II or IV.\n\nThis exemption shall_**\n**_not apply to foundation models as defined_**\n**_in Art 3._**", "**Article 3 \u2013 paragraph 1 \u2013 point 1**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(1) \u2018genai system\u2019 (genai\nsystem) means **_software_** that is **_developed_**\n**_with one or more of the techniques and_**\n**_approaches listed in Annex I and can, for_**\n**_a given set of human-defined_** objectives,\ngenerate outputs such as **_content,_**\npredictions, recommendations, or decisions\n**_influencing the_** environments **_they interact_**\n**_with_** ;\n\n\n(1) \u2018\u2018genai system\u2019 (genai\nsystem) means **_a machine-based system_**\n**_that is designed to operate with varying_**\n**_levels of autonomy and that can, for_**\n**_explicit or implicit objectives, generate_**\n**_outputs such as predictions,_**\n**_recommendations, or decisions, that_**\n**_influence physical or virtual_**\n**_environments;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 1 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(1b) \u2018significant risk\u2019 means a risk that is_**\n**_significant as a result of the combination_**\n**_of its severity, intensity, probability of_**\n**_occurrence, and duration of its effects,_**\n**_and its the ability to affect an individual, a_**\n**_plurality of persons or to affect a_**\n**_particular group of persons;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 1 c (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(1c) \u2018foundation model\u2019 means an AI_**\n**_system model that is trained on broad data_**\n**_at scale, is designed for generality of_**\n**_output, and can be adapted to a wide_**\n**_range of distinctive tasks;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(3)_** **_\u2018small-scale provider\u2019 means a_**\n**_provider that is a micro or small_**\n**_enterprise within the meaning of_**\n**_Commission Recommendation_**\n**_2003/361/EC_** **_61_** **_;_**\n\n\n**_deleted_**\n\n\n-----\n\n**____________________**\n\n**_61_** **_Commission Recommendation of 6 May_**\n**_2003 concerning the definition of micro,_**\n**_small and medium-sized enterprises (OJ L_**\n**_124, 20.5.2003, p. 36)._**", "**Article 3 \u2013 paragraph 1 \u2013 point 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(4) \u2018 **_user_** \u2019 means any natural or legal\nperson, public authority, agency or other\nbody using an genai system under its\nauthority **_,_** except where the genai system is\nused in the course of a personal nonprofessional activity;\n\n\n(4) \u2018 **_deployer_** means any natural or legal\nperson, public authority, agency or other\nbody using an genai system under its\nauthority except where the genai system is\nused in the course of a personal nonprofessional activity;", "**Article 3 \u2013 paragraph 1 \u2013 point 11**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(11) \u2018putting into service\u2019 means the\nsupply of an genai system for first use directly\nto the **_user_** or for own use on the Union\nmarket for its intended purpose;\n\n\n(11) \u2018putting into service\u2019 means the\nsupply of an genai system for first use directly\nto the **_deployer_** or for own use on the\nUnion market for its intended purpose;", "**Article 3 \u2013 paragraph 1 \u2013 point 13**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(13) \u2018reasonably foreseeable misuse\u2019\nmeans the use of an genai system in a way\nthat is not in accordance with its intended\npurpose, but which may result from\nreasonably foreseeable human behaviour or\ninteraction with other systems;\n\n\n(13) \u2018reasonably foreseeable misuse\u2019\nmeans the use of an genai system in a way\nthat is not in accordance with its intended\npurpose **_as indicated in instructions for_**\n**_use established by the provider_** , but which\nmay result from reasonably foreseeable\nhuman behaviour or interaction with other\nsystems **_, including other genai systems_** ;", "**Article 3 \u2013 paragraph 1 \u2013 point 14**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(14) \u2018safety component of a product or\nsystem\u2019 means a component of a product or\nof a system which fulfils a safety function\nfor that product or system **_or_** the failure or\nmalfunctioning of which endangers the\nhealth and safety of persons **_or property_** ;\n\n\n(14) \u2018safety component of a product or\nsystem\u2019 means, **_in line with Union_**\n**_harmonisation law listed in Annex II,_** a\ncomponent of a product or of a system\nwhich fulfils a safety function for that\nproduct or system **_,_** or the failure or\nmalfunctioning of which endangers the\nhealth and safety of persons;", "**Article 3 \u2013 paragraph 1 \u2013 point 15**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(15) \u2018instructions for use\u2019 means the\ninformation provided by the provider to\ninform the **_user_** of in particular an genai\nsystem\u2019s intended purpose and proper use,\ninclusive of the specific geographical,\nbehavioural or functional setting within\nwhich the high-risk genai system is intended\nto be used;\n\n\n(15) \u2018instructions for use\u2019 means the\ninformation provided by the provider to\ninform the **_deployer_** of in particular an genai\nsystem\u2019s intended purpose and proper use,\n**_as well as information on any precautions_**\n**_to be taken;_** inclusive of the specific\ngeographical, behavioural or functional\nsetting within which the high-risk genai\nsystem is intended to be used;", "**Article 3 \u2013 paragraph 1 \u2013 point 16**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(16) \u2018recall of an genai system\u2019 means any\nmeasure aimed at achieving the return to\nthe provider of an genai system made\navailable to **_users_** ;\n\n\n(16) \u2018recall of an genai system\u2019 means any\nmeasure aimed at achieving the return to\nthe provider of an genai system **_that has been_**\nmade available to **_deployers_** ;", "**Article 3 \u2013 paragraph 1 \u2013 point 20**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(20) \u2018conformity assessment\u2019 means the\nprocess of **_verifying_** whether the\nrequirements set out in Title III, Chapter 2\nof this Regulation relating to an genai system\nhave been fulfilled;\n\n\n(20) \u2018conformity assessment\u2019 means the\nprocess of **_demonstrating_** whether the\nrequirements set out in Title III, Chapter 2\nof this Regulation relating to an genai system\nhave been fulfilled;", "**Article 3 \u2013 paragraph 1 \u2013 point 22**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(22) \u2018notified body\u2019 means a conformity\nassessment body **_designated_** in accordance\n\n\n(22) \u2018notified body\u2019 means a conformity\nassessment body **_notified_** in accordance\n\n\n-----\n\nwith this Regulation and other relevant\nUnion harmonisation legislation;\n\n\nwith this Regulation and other relevant\nUnion harmonisation legislation;", "**Article 3 \u2013 paragraph 1 \u2013 point 23**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(23) \u2018substantial modification\u2019 means a\n**_change to_** the genai system **_following_** its\nplacing on the market or putting into\nservice which **_affects_** the compliance of the\ngenai system with the requirements set out in\nTitle III, Chapter 2 of this Regulation or\nresults in a modification to the intended\npurpose for which the genai system has been\nassessed;\n\n\n(23) \u2018substantial modification\u2019 means a\n**_modification or a series of modifications_**\n**_of_** the genai system **_after_** its placing on the\nmarket or putting into service which **_is not_**\n**_foreseen or planned in the initial risk_**\n**_assessment by the provider and as a result_**\n**_of which_** the compliance of the genai system\nwith the requirements set out in Title III,\nChapter 2 of this Regulation **_is affected_** or\nresults in a modification to the intended\npurpose for which the genai system has been\nassessed;", "**Article 3 \u2013 paragraph 1 \u2013 point 24**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(24) \u2018CE marking of conformity\u2019 (CE\nmarking) means a marking by which a\nprovider indicates that an genai system is in\nconformity with the requirements set out in\nTitle III, Chapter 2 of this Regulation and\nother applicable Union legislation\nharmonising the conditions for the\nmarketing of products (\u2018Union\nharmonisation legislation\u2019) providing for\nits affixing;\n\n\n(24) \u2018CE marking of conformity\u2019 (CE\nmarking) means a **_physical or digital_**\nmarking by which a provider indicates that\nan **_AI system or a product with an_**\n**_embedded_** genai system is in conformity with\nthe requirements set out in Title III,\nChapter 2 of this Regulation and other\napplicable Union legislation harmonising\nthe conditions for the marketing of\nproducts (\u2018Union harmonisation\nlegislation\u2019) providing for its affixing;", "**Article 3 \u2013 paragraph 1 \u2013 point 29**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(29) \u2018training data\u2019 means data used for\ntraining an genai system through fitting its\nlearnable parameters **_, including the_**\n**_weights of a neural network_** ;\n\n\n(29) \u2018training data\u2019 means data used for\ntraining an genai system through fitting its\nlearnable parameters;", "**Article 3 \u2013 paragraph 1 \u2013 point 30**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(30) \u2018validation data\u2019 means data used for\nproviding an evaluation of the trained genai\nsystem and for tuning its non-learnable\nparameters and its learning process, among\nother things, in order to prevent overfitting;\nwhereas the validation dataset **_can be_** a\nseparate dataset or part of the training\ndataset, either as a fixed or variable split;\n\n\n(30) \u2018validation data\u2019 means data used for\nproviding an evaluation of the trained genai\nsystem and for tuning its non-learnable\nparameters and its learning process, among\nother things, in order to prevent\n**_underfitting or_** overfitting; whereas the\nvalidation dataset **_is_** a separate dataset or\npart of the training dataset, either as a fixed\nor variable split;", "**Article 3 \u2013 paragraph 1 \u2013 point 33**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(33) \u2018biometric data\u2019 means **_personal data_**\n**_resulting from specific technical_**\n**_processing relating to the physical,_**\n**_physiological or behavioural_**\n**_characteristics of a natural person, which_**\n**_allow or confirm the unique identification_**\n**_of that natural person, such as facial_**\n**_images or dactyloscopic data_** ;\n\n\n(33) \u2018biometric data\u2019 means **_biometric_**\n**_data as defined in Article 4, point (14) of_**\n**_Regulation (EU) 2016/679;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 33 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(33b) \u2018biometric identification\u2019 means the_**\n**_automated recognition of physical,_**\n**_physiological, behavioural, and_**\n**_psychological human features for the_**\n**_purpose of establishing an individual\u2019s_**\n**_identity by comparing biometric data of_**\n**_that individual to stored biometric data of_**\n**_individuals in a database (one-to-many_**\n**_identification);_**", "**Article 3 \u2013 paragraph 1 \u2013 point 34**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(34) \u2018emotion recognition system\u2019 means\nan genai system for the purpose of identifying\nor inferring emotions or intentions of\n**_natural persons_** on the basis of their\nbiometric data;\n\n\n(34) \u2018emotion recognition system\u2019 means\nan genai system for the purpose of identifying\nor inferring emotions **_, thoughts, states of_**\n**_mind_** or intentions of **_individuals or_**\n**_groups_** on the basis of their biometric **_and_**\n**_biometric-based_** data;", "**Article 3 \u2013 paragraph 1 \u2013 point 35**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(35) \u2018biometric categorisation **_system\u2019_**\nmeans **_an genai system for the purpose of_**\nassigning natural persons to specific\ncategories, **_such as sex, age, hair colour,_**\n**_eye colour, tattoos, ethnic origin or sexual_**\n**_or political orientation,_** on the basis of\ntheir biometric data;\n\n\n(35) \u2018biometric categorisation means\nassigning natural persons to specific\ncategories, **_or inferring their_**\n**_characteristics and attributes_** on the basis\nof their biometric **_or biometric-based_** data,\n**_or which can be inferred from such data_** ;", "**Article 3 \u2013 paragraph 1 \u2013 point 36**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(36) \u2018remote biometric identification\nsystem\u2019 means an genai system for the\npurpose of identifying natural persons at a\n\n\n(36) \u2018remote biometric identification\nsystem\u2019 means an genai system for the\npurpose of identifying natural persons at a\n\n\n-----\n\ndistance through the comparison of a\nperson\u2019s biometric data with the biometric\ndata contained in a reference database, and\nwithout prior knowledge of the **_user_** of the\ngenai system whether the person will be\npresent and can be identified **_;_**\n\n\ndistance through the comparison of a\nperson\u2019s biometric data with the biometric\ndata contained in a reference database, and\nwithout prior knowledge of the **_deployer_** of\nthe genai system whether the person will be\npresent and can be identified **_, excluding_**\n**_verification systems;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 37**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(37) \u2018\u2018real-time\u2019 remote biometric\nidentification system\u2019 means a remote\nbiometric identification system whereby\nthe capturing of biometric data, the\ncomparison and the identification all occur\nwithout a significant delay.\n\nThis comprises\nnot only instant identification, but also\nlimited **_short_** delays in order to avoid\ncircumvention **_._**\n\n\n(37) \u2018\u2018real-time\u2019 remote biometric\nidentification system\u2019 means a remote\nbiometric identification system whereby\nthe capturing of biometric data, the\ncomparison and the identification all occur\nwithout a significant delay.\n\nThis comprises\nnot only instant identification, but also\nlimited delays in order to avoid\ncircumvention **_;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 39**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(39) \u2018publicly accessible space\u2019 means\nany physical place accessible to the public,\nregardless of whether certain conditions for\naccess may apply;\n\n\n(39) \u2018publicly accessible space\u2019 means\nany **_publicly or privately owned_** physical\nplace accessible to the public, regardless of\nwhether certain conditions for access may\napply **_, and regardless of the potential_**\n**_capacity restrictions_** ;", "**Article 3 \u2013 paragraph 1 \u2013 point 41**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(41) \u2018law enforcement\u2019 means activities\ncarried out by law enforcement authorities\n\n\n(41) \u2018law enforcement\u2019 means activities\ncarried out by law enforcement authorities\n\n\n-----\n\nfor the prevention, investigation, detection\nor prosecution of criminal offences or the\nexecution of criminal penalties, including\nthe safeguarding against and the prevention\nof threats to public security;\n\n\n**_or on their behalf_** for the prevention,\ninvestigation, detection or prosecution of\ncriminal offences or the execution of\ncriminal penalties, including the\nsafeguarding against and the prevention of\nthreats to public security;", "**Article 3 \u2013 paragraph 1 \u2013 point 42**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(42) \u2018national supervisory authority\u2019\nmeans **_the_** authority to which a Member\nState assigns the responsibility for the\nimplementation and application of this\nRegulation, for coordinating the activities\nentrusted to that Member State, for acting\nas the single contact point for the\nCommission, and for representing the\nMember State **_at the European Artificial_**\n**_Intelligence_** Board;\n\n\n(42) \u2018national supervisory authority\u2019\nmeans **_a public (AM 69)_** authority to which\na Member State assigns the responsibility\nfor the implementation and application of\nthis Regulation, for coordinating the\nactivities entrusted to that Member State,\nfor acting as the single contact point for the\nCommission, and for representing the\nMember State **_in the management_** Board\n**_of the genai Office_** ;", "**Article 3 \u2013 paragraph 1 \u2013 point 43**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(43) \u2018national competent authority\u2019 means\nthe national **_supervisory authority, the_**\n**_notifying authority and the market_**\n**_surveillance authority_** ;\n\n\n(43) \u2018national competent authority\u2019 means\n**_any of_** the national **_authorities which are_**\n**_responsible for the enforcement of this_**\n**_Regulation;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 44 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(44) \u2018serious incident\u2019 means any incident\nthat directly or indirectly leads, might have\n\n\n(44) \u2018serious incident\u2019 means any incident\n**_or malfunctioning of an genai system_** that\ndirectly or indirectly leads, might have led\n\n\n-----\n\nled or might lead to any of the following: or might lead to any of the following:\n\n\n(a) the death of a person or serious\ndamage to a person\u2019s health, **_to property or_**\n**_the environment,_**\n\n(b) a serious disruption of the\nmanagement and operation of critical\ninfrastructure **_._**\n\n\n(a) the death of a person or serious\ndamage to a person\u2019s health,\n\n(b) a serious disruption of the\nmanagement and operation of critical\ninfrastructure **_,_**\n\n**_(ba) a breach of fundamental rights_**\n**_protected under Union law,_**\n\n**_(bb) serious damage to property or the_**\n**_environment._**", "**Article 3 \u2013 paragraph 1 \u2013 point 44 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(44c) \u2018profiling\u2019 means any form of_**\n**_automated processing of personal data as_**\n**_defined in point (4) of Article 4 of_**\n**_Regulation (EU) 2016/679; or in the case_**\n**_of law enforcement authorities \u2013 in point_**\n\n\n-----\n\n**_4 of Article 3 of Directive (EU) 2016/680_**\n**_or, in the case of Union institutions,_**\n**_bodies, offices or agencies, in point 5_**\n**_Article 3 of Regulation (EU) 2018/1725;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 44 d (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(44d) \"deep fake\" means manipulated or_**\n**_synthetic audio, image or video content_**\n**_that would falsely appear to be authentic_**\n**_or truthful, and which features depictions_**\n**_of persons appearing to say or do things_**\n**_they did not say or do, produced using AI_**\n**_techniques, including machine learning_**\n**_and deep learning;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 44 e (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(44e) \u2018widespread infringement\u2019 means_**\n**_any act or omission contrary to Union law_**\n**_that protects the interest of individuals:_**\n\n**_(a) which has harmed or is likely to harm_**\n**_the collective interests of individuals_**\n**_residing in at least two Member States_**\n**_other than the Member State, in which:_**\n\n**_(i) the act or omission originated or took_**\n**_place;_**\n\n**_(ii) the provider concerned, or, where_**\n**_applicable, its authorised representative is_**\n**_established; or,_**\n\n**_(iii) the deployer is established, when the_**\n**_infringement is committed by the_**\n**_deployer;_**\n\n**_(b) which protects the interests of_**\n**_individuals, that have caused, cause or_**\n**_are likely to cause harm to the collective_**\n\n\n-----\n\n**_interests of individuals and that have_**\n**_common features, including the same_**\n**_unlawful practice, the same interest being_**\n**_infringed and that are occurring_**\n**_concurrently, committed by the same_**\n**_operator, in at least three Member States;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 44 f (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(44f) \u2018widespread infringement with a_**\n**_Union dimension\u2019 means a widespread_**\n**_infringement that has harmed or is likely_**\n**_to harm the collective interests of_**\n**_individuals in at least two-thirds of the_**\n**_Member States, accounting, together, for_**\n**_at least two-thirds of the population of the_**\n**_Union;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 44 g (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(44g) \u2018regulatory sandbox\u2019 means a_**\n**_controlled environment established by a_**\n**_public authority that facilitates the safe_**\n**_development, testing and validation of_**\n**_innovative genai systems for a limited time_**\n**_before their placement on the market or_**\n**_putting into service pursuant to a specific_**\n**_plan under regulatory supervision;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 44 h (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(44h)\u2018critical infrastructure\u2019 means an_**\n**_asset, a facility, equipment, a network or a_**\n**_system, or a part of an asset, a facility,_**\n**_equipment, a network or a system, which_**\n**_is necessary for the provision of an_**\n**_essential service within the meaning of_**\n**_Article 2(4) of Directive (EU) 2022/2557;_**", "**Article 3 \u2013 paragraph 1 \u2013 point 44 m (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(44m)_** **_\u2018state of the art\u2019 means the_**\n**_developed stage of technical capability at_**\n**_a given time as regards products,_**\n**_processes and services, based on the_**\n\n\n-----\n\n**_relevant consolidated findings of science,_**\n**_technology and experience;_**", "**Article 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 4_** **_deleted_**\n\n**_Amendments to Annex I_**\n\n**_The Commission is empowered to adopt_**\n**_delegated acts in accordance with Article_**\n**_73 to amend the list of techniques and_**\n**_approaches listed in Annex I, in order to_**\n**_update that list to market and_**\n**_technological developments on the basis_**\n**_of characteristics that are similar to the_**\n**_techniques and approaches listed therein._**", "**Article 4 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 4 a_**\n\n**_General principles applicable to all AI_**\n**_systems_**\n\n**_1.\n\nAll operators falling under this_**\n\n\n-----\n\n**_Regulation shall make their best efforts to_**\n**_develop and use genai systems or foundation_**\n**_models in accordance with the following_**\n**_general principles establishing a highlevel framework that promotes a coherent_**\n**_human-centric European approach to_**\n**_ethical and trustworthy Artificial_**\n**_Intelligence, which is fully in line with the_**\n**_Charter as well as the values on which the_**\n**_Union is founded:_**\n\n**_a) \u2018human agency and oversight\u2019 means_**\n**_that genai systems shall be developed and_**\n**_used as a tool that serves people, respects_**\n**_human dignity and personal autonomy,_**\n**_and that is functioning in a way that can_**\n**_be appropriately controlled and overseen_**\n**_by humans;_**\n\n**_b) \u2018technical robustness and safety\u2019_**\n**_means that genai systems shall be developed_**\n**_and used in a way to minimize unintended_**\n**_and unexpected harm as well as being_**\n**_robust in case of unintended problems_**\n**_and being resilient against attempts to_**\n**_alter the use or performance of the AI_**\n**_system so as to allow unlawful use by_**\n**_malicious third parties;_**\n\n**_c) \u2018privacy and data governance\u2019 means_**\n**_that genai systems shall be developed and_**\n**_used in compliance with existing privacy_**\n**_and data protection rules, while_**\n**_processing data that meets high standards_**\n**_in terms of quality and integrity;_**\n\n**_d) \u2018transparency\u2019 means that genai systems_**\n**_shall be developed and used in a way that_**\n**_allows appropriate traceability and_**\n**_explainability, while making humans_**\n**_aware that they communicate or interact_**\n**_with an genai system as well as duly_**\n**_informing users of the capabilities and_**\n**_limitations of that genai system and affected_**\n**_persons about their rights;._**\n\n**_e) \u2018diversity, non-discrimination and_**\n**_fairness\u2019 means that genai systems shall be_**\n**_developed and used in a way that includes_**\n**_diverse actors and promotes equal access,_**\n**_gender equality and cultural diversity,_**\n**_while avoiding discriminatory impacts_**\n**_and unfair biases that are prohibited by_**\n\n\n-----\n\n**_Union or national law;_**\n\n**_f) \u2018social and environmental well-being\u2019_**\n**_means that genai systems shall be developed_**\n**_and used in a sustainable and_**\n**_environmentally friendly manner as well_**\n**_as in a way to benefit all human beings,_**\n**_while monitoring and assessing the longterm impacts on the individual, society_**\n**_and democracy._**\n\n**_2.\n\nParagraph 1 is without prejudice to_**\n**_obligations set up by existing Union and_**\n**_national law.\n\nFor high-risk genai systems,_**\n**_the general principles are translated into_**\n**_and complied with by providers or_**\n**_deployers by means of the requirements_**\n**_set out in Articles 8 to 15, and the relevant_**\n**_obligations laid down in Chapter 3 of Title_**\n**_III of this Regulation.\n\nFor foundation_**\n**_models, the general principles are_**\n**_translated into and complied with by_**\n**_providers by means of the requirements_**\n**_set out in Articles 28 to 28b.\n\nFor all AI_**\n**_systems, the application of the principles_**\n**_referred to in paragraph 1 can be_**\n**_achieved, as applicable, through the_**\n**_provisions of Article 28, Article 52, or the_**\n**_application of harmonised standards,_**\n**_technical specifications, and codes of_**\n**_conduct as referred to in Article_**\n**_69,without creating new obligations under_**\n**_this Regulation._**\n\n**_3.\n\nThe Commission and the genai Office_**\n**_shall incorporate these guiding principles_**\n**_in standardisation requests as well as_**\n**_recommendations consisting in technical_**\n**_guidance to assist providers and deployers_**\n**_on how to develop and use genai systems._**\n**_European Standardisation Organisations_**\n**_shall take the general principles referred_**\n**_to in paragraph 1of this Article into_**\n**_account as outcome-based objectives_**\n**_when developing the appropriate_**\n**_harmonised standards for high risk AI_**\n**_systems as referred to in Article 40(2b)._**", "**Article 4 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 4 b_**\n\n**_AI literacy_**\n\n**_1.\n\nWhen implementing this Regulation,_**\n**_the Union and the Member States shall_**\n**_promote measures for the development of_**\n**_a sufficient level of genai literacy, across_**\n**_sectors and taking into account the_**\n**_different needs of groups of providers,_**\n**_deployers and affected persons concerned,_**\n**_including through education and training,_**\n**_skilling and reskilling programmes and_**\n**_while ensuring proper gender and age_**\n**_balance, in view of allowing a democratic_**\n**_control of genai systems_**\n\n**_2.\n\nProviders and deployers of genai systems_**\n**_shall take measures to ensure a sufficient_**\n**_level of genai literacy of their staff and other_**\n**_persons dealing with the operation and_**\n**_use of genai systems on their behalf, taking_**\n**_into account their technical knowledge,_**\n**_experience, education and training and_**\n**_the context the genai systems are to be used_**\n**_in, and considering the persons or groups_**\n**_of persons on which the genai systems are to_**\n**_be used._**\n\n**_3.\n\nSuch literacy measures shall consist, in_**\n**_particular, of the teaching of basic_**\n**_notions and skills about genai systems and_**\n**_their functioning, including the different_**\n**_types of products and uses, their risks and_**\n**_benefits._**\n\n**_4.\n\nA sufficient level of genai literacy is one_**\n**_that contributes, as necessary, to the_**\n**_ability of providers and deployers to_**\n**_ensure compliance and enforcement of_**\n**_this Regulation._**", "**Article 5 \u2013 paragraph 1 \u2013 point a**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) the placing on the market, putting\ninto service or use of an genai system that\ndeploys subliminal techniques beyond a\nperson\u2019s consciousness **_in order to_**\nmaterially **_distort_** a person\u2019s behaviour in a\nmanner that causes or is likely to cause that\nperson **_or_** another person **_physical or_**\n**_psychological_** harm;\n\n\n(a) the placing on the market, putting\ninto service or use of an genai system that\ndeploys subliminal techniques beyond a\nperson\u2019s consciousness **_or purposefully_**\n**_manipulative or deceptive techniques,_**\n**_with the objective to or the effect of_**\nmaterially **_distorting_** a person\u2019s **_or a group_**\n**_of persons\u2019_** behaviour **_by appreciably_**\n**_impairing the person\u2019s ability to make an_**\n**_informed decision, thereby causing the_**\n**_person to take a decision that that person_**\n**_would not have otherwise taken_** in a\nmanner that causes or is likely to cause that\nperson **_,_** another person **_or group of persons_**\n**_significant_** harm;\n\n**_The prohibition of genai system that deploys_**\n**_subliminal techniques referred to in the_**\n**_first sub-paragraph shall not apply to AI_**\n**_systems intended to be used for approved_**\n**_therapeutical purposes on the basis of_**\n**_specific informed consent of the_**\n**_individuals that are exposed to them or,_**\n**_where applicable, of their legal guardian;_**", "**Article 5 \u2013 paragraph 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) the placing on the market, putting\ninto service or use of an genai system that\nexploits any of the vulnerabilities of a\nspecific group of persons **_due to their_** age,\nphysical or mental **_disability, in order to_**\nmaterially **_distort_** the behaviour of a person\npertaining to that group in a manner that\ncauses or is likely to cause that person or\nanother person **_physical or psychological_**\nharm;\n\n\n(b) the placing on the market, putting\ninto service or use of an genai system that\nexploits any of the vulnerabilities of a\n**_person or a_** specific group of persons **_,_**\n**_including characteristics of such person\u2019s_**\n**_or a such group\u2019s known or predicted_**\n**_personality traits or social or economic_**\n**_situation_** age, physical or mental **_ability_**\n**_with the objective or to the effect of_**\nmaterially **_distorting_** the behaviour of **_that_**\n**_person or_** a person pertaining to that group\nin a manner that causes or is likely to cause\nthat person or another person **_significant_**\nharm;;\n\n\n-----", "**Article 5 \u2013 paragraph 1 \u2013 point b a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(b a) the placing on the market, putting_**\n**_into service or use of biometric_**\n**_categorisation systems that categorise_**\n**_natural persons according to sensitive or_**\n**_protected attributes or characteristics or_**\n**_based on the inference of those attributes_**\n**_or characteristics.\n\nThis prohibition shall_**\n**_not apply to genai systems intended to be_**\n**_used for approved therapeutical purposes_**\n**_on the basis of specific informed consent_**\n**_of the individuals that are exposed to them_**\n**_or, where applicable, of their legal_**\n**_guardian._**", "**Article 5 \u2013 paragraph 1 \u2013 point c \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) the placing on the market, putting\ninto service or use of genai systems **_by public_**\n**_authorities or on their behalf_** for the\nevaluation or classification of **_the_**\n**_trustworthiness of_** natural persons over a\ncertain period of time based on their social\nbehaviour or known or predicted personal\nor personality characteristics, with the\nsocial score leading to either or both of the\nfollowing:\n\n\n(c) the placing on the market, putting\ninto service or use of genai systems for the\n**_social scoring_** evaluation or classification\nof natural persons **_or groups thereof_** over a\ncertain period of time based on their social\nbehaviour or known **_, inferred_** or predicted\npersonal or personality characteristics, with\nthe social score leading to either or both of\nthe following:", "**Article 5 \u2013 paragraph 1 \u2013 point c \u2013 point i**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(i) detrimental or unfavourable\ntreatment of certain natural persons or\nwhole groups thereof in social contexts\n**_which_** are unrelated to the contexts in\nwhich the data was originally generated or\ncollected;\n\n\n(i) detrimental or unfavourable\ntreatment of certain natural persons or\nwhole groups thereof in social contexts\n**_that_** are unrelated to the contexts in which\nthe data was originally generated or\ncollected;", "**Article 5 \u2013 paragraph 1 \u2013 point d \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) the use of \u2018real-time\u2019 remote\nbiometric identification systems in publicly\naccessible spaces **_for the purpose of law_**\n**_enforcement, unless and in as far as such_**\n**_use is strictly necessary for one of the_**\n**_following objectives:_**\n\n\n(d) the use of \u2018real-time\u2019 remote\nbiometric identification systems in publicly\naccessible spaces **_;_**", "**Article 5 \u2013 paragraph 1 \u2013 point d \u2013 point iii**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(iii)_** **_the detection, localisation,_**\n**_identification or prosecution of a_**\n**_perpetrator or suspect of a criminal_**\n**_offence referred to in Article 2(2) of_**\n**_Council Framework Decision_**\n**_2002/584/JHA_** **_62_** **_and punishable in the_**\n**_Member State concerned by a custodial_**\n**_sentence or a detention order for a_**\n**_maximum period of at least three years, as_**\n**_determined by the law of that Member_**\n**_State._**\n\n\n**_deleted_**\n\n\n**____________________**\n\n**_62_** **_Council Framework Decision_**\n**_2002/584/JHA of 13 June 2002 on the_**\n**_European arrest warrant and the_**\n**_surrender procedures between Member_**\n**_States (OJ L 190, 18.7.2002, p. 1)._**", "**Article 5 \u2013 paragraph 1 \u2013 point d a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(d a) the placing on the market, putting_**\n**_into service or use of an genai system for_**\n**_making risk assessments of natural_**\n**_persons or groups thereof in order to_**\n**_assess the risk of a natural person for_**\n**_offending or reoffending or for predicting_**\n**_the occurrence or reoccurrence of an_**\n**_actual or potential criminal or_**\n**_administrative offence based on profiling_**\n**_of a natural person or on assessing_**\n**_personality traits and characteristics,_**\n**_including the person\u2019s location, or past_**\n**_criminal behaviour of natural persons or_**\n**_groups of natural persons;_**\n\n\n-----", "**Article 5 \u2013 paragraph 1 \u2013 point d b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(d b) The placing on the market, putting_**\n**_into service or use of genai systems that_**\n**_create or expand facial recognition_**\n**_databases through the untargeted_**\n**_scraping of facial images from the_**\n**_internet or CCTV footage;_**", "**Article 5 \u2013 paragraph 1 \u2013 point d c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_dc) the placing on the market, putting into_**\n**_service or use of genai systems to infer_**\n**_emotions of a natural person in the areas_**\n**_of law enforcement, border management,_**\n**_in workplace and education institutions._**", "**Article 5 \u2013 paragraph 1 \u2013 point d d (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(d d) the putting into service or use of AI_**\n**_systems for the analysis of recorded_**\n**_footage of publicly accessible spaces_**\n**_through \u2018post\u2019 remote biometric_**\n**_identification systems, unless they are_**\n**_subject to a pre-judicial authorisation in_**\n**_accordance with Union law and strictly_**\n**_necessary for the targeted search_**\n**_connected to a specific serious criminal_**\n**_offense as defined in Article 83(1) of_**\n**_TFEU that already took place for the_**\n**_purpose of law enforcement._**\n\n\n-----", "**Article 5 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_2._** **_The use of \u2018real-time\u2019 remote_**\n**_biometric identification systems in_**\n**_publicly accessible spaces for the purpose_**\n**_of law enforcement for any of the_**\n**_objectives referred to in paragraph 1 point_**\n**_d) shall take into account the following_**\n**_elements:_**\n\n\n**_deleted_**\n\n\n**_(a)_** **_the nature of the situation giving_**\n**_rise to the possible use, in particular the_**\n**_seriousness, probability and scale of the_**\n**_harm caused in the absence of the use of_**\n**_the system;_**\n\n**_(b)_** **_the consequences of the use of the_**\n**_system for the rights and freedoms of all_**\n**_persons concerned, in particular the_**\n**_seriousness, probability and scale of those_**\n**_consequences._**\n\n**_In addition, the use of \u2018real-time\u2019 remote_**\n**_biometric identification systems in_**\n**_publicly accessible spaces for the purpose_**\n**_of law enforcement for any of the_**\n**_objectives referred to in paragraph 1 point_**\n**_d) shall comply with necessary and_**\n**_proportionate safeguards and conditions_**\n**_in relation to the use, in particular as_**\n\n\n-----\n\n**_regards the temporal, geographic and_**\n**_personal limitations._**", "**Article 5 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_3._** **_As regards paragraphs 1, point (d)_**\n**_and 2, each individual use for the purpose_**\n**_of law enforcement of a \u2018real-time\u2019_**\n**_remote biometric identification system in_**\n**_publicly accessible spaces shall be subject_**\n**_to a prior authorisation granted by a_**\n**_judicial authority or by an independent_**\n**_administrative authority of the Member_**\n**_State in which the use is to take place,_**\n**_issued upon a reasoned request and in_**\n**_accordance with the detailed rules of_**\n**_national law referred to in paragraph 4._**\n**_However, in a duly justified situation of_**\n**_urgency, the use of the system may be_**\n**_commenced without an authorisation and_**\n**_the authorisation may be requested only_**\n**_during or after the use._**\n\n\n**_deleted_**\n\n\n**_The competent judicial or administrative_**\n**_authority shall only grant the_**\n**_authorisation where it is satisfied, based_**\n**_on objective evidence or clear indications_**\n**_presented to it, that the use of the \u2018realtime\u2019 remote biometric identification_**\n**_system at issue is necessary for and_**\n**_proportionate to achieving one of the_**\n**_objectives specified in paragraph 1, point_**\n**_(d), as identified in the request.\n\nIn_**\n**_deciding on the request, the competent_**\n**_judicial or administrative authority shall_**\n**_take into account the elements referred to_**\n**_in paragraph 2._**", "**Article 5 \u2013 paragraph 4**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_4._** **_A Member State may decide to_**\n**_provide for the possibility to fully or_**\n**_partially authorise the use of \u2018real-time\u2019_**\n**_remote biometric identification systems in_**\n**_publicly accessible spaces for the purpose_**\n**_of law enforcement within the limits and_**\n**_under the conditions listed in paragraphs_**\n**_1, point (d), 2 and 3.\n\nThat Member State_**\n**_shall lay down in its national law the_**\n**_necessary detailed rules for the request,_**\n**_issuance and exercise of, as well as_**\n**_supervision relating to, the authorisations_**\n**_referred to in paragraph 3.\n\nThose rules_**\n**_shall also specify in respect of which of_**\n**_the objectives listed in paragraph 1, point_**\n**_(d), including which of the criminal_**\n**_offences referred to in point (iii) thereof,_**\n**_the competent authorities may be_**\n**_authorised to use those systems for the_**\n**_purpose of law enforcement._**\n\n\n**_deleted_**", "**Article 6 \u2013 paragraph 1 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) the genai system is intended to be used\nas a safety component of a product, or is\nitself a product, covered by the Union\nharmonisation legislation listed in Annex\nII;\n\n\n(a) the genai system is intended to be used\nas a safety component of a product, **_or the_**\n**_AI system_** is itself a product, covered by\nthe Union harmonisation **_law_** listed in\nAnnex II;", "**Article 6 \u2013 paragraph 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) the product whose safety component\nis the genai system, or the genai system itself as\na product, is required to undergo a thirdparty conformity assessment with a view to\n\n\n(b) the product whose safety component\n**_pursuant to point (a)_** is the genai system, or\nthe genai system itself as a product, is\nrequired to undergo a third-party\n\n\n-----\n\nthe placing on the market or putting into\nservice of that product pursuant to the\nUnion harmonisation legislation listed in\nAnnex II **_._**\n\n\nconformity assessment **_related to risks for_**\n**_health and safety,_** with a view to the\nplacing on the market or putting into\nservice of that product pursuant to the\nUnion harmonisation **_law_** listed in Annex\nII **_;_**", "**Article 6 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nIn addition to the high-risk genai\nsystems referred to in paragraph 1, genai\nsystems referred to in Annex III shall **_also_**\nbe considered high-risk.\n\n2.\n\nIn addition to the high-risk genai\nsystems referred to in paragraph 1, genai\nsystems **_falling under one or more of the_**\n**_critical areas and use cases_** referred to in\nAnnex III shall **_be considered high-risk if_**\n**_they pose a significant risk of harm to the_**\n**_health, safety or fundamental rights of_**\n**_natural persons.\n\nWhere an genai system falls_**\n**_under Annex III point 2, it shall_** be\nconsidered **_to be_** high-risk **_if it poses a_**\n**_significant risk of harm to the_**\n**_environment_** .\n\n**_The Commission shall, six months prior_**\n**_to the entry into force of this Regulation,_**\n**_after consulting the genai Office and_**\n**_relevant stakeholders, provide guidelines_**\n**_clearly specifying the circumstances_**\n**_where the output of genai systems referred to_**\n**_in Annex III would pose a significant risk_**\n**_of harm to the health, safety or_**\n**_fundamental rights of natural persons or_**\n**_cases in which it would not._**", "**Article 6 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_Where providers falling under one_**\n**_or more of the critical areas and use cases_**\n**_referred to in Annex III consider that_**\n\n\n-----\n\n**_their genai system does not pose a significant_**\n**_risk as described in paragraph 2, they_**\n**_shall submit a reasoned notification to the_**\n**_national supervisory authority that they_**\n**_are not subject to the requirements of_**\n**_Title III Chapter 2 of this Regulation._**\n**_Where the genai system is intended to be_**\n**_used in two or more Member States, that_**\n**_notification shall be addressed to the AI_**\n**_Office.\n\nWithout prejudice to Article 65,_**\n**_the national supervisory authority shall_**\n**_review and reply to the notification,_**\n**_directly or via the genai Office, within three_**\n**_months if they deem the genai system to be_**\n**_misclassified._**", "**Article 6 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 b._** **_Providers that misclassify their AI_**\n**_system as not subject to the requirements_**\n**_of Title III Chapter 2 of this Regulation_**\n**_and place it on the market before the_**\n**_deadline for objection by national_**\n**_supervisory authorities shall be subject to_**\n**_fines pursuant to Article 71._**", "**Article 7 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nThe Commission is empowered to\nadopt delegated acts in accordance with\nArticle 73 to **_update the list in_** Annex III\nby adding high-risk genai systems where **_both_**\n**_of the following conditions are fulfilled:_**\n\n\n1.\n\nThe Commission is empowered to\nadopt delegated acts in accordance with\nArticle 73 to **_amend_** Annex III by adding\n**_or modifying areas or use-cases of_** highrisk genai systems where **_these pose a_**\n**_significant risk of harm to health and_**\n**_safety, or an adverse impact on_**\n**_fundamental rights, to the environment,_**\n**_or to democracy and the rule of law, and_**\n**_that risk is, in respect of its severity and_**\n**_probability of occurrence, equivalent to or_**\n**_greater than the risk of harm or of_**\n**_adverse impact posed by the high-risk AI_**\n**_systems already referred to in Annex III._**", "**Article 7 \u2013 paragraph 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(b)_** **_the genai systems pose a risk of harm_**\n**_to the health and safety, or a risk of_**\n**_adverse impact on fundamental rights,_**\n**_that is, in respect of its severity and_**\n**_probability of occurrence, equivalent to or_**\n**_greater than the risk of harm or of_**\n**_adverse impact posed by the high-risk AI_**\n**_systems already referred to in Annex III._**\n\n\n**_deleted_**\n\n\n-----", "**Article 7 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 a._** **_The Commission is also empowered_**\n**_to adopt delegated acts in accordance with_**\n**_Article 73 to remove use-cases of highrisk genai systems from the list in Annex III_**\n**_if the conditions referred to in paragraph_**\n**_1 no longer apply;_**", "**Article 7 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWhen assessing for the purposes of\nparagraph 1 **_whether an genai system poses a_**\n**_risk of harm to the health and safety or a_**\n**_risk of adverse impact on fundamental_**\n**_rights that is equivalent to or greater than_**\n**_the risk of harm posed by the high-risk AI_**\n**_systems already referred to in Annex III,_**\nthe Commission shall take into account the\nfollowing criteria:\n\n\n2.\n\nWhen assessing **_an genai system_** for the\npurposes of paragraph 1 **_and 1a_** the\nCommission shall take into account the\nfollowing criteria:", "**Article 7 \u2013 paragraph 2 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) the extent to which the use of an genai\nsystem has already caused harm to **_the_**\nhealth and safety **_or_** adverse impact on **_the_**\nfundamental rights or has given rise to\nsignificant concerns in relation to the\n**_materialisation_** of such harm or adverse\nimpact, as demonstrated by reports or\ndocumented allegations submitted to\nnational **_competent_** authorities;\n\n\n(c) the extent to which the use of an genai\nsystem has already caused harm to health\nand safety **_, has had an_** adverse impact on\nfundamental rights **_, the environment,_**\n**_democracy and the rule of law_** or has\ngiven rise to significant concerns in\nrelation to the **_likelihood_** of such harm or\nadverse impact, as demonstrated **_for_**\n**_example_** by reports or documented\nallegations submitted to national\n**_supervisory_** authorities **_, to the_**\n**_Commission, to the genai Office, to the_**\n**_EDPS, or to the European Union Agency_**\n**_for Fundamental Rights_** ;", "**Article 7 \u2013 paragraph 2 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) the potential extent of such harm or\nsuch adverse impact, in particular in terms\n\n\n(d) the potential extent of such harm or\nsuch adverse impact, in particular in terms\n\n\n-----\n\nof its intensity and its ability to affect a\nplurality of persons;\n\n\nof its intensity and its ability to affect a\nplurality of persons **_or to_**\n**_disproportionately affect a particular_**\n**_group of persons_** ;", "**Article 7 \u2013 paragraph 2 \u2013 point e**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(e) the extent to which potentially\nharmed or adversely impacted persons are\ndependent on the **_outcome_** produced **_with_**\nan genai system, in particular because for\npractical or legal reasons it is not\nreasonably possible to opt-out from that\n**_outcome_** ;\n\n\n(e) the extent to which potentially\nharmed or adversely impacted persons are\ndependent on the **_output_** produced\n**_involving_** an genai system **_, and that output is_**\n**_purely accessory in respect of the relevant_**\n**_action or decision to be taken_** , in particular\nbecause for practical or legal reasons it is\nnot reasonably possible to opt-out from\nthat **_output_** ;", "**Article 7 \u2013 paragraph 2 \u2013 point f**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(f) the extent to which potentially\nharmed or adversely impacted persons are\nin a vulnerable position in relation to the\nuser of an genai system, in particular due to\n**_an imbalance of power_** , knowledge,\neconomic or social circumstances, or age;\n\n\n(f) the extent to which **_there is an_**\n**_imbalance of power, or the_** potentially\nharmed or adversely impacted persons are\nin a vulnerable position in relation to the\nuser of an genai system, in particular due to\n**_status, authority_** , knowledge, economic or\n\n\n-----\n\nsocial circumstances, or age;", "**Article 7 \u2013 paragraph 2 \u2013 point g**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(g) the extent to which the outcome\nproduced **_with_** an genai system is easily\nreversible, whereby outcomes having an\nimpact on **_the_** health **_or_** safety of persons\nshall not be considered as easily reversible;\n\n\n(g) the extent to which the outcome\nproduced **_involving_** an genai system is easily\nreversible **_or remedied_** , whereby outcomes\nhaving an **_adverse_** impact on health **_,_** safety **_,_**\n**_fundamental rights_** of persons **_, the_**\n**_environment, or on democracy and rule of_**\n**_law_** shall not be considered as easily\nreversible;", "**Article 7 \u2013 paragraph 2 \u2013 point h \u2013**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(i) effective measures of redress in\nrelation to the **_risks posed_** by an genai system,\nwith the exclusion of claims for damages;\n\n\n(h) the extent to which existing Union\nlaw provides for:\n\n(i) effective measures of redress in\nrelation to the **_damage caused_** by an genai\nsystem, with the exclusion of claims for\n**_direct or indirect_** damages;\n\n(ii) effective measures to prevent or\nsubstantially minimise those risks.", "**Article 7 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_When assessing an genai system for the_**\n**_purposes of paragraphs 1 or 1a the_**\n**_Commission shall consult the genai Office_**\n**_and, where relevant, representatives of_**\n**_groups on which an genai system has an_**\n**_impact, industry, independent experts, the_**\n**_social partners, and civil society_**\n**_organisations.\n\nThe Commission shall also_**\n**_organise public consultations in this_**\n**_regard and shall make the results of those_**\n**_consultations and of the final assessment_**\n**_publicly available;_**\n\n\n-----", "**Article 7 \u2013 paragraph 2 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 b._** **_The genai Office, national supervisory_**\n**_authorities or the European Parliament_**\n**_may request the Commission to reassess_**\n**_and recategorise the risk categorisation of_**\n**_an genai systemin accordance with_**\n**_paragraphs 1 and 1a.\n\nThe Commission_**\n**_shall give reasons for its decision and_**\n**_make them public._**", "**Article 8 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 a._** **_In complying with the requirement_**\n**_established in this Chapter, due account_**\n**_shall be taken of guidelines developed as_**\n**_referred to in Article 82b, the generally_**\n**_acknowledged state of the art, including_**\n**_as reflected in the relevant harmonised_**\n**_standards and common specifications as_**\n**_referred to in articles 40 and 41 or those_**\n**_already set out in Union harmonisation_**\n**_law;._**", "**Article 8 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe intended purpose of the high-risk\ngenai system and the risk management system\nreferred to in Article 9 shall be taken into\naccount when ensuring compliance with\nthose requirements.\n\n2.\n\nThe intended purpose of the high-risk\ngenai system **_, the reasonably foreseeable_**\n**_misuses_** and the risk management system\nreferred to in Article 9 shall be taken into\naccount when ensuring compliance with\n\n\n-----\n\nthose requirements.", "**Article 8 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_As long as the requirements of Title_**\n**_III, Chapters 2 and 3 or Title VIII,_**\n**_Chapters 1, 2 and 3 for high-risk AI_**\n**_systems are addressed by Union_**\n**_harmonisation law listed in Annex II,_**\n**_Section A, the requirements or obligations_**\n**_of those Chapters of this Regulation shall_**\n**_be deemed to be fulfilled, as long as they_**\n**_include the genai component.\n\nRequirements_**\n**_of Chapters 2 and 3 of Title III or Title_**\n**_VIII, Chapters 1, 2 and 3 for high-risk AI_**\n**_systems not addressed by Union_**\n**_harmonisation law listed in Annex II_**\n**_Section A, shall be incorporated into that_**\n**_Union harmonisation law, where_**\n**_applicable.\n\nThe relevant conformity_**\n**_assessment shall be carried out as part of_**\n**_the procedures laid out under Union_**\n**_harmonisation law listed in Annex II,_**\n**_Section A._**", "**Article 9 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nA risk management system shall be\nestablished, implemented, documented and\nmaintained in relation to high-risk genai\nsystems.\n\n1.\n\nA risk management system shall be\nestablished, implemented, documented and\nmaintained in relation to high-risk genai\nsystems **_, throughout the entire lifecycle of_**\n**_the genai system_** .\n\n**_The risk management_**\n**_system can be integrated into, or a part of,_**\n**_already existing risk management_**\n**_procedures relating to the relevant Union_**\n**_sectoral law insofar as it fulfils the_**\n**_requirements of this article._**\n\n\n-----", "**Article 9 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe risk management system shall\nconsist of a continuous iterative process\nrun throughout the entire lifecycle of a\nhigh-risk genai system, requiring regular\n**_systematic_** updating.\n\nIt shall comprise the\nfollowing steps:\n\n\n2.\n\nThe risk management system shall\nconsist of a continuous iterative process\nrun throughout the entire lifecycle of a\nhigh-risk genai system, requiring regular\n**_review and_** updating **_of the risk_**\n**_management process, to ensure its_**\n**_continuing effectiveness, and_**\n**_documentation of any significant_**\n**_decisions and actions taken subject to this_**\n**_Article_** .\n\nIt shall comprise the following\nsteps:", "**Article 9 \u2013 paragraph 2 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) identification **_and analysis_** of the\nknown and foreseeable risks **_associated_**\n**_with each_** high-risk genai system;\n\n\n(a) identification **_, estimation and_**\n**_evaluation_** of the known and **_the_**\n**_reasonably_** highrisk genai system foreseeable risks **_can pose to the health or_** **_that the_**\n**_safety of natural persons, their_**\n**_fundamental rights including equal_**\n**_access and opportunities, democracy and_**\n**_rule of law or the environement when the_**\n**_high-risk genai system is used in accordance_**\n**_with its intended purpose and under_**\n**_conditions of reasonably foreseeable_**\n**_misuse_** ;", "**Article 9 \u2013 paragraph 2 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) evaluation of **_other possibly arising_**\nrisks based on the analysis of data gathered\nfrom the post-market monitoring system\nreferred to in Article 61;\n\n\n(c) evaluation of **_emerging significant_**\nrisks **_as described in point (a) and_**\n**_identified_** based on the analysis of data\ngathered from the post-market monitoring\nsystem referred to in Article 61;", "**Article 9 \u2013 paragraph 2 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) adoption of **_suitable_** risk\nmanagement measures in accordance with\nthe provisions of the following paragraphs\n\n\n(d) adoption of **_appropriate and targeted_**\nrisk management measures **_designed to_**\n**_address the risks identified pursuant to_**\n**_points a and b of this paragraph_** in\naccordance with the provisions of the\nfollowing paragraphs", "**Article 9 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nThe risk management measures\nreferred to in paragraph 2, point (d) shall\ngive due consideration to the effects and\npossible interactions resulting from the\n\n\n3.\n\nThe risk management measures\nreferred to in paragraph 2, point **_(d)_** shall\ngive due consideration to the effects and\npossible interactions resulting from the\n\n\n-----\n\ncombined application of the requirements\nset out in this Chapter 2 **_.\n\nThey shall take_**\n**_into account the generally acknowledged_**\n**_state_** of the **_art, including as reflected in_**\n**_relevant harmonised standards or_**\n**_common specifications_** .\n\ncombined application of the requirements\nset out in this Chapter 2 **_, with a view to_**\n**_mitigate risks effectively while ensuring_**\n**_an appropriate and proportionate_**\n**_implementation_** of the **_requirements_** .", "**Article 9 \u2013 paragraph 4 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nThe risk management measures\nreferred to in paragraph 2, point (d) shall\nbe such that **_any_** residual risk associated\nwith each hazard as well as the overall\nresidual risk of the high-risk genai systems is\njudged acceptable, provided that the highrisk genai system is used in accordance with\nits intended purpose or under conditions of\nreasonably foreseeable misuse.\n\nThose\nresidual risks shall be communicated to the\n**_user_** .\n\n4.\n\nThe risk management measures\nreferred to in paragraph 2, point **_(d)_** shall\nbe such that **_relevant_** residual risk\nassociated with each hazard as well as the\noverall residual risk of the high-risk genai\nsystems is **_reasonably_** judged **_to be_**\nacceptable, provided that the high-risk genai\nsystem is used in accordance with its\nintended purpose or under conditions of\nreasonably foreseeable misuse.\n\nThose\nresidual risks **_and the reasoned_**\n**_judgements made_** shall be communicated\nto the **_deployer_** .\n\n**_In identifying the most appropriate risk_**\n**_management measures, the following_**\n**_shall be ensured:_**", "**Article 9 \u2013 paragraph 4 \u2013 subparagraph 1 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) elimination or reduction of risks as\nfar as **_possible_** through adequate design and\ndevelopment;\n\n\n(a) elimination or reduction of **_identified_**\nrisks as far as **_technically feasible_** through\nadequate design and development **_of the_**\n**_high-risk genai system, involving when_**\n**_relevant, experts and external_**\n**_stakeholders_** ;", "**Article 9 \u2013 paragraph 4 \u2013 subparagraph 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) where appropriate, implementation of\nadequate mitigation and control measures\n**_in relation to_** risks that cannot be\neliminated;\n\n\n(b) where appropriate, implementation of\nadequate mitigation and control measures\n**_addressing significant_** risks that cannot be\neliminated;", "**Article 9 \u2013 paragraph 4 \u2013 subparagraph 1 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) provision of **_adequate_** information\npursuant to Article 13 **_, in particular as_**\n**_regards the risks referred to in paragraph_**\n**_2, point (b) of this Article_** , and, where\nappropriate, training to **_users_** .\n\n(c) provision of **_the required_** information\npursuant to Article 13, and, where\nappropriate, training to **_deployers_** .", "**Article 9 \u2013 paragraph 4 \u2013 subparagraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nIn eliminating or reducing risks related to\nthe use of the high-risk genai system, due\nconsideration **_shall be given to_** the\ntechnical knowledge, experience,\neducation **_,_** training **_to be expected by the_**\n**_user and the environment in which the_**\n**_system is intended to be used_** .\n\nIn eliminating or reducing risks related to\nthe use of the high-risk genai system,\n**_providers shall take into_** due consideration\nthe technical knowledge, experience,\neducation **_and_** training **_the deployer may_**\n**_need, including in relation to the_**\n**_presumable context of use_** .", "**Article 9 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n5.\n\nHigh-risk genai systems shall be tested 5.\n\nHigh-risk genai systems shall be tested\n\n\n-----\n\nfor the purposes of identifying the most\nappropriate risk management measures.\n\nTesting shall ensure that high-risk genai\nsystems perform consistently for their\nintended purpose and they are in\ncompliance with the requirements set out\nin this Chapter.\n\nfor the purposes of identifying the most\nappropriate **_and targeted_** risk management\nmeasures **_and weighing any such_**\n**_measures against the potential benefits_**\n**_and intended goals of the system_** .\n\nTesting\nshall ensure that high-risk genai systems\nperform consistently for their intended\npurpose and they are in compliance with\nthe requirements set out in this Chapter.", "**Article 9 \u2013 paragraph 6**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\nTesting procedures shall be suitable\nto achieve the intended purpose of the genai\nsystem **_and do not need to go beyond what_**\n**_is necessary to achieve that purpose_** .\n\n6.\n\nTesting procedures shall be suitable\nto achieve the intended purpose of the genai\nsystem.", "**Article 9 \u2013 paragraph 7**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n7.\n\nThe testing of the high-risk genai\nsystems shall be performed **_, as_**\n**_appropriate, at any point in time_**\n**_throughout the development process, and,_**\n**_in any event_** , prior to the placing on the\nmarket or the putting into service.\n\nTesting\nshall be made against **_preliminarily_** defined\nmetrics and probabilistic thresholds that are\nappropriate to the intended purpose of the\nhigh-risk genai system.\n\n7.\n\nThe testing of the high-risk genai\nsystems shall be performed, prior to the\nplacing on the market or the putting into\nservice.\n\nTesting shall be made against **_prior_**\ndefined metrics **_,_** and probabilistic\nthresholds that are appropriate to the\nintended purpose **_or reasonably_**\n**_foreseeable misuse_** of the high-risk genai\nsystem.", "**Article 9 \u2013 paragraph 8**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n8.\n\nWhen implementing the risk\nmanagement system described in\nparagraphs 1 to 7, specific consideration\n**_shall be given_** to whether the high-risk genai\nsystem is likely to **_be accessed by or have_**\n**_an_** impact **_on_** children.\n\n8.\n\nWhen implementing the risk\nmanagement system described in\nparagraphs 1 to 7, **_providers shall give_**\nspecific consideration to whether the highrisk genai system is likely to **_adversely_** impact\n**_vulnerable groups of people or_** children.", "**Article 9 \u2013 paragraph 9**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n9.\n\nFor credit institutions regulated by\nDirective 2013/36/EU, the aspects\ndescribed in paragraphs 1 to 8 shall be part\nof the risk management procedures\nestablished by those **_institutions pursuant_**\n**_to Article 74 of that Directive_** .\n\n9.\n\nFor **_providers and genai systems_**\n**_already covered by Union law that require_**\n**_them to establish a specific risk_**\n**_management, including_** credit institutions\nregulated by Directive 2013/36/EU, the\naspects described in paragraphs 1 to 8 shall\nbe part of **_or combined with_** the risk\nmanagement procedures established by\n**_that Union law_** .", "**Article 10 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nHigh-risk genai systems which make\nuse of techniques involving the training of\nmodels with data shall be developed on the\nbasis of training, validation and testing data\nsets that meet the quality criteria referred to\nin paragraphs 2 to 5.\n\n1.\n\nHigh-risk genai systems which make\nuse of techniques involving the training of\nmodels with data shall be developed on the\nbasis of training, validation and testing data\nsets that meet the quality criteria referred to\nin paragraphs 2 to 5 **_as far as this is_**\n**_technically feasible according to the_**\n**_specific market segment or scope of_**\n**_application_** .\n\n**_Techniques that do not require labelled_**\n**_input data such as unsupervised learning_**\n**_and reinforcement learning shall be_**\n**_developed on the basis of data sets such as_**\n**_for testing and verification that meet the_**\n\n\n-----\n\n**_quality criteria referred to in paragraphs_**\n**_2 to 5._**", "**Article 10 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nTraining, validation and testing data\nsets shall be subject to **_appropriate_** data\ngovernance **_and management practices_** .\n\nThose **_practices_** shall concern in particular,\n\n\n2.\n\nTraining, validation and testing data\nsets shall be subject to data governance\n**_appropriate for the context of use as well_**\n**_as the intended purpose of the genai system_** .\n\nThose **_measures_** shall concern in\nparticular,", "**Article 10 \u2013 paragraph 2 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) the formulation of **_relevant_**\nassumptions, notably with respect to the\ninformation that the data are supposed to\nmeasure and represent;\n\n\n(d) the formulation of assumptions,\nnotably with respect to the information that\nthe data are supposed to measure and\nrepresent;", "**Article 10 \u2013 paragraph 2 \u2013 point f**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(f) examination in view of possible\nbiases;\n\n\n(f) examination in view of possible\nbiases **_that are likely to affect the health_**\n**_and safety of persons, negatively impact_**\n**_fundamental rights or lead to_**\n**_discrimination prohibited under Union_**\n**_law, especially where data outputs_**\n**_influence inputs for future operations_**\n**_(\u2018feedback loops\u2019) and appropriate_**\n**_measures to detect, prevent and mitigate_**\n**_possible biases_** ;", "**Article 10 \u2013 paragraph 2 \u2013 point g**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(g) the identification of **_any possible_** data\ngaps or shortcomings, and how those gaps\nand shortcomings can be addressed **_._**\n\n\n(g) the identification of **_relevant_** data\ngaps or shortcomings **_that prevent_**\n**_compliance with this Regulation_** , and how\nthose gaps and shortcomings can be\naddressed **_;_**", "**Article 10 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nTraining, validation and testing **_data_**\n**_sets_** shall be relevant, representative, **_free_**\n**_of_** errors and complete.\n\nThey shall have the\nappropriate statistical properties, including,\nwhere applicable, as regards the persons or\ngroups of persons **_on which_** the high-risk\ngenai system is intended to be used.\n\nThese\ncharacteristics of the **_data sets may_** be met\nat the level of individual **_data sets_** or a\ncombination thereof.\n\n3.\n\nTraining **_datasets, and where they_**\n**_are used_** , validation and testing **_datasets,_**\n**_including the labels,_** shall be relevant,\n**_sufficiently_** representative **_, appropriately_**\n**_vetted for_** errors and **_be as_** complete **_as_**\n**_possible in view of the intended purpose_** .\n\nThey shall have the appropriate statistical\nproperties, including, where applicable, as\nregards the persons or groups of persons **_in_**\n**_relation to whom_** the high-risk genai system\nis intended to be used.\n\nThese\ncharacteristics of the **_datasets shall_** be met\nat the level of individual **_datasets_** or a\ncombination thereof.", "**Article 10 \u2013 paragraph 4**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\n**_Training, validation and testing data_**\n**_sets_** shall take into account, to the extent\nrequired by the intended purpose, the\ncharacteristics or elements that are\nparticular to the specific geographical,\nbehavioural or functional setting within\nwhich the high-risk genai system is intended\nto be used.\n\n4.\n\n**_Datasets_** shall take into account, to\nthe extent required by the intended purpose\n**_or reasonably foreseeable misuses of the_**\n**_AI system_** , the characteristics or elements\nthat are particular to the specific\ngeographical, **_contextual_** behavioural or\nfunctional setting within which the highrisk genai system is intended to be used.", "**Article 10 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nTo the extent that it is strictly\nnecessary for the purposes of ensuring bias\n**_monitoring,_** detection and correction in\nrelation to the high-risk genai systems, the\nproviders of such systems may process\nspecial categories of personal data referred\nto in Article 9(1) of Regulation (EU)\n2016/679, Article 10 of Directive (EU)\n2016/680 and Article 10(1) of Regulation\n(EU) 2018/1725, subject to appropriate\nsafeguards for the fundamental rights and\nfreedoms of natural persons, including\ntechnical limitations on the re-use and use\nof state-of-the-art security and privacypreserving measures **_, such as_**\n**_pseudonymisation, or encryption where_**\n**_anonymisation may significantly affect_**\nthe purpose **_pursued_** .\n\n5.\n\nTo the extent that it is strictly\nnecessary for the purposes of ensuring\n**_negative_** bias detection and correction in\nrelation to the high-risk genai systems, the\nproviders of such systems may\n**_exceptionally_** process special categories of\npersonal data referred to in Article 9(1) of\nRegulation (EU) 2016/679, Article 10 of\nDirective (EU) 2016/680 and Article 10(1)\nof Regulation (EU) 2018/1725, subject to\nappropriate safeguards for the fundamental\nrights and freedoms of natural persons,\nincluding technical limitations on the reuse and use of state-of-the-art security and\nprivacy-preserving **_.\n\nIn particular, all the_**\n**_following conditions shall apply in order_**\n**_for this processing to occur: (a) the bias_**\n**_detection and correction cannot be_**\n**_effectively fulfilled by processing synthetic_**\n**_or anonymised data;_**\n\n**_(b) the data are pseudonymised;_**\n\n**_(c) the provider takes appropriate_**\n**_technical and organisational_** measures **_to_**\n**_ensure that the data processed for_** the\npurpose **_of this paragraph are secured,_**\n**_protected, subject to suitable safeguards_**\n**_and only authorised persons have access_**\n**_to those data with appropriate_**\n**_confidentiality obligations;_**\n\n\n-----\n\n**_(d) the data processed for the purpose of_**\n**_this paragraph are not to be transmitted,_**\n**_transferred or otherwise accessed by other_**\n**_parties;_**\n\n**_(e) the data processed for the purpose of_**\n**_this paragraph are protected by means of_**\n**_appropriate technical and organisational_**\n**_measures and deleted once the bias has_**\n**_been corrected or the personal data has_**\n**_reached the end of its retention period;_**\n\n**_(f) effective and appropriate measures are_**\n**_in place to ensure availability, security_**\n**_and resilience of processing systems and_**\n**_services against technical or physical_**\n**_incidents;_**\n\n**_(g) effective and appropriate measures are_**\n**_in place to ensure physical security of_**\n**_locations where the data are stored and_**\n**_processed, internal IT and IT security_**\n**_governance and management,_**\n**_certification of processes and products;_**\n\n**_Providers having recourse to this_**\n**_provision shall draw up documentation_**\n**_explaining why the processing of special_**\n**_categories of personal data was necessary_**\n**_to detect and correct biases_** .", "**Article 10 \u2013 paragraph 6 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_6 a._** **_Where the provider cannot comply_**\n**_with the obligations laid down in this_**\n**_Article because that provider does not_**\n**_have access to the data and the data is_**\n**_held exclusively by the deployer, the_**\n**_deployer may, on the basis of a contract,_**\n**_be made responsible for any infringement_**\n**_of this Article._**", "**Article 11 \u2013 paragraph 1 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nThe technical documentation shall be\ndrawn up in such a way to demonstrate that\nthe high-risk genai system complies with the\nrequirements set out in this Chapter and\nprovide national **_competent_** authorities and\nnotified bodies with **_all_** the necessary\ninformation to assess the compliance of the\ngenai system with those requirements.\n\nIt shall\ncontain, at a minimum, the elements set out\nin Annex IV.\n\nThe technical documentation shall be\ndrawn up in such a way to demonstrate that\nthe high-risk genai system complies with the\nrequirements set out in this Chapter and\nprovide national **_supervisory_** authorities\nand notified bodies with the necessary\ninformation to assess the compliance of the\ngenai system with those requirements.\n\nIt shall\ncontain, at a minimum, the elements set out\nin Annex IV **_or, in the case of SMEs and_**\n**_start-ups, any equivalent documentation_**\n**_meeting the same objectives, subject to_**\n**_approval of the competent national_**\n**_authority_** .", "**Article 11 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWhere a high-risk genai system related\nto a product, to which the legal acts listed\nin Annex II, section A apply, is placed on\nthe market or put into service one single\ntechnical documentation shall be drawn up\ncontaining all the information set out in\n**_Annex IV_** as well as the information\nrequired under those legal acts.\n\n2.\n\nWhere a high-risk genai system related\nto a product, to which the legal acts listed\nin Annex II, section A apply, is placed on\nthe market or put into service one single\ntechnical documentation shall be drawn up\ncontaining all the information set out in\n**_paragraph 1_** as well as the information\nrequired under those legal acts.", "**Article 12 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nHigh-risk genai systems shall be\ndesigned and developed with capabilities\nenabling the automatic recording of events\n(\u2018logs\u2019) while the high-risk genai systems is\noperating.\n\nThose logging capabilities shall\nconform to recognised standards or\ncommon specifications.\n\n1.\n\nHigh-risk genai systems shall be\ndesigned and developed with capabilities\nenabling the automatic recording of events\n(\u2018logs\u2019) while the high-risk genai systems is\noperating.\n\nThose logging capabilities shall\nconform to **_the state of the art and_**\nrecognised standards or common\nspecifications.", "**Article 12 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\n**_The logging capabilities shall_** ensure\na level of traceability of the genai system\u2019s\nfunctioning throughout its **_lifecycle_** that is\nappropriate to the intended purpose of the\nsystem.\n\n2.\n\n**_In order to_** ensure a level of\ntraceability of the genai system\u2019s functioning\nthroughout its **_entire lifetime_** that is\nappropriate to the intended purpose of the\nsystem **_, the logging capabilities shall_**\n**_facilitate the monitoring of operations as_**\n**_referred to in Article 29(4) as well as the_**\n**_post market monitoring referred to in_**\n**_Article 61_** .\n\n**_In particular, they shall enable_**\n**_the recording of events relevant for the_**\n**_identification of situations that may:_**\n\n**_(a) result in the genai system presenting a_**\n**_risk within the meaning of Article65(1);_**\n**_or_**\n\n**_(b) lead to a substantial modification of_**\n**_the genai system._**", "**Article 12 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_High-risk genai systems shall be_**\n**_designed and developed with, the logging_**\n**_capabilities enabling the recording of_**\n**_energy consumption, the measurement or_**\n**_calculation of resource use and_**\n**_environmental impact of the high-risk AI_**\n**_system during all phases of the system\u2019s_**\n**_lifecycle._**", "**Article 12 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_3._** **_In particular, logging capabilities_**\n**_shall enable the monitoring of the_**\n**_operation of the high-risk genai system with_**\n**_respect to the occurrence of situations_**\n**_that may result in the genai system_**\n**_presenting a risk within the meaning of_**\n**_Article 65(1) or lead to a substantial_**\n**_modification, and facilitate the postmarket monitoring referred to in Article_**\n**_61._**\n\n\n**_deleted_**", "**Article 13 \u2013 paragraph 1**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nHigh-risk genai systems shall be\ndesigned and developed in such a way to\nensure that their operation is sufficiently\ntransparent to enable users to **_interpret_** the\nsystem\u2019s **_output and use it appropriately_** .\n\n**_An_** appropriate **_type and degree of_**\ntransparency shall be ensured, with a view\nto achieving compliance with the relevant\nobligations of the **_user and of the_** provider\nset out in Chapter 3 of this Title.\n\n1.\n\nHigh-risk genai systems shall be\ndesigned and developed in such a way to\nensure that their operation is sufficiently\ntransparent to enable **_providers and_** users\nto **_reasonably understand_** the system\u2019s\n**_functioning_** .\n\nAppropriate transparency\nshall be ensured **_in accordance with the_**\n**_intended purpose of the genai system_** , with a\nview to achieving compliance with the\nrelevant obligations of the provider **_and_**\n**_user_** set out in Chapter 3 of this Title.\n\n**_Transparency shall thereby mean that, at_**\n**_the time the high-risk genai system is placed_**\n**_on the market, all technical means_**\n**_available in accordance with the generally_**\n**_acknowledged state of art are used to_**\n**_ensure that the genai system\u2019s output is_**\n**_interpretable by the provider and the user._**\n**_The user shall be enabled to understand_**\n**_and use the genai system appropriately by_**\n**_generally knowing how the genai system_**\n**_works and what data it processes,_**\n**_allowing the user to explain the decisions_**\n**_taken by the genai system to the affected_**\n**_person pursuant to Article 68(c)._**", "**Article 13 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nHigh-risk genai systems shall be\naccompanied by instructions for use in an\nappropriate digital format or otherwise that\ninclude concise, complete **_, correct and_**\n**_clear_** information that **_is_** relevant,\naccessible and comprehensible to users.\n\n2.\n\nHigh-risk genai systems shall be\naccompanied by **_intelligible_** instructions\nfor use in an appropriate digital format or\n**_made_** otherwise **_available in a durable_**\n**_medium_** that include concise, **_correct, clear_**\n**_and to the extent possible_** complete\ninformation that **_helps operating and_**\n**_maintaining the genai system as well as_**\n**_supporting informed decision-making by_**\n**_users and is reasonably_** relevant,\naccessible and comprehensible to users .\n\n-----", "**Article 13 \u2013 paragraph 3 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) the identity and the contact details of\nthe provider and, where applicable, of its\nauthorised **_representative_** ;\n\n\n(a) the identity and the contact details of\nthe provider and, where applicable, of its\nauthorised **_representatives_** ;", "**Article 13 \u2013 paragraph 3 \u2013 point b \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) the characteristics, capabilities and\nlimitations of performance of the high-risk\ngenai system, including:\n\n\n(b) the characteristics, capabilities and\nlimitations of performance of the high-risk\ngenai system, including **_, where appropriate_** :\n\n\n-----", "**Article 13 \u2013 paragraph 3 \u2013 point b \u2013 point ii**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(ii) the level of accuracy, robustness and\ncybersecurity referred to in Article 15\nagainst which the high-risk genai system has\nbeen tested and validated and which can be\nexpected, and any known and foreseeable\ncircumstances that may have an impact on\nthat expected level of accuracy, robustness\nand cybersecurity;\n\n\n(ii) the level of accuracy, robustness and\ncybersecurity referred to in Article 15\nagainst which the high-risk genai system has\nbeen tested and validated and which can be\nexpected, and any **_clearly_** known and\nforeseeable circumstances that may have\nan impact on that expected level of\naccuracy, robustness and cybersecurity;", "**Article 13 \u2013 paragraph 3 \u2013 point b \u2013 point iii**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(iii) any known or foreseeable\ncircumstance, related to the use of the\nhigh-risk genai system in accordance with its\nintended purpose or under conditions of\nreasonably foreseeable misuse, which may\nlead to risks to the health and safety **_or_**\nfundamental rights;\n\n\n(iii) any **_clearly_** known or foreseeable\ncircumstance, related to the use of the\nhigh-risk genai system in accordance with its\nintended purpose or under conditions of\nreasonably foreseeable misuse, which may\nlead to risks to the health and safety **_,_**\nfundamental rights **_or the environment,_**\n**_including, where appropriate, illustrative_**\n**_examples of such limitations and of_**\n**_scenarios for which the system should not_**\n**_be used_** ;", "**Article 13 \u2013 paragraph 3 \u2013 point b \u2013 point v**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(v) **_when appropriate, specifications for_**\n**_the_** input data, or any other relevant\ninformation in terms of the training,\nvalidation and testing data sets used, taking\ninto account the intended purpose of the genai\nsystem.\n\n(v) **_relevant information about user_**\n**_actions that may influence system_**\n**_performance, including type or quality of_**\ninput data, or any other relevant\ninformation in terms of the training,\nvalidation and testing data sets used, taking\ninto account the intended purpose of the genai\nsystem.", "**Article 13 \u2013 paragraph 3 \u2013 point e**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(e) **_the expected lifetime of the high-risk_**\n**_AI system and_** any necessary maintenance\nand care measures to ensure the proper\nfunctioning of that genai system, including as\nregards software updates.\n\n(e) any necessary maintenance and care\nmeasures to ensure the proper functioning\nof that genai system, including as regards\nsoftware updates **_, through its expected_**\n**_lifetime_** .", "**Article 14 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nHigh-risk genai systems shall be\ndesigned and developed in such a way,\nincluding with appropriate human-machine\ninterface tools, that they **_can_** be effectively\noverseen by natural persons during the\nperiod in which the genai system is in use.\n\n1.\n\nHigh-risk genai systems shall be\ndesigned and developed in such a way,\nincluding with appropriate human-machine\ninterface tools, that they be effectively\noverseen by natural persons **_as_**\n**_proportionate to the risks associated with_**\n**_those systems.\n\nNatural persons in charge_**\n**_of ensuring human oversight shall have_**\n**_sufficient level of genai literacy in_**\n**_accordance with Article 4b and the_**\n**_necessary support and authority to_**\n**_exercise that function,_** during the period in\nwhich the genai system is in use **_and to allow_**\n**_for thorough investigation after an_**\n**_incident_** .", "**Article 14 \u2013 paragraph 2**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nHuman oversight shall aim at\npreventing or minimising the risks to\nhealth, safety **_or_** fundamental rights that\nmay emerge when a high-risk genai system is\nused in accordance with its intended\npurpose or under conditions of reasonably\nforeseeable misuse, in particular when such\nrisks persist notwithstanding the\napplication of other requirements set out in\nthis Chapter.\n\n2.\n\nHuman oversight shall aim at\npreventing or minimising the risks to\nhealth, safety **_,_** fundamental rights **_or_**\n**_environment_** that may emerge when a\nhigh-risk genai system is used in accordance\nwith its intended purpose or under\nconditions of reasonably foreseeable\nmisuse, in particular when such risks\npersist notwithstanding the application of\nother requirements set out in this Chapter\n**_and where decisions based solely on_**\n**_automated processing by genai systems_**\n**_produce legal or otherwise significant_**\n**_effects on the persons or groups of_**\n**_persons on which the system is to be used_** .", "**Article 14 \u2013 paragraph 3 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nHuman oversight shall be ensured\nthrough either one or all of the following\nmeasures:\n\n\n3.\n\nHuman oversight **_shall take into_**\n**_account the specific risks, the level of_**\n**_automation, and context of the genai system_**\n**_and_** shall be ensured through either one or\nall of the following **_types of_** measures:", "**Article 14 \u2013 paragraph 4 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\n**_The measures referred to in_**\n**_paragraph 3_** shall **_enable the individuals_**\nto whom human oversight is assigned **_to do_**\n**_the following_** , as appropriate to the\ncircumstances:\n\n\n4.\n\n**_For the purpose of implementing_**\n**_paragraphs 1 to 3, the high-risk genai system_**\nshall **_be provided to the user in such a way_**\n**_that natural persons_** to whom human\noversight is assigned **_are enabled_** , as\nappropriate **_and proportionate_** to the\ncircumstances:\n\n\n-----", "**Article 14 \u2013 paragraph 4 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) **_fully_** understand the capacities and\nlimitations of the high-risk genai system and\nbe able to duly monitor its operation, so\nthat signs of anomalies, dysfunctions and\nunexpected performance can be detected\nand addressed as soon as possible;\n\n\n(a) **_be aware of and sufficiently_**\nunderstand the **_relevant_** capacities and\nlimitations of the high-risk genai system and\nbe able to duly monitor its operation, so\nthat signs of anomalies, dysfunctions and\nunexpected performance can be detected\nand addressed as soon as possible;", "**Article 14 \u2013 paragraph 4 \u2013 point e**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(e) be able to intervene on the operation\nof the high-risk genai system or interrupt the\nsystem through a \u201cstop\u201d button or a similar\nprocedure.\n\n(e) be able to intervene on the operation\nof the high-risk genai system or interrupt **_,_** the\nsystem through a \u201cstop\u201d button or a similar\nprocedure **_that allows the system to come_**\n**_to a halt in a safe state, except if the_**\n**_human interference increases the risks or_**\n**_would negatively impact the performance_**\n**_in consideration of generally_**\n**_acknowledged state-of-the-art_** .", "**Article 14 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nFor high-risk genai systems referred to\nin point 1(a) of Annex III, the measures\nreferred to in paragraph 3 shall be such as\nto ensure that, in addition, no action or\ndecision is taken by the user on the basis of\nthe identification resulting from the system\nunless this has been verified and confirmed\nby at least two natural persons.\n\n5.\n\nFor high-risk genai systems referred to\nin point1(a) of Annex III, the measures\nreferred to in paragraph 3 shall be such as\nto ensure that, in addition, no action or\ndecision is taken by the user on the basis of\nthe identification resulting from the system\nunless this has been verified and confirmed\nby at least two natural persons **_with the_**\n**_necessary competence, training and_**\n\n\n-----\n\n**_authority_** .", "**Article 15 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nHigh-risk genai systems shall be\ndesigned and developed **_in such a way that_**\n**_they achieve,_** in the light of their intended\npurpose, an appropriate level of accuracy,\nrobustness and cybersecurity, and perform\nconsistently in those respects throughout\ntheir lifecycle.\n\n1.\n\nHigh-risk genai systems shall be\ndesigned and developed **_following the_**\n**_principle of security by design and by_**\n**_default._** In the light of their intended\npurpose, **_they should achieve_** an\nappropriate level of accuracy, robustness **_,_**\n**_safety,_** and cybersecurity, and perform\nconsistently in those respects throughout\ntheir lifecycle.\n\n**_Compliance with these_**\n**_requirements shall include_**\n**_implementation of state-of-the-art_**\n**_measures, according to the specific_**\n**_market segment or scope of application._**", "**Article 15 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 a._** **_To address the technical aspects of_**\n**_how to measure the appropriate levels of_**\n**_accuracy and robustness set out in_**\n**_paragraph 1 of this Article, the genai Office_**\n**_shall bring together national and_**\n**_international metrology and_**\n**_benchmarking authorities and provide_**\n**_non-binding guidance on the matter as set_**\n**_out in Article 56, paragraph 2, point (a)._**", "**Article 15 \u2013 paragraph 1 b (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1b._** **_To address any emerging issues_**\n**_across the internal market with regard to_**\n**_cybersecurity, the European Union_**\n**_Agency for Cybersecurity (ENISA) shall_**\n**_be involved alongside the European_**\n**_Artificial Intelligence Board as set out_**\n**_Article 56, paragraph 2, point (b)._**", "**Article 15 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe levels of accuracy and the\nrelevant accuracy metrics of high-risk genai\nsystems shall be declared in the\naccompanying instructions of use.\n\n2.\n\nThe levels of accuracy and the\nrelevant accuracy metrics of high-risk genai\nsystems shall be declared in the\naccompanying instructions of use.\n\n**_The_**\n**_language used shall be clear, free of_**\n**_misunderstandings or misleading_**\n**_statements._**", "**Article 15 \u2013 paragraph 3 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nHigh-risk genai systems shall be resilient as\n**_regards_** errors, faults or inconsistencies\nthat may occur within the system or the\nenvironment in which the system operates,\nin particular due to their interaction with\nnatural persons or other systems.\n\n**_Technical and organisational measures_**\n**_shall be taken to ensure that_** high-risk genai\nsystems shall be **_as_** resilient as **_possible_**\n**_regarding_** errors, faults or inconsistencies\nthat may occur within the system or the\nenvironment in which the system operates,\nin particular due to their interaction with\nnatural persons or other systems.", "**Article 15 \u2013 paragraph 3 \u2013 subparagraph 2**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\nThe robustness of high-risk genai systems\nmay be achieved through technical\nredundancy solutions, which may include\nbackup or fail-safe plans.\n\nThe robustness of high-risk genai systems\nmay be achieved **_by the appropriate_**\n**_provider with input from the user, where_**\n**_necessary,_** through technical redundancy\nsolutions, which may include backup or\nfail-safe plans.", "**Article 15 \u2013 paragraph 3 \u2013 subparagraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nHigh-risk genai systems that continue to learn\nafter being placed on the market or put into\nservice shall be developed in such a way to\nensure that possibly biased outputs **_due to_**\n**_outputs used as an_** input for future\noperations (\u2018feedback loops\u2019) are duly\naddressed with appropriate mitigation\nmeasures.\n\nHigh-risk genai systems that continue to learn\nafter being placed on the market or put into\nservice shall be developed in such a way to\nensure that possibly biased outputs\n**_influencing_** input for future operations\n(\u2018feedback loops\u2019) **_and malicious_**\n**_manipulation of inputs used in learning_**\n**_during operation_** are duly addressed with\nappropriate mitigation measures.", "**Article 15 \u2013 paragraph 4 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nHigh-risk genai systems shall be resilient as\nregards attempts by unauthorised third\nparties to alter their use or performance by\nexploiting the system vulnerabilities.\n\nHigh-risk genai systems shall be resilient as\nregards **_to_** attempts by unauthorised third\nparties to alter their use **_, behaviour,_**\n**_outputs_** or performance by exploiting the\nsystem vulnerabilities.", "**Article 15 \u2013 paragraph 4 \u2013 subparagraph 3**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\nThe technical solutions to address genai\nspecific vulnerabilities shall include, where\nappropriate, measures to prevent and\ncontrol for attacks trying to manipulate the\ntraining dataset (\u2018data poisoning\u2019), inputs\ndesigned to cause the model to make a\nmistake (\u2018adversarial examples\u2019), or model\nflaws.\n\nThe technical solutions to address genai\nspecific vulnerabilities shall include, where\nappropriate, measures to prevent **_, detect,_**\n**_respond to, resolve_** and control for attacks\ntrying to manipulate the training dataset\n(\u2018data poisoning\u2019), **_or pre-trained_**\n**_components used in training (\u2018model_**\n**_poisoning\u2019) ,_** inputs designed to cause the\nmodel to make a mistake (\u2018adversarial\nexamples\u2019 **_or \u2018model evasion\u2019_** ),\n**_confidentiality attacks_** or model flaws **_,_**\n**_which could lead to harmful decisionmaking_** .", "**Article 16 \u2013 paragraph 1 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) ensure that their high-risk genai systems\nare compliant with the requirements set out\n\n\n(a) ensure that their high-risk genai systems\nare compliant with the requirements set out\n\n\n-----\n\nin Chapter 2 of this Title; in Chapter 2 of this Title **_before placing_**\n**_them on the market or putting them into_**\n**_service_** ;", "**Article 16 \u2013 paragraph 1 \u2013 point a a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(a a) indicate their name, registered trade_**\n**_name or registered trade mark, and their_**\n**_address and contact information on the_**\n**_high-risk genai system or, where that is not_**\n**_possible, on its accompanying_**\n**_documentation, as appropriate;_**", "**Article 16 \u2013 paragraph 1 \u2013 point a c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(a c) provide specifications for the input_**\n**_data, or any other relevant information in_**\n**_terms of the datasets used, including their_**\n**_limitation and assumptions, taking into_**\n**_account the intended purpose and the_**\n**_foreseeable and reasonably foreseeable_**\n**_misuses of the genai system;_**\n\n\n-----", "**Article 16 \u2013 paragraph 1 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) when under their control, keep the\nlogs automatically generated by their highrisk genai systems;\n\n\n(d) when under their control, keep the\nlogs automatically generated by their highrisk genai systems **_that are required for_**\n**_ensuring and demonstrating compliance_**\n**_with this Regulation, in accordance with_**\n**_Article 20_** ;", "**Article 16 \u2013 paragraph 1 \u2013 point e**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(e) ensure that the high-risk genai system\nundergoes the relevant conformity\nassessment procedure, prior to its placing\non the market or putting into service;\n\n\n(e) ensure that the high-risk genai system\nundergoes the relevant conformity\nassessment procedure, prior to its placing\non the market or putting into service **_, in_**\n**_accordance with Article 43_** ;", "**Article 16 \u2013 paragraph 1 \u2013 point g**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(g) take the necessary corrective actions **_,_**\n**_if the high-risk genai system is not in_**\n**_conformity with the requirements set out_**\n**_in Chapter 2 of this Title_** ;\n\n\n(g) take the necessary corrective actions\n**_as referred to in Article 21 and provide_**\n**_information in that regard_** ;", "**Article 16 \u2013 paragraph 1 \u2013 point h**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(h)_** **_inform the national competent_**\n**_authorities of the Member States in which_**\n**_they made the genai system available or put_**\n**_it into service and, where applicable, the_**\n**_notified body of the non-compliance and_**\n**_of any corrective actions taken;_**\n\n\n**_deleted_**", "**Article 16 \u2013 paragraph 1 \u2013 point j**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(j) upon request of a national **_competent_**\nauthority, demonstrate the conformity of\nthe high-risk genai system with the\nrequirements set out in Chapter 2 of this\nTitle.\n\n(j) upon **_a reasoned_** request of a national\n**_supervisory_** authority, demonstrate the\nconformity of the high-risk genai system with\nthe requirements set out in Chapter 2 of\nthis Title.", "**Article 17 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nProviders of high-risk genai systems\nshall **_put_** a quality management system in\nplace that ensures compliance with this\nRegulation.\n\n**_That system_** shall be\ndocumented in a systematic and orderly\nmanner in the form of written policies,\nprocedures **_and_** instructions, and shall\ninclude at least the following aspects:\n\n\n1.\n\nProviders of high-risk genai systems\nshall **_have_** a quality management system in\nplace that ensures compliance with this\nRegulation.\n\n**_It_** shall be documented in a\nsystematic and orderly manner in the form\nof written policies, procedures **_or_**\ninstructions, and **_can be incorporated into_**\n**_an existing quality management system_**\n**_under Union sectoral legislative acts.\n\nIt_**\n\n\n-----\n\nshall include at least the following aspects:", "**Article 17 \u2013 paragraph 1 \u2013 point e**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(e) technical specifications, including\nstandards, to be applied and, where the\nrelevant harmonised standards are not\napplied in full, the means to be used to\nensure that the high-risk genai system\ncomplies with the requirements set out in\nChapter 2 of this Title;\n\n\n(e) technical specifications, including\nstandards, to be applied and, where the\nrelevant harmonised standards are not\napplied in full, **_or do not cover all of the_**\n**_relevant requirements,_** the means to be\nused to ensure that the high-risk genai system\ncomplies with the requirements set out in\nChapter 2 of this Title;", "**Article 17 \u2013 paragraph 1 \u2013 point f**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(f) systems and procedures for data\nmanagement, including data collection,\ndata analysis, data labelling, data storage,\ndata filtration, data mining, data\naggregation, data retention and any other\noperation regarding the data that is\nperformed before and for the purposes of\nthe placing on the market or putting into\n\n\n(f) systems and procedures for data\nmanagement, including **_data acquisition_**\ndata collection, data analysis, data\nlabelling, data storage, data filtration, data\nmining, data aggregation, data retention\nand any other operation regarding the data\nthat is performed before and for the\npurposes of the placing on the market or\nputting into **_service of_** high-risk genai\n\n\n-----\n\nservice of high-risk genai systems; systems;", "**Article 17 \u2013 paragraph 1 \u2013 point j**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(j) the handling of communication with\n**_national competent authorities,_** competent\nauthorities, including sectoral ones **_,_**\n**_providing or supporting the access to data,_**\n**_notified bodies, other operators,_**\n**_customers or other interested parties_** ;\n\n\n(j) the handling of communication with\n**_relevant_** competent authorities, including\nsectoral ones;", "**Article 17 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe implementation of aspects\nreferred to in paragraph 1 shall be\nproportionate to the size of the provider\u2019s\norganisation.\n\n2.\n\nThe implementation of aspects\nreferred to in paragraph 1 shall be\nproportionate to the size of the provider\u2019s\norganisation.\n\n**_Providers shall in any event_**\n**_respect the degree of rigour and the level_**\n**_of protection required to ensure_**\n**_compliance of their genai systems with this_**\n**_Regulation._**", "**Article 19**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 19_** **_deleted_**\n\n**_Conformity assessment_**\n\n**_1._** **_Providers of high-risk genai systems_**\n**_shall ensure that their systems undergo_**\n**_the relevant conformity assessment_**\n**_procedure in accordance with Article 43,_**\n**_prior to their placing on the market or_**\n**_putting into service.\n\nWhere the_**\n**_compliance of the genai systems with the_**\n**_requirements set out in Chapter 2 of this_**\n**_Title has been demonstrated following_**\n**_that conformity assessment, the providers_**\n**_shall draw up an EU declaration of_**\n**_conformity in accordance with Article 48_**\n**_and affix the CE marking of conformity_**\n\n\n-----\n\n**_in accordance with Article 49._**\n\n**_2._** **_For high-risk genai systems referred to_**\n**_in point 5(b) of Annex III that are placed_**\n**_on the market or put into service by_**\n**_providers that are credit institutions_**\n**_regulated by Directive 2013/36/EU, the_**\n**_conformity assessment shall be carried_**\n**_out as part of the procedure referred to in_**\n**_Articles 97 to101 of that Directive._**", "**Article 20 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nProviders of high-risk genai systems\nshall keep the logs automatically generated\nby their high-risk genai systems, to the extent\nsuch logs are under their control **_by virtue_**\n**_of a contractual arrangement with the_**\n**_user or otherwise by law._** The logs shall be\nkept for a period **_that is_** appropriate **_in the_**\n**_light of_** the intended purpose of high-risk\ngenai system **_and applicable legal obligations_**\n**_under Union or national law_** .\n\n1.\n\nProviders of high-risk genai systems\nshall keep the logs automatically generated\nby their high-risk genai systems, to the extent\nsuch logs are under their control **_. Without_**\n**_prejudice to applicable Union or national_**\n**_law,_** the logs shall be kept for a period **_of at_**\n**_least 6 months.\n\nThe retention period shall_**\n**_be in accordance with industry standards_**\n**_and_** appropriate **_to_** the intended purpose of\nhigh-risk genai system.", "**Article 21 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nProviders of high-risk genai systems which\nconsider or have reason to consider that a\nhigh-risk genai system which they have\nplaced on the market or put into service is\nnot in conformity with this Regulation\nshall immediately take the necessary\ncorrective actions to bring that system into\nconformity, to withdraw it or to recall it, as\nappropriate.\n\n**_They shall inform the_**\n**_distributors of the high-risk genai system in_**\n**_question and, where applicable, the_**\n**_authorised representative and importers_**\n\n\nProviders of high-risk genai systems which\nconsider or have reason to consider that a\nhigh-risk genai system which they have\nplaced on the market or put into service is\nnot in conformity with this Regulation\nshall immediately take the necessary\ncorrective actions to bring that system into\nconformity, to withdraw it **_, to disable it_** or\nto recall it, as appropriate.\n\n-----\n\n**_accordingly._**\n\n**_In the cases referred to in the first_**\n**_paragraph, providers shall immediately_**\n**_inform:_**\n\n**_a.\n\nthe distributors;_**\n\n**_b.\n\nthe importers;_**\n\n**_c.\n\nthe national competent authorities of_**\n**_the Member States in which they made the_**\n**_AI system available or put it into service;_**\n**_and_**\n\n**_d.\n\nwhere possible, the deployer._**", "**Article 21 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_The providers shall also inform the_**\n**_authorised representative, if one was_**\n**_appointed in accordance with Article 25,_**\n**_and the notified body if the high-risk AI_**\n**_system had to undergo a third-party_**\n**_conformity assessment in accordance with_**\n**_Article 43.\n\nWhere applicable, they shall_**\n**_also investigate the causes in_**\n**_collaboration with the deployer._**", "**Article 22 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nWhere the high-risk genai system presents a\nrisk within the meaning of Article 65(1)\nand **_that risk is known to_** the provider of\nthe system, that provider shall immediately\ninform the national **_competent_** authorities\nof the Member States in which it made the\nsystem available and, where applicable, the\nnotified body that issued a certificate for\nthe high-risk genai system, in particular of the\nnon-compliance and of any corrective\n\n\nWhere the high-risk genai system presents a\nrisk within the meaning of Article 65(1)\nand the provider of the system **_becomes_**\n**_aware of that risk_** , that provider shall\nimmediately inform the national\n**_supervisory_** authorities of the Member\nStates in which it made the system\navailable and, where applicable, the\nnotified body that issued a certificate for\nthe high-risk genai system, in particular **_the_**\n\n\n-----\n\nactions taken.\n\n**_nature_** of the non-compliance and of any\n**_relevant_** corrective actions taken.", "**Article 22 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_In the cases referred to inthe first_**\n**_paragraph, providers of the high-risk AI_**\n**_system shall immediately inform:_**\n\n**_a) the distributors;_**\n\n**_b) the importers;_**\n\n**_c) the national competent authorities of_**\n**_the Member States in which they made the_**\n**_AI system available or put it into service;_**\n**_and_**\n\n**_d) where possible, the deployers._**", "**Article 23 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nProviders of high-risk genai systems shall,\nupon request by a national competent\nauthority, provide **_that authority_** with all\nthe information and documentation\nnecessary to demonstrate the conformity of\nthe high-risk genai system with the\nrequirements set out in Chapter 2 of this\nTitle, in an official Union language\ndetermined by the Member State\nconcerned.\n\n**_Upon a reasoned request from_**\n**_a national competent authority, providers_**\n**_shall also give that authority access to the_**\n**_logs automatically generated by the highrisk genai system, to the extent such logs are_**\n**_under their control by virtue of a_**\n**_contractual arrangement with the user or_**\n**_otherwise by law._**\n\n\nProviders **_and where applicable, deployers_**\nof high-risk genai systems shall, upon **_a_**\n**_reasoned_** request by a national competent\nauthority **_or where applicable, by the AI_**\n**_Office or the Commission_** , provide **_them_**\nwith all the information and documentation\nnecessary to demonstrate the conformity of\nthe high-risk genai system with the\nrequirements set out in Chapter 2 of this\nTitle, in an official Union language\ndetermined by the Member State\nconcerned.", "**Article 23 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Upon a reasoned request by a national_**\n**_competent authority or, where applicable,_**\n**_by the Commission, providers and, where_**\n**_applicable, deployers shall also give the_**\n**_requesting national competent authority_**\n**_or the Commission, as applicable, access_**\n**_to the logs automatically generated by the_**\n**_high-risk genai system, to the extent such_**\n**_logs are under their control._**", "**Article 23 \u2013 paragraph 1 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Any information obtained by a national_**\n\n\n-----\n\n**_competent authority or by the Commission_**\n**_pursuant to the provisions of this Article_**\n**_shall be considered a trade secret and be_**\n**_treated in compliance with the_**\n**_confidentiality obligations set out in_**\n**_Article 70._**", "**Article 25 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nPrior to making their systems\navailable on the Union market **_, where an_**\n**_importer cannot be identified_** , providers\nestablished outside the Union shall, by\nwritten mandate, appoint an authorised\nrepresentative which is established in the\nUnion.\n\n1.\n\nPrior to making their systems\navailable on the Union market, providers\nestablished outside the Union shall, by\nwritten mandate, appoint an authorised\nrepresentative which is established in the\nUnion.", "**Article 25 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe authorised representative shall\nperform the tasks specified in the mandate\nreceived from the provider.\n\nThe mandate\nshall empower the authorised\nrepresentative to carry out the following\ntasks:\n\n\n2.\n\nThe authorised representative shall\nperform the tasks specified in the mandate\nreceived from the provider.\n\n**_It shall provide_**\n**_a copy of the mandate to the market_**\n**_surveillance authorities upon request, in_**\n**_one of the official languages of the_**\n**_institution of the Union determined by the_**\n**_national competent authority.\n\nFor the_**\n**_purpose of this Regulation,_** the mandate\nshall empower the authorised\nrepresentative to carry out the following\ntasks:", "**Article 25 \u2013 paragraph 2 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) **_keep a copy of_** the EU declaration of\nconformity and the technical\ndocumentation **_at the disposal of the_**\n**_national competent authorities and_**\n**_national authorities referred to in Article_**\n**_63(7)_** ;\n\n\n(a) **_ensure that_** the EU declaration of\nconformity and the technical\ndocumentation **_have been drawn up and_**\n**_that an appropriate conformity_**\n**_assessment procedure has been carried_**\n**_out by the provider_** ;", "**Article 25 \u2013 paragraph 2 \u2013 point a a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(a a) keep at the disposal of the national_**\n**_competent authorities and national_**\n**_authorities referred to in Article 63(7), a_**\n**_copy of the EU declaration of conformity,_**\n**_the technical documentation and, if_**\n\n\n-----\n\n**_applicable, the certificate issued by the_**\n**_notified body;_**", "**Article 25 \u2013 paragraph 2 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) provide a national competent\nauthority, upon a reasoned request, with all\nthe information and documentation\nnecessary to demonstrate the conformity of\na high-risk genai system with the\nrequirements set out in Chapter 2 of this\nTitle, including access to the logs\nautomatically generated by the high-risk genai\nsystem to the extent such logs are under the\ncontrol of the provider **_by virtue of a_**\n**_contractual arrangement with the user or_**\n**_otherwise by law_** ;\n\n\n(b) provide a national competent\nauthority, upon a reasoned request, with all\nthe information and documentation\nnecessary to demonstrate the conformity of\na high-risk genai system with the\nrequirements set out in Chapter 2 of this\nTitle, including access to the logs\nautomatically generated by the high-risk genai\nsystem to the extent such logs are under the\ncontrol of the provider;", "**Article 25 \u2013 paragraph 2 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) cooperate with **_competent_** national\nauthorities, upon a reasoned request, on\nany action the **_latter_** takes **_in relation_** to the\nhigh-risk genai system **_._**\n\n\n(c) cooperate with national **_supervisory_**\nauthorities, upon a reasoned request, on\nany action the **_authority_** takes to **_reduce_**\n**_and mitigate the risks posed by_** the highrisk genai system **_;_**", "**Article 25 \u2013 paragraph 2 \u2013 point c a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(c a) where applicable, comply with the_**\n**_registration obligations referred in Article_**\n**_51, or, if the registration is carried out by_**\n**_the provider itself, ensure that the_**\n\n\n-----\n\n**_information referred to in point 3 of_**\n**_Annex VIII is correct._**", "**Article 25 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_The authorised representative shall_**\n**_be mandated to be addressed, in addition_**\n**_to or instead of the provider, by, in_**\n**_particular, the national supervisory_**\n**_authority or the national competent_**\n**_authorities, on all issues related to_**\n**_ensuring compliance with this Regulation._**", "**Article 25 \u2013 paragraph 2 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 b._** **_The authorised representative shall_**\n**_terminate the mandate if it considers or_**\n**_has reason to consider that the provider_**\n**_acts contrary to its obligations under this_**\n**_Regulation.\n\nIn such a case, it shall also_**\n**_immediately inform the national_**\n**_supervisory authority of the Member State_**\n**_in which it is established, as well as,_**\n**_where applicable, the relevant notified_**\n**_body, about the termination of the_**\n**_mandate and the reasons thereof._**", "**Article 26 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nBefore placing a high-risk genai system\non the market, importers of such system\n\n\n1.\n\nBefore placing a high-risk genai system\non the market, importers of such system\nshall ensure that **_such a system is in_**\n\n\n-----\n\nshall ensure that: **_conformity with this Regulation by_**\n**_ensuring that_** :", "**Article 26 \u2013 paragraph 1 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) the **_appropriate_** conformity\nassessment procedure has been carried out\nby the provider of that genai system\n\n\n(a) the **_relevant_** conformity assessment\nprocedure **_referred to in Article 43_** has\nbeen carried out by the provider of that genai\nsystem", "**Article 26 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWhere an importer considers or has\nreason to consider that a high-risk genai\n\n\n2.\n\nWhere an importer considers or has\nreason to consider that a high-risk genai\n\n\n-----\n\nsystem is not in conformity with this\nRegulation, it shall not place that system\non the market until that genai system has been\nbrought into conformity.\n\nWhere the highrisk genai system presents a risk within the\nmeaning of Article 65(1), the importer\nshall inform the provider of the genai system\nand the market surveillance authorities to\nthat effect.\n\nsystem is not in conformity with this\nRegulation, **_or is counterfeit, or_**\n**_accompanied by falsified documentation_** it\nshall not place that system on the market\nuntil that genai system has been brought into\nconformity.\n\nWhere the high-risk genai system\npresents a risk within the meaning of\nArticle 65(1), the importer shall inform the\nprovider of the genai system and the market\nsurveillance authorities to that effect.", "**Article 26 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nImporters shall indicate their name,\nregistered trade name or registered trade\nmark, and the address at which they can be\ncontacted on the high-risk genai system **_or,_**\n**_where that is not possible,_** on its packaging\nor its accompanying documentation, **_as_**\napplicable.\n\n3.\n\nImporters shall indicate their name,\nregistered trade name or registered trade\nmark, and the address at which they can be\ncontacted on the high-risk genai system **_and_**\non its packaging or its accompanying\ndocumentation, **_where_** applicable.", "**Article 26 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nImporters shall provide national\ncompetent authorities, upon a reasoned\nrequest, with all necessary information and\ndocumentation to demonstrate the\nconformity of a high-risk genai system with\nthe requirements set out in Chapter 2 of\nthis Title in a language which can be easily\nunderstood by **_that national competent_**\n**_authority_** , including access to the logs\nautomatically generated by the high-risk genai\nsystem to the extent such logs are under the\ncontrol of the provider **_by virtue of a_**\n**_contractual arrangement with the user or_**\n**_otherwise by law_** .\n\n**_They shall also_**\n**_cooperate with those authorities on any_**\n\n\n5.\n\nImporters shall provide national\ncompetent authorities, upon a reasoned\nrequest, with all **_the_** necessary information\nand documentation to demonstrate the\nconformity of a high-risk genai system with\nthe requirements set out in Chapter 2 of\nthis Title in a language which can be easily\nunderstood by **_them_** , including access to\nthe logs automatically generated by the\nhigh-risk genai system to the extent such logs\nare under the control of the provider **_in_**\n**_accordance with Article 20_** .\n\n-----\n\n**_action national competent authority takes_**\n**_in relation to that system._**", "**Article 27 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nBefore making a high-risk genai system\navailable on the market, distributors shall\nverify that the high-risk genai system bears\nthe required CE conformity marking, that it\nis accompanied by the required\ndocumentation and instruction of use, and\nthat the provider and the importer of the\nsystem, as applicable, have complied with\n**_the_** obligations set out in this Regulation.\n\n1.\n\nBefore making a high-risk genai system\navailable on the market, distributors shall\nverify that the high-risk genai system bears\nthe required CE conformity marking, that it\nis accompanied by the required\ndocumentation and instruction of use, and\nthat the provider and the importer of the\nsystem, as applicable, have complied with\n**_their_** obligations set out in this Regulation\n**_in Articles 16 and 26 respectively_** .", "**Article 27 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWhere a distributor considers or has\nreason to consider that a high-risk genai\nsystem is not in conformity with the\nrequirements set out in Chapter 2 of this\nTitle, it shall not make the high-risk genai\nsystem available on the market until that\n\n\n2.\n\nWhere a distributor considers or has\nreason to consider **_, on the basis of the_**\n**_information in its possession_** that a highrisk genai system is not in conformity with\nthe requirements set out in Chapter 2 of\nthis Title, it shall not make the high-risk genai\n\n\n-----\n\nsystem has been brought into conformity\nwith those requirements.\n\nFurthermore,\nwhere the system presents a risk within the\nmeaning of Article 65(1), the distributor\nshall inform the provider or the importer of\nthe system, as applicable, to that effect.\n\nsystem available on the market until that\nsystem has been brought into conformity\nwith those requirements.\n\nFurthermore,\nwhere the system presents a risk within the\nmeaning of Article 65(1), the distributor\nshall inform the provider or the importer of\nthe system, **_the relevant national_**\n**_competent authority,_** as applicable, to that\neffect.", "**Article 27 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nA distributor that considers or has\nreason to consider that a high-risk genai\nsystem which it has made available on the\nmarket is not in conformity with the\nrequirements set out in Chapter 2 of this\nTitle shall take the corrective actions\nnecessary to bring that system into\nconformity with those requirements, to\nwithdraw it or recall it or shall ensure that\nthe provider, the importer or any relevant\noperator, as appropriate, takes those\ncorrective actions.\n\nWhere the high-risk genai\nsystem presents a risk within the meaning\nof Article 65(1), the distributor shall\nimmediately inform the national competent\nauthorities of the Member States in which\nit has made the product available to that\neffect, giving details, in particular, of the\nnon-compliance and of any corrective\nactions taken.\n\n4.\n\nA distributor that considers or has\nreason to consider **_, on the basis of the_**\n**_information in its possession,_** that a highrisk genai system which it has made available\non the market is not in conformity with the\nrequirements set out in Chapter 2 of this\nTitle shall take the corrective actions\nnecessary to bring that system into\nconformity with those requirements, to\nwithdraw it or recall it or shall ensure that\nthe provider, the importer or any relevant\noperator, as appropriate, takes those\ncorrective actions.\n\nWhere the high-risk genai\nsystem presents a risk within the meaning\nof Article 65(1), the distributor shall\nimmediately inform the **_provider or_**\n**_importer of the system and the_** national\ncompetent **_authorities_** of the Member\nStates in which it has made the product\navailable to that effect, giving details, in\nparticular, of the non-compliance and of\nany corrective actions taken.", "**Article 27 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n5.\n\nUpon a reasoned request from a 5.\n\nUpon a reasoned request from a\n\n\n-----\n\nnational competent authority, distributors\nof high-risk genai systems shall provide that\nauthority with all the information and\ndocumentation necessary to demonstrate\nthe conformity of a high-risk system with\nthe requirements set out in Chapter 2 of\nthis Title.\n\n**_Distributors shall also cooperate_**\n**_with that national competent authority on_**\n**_any action taken by that authority._**\n\n\nnational competent authority, distributors\nof **_the_** high-risk genai system shall provide\nthat authority with all the information and\ndocumentation **_in their possession or_**\n**_available to them, in accordance with the_**\n**_obligations of distributors as outlined in_**\n**_paragraph 1, that are_** necessary to\ndemonstrate the conformity of a high-risk\nsystem with the requirements set out in\nChapter 2 of this Title.", "**Article 28 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nAny distributor, importer, **_user_** or\nother third-party shall be considered a\nprovider for the purposes of this\nRegulation and shall be subject to the\nobligations of the provider under Article\n\n\n1.\n\nAny distributor, importer, **_deployer_**\nor other third-party shall be considered a\nprovider **_of a high-risk genai system_** for the\npurposes of this Regulation and shall be\nsubject to the obligations of the provider\n\n\n-----\n\n16, in any of the following circumstances: under Article 16, in any of the following\ncircumstances:", "**Article 28 \u2013 paragraph 1 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) they **_place_** on the market or put into\nservice **_a high-risk genai system under their_**\n**_name or trademark;_**\n\n\n(a) they **_put their name or trademarkt_**\n**_on a high-risk genai system already placed_**\non the market or put into service **_;_**", "**Article 28 \u2013 paragraph 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) they **_modify the intended purpose of_**\na high-risk genai system already placed on the\nmarket or put into service;\n\n\n(b) they **_make a substantial_**\n**_modification to_** a high-risk genai system **_that_**\n**_has_** already **_been_** placed on the market or\n**_has already been_** put into service **_and in a_**\n**_way that it remains a high-risk genai system_**\n**_in accordance with Article 6_** ;", "**Article 28 \u2013 paragraph 1 \u2013 point b a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(b a) they make a substantial_**\n**_modification to an genai system, including a_**\n**_general purpose genai system, which has not_**\n**_been classified as high-risk and has_**\n**_already been placed on the market or put_**\n**_into service in such manner that the AI_**\n**_system becomes a high risk genai system in_**\n**_accordance with Article 6_**", "**Article 28 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWhere the circumstances referred to\nin paragraph 1, point **_(b) or (c),_** occur, the\nprovider that initially placed the **_high-risk_**\ngenai system on the market or put it into\nservice shall no longer be considered a\nprovider for the purposes of this\nRegulation.\n\n2.\n\nWhere the circumstances referred to\nin paragraph 1, point **_(a) to (ba)_** occur, the\nprovider that initially placed the genai system\non the market or put it into service shall no\nlonger be considered a provider **_of that_**\n**_specific genai system_** for the purposes of this\nRegulation.\n\n**_This former provider shall_**\n**_provide the new provider with the_**\n**_technical documentation and all other_**\n**_relevant and reasonably expected_**\n**_information capabilities of the genai system,_**\n**_technical access or other assistance based_**\n**_on the generally acknowledged state of_**\n**_the art that are required for the fulfilment_**\n**_of the obligations set out in this_**\n**_Regulation._**\n\n**_This paragraph shall also apply to_**\n**_providers of foundation models as defined_**\n**_in Article 3 when the foundation model is_**\n**_directly integrated in an high-risk AI_**\n**_system._**", "**Article 28 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_The provider of a high risk AI_**\n**_system and the third party that supplies_**\n**_tools, services, components or processes_**\n**_that are used or integrated in the high risk_**\n**_AI system shall, by written agreement_**\n**_specify the information, capabilities,_**\n**_technical access, and or other assistance,_**\n**_based on the generally acknowledged state_**\n**_of the art, that the third party is required_**\n**_to provide in order to enable the provider_**\n**_of the high risk genai system to fully comply_**\n**_with the obligations under this_**\n**_Regulation._**\n\n\n-----\n\n**_The Commission shall develop and_**\n**_recommend non-binding model_**\n**_contractual terms between providers of_**\n**_high-risk genai systems and third parties that_**\n**_supply tools, services, components or_**\n**_processes that are used or integrated in_**\n**_high-risk genai systems in order to assist_**\n**_both parties in drafting and negotiating_**\n**_contracts with balanced contractual rights_**\n**_and obligations, consistent with each_**\n**_party\u2019s level of control.\n\nWhen developing_**\n**_non-binding model contractual terms, the_**\n**_Commission shall take into account_**\n**_possible contractual requirements_**\n**_applicable in specific sectors or business_**\n**_cases.\n\nThe non-binding contractual terms_**\n**_shall be published and be available free of_**\n**_charge in an easily usable electronic_**\n**_format on the genai Office\u2019s website._**", "**Article 28 \u2013 paragraph 2 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 b._** **_For the purposes of this Article,_**\n**_trade secrets shall be preserved and shall_**\n**_only be disclosed provided that all specific_**\n**_necessary measures pursuant to Directive_**\n**_(EU) 2016/943 are taken in advance to_**\n**_preserve their confidentiality, in_**\n**_particular with respect to third parties._**\n**_Where necessary, appropriate technical_**\n**_and organizational arrangements can be_**\n**_agreed to protect intellectual property_**\n**_rights or trade secrets._**", "**Article 28 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 28 a_**\n\n\n-----\n\n**_Unfair contractual terms unilaterally_**\n**_imposed on an SME or startup_**\n\n**_1.\n\nA contractual term concerning the_**\n**_supply of tools, services, components or_**\n**_processes that are used or integrated in a_**\n**_high risk genai system or the remedies for_**\n**_the breach or the termination of related_**\n**_obligations which has been unilaterally_**\n**_imposed by an enterprise on a SME or_**\n**_startup shall not be binding on the latter_**\n**_enterprise if it is unfair._**\n\n**_2.\n\nA contractual term is not to be_**\n**_considered unfair where it arises from_**\n**_applicable Union law._**\n\n**_3.\n\nA contractual term is unfair if it is of_**\n**_such a nature that it objectively impairs_**\n**_the ability of the party upon whom the_**\n**_term has been unilaterally imposed to_**\n**_protect its legitimate commercial interest_**\n**_in the information in question or its use_**\n**_grossly deviates from good commercial_**\n**_practice in the supply of tools, services,_**\n**_components or processes that are used or_**\n**_integrated in a high-risk genai system,_**\n**_contrary to good faith and fair dealing or_**\n**_creates a significant imbalance between_**\n**_the rights and the obligations of the_**\n**_parties in the contract.\n\nA contractual term_**\n**_is also unfair if it has the effect of shifting_**\n**_penalties referred to in Article 71 or_**\n**_associated litigation costs across parties to_**\n**_the contract, as referred to in Article_**\n**_71(8)._**\n\n**_4.\n\nA contractual term is unfair for the_**\n**_purposes of this Article if its object or_**\n**_effect is to:_**\n\n**_(a) exclude or limit the liability of the_**\n**_party that unilaterally imposed the term_**\n**_for intentional acts or gross negligence;_**\n\n**_(b) exclude the remedies available to the_**\n**_party upon whom the term has been_**\n**_unilaterally imposed in the case of nonperformance of contractual obligations or_**\n**_the liability of the party that unilaterally_**\n**_imposed the term in the case of a breach_**\n**_of those obligations;_**\n\n**_(c) give the party that unilaterally imposed_**\n\n\n-----\n\n**_the term the exclusive right to determine_**\n**_whether the technical documentation,_**\n**_information supplied are in conformity_**\n**_with the contract or to interpret any term_**\n**_of the contract._**\n\n**_5.\n\nA contractual term shall be considered_**\n**_to be unilaterally imposed within the_**\n**_meaning of this Article if it has been_**\n**_supplied by one contracting party and the_**\n**_other contracting party has not been able_**\n**_to influence its content despite an attempt_**\n**_to negotiate it.\n\nThe contracting party that_**\n**_supplied a contractual term shall bears_**\n**_the burden of proving that that term has_**\n**_not been unilaterally imposed._**\n\n**_6.\n\nWhere the unfair contractual term is_**\n**_severable from the remaining terms of the_**\n**_contract, those remaining terms shall_**\n**_remain binding.\n\nThe party that supplied_**\n**_the contested term shall not argue that the_**\n**_term is an unfair term._**\n\n**_7.\n\nThis Article shall apply to all new_**\n**_contracts entered into force after ... [date_**\n**_of entry into force of this Regulation]._**\n**_Businesses shall review existing_**\n**_contractual obligations that are subject to_**\n**_this Regulation by \u2026[three years after the_**\n**_date of entry into force of this_**\n**_Regulation]._**\n\n**_8.\n\nGiven the rapidity in which innovations_**\n**_occur in the markets, the list of unfair_**\n**_contractual terms within Article 28a shall_**\n**_be reviewed regularly by the Commission_**\n**_and be updated to new business practices_**\n**_if necessary._**", "**Article 28 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 28 b_**\n\n**_Obligations of the provider of a_**\n**_foundation model_**\n\n\n-----\n\n**_1.\n\nA provider of a foundation model shall,_**\n**_prior to making it available on the market_**\n**_or putting it into service, ensure that it is_**\n**_compliant with the requirements set out in_**\n**_this Article, regardless of whether it is_**\n**_provided as a standalone model or_**\n**_embedded in an genai system or a product, or_**\n**_provided under free and open source_**\n**_licences, as a service, as well as other_**\n**_distribution channels._**\n\n**_2.\n\nFor the purpose of paragraph 1, the_**\n**_provider of a foundation model shall:_**\n\n**_(a) demonstrate through appropriate_**\n**_design, testing and analysis the_**\n**_identification, the reduction and_**\n**_mitigation of reasonably foreseeable risks_**\n**_to health, safety, fundamental rights, the_**\n**_environment and democracy and the rule_**\n**_of law prior and throughout development_**\n**_with appropriate methods such as with the_**\n**_involvement of independent experts, as_**\n**_well as the documentation of remaining_**\n**_non-mitigable risks after development_**\n\n**_(b) process and incorporate only datasets_**\n**_that are subject to appropriate data_**\n**_governance measures for foundation_**\n**_models, in particular measures to_**\n**_examine the suitability of the data sources_**\n**_and possible biases and appropriate_**\n**_mitigation_**\n\n**_(c) design and develop the foundation_**\n**_model in order to achieve throughout its_**\n**_lifecycle appropriate levels of_**\n**_performance, predictability,_**\n**_interpretability, corrigibility, safety and_**\n**_cybersecurity assessed through_**\n**_appropriate methods such as model_**\n**_evaluation with the involvement of_**\n**_independent experts, documented_**\n**_analysis, and extensive testing during_**\n**_conceptualisation, design, and_**\n**_development;_**\n\n**_(d) design and develop the foundation_**\n**_model, making use of applicable_**\n**_standards to reduce energy use, resource_**\n**_use and waste, as well as to increase_**\n**_energy efficiency, and the overall_**\n**_efficiency of the system, whithout_**\n\n\n-----\n\n**_prejudice to relevant existing Union and_**\n**_national law.\n\nThis obligation shall not_**\n**_apply before the standards referred to in_**\n**_Article 40 are published.\n\nFoundation_**\n**_models shall be designed with capabilities_**\n**_enabling the measurement and logging of_**\n**_the consumption of energy and resources,_**\n**_and, where technically feasible, other_**\n**_environmental impact the deployment and_**\n**_use of the systems may have over their_**\n**_entire lifecycle;_**\n\n**_(e) draw up extensive technical_**\n**_documentation and intelligible_**\n**_instructions for use, in order to enable the_**\n**_downstream providers to comply with_**\n**_their obligations pursuant to Articles 16_**\n**_and 28(1);._**\n\n**_(f) establish a quality management system_**\n**_to ensure and document compliance with_**\n**_this Article, with the possibility to_**\n**_experiment in fulfilling this requirement,_**\n\n**_(g) register that foundation model in the_**\n**_EU database referred to in Article 60, in_**\n**_accordance with the instructions outlined_**\n**_in Annex VIII point C._**\n\n**_When fulfilling those requirements, the_**\n**_generally acknowledged state of the art_**\n**_shall be taken into account, including as_**\n**_reflected in relevant harmonised_**\n**_standards or common specifications, as_**\n**_well as the latest assessment and_**\n**_measurement methods, reflected in_**\n**_particular in benchmarking guidance and_**\n**_capabilities referred to in Article 58a;_**\n\n**_3.\n\nProviders of foundation models shall,_**\n**_for a period ending 10 years after their_**\n**_foundation models have been placed on_**\n**_the market or put into service, keep the_**\n**_technical documentation referred to in_**\n**_paragraph 2(e) at the disposal of the_**\n**_national competent authorities_**\n\n**_4.", "Providers of foundation models used in_**\n**_AI systems specifically intended to_**\n**_generate, with varying levels of autonomy,_**\n**_content such as complex text, images,_**\n**_audio, or video (\u201cgenai\u201d) and_**\n**_providers who specialise a foundation_**\n**_model into a genai system, shall_**\n\n\n-----\n\n**_in addition_**\n\n**_a) comply with the transparency_**\n**_obligations outlined in Article 52 (1),_**\n\n**_b) train, and where applicable, design and_**\n**_develop the foundation model in such a_**\n**_way as to ensure adequate safeguards_**\n**_against the generation of content in_**\n**_breach of Union law in line with the_**\n**_generally-acknowledged state of the art,_**\n**_and without prejudice to fundamental_**\n**_rights, including the freedom of_**\n**_expression,_**\n\n**_c) without prejudice to Union or national_**\n**_or Union legislation on copyright,_**\n**_document and make publicly available a_**\n**_sufficiently detailed summary of the use_**\n**_of training data protected under copyright_**\n**_law._**", "**Article 29 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\n**_Users_** of high-risk genai systems shall\nuse such systems in accordance with the\ninstructions of use accompanying the\nsystems, pursuant to paragraphs 2 and 5.\n\n1.\n\n**_Deployers_** of high-risk genai systems\nshall **_take appropriate technical and_**\n**_organisational measures to ensure they_**\nuse such systems in accordance with the\ninstructions of use accompanying the\nsystems, pursuant to paragraphs 2 and 5 **_of_**\n**_this Article_** .", "**Article 29 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 a._** **_To the extent deployers exercise_**\n**_control over the high-risk genai system, they_**\n**_shall_**\n\n\n-----\n\n**_i) implement human oversight according_**\n**_to the requirements laid down in this_**\n**_Regulation_**\n\n**_(ii) ensure that the natural persons_**\n**_assigned to ensure human oversight of the_**\n**_high-risk genai systems are competent,_**\n**_properly qualified and trained, and have_**\n**_the necessary resources in order to ensure_**\n**_the effective supervision of the genai system_**\n**_in accordance with Article 14_**\n\n**_(iii) ensure that relevant and appropriate_**\n**_robustness and cybersecurity measures_**\n**_are regularly monitored for effectiveness_**\n**_and are regularly adjusted or updated._**", "**Article 29 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe obligations in paragraph 1 are\nwithout prejudice to other **_user_** obligations\nunder Union or national law and to the\n**_user\u2019s_** discretion in organising its own\nresources and activities for the purpose of\nimplementing the human oversight\nmeasures indicated by the provider.\n\n2.\n\nThe obligations in paragraph 1 and\n**_1a,_** are without prejudice to other **_deployer_**\nobligations under Union or national law\nand to the **_deployer\u2019s_** discretion in\norganising its own resources and activities\nfor the purpose of implementing the human\noversight measures indicated by the\nprovider.", "**Article 29 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nWithout prejudice to paragraph 1, to\nthe extent the **_user_** exercises control over\nthe input data, that **_user_** shall ensure that\ninput data is relevant in view of the\nintended purpose of the high-risk genai\nsystem.\n\n3.\n\nWithout prejudice to paragraph 1 **_and_**\n**_1a,_** to the extent the **_deployer_** exercises\ncontrol over the input data, that **_deployer_**\nshall ensure that input data is relevant **_and_**\n**_sufficiently representative_** in view of the\nintended purpose of the high-risk genai\nsystem.\n\n-----", "**Article 29 \u2013 paragraph 4 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\n**_Users_** shall monitor the operation of\nthe high-risk genai system on the basis of the\ninstructions of use.\n\nWhen they have\nreasons to consider that the use in\naccordance with the instructions of use\nmay result in the genai system presenting a\nrisk within the meaning of Article 65(1)\nthey shall inform the provider or distributor\nand suspend the use of the system.\n\nThey\nshall also inform the provider or distributor\nwhen they have identified any serious\nincident or any malfunctioning within the\nmeaning of Article 62 and interrupt the use\nof the genai system.\n\nIn case the **_user_** is not\nable to reach the provider, Article 62 shall\napply mutatis mutandis.\n\n4.\n\n**_Deployers_** shall monitor the\noperation of the high-risk genai system on the\nbasis of the instructions of use **_and when_**\n**_relevant, inform providers in accordance_**\n**_with Article 61_** .\n\nWhen they have reasons to\nconsider that the use in accordance with the\ninstructions of use may result in the genai\nsystem presenting a risk within the\nmeaning of Article 65(1) they shall **_,_**\n**_without undue delay,_** inform the provider\nor distributor **_and relevant national_**\n**_supervisory authorities_** and suspend the\nuse of the system.\n\nThey shall also\n**_immediately_** inform **_first_** the provider **_, and_**\n**_then the importer_** or distributor **_and_**\n**_relevant national supervisory authorities_**\nwhen they have identified any serious\nincident or any malfunctioning within the\nmeaning of Article 62 and interrupt the use\nof the genai system.\n\nIf the **_deployer_** is not able\nto reach the provider, Article 62 shall apply\nmutatis mutandis.", "**Article 29 \u2013 paragraph 4 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nFor **_users_** that are credit institutions\nregulated by Directive 2013/36/EU, the\nmonitoring obligation set out in the first\nsubparagraph shall be deemed to be\nfulfilled by complying with the rules on\ninternal governance arrangements,\nprocesses and mechanisms pursuant to\nArticle 74 of that Directive.\n\nFor **_deployers_** that are credit institutions\nregulated by Directive 2013/36/EU, the\nmonitoring obligation set out in the first\nsubparagraph shall be deemed to be\nfulfilled by complying with the rules on\ninternal governance arrangements,\nprocesses and mechanisms pursuant to\nArticle 74 of that Directive.\n\n-----", "**Article 29 \u2013 paragraph 5 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\n**_Users_** of high-risk genai systems shall\nkeep the logs automatically generated by\nthat high-risk genai system, to the extent such\nlogs are under their control.\n\nThe logs shall\nbe kept for a period **_that is_** appropriate **_in_**\n**_the light of_** the intended purpose of the\nhigh-risk genai system **_and applicable legal_**\n**_obligations under Union or national law_** .\n\n5.\n\n**_Deployers_** of high-risk genai systems\nshall keep the logs automatically generated\nby that high-risk genai system, to the extent\n**_that_** such logs are under their control **_and_**\n**_are required for ensuring and_**\n**_demonstrating compliance with this_**\n**_Regulation, for ex-post audits of any_**\n**_reasonably foreseeable malfunction,_**\n**_incidents or misuses of the system, or for_**\n**_ensuring and monitoring for the proper_**\n**_functioning of the system throughout its_**\n**_lifecycle_** .\n\n**_Without prejudice to applicable_**\n**_Union or national law,_** the logs shall be\nkept for a period **_of at least six months._**\n**_The retention period shall be in_**\n**_accordance with industry standards and_**\nappropriate **_to_** the intended purpose of the\nhigh-risk genai system.", "**Article 29 \u2013 paragraph 5 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_Users_** that are credit institutions regulated\nby Directive 2013/36/EU shall maintain the\nlogs as part of the documentation\nconcerning internal governance\narrangements, processes and mechanisms\npursuant to Article 74 of that Directive.\n\n**_Deployers_** that are credit institutions\nregulated by Directive 2013/36/EU shall\nmaintain the logs as part of the\ndocumentation concerning internal\ngovernance arrangements, processes and\nmechanisms pursuant to Article 74 of that\nDirective.", "**Article 29 \u2013 paragraph 5 a (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_5 a._** **_Prior to putting into service or use a_**\n**_high-risk genai system at the workplace,_**\n**_deployers shall consult workers_**\n**_representatives with a view to reaching an_**\n**_agreement in accordance with Directive_**\n**_2002/14/EC and inform the affected_**\n**_employees that they will be subject to the_**\n**_system._**", "**Article 29 \u2013 paragraph 6**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\n**_Users_** of high-risk genai systems shall\nuse the information provided under Article\n13 to comply with their obligation to carry\nout a data protection impact assessment\nunder Article 35 of Regulation (EU)\n2016/679 or Article 27 of Directive (EU)\n2016/680, **_where applicable_** .\n\n6. of highrisk genai systems shall use the information **_Where applicable, deployers_**\nprovided under Article 13 to comply with\ntheir obligation to carry out a data\nprotection impact assessment under Article\n35 of Regulation (EU) 2016/679 or Article\n27 of Directive (EU) 2016/680, **_a summary_**\n**_of which shall be published, having_**\n**_regard to the specific use and the specific_**\n**_context in which the genai system is intended_**\n**_to operate_** .\n\n**_Deployers may revert in part to_**\n**_those data protection impact assessments_**\n**_for fulfilling some of the obligations set_**\n**_out in this article, insofar as the data_**\n**_protection impact assesment fulfill those_**\n\n\n-----\n\n**_obligations._**", "**Article 29 \u2013 paragraph 6 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_6 a._** **_Without prejudice to Article 52,_**\n**_deployers of high-risk genai systems referred_**\n**_to in Annex III, which make decisions or_**\n**_assist in making decisions related to_**\n**_natural persons, shall inform the natural_**\n**_persons that they are subject to the use of_**\n**_the high-risk genai system.\n\nThis information_**\n**_shall include the intended purpose and_**\n**_the type of decisions it makes.\n\nThe_**\n**_deployer shall also inform the natural_**\n**_person about its right to an explanation_**\n**_referred to in Article 68c._**", "**Article 29 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 29 a_**\n\n**_Fundamental rights impact assessment_**\n**_for high-risk genai systems_**\n\n\n-----\n\n**_Prior to putting a high-risk genai system as_**\n**_defined in Article 6(2) into use, with the_**\n**_exception of genai systems intended to be_**\n**_used in area 2 of Annex III, deployers_**\n**_shall conduct an assessment of the_**\n**_systems\u2019 impact in the specific context of_**\n**_use.\n\nThis assessment shall include, at a_**\n**_minimum, the following elements:_**\n\n**_(a) a clear outline of the intended purpose_**\n**_for which the system will be used;_**\n\n**_(b) a clear outline of the intended_**\n**_geographic and temporal scope of the_**\n**_system\u2019s use;_**\n\n**_(c) categories of natural persons and_**\n**_groups likely to be affected by the use of_**\n**_the system;_**\n\n**_(d) verification that the use of the system_**\n**_is compliant with relevant Union and_**\n**_national law on fundamental rights;_**\n\n**_(e) the reasonably foreseeable impact on_**\n**_fundamental rights of putting the highrisk genai system into use;_**\n\n**_(f) specific risks of harm likely to impact_**\n**_marginalised persons or vulnerable_**\n**_groups;_**\n\n**_(g) the reasonably foreseeable adverse_**\n**_impact of the use of the system on the_**\n**_environment;_**\n\n**_(h) a detailed plan as to how the harms_**\n**_and the negative impact on fundamental_**\n**_rights identified will be mitigated._**\n\n**_(j) the governance system the deployer_**\n**_will put in place, including human_**\n**_oversight, complaint-handling and_**\n**_redress._**\n\n**_2.\n\nIf a detailed plan to mitigate the risks_**\n**_outlined in the course of the assessment_**\n**_outlined in paragraph 1 cannot be_**\n**_identified, the deployer shall refrain from_**\n**_putting the high-risk genai system into use_**\n**_and inform the provider and the National_**\n**_supervisory authority without undue_**\n**_delay.\n\nNational supervisory authorities,_**\n**_pursuant to Articles 65 and 67, shall take_**\n**_this information into account when_**\n**_investigating systems which present a risk_**\n\n\n-----\n\n**_at national level._**\n\n**_3.\n\nThe obligation outlined under_**\n**_paragraph 1 applies for the first use of the_**\n**_high-risk genai system.\n\nThe deployer may, in_**\n**_similar cases, draw back on previously_**\n**_conducted fundamental rights impact_**\n**_assessment or existing assessment carried_**\n**_out by providers.\n\nIf, during the use of the_**\n**_high-risk genai system, the deployer_**\n**_considers that the criteria listed in_**\n**_paragraph 1 are not longer met, it shall_**\n**_conduct a new fundamental rights impact_**\n**_assessment._**\n\n**_4.\n\nIn the course of the impact assessment,_**\n**_the deployer, with the exception of SMEs,_**\n**_shall shall notify national supervisory_**\n**_authority and relevant stakeholders and_**\n**_shall, to best extent possible, involve_**\n**_representatives of the persons or groups_**\n**_of persons that are likely to be affected by_**\n**_the high-risk genai system, as identified in_**\n**_paragraph 1, including but not limited to:_**\n**_equality bodies, consumer protection_**\n**_agencies, social partners and data_**\n**_protection agencies, with a view to_**\n**_receiving input into the impact_**\n**_assessment.\n\nThe deployer shall allow a_**\n**_period of six weeks for bodies to respond._**\n**_SMEs may voluntarily apply the_**\n**_provisions laid down in this paragraph._**\n\n**_In the case referred to in Article 47(1),_**\n**_public authorities may be exempted from_**\n**_this obligations._**\n\n**_5.\n\nThe deployer that is a public authority_**\n**_or an undertaking referred to in Article_**\n**_51(1a) (b) shall publish a summary of the_**\n**_results of the impact assessment as part of_**\n**_the registration of use pursuant to their_**\n**_obligation under Article 51(2)._**\n\n**_6.\n\nWhere the deployer is already required_**\n**_to carry out a data protection impact_**\n**_assessment under Article 35 of Regulation_**\n**_(EU) 2016/679 or Article 27 of Directive_**\n**_(EU) 2016/680, the fundamental rights_**\n**_impact assessment referred to in_**\n**_paragraph 1 shall be conducted in_**\n**_conjunction with the data protection_**\n**_impact assessment.\n\nThe data protection_**\n\n\n-----\n\n**_impact assessment shall be published as_**\n**_an addendum._**", "**Article 30 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nEach Member State shall designate\nor establish a notifying authority\nresponsible for setting up and carrying out\nthe necessary procedures for the\nassessment, designation and notification of\nconformity assessment bodies and for their\nmonitoring.\n\n1.\n\nEach Member State shall designate\nor establish a notifying authority\nresponsible for setting up and carrying out\nthe necessary procedures for the\nassessment, designation and notification of\nconformity assessment bodies and for their\nmonitoring.\n\n**_Those procedures shall be_**\n**_developed in cooperation between the_**\n**_notifying authorities of all Member States._**", "**Article 30 \u2013 paragraph 7**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n7.\n\nNotifying authorities shall have a\nsufficient number of competent personnel\nat their disposal for the proper performance\nof their tasks.\n\n7.\n\nNotifying authorities shall have a\nsufficient number of competent personnel\nat their disposal for the proper performance\nof their tasks.\n\n**_Where applicable,_**\n**_competent personnel shall have the_**\n**_necessary expertise, such as a degree in_**\n**_an appropriate legal field, in the_**\n**_supervision of fundamental rights_**\n**_enshrined in the Charter of Fundamental_**\n**_Rights of the European Union._**", "**Article 30 \u2013 paragraph 8**\n\n_Text proposed by the Commission_ _Amendment_\n\n8.\n\nNotifying authorities shall make sure 8.\n\nNotifying authorities shall make sure\n\n\n-----\n\nthat conformity assessments are carried out\nin a proportionate manner, avoiding\nunnecessary burdens for providers and that\nnotified bodies perform their activities\ntaking due account of the size of an\nundertaking, the sector in which it\noperates, its structure and the degree of\ncomplexity of the genai system in question.\n\nthat conformity assessments are carried out\nin a proportionate **_and timely_** manner,\navoiding unnecessary burdens for\nproviders **_,_** and that notified bodies perform\ntheir activities taking due account of the\nsize of an undertaking, the sector in which\nit operates, its structure and the degree of\ncomplexity of the genai system in question.\n\n**_Particular attention shall be paid to_**\n**_minimising administrative burdens and_**\n**_compliance costs for micro and small_**\n**_enterprises as defined in the Annex to_**\n**_Commission Recommendation_**\n**_2003/361/EC._**", "**Article 32 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nNotifying authorities shall notify the\nCommission and the other Member States\nusing the electronic notification tool\ndeveloped and managed by the\nCommission.\n\n2.\n\nNotifying authorities shall notify the\nCommission and the other Member States\nusing the electronic notification tool\ndeveloped and managed by the\nCommission **_of each conformity_**\n**_assessment body referred to in paragraph_**\n**_1_** .", "**Article 32 \u2013 paragraph 3**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nThe notification shall include full\ndetails of the conformity assessment\nactivities, the conformity assessment\nmodule or modules and the artificial\nintelligence technologies concerned.\n\n3.\n\nThe notification **_referred to in_**\n**_paragraph 2_** shall include full details of the\nconformity assessment activities, the\nconformity assessment module or modules\nand the genai technologies\nconcerned **_, as well as the relevant_**\n**_attestation of competence_** .", "**Article 32 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nThe conformity assessment body\nconcerned may perform the activities of a\nnotified body only where no objections are\nraised by the Commission or the other\nMember States within one month of a\nnotification.\n\n4.\n\nThe conformity assessment body\nconcerned may perform the activities of a\nnotified body only where no objections are\nraised by the Commission or the other\nMember States within **_two weeks of the_**\n**_validation of the_** notification **_where it_**\n**_includes an accreditation certificate_**\n**_referred to in Article 31(2), or within two_**\n**_months of the notification where it_**\n**_incudes documentary evidence referred to_**\n**_in Article 31(3_** .", "**Article 32 \u2013 paragraph 4 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_4 a._** **_Where objections are raised, the_**\n**_Commission shall without delay enter into_**\n**_consultation with the relevant Member_**\n**_States and the conformity assessment_**\n**_body.\n\nIn view thereof, the Commission_**\n**_shall decide whether the authorisation is_**\n**_justified or not.\n\nThe Commission shall_**\n**_address its decision to the Member State_**\n**_concerned and the relevant conformity_**\n**_assessment body._**\n\n\n-----", "**Article 33 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nNotified bodies shall satisfy the\norganisational, quality management,\nresources and process requirements that are\nnecessary to fulfil their tasks.\n\n2.\n\nNotified bodies shall satisfy the\norganisational, quality management,\nresources and process requirements that are\nnecessary to fulfil their tasks **_as well as the_**\n**_minimum cybersecurity requirements set_**\n**_out for public administration entities_**\n**_identified as operators of essential_**\n**_services pursuant to Directive (EU_**\n**_2022/2555_** .", "**Article 33 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nNotified bodies shall be independent\nof the provider of a high-risk genai system in\nrelation to which it performs conformity\nassessment activities.\n\nNotified bodies shall\nalso be independent of any other operator\nhaving an economic interest in the highrisk genai system that is assessed, as well as\nof any competitors of the provider.\n\n4.\n\nNotified bodies shall be independent\nof the provider of a high-risk genai system in\nrelation to which it performs conformity\nassessment activities.\n\nNotified bodies shall\nalso be independent of any other operator\nhaving an economic interest in the highrisk genai system that is assessed, as well as\nof any competitors of the provider.\n\n**_This_**\n**_shall not preclude the use of assessed AI_**\n**_systems that are necessary for the_**\n**_operations of the conformity assessment_**\n**_body or the use of such systems for_**\n**_personal purposes._**\n\n\n-----", "**Article 33 \u2013 paragraph 4 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_4 a._** **_A conformity assessment pursuant_**\n**_to paragraph 1 shall be performed by_**\n**_employees of notified bodies who have not_**\n**_provided any other other service related to_**\n**_the matter assessed than the conformity_**\n**_assessment to the provider of a high-risk_**\n**_AI system nor to any legal person_**\n**_connected to that provider in the 12_**\n**_months\u2019 period before the assessment and_**\n**_have committed to not providing them_**\n**_with such services in the 12 month period_**\n**_following the completion of the_**\n**_assessment._**", "**Article 33 \u2013 paragraph 6**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\nNotified bodies shall have\ndocumented procedures in place ensuring\nthat their personnel, committees,\nsubsidiaries, subcontractors and any\nassociated body or personnel of external\nbodies respect the confidentiality of the\ninformation which comes into their\npossession during the performance of\nconformity assessment activities, except\nwhen disclosure is required by law.\n\nThe\nstaff of notified bodies shall be bound to\nobserve professional secrecy with regard to\nall information obtained in carrying out\ntheir tasks under this Regulation, except in\nrelation to the notifying authorities of the\nMember State in which their activities are\ncarried out.\n\n6.\n\nNotified bodies shall have\ndocumented procedures in place ensuring\nthat their personnel, committees,\nsubsidiaries, subcontractors and any\nassociated body or personnel of external\nbodies respect the confidentiality of the\ninformation which comes into their\npossession during the performance of\nconformity assessment activities, except\nwhen disclosure is required by law.\n\nThe\nstaff of notified bodies shall be bound to\nobserve professional secrecy with regard to\nall information obtained in carrying out\ntheir tasks under this Regulation, except in\nrelation to the notifying authorities of the\nMember State in which their activities are\ncarried out.\n\n**_Any information and_**\n**_documentation obtained by notified bodies_**\n**_pursuant to the provisions of this Article_**\n\n\n-----\n\n**_shall be treated in compliance with the_**\n**_confidentiality obligations set out in_**\n**_Article 70._**", "**Article 34 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nActivities may be subcontracted or\ncarried out by a subsidiary only with the\nagreement of the provider.\n\n3.\n\nActivities may be subcontracted or\ncarried out by a subsidiary only with the\nagreement of the provider.\n\n**_Notified bodies_**\n**_shall make a list of their subsidiaries_**\n**_publicly available._**", "**Article 34 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nNotified bodies shall keep at the\ndisposal of the notifying authority the\nrelevant documents concerning the\n**_assessment_** of the qualifications of the\nsubcontractor or the subsidiary and the\nwork carried out by them under this\nRegulation.\n\n4.\n\nNotified bodies shall keep at the\ndisposal of the notifying authority the\nrelevant documents concerning the\n**_verification_** of the qualifications of the\nsubcontractor or the subsidiary and the\nwork carried out by them under this\nRegulation.", "**Article 36 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nWhere a notifying authority has\nsuspicions or has been informed that a\nnotified body no longer meets the\nrequirements laid down in Article 33, or\nthat it is failing to fulfil its obligations, that\nauthority shall without delay investigate\nthe matter with the utmost diligence.\n\nIn\nthat context, it shall inform the notified\nbody concerned about the objections raised\nand give it the possibility to make its views\nknown.\n\nIf the notifying authority comes to\nthe conclusion that the notified body\n**_investigation_** no longer meets the\nrequirements laid down in Article 33 or\nthat it is failing to fulfil its obligations, it\nshall restrict, suspend or withdraw the\nnotification as appropriate, depending on\nthe seriousness of the failure.\n\nIt shall also\nimmediately inform the Commission and\nthe other Member States accordingly.\n\n1.\n\nWhere a notifying authority has\nsuspicions or has been informed that a\nnotified body no longer meets the\nrequirements laid down in Article 33, or\nthat it is failing to fulfil its obligations, that\nauthority shall without delay investigate\nthe matter with the utmost diligence.\n\nIn\nthat context, it shall inform the notified\nbody concerned about the objections raised\nand give it the possibility to make its views\nknown.\n\nIf the notifying authority comes to\nthe conclusion that the notified body no\nlonger meets the requirements laid down in\nArticle 33 or that it is failing to fulfil its\nobligations, it shall restrict, suspend or\nwithdraw the notification as appropriate,\ndepending on the seriousness of the failure.\n\nIt shall also immediately inform the\nCommission and the other Member States\naccordingly.", "**Article 36 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nIn the event of restriction, suspension\nor withdrawal of notification, or where the\nnotified body has ceased its activity, the\nnotifying authority shall take appropriate\nsteps to ensure that the files of that notified\nbody are either taken over by another\nnotified body or kept available for the\nresponsible notifying authorities at their\nrequest.\n\n2.\n\nIn the event of restriction, suspension\nor withdrawal of notification, or where the\nnotified body has ceased its activity, the\nnotifying authority shall take appropriate\nsteps to ensure that the files of that notified\nbody are either taken over by another\nnotified body or kept available for the\nresponsible notifying authorities **_, and_**\n**_market surveillance authority_** at their\nrequest.", "**Article 37 \u2013 paragraph 1**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nThe Commission shall, where\nnecessary, investigate all cases where there\nare reasons to doubt **_whether_** a notified\nbody **_complies with the_** requirements **_laid_**\n**_down in Article 33_** .\n\n1.\n\nThe Commission shall, where\nnecessary, investigate all cases where there\nare reasons to doubt **_the competence of_** a\nnotified body **_or the continued fulfilment_**\n**_by a notified body of the applicable_**\nrequirements **_and responsibilities_** .", "**Article 37 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe Notifying authority shall provide\nthe Commission, on request, with all\nrelevant information relating to the\nnotification of the notified body concerned.\n\n2.\n\nThe Notifying authority shall provide\nthe Commission, on request, with all\nrelevant information relating to the\nnotification **_or the maintenance of the_**\n**_competence_** of the notified body\nconcerned.", "**Article 37 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nThe Commission shall ensure that all\n**_confidential_** information obtained in the\ncourse of its investigations pursuant to this\nArticle is treated confidentially.\n\n3.\n\nThe Commission shall ensure that all\n**_sensitive_** information obtained in the\ncourse of its investigations pursuant to this\nArticle is treated confidentially.", "**Article 37 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nWhere the Commission ascertains\nthat a notified body does not meet or no\nlonger meets the requirements **_laid down in_**\n**_Article 33_** , it shall **_adopt a reasoned_**\n\n\n4.\n\nWhere the Commission ascertains\nthat a notified body does not meet or no\nlonger meets the requirements **_for its_**\n**_notification_** , it shall **_inform_** the notifying\n\n\n-----\n\n**_decision requesting_** the notifying Member\nState to take the necessary corrective\nmeasures, including withdrawal of\nnotification if necessary.\n\nThat\nimplementing act shall be adopted in\naccordance with the examination procedure\nreferred to in Article 74(2).\n\nMember State **_accordingly and request it_**\nto take the necessary corrective measures,\nincluding **_suspension or_** withdrawal of **_the_**\nnotification if necessary.\n\n**_Where the_**\n**_Member State fails to take the necessary_**\n**_corrective measures, the Commission_**\n**_may, by means of an implementing act,_**\n**_suspend, restrict or withdraw the_**\n**_designation._** That implementing act shall\nbe adopted in accordance with the\nexamination procedure referred to in\nArticle 74(2).", "**Article 40 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nHigh-risk genai systems which are in\nconformity with harmonised standards or\nparts thereof the references of which have\nbeen published in the Official Journal of\nthe European Union shall be presumed to\nbe in conformity with the requirements set\nout in Chapter 2 of this Title, to the extent\nthose standards cover those requirements.\n\nHigh-risk genai systems **_and foundation_**\n**_models_** which are in conformity with\nharmonised standards or parts thereof the\nreferences of which have been published in\nthe Official Journal of the European Union\n**_in accordance with Regulation (EU)_**\n**_1025/2012_** shall be presumed to be in\nconformity with the requirements set out in\nChapter 2 of this Title **_or Article 28b_** , to\nthe extent those standards cover those\nrequirements.", "**Article 40 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_The Commission shall issue_**\n**_standardisation requests covering all_**\n**_requirements of this Regulation, in_**\n**_accordance with Article 10 of Regulation_**\n**_EU (No)1025/2012 by... [two months after_**\n**_the date of entry into force of this_**\n**_Regulation].\n\nWhen preparing_**\n**_standardisation request, the Commission_**\n**_shall consult the genai Office and the_**\n**_Advisory Forum;_**", "**Article 40 \u2013 paragraph 1 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_When issuing a standardisation request to_**\n**_European standardisation organisations,_**\n**_the Commission shall specify that_**\n**_standards have to be consistent, including_**\n**_with the sectorial law listed in Annex II,_**\n**_and aimed at ensuring that genai systems or_**\n**_foundation models placed on the market_**\n**_or put into service in the Union meet the_**\n**_relevant requirements laid down in this_**\n**_Regulation;_**", "**Article 40 \u2013 paragraph 1 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_The actors involved in the standardisation_**\n**_process shall take into account the_**\n**_general principles for trustworthy genai set_**\n**_out in Article 4(a), seek to promote_**\n**_investment and innovation in genai as well_**\n**_as competitiveness and growth of the_**\n**_Union market, and contribute to_**\n\n\n-----\n\n**_strengthening global cooperation on_**\n**_standardisation and taking into account_**\n**_existing international standards in the_**\n**_field of genai that are consistent with Union_**\n**_values, fundamental rights and interests,_**\n**_and ensure a balanced representation of_**\n**_interests and effective participation of all_**\n**_relevant stakeholders in accordance with_**\n**_Articles 5, 6, and 7 of Regulation (EU) No_**\n**_1025/2012_**", "**Article 41 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_1._** **_Where harmonised standards_**\n**_referred to in Article 40 do not exist or_**\n**_where the Commission considers that the_**\n**_relevant harmonised standards are_**\n**_insufficient or that there is a need to_**\n**_address specific safety or fundamental_**\n**_right concerns, the Commission may, by_**\n**_means of implementing acts, adopt_**\n**_common specifications in respect of the_**\n**_requirements set out in Chapter 2 of this_**\n**_Title.\n\nThose implementing acts shall be_**\n**_adopted in accordance with the_**\n**_examination procedure referred to in_**\n**_Article 74(2)._**\n\n\n**_deleted_**", "**Article 41 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 a._** **_The Commission may, by means of_**\n**_implementing act adopted in accordance_**\n**_with the examination procedure referred_**\n**_to in Article 74(2) and after consulting the_**\n**_AI Office and the genai Advisory Forum,_**\n**_adopt common specifications in respect of_**\n**_the requirements set out in Chapter 2 of_**\n**_this Title or Article 28b wherein all of the_**\n\n\n-----\n\n**_following conditions are fulfilled:_**\n\n**_(a) there is no reference to harmonised_**\n**_standards already published in the_**\n**_Official Journal of the European Union_**\n**_related to the essential requirement(s),_**\n**_unless the harmonised standard in_**\n**_question is an existing standard that must_**\n**_be revised;_**\n\n**_(b) the Commission has requested one or_**\n**_more European standardisation_**\n**_organisations to draft a harmonised_**\n**_standard for the essential requirement(s)_**\n**_set out in Chapter 2;_**\n\n**_(c) the request referred to in point (b) has_**\n**_not been accepted by any of the European_**\n**_standardisation organisations; or there_**\n**_are undue delays in the establishment of_**\n**_an appropriate harmonised standard; or_**\n**_the standard provided does not satisfy the_**\n**_requirements of the relevant Union law,_**\n**_or does not comply with the request of the_**\n**_Commission._**", "**Article 41 \u2013 paragraph 1 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 c._** **_The Commission shall develop_**\n**_common specifications for the_**\n\n\n-----\n\n**_methodology to fulfil the reporting and_**\n**_documentation requirement on the_**\n**_consumption of energy and resources_**\n**_during development, training and_**\n**_deployment of the high risk genai system._**", "**Article 41 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe Commission, **_when preparing_**\nthe common specifications referred to in\n**_paragraph 1_** , shall **_gather the views of_**\nrelevant bodies or expert groups\nestablished under relevant sectorial Union\nlaw.\n\n2.\n\nThe Commission **_shall,_** **_throughout_**\n**_the whole process of drafting_** the common\nspecifications referred to in **_paragraphs 1a_**\n**_and 1b_** , **_regularly consult the genai Office_**\n**_and the Advisory Forum, the European_**\n**_standardisation organisations and bodies_**\n**_or expert groups established under_**\nrelevant **_sectorial Union law as well as_**\n**_other relevant stakeholders._** **_The_**\n**_Commission shall fulfil the objectives_**\n**_referred to in Article 40 (1c) and duly_**\n**_justify why it decided to resort to common_**\n**_specifications._**\n\n**_Where the Commission intends to adopt_**\n**_common specifications pursuant to_**\n**_paragraph 1a of this Article, it shall also_**\n**_clearly identify the specific fundamental_**\n**_rights concern to be addressed._**\n\n**_When adopting common specifications_**\n**_pursuant to paragraphs 1a and 1b of this_**\n**_Article, the Commission shall take into_**\n**_account the opinion issued by the AI_**\n**_Office referred to in Article 56e(b) of this_**\n**_Regulation.\n\nWhere the Commission_**\n**_decides not to follow the opinion of the AI_**\n**_Office, it shall provide a reasoned_**\n**_explanation to the genai Office._**", "**Article 41 \u2013 paragraph 3**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nHigh-risk genai systems which are in\nconformity with the common specifications\nreferred to in paragraph **_1_** shall be\npresumed to be in conformity with the\nrequirements set out in Chapter 2 of this\nTitle, to the extent those common\nspecifications cover those requirements **_._**\n\n\n3.\n\nHigh-risk genai systems which are in\nconformity with the common specifications\nreferred to in paragraph **_1a and 1b_** shall be\npresumed to be in conformity with the\nrequirements set out in Chapter 2 of this\nTitle, to the extent those common\nspecifications cover those requirements", "**Article 41 \u2013 paragraph 3 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_3 a._** **_Where a harmonised standard is_**\n**_adopted by a European standardisation_**\n**_organisation and proposed to the_**\n**_Commission for the publication of its_**\n**_reference in the Official Journal of the_**\n**_European Union, the Commission shall_**\n**_assess the harmonised standard in_**\n**_accordance with Regulation (EU) No_**\n**_1025/2012.\n\nWhen reference of a_**\n**_harmonised standard is published in the_**\n**_Official Journal of the European Union,_**\n**_the Commission shall repeal acts referred_**\n**_to in paragraph 1 and 1b, or parts thereof_**\n**_which cover the same requirements set_**\n**_out in Chapter 2 of this Title._**", "**Article 41 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nWhere providers do not comply with\nthe common specifications referred to in\nparagraph 1, they shall duly justify that\nthey have adopted technical solutions that\n**_are_** at least equivalent thereto **_._**\n\n\n4.\n\nWhere providers **_of high-risk AI_**\n**_systems_** do not comply with the common\nspecifications referred to in paragraph 1,\nthey shall duly justify that they have\nadopted technical solutions that **_meet the_**\n**_requirements referred to in Chapter II to_**\n**_a level_** at least equivalent thereto **_;_**\n\n\n-----", "**Article 42 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nTaking into account their intended\npurpose, high-risk genai systems that have\nbeen trained and tested on data concerning\nthe specific geographical, behavioural and\nfunctional setting within which they are\nintended to be used shall be presumed to be\nin compliance with the **_requirement_** set out\nin Article 10(4).\n\n1.\n\nTaking into account their intended\npurpose, high-risk genai systems that have\nbeen trained and tested on data concerning\nthe specific geographical, behavioural\n**_contextual_** and functional setting within\nwhich they are intended to be used shall be\npresumed to be in compliance with the\n**_respective requirements_** set out in Article\n10(4).", "**Article 43 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nFor high-risk genai systems listed in\npoint 1 of Annex III, where, in\ndemonstrating the compliance of a highrisk genai system with the requirements set\nout in Chapter 2 of this Title, the provider\nhas applied harmonised standards referred\nto in Article 40, or, where applicable,\ncommon specifications referred to in\nArticle 41, the provider shall **_follow_** one of\nthe following procedures **_:_**\n\n\n1.\n\nFor high-risk genai systems listed in\npoint 1 of Annex III, where, in\ndemonstrating the compliance of a highrisk genai system with the requirements set\nout in Chapter 2 of this Title, the provider\nhas applied harmonised standards referred\nto in Article 40, or, where applicable,\ncommon specifications referred to in\nArticle 41, the provider shall **_opt for_** one of\nthe following procedures **_;_**", "**Article 43 \u2013 paragraph 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) the conformity assessment procedure\nbased on assessment of the quality\nmanagement system and **_assessment_** of the\ntechnical documentation, with the\ninvolvement of a notified body, referred to\nin Annex VII **_._**\n\n\n(b) the conformity assessment procedure\nbased on assessment of the quality\nmanagement system and of the technical\ndocumentation, with the involvement of a\nnotified body, referred to in Annex VII **_;_**", "**Article 43 \u2013 paragraph 1 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_Where,_** in demonstrating the compliance of\na high-risk genai system with the\nrequirements set out in Chapter 2 of this\nTitle, the provider **_has not applied or has_**\n**_applied only in part_** harmonised standards\nreferred to in Article 40, **_or where such_**\n**_harmonised standards_** do not exist and\ncommon specifications referred to in\nArticle 41 are not available **_,_** the provider\n**_shall follow the conformity assessment_**\n**_procedure set out in Annex VII_** .\n\nIn demonstrating the compliance of a highrisk genai system with the requirements set\nout in Chapter 2 of this Title, the provider\n**_shall follow the conformity assessment_**\n**_procedure set out in Annex VII in the_**\n**_following cases:_**\n\n**_(a) where_** harmonised standards referred to\nin Article 40, **_the reference number of_**\n**_which has been published in the Official_**\n**_Journal of the European Union, covering_**\n**_all relevant safety requirements for the AI_**\n**_system,_** do not exist and common\nspecifications referred to in Article 41 are\nnot available **_;_**\n\n**_(b) where the technical specifications_**\n**_referred to in point (a) exist but_** the\nprovider **_has not applied them or has_**\n**_applied them only in part;_**\n\n**_(c) where one or more of the technical_**\n**_specifications referred to in point (a) has_**\n**_been published with a restriction and only_**\n**_on the part of the standard that was_**\n\n\n-----\n\n**_restricted;_**\n\n**_(d) when the provider considers that the_**\n**_nature, design, construction or purpose of_**\n**_the genai system necessitate third party_**\n**_verification, regardless of its risk level_** .", "**Article 43 \u2013 paragraph 1 \u2013 subparagraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nFor the purpose of the conformity\nassessment procedure referred to in Annex\nVII, the provider may choose any of the\nnotified bodies.\n\nHowever, when the system\nis intended to be put into service by law\nenforcement, immigration or asylum\nauthorities as well as EU institutions,\nbodies or agencies, the market surveillance\nauthority referred to in Article 63(5) or (6),\nas applicable, shall act as a notified body.\n\nFor the purpose of **_carrying out_** the\nconformity assessment procedure referred\nto in Annex VII, the provider may choose\nany of the notified bodies.\n\nHowever, when\nthe system is intended to be put into\nservice by law enforcement, immigration\nor asylum authorities as well as EU\ninstitutions, bodies or agencies, the market\nsurveillance authority referred to in Article\n63(5) or (6), as applicable, shall act as a\nnotified body.", "**Article 43 \u2013 paragraph 4 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nHigh-risk genai systems shall undergo a\nnew conformity assessment procedure\nwhenever they are substantially modified,\nregardless of whether the modified system\nis intended to be further distributed or\ncontinues to be used by the current **_user._**\n\n\n4.\n\nHigh-risk genai systems **_that have_**\n**_already been subject to a conformity_**\n**_assessment procedure_** shall undergo a new\nconformity assessment procedure\nwhenever they are substantially modified,\nregardless of whether the modified system\nis intended to be further distributed or\ncontinues to be used by the current\n**_deployer;_**", "**Article 43 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nThe Commission is empowered to\nadopt delegated acts in accordance with\nArticle 73 for the purpose of updating\nAnnexes VI and Annex VII in order to\nintroduce elements of the conformity\nassessment procedures that become\nnecessary in light of technical progress.\n\n5.\n\nThe Commission is empowered to\nadopt delegated acts in accordance with\nArticle 73 for the purpose of updating\nAnnexes VI and Annex VII in order to\nintroduce elements of the conformity\nassessment procedures that become\nnecessary in light of technical progress.\n\n**_When preparing such delegated acts, the_**\n**_Commission shall consult the genai Office_**\n**_and the stakeholders affected;_**", "**Article 43 \u2013 paragraph 6**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\nThe Commission is empowered to\nadopt delegated acts to amend paragraphs 1\nand 2 in order to subject high-risk genai\nsystems referred to in points 2 to 8 of\nAnnex III to the conformity assessment\nprocedure referred to in Annex VII or parts\nthereof.\n\nThe Commission shall adopt such\ndelegated acts taking into account the\neffectiveness of the conformity assessment\nprocedure based on internal control\nreferred to in Annex VI in preventing or\nminimizing the risks to health and safety\nand protection of fundamental rights posed\nby such systems as well as the availability\n\n\n6.\n\nThe Commission is empowered to\nadopt delegated acts to amend paragraphs 1\nand 2 in order to subject high-risk genai\nsystems referred to in points 2 to 8 of\nAnnex III to the conformity assessment\nprocedure referred to in Annex VII or parts\nthereof.\n\nThe Commission shall adopt such\ndelegated acts taking into account the\neffectiveness of the conformity assessment\nprocedure based on internal control\nreferred to in Annex VI in preventing or\nminimizing the risks to health and safety\nand protection of fundamental rights posed\nby such systems as well as the availability\n\n\n-----\n\nof adequate capacities and resources\namong notified bodies.\n\nof adequate capacities and resources\namong notified bodies.\n\n**_When preparing_**\n**_such delegated acts, the Commission shall_**\n**_consult the genai Office and the stakeholders_**\n**_affected;_**", "**Article 44 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nCertificates issued by notified bodies\nin accordance with Annex VII shall be\ndrawn-up in **_an_** official Union **_language_**\ndetermined by the Member State in which\nthe notified body is established or in **_an_**\nofficial Union **_language_** otherwise\nacceptable to the notified body **_._**\n\n\n1.\n\nCertificates issued by notified bodies\nin accordance with Annex VII shall be\ndrawn-up in **_one or several_** official Union\n**_languages_** determined by the Member\nState in which the notified body is\nestablished or in **_one or several_** official\nUnion **_languages_** otherwise acceptable to\nthe notified body **_;_**", "**Article 44 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nCertificates shall be valid for the\nperiod they indicate, which shall not\nexceed **_five_** years.\n\nOn application by the\nprovider, the validity of a certificate may\nbe extended for further periods, each not\nexceeding years, based on a reassessment in accordance with the **_five_**\napplicable conformity assessment\nprocedures **_._**\n\n\n2.\n\nCertificates shall be valid for the\nperiod they indicate, which shall not\nexceed **_four_** years.\n\nOn application by the\nprovider, the validity of a certificate may\nbe extended for further periods, each not\nexceeding years, based on a reassessment in accordance with the **_four_**\napplicable conformity assessment\nprocedures **_;_**", "**Article 44 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n3.\n\nWhere a notified body finds that an 3.\n\nWhere a notified body finds that an\n\n\n-----\n\ngenai system no longer meets the\nrequirements set out in Chapter 2 of this\nTitle, it shall **_, taking account of the_**\n**_principle of proportionality_** , suspend or\nwithdraw the certificate issued or impose\nany restrictions on it, unless compliance\nwith those requirements is ensured by\nappropriate corrective action taken by the\nprovider of the system within an\nappropriate deadline set by the notified\nbody.\n\nThe notified body shall give reasons\nfor its decision **_._**\n\n\ngenai system no longer meets the\nrequirements set out in Chapter 2 of this\nTitle, it shall suspend or withdraw the\ncertificate issued or impose any restrictions\non it, unless compliance with those\nrequirements is ensured by appropriate\ncorrective action taken by the provider of\nthe system within an appropriate deadline\nset by the notified body.\n\nThe notified body\nshall give reasons for its decision **_._**", "**Article 45 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nMember States shall ensure that an appeal\nprocedure against decisions of the notified\nbodies is available to parties having a\nlegitimate interest in that decision **_._**\n\n\nMember States shall ensure that an appeal\nprocedure against decisions of the notified\nbodies **_, including on issued conformity_**\n**_certificates_** is available to parties having a\nlegitimate interest in that decision **_._**", "**Article 46 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nEach notified body shall provide the\nother notified bodies carrying out similar\nconformity assessment activities **_covering_**\n**_the same artificial intelligence_**\n**_technologies_** with relevant information on\nissues relating to negative and, on request,\npositive conformity assessment results **_._**\n\n\n3.\n\nEach notified body shall provide the\nother notified bodies carrying out similar\nconformity assessment activities with\nrelevant information on issues relating to\nnegative and, on request, positive\nconformity assessment results **_._**", "**Article 47 \u2013 paragraph 1**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nBy way of derogation from Article\n43, any **_market surveillance_** authority may\nauthorise the placing on the market or\nputting into service of specific high-risk genai\nsystems within the territory of the Member\nState concerned, for exceptional reasons of\n**_public security or_** the protection of life and\nhealth of persons, environmental protection\nand the protection of **_key industrial and_**\n**_infrastructural assets_** .\n\nThat authorisation\nshall be for a limited period of time, while\nthe necessary conformity assessment\nprocedures are being carried out, and shall\nterminate once those procedures have been\ncompleted.\n\nThe completion of those\nprocedures shall be undertaken without\nundue delay **_._**\n\n\n1.\n\nBy way of derogation from Article\n43, any **_national supervisory_** authority may\n**_request a judicial authority to_** authorise\nthe placing on the market or putting into\nservice of specific high-risk genai systems\nwithin the territory of the Member State\nconcerned, for exceptional reasons of the\nprotection of life and health of persons,\nenvironmental protection and the\nprotection of **_critical infrastructure_** .\n\nThat\nauthorisation shall be for a limited period\nof time, while the necessary conformity\nassessment procedures are being carried\nout, and shall terminate once those\nprocedures have been completed.\n\nThe\ncompletion of those procedures shall be\nundertaken without undue delay **_;_**", "**Article 47 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe authorisation referred to in\nparagraph 1 shall be issued only if the\n**_market surveillance_** authority **_concludes_**\nthat the high-risk genai system complies with\nthe requirements of Chapter 2 of this Title.\n\nThe **_market surveillance_** authority shall\ninform the Commission and the other\nMember States of any authorisation issued\npursuant to paragraph 1 **_._**\n\n\n2.\n\nThe authorisation referred to in\nparagraph 1 shall be issued only if the\n**_national supervisory_** authority **_and judicial_**\n**_authority conclude_** that the high-risk genai\nsystem complies with the requirements of\nChapter 2 of this Title.\n\nThe **_national_**\n**_supervisory_** authority shall inform the\nCommission **_, the genai office,_** and the other\nMember States of any **_request made and_**\n**_any subsequent_** authorisation issued\npursuant to paragraph 1 **_;_**", "**Article 47 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n3.\n\nWhere, within 15 calendar days of 3.\n\nWhere, within 15 calendar days of\n\n\n-----\n\nreceipt of the information referred to in\nparagraph 2, no objection has been raised\nby either a Member State or the\nCommission in respect **_of_** an authorisation\nissued by a **_market surveillance_** authority\nof a Member State in accordance with\nparagraph 1, that authorisation shall be\ndeemed justified **_._**\n\n\nreceipt of the information referred to in\nparagraph 2, no objection has been raised\nby either a Member State or the\nCommission in respect **_to the request of_**\n**_the national supervisory authority for_** an\nauthorisation issued by a **_national_**\n**_supervisory_** authority of a Member State in\naccordance with paragraph 1, that\nauthorisation shall be deemed justified **_;_**", "**Article 47 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nWhere, within 15 calendar days of\nreceipt of the notification referred to in\nparagraph 2, objections are raised by a\nMember State against **_an authorisation_**\nissued by a **_market surveillance_** authority\nof another Member State, or where the\nCommission considers the authorisation to\nbe contrary to Union law or the conclusion\nof the Member States regarding the\ncompliance of the system as referred to in\nparagraph 2 to be unfounded, the\nCommission shall without delay enter into\nconsultation with the relevant Member\nState; the operator(s) concerned shall be\nconsulted and have the possibility to\npresent their views.\n\nIn view thereof, the\nCommission shall decide whether the\nauthorisation is justified or not.\n\nThe\nCommission shall address its decision to\nthe Member State concerned and the\nrelevant operator **_or operators._**\n\n\n4.\n\nWhere, within 15 calendar days of\nreceipt of the notification referred to in\nparagraph 2, objections are raised by a\nMember State against **_a request_** issued by a\n**_national supervisory_** authority of another\nMember State, or where the Commission\nconsiders the authorisation to be contrary\nto Union law or the conclusion of the\nMember States regarding the compliance\nof the system as referred to in paragraph 2\nto be unfounded, the Commission shall\nwithout delay enter into consultation with\nthe relevant Member State **_and the AI_**\n**_Office_** ; the operator(s) concerned shall be\nconsulted and have the possibility to\npresent their views.\n\nIn view thereof, the\nCommission shall decide whether the\nauthorisation is justified or not.\n\nThe\nCommission shall address its decision to\nthe Member State concerned and the\nrelevant operator **_(s);_**", "**Article 47 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nIf the authorisation is considered\nunjustified, this shall be withdrawn by the\n\n\n5.\n\nIf the authorisation is considered\nunjustified, this shall be withdrawn by the\n\n\n-----\n\n**_market surveillance_** authority of the\nMember State concerned **_._**\n\n\n**_national supervisory_** authority of the\nMember State concerned **_;_**", "**Article 48 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nThe provider shall draw up a written\nEU declaration of conformity for each genai\nsystem and keep it at the disposal of the\nnational competent authorities for 10 years\nafter the genai system has been placed on the\nmarket or put into service.\n\n**_The EU_**\n**_declaration of conformity shall identify_**\n**_the genai system for which it has been drawn_**\n**_up._** A copy of the EU declaration of\nconformity shall be **_given to_** the relevant\nnational competent authorities upon\nrequest **_._**\n\n\n1.\n\nThe provider shall draw up a written\n**_machine readable, physical or electronic_**\nEU declaration of conformity for each\n**_high-risk_** genai system and keep it at the\ndisposal of **_the national supervisory_**\n**_authority and_** the national competent\nauthorities for 10 years after the genai **_highrisk_** system has been placed on the market\nor put into service.\n\nA copy of the EU\ndeclaration of conformity shall be\n**_submitted to the national supervisory_**\n**_authority and_** the relevant national\ncompetent authorities upon request **_;_**", "**Article 48 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe EU declaration of conformity\nshall state that the high-risk genai system in\nquestion meets the requirements set out in\nChapter 2 of this Title.\n\nThe EU declaration\nof conformity shall contain the information\nset out in Annex V and shall be translated\ninto an official Union language or\nlanguages required by the Member State(s)\nin which the high-risk genai system is made\navailable **_._**\n\n\n2.\n\nThe EU declaration of conformity\nshall state that the high-risk genai system in\nquestion meets the requirements set out in\nChapter 2 of this Title.\n\nThe EU declaration\nof conformity shall contain the information\nset out in Annex V and shall be translated\ninto an official Union language or\nlanguages required by the Member State(s)\nin which the high-risk genai system is **_placed_**\n**_on the market or_** made available **_;_**", "**Article 48 \u2013 paragraph 3**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nWhere high-risk genai systems are\nsubject to other Union harmonisation\nlegislation which also requires an EU\ndeclaration of conformity, a single EU\ndeclaration of conformity **_shall_** be drawn\nup in respect of all Union legislations\napplicable to the high-risk genai system.\n\nThe\ndeclaration shall contain all the information\nrequired for identification of the Union\nharmonisation legislation to which the\ndeclaration relates.\n\n3.\n\nWhere high-risk genai systems are\nsubject to other Union harmonisation\nlegislation which also requires an EU\ndeclaration of conformity, a single EU\ndeclaration of conformity **_may_** be drawn up\nin respect of all Union legislations\napplicable to the high-risk genai system.\n\nThe\ndeclaration shall contain all the information\nrequired for identification of the Union\nharmonisation legislation to which the\ndeclaration relates.", "**Article 48 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nThe Commission shall be empowered\nto adopt delegated acts in accordance with\nArticle 73 for the purpose of updating the\ncontent of the EU declaration of\nconformity set out in Annex V in order to\nintroduce elements that become necessary\nin light of technical progress **_._**\n\n\n5.\n\n**_After consulting the genai Office,_** the\nCommission shall be empowered to adopt\ndelegated acts in accordance with Article\n73 for the purpose of updating the content\nof the EU declaration of conformity set out\nin Annex V in order to introduce elements\nthat become necessary in light of technical\nprogress **_;_**", "**Article 49 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nThe CE marking shall be affixed\nvisibly, legibly and indelibly for high-risk\ngenai systems **_._** Where that is not possible or\nnot warranted on account of the nature of\nthe high-risk genai system, it shall be affixed\nto the packaging or to the accompanying\ndocumentation, as appropriate.\n\n1.\n\nThe **_physical_** CE marking shall be\naffixed visibly, legibly and indelibly for\nhigh-risk genai systems **_before the high-risk_**\n**_AI system is placed on the market_** Where\nthat is not possible or not warranted on\naccount of the nature of the high-risk genai\nsystem, it shall be affixed to the packaging\nor to the accompanying documentation, as\nappropriate.\n\n**_It may be followed by a_**\n**_pictogram or any other marking_**\n\n\n-----\n\n**_indicating a special risk of use;_**", "**Article 49 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 a._** **_For digital only high-risk AI_**\n**_systems, a digital CE marking shall be_**\n**_used, only if it can be easily accessed via_**\n**_the interface from which the genai system is_**\n**_accessed or via an easily accessible_**\n**_machine-readable code or other electronic_**\n**_means._**", "**Article 49 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nWhere applicable, the CE marking\nshall be followed by the identification\nnumber of the notified body responsible for\nthe conformity assessment procedures set\nout in Article 43.\n\nThe identification\nnumber shall also be indicated in any\npromotional material which mentions that\nthe high-risk genai system fulfils the\nrequirements for CE marking **_._**\n\n\n3.\n\nWhere applicable, the CE marking\nshall be followed by the identification\nnumber of the notified body responsible for\nthe conformity assessment procedures set\nout in Article 43.\n\nThe identification\nnumber **_of the notified body shall be_**\n**_affixed by the body itself or, under its_**\n**_instructions, by the provider\u2019s authorised_**\n**_representative.\n\nThe identification number_**\nshall also be indicated in any promotional\nmaterial which mentions that the high-risk\ngenai system fulfils the requirements for CE\nmarking **_;_**", "**Article 49 \u2013 paragraph 3 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_3 a._** **_Where high-risk genai systems are_**\n**_subject to other Union law which also_**\n\n\n-----\n\n**_provides for the affixing of the CE_**\n**_marking, the CE marking shall indicate_**\n**_that the high-risk genai system also fulfil the_**\n**_requirements of that other law._**", "**Article 50 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nThe provider shall, for a period ending 10\nyears after the genai system has been placed\non the market or put into service **_,_** keep at\nthe disposal of the national competent\nauthorities:\n\n\nThe provider shall, for a period ending 10\nyears **_,_** after the genai system has been placed\non the market or put into service keep at\nthe disposal of the national **_supervisory_**\n**_authority and the national_** competent\nauthorities:", "**Article 51 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nBefore placing on the market or putting\ninto service a high-risk genai system referred\nto in Article 6(2) **_,_** the provider or, where\napplicable, the authorised representative\nshall register that system in the EU\ndatabase referred to in Article 60 **_._**\n\n\nBefore placing on the market or putting\ninto service a high-risk genai system referred\nto in Article 6(2) the provider or, where\napplicable, the authorised representative\nshall register that system in the EU\ndatabase referred to in Article 60 **_, in_**\n**_accordance with Article 60(2);_**", "**Article 51 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Before putting into service or using a_**\n**_high-risk genai system in accordance with_**\n**_Article 6(2), the following categories of_**\n**_deployers shall register the use of that AI_**\n**_system in the EU database referred to in_**\n\n\n-----\n\n**_Article 60:_**\n\n**_a) deployers who are public authorities or_**\n**_Union institutions, bodies, offices or_**\n**_agencies or deployers acting on their_**\n**_behalf;_**\n\n**_b) deployers who are undertakings_**\n**_designated as a gatekeeper under_**\n**_Regulation (EU) 2022/1925._**", "**Article 52 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nProviders shall ensure that genai\nsystems intended to interact with natural\npersons are designed and developed in\nsuch a way that natural **_persons are_**\n**_informed_** that they are interacting with an\ngenai system, unless this is obvious from the\ncircumstances and the context of use.\n\n**_This_**\n**_obligation_** shall not apply to genai systems\nauthorised by law to detect, prevent,\ninvestigate and prosecute criminal\noffences, unless those systems are\navailable for the public to report a criminal\noffence.\n\n1.\n\nProviders shall ensure that genai\nsystems intended to interact with natural\npersons are designed and developed in\nsuch a way that **_the genai system, the provider_**\n**_itself or the user informs the_** natural\n**_person exposed to an genai system_** that they\nare interacting with an genai system **_in a_**\n**_timely, clear and intelligible manner_** ,\nunless this is obvious from the\ncircumstances and the context of use.\n\n**_Where appropriate and relevant, this_**\n**_information_** shall **_also include which_**\n**_functions are genai enabled, if there is_**\n**_human oversight, and who is responsible_**\n**_for the decision-making process, as well_**\n**_as the existing rights and processes that,_**\n**_according to Union and national law,_**\n**_allow natural persons or their_**\n**_representatives to object against the_**\n**_application of such systems to them and to_**\n**_seek judicial redress against decisions_**\n**_taken by or harm caused by genai systems,_**\n**_including their right to seek an_**\n**_explanation.\n\nThis obligation shall_** not\napply to genai systems authorised by law to\ndetect, prevent, investigate and prosecute\ncriminal offences, unless those systems are\navailable for the public to report a criminal\noffence.\n\n-----", "**Article 52 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nUsers of an emotion recognition\nsystem or a biometric categorisation\nsystem shall inform of the operation of the\nsystem the natural persons exposed thereto.\n\nThis obligation shall not apply to genai\nsystems used for biometric categorisation,\nwhich are permitted by law to detect,\nprevent and investigate criminal offences.\n\n2.\n\nUsers of an emotion recognition\nsystem or a biometric categorisation\nsystem **_which is not prohibited pursuant_**\n**_to Article 5_** shall inform **_in a timely, clear_**\n**_and intelligible manner_** of the operation of\nthe system the natural persons exposed\nthereto **_and obtain their consent prior to_**\n**_the processing of their biometric and_**\n**_other personal data in accordance with_**\n**_Regulation (EU) 2016/679, Regulation_**\n**_(EU) 2016/1725 and Directive (EU)_**\n**_2016/280, as applicable_** .\n\nThis obligation\nshall not apply to genai systems used for\nbiometric categorisation, which are\npermitted by law to detect, prevent and\ninvestigate criminal offences.", "**Article 52 \u2013 paragraph 3 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nUsers of an genai system that generates\nor manipulates **_image_** , audio or **_video_**\ncontent that **_appreciably resembles_**\n**_existing persons, objects, places or other_**\n**_entities or events and_** would falsely appear\n**_to a person_** to be authentic or truthful\n(\u2018deep fake\u2019), shall disclose that the content\nhas been artificially generated or\nmanipulated.\n\n3.\n\nUsers of an genai system that generates\nor manipulates **_text_** , audio or **_visual_** content\nthat would falsely appear to be authentic or\ntruthful **_and which features depictions of_**\n**_people appearing to say or do things they_**\n**_did not say or do, without their consent_**\n(\u2018deep fake\u2019), shall disclose **_in an_**\n**_appropriate, timely, clear and visible_**\n**_manner_** that the content has been\nartificially generated or manipulated **_, as_**\n**_well as, whenever possible, the name of_**\n**_the natural or legal person that generated_**\n**_or manipulated it_** .\n\n**_Disclosure shall mean_**\n**_labelling the content in a way that informs_**\n**_that the content is inauthentic and that is_**\n**_clearly visible for the recipient of that_**\n**_content.\n\nTo label the content, users shall_**\n**_take into account the generally_**\n\n\n-----\n\n**_acknowledged state of the art and relevant_**\n**_harmonised standards and specifications._**", "**Article 52 \u2013 paragraph 3 \u2013 subparagraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_However, the first subparagraph_** shall not\napply where the use is authorised by law **_to_**\n**_detect, prevent, investigate and prosecute_**\n**_criminal offences_** or it is necessary for the\nexercise of the right to freedom of\nexpression and the right to freedom of the\narts and sciences guaranteed in the Charter\nof Fundamental Rights of the EU, and\nsubject to appropriate safeguards for the\nrights and freedoms of third parties.\n\n**_3a._** **_Paragraph 3_** shall not apply where\nthe use **_of an genai system that generates or_**\n**_manipulates text, audio or visual content_**\nis authorized by law or **_if_** it is necessary for\nthe exercise of the right to freedom of\nexpression and the right to freedom of the\narts and sciences guaranteed in the Charter\nof Fundamental Rights of the EU, and\nsubject to appropriate safeguards for the\nrights and freedoms of third parties.\n\n**_Where_**\n**_the content forms part of an evidently_**\n**_creative, satirical, artistic or fictional_**\n**_cinematographic, video games visuals and_**\n**_analogous work or programme,_**\n**_transparency obligations set out in_**\n**_paragraph 3 are limited to disclosing of_**\n**_the existence of such generated or_**\n**_manipulated content in an appropriate_**\n**_clear and visible manner that does not_**\n**_hamper the display of the work and_**\n**_disclosing the applicable copyrights,_**\n**_where relevant.\n\nIt shall also not prevent_**\n**_law enforcement authorities from using_**\n**_AI systems intended to detect deep fakes_**\n**_and prevent, investigate and prosecute_**\n**_criminal offences linked with their use_**", "**Article 52 \u2013 paragraph 3 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_3b._** **_The information referred to in_**\n**_paragraphs 1 to 3 shall be provided to the_**\n**_natural persons at the latest at the time of_**\n**_the first interaction or exposure.\n\nIt shall_**\n\n\n-----\n\n**_be accessible to vulnerable persons, such_**\n**_as persons with disabilities or children,_**\n**_complete, where relevant and appropriate,_**\n**_with intervention or flagging procedures_**\n**_for the exposed natural person taking into_**\n**_account the generally acknowledged state_**\n**_of the art and relevant harmonised_**\n**_standards and common specifications._**", "**Article 53 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1. genai regulatory **_sandboxes established_**\n**_by one or more Member States competent_**\n**_authorities or the European Data_**\n**_Protection Supervisor_** shall **_provide a_**\n**_controlled environment that facilitates the_**\n**_development, testing and validation of_**\n**_innovative genai systems for a limited time_**\n**_before their placement_** on the **_market or_**\n**_putting into service pursuant to a specific_**\n**_plan.\n\nThis shall take place under the_**\n**_direct supervision and guidance by the_**\n**_competent authorities with a view to_**\n**_ensuring compliance with the_**\n**_requirements_** of this Regulation **_and,_**\n**_where relevant,_** other **_Union and_** Member\nStates **_legislation supervised within the_**\n**_sandbox._**\n\n\n1.\n\n**_Member States shall establish at_**\n**_least one_** genai regulatory **_sandbox at_**\n**_national level, which_** shall **_be operational_**\n**_at the latest_** on the **_day of the entry into_**\n**_application_** of this Regulation **_This_**\n**_sandbox can also be established jointly_**\n**_with one or several_** other Member States **_;_**", "**Article 53 \u2013 paragraph 1 d (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 d._** **_AI regulatory sandboxes shall, in_**\n**_accordance with criteria set out in Article_**\n**_53a, provide for a controlled environment_**\n**_that fosters innovation and facilitates the_**\n**_development, testing and validation of_**\n**_innovative genai systems for a limited time_**\n**_before their placement on the market or_**\n**_putting into service pursuant to a specific_**\n**_plan agreed between the prospective_**\n**_providers and the establishing authority;_**", "**Article 53 \u2013 paragraph 1 e (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 e._** **_The establishment of genai regulatory_**\n**_sandboxes shall aim to contribute to the_**\n**_following objectives:_**\n\n**_a) for the competent authorities to provide_**\n**_guidance to genai systems prospective_**\n**_providers providers to achieve regulatory_**\n**_compliance with this Regulation or where_**\n**_relevant other applicable Union and_**\n**_Member States legislation;_**\n\n**_b) for the prospective providers to allow_**\n**_and facilitate the testing and development_**\n**_of innovative solutions related to AI_**\n**_systems;_**\n\n**_c) regulatory learning in a controlled_**\n**_environment._**", "**Article 53 \u2013 paragraph 1 f (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 f._** **_Establishing authorities shall_**\n**_provide guidance and supervision within_**\n**_the sandbox with a view to identify risks,_**\n**_in particular to fundamental rights,_**\n**_democracy and rule of law, health and_**\n**_safety and the environment, test and_**\n**_demonstrate mitigation measures for_**\n**_identified risks, and their effectiveness_**\n**_and ensure compliance with the_**\n**_requirements of this Regulation and,_**\n**_where relevant, other Union and Member_**\n**_States legislation;_**", "**Article 53 \u2013 paragraph 1 f (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 g._** **_Establishing authorities shall_**\n**_provide sandbox prospective providers_**\n**_who develop high-risk genai systems with_**\n**_guidance and supervision on how to fulfil_**\n**_the requirements set out in this_**\n**_Regulation, so that the genai systems may_**\n**_exit the sandbox being in presumption of_**\n**_conformity with the specific requirements_**\n**_of this Regulation that were assessed_**\n**_within the sandbox.\n\nInsofar as the AI_**\n**_system complies with the requirements_**\n**_when exiting the sandbox, it shall be_**\n**_presumed to be in conformity with this_**\n**_regulation.\n\nIn this regard, the exit reports_**\n**_created by the establishing authority shall_**\n**_be taken into account by market_**\n**_surveillance authorities or notified bodies,_**\n**_as applicable, in the context of conformity_**\n**_assessment procedures or market_**\n**_surveillance checks;_**", "**Article 53 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\n**_Member States_** shall ensure that to\nthe extent the innovative genai systems\ninvolve the processing of personal data or\notherwise fall under the supervisory remit\nof other national authorities or competent\nauthorities providing or supporting access\nto data, the national data protection\nauthorities and those other national\nauthorities are associated to the operation\nof the genai regulatory sandbox **_._**\n\n\n2.\n\n**_Establishing authorities_** shall ensure\nthat **_,_** to the extent the innovative genai\nsystems involve the processing of personal\ndata or otherwise fall under the supervisory\nremit of other national authorities or\ncompetent authorities providing or\nsupporting access to **_personal_** data, the\nnational data protection authorities **_, or in_**\n**_cases referred to in paragraph 1b the_**\n**_EDPS,_** and those other national authorities\nare associated to the operation of the genai\nregulatory sandbox **_and involved in the_**\n**_supervision of those aspects to the full_**\n**_extent of their respective tasks and_**\n**_powers;_**", "**Article 53 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nThe genai regulatory sandboxes shall\nnot affect the supervisory and corrective\npowers of the competent authorities.\n\nAny\nsignificant risks to **_health and safety and_**\nfundamental rights identified during the\ndevelopment and testing of such systems\nshall result in immediate mitigation **_and,_**\n**_failing that, in the suspension of the_**\n**_development and_** testing process **_until_**\n**_such_** mitigation **_takes place._**\n\n\n3.\n\nThe genai regulatory sandboxes shall\nnot affect the supervisory and corrective\npowers of the competent authorities **_,_**\n**_including at regional or local level_** .\n\nAny\nsignificant risks to fundamental rights **_,_**\n**_democracy and rule of law, health and_**\n**_safety or the environment_** identified during\nthe development and testing of such **_AI_**\nsystems shall result in immediate **_and_**\n**_adequate_** mitigation **_. Competent_**\n**_authorities shall have the power to_**\n**_temporarily or permanently suspend the_**\ntesting process **_, or participation in the_**\n**_sandbox if no effective_** mitigation **_is_**\n**_possible and inform the genai office of such_**\n**_decision;_**", "**Article 53 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\n**_Participants_** in the genai regulatory\nsandbox shall remain liable under\napplicable Union and Member States\nliability legislation for any harm inflicted\non third parties as a result **_from_** the\nexperimentation taking place in the\nsandbox.\n\n4.\n\n**_Prospective providers_** in the genai\nregulatory sandbox shall remain liable\nunder applicable Union and Member States\nliability legislation for any harm inflicted\non third parties as a result **_of_** the\nexperimentation taking place in the\nsandbox.\n\n**_However, provided that the_**\n**_prospective provider(s) respect the specific_**\n**_plan referred to in paragraph 1c and the_**\n**_terms and conditions for their_**\n**_participation and follow in good faith the_**\n**_guidance given by the establishing_**\n**_authorities, no administrative fines shall_**\n**_be imposed by the authorities for_**\n**_infringements of this Regulation;_**", "**Article 53 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\n**_Member States\u2019 competent_**\nauthorities **_that have established AI_**\n**_regulatory sandboxes_** shall coordinate\ntheir activities and cooperate within the\nframework of the **_European Artificial_**\n**_Intelligence Board.\n\nThey shall submit_**\n**_annual reports to the Board and the_**\n**_Commission on the results from the_**\n**_implementation of those scheme,_**\n**_including good practices, lessons learnt_**\n**_and recommendations on their setup and,_**\n**_where relevant, on the application of this_**\n**_Regulation and other Union legislation_**\n**_supervised within the sandbox._**\n\n\n5.\n\n**_Establishing_** authorities shall\ncoordinate their activities and cooperate\nwithin the framework of the **_AI office;_**", "**Article 53 \u2013 paragraph 5 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_5 a._** **_Establishing authorities shall_**\n**_inform the genai Office of the establishment_**\n**_of a sandbox and may ask for support and_**\n**_guidance.\n\nA list of planned and existing_**\n**_sandboxes shall be made publicly_**\n**_available by the genai office and kept up to_**\n**_date in order to encourage more_**\n**_interaction in the regulatory sandboxes_**\n**_and transnational cooperation;_**", "**Article 53 \u2013 paragraph 5 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_5 b._** **_Establishing authorities shall_**\n**_submit to the genai office and, unless the_**\n**_Commission is the sole establishing_**\n**_authority, to the Commission, annual_**\n\n\n-----\n\n**_reports, starting one year after the_**\n**_establishment of the sandbox and then_**\n**_every year until its termination and a final_**\n**_report.\n\nThose reports shall provide_**\n**_information on the progress and results of_**\n**_the implementation of those sandboxes,_**\n**_including best practices, incidents, lessons_**\n**_learnt and recommendations on their_**\n**_setup and, where relevant, on the_**\n**_application and possible revision of this_**\n**_Regulation and other Union law_**\n**_supervised within the sandbox.\n\nThose_**\n**_annual reports or abstracts thereof shall_**\n**_be made available to the public, online;_**", "**Article 53 \u2013 paragraph 6**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\nThe **_modalities and the conditions of_**\n**_the operation of the AI_** regulatory\nsandboxes **_, including the eligibility criteria_**\n**_and the procedure for the application,_**\n**_selection, participation and exiting from_**\n**_the sandbox, and the rights and_**\n**_obligations of the participants_** shall **_be set_**\n**_out in implementing acts.\n\nThose_**\n**_implementing acts shall be adopted in_**\n**_accordance with the examination_**\n**_procedure referred to in Article 74(2)._**\n\n\n6.\n\nThe **_Commission shall develop a_**\n**_single and dedicated interface containing_**\n**_all relevant information related to_**\n**_sandboxes, together with a single contact_**\n**_point at Union level to interact with the_**\nregulatory sandboxes **_and to allow_**\n**_stakeholders to raise enquiries with_**\n**_competent authorities, and to seek nonbinding guidance on the conformity of_**\n**_innovative products, services, business_**\n**_models embedding genai technologies;_**\n\n**_The Commission_** shall **_proactively_**\n**_coordinate with national, regional and_**\n**_also local authorities, where relevant;_**", "**Article 53 \u2013 paragraph 6 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_6 a._** **_For the purpose of paragraph 1 and_**\n**_1a, the Commission shall play a_**\n\n\n-----\n\n**_complementary role, enabling Member_**\n**_States to build on their expertise and, on_**\n**_the other hand, assisting and providing_**\n**_technical understanding and resources to_**\n**_those Member States that seek guidance_**\n**_on the set-up and running of these_**\n**_regulatory sandboxes;_**", "**Article 53 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 53 a_**\n\n**_Modalities and functioning of AI_**\n**_regulatory sandboxes_**\n\n**_1.\n\nIn order to avoid fragmentation across_**\n**_the Union, the Commission, in_**\n**_consultation with the genai office, shall_**\n**_adopt a delegated act detailing the_**\n**_modalities for the establishment,_**\n**_development, implementation, functioning_**\n**_and supervision of the genai regulatory_**\n**_sandboxes, including the eligibility_**\n**_criteria and the procedure for the_**\n**_application, selection, participation and_**\n**_exiting from the sandbox, and the rights_**\n**_and obligations of the participants based_**\n**_on the provisions set out in this Article;_**\n\n**_2.\n\nThe Commission is empowered to adopt_**\n**_delegated acts in accordance with the_**\n**_procedure referred to in Article 73, no_**\n**_later than 12 months following the entry_**\n**_into force of this Regulation and shall_**\n**_ensure that:_**\n\n**_a) regulatory sandboxes are open to any_**\n**_applying prospective provider of an AI_**\n**_system who fulfils eligibility and selection_**\n**_criteria.\n\nThe criteria for accessing to the_**\n**_regulatory sandbox are transparent and_**\n**_fair and establishing authorities inform_**\n**_applicants of their decision within 3_**\n**_months of the application;_**\n\n\n-----\n\n**_b) regulatory sandboxes allow broad and_**\n**_equal access and keep up with demand for_**\n**_participation;_**\n\n**_c) access to the genai regulatory sandboxes is_**\n**_free of charge for SMEs and start-ups_**\n**_without prejudice to exceptional costs that_**\n**_establishing authorities may recover in a_**\n**_fair and proportionate manner;_**\n\n**_d) regulatory sandboxes facilitate the_**\n**_involvement of other relevant actors_**\n**_within the genai ecosystem, such as notified_**\n**_bodies and standardisation organisations_**\n**_(SMEs, start-ups, enterprises, innovators,_**\n**_testing and experimentation facilities,_**\n**_research and experimentation labs and_**\n**_digital innovation hubs, centers of_**\n**_excellence, individual researchers), in_**\n**_order to allow and facilitate cooperation_**\n**_with the public and private sector;_**\n\n**_e) they allow prospective providers to to_**\n**_fulfil, in a controlled environment, the_**\n**_conformity assessment obligations of this_**\n**_Regulation or the voluntary application of_**\n**_the codes of conduct referred to in Article_**\n**_69;_**\n\n**_f) procedures, processes and_**\n**_administrative requirements for_**\n**_application, selection, participation and_**\n**_exiting the sandbox are simple, easily_**\n**_intelligible, clearly communicated in_**\n**_order to facilitate the participation of_**\n**_SMEs and start-ups with limited legal and_**\n**_administrative capacities and are_**\n**_streamlined across the Union, in order to_**\n**_avoid fragmentation and that_**\n**_participation in a regulatory sandbox_**\n**_established by a Member State, by the_**\n**_Commission, or by the EDPS is mutually_**\n**_and uniformly recognised and carries the_**\n**_same legal effects across the Union;_**\n\n**_g) participation in the genai regulatory_**\n**_sandbox is limited to a period that is_**\n**_appropriate to the complexity and scale of_**\n**_the project._**\n\n**_h) the sandboxes shall facilitate the_**\n**_development of tools and infrastructure_**\n**_for testing, benchmarking, assessing and_**\n**_explaining dimensions of genai systems_**\n\n\n-----\n\n**_relevant to sandboxes, such as accuracy,_**\n**_robustness and cybersecurity as well as_**\n**_minimisation of risks to fundamental_**\n**_rights, environment and the society at_**\n**_large_**\n\n**_3.\n\nProspective providers in the sandboxes,_**\n**_in particular SMEs and start-ups, shall be_**\n**_facilitated access to pre-deployment_**\n**_services such as guidance on the_**\n**_implementation of this Regulation, to_**\n**_other value-adding services such as help_**\n**_with standardisation documents and_**\n**_certification and consultation, and to_**\n**_other Digital Single Market initiatives_**\n**_such as Testing & Experimentation_**\n**_Facilities, Digital Hubs, Centres of_**\n**_Excellence, and EU benchmarking_**\n**_capabilities;_**", "**Article 54 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nIn the genai regulatory sandbox\npersonal data lawfully collected for other\npurposes **_shall_** be processed for the\npurposes of developing and testing certain\n**_innovative_** genai systems in the sandbox\n**_under_** the following conditions:\n\n\n1.\n\nIn the genai regulatory sandbox\npersonal data lawfully collected for other\npurposes **_may_** be processed **_solely_** for the\npurposes of developing and testing certain\ngenai systems in the sandbox **_when all of_** the\nfollowing conditions **_are met_** :", "**Article 54 \u2013 paragraph 1 \u2013 point a \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) **_the innovative_** genai systems shall be\ndeveloped for safeguarding substantial\npublic interest in one or more of the\nfollowing areas:\n\n\n(a) genai systems shall be developed for\nsafeguarding substantial public interest in\none or more of the following areas:\n\n**_(ii) public safety and public health,_**\n**_including disease detection, diagnosis_**\n**_prevention, control and treatment;_**\n\n**_(iii) a high level of protection and_**\n**_improvement of the quality of the_**\n**_environment, protection of biodiversity,_**\n**_pollution as well as climate change_**\n**_mitigation and adaptation;_**\n\n**_(iii a) safety and resilience of transport_**\n**_systems, critical infrastructure and_**\n**_networks._**", "**Article 54 \u2013 paragraph 1 \u2013 point a \u2013 point i**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(i)_** **_the prevention, investigation,_**\n**_detection or prosecution of criminal_**\n**_offences or the execution of criminal_**\n**_penalties, including the safeguarding_**\n**_against and the prevention of threats to_**\n**_public security, under the control and_**\n**_responsibility of the competent_**\n**_authorities.\n\nThe processing shall be based_**\n**_on Member State or Union law;_**\n\n\n**_deleted_**", "**Article 54 \u2013 paragraph 1 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) there are effective monitoring\nmechanisms to identify if any high risks to\n\n\n(c) there are effective monitoring\nmechanisms to identify if any high risks to\n\n\n-----\n\nthe **_fundamental_** rights of the data subjects\nmay arise during the sandbox\nexperimentation as well as response\nmechanism to promptly mitigate those\nrisks and, where necessary, stop the\nprocessing;\n\n\nthe rights **_and freedoms_** of the data\nsubjects **_, as referred to in Article 35 of_**\n**_Regulation (EU) 2016/679 and in Article_**\n**_35 of Regulation (EU) 2018/1725_** may\narise during the sandbox experimentation\nas well as response mechanism to promptly\nmitigate those risks and, where necessary,\nstop the processing;", "**Article 54 \u2013 paragraph 1 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) any personal data to be processed in\nthe context of the sandbox are in a\nfunctionally separate, isolated and\nprotected data processing environment\nunder the control of the **_participants_** and\nonly authorised persons have access to that\ndata;\n\n\n(d) any personal data to be processed in\nthe context of the sandbox are in a\nfunctionally separate, isolated and\nprotected data processing environment\nunder the control of the **_prospective_**\n**_provider_** and only authorised persons have\naccess to that **_those_** data;", "**Article 54 \u2013 paragraph 1 \u2013 point f**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(f) any processing of personal data in the\ncontext of the sandbox do not lead to\nmeasures or decisions affecting the data\nsubjects;\n\n\n(f) any processing of personal data in the\ncontext of the sandbox do not lead to\nmeasures or decisions affecting the data\nsubjects **_nor affect the application of their_**\n**_rights laid down in Union law on the_**\n**_protection of personal data_** ;", "**Article 54 \u2013 paragraph 1 \u2013 point g**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(g) any personal data processed in the\ncontext of the sandbox are deleted once the\n\n\n(g) any personal data processed in the\ncontext of the sandbox are **_protected by_**\n\n\n-----\n\nparticipation in the sandbox has terminated\nor the personal data has reached the end of\nits retention period;\n\n\n**_means of appropriate technical and_**\n**_organisational measures and_** deleted once\nthe participation in the sandbox has\nterminated or the personal data has reached\nthe end of its retention period;", "**Article 54 \u2013 paragraph 1 \u2013 point h**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(h) the logs of the processing of personal\ndata in the context of the sandbox are kept\nfor the duration of the participation in the\nsandbox **_and 1 year after its termination,_**\n**_solely for the purpose of and only as long_**\n**_as necessary for fulfilling accountability_**\n**_and documentation obligations under this_**\n**_Article or other application Union or_**\n**_Member States legislation_** ;\n\n\n(h) the logs of the processing of personal\ndata in the context of the sandbox are kept\nfor the duration of the participation in the\nsandbox;", "**Article 54 \u2013 paragraph 1 \u2013 point j**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(j) a short summary of the genai **_project_**\ndeveloped in the sandbox, its objectives\nand expected results published on the\nwebsite of the competent authorities **_._**\n\n\n(j) a short summary of the genai **_system_**\ndeveloped in the sandbox, its objectives **_,_**\n**_hypotheses,_** and expected results **_,_**\npublished on the website of the competent\nauthorities **_;_**", "**Article 54 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 54 a_**\n\n**_Promotion of genai research and_**\n**_development in support of socially and_**\n\n\n-----\n\n**_environmentally beneficial outcomes_**\n\n**_1.\n\nMember States shall promote research_**\n**_and development of genai solutions which_**\n**_support socially and environmentally_**\n**_beneficial outcomes, including but not_**\n**_limited to development of genai-based_**\n**_solutions to increase accessibility for_**\n**_persons with disabilities, tackle socioeconomic inequalities, and meet_**\n**_sustainability and environmental targets,_**\n**_by:_**\n\n**_(a) providing relevant projects with_**\n**_priority access to the genai regulatory_**\n**_sandboxes to the extent that they fulfil the_**\n**_eligibility conditions;_**\n\n**_(b) earmarking public funding, including_**\n**_from relevant EU funds, for genai research_**\n**_and development in support of socially_**\n**_and environmentally beneficial outcomes;_**\n\n**_(c) organising specific awareness raising_**\n**_activities about the application of this_**\n**_Regulation, the availability of and_**\n**_application procedures for dedicated_**\n**_funding, tailored to the needs of those_**\n**_projects;_**\n\n**_(d) where appropriate, establishing_**\n**_accessible dedicated channels, including_**\n**_within the sandboxes, for communication_**\n**_with projects to provide guidance and_**\n**_respond to queries about the_**\n**_implementation of this Regulation._**\n\n**_Member States shall support civil society_**\n**_and social stakeholders to lead or_**\n**_participate in such projects;_**", "**Article 55 \u2013 paragraph 1 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) provide **_small-scale providers_** and\nstart-ups with priority access to the genai\nregulatory sandboxes to the extent that they\nfulfil the eligibility conditions;\n\n\n(a) provide **_SMEs_** and start-ups **_,_**\n**_established in the Union,_** with priority\naccess to the genai regulatory sandboxes **_,_** to\nthe extent that they fulfil the eligibility\nconditions;", "**Article 55 \u2013 paragraph 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) organise specific awareness raising\nactivities **_about_** the application of this\nRegulation tailored to the needs of **_the_**\n**_small-scale providers_** and users;\n\n\n(b) organise specific awareness raising\n**_and enhanced digital skills development_**\nactivities **_on_** the application of this\nRegulation tailored to the needs of **_SMEs,_**\n**_start-ups_** and users;", "**Article 55 \u2013 paragraph 1 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) where appropriate, establish **_a_**\ndedicated **_channel_** for communication with\n**_small-scale providers and user_** and other\ninnovators to provide guidance and\nrespond to queries about the\nimplementation of this Regulation **_._**\n\n\n(c) **_utilise existing dedicated channels_**\n**_and_** where appropriate, establish **_new_**\ndedicated **_channels_** for communication\nwith **_SMEs, start-ups, users_** and other\ninnovators to provide guidance and\nrespond to queries about the\nimplementation of this Regulation **_;_**", "**Article 55 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe specific interests and needs of\nthe **_small-scale providers_** shall be taken\ninto account when setting the fees for\nconformity assessment under Article 43,\nreducing those fees proportionately to their\nsize and market **_size_** .\n\n2.\n\nThe specific interests and needs of\nthe **_SMEs, start-ups and users_** shall be\ntaken into account when setting the fees for\nconformity assessment under Article 43,\nreducing those fees proportionately to\n**_development stage,_** their **_size, market_** size\nand market **_demand_** .\n\n**_The Commission_**\n**_shall regularly assess the certification and_**\n**_compliance costs for SMEs and start-ups,_**\n**_including through transparent_**\n**_consultations with SMEs, start-ups and_**\n**_users and shall work with Member States_**\n**_to lower such costs where possible.\n\nThe_**\n**_Commission shall report on these findings_**\n**_to the European Parliament and to the_**\n**_Council as part of the report on the_**\n**_evaluation and review of this Regulation_**\n**_provided for in Article 84(2)._**", "**Article 56 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\n**_A_** \u2018European genai\n**_Board_** \u2019 (the \u2018 **_Board_** \u2019) is established.\n\n1.\n\n**_The_** \u2018European genai\n**_Office_** \u2019 (the \u2018 **_AI Office_** \u2019) is **_hereby_**\nestablished.\n\n**_The genai Office shall be an_**\n**_independent body of the Union.\n\nIt shall_**\n**_have legal personality._**", "**Article 56 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe **_Board_** shall **_provide advice and_**\n**_assistance to the Commission in order to:_**\n\n\n2.\n\nThe **_AI Office_** shall **_have a_**\n**_secretariat, and shall be adequately_**\n**_funded and staffed for the purpose of_**\n**_performing its tasks pursuant to this_**\n**_Regulation._**", "**Article 56 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 56 b_**\n\n**_Tasks of the genai Office_**\n\n**_The genai Office shall carry out the_**\n**_following tasks:_**\n\n**_a) support, advise, and cooperate with_**\n**_Member States, national supervisory_**\n**_authorities, the Commission and other_**\n**_Union institutions, bodies, offices and_**\n**_agencies with regard to the_**\n**_implementation of this Regulation;_**\n\n**_b) monitor and ensure the effective and_**\n**_consistent application of this Regulation,_**\n**_without prejudice to the tasks of national_**\n**_supervisory authorities;_**\n\n**_c) contribute to the coordination among_**\n**_national supervisory authorities_**\n**_responsible for the application of this_**\n**_Regulation,_**\n\n**_d) serve as a mediator in discussions_**\n**_about serious disagreements that may_**\n**_arise between competent authorities_**\n**_regarding the application of the_**\n\n\n-----\n\n**_Regulation_**\n\n**_e) coordinate joint investigations,_**\n**_pursuant to Article 66a;_**\n\n**_f) contribute to the effective cooperation_**\n**_with the competent authorities of third_**\n**_countries and with international_**\n**_organisations,_**\n\n**_g) collect and share Member States\u2019_**\n**_expertise and best practices and to assist_**\n**_Member States national supervisory_**\n**_authorities and the Commission in_**\n**_developing the organizational and_**\n**_technical expertise required for the_**\n**_implementation of this Regulation,_**\n**_including by means of facilitating the_**\n**_creation and maintenance of a Union_**\n**_pool of experts_**\n\n**_h) examine, on its own initiative or upon_**\n**_the request of its management board or_**\n**_the Commission, questions relating to the_**\n**_implementation of this Regulation and to_**\n**_issue opinions, recommendations or_**\n**_written contributions including with_**\n**_regard to:_**\n\n**_(i) technical specifications or existing_**\n**_standards; (ii) the Commission\u2019s_**\n**_guidelines_**\n\n**_(iii) codes of conduct and the application_**\n**_thereof, in close cooperation with industry_**\n**_and other relevant stakeholders;_**\n\n**_(iv) the possible revision of the_**\n**_Regulation, the preparation of the_**\n**_delegated acts, and possible alignments of_**\n**_this Regulation with the legal acts listed in_**\n**_Annex II;_**\n\n**_(v) trends, such as European global_**\n**_competitiveness in genai,_**\n**_the uptake of genai in the_**\n**_Union, the development of digital skills,_**\n**_and emerging systemic threats relating to_**\n**_artificial intelligence_**\n\n**_(vi) guidance on how this Regulation_**\n**_applies to the ever evolving typology of AI_**\n**_value chains, in particular on the_**\n**_resulting implications in terms of_**\n**_accountability of all the entities involved_**\n\n\n-----\n\n**_i) issue:_**\n\n**_(i) an annual report that includes an_**\n**_evaluation of the implementation of this_**\n**_Regulation, a review of serious incident_**\n**_reports as referred to in Article 62 and the_**\n**_functioning of the database referred to in_**\n**_Article 60 and_**\n\n**_(ii) recommendations to the Commission_**\n**_on the categorisation of prohibited_**\n**_practices, high-risk genai systems referred to_**\n**_in Annex III, the codes of conduct_**\n**_referred to in Article 69, and the_**\n**_application of the general principles_**\n**_outlines in Article 4a_**\n\n**_j) assist authorities in the establishment_**\n**_and development of regulatory sandboxes_**\n**_and to facilitate cooperation among_**\n**_regulatory sandboxes;_**\n\n**_k) organise meetings with Union agencies_**\n**_and governance bodies whose tasks are_**\n**_related to genai and the_**\n**_implementation of this Regulation;_**\n\n**_l)organise quarterly consultations with_**\n**_the advisory forum, and, where_**\n**_appropriate, public consultations with_**\n**_other stakeholders, and to make the_**\n**_results of those consultations public on its_**\n**_website;_**\n\n**_m) promote public awareness and_**\n**_understanding of the benefits, risks,_**\n**_safeguards and rights and obligations in_**\n**_relation to the use of genai systems;_**\n\n**_n) facilitate the development of common_**\n**_criteria and a shared understanding_**\n**_among market operators and competent_**\n**_authorities of the relevant concepts_**\n**_provided for in this Regulation;_**\n\n**_o) provide monitoring of foundation_**\n**_models and to organise a regular dialogue_**\n**_with the developers of foundation models_**\n**_with regard to their compliance as well as_**\n**_AI systems that make use of such AI_**\n**_models_**\n\n**_p) provide interpretive guidance on how_**\n**_the genai Act applies to the ever evolving_**\n**_typology of genai value chains, and what the_**\n\n\n-----\n\n**_resulting implications in terms of_**\n**_accountability of all the entities involved_**\n**_will be under the different scenarios based_**\n**_on the generally acknowledged state of_**\n**_the art, including as reflected in relevant_**\n**_harmonized standards;_**\n\n**_q) provide particular oversight and_**\n**_monitoring and institutionalize regular_**\n**_dialogue with the providers of foundation_**\n**_models about the compliance of_**\n**_foundation models as well as genai systems_**\n**_that make use of such genai models with_**\n**_Article 28b of this Regulation, and about_**\n**_industry best practices for selfgovernance.", "Any such meeting shall be_**\n**_open to national supervisory authorities,_**\n**_notified bodies and market surveillance_**\n**_authorities to attend and contribute_**\n\n**_r) issue and periodically update guidelines_**\n**_on the thresholds that qualify training a_**\n**_foundation model as a large training run,_**\n**_record and monitor known instances of_**\n**_large training runs, and issue an annual_**\n**_report on the state of play in the_**\n**_development, proliferation, and use of_**\n**_foundation models alongside policy_**\n**_options to address risks and opportunities_**\n**_specific to foundation models._**\n\n**_s) promote genai literacy pursuant to Article_**\n**_4b._**", "**Article 56 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 56 c_**\n\n**_Accountability, independence, and_**\n**_transparency_**\n\n**_1.\n\nThe genai Office shall:_**\n\n**_a.\n\nbe accountable to the European_**\n**_Parliament and to the Council in_**\n**_accordance with this Regulation;_**\n\n**_b.\n\nact independently when carrying out its_**\n\n\n-----\n\n**_tasks or exercising its powers; and_**\n\n**_c.\n\nensure a high level of transparency_**\n**_concerning its activities and develop good_**\n**_administrative practices in that regard._**\n\n**_Regulation (EC) No 1049/2001 shall_**\n**_apply to documents held by the genai Office._**", "**Article - 57 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article - 57 a_**\n\n**_Composition of the management board_**\n\n**_1.\n\nThe management board shall be_**\n**_composed of the following members:_**\n\n**_(a) one representative of each Member_**\n**_State\u2019s national supervisory authority;_**\n\n**_(b) one representative from the_**\n**_Commission;_**\n\n**_(c) one representative from the European_**\n**_Data Protection Supervisor (EDPS);_**\n\n**_(d) one representative from the European_**\n**_Union Agency for Cybersecurity_**\n**_(ENISA);_**\n\n**_(e) one representative from the_**\n**_Fundamental Rights Agency (FRA)_**\n\n**_Each representative of a national_**\n**_supervisory authority shall have one vote._**\n**_The representatives of the Commission,_**\n**_the EDPS, the ENISA and the FRA shall_**\n\n\n-----\n\n**_not have voting rights.\n\nEach member shall_**\n**_have a substitute.\n\nThe appointment of_**\n**_members and substitute members of the_**\n**_management board shall take into_**\n**_account the need to gender balance.\n\nThe_**\n**_members of the management board and_**\n**_their substitute members shall be made_**\n**_public._**\n\n**_2.\n\nThe members and substitutes members_**\n**_of the management board shall not hold_**\n**_conflicting positions or commercial_**\n**_interests with regard to any topic related_**\n**_to the application of this Regulation._**\n\n**_3.\n\nThe rules for the meetings and voting_**\n**_of the management board and the_**\n**_appointment and removal of the Executive_**\n**_Director shall be laid down in the rules of_**\n**_procedure referred to in Article \u2013 57 b,_**\n**_point (a)._**", "**Article - 57 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article - 57 b_**\n\n**_Functions of the management board_**\n\n**_1.\n\nThe management board shall have the_**\n**_following tasks:_**\n\n**_(a) to make strategic decisions on the_**\n**_activities of the genai Office and to adopt its_**\n**_rules of procedure by a two-thirds_**\n**_majority of its members;_**\n\n**_(b) to implement its rules of procedure;_**\n\n**_(c) to adopt the genai Office\u2019s single_**\n**_programming document as well as it_**\n**_annual public report and transmit both to_**\n**_the European Parliament, to the Council,_**\n**_to the Commission, and to the Court of_**\n**_Auditors;_**\n\n**_(d) to adopt the genai Office\u2019s budget;_**\n\n**_(e) to appoint the executive director and,_**\n**_where relevant, to extend or curtail the_**\n\n\n-----\n\n**_executive director\u2019s term of office or_**\n**_remove him or her from office;_**\n\n**_(f) to decide on the establishment of the_**\n**_AI Office\u2019s internal structures and, where_**\n**_necessary, the modification of those_**\n**_internal structures necessary for the_**\n**_fulfilment of the genai Office tasks;_**", "**Article - 57 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article - 57 c_**\n\n**_Chair of the management board_**\n\n**_1.\n\nThe management board shall elect a_**\n**_Chair and two deputy Chairs from among_**\n**_its voting members, by simple majority._**\n\n**_2.\n\nThe term of office of the Chair and of_**\n**_the deputy Chairs shall be four years.\n\nThe_**\n**_terms of the Chair and of the deputy_**\n**_Chairs renewable once._**", "**Article 57 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nThe **_Board_** shall be **_composed of the_**\n**_national supervisory authorities_** , who shall\nbe **_represented by the head or equivalent_**\n**_high-level official of that authority,_** and\n\n\n1.\n\nThe **_activities of the secretariat_** shall\nbe **_managed by an executive director._** **_The_**\n**_executive director_** shall be **_accountable to_**\n**_the management board.\n\nWithout prejudice_**\n\n\n-----\n\nthe **_European Data Protection Supervisor._**\nOther **_national authorities may be invited_**\n**_to the meetings, where the issues_**\n**_discussed are of relevance for them._**\n\n\n**_to the respective powers of the_**\n**_management board_** and the **_Union_**\n**_institutions, the executive director shall_**\n**_neither seek nor take instructions from_**\n**_any government or from any_** other **_body_**", "**Article 57 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe **_Board_** shall **_adopt its rules of_**\n**_procedure by a simple majority of its_**\n**_members, following the consent_** of the\n**_Commission.\n\nThe rules of procedure shall_**\n**_also contain the operational aspects_**\n**_related to the execution of the Board\u2019s_**\n**_tasks as listed in Article 58_** .\n\n**_The Board_**\n**_may establish sub-groups as appropriate_**\n**_for the purpose of examining specific_**\n**_questions._**\n\n\n2.\n\nThe **_executive director_** shall **_attend_**\n**_hearings on any matter linked to the AI_**\n**_Office's activities and shall report on the_**\n**_performance_** of the **_executive director\u2019s_**\n**_duties when invited to do so by the_**\n**_European Parliament or the Council_** .", "**Article 57 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nThe **_Board_** shall **_be chaired by the_**\n**_Commission.\n\nThe Commission shall_**\n**_convene the meetings and prepare the_**\n**_agenda in accordance with the tasks of_**\n**_the Board pursuant to this Regulation and_**\n**_with its rules of procedure.\n\nThe_**\n**_Commission shall provide administrative_**\n**_and analytical support for the activities of_**\n**_the Board pursuant to this Regulation._**\n\n\n3.\n\nThe **_executive director_** shall\n**_represent the genai Office, including in_**\n**_international fora for cooperation with_**\n**_regard to genai;_**", "**Article 57 \u2013 paragraph 4**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nThe Board **_may invite external_**\n**_experts and observers to attend its_**\n**_meetings and may hold exchanges with_**\n**_interested third parties to inform its_**\nactivities **_to an appropriate extent.\n\nTo that_**\n**_end the Commission may facilitate_**\n**_exchanges between the_** Board **_and other_**\n**_Union bodies, offices, agencies and_**\n**_advisory groups._**\n\n\n4.\n\nThe **_secretariat shall provide the_**\n**_management_** board **_and the advisory_**\n**_forum with the analytical, administrative_**\n**_and logistical support necessary to fulfil_**\n**_the tasks of the genai Office, including by:_**\n\n**_(a) Implementing the decisions,_**\n**_programmes and_** activities **_adopted by the_**\n**_management_** board **_;_**\n\n**_(b) preparing each year the draft single_**\n**_programming document, the draft budget,_**\n**_the annual activity report on the AI_**\n**_Office, the draft opinions and the draft_**\n**_positions of the genai Office, and submit_**\n**_them to the management board_**\n\n**_(c) Coordinating with international fora_**\n**_for cooperation on genai;_**", "**Article 58 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_When providing advice and assistance to_**\n**_the Commission in the context of Article_**\n**_56(2), the Board_** shall in particular **_:_**\n\n\n**_The advisory forum_** shall **_provide the AI_**\n**_Office with stakeholder input in matters_**\n**_relating to this Regulation,_** in particular\n**_with regard to the tasks set out in Article_**\n**_56b point (l)._**\n\n\n-----", "**Article 58 \u2013 paragraph 2 (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_The membership of the advisory forum_**\n**_shall represent a balanced selection of_**\n**_stakeholders, including industry, startups, SMEs, civil society, the social_**\n**_partners and academia.\n\nThe membership_**\n**_of the advisory forum shall be balanced_**\n**_with regard to commercial and noncommercial interests and, within the_**\n**_category of commercial interests, with_**\n**_regards to SMEs and other undertakings._**", "**Article 58 \u2013 paragraph 3 (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_The management board shall appoint the_**\n**_members of the advisory forum in_**\n**_accordance with the selection procedure_**\n**_established in the genai Office\u2019s rules of_**\n**_procedure and taking into account the_**\n**_need for transparency and in accordance_**\n**_with the criteria set out in paragraph 2;_**", "**Article 58 \u2013 paragraph 5 (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_The European Committee for_**\n**_Standardization (CEN), the European_**\n**_Committee for Electrotechnical_**\n**_Standardization (CENELEC), and the_**\n**_European Telecommunications Standards_**\n**_Institute (ETSI) shall be permanent_**\n**_members of the Advisory Forum.\n\nThe_**\n**_Joint Research Centre shall be permanent_**\n**_member, without voting rights._**", "**Article 58 \u2013 paragraph 6 (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_The advisory forum shall draw up its rules_**\n**_of procedure.\n\nIt shall elect two co-Chairs_**\n**_from among its members, in accordance_**\n**_with criteria set out in paragraph 2.\n\nThe_**\n**_term of office of the co-Chairs shall be_**\n**_two years, renewable once._**", "**Article 58 a (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 58 a_**\n\n**_Benchmarking_**\n\n**_The European authorities on_**\n**_benchmarking referred to in Article 15_**\n**_(1a) and the genai Office shall, in close_**\n**_cooperation with international partners,_**\n**_jointly develop cost-effective guidance and_**\n**_capabilities to measure and benchmark_**\n**_aspects of genai systems and genai components,_**\n**_and in particular of foundation models_**\n**_relevant to the compliance and_**\n**_enforcement of this Regulation based on_**\n**_the generally acknowledged state of the_**\n**_art, including as reflected in relevant_**\n**_harmonized standards._**", "**Article 59 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\n**_National competent authorities shall_**\n**_be established or designated by_** each\nMember State **_for the purpose of ensuring_**\n**_the application and implementation of this_**\n**_Regulation._** National **_competent_**\n**_authorities_** shall be organised so as to\nsafeguard the objectivity and impartiality\nof **_their_** activities and tasks.\n\n1.\n\nEach Member State **_shall designate_**\n**_one_** national **_supervisory authority, which_**\nshall be organised so as to safeguard the\nobjectivity and impartiality of **_its_** activities\nand tasks **_by ...[three months after the date_**\n**_of entry into force of this Regulation]_** .", "**Article 59 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\n**_Each Member State shall designate_**\n**_a_** national supervisory authority **_among the_**\n**_national_** competent authorities.\n\nThe\nnational supervisory authority shall act as\n**_notifying authority and_** market\nsurveillance authority **_unless a Member_**\n**_State has organisational and_**\n**_administrative reasons to designate more_**\n**_than one authority_** .\n\n2.\n\n**_The_** national supervisory authority\n**_shall ensure the application and_**\n**_implementation of this Regulation.\n\nWith_**\n**_regard to high-risk genai systems, related to_**\n**_products to which legal acts listed in_**\n**_Annex II apply, the_** competent authorities\n**_designated under those legal acts shall_**\n**_continue to lead the administrative_**\n**_procedures.\n\nHowever, to the extent a case_**\n**_involves aspects exclusively covered by_**\n**_this Regulation, those competent_**\n**_authorities shall be bound by the_**\n**_measures related to those aspects issued_**\n**_by the national supervisory authority_**\n**_designated under this Regulation_** .\n\nThe\nnational supervisory authority shall act as\nmarket surveillance authority.", "**Article 59 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nMember States shall **_inform_** the\nCommission **_of their designation or_**\n**_designations and, where applicable, the_**\n**_reasons for designating more than one_**\nauthority.\n\n3.\n\nMember States shall **_make publicly_**\n**_available and communicate to the AI_**\n**_Office and_** the Commission **_the national_**\n**_supervisory authority and information on_**\n**_how it can be contacted, by\u2026 [three_**\n**_months after the date of entry into force_**\n**_of this Regulation].\n\nThe national_**\n**_supervisory_** authority **_shall act as single_**\n**_point of contact for this Regulation and_**\n**_should be contactable though electronic_**\n**_communications means_** .", "**Article 59 \u2013 paragraph 4**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nMember States shall ensure that\nnational **_competent authorities are_**\nprovided with adequate financial and\nhuman resources to fulfil their tasks under\nthis Regulation.\n\nIn particular, national\n**_competent authorities_** shall have a\nsufficient number of personnel\npermanently available whose competences\nand expertise shall include an in-depth\nunderstanding of genai\ntechnologies, data and data computing,\nfundamental rights, health and safety risks\nand knowledge of existing standards and\nlegal requirements.\n\n4.\n\nMember States shall ensure that **_the_**\nnational **_supervisory authority is_** provided\nwith adequate **_technical,_** financial and\nhuman resources **_, and infrastructure_** to\nfulfil their tasks **_effectively_** under this\nRegulation.\n\nIn particular, **_the_** national\n**_supervisory authority_** shall have a\nsufficient number of personnel\npermanently available whose competences\nand expertise shall include an in-depth\nunderstanding of genai\ntechnologies, data and data computing,\n**_personal data protection, cybersecurity,_**\n**_competition law,_** fundamental rights,\nhealth and safety risks and knowledge of\nexisting standards and legal requirements.\n\n**_Member States shall assess and, if deemed_**\n**_necessary, update competence and_**\n**_resource requirements referred to in this_**\n**_paragraph on an annual basis._**", "**Article 59 \u2013 paragraph 4 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_4 a._** **_Each national supervisory authority_**\n**_shall exercise their powers and carry out_**\n**_their duties independently, impartially and_**\n**_without bias.\n\nThe members of each_**\n**_national supervisory authority, in the_**\n**_performance of their tasks and exercise of_**\n**_their powers under this Regulation, shall_**\n**_neither seek nor take instructions from_**\n**_any body and shall refrain from any_**\n**_action incompatible with their duties._**", "**Article 59 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nMember States shall report to the\nCommission on an annual basis on the\nstatus of the financial and human resources\nof the national **_competent authorities_** with\nan assessment of their adequacy.\n\nThe\nCommission shall transmit that information\nto the **_Board_** for discussion and possible\nrecommendations.\n\n5.\n\nMember States shall report to the\nCommission on an annual basis on the\nstatus of the financial and human resources\nof the national **_supervisory authority_** with\nan assessment of their adequacy.\n\nThe\nCommission shall transmit that information\nto the **_AI Office_** for discussion and possible\nrecommendations.", "**Article 59 \u2013 paragraph 7**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n7.\n\nNational **_competent_** authorities may\nprovide guidance and advice on the\nimplementation of this Regulation,\nincluding to **_small-scale providers_** .\n\nWhenever national **_competent authorities_**\nintend to provide guidance and advice with\nregard to an genai system in areas covered by\nother Union legislation, the competent\nnational authorities under that Union\nlegislation **_shall be consulted_** , as\nappropriate.\n\n**_Member States may also_**\n**_establish one central contact point for_**\n**_communication with operators._**\n\n\n7.\n\nNational **_supervisory_** authorities may\nprovide guidance and advice on the\nimplementation of this Regulation,\nincluding to **_SMEs and start-ups, taking_**\n**_into account the genai Office or the_**\n**_Commission\u2019s guidance and advice_** .\n\nWhenever **_the_** national **_supervisory_**\n**_authority_** intend to provide guidance and\nadvice with regard to an genai system in areas\ncovered by other Union **_law_** , the **_guidance_**\n**_shall be drafted in consultation with the_**\ncompetent national authorities under that\nUnion **_law_** , as appropriate.", "**Article 59 \u2013 paragraph 8**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n8.\n\nWhen Union institutions, agencies\nand bodies fall within the scope of this\nRegulation, the European Data Protection\nSupervisor shall act as the competent\nauthority for their supervision.\n\n8.\n\nWhen Union institutions, agencies\nand bodies fall within the scope of this\nRegulation, the European Data Protection\nSupervisor shall act as the competent\nauthority for their supervision **_and_**\n**_coordination_** .", "**Article 59 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 59 a_**\n\n**_Cooperation mechanism between national_**\n\n\n-----\n\n**_supervisory authorities in cases involving_**\n**_two or more Member States_**\n\n**_1.\n\nEach national supervisory authority_**\n**_shall perform its tasks and powers_**\n**_conferred on in accordance with this_**\n**_Regulation on the territory of its own_**\n**_Member State._**\n\n**_2.\n\nIn the event of a case involving two or_**\n**_more national supervisory authorities, the_**\n**_national supervisory authority of the_**\n**_Member State where the infringement_**\n**_took place shall be considered the lead_**\n**_supervisory authority._**\n\n**_3.\n\nIn the cases referred to in paragraph 2,_**\n**_the relevant supervisory authorities shall_**\n**_cooperate and exchange all relevant_**\n**_information in due time.\n\nNational_**\n**_supervisory authorities shall cooperate in_**\n**_order to reach a consensus._**", "**Article 60 \u2013 paragraph 1**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nThe Commission shall, in\ncollaboration with the Member States, set\nup and maintain a EU database containing\ninformation referred to in **_paragraph 2_**\nconcerning high-risk genai systems referred to\nin Article **_6(2)_** which are registered in\naccordance with Article 51.\n\n1.\n\nThe Commission shall, in\ncollaboration with the Member States, set\nup and maintain a **_public_** EU database\ncontaining information referred to in\n**_paragraphs 2 and 2a_** concerning high-risk\ngenai systems referred to in Article **_6 (2)_**\nwhich are registered in accordance with\nArticle 51.", "**Article 60 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe data listed in Annex VIII shall\nbe entered into the EU database by the\nproviders.\n\n**_The Commission shall provide_**\n**_them with technical and administrative_**\n**_support._**\n\n\n2.\n\nThe data listed in Annex VIII **_,_**\n**_Section A,_** shall be entered into the EU\ndatabase by the providers.", "**Article 60 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_The data listed in Annex VIII,_**\n**_Section B, shall be entered into the EU_**\n**_database by the deployers who are or who_**\n**_act on behalf of public authorities or_**\n**_Union institutions, bodies, offices or_**\n**_agencies and by deployers who are_**\n**_undertakings referred to in Article 51(1a)_**\n**_and (1b)._**", "**Article 60 \u2013 paragraph 3**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nInformation contained in the EU\ndatabase shall be **_accessible_** to the public.\n\n3.\n\nInformation contained in the EU\ndatabase shall be **_freely available_** to the\npublic **_, user-friendly and accessible, easily_**\n**_navigable and machine-readable_**\n**_containing structured digital data based_**\n**_on a standardised protocol_** .", "**Article 60 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nThe EU database shall contain\npersonal data only insofar as necessary for\ncollecting and processing information in\naccordance with this Regulation.\n\nThat\ninformation shall include the names and\ncontact details of natural persons who are\nresponsible for registering the system and\nhave the legal authority to represent the\nprovider.\n\n4.\n\nThe EU database shall contain\npersonal data only insofar as necessary for\ncollecting and processing information in\naccordance with this Regulation.\n\nThat\ninformation shall include the names and\ncontact details of natural persons who are\nresponsible for registering the system and\nhave the legal authority to represent the\nprovider **_or the deployer which is a public_**\n**_authority or Union institution, body,_**\n**_office or agency or a deployer acting on_**\n**_their behalf or a deployer which is an_**\n**_undertaking referred to in Article_**\n**_51(1a)(b) and (1b)_** .", "**Article 60 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nThe Commission shall be the\ncontroller of the EU database.\n\nIt shall also\nensure to providers adequate technical and\nadministrative support.\n\n5.\n\nThe Commission shall be the\ncontroller of the EU database.\n\nIt shall also\nensure to providers **_and deployers_** adequate\ntechnical and administrative support.\n\n**_The database shall comply with the_**\n**_accessibility requirements of Annex I to_**\n**_Directive (EU) 2019/882._**\n\n\n-----", "**Article 61 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe post-market monitoring system\nshall actively and systematically collect,\ndocument and analyse relevant data\nprovided by **_users_** or collected through\nother sources on the performance of highrisk genai systems throughout their lifetime,\nand allow the provider to evaluate the\ncontinuous compliance of genai systems with\nthe requirements set out in Title III,\nChapter 2.\n\n2.\n\nThe post-market monitoring system\nshall actively and systematically collect,\ndocument and analyse relevant data\nprovided by **_deployers_** or collected through\nother sources on the performance of highrisk genai systems throughout their lifetime,\nand allow the provider to evaluate the\ncontinuous compliance of genai systems with\nthe requirements set out in Title III,\nChapter 2.\n\n**_Where relevant, post-market_**\n**_monitoring shall include an analysis of_**\n**_the interaction with other genai systems_**\n**_environment, including other devices and_**\n**_software taking into account the rules_**\n**_applicable from areas such as data_**\n**_protection, intellectual property rights and_**\n**_competition law._**", "**Article 61 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nThe post-market monitoring system\nshall be based on a post-market monitoring\nplan.\n\nThe post-market monitoring plan\nshall be part of the technical\ndocumentation referred to in Annex IV.\n\nThe Commission shall adopt an\nimplementing act laying down detailed\nprovisions establishing a template for the\npost-market monitoring plan and the list of\nelements to be included in the plan.\n\n3.\n\nThe post-market monitoring system\nshall be based on a post-market monitoring\nplan.\n\nThe post-market monitoring plan\nshall be part of the technical\ndocumentation referred to in Annex IV.\n\nThe Commission shall adopt an\nimplementing act laying down detailed\nprovisions establishing a template for the\npost-market monitoring plan and the list of\nelements to be included in the plan **_by_**\n\n**_[twelve months after the date of entry into_**\n**_force of this Regulation]_** .", "**Article 62 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nProviders of high-risk genai systems\nplaced on the Union market shall report\nany serious incident **_or any_**\n**_malfunctioning_** of those systems which\nconstitutes a breach of obligations under\nUnion law intended to protect fundamental\nrights to the **_market surveillance_**\n**_authorities_** of the Member States where\nthat incident or breach occurred.\n\n1.\n\nProviders **_and, where deployers have_**\n**_identified a serious incident, deployers_** of\nhigh-risk genai systems placed on the Union\nmarket shall report any serious incident of\nthose systems which constitutes a breach of\nobligations under Union law intended to\nprotect fundamental rights to the **_national_**\n**_supervisory authority_** of the Member\nStates where that incident or breach\noccurred.", "**Article 62 \u2013 paragraph 1 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nSuch notification shall be made\n**_immediately_** after the provider has\nestablished a causal link between the genai\nsystem and the incident **_or malfunctioning_**\nor the reasonable likelihood of such a link,\nand, in any event, not later than **_15 days_**\nafter the **_providers_** becomes aware of the\nserious incident **_or of the malfunctioning_** .\n\nSuch notification shall be made **_without_**\n**_undue delay_** after the provider **_, or, where_**\n**_applicable the deployer,_** has established a\ncausal link between the genai system and the\nincident or the reasonable likelihood of\nsuch a link, and, in any event, not later than\n**_72 hours_** after the **_provider or, where_**\n**_applicable, the deployer_** becomes aware of\nthe serious incident.", "**Article 62 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nUpon receiving a notification related\nto a breach of obligations under Union law\nintended to protect fundamental rights, the\n**_market surveillance_** authority shall inform\nthe national public authorities or bodies\nreferred to in Article 64(3).\n\nThe\nCommission shall develop dedicated\nguidance to facilitate compliance with the\nobligations set out in paragraph 1.\n\nThat\nguidance shall be issued **_12 months after_**\nthe entry into force of this Regulation **_, at_**\n**_the latest_** .\n\n2.\n\nUpon receiving a notification related\nto a breach of obligations under Union law\nintended to protect fundamental rights, the\n**_national supervisory_** authority shall inform\nthe national public authorities or bodies\nreferred to in Article 64(3).\n\nThe\nCommission shall develop dedicated\nguidance to facilitate compliance with the\nobligations set out in paragraph 1.\n\nThat\nguidance shall be issued **_by [_** the entry into\nforce of this Regulation **_] and shall be_**\n**_assessed regularly_** .", "**Article 62 \u2013 paragraph 2 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_The national supervisory authority_**\n**_shall take appropriate measures within 7_**\n**_days from the date it received the_**\n**_notification referred to in paragraph 1._**\n**_Where the infringement takes place or is_**\n**_likely to take place in other Member_**\n**_States, the national supervisory authority_**\n**_shall notify the genai Office and the relevant_**\n**_national supervisory authorities of these_**\n**_Member States._**\n\n\n-----", "**Article 62 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nFor high-risk genai systems referred to\nin **_point 5(b) of_** Annex III **_which_** are placed\non the market or put into service by\nproviders that are **_credit institutions_**\n**_regulated by Directive 2013/36/EU and_**\n**_for high-risk genai systems which are safety_**\n**_components of devices, or are themselves_**\n**_devices, covered by_** Regulation **_(EU)_**\n**_2017/745 and Regulation (EU) 2017/746_** ,\nthe notification of serious incidents **_or_**\n**_malfunctioning shall be limited to those_**\n**_that that constitute_** a breach of **_obligations_**\n**_under Union law intended to protect_**\nfundamental rights.\n\n3.\n\nFor high-risk genai systems referred to\nin Annex III **_that_** are placed on the market\nor put into service by providers that are\n**_subject to Union legislative instruments_**\n**_laying down reporting obligations_**\n**_equivalent to those set out in this_**\nRegulation, the notification of serious\nincidents **_constituting_** a breach of\nfundamental rights **_under Union law shall_**\n**_be transferred to the national supervisory_**\n**_authority_** .", "**Article 63 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nRegulation (EU) 2019/1020 shall\napply to genai systems covered by this\nRegulation.\n\nHowever, for the purpose of\nthe effective enforcement of this\nRegulation:\n\n\n1.\n\nRegulation (EU) 2019/1020 shall\napply to genai systems **_and foundation_**\n**_models_** covered by this Regulation.\n\nHowever, for the purpose of the effective\nenforcement of this Regulation:\n\n\n-----", "**Article 63 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe national supervisory authority\nshall report to the Commission **_on a_**\n**_regular basis_** the outcomes of relevant\nmarket surveillance activities.\n\nThe national\nsupervisory authority shall report, without\ndelay, to the Commission and relevant\nnational competition authorities any\ninformation identified in the course of\nmarket surveillance activities that may be\nof potential interest for the application of\nUnion law on competition rules.\n\n2.\n\nThe national supervisory authority\nshall report to the Commission **_and the AI_**\n**_Office annually_** the outcomes of relevant\nmarket surveillance activities.\n\nThe national\nsupervisory authority shall report, without\ndelay, to the Commission and relevant\nnational competition authorities any\ninformation identified in the course of\nmarket surveillance activities that may be\nof potential interest for the application of\nUnion law on competition rules.", "**Article 63 \u2013 paragraph 3 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_3 a._** **_For the purpose of ensuring the_**\n**_effective enforcement of this Regulation,_**\n**_national supervisory authorities may:_**\n\n**_(a) carry out unannounced on-site and_**\n**_remote inspections of high-risk AI_**\n**_systems;_**\n\n**_(b) acquire samples related to high-risk_**\n\n\n-----\n\n**_AI systems, including through remote_**\n**_inspections, to reverse-engineer the AI_**\n**_systems and to acquire evidence to_**\n**_identify non-compliance._**", "**Article 63 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nFor genai systems **_listed in point 1(a) in_**\n**_so far as the systems_** are used for law\nenforcement purposes **_, points 6 and 7 of_**\n**_Annex III_** , Member States shall designate\nas market surveillance authorities for the\npurposes of this Regulation **_either_** the\ncompetent data protection supervisory\nauthorities under Directive (EU) 2016/680 **_,_**\n**_or Regulation 2016/679 or the national_**\n**_competent authorities supervising the_**\n**_activities of the law enforcement,_**\n**_immigration or asylum authorities putting_**\n**_into service or using those systems_** .\n\n5.\n\nFor genai systems **_that_** are used for law\nenforcement purposes, Member States shall\ndesignate as market surveillance authorities\nfor the purposes of this Regulation the\ncompetent data protection supervisory\nauthorities under Directive (EU) 2016/680.", "**Article 63 \u2013 paragraph 7**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n7.\n\n**_Member States shall facilitate the_**\n**_coordination between market surveillance_**\nauthorities designated under this\nRegulation **_and_** other relevant national\nauthorities or bodies which supervise the\napplication of Union harmonisation\nlegislation listed in Annex II or other\nUnion legislation that might be relevant for\nthe high-risk genai systems referred to in\nAnnex III.\n\n7.\n\n**_National supervisory_** authorities\ndesignated under this Regulation **_shall_**\n**_coordinate with_** other relevant national\nauthorities or bodies which supervise the\napplication of Union harmonisation **_law_**\nlisted in Annex II or other Union **_law_** that\nmight be relevant for the high-risk genai\nsystems referred to in Annex III.", "**Article 64 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\n**_Access to data and documentation_** in\nthe context of their activities, **_the market_**\n**_surveillance authorities_** shall be granted\nfull access to the training, validation and\ntesting datasets used by the provider,\n**_including_** through **_application_**\n**_programming interfaces (\u2018API\u2019) or other_**\nappropriate technical means and tools\n**_enabling remote access_** .\n\n1.\n\nIn the context of their activities, **_and_**\n**_upon their reasoned request the national_**\n**_supervisory authority_** shall be granted full\naccess to the training, validation and\ntesting datasets used by the provider, **_or,_**\n**_where relevant, the deployer, that are_**\n**_relevant and strictly necessary for the_**\n**_purpose of its request_** through appropriate\ntechnical means and tools.", "**Article 64 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWhere necessary to assess the\nconformity of the high-risk genai system with\nthe requirements set out in Title III,\nChapter 2 and upon a reasoned request, the\n**_market surveillance authorities_** shall be\ngranted access to the **_source code_** of the genai\nsystem.\n\n2.\n\nWhere necessary to assess the\nconformity of the high-risk genai system with\nthe requirements set out in Title III,\nChapter 2 **_, after all other reasonable ways_**\n**_to verify conformity including paragraph_**\n**_1 have been exhausted and have proven to_**\n**_be insufficient,_** and upon a reasoned\nrequest, the **_national supervisory authority_**\nshall be granted access to the **_training and_**\n**_trained models_** of the genai system **_, including_**\n**_its relevant model parameters_** .\n\n**_All_**\n**_information in line with Article 70_**\n**_obtained shall be treated as confidential_**\n**_information and shall be subject to_**\n**_existing Union law on the protection of_**\n**_intellectual property and trade secrets and_**\n**_shall be deleted upon the completion of_**\n**_the investigation for which the_**\n**_information was requested._**", "**Article 64 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nNational public authorities or bodies\nwhich supervise or enforce the respect of\nobligations under Union law protecting\nfundamental rights in relation to the use of\nhigh-risk genai systems referred to in Annex\nIII shall have the power to request and\naccess any documentation created or\nmaintained under this Regulation when\naccess to that documentation is necessary\nfor the fulfilment of the competences under\ntheir mandate within the limits of their\njurisdiction.\n\nThe relevant public authority\nor body shall inform the **_market_**\n**_surveillance_** authority of the Member State\nconcerned of any such request.\n\n3.\n\nNational public authorities or bodies\nwhich supervise or enforce the respect of\nobligations under Union law protecting\nfundamental rights in relation to the use of\nhigh-risk genai systems referred to in Annex\nIII shall have the power to request and\naccess any documentation created or\nmaintained under this Regulation when\naccess to that documentation is necessary\nfor the fulfilment of the competences under\ntheir mandate within the limits of their\njurisdiction.\n\nThe relevant public authority\nor body shall inform the **_national_**\n**_supervisory_** authority of the Member State\nconcerned of any such request.", "**Article 64 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nBy 3 months after the entering into\nforce of this Regulation, each Member\nState shall identify the public authorities or\nbodies referred to in paragraph 3 and make\na list publicly available on the website of\nthe national supervisory authority.\n\n**_Member_**\n**_States_** shall notify the list to the\nCommission and all other **_Member States_**\nand keep the list up to date.\n\n4.\n\nBy 3 months after the entering into\nforce of this Regulation, each Member\nState shall identify the public authorities or\nbodies referred to in paragraph 3 and make\na list publicly available on the website of\nthe national supervisory authority.\n\n**_National supervisory authorities_** shall\nnotify the list to the Commission, **_the AI_**\n**_Office,_** and all other **_national supervisory_**\n**_authorities_** and keep the list up to date.\n\n-----\n\n**_The Commission shall publish in a_**\n**_dedicated website the list of all the_**\n**_competent authorities designated by the_**\n**_Member States in accordance with this_**\n**_Article._**", "**Article 64 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nWhere the documentation referred to\nin paragraph 3 is insufficient to ascertain\nwhether a breach of obligations under\nUnion law intended to protect fundamental\nrights has occurred, the public authority or\nbody referred to paragraph 3 may make a\nreasoned request to the **_market_**\n**_surveillance_** authority to organise testing\nof the high-risk genai system through\ntechnical means.\n\nThe **_market surveillance_**\nauthority shall organise the testing with the\nclose involvement of the requesting public\nauthority or body within reasonable time\nfollowing the request.\n\n5.\n\nWhere the documentation referred to\nin paragraph 3 is insufficient to ascertain\nwhether a breach of obligations under\nUnion law intended to protect fundamental\nrights has occurred, the public authority or\nbody referred to **_in_** paragraph 3 may make\na reasoned request to the **_national_**\n**_supervisory_** authority **_,_** to organise testing\nof the high-risk genai system through\ntechnical means.\n\nThe **_national supervisory_**\nauthority shall organise the testing with the\nclose involvement of the requesting public\nauthority or body within reasonable time\nfollowing the request.", "**Article 65 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1. genai systems presenting a risk shall be\nunderstood as **_a product presenting a risk_**\n**_defined in Article 3, point 19 of_**\n**_Regulation (EU) 2019/1020 insofar as_**\n**_risks to the_** health **_or_** safety **_or to the_**\n**_protection of_** fundamental rights of persons\nare concerned.\n\n1. genai systems presenting a risk shall be\nunderstood as **_an genai system having the_**\n**_potential to affect adversely_** health **_and_**\nsafety **_,_** fundamental rights of persons **_in_**\n**_general, including in the workplace,_**\n**_protection of consumers, the environment,_**\n**_public security, or democracy or the rule_**\n**_of law and other public interests, that are_**\n**_protected by the applicable Union_**\n**_harmonisation law, to a degree which_**\n**_goes beyond that considered reasonable_**\n**_and acceptable in relation to its intended_**\n**_purpose or under the normal or_**\n\n\n-----\n\n**_reasonably foreseeable conditions of use_**\n**_of the system_** are concerned **_, including the_**\n**_duration of use and, where applicable, its_**\n**_putting into service, installation and_**\n**_maintenance requirements_** .", "**Article 65 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWhere the **_market surveillance_**\nauthority of a Member State has sufficient\nreasons to consider that an genai system\npresents a risk as referred to in paragraph\n1, **_they_** shall carry out an evaluation of the\ngenai system concerned in respect of its\ncompliance with all the requirements and\nobligations laid down in this Regulation.\n\nWhen risks **_to the protection of_**\nfundamental rights are present, the **_market_**\n**_surveillance_** authority shall also inform the\nrelevant national public authorities or\nbodies referred to in Article 64(3).\n\nThe\nrelevant operators shall cooperate as\nnecessary with the **_market surveillance_**\n**_authorities_** and the other national public\nauthorities or bodies referred to in Article\n64(3).\n\n2.\n\nWhere the **_national supervisory_**\nauthority of a Member State has sufficient\nreasons to consider that an genai system\npresents a risk as referred to in paragraph\n1, **_it_** shall carry out an evaluation of the genai\nsystem concerned in respect of its\ncompliance with all the requirements and\nobligations laid down in this Regulation.\n\nWhen risks to fundamental rights are\npresent, the **_national supervisory_** authority\nshall also **_immediately_** inform **_and fully_**\n**_cooperate with_** the relevant national public\nauthorities or bodies referred to in Article\n64(3); **_Where there is sufficient reason to_**\n**_consider that that an genai system exploits_**\n**_the vulnerabilities of vulnerable groups or_**\n**_violates their rights intentionally or_**\n**_unintentionally, the national supervisory_**\n**_authority shall have the duty to investigate_**\n**_the design goals, data inputs, model_**\n**_selection, implementation and outcomes_**\n**_of the genai system ._** The relevant operators\nshall cooperate as necessary with the\n**_national supervisory authority_** and the\nother national public authorities or bodies\nreferred to in Article 64(3);", "**Article 65 \u2013 paragraph 2 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\nWhere, in the course of that evaluation, the Where, in the course of that evaluation, the\n\n\n-----\n\n**_market surveillance_** authority finds that the\ngenai system does not comply with the\nrequirements and obligations laid down in\nthis Regulation, it shall without delay\nrequire the relevant operator to take all\nappropriate corrective actions to bring the\ngenai system into compliance, to withdraw\nthe genai system from the market, or to recall\nit within a reasonable period,\ncommensurate with the nature of the risk,\nas it may prescribe **_._**\n\n\n**_national supervisory_** authority **_or, where_**\n**_relevant, the national public authority_**\n**_referred to in Article 64(3)_** finds that the\ngenai system does not comply with the\nrequirements and obligations laid down in\nthis Regulation, it shall without delay\nrequire the relevant operator to take all\nappropriate corrective actions to bring the\ngenai system into compliance, to withdraw\nthe genai system from the market, or to recall\nit within a reasonable period,\ncommensurate with the nature of the risk,\nas it may prescribe **_and in any event no_**\n**_later than fifteen working days or as_**\n**_provided for in the relevant Union_**\n**_harmonisation law as applicable_**", "**Article 65 \u2013 paragraph 2 \u2013 subparagraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nThe **_market surveillance_** authority shall\ninform the relevant notified body\naccordingly.\n\nArticle 18 of Regulation (EU)\n2019/1020 shall apply to the measures\nreferred to in the second subparagraph.\n\nThe **_national supervisory_** authority shall\ninform the relevant notified body\naccordingly.\n\nArticle 18 of Regulation (EU)\n2019/1020 shall apply to the measures\nreferred to in the second subparagraph.", "**Article 65 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nWhere the **_market surveillance_**\nauthority considers that non-compliance is\nnot restricted to its national territory, it\nshall inform the Commission **_and_** the other\nMember States of the results of the\nevaluation and of the actions which it has\nrequired the operator to take.\n\n3.\n\nWhere the **_national supervisory_**\nauthority considers that non-compliance is\nnot restricted to its national territory, it\nshall inform the Commission **_, the AI_**\n**_Office and the national supervisory_**\n**_authority of_** the other Member States\n**_without undue delay_** of the results of the\nevaluation and of the actions which it has\nrequired the operator to take.\n\n-----", "**Article 65 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nWhere the operator of an genai system\ndoes not take adequate corrective action\nwithin the period referred to in paragraph\n2, the **_market surveillance_** authority shall\ntake all appropriate provisional measures to\nprohibit or restrict the genai system's being\nmade available on its national market, to\nwithdraw the **_product_** from that market or\nto recall it.\n\nThat authority shall inform the\nCommission **_and_** the other Member States **_,_**\n**_without delay,_** of those measures.\n\n5.\n\nWhere the operator of an genai system\ndoes not take adequate corrective action\nwithin the period referred to in paragraph\n2, the **_national supervisory_** authority shall\ntake all appropriate provisional measures to\nprohibit or restrict the genai system's being\nmade available on its national market **_or_**\n**_put into service_** , to withdraw the **_AI system_**\nfrom that market or to recall it.\n\nThat\nauthority shall **_immediately_** inform the\nCommission **_, the genai Office and the_**\n**_national supervisory authority of_** the other\nMember States of those measures.", "**Article 65 \u2013 paragraph 6 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\nThe information referred to in\nparagraph 5 shall include all available\ndetails, in particular the data necessary for\nthe identification of the non-compliant genai\nsystem, the origin of the genai system, the\nnature of the non-compliance alleged and\nthe risk involved, the nature and duration\nof the national measures taken and the\narguments put forward by the relevant\noperator.\n\nIn particular, the **_market_**\n**_surveillance authorities_** shall indicate\nwhether the non-compliance is due to one\nor more of the following:\n\n\n6.\n\nThe information referred to in\nparagraph 5 shall include all available\ndetails, in particular the data necessary for\nthe identification of the non-compliant genai\nsystem, the origin of the genai system **_and the_**\n**_supply chain_** , the nature of the noncompliance alleged and the risk involved,\nthe nature and duration of the national\nmeasures taken and the arguments put\nforward by the relevant operator.\n\nIn\nparticular, the **_national supervisory_**\n**_authority_** shall indicate whether the noncompliance is due to one or more of the\nfollowing:", "**Article 65 \u2013 paragraph 7**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n7.\n\nThe **_market surveillance_** authorities\nof the Member States other than the **_market_**\n**_surveillance_** authority of the Member State\ninitiating the procedure shall without delay\ninform the Commission and the other\nMember States of any measures adopted\nand of any additional information at their\ndisposal relating to the non-compliance of\nthe genai system concerned, and, in the event\nof disagreement with the notified national\nmeasure, of their objections.\n\n7.\n\nThe **_national supervisory_** authorities\nof the Member States other than the\n**_national supervisory_** authority of the\nMember State initiating the procedure shall\nwithout delay inform the Commission **_, the_**\n**_AI Office_** and the other Member States of\nany measures adopted and of any\nadditional information at their disposal\nrelating to the non-compliance of the genai\nsystem concerned, and, in the event of\ndisagreement with the notified national\n\n\n-----\n\nmeasure, of their objections.", "**Article 65 \u2013 paragraph 8**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n8.\n\nWhere, within three months of\nreceipt of the information referred to in\nparagraph 5, no objection has been raised\nby either a Member State or the\nCommission in respect of a provisional\nmeasure taken by a Member State, that\nmeasure shall be deemed justified.\n\nThis is\nwithout prejudice to the procedural rights\nof the concerned operator in accordance\nwith Article 18 of Regulation (EU)\n2019/1020.\n\n8.\n\nWhere, within three months of\nreceipt of the information referred to in\nparagraph 5, no objection has been raised\nby either a **_national supervisory authority_**\n**_of a_** Member State or the Commission in\nrespect of a provisional measure taken by a\n**_national supervisory authority of another_**\nMember State, that measure shall be\ndeemed justified.\n\nThis is without prejudice\nto the procedural rights of the concerned\noperator in accordance with Article 18 of\nRegulation (EU) 2019/1020.\n\n**_The period_**\n**_referred to in the first sentence of this_**\n**_paragraph shall be reduced to thirty days_**\n**_in the event of non-compliance with the_**\n**_prohibition of the artificial intelligence_**\n**_practices referred to in Article 5._**", "**Article 65 \u2013 paragraph 9**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n9.\n\nThe **_market surveillance_** authorities\nof all Member States shall ensure that\nappropriate restrictive measures are taken\nin respect of the **_product_** concerned, such\nas withdrawal of the **_product_** from their\nmarket, without delay.\n\n9.\n\nThe **_national supervisory_** authorities\nof all Member States shall ensure that\nappropriate restrictive measures are taken\nin respect of the **_AI system_** concerned, such\nas withdrawal of the **_AI system_** from their\nmarket, without delay.", "**Article 65 \u2013 paragraph 9 a (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_9 a._** **_National supervisory authorities_**\n**_shall annually report to the genai Office_**\n**_about the use of prohibited practices that_**\n**_occurred during that year and about the_**\n**_measures taken to eliminate or mitigate_**\n**_the risks in accordance with this Article._**", "**Article 66 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nWhere, within three months of\nreceipt of the notification referred to in\nArticle 65(5), objections are raised by a\nMember State against a measure taken by\nanother **_Member State_** , or where the\nCommission considers the measure to be\ncontrary to Union law, the Commission\nshall without delay enter into consultation\nwith the relevant Member State and\noperator or operators and shall evaluate the\nnational measure.\n\nOn the basis of the\nresults of that evaluation, the Commission\nshall decide whether the national measure\nis justified or not within **_9_** months from the\nnotification referred to in Article 65(5) and\nnotify such decision to the Member State\nconcerned.\n\n1.\n\nWhere, within three months of\nreceipt of the notification referred to in\nArticle 65(5), **_or 30 days in the case of_**\n**_non-compliance with the prohibition of_**\n**_the genai practices_**\n**_referred to in Article 5,_** objections are\nraised by **_the national supervisory_**\n**_authority of_** a Member State against a\nmeasure taken by another **_national_**\n**_supervisory authority,_** or where the\nCommission considers the measure to be\ncontrary to Union law, the Commission\nshall without delay enter into consultation\nwith **_the national supervisory authority of_**\nthe relevant Member State and operator or\noperators and shall evaluate the national\nmeasure.\n\nOn the basis of the results of that\nevaluation, the Commission shall decide\nwhether the national measure is justified or\nnot within **_three_** months **_, or 60 days in the_**\n**_case of non-compliance with the_**\n**_prohibition of the artificial intelligence_**\n**_practices referred to in Article 5, starting_**\nfrom the notification referred to in Article\n65(5) and notify such decision to the\n**_national supervisory authority of the_**\nMember State concerned.\n\n**_The Commission_**\n**_shall also inform all other national_**\n**_supervisory authorities of such decision._**", "**Article 66 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nIf the national measure is considered\njustified, all **_Member States_** shall take the\nmeasures necessary to ensure that the noncompliant genai system is withdrawn from\ntheir market, and shall inform the\nCommission accordingly.\n\nIf the national\nmeasure is considered unjustified, the\nMember State concerned shall withdraw\nthe measure.\n\n2.\n\nIf the national measure is considered\njustified, all **_national supervisory_**\n**_authorities designated under this_**\n**_Regulation_** shall take the measures\nnecessary to ensure that the non-compliant\ngenai system is withdrawn from their market\n**_without delay_** , and shall inform the\nCommission **_and the genai Office_**\naccordingly.\n\nIf the national measure is\nconsidered unjustified, the **_national_**\n**_supervisory authority of the_** Member State\nconcerned shall withdraw the measure.", "**Article 66 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 66 a_**\n\n**_Joint investigations_**\n\n**_Where a national supervisory authority_**\n**_has reasons to suspect that the_**\n**_infringement by a provider or a deployer_**\n**_of a high-risk genai system or foundation_**\n**_model to this Regulation amount to a_**\n**_widespread infringement with a Union_**\n**_dimension, or affects or is likely affect at_**\n**_least 45 million individuals, in more than_**\n**_one Member State, that national_**\n**_supervisory authority shall inform the AI_**\n**_Office and may request the national_**\n**_supervisory authorities of the Member_**\n**_States where such infringement took place_**\n**_to start a joint investigation.\n\nThe AI_**\n**_Office shall provide central coordination_**\n**_to the joint investigation.\n\nInvestigation_**\n**_powers shall remain within the_**\n**_competence of the national supervisory_**\n**_authorities._**\n\n\n-----", "**Article 67 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nWhere, having performed an\nevaluation under Article 65, **_the market_**\n**_surveillance_** authority of a Member State\nfinds that although an genai system is in\ncompliance with this Regulation, it\npresents a risk to the health or safety of\npersons, to the compliance with obligations\nunder Union or national law intended to\nprotect fundamental rights or to other\naspects of public interest protection, it shall\nrequire the relevant operator to take all\nappropriate measures to ensure that the genai\nsystem concerned, when placed on the\nmarket or put into service, no longer\npresents that risk **_, to withdraw the AI_**\n**_system from the market or to recall it_**\n**_within a reasonable period,_**\n**_commensurate with the nature of the risk,_**\n**_as it may prescribe_** .\n\n1.\n\nWhere, having performed an\nevaluation under Article 65, **_in full_**\n**_cooperation with the relevant national_**\n**_public authority referred to in Article_**\n**_64(3), the national supervisory_** authority\nof a Member State finds that although an\ngenai system is in compliance with this\nRegulation, it presents a **_serious_** risk to the\nhealth or safety of persons, to the\ncompliance with obligations under Union\nor national law intended to protect\nfundamental rights **_, or the environment or_**\n**_the democracy and rule of law_** or to other\naspects of public interest protection , it\nshall require the relevant operator to take\nall appropriate measures to ensure that the\ngenai system concerned, when placed on the\nmarket or put into service, no longer\npresents that risk.", "**Article 67 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe provider or other relevant\noperators shall ensure that corrective action\nis taken in respect of all the genai systems\nconcerned that they have made available\non the market throughout the Union within\nthe timeline prescribed by the **_market_**\n**_surveillance_** authority of the Member State\nreferred to in paragraph 1.\n\n2.\n\nThe provider or other relevant\noperators shall ensure that corrective action\nis taken in respect of all the genai systems\nconcerned that they have made available\non the market throughout the Union within\nthe timeline prescribed by the **_national_**\n**_supervisory authority_** authority of the\nMember State referred to in paragraph 1.", "**Article 67 \u2013 paragraph 2 a (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_2 a._** **_Where the provider or other relevant_**\n**_operators fail to take corrective action as_**\n**_referred to in paragraph 2 and the AI_**\n**_system continues to present a risk as_**\n**_referred to in paragraph 1, the national_**\n**_supervisory authority may require the_**\n**_relevant operator to withdraw the AI_**\n**_system from the market or to recall it_**\n**_within a reasonable period,_**\n**_commensurate with the nature of the risk._**", "**Article 67 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nThe **_Member State_** shall immediately\ninform the Commission and the other\n**_Member States_** .\n\nThat information shall\ninclude all available details, in particular\nthe data necessary for the identification of\nthe genai system concerned, the origin and the\nsupply chain of the genai system, the nature\nof the risk involved and the nature and\nduration of the national measures taken.\n\n3.\n\nThe **_national supervisory authority_**\nshall immediately inform the Commission **_,_**\n**_the genai Office_** and the other **_national_**\n**_supervisory authorities_** .\n\nThat information\nshall include all available details, in\nparticular the data necessary for the\nidentification of the genai system concerned,\nthe origin and the supply chain of the genai\nsystem, the nature of the risk involved and\nthe nature and duration of the national\nmeasures taken.", "**Article 67 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nThe Commission shall without delay\nenter into consultation with the **_Member_**\n**_States_** and the relevant operator and shall\nevaluate the national measures taken.\n\nOn\nthe basis of the results of that evaluation,\nthe **_Commission_** shall decide whether the\nmeasure is justified or not and, where\nnecessary, propose appropriate measures.\n\n4.\n\nThe Commission **_, in consultation_**\n**_with the genai Office_** shall without delay\nenter into consultation with the **_national_**\n**_supervisory authorities concerned_** and the\nrelevant operator and shall evaluate the\nnational measures taken.\n\nOn the basis of\nthe results of that evaluation, the **_AI Office_**\nshall decide whether the measure is\n\n\n-----\n\njustified or not and, where necessary,\npropose appropriate measures.", "**Article 67 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nThe Commission shall **_address_** its\ndecision to the Member States.\n\n5.\n\nThe Commission **_, in consultation_**\n**_with the genai Office_** shall **_immediately_**\n**_communicate_** its decision to the **_national_**\n**_supervisory authorities of the_** Member\nStates **_concerned and to the relevant_**\n**_operators_** .\n\n**_It shall also inform the decision_**\n**_to all other national supervisory_**\n**_authorities._**", "**Article 68 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nWhere the **_market surveillance_**\nauthority of a Member State makes one of\nthe following findings, it shall require the\nrelevant provider to put an end to the noncompliance concerned:\n\n\n1.\n\nWhere the **_national supervisory_**\nauthority of a Member State makes one of\nthe following findings, it shall require the\nrelevant provider to put an end to the noncompliance concerned:\n\n\n-----", "**Article 68 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWhere the non-compliance referred\nto in paragraph 1 persists, the Member\nState concerned shall take **_all_** appropriate\nmeasures to restrict or prohibit the highrisk genai system being made available on the\nmarket or ensure that it is recalled or\nwithdrawn from the market.\n\n2.\n\nWhere the non-compliance referred\nto in paragraph 1 persists, the **_national_**\n**_supervisory authority of the_** Member State\nconcerned shall take appropriate **_and_**\n**_proportionate_** measures to restrict or\nprohibit the high-risk genai system being\nmade available on the market or ensure that\nit is recalled or withdrawn from the market\n**_without delay_** .\n\n**_The national supervisory_**\n**_authority of the Member State concerned_**\n**_shall immediately inform the genai Office of_**\n**_the non-compliance and the measures_**\n**_taken._**", "**Article 68 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 68 a_**\n\n**_Right to lodge a complaint with a national_**\n**_supervisory authority_**\n\n\n-----\n\n**_1.\n\nWithout prejudice to any other_**\n**_administrative or judicial remedy, every_**\n**_natural persons or groups of natural_**\n**_persons shall have the right to lodge a_**\n**_complaint with a national supervisory_**\n**_authority, in particular in the Member_**\n**_State of his or her habitual residence,_**\n**_place of work or place of the alleged_**\n**_infringement if they consider that the AI_**\n**_system relating to him or her infringes_**\n**_this Regulation._**\n\n**_2.\n\nThe national supervisory authority with_**\n**_which the complaint has been lodged_**\n**_shall inform the complainant on the_**\n**_progress and the outcome of the_**\n**_complaint including the possibility of a_**\n**_judicial remedy pursuant to Article 78._**", "**Article 68 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 68 b_**\n\n**_Right to an effective judicial remedy_**\n**_against a national supervisory authority_**\n\n**_1.\n\nWithout prejudice to any other_**\n**_administrative or non-judicial remedy,_**\n**_each natural or legal person shall have_**\n**_the right to an effective judicial remedy_**\n**_against a legally binding decision of a_**\n**_national supervisory authority concerning_**\n**_them._**\n\n**_2.\n\nWithout prejudice to any other_**\n**_administrative or non-judicial remedy,_**\n**_each natural or legal person shall have_**\n**_the right to a an effective judicial remedy_**\n**_where the national supervisory authority_**\n**_which is competent pursuant to Articles_**\n**_59 does not handle a complaint or does_**\n**_not inform the data subject within three_**\n**_months on the progress or outcome of the_**\n**_complaint lodged pursuant to Article 68a._**\n\n**_3.\n\nProceedings against a national_**\n**_supervisory authority shall be brought_**\n\n\n-----\n\n**_before the courts of the Member State_**\n**_where the national supervisory authority_**\n**_is established._**\n\n**_4.\n\nWhere proceedings are brought against_**\n**_a decision of a national supervisory_**\n**_authority which was preceded by an_**\n**_opinion or a decision of the Commission_**\n**_in the union safeguard procedure, the_**\n**_supervisory authority shall forward that_**\n**_opinion or decision to the court._**", "**Article 68 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 68 c_**\n\n**_A right to explanation of individual_**\n**_decision-making_**\n\n**_1.\n\nAny affected person subject to a_**\n**_decision which is taken by the deployer on_**\n**_the basis of the output from an high-risk_**\n**_AI system which produces legal effects or_**\n**_similarly significantly affects him or her_**\n**_in a way that they consider to adversely_**\n**_impact their health, safety, fundamental_**\n**_rights, socio-economic well-being or any_**\n**_other of the rights deriving from the_**\n**_obligations laid down in this Regulation,_**\n**_shall have the right to request from the_**\n**_deployer clear and meaningful_**\n**_explanation pursuant to Article 13(1) on_**\n**_the role of the genai system in the decisionmaking procedure, the main parameters_**\n**_of the decision taken and the related input_**\n**_data._**\n\n**_2.\n\nParagraph 1 shall not apply to the use_**\n**_of genai systems for which exceptions from,_**\n**_or restrictions to, the obligation under_**\n**_paragraph 1 follow from Union or_**\n**_national law are provided in so far as_**\n**_such exception or restrictions respect the_**\n**_essence of the fundamental rights and_**\n**_freedoms and is a necessary and_**\n**_proportionate measure in a democratic_**\n\n\n-----\n\n**_society._**\n\n**_3.\n\nThis Article shall apply without_**\n**_prejudice to Articles 13, 14, 15, and 22 of_**\n**_the Regulation 2016/679._**", "**Article 68 d (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 68 d_**\n\n**_Amendment to Directive (EU) 2020/1828_**\n\n**_In Annex I to Directive (EU) 2020/1828 of_**\n**_the European Parliament and of the_**\n**_Council_** **_1a_** **_, the following point is added:_**\n\n**_\u201c(67a) Regulation xxxx/xxxx of the_**\n**_European Parliament and of the Council_**\n\n**_[laying down harmonised rules on_**\n**_artificial intelligence (Artificial_**\n**_Intelligence Act) and amending certain_**\n**_Union legislative acts (OJ L ...)]\u201d._**\n\n**___________________**\n\n**_1a_** **_Directive (EU) 2020/1828 of the_**\n**_European Parliament and of the Council_**\n**_of 25 November 2020 on representative_**\n**_actions for the protection of the collective_**\n**_interests of consumers and repealing_**\n**_Directive 2009/22/EC (OJ L 409,_**\n**_4.12.2020, p. 1)._**", "**Article 68 e (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 68 e_**\n\n**_Reporting of breaches and protection of_**\n**_reporting persons_**\n\n**_Directive (EU) 2019/1937 of the_**\n**_European Parliament and of the Council_**\n\n\n-----\n\n**_shall apply to the reporting of breaches of_**\n**_this Regulation and the protection of_**\n**_persons reporting such breaches._**", "**Article 69 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nThe Commission and the Member\nStates shall encourage and facilitate the\ndrawing up of codes of conduct intended to\nfoster the voluntary application to genai\nsystems other than high-risk genai systems of\nthe requirements set out in Title III,\nChapter 2 on the basis of technical\nspecifications and solutions that are\nappropriate means of ensuring compliance\nwith such requirements in light of the\nintended purpose of the systems.\n\n1.\n\nThe Commission, **_the genai Office_** and\nthe Member States shall encourage and\nfacilitate the drawing up of codes of\nconduct intended **_, including where they_**\n**_are drawn up in order to demonstrate how_**\n**_AI systems respect the principles set out in_**\n**_Article 4a and can thereby be considered_**\n**_trustworthy,_** to foster the voluntary\napplication to genai systems other than highrisk genai systems of the requirements set out\nin Title III, Chapter 2 on the basis of\ntechnical specifications and solutions that\nare appropriate means of ensuring\ncompliance with such requirements in light\nof the intended purpose of the systems.", "**Article 69 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\n**_The Commission and the Board_**\n**_shall encourage and facilitate the drawing_**\n**_up of_** codes of **_conduct_** intended to foster\nthe voluntary **_application to_** genai systems **_of_**\n**_requirements related for example_** to\nenvironmental sustainability **_, accessibility_**\n**_for persons with a disability, stakeholders_**\n**_participation in the design and_**\n**_development of the genai systems and_**\n**_diversity of development teams on the_**\n**_basis of clear objectives and key_**\n**_performance indicators to measure the_**\n**_achievement of those objectives_** .\n\n2.\n\nCodes of **_conduct_** intended to foster\nthe voluntary **_compliance with the_**\n**_principles underpinning trustworthy AI_**\n**_systems, shall, in particular:_**\n\n\n-----\n\n**_(a)_** **_aim for a sufficient level of AI_**\n**_literacy among their staff and other_**\n**_persons dealing with the operation and_**\n**_use of_** genai systems **_in order to observe such_**\n**_principles;_**\n\n**_(b)_** **_assess to what extent their AI_**\n**_systems may affect vulnerable persons or_**\n**_groups of persons, including children, the_**\n**_elderly, migrants and persons with_**\n**_disabilities or whether measures could be_**\n**_put in place in order to increase_**\n**_accessibility, or otherwise support such_**\n**_persons or groups of persons;_**\n\n**_(c)_** **_consider the way in which the use of_**\n**_their genai systems may have an impact or_**\n**_can increase diversity, gender balance_**\n**_and equality;_**\n\n**_(d)_** **_have regard to whether their AI_**\n**_systems can be used in a way that, directly_**\n**_or indirectly, may residually or_**\n**_significantly reinforce existing biases or_**\n**_inequalities;_**\n\n**_(e)_** **_reflect on the need and relevance of_**\n**_having in place diverse development_**\n**_teams in view of securing an inclusive_**\n**_design of their systems;_**\n\n**_(f)_** **_give careful consideration to_**\n**_whether their systems can have a negative_**\n**_societal impact, notably concerning_**\n**_political institutions and democratic_**\n**_processes;_**\n\n**_(g)_** **_evaluate how genai systems can_**\n**_contribute_** to environmental sustainability\n**_and in particular to the Union\u2019s_**\n**_commitments under the European Green_**\n**_Deal and the European Declaration on_**\n**_Digital Rights and Principles_** .", "**Article 69 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n3.\n\nCodes of conduct may be drawn up 3.\n\nCodes of conduct may be drawn up\n\n\n-----\n\nby individual providers of genai systems or by\norganisations representing them or by both,\nincluding with the involvement of users\nand any interested stakeholders and their\nrepresentative organisations.\n\nCodes of\nconduct may cover one or more genai systems\ntaking into account the similarity of the\nintended purpose of the relevant systems.\n\nby individual providers of genai systems or by\norganisations representing them or by both,\nincluding with the involvement of users\nand any interested stakeholders **_, including_**\n**_scientific researchers,_** and their\nrepresentative **_organisations, in particular_**\n**_trade unions, and consumer_** organisations.\n\nCodes of conduct may cover one or more\ngenai systems taking into account the\nsimilarity of the intended purpose of the\nrelevant systems.\n\n**_Providers adopting codes_**\n**_of conduct will designate at least one_**\n**_natural person responsible for internal_**\n**_monitoring._**", "**Article 69 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nThe Commission and the Board shall\ntake into account the specific interests and\nneeds of **_the small-scale providers_** and\nstart-ups when encouraging and facilitating\nthe drawing up of codes of conduct.\n\n4.\n\nThe Commission and the **_AI Office_**\nshall take into account the specific interests\nand needs of **_SMEs_** and start-ups when\nencouraging and facilitating the drawing up\nof codes of conduct.", "**Article 70 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nNational competent authorities and\nnotified bodies involved in the application\nof this Regulation shall respect the\nconfidentiality of information and data\nobtained in carrying out their tasks and\nactivities in such a manner as to protect, in\nparticular **_:_**\n\n\n1.\n\n**_The Commission,_** national competent\nauthorities and notified bodies **_, the AI_**\n**_Office and any other natural or legal_**\n**_person_** involved in the application of this\nRegulation shall respect the confidentiality\nof information and data obtained in\ncarrying out their tasks and activities in\nsuch a manner as to protect, in particular **_;_**", "**Article 70 \u2013 paragraph 1 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) intellectual property rights, and\nconfidential business information or trade\nsecrets of a natural or legal person,\nincluding source code, except the cases\nreferred to in Article 5 of Directive\n2016/943 on the protection of undisclosed\nknow-how and business information (trade\nsecrets) against their unlawful acquisition,\nuse and disclosure apply **_._**\n\n\n(a) intellectual property rights, and\nconfidential business information or trade\nsecrets of a natural or legal person **_, in_**\n**_accordance with the provisions of_**\n**_Directives 2004/48/EC and 2016/943/EC_** ,\nincluding source code, except the cases\nreferred to in Article 5 of Directive\n2016/943 on the protection of undisclosed\nknow-how and business information (trade\nsecrets) against their unlawful acquisition,\nuse and disclosure apply **_;_**", "**Article 70 \u2013 paragraph 1 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_1 a._** **_The authorities involved in the_**\n**_application of this Regulation pursuant to_**\n**_paragraph 1 shall minimise the quantity_**\n**_of data requested for disclosure to the_**\n**_data that is strictly necessary for the_**\n**_perceived risk and the assessment of that_**\n**_risk.\n\nThey shall delete the data as soon as_**\n**_it is no longer needed for the purpose it_**\n**_was requested for.\n\nThey shall put in place_**\n**_adequate and effective cybersecurity,_**\n**_technical and organisational measures to_**\n**_protect the security and confidentiality of_**\n**_the information and data obtained in_**\n\n\n-----\n\n**_carrying out their tasks and activities;_**", "**Article 70 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nWithout prejudice to **_paragraph 1_** ,\ninformation exchanged on a confidential\nbasis between the national competent\nauthorities and between national competent\nauthorities and the Commission shall not\nbe disclosed without the prior consultation\nof the originating national competent\nauthority and the **_user_** when high-risk genai\nsystems referred to in points 1, 6 and 7 of\nAnnex III are used by law enforcement,\nimmigration or asylum authorities, when\nsuch disclosure would jeopardise public\n**_and_** national security **_interests._**\n\n\n2.\n\n**_Without prejudice to paragraphs 1_**\n**_and 1a_** , information exchanged on a\nconfidential basis between the national\ncompetent authorities and between national\ncompetent authorities and the Commission\nshall not be disclosed without the prior\nconsultation of the originating national\ncompetent authority and the **_deployer_** when\nhigh-risk genai systems referred to in points\n1, 6 and 7 of Annex III are used by law\nenforcement, immigration or asylum\nauthorities, when such disclosure would\njeopardise public **_or_** national security **_._**", "**Article 70 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nParagraphs 1 and 2 shall not affect\nthe rights and obligations of the\nCommission, Member States and notified\nbodies with regard to the exchange of\ninformation and the dissemination of\nwarnings, nor the obligations of the parties\nconcerned to provide information under\ncriminal law of the Member States **_._**\n\n\n3.\n\nParagraphs 1 **_, 1a_** and 2 shall not\naffect the rights and obligations of the\nCommission, Member States and notified\nbodies with regard to the exchange of\ninformation and the dissemination of\nwarnings, nor the obligations of the parties\nconcerned to provide information under\ncriminal law of the Member States **_;_**", "**Article 70 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n4.\n\nThe Commission and Member States 4.\n\nThe Commission and Member States\n\n\n-----\n\nmay exchange, where necessary,\nconfidential information with regulatory\nauthorities of third countries with which\nthey have concluded bilateral or\nmultilateral confidentiality arrangements\nguaranteeing an adequate level of\nconfidentiality.\n\nmay exchange, where **_strictly_** necessary\n**_and in accordance with relevant_**\n**_provisions of international and trade_**\n**_agreements_** , confidential information with\nregulatory authorities of third countries\nwith which they have concluded bilateral\nor multilateral confidentiality arrangements\nguaranteeing an adequate level of\nconfidentiality.", "**Article 71 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nIn compliance with the terms and\nconditions laid down in this Regulation,\nMember States shall lay down the rules on\npenalties, **_including administrative fines,_**\napplicable to infringements of this\nRegulation and shall take all measures\nnecessary to ensure that they are properly\nand effectively implemented.\n\nThe penalties\nprovided for shall be effective,\nproportionate, and dissuasive.\n\nThey shall\ntake into **_particular_** account the interests of\n**_small-scale providers and start-up_** and\ntheir economic viability **_._**\n\n\n1.\n\nIn compliance with the terms and\nconditions laid down in this Regulation,\nMember States shall lay down the rules on\npenalties, applicable to infringements of\nthis Regulation **_by any operator,_** and shall\ntake all measures necessary to ensure that\nthey are properly and effectively\nimplemented **_and aligned with the_**\n**_guidelines issued by the Commission and_**\n**_the genai Office pursuant to Article 82b_** .\n\nThe\npenalties provided for shall be effective,\nproportionate, and dissuasive.\n\nThey shall\ntake into account the interests of **_SMEs_**\n**_and start-ups_** and their economic viability **_;_**", "**Article 71 \u2013 paragraph 2**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe Member States shall notify the\nCommission of those rules and of those\nmeasures and shall notify **_it_** , without delay,\nof any subsequent amendment affecting\nthem.\n\n2.\n\nThe Member States shall notify the\nCommission **_and the Office by [ 12_**\n**_months after the date of entry into force_**\n**_of this Regulation]_** of those rules and of\nthose measures and shall notify **_them_** ,\nwithout delay, of any subsequent\namendment affecting them.", "**Article 71 \u2013 paragraph 3 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\n**_The following infringements_** shall be\nsubject to administrative fines of up to **_30_**\n**_000 000_** EUR or, if the offender is\ncompany, up to **_6_** % of its total worldwide\nannual turnover for the preceding financial\nyear, whichever is higher:\n\n\n3.\n\n**_Non compliance with the_**\n**_prohibition of the artificial intelligence_**\n**_practices referred to in Article 5_** shall be\nsubject to administrative fines of up to **_40_**\n**_000 000_** EUR or, if the offender is **_a_**\ncompany, up to **_7_** % of its total worldwide\nannual turnover for the preceding financial\nyear, whichever is higher:", "**Article 71 \u2013 paragraph 3 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_3 a._** **_Non-compliance of the genai system_**\n**_with the requirements laid down in Article_**\n**_10 and 13 shall be subject to_**\n**_administrative fines of up to EUR 20 000_**\n**_000 or, if the offender is a company, up to_**\n**_4% of its total worldwide annual turnover_**\n**_for the preceding financial year,_**\n**_whichever is the higher._**", "**Article 71 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\n**_The_** non-compliance of the genai\nsystem with any requirements or\nobligations under this Regulation, other\nthan those laid down in Articles 5 **_and 10_** ,\nshall be subject to administrative fines of\nup to **_20 000 000_** EUR or, if the offender is\na company, up to **_4 %_** of its total\nworldwide annual turnover for the\npreceding financial year, whichever is\nhigher **_._**\n\n\n4.\n\nNon-compliance of the genai system **_or_**\n**_foundation model_** with any requirements\nor obligations under this Regulation, other\nthan those laid down in Articles 5 **_, 10 and_**\n**_13_** , shall be subject to administrative fines\nof up to **_EUR_** **_10 000 000_** or, if the offender\nis a company, up to **_2%_** of its total\nworldwide annual turnover for the\npreceding financial year, whichever is\nhigher **_;_**", "**Article 71 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nThe supply of incorrect, incomplete\nor misleading information to notified\nbodies and national competent authorities\nin reply to a request shall be subject to\n\n\n5.\n\nThe supply of incorrect, incomplete\nor misleading information to notified\nbodies and national competent authorities\nin reply to a request shall be subject to\n\n\n-----\n\nadministrative fines of up to **_10 000 000_**\nEUR or, if the offender is a company, up to\n**_2_** % of its total worldwide annual turnover\nfor the preceding financial year, whichever\nis higher **_._**\n\n\nadministrative fines of up to **_5 000 000_**\nEUR or, if the offender is a company, up to\n**_1_** % of its total worldwide annual turnover\nfor the preceding financial year, whichever\nis higher **_._**", "**Article 71 \u2013 paragraph 6 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\n**_When_** deciding on the amount of the\nadministrative fine in each individual case,\nall relevant circumstances of the specific\nsituation shall be taken into account and\ndue regard shall be given to the following **_:_**\n\n\n6.\n\n**_Fines may be imposed in addition to_**\n**_or instead of non-monetary measures_**\n**_such as orders or warnings.\n\nWhen_**\ndeciding on the amount of the\nadministrative fine in each individual case,\nall relevant circumstances of the specific\nsituation shall be taken into account and\ndue regard shall be given to the following **_;_**", "**Article 71 \u2013 paragraph 6 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) the nature, gravity and duration of\nthe infringement and of its consequences;\n\n\n(a) the nature, gravity and duration of\nthe infringement and of its consequences **_,_**\n**_taking into account the purpose of the AI_**\n**_system, as well as, where appropriate, the_**\n**_number of affected persons and the level_**\n**_of damage suffered by them_** ;", "**Article 71 \u2013 paragraph 6 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) whether administrative fines have\nbeen already applied by other **_market_**\n**_surveillance_** authorities to the same\n\n\n(b) whether administrative fines have\nbeen already applied by other **_national_**\n**_supervisory_** authorities **_of one or more_**\n**_Member States_** to the same operator for the\n\n\n-----\n\noperator for the same infringement **_._** same infringement **_;_**", "**Article 71 \u2013 paragraph 7**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n7.\n\nEach Member State shall lay down\nrules on **_whether and to what extent_**\nadministrative fines **_may_** be imposed on\npublic authorities and bodies established in\nthat Member State **_._**\n\n\n7. each Member State shall lay down\nrules on administrative fines **_to_** be imposed\non public authorities and bodies established\nin that Member State **_;_**", "**Article 71 \u2013 paragraph 8 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_8 a._** **_The penalties referred to in this_**\n**_article as well as the associated litigation_**\n**_costs and indemnification claims may not_**\n**_be the subject of contractual clauses or_**\n**_other form of burden-sharing agreements_**\n**_between providers and distributors,_**\n**_importers, deployers, or any other third_**\n**_parties;_**", "**Article 72 \u2013 paragraph 1 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) the nature, gravity and duration of\nthe infringement and of its consequences;\n\n\n(a) the nature, gravity and duration of\nthe infringement and of its consequences; **_,_**\n**_taking into account the purpose of the AI_**\n**_system concerned as well as the number_**\n**_of affected persons and the level of_**\n**_damage suffered by them, and any_**\n**_relevant previous infringement;_**", "**Article 72 \u2013 paragraph 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) the cooperation with the European\nData Protection Supervisor in order to\nremedy the infringement and mitigate the\npossible adverse effects of the\ninfringement, including compliance with\nany of the measures previously ordered by\nthe European Data Protection Supervisor\nagainst the Union institution or agency or\nbody concerned with regard to the same\nsubject matter;\n\n\n(b) the **_degree of_** cooperation with the\nEuropean Data Protection Supervisor in\norder to remedy the infringement and\nmitigate the possible adverse effects of the\ninfringement, including compliance with\nany of the measures previously ordered by\nthe European Data Protection Supervisor\nagainst the Union institution or agency or\nbody concerned with regard to the same\nsubject matter;", "**Article 72 \u2013 paragraph 1 \u2013 point c a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(c a) the manner in which the_**\n**_infringement became known to the_**\n\n\n-----\n\n**_European Data Protection Supervisor, in_**\n**_particular whether, and if so to what_**\n**_extent, the Union institution or body_**\n**_notified the infringement;_**", "**Article 72 \u2013 paragraph 2 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\n**_The following infringements_** shall be\nsubject to administrative fines of up to **_500_**\n**_000 EUR_** :\n\n\n2.\n\n**_Non compliance with the_**\n**_prohibition of the artificial intelligence_**\n**_practices referred to in Article 5_** shall be\nsubject to administrative fines of up to\n**_EUR 1 500 000._**", "**Article 72 \u2013 paragraph 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nThe non-compliance of the genai\nsystem with any requirements or\nobligations under this Regulation, other\nthan those laid down in Articles 5 and 10,\nshall be subject to administrative fines of\nup to **_250 000 EUR._**\n\n\n3. the non-compliance of the genai system\nwith any requirements or obligations under\nthis Regulation, other than those laid down\nin Articles 5 and 10, shall be subject to\nadministrative fines of up to **_EUR 750 000._**", "**Article 72 \u2013 paragraph 6**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\nFunds collected by imposition of\nfines in this Article shall **_be the income of_**\nthe general budget of the Union.\n\n6.\n\nFunds collected by imposition of\nfines in this Article shall **_contribute to_** the\ngeneral budget of the Union.\n\n**_The fines_**\n**_shall not affect the effective operation of_**\n**_the Union institution, body or agency_**\n**_fined._**", "**Article 73 \u2013 paragraph 2**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThe **_delegation of_** power referred to\nin Article 4, Article 7(1), Article 11(3),\nArticle 43(5) and (6) and Article 48(5)\nshall be conferred on the Commission for\n**_an indeterminate_** period of **_time_** from\n\n[ **_entering_** into force of the Regulation].\n\n2.\n\nThe power **_to adopt delegated acts_**\nreferred to in Article 4, Article 7(1), Article\n11(3), Article 43(5) and (6) and Article\n48(5) shall be conferred on the\nCommission for **_a_** period of **_five years_** from\n\u2026 [ **_the date of entry_** into force of the\nRegulation].\n\n**_The Commission shall draw_**\n**_up a report in respect of the delegation of_**\n**_power not later than 9 months before the_**\n**_end of the five-year period.\n\nThe delegation_**\n**_of power shall be tacitly extended for_**\n**_periods of an identical duration, unless_**\n**_the European Parliament or the Council_**\n**_opposes such extension not later than_**\n**_three months before the end of each_**\n**_period._**", "**Article 73 \u2013 paragraph 3 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_3 a._** **_Before adopting a delegated act, the_**\n**_Commission shall consult with the_**\n**_relevant institutions, the Office, the_**\n**_Advisory Forum and other relevant_**\n**_stakeholders in accordance with the_**\n**_principles laid down in the_**\n**_Interinstitutional Agreement of 13 April_**\n**_2016 on Better Law-Making._**\n\n**_Once the Commission decides to draft a_**\n**_delegated act, it shall notify the European_**\n**_Parliament of this fact.\n\nThis notification_**\n**_does not place an obligation on the_**\n**_Commission to adopt the said act._**\n\n\n-----", "**Article 82 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 82 a_**\n\n**_Better Regulation_**\n\n**_in taking into account the requirements of_**\n**_this Regulation pursuant to the_**\n**_Amendments in Articles 75, 76, 77, 78, 79,_**\n**_80, 81, and 82, the Commission shall_**\n**_conduct an analysis and consult relevant_**\n**_stakeholders to determine potential gaps_**\n**_as well as overlaps between existing_**\n**_sectoral legislation and the provisions of_**\n**_this Regulation._**", "**Article 82 b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Article 82 b_**\n\n\n-----\n\n**_Guidelines from the Commission on the_**\n**_implementation of this Regulation_**\n\n**_1.\n\nThe Commission shall develop, in_**\n**_consultation with the genai office, guidelines_**\n**_on the practical implementation of this_**\n**_Regulation, and in particular on:_**\n\n**_(a) the application of the requirements_**\n**_referred to in Articles 8 - 15 and Article_**\n**_28 to 28b;_**\n\n**_(b) the prohibited practices referred to in_**\n**_Article 5;_**\n\n**_(c) the practical implementation of the_**\n**_provisions related to substantial_**\n**_modification;_**\n\n**_(d) the practical circumstances where the_**\n**_output of an genai system referred to in_**\n**_Annex III would pose a significant risk of_**\n**_harm to the health, safety or fundamental_**\n**_rights of natural persons as referred to in_**\n**_Article 6, paragraph 2, including_**\n**_examples in relation to high risk AI_**\n**_systems referred to in Annex III;_**\n\n**_(e) the practical implementation of_**\n**_transparency obligations laid down in_**\n**_Article 52;_**\n\n**_(f) the development of codes of conduct_**\n**_referred to in Article 69;_**\n\n**_(g) the relationship of this Regulation_**\n**_with other relevant Union law, including_**\n**_as regards consistency in their_**\n**_enforcement._**\n\n**_(h) the practical implementation of Article_**\n**_12, Article 28b on environmental impact_**\n**_of foundation models and Annex IV 3(b),_**\n**_particularly the measurement and logging_**\n**_methods to enable calculations and_**\n**_reporting of the environmental impact of_**\n**_systems to comply with the obligations in_**\n**_this Regulation, including carbon_**\n**_footprint and energy efficiency, taking_**\n**_into account state-of-the-art methods and_**\n**_economies of scale._**\n\n**_When issuing such guidelines, the_**\n**_Commission shall pay particular attention_**\n**_to the needs of SMEs including start-ups,_**\n**_local public authorities and sectors most_**\n\n\n-----\n\n**_likely to be affected by this Regulation._**\n\n**_2.\n\nUpon request of the Member States or_**\n**_the genai Office, or on its own initiative, the_**\n**_Commission shall update already adopted_**\n**_guidelines when deemed necessary._**", "**Article 83 \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\n**_This Regulation shall not apply to_**\nthe genai systems which are components of\nthe large-scale IT systems established by\nthe legal acts listed in Annex IX that have\nbeen placed on the market or put into\nservice **_before [12 months after_** the date of\n**_application_** of this Regulation **_referred to_**\n**_in Article 85(2)], unless the replacement_**\n**_or amendment of those legal acts leads to_**\n**_a significant change in the design or_**\n**_intended purpose of the genai system or AI_**\n**_systems concerned._**\n\n\n1.\n\n**_Operators of_** the genai systems which\nare components of the large-scale IT\nsystems established by the legal acts listed\nin Annex IX that have been placed on the\nmarket or put into service **_prior to ... [_** the\ndate of **_entry into force_** of this Regulation **_]_**\n**_shall take the necessary steps to comply_**\n**_with the requirements laid down in this_**\n**_Regulation by \u2026 [four years after the date_**\n**_of entry into force of this Regulation]_** .", "**Article 83 \u2013 paragraph 1 \u2013 subparagraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nThe requirements laid down in this\nRegulation shall be taken into account **_,_**\n**_where applicable,_** in the evaluation of each\nlarge-scale IT systems established by the\nlegal acts listed in Annex IX to be\nundertaken as provided for in those\nrespective acts **_._**\n\n\nThe requirements laid down in this\nRegulation shall be taken into account in\nthe evaluation of each large-scale IT\nsystems established by the legal acts listed\nin Annex IX to be undertaken as provided\nfor in those respective acts **_and whenever_**\n**_those legal acts are replaced or amended._**", "**Article 83 \u2013 paragraph 2**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nThis Regulation shall apply to **_the_**\nhigh-risk genai systems, other than the ones\nreferred to in paragraph 1, that have been\nplaced on the market or put into service\nbefore [date of application of this\nRegulation referred to in Article 85(2)],\nonly if, from that date, those systems are\nsubject to **_significant changes in their_**\n**_design or_** intended **_purpose._**\n\n\n2.\n\nThis Regulation shall apply to\n**_operators of_** high-risk genai systems, other\nthan the ones referred to in paragraph 1,\nthat have been placed on the market or put\ninto service before [date of application of\nthis Regulation referred to in Article\n85(2)], only if, from that date, those\nsystems are subject to **_substantial_**\n**_modifications as defined in Article 3(23)._**\n**_In the case of high-risk genai systems_**\nintended **_to be used by public authorities,_**\n**_providers and deployers of such systems_**\n**_shall take the necessary steps to comply_**\n**_with the requirements of the present_**\n**_Regulation [two years after the date of_**\n**_entry into force of this Regulation]_** .", "**Article 84 \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n1.\n\nThe Commission shall assess the\nneed for amendment of the list in Annex III\nonce a year following the entry into force\nof this Regulation **_._**\n\n\n1.\n\n**_After consulting the genai Office,_** the\nCommission shall assess the need for\namendment of the list in Annex III **_,_**\n**_including the extension of existing area_**\n**_headings or addition of new area_**\n**_headings in that Annex the list of_**\n**_prohibited genai practices in Article 5, and_**\n**_the list of genai systems requiring additional_**\n**_transparency measures in Article 52_** once\na year following the entry into force of this\nRegulation **_and following a_**\n**_recommendation of the Office._**\n\n**_the Commission shall submit the findings_**\n**_of that assessment to the European_**\n**_Parliament and the Council._**", "**Article 84 \u2013 paragraph 2**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n2.\n\nBy [ **_three_** years after the date of\napplication of this Regulation referred to in\nArticle 85(2)] and every **_four_** years\nthereafter, the Commission shall submit a\nreport on the evaluation and review of this\nRegulation to the European Parliament and\nto the Council.\n\nThe reports shall be made\npublic **_._**\n\n\n2.\n\nBy \u2026 [ **_two_** years after the date of\napplication of this Regulation referred to in\nArticle 85(2)] and every **_two_** years\nthereafter, the Commission **_, together with_**\n**_the genai office,_** shall submit a report on the\nevaluation and review of this Regulation to\nthe European Parliament and to the\nCouncil.\n\nThe reports shall be made public **_._**", "**Article 84 \u2013 paragraph 3 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) the status of the financial and human\nresources of the national competent\nauthorities in order to effectively perform\nthe tasks assigned to them under this\nRegulation;\n\n\n(a) the status of the financial **_, technical_**\nand human resources of the national\ncompetent authorities in order to\neffectively perform the tasks assigned to\nthem under this Regulation;", "**Article 84 \u2013 paragraph 3 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_3 a._** **_By ... [two years after the date of_**\n**_entry into application of this Regulation_**\n**_referred to in Article 85(2)] the_**\n**_Commission shall evaluate the_**\n**_functioning of the genai office, whether the_**\n**_office has been given sufficient powers_**\n**_and competences to fulfil its tasks and_**\n**_whether it would be relevant and needed_**\n**_for the proper implementation and_**\n**_enforcement of this Regulation to upgrade_**\n**_the Office and its enforcement_**\n**_competences and to increase its resources._**\n**_The Commission shall submit this_**\n**_evaluation report to the European_**\n\n\n-----\n\n**_Parliament and to the Council._**", "**Article 84 \u2013 paragraph 4**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.\n\nWithin [ **_three years_** after the date of\napplication of this Regulation referred to in\nArticle 85(2)] and every **_four_** years\nthereafter, the Commission shall evaluate\nthe impact and effectiveness of codes of\nconduct to foster the application of the\nrequirements set out in Title III, Chapter 2\nand possibly other additional requirements\nfor genai systems other than high-risk genai\nsystems **_._**\n\n\n4.\n\nWithin \u2026 [ **_one year_** after the date of\napplication of this Regulation referred to in\nArticle 85(2)] and every **_two_** years\nthereafter, the Commission shall evaluate\nthe impact and effectiveness of codes of\nconduct to foster the application of the\nrequirements set out in Title III, Chapter 2\nand possibly other additional requirements\nfor genai systems other than high-risk genai\nsystems **_;_**", "**Article 84 \u2013 paragraph 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nFor the purpose of paragraphs 1 to 4\nthe **_Board_** , the Member States and national\ncompetent authorities shall provide the\nCommission with information on its\nrequest **_._**\n\n\n5.\n\nFor the purpose of paragraphs 1 to 4\nthe **_AI Office_** , the Member States and\nnational competent authorities shall\nprovide the Commission with information\non its request **_without undue delay._**", "**Article 84 \u2013 paragraph 6**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\nIn carrying out the evaluations and\nreviews referred to in paragraphs 1 to 4 the\nCommission shall take into account the\npositions and findings of the **_Board,_** of the\nEuropean Parliament, of the Council, and\nof other relevant bodies or sources.\n\n6. in carrying out the evaluations and\nreviews referred to in paragraphs 1 to 4 the\nCommission shall take into account the\npositions and findings of the **_-genai Office_** of\nthe European Parliament, of the Council,\nand of other relevant bodies or sources **_and_**\n**_shall consult relevant stakeholders_** .\n\n**_The_**\n\n\n-----\n\n**_result of such consultation shall be_**\n**_attached to the report;_**", "**Article 84 \u2013 paragraph 7**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n7.\n\nThe Commission shall, if necessary,\nsubmit appropriate proposals to amend this\nRegulation, in particular taking into\naccount developments in technology and in\nthe light of the state of progress in the\ninformation society **_._**\n\n\n7. the Commission shall, if necessary,\nsubmit appropriate proposals to amend this\nRegulation, in particular taking into\naccount developments in technology **_, the_**\n**_effect of genai systems on health and safety,_**\n**_fundamental rights, the environment,_**\n**_equality, and accessibility for persons with_**\n**_disabilities, democracy and rule of law_**\nand in the light of the state of progress in\nthe information society **_._**", "**Article 84 \u2013 paragraph 7 a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_7 a._** **_To guide the evaluations and_**\n**_reviews referred to in paragraphs 1 to 4 of_**\n**_this Article, the Office shall undertake to_**\n**_develop an objective and participative_**\n**_methodology for the evaluation of risk_**\n**_level based on the criteria outlined in the_**\n**_relevant articles and inclusion of new_**\n**_systems in: the list in Annex III, including_**\n**_the extension of existing area headings or_**\n**_addition of new area headings in that_**\n**_Annex; the list of prohibited practices laid_**\n**_down in Article 5; and the list of AI_**\n**_systems requiring additional transparency_**\n**_measures pursuant to Article 52._**", "**Article 84 \u2013 paragraph 7 b (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_7 b._** **_Any amendment to this Regulation_**\n**_pursuant to paragraph 7 of this Article, or_**\n**_relevant future delegated or implementing_**\n**_acts, which concern sectoral legislation_**\n**_listed in Annex II Ssection B, shall take_**\n**_into account the regulatory specificities of_**\n**_each sector, and existing governance,_**\n**_conformity assessment and enforcement_**\n**_mechanisms and authorities established_**\n**_therein._**", "**Article 84 \u2013 paragraph 7 c (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_7 c._** **_By \u2026 [five years from the date of_**\n**_application of this Regulation], the_**\n**_Commission shall carry out an assessment_**\n**_of the enforcement of this Regulation and_**\n**_shall report it to the European_**\n**_Parliament, the Council and the_**\n**_European Economic and Social_**\n**_Committee, taking into account the first_**\n**_years of application of the Regulation.\n\nOn_**\n**_the basis of the findings that report shall,_**\n**_where appropriate, be accompanied by a_**\n**_proposal for amendment of this_**\n**_Regulation with regard to the structure of_**\n**_enforcement and the need for an Union_**\n**_agency to resolve any identified_**\n**_shortcomings._**", "**Annex I**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_ARTIFICIAL INTELLIGENCE_**\n**_TECHNIQUES AND APPROACHES_**\n**_referred to in Article 3, point 1_**\n\n\n**_deleted_**\n\n\n-----\n\n**_(a)_** **_Machine learning approaches,_**\n**_including supervised, unsupervised and_**\n**_reinforcement learning, using a wide_**\n**_variety of methods including deep_**\n**_learning;_**\n\n**_(b)_** **_Logic- and knowledge-based_**\n**_approaches, including knowledge_**\n**_representation, inductive (logic)_**\n**_programming, knowledge bases, inference_**\n**_and deductive engines, (symbolic)_**\n**_reasoning and expert systems;_**\n\n**_(c)_** **_Statistical approaches, Bayesian_**\n**_estimation, search and optimization_**\n**_methods._**", "**Annex III \u2013 paragraph 1 \u2013 introductory part**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nHigh-risk genai systems pursuant to Article\n6(2) **_are the genai systems listed in any of the_**\n**_following areas_** :\n\n\n**_The genai systems specifically refered to in_**\n**_under points 1 to 8a stand for critical use_**\n**_cases and are each considered to be_** highrisk genai systems pursuant to Article 6(2) **_,_**\n**_provided that they fulfil the criteria set out_**\n**_in that Article_** :", "**Annex III \u2013 paragraph 1 \u2013 point 1 \u2013 point a**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) genai systems intended to be used for\n**_the \u2018real-time\u2019 and \u2018post\u2019 remote_** biometric\nidentification of natural persons;\n\n\n(a) genai systems intended to be used for\nbiometric identification of natural persons **_,_**\n**_with the exception of those mentioned in_**\n**_Article 5_** ;", "**Annex III \u2013 paragraph 1 \u2013 point 1 \u2013 point a a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(a a) genai systems intended to be used to_**\n**_make inferences about personal_**\n**_characteristics of natural persons on the_**\n**_basis of biometric or biometrics-based_**\n**_data, including emotion recognition_**\n**_systems, with the exception of those_**\n**_mentioned in Article 5;_**\n\n**_Point 1 shall not include genai systems_**\n**_intended to be used for biometric_**\n**_verification whose sole purpose is to_**\n**_confirm that a specific natural person is_**\n**_the person he or she claims to be._**", "**Annex III \u2013 paragraph 1 \u2013 point 2 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) genai systems intended to be used as\nsafety components in the management and\noperation of road traffic **_and the supply of_**\n**_water, gas, heating and electricity_** .\n\n(a) genai systems intended to be used as\nsafety components in the management and\noperation of road **_, rail and air_** traffic\n**_unless they are regulated in_**\n**_harmonisation or sectoral law_** .", "**Annex III \u2013 paragraph 1 \u2013 point 3 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) genai systems intended to be used for\nthe purpose of determining access or\nassigning natural persons to educational\nand vocational training institutions;\n\n\n(a) genai systems intended to be used for\nthe purpose of determining access **_or_**\n**_materially influence decisions on_**\n**_admission_** or assigning natural persons to\neducational and vocational training\ninstitutions;", "**Annex III \u2013 paragraph 1 \u2013 point 3 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) genai systems intended to be used for\nthe purpose of assessing students in\neducational and vocational training\ninstitutions and for assessing participants in\ntests commonly required for admission to\n**_educational_** institutions **_._**\n\n\n(b) genai systems intended to be used for\nthe purpose of assessing students in\neducational and vocational training\ninstitutions and for assessing participants in\ntests commonly required for admission to\n**_those_** institutions **_;_**", "**Annex III \u2013 paragraph 1 \u2013 point 3 \u2013 point b a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(b a) genai systems intended to be used for_**\n**_the purpose of assessing the appropriate_**\n**_level of education for an individual and_**\n\n\n-----\n\n**_materially influencing the level of_**\n**_education and vocational training that_**\n**_individual will receive or will be able to_**\n**_access;_**", "**Annex III \u2013 paragraph 1 \u2013 point 4 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) genai systems intended to be used for\nrecruitment or selection of natural persons,\nnotably for **_advertising vacancies_** ,\nscreening or filtering applications,\nevaluating candidates in the course of\ninterviews or tests;\n\n\n(a) genai systems intended to be used for\nrecruitment or selection of natural persons,\nnotably for **_placing targeted job_**\n**_advertisements_** screening or filtering\napplications, evaluating candidates in the\ncourse of interviews or tests;", "**Annex III \u2013 paragraph 1 \u2013 point 4 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) genai intended to be used **_for making_**\ndecisions **_on_** promotion and termination of\nwork-related contractual relationships, **_for_**\ntask allocation **_and_** for monitoring and\nevaluating performance and behavior of\npersons in such relationships **_._**\n\n\n(b) genai **_systems_** intended to be used **_to_**\n**_make or materially influence_** decisions\n**_affecting the initiation,_** promotion and\ntermination of work-related contractual\nrelationships, task allocation **_based on_**\n**_individual behaviour or personal traits or_**\n**_characteristics, or_** for monitoring and\nevaluating performance and behavior of\n\n\n-----\n\npersons in such relationships **_;_**", "**Annex III \u2013 paragraph 1 \u2013 point 5 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) genai systems intended to be used by\n**_public authorities_** or on behalf of public\nauthorities to evaluate the eligibility of\nnatural persons for public assistance\nbenefits and services, as well as to grant,\nreduce, revoke, or reclaim such benefits\nand services;\n\n\n(a) genai systems intended to be used by or\non behalf of public authorities to evaluate\nthe eligibility of natural persons for public\nassistance benefits and services, **_including_**\n**_healthcare services and essential services,_**\n**_including but not limited to housing,_**\n**_electricity, heating/cooling and internet,_**\nas well as to grant, reduce, revoke,\n**_increase_** or reclaim such benefits and\nservices;", "**Annex III \u2013 paragraph 1 \u2013 point 5 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) genai systems intended to be used to\nevaluate the creditworthiness of natural\npersons or establish their credit score, with\nthe exception of genai systems **_put into_**\n**_service by small scale providers for their_**\n**_own use;_**\n\n\n(b) genai systems intended to be used to\nevaluate the creditworthiness of natural\npersons or establish their credit score , with\nthe exception of genai systems **_used for the_**\n**_purpose of detecting financial fraud;_**", "**Annex III \u2013 paragraph 1 \u2013 point 5 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) genai systems intended to be used to\ndispatch, or to establish priority in the\ndispatching of emergency first response\nservices, including by firefighters and\nmedical aid **_._**\n\n\n(c) genai systems intended **_to evaluate and_**\n**_classify emergency calls by natural_**\n**_persons or_** to be used to dispatch, or to\nestablish priority in the dispatching of\nemergency first response services,\nincluding by **_police and law enforcement,_**\nfirefighters and medical aid **_, as well as of_**\n**_emergency healthcare patient triage_**\n**_systems;_**", "**Annex III \u2013 paragraph 1 \u2013 point 6 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(a)_** **_AI systems intended to be used by_**\n**_law enforcement authorities for making_**\n**_individual risk assessments of natural_**\n**_persons in order to assess the risk of a_**\n**_natural person for offending or_**\n**_reoffending or the risk for potential_**\n**_victims of criminal offences;_**\n\n\n**_deleted_**", "**Annex III \u2013 paragraph 1 \u2013 point 6 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) genai systems intended to be used by\nlaw enforcement authorities as polygraphs\nand similar tools **_or to detect the emotional_**\n**_state of a natural person;_**\n\n\n(b) genai systems intended to be used by **_or_**\n**_on behalf of law enforcement authorities,_**\n**_or by Union agencies, offices or bodies in_**\n**_support of_** law enforcement authorities as\npolygraphs and similar tools, **_insofar as_**\n**_their use is permitted under relevant_**\n**_Union and national law;_**\n\n\n-----", "**Annex III \u2013 paragraph 1 \u2013 point 6 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) genai systems intended to be used by\nlaw enforcement authorities **_for evaluation_**\n**_of_** the reliability of evidence in the course\nof investigation or prosecution of criminal\noffences;\n\n\n(d) genai systems intended to be used by **_or_**\n**_on behalf of law enforcement authorities,_**\n**_or by Union agencies, offices or bodies in_**\n**_support of_** law enforcement authorities **_to_**\n**_evaluate_** the reliability of evidence in the\ncourse of investigation or prosecution of\ncriminal offences;", "**Annex III \u2013 paragraph 1 \u2013 point 6 \u2013 point e**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_(e)_** **_AI systems intended to be used by_**\n**_law enforcement authorities for predicting_**\n**_the occurrence or reoccurrence of an_**\n**_actual or potential criminal offence based_**\n**_on profiling of natural persons as referred_**\n**_to in Article 3(4) of Directive (EU)_**\n**_2016/680 or assessing personality traits_**\n**_and characteristics or past criminal_**\n**_behaviour of natural persons or groups;_**\n\n\n**_deleted_**", "**Annex III \u2013 paragraph 1 \u2013 point 6 \u2013 point f**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(f) genai systems intended to be used by\nlaw enforcement authorities for profiling of\nnatural persons as referred to in Article\n3(4) of Directive (EU) 2016/680 in the\ncourse of detection, investigation or\nprosecution of criminal offences;\n\n\n(f) genai systems intended to be used by **_or_**\n**_on behalf of law enforcement authorities_**\n**_or by Union agencies, offices or bodies in_**\n**_support of_** law enforcement authorities for\nprofiling of natural persons as referred to in\nArticle 3(4) of Directive (EU) 2016/680 in\nthe course of detection, investigation or\nprosecution of criminal offences **_or, in the_**\n**_case of Union agencies, offices or bodies,_**\n**_as referred to in Article 3(5) of Regulation_**\n**_(EU) 2018/1725_** ;", "**Annex III \u2013 paragraph 1 \u2013 point 6 \u2013 point g**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(g) genai systems intended to be used for\ncrime analytics regarding natural persons,\nallowing law enforcement authorities to\nsearch complex related and unrelated large\ndata sets available in different data sources\nor in different data formats in order to\nidentify unknown patterns or discover\nhidden relationships in the data **_._**\n\n\n(g) genai systems intended to be used **_by or_**\n**_on behalf of law enforcement authorities_**\n**_or by Union agencies, offices or bodies in_**\n**_support of law enforcement authorities_** for\ncrime analytics regarding natural persons,\nallowing law enforcement authorities to\nsearch complex related and unrelated large\ndata sets available in different data sources\nor in different data formats in order to\nidentify unknown patterns or discover\nhidden relationships in the data **_._**", "**Annex III \u2013 paragraph 1 \u2013 point 7 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) genai systems intended to be used by\ncompetent public authorities as polygraphs\nand similar tools **_or to detect the emotional_**\n**_state of a natural person;_**\n\n\n(a) genai systems intended to be used by **_or_**\n**_on behalf of_** competent public authorities\n**_or by Union agencies, offices or bodies_** as\npolygraphs and similar tools **_insofar as_**\n**_their use is permitted under relevant_**\n\n\n-----\n\n**_Union or national law_**", "**Annex III \u2013 paragraph 1 \u2013 point 7 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) genai systems intended to be used by\ncompetent public authorities to assess a\nrisk, including a security risk, a risk of\nirregular immigration, or a health risk,\nposed by a natural person who intends to\nenter or has entered into the territory of a\nMember State;\n\n\n(b) genai systems intended to be used by **_or_**\n**_on behalf of_** competent public **_authorities_**\n**_or by Union agencies, offices or bodies_** to\nassess a risk, including a security risk, a\nrisk of irregular immigration, or a health\nrisk, posed by a natural person who intends\nto enter or has entered into the territory of a\nMember State;", "**Annex III \u2013 paragraph 1 \u2013 point 7 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) genai systems intended to be used by\ncompetent public authorities for the\nverification of the authenticity of travel\ndocuments and supporting documentation\nof natural persons and detect non-authentic\ndocuments by checking their security\nfeatures;\n\n\n(c) genai systems intended to be used by **_or_**\n**_on behalf of_** competent public **_authorities_**\n**_or by Union agencies, offices or bodies_** for\nthe verification of the authenticity of travel\ndocuments and supporting documentation\nof natural persons and detect non-authentic\ndocuments by checking their security\nfeatures;", "**Annex III \u2013 paragraph 1 \u2013 point 7 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) genai systems intended to assist\ncompetent public authorities for the\nexamination **_of_** applications for asylum,\nvisa and residence permits and associated\ncomplaints with regard to the eligibility of\n\n\n(d) genai systems intended **_to be used by or_**\n**_on behalf of competent public authorities_**\n**_or by Union agencies, offices or bodies_** to\nassist competent public authorities for the\nexamination **_and assessment of the_**\n**_veracity of evidence in relation to_**\n\n\n-----\n\nthe natural persons applying for a status **_._** applications for asylum, visa and residence\npermits and associated complaints with\nregard to the eligibility of the natural\npersons applying for a status **_;_**", "**Annex III \u2013 paragraph 1 \u2013 point 7 \u2013 point d a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(d a) genai systems intended to be used by or_**\n**_on behalf of competent public authorities_**\n**_or by Union agencies, offices or bodies in_**\n**_migration, asylum and border control_**\n**_management to monitor, surveil or_**\n**_process data in the context of border_**\n**_management activities, for the purpose of_**\n**_detecting, recognising or identifying_**\n**_natural persons;_**", "**Annex III \u2013 paragraph 1 \u2013 point 7 \u2013 point d b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(d b) genai systems intended to be used by or_**\n**_on behalf of competent public authorities_**\n**_or by Union agencies, offices or bodies in_**\n**_migration, asylum and border control_**\n**_management for the forecasting or_**\n**_prediction of trends related to migration_**\n**_movement and border crossing;_**", "**Annex III \u2013 paragraph 1 \u2013 point 8 \u2013 point a**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) genai systems intended to assist a\njudicial authority in researching and\ninterpreting facts and the law and in\n\n\n(a) genai systems intended **_to be used by a_**\n**_judicial authority ot administrative body_**\n**_or on their behalf_** to assist a judicial\n\n\n-----\n\napplying the law to a concrete set of facts.\n\nauthority **_or administrative body_** in\nresearching and interpreting facts and the\nlaw and in applying the law to a concrete\nset of facts **_or used in a similar way in_**\n**_alternative dispute resolution_** .", "**Annex III \u2013 paragraph 1 \u2013 point 8 \u2013 point a a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(a a) genai systems intended to be used for_**\n**_influencing the outcome of an election or_**\n**_referendum or the voting behaviour of_**\n**_natural persons in the exercise of their_**\n**_vote in elections or referenda.\n\nThis does_**\n**_not include genai systems whose output_**\n**_natural persons are not directly exposed_**\n**_to, such as tools used to organise, optimise_**\n**_and structure political campaigns from an_**\n**_administrative and logistic point of view._**", "**Annex III \u2013 paragraph 1 \u2013 point 8 \u2013 point a b (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(a b) genai systems intended to be used by_**\n**_social media platforms that have been_**\n**_designated as very large online platforms_**\n**_within the meaning of Article 33 of_**\n**_Regulation EU 2022/2065, in their_**\n**_recommender systems to recommend to_**\n**_the recipient of the service user-generated_**\n**_content available on the platform._**", "**Annex IV \u2013 paragraph 1 \u2013 point 1 \u2013 point a**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(a) its intended purpose, the **_person/s_**\n**_developing the system the date_** and the\nversion of the system;\n\n\n(a) its intended purpose, the **_name of the_**\n**_provider_** and the version of the system\n**_reflecting its relation to previous and,_**\n**_where applicable, more recent, versions in_**\n**_the succession of revisions_** ;", "**Annex IV \u2013 paragraph 1 \u2013 point 1 \u2013 point a a (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_(a a) the nature of data likely or intended_**\n**_to be processed by the system and, in the_**\n**_case of personal data, the categories of_**\n**_natural persons and groups likely or_**\n**_intended to be affected;_**", "**Annex IV \u2013 paragraph 1 \u2013 point 1 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) how the genai system **_interacts_** or can\nbe used to interact with hardware or\nsoftware **_that is_** not part of the genai system\nitself, where applicable;\n\n\n(b) how the genai system **_can interact_** or\ncan be used to interact with hardware or\nsoftware **_, including other genai systems, that_**\n**_are_** not part of the genai system itself, where\napplicable;", "**Annex IV \u2013 paragraph 1 \u2013 point 1 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) the versions of relevant software or\nfirmware and any requirement related to\nversion update;\n\n\n(c) the versions of relevant software or\nfirmware and **_, where applicable,_**\n**_information for the deployer on_** any\nrequirement related to version update;\n\n\n-----", "**Annex IV \u2013 paragraph 1 \u2013 point 1 \u2013 point d**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(d) the description of **_all forms in which_**\nthe genai system **_is_** placed on the market or\nput into service;\n\n\n(d) the description of **_the various_**\n**_configurations and variants of_** the genai\nsystem **_which are intended to be_** placed on\nthe market or put into service;", "**Annex IV \u2013 paragraph 1 \u2013 point 1 \u2013 point g**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(g) instructions of use for the **_user_** and,\nwhere applicable installation instructions;\n\n\n(g) instructions of use for the **_deployer in_**\n**_accordance with Article 13(2) and (3) as_**\n**_well as 14(4)(e)_** and, where applicable\ninstallation instructions;", "**Annex IV \u2013 paragraph 1 \u2013 point 2 \u2013 point b**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(b) **_the_** design specifications **_of the_**\n**_system, namely the general_** logic of the genai\nsystem **_and of the algorithms_** ; the key\ndesign choices including the rationale and\nassumptions made, also with regard to\npersons or groups of persons on which the\nsystem is intended to be used; the main\nclassification choices; what the system is\n\n\n(b) **_a description of the architecture,_**\ndesign specifications **_, algorithms and the_**\n**_data structures including a decomposition_**\n**_of its components and interfaces, how_**\n**_they relate to one another and how they_**\n**_provide for the overall processing or_** logic\nof the genai system; the key design choices\nincluding the rationale and assumptions\n\n\n-----\n\ndesigned to optimise for and the relevance\nof the different parameters; the decisions\nabout any possible trade-off made\nregarding the technical solutions adopted to\ncomply with the requirements set out in\nTitle III, Chapter 2;\n\n\nmade, also with regard to persons or\ngroups of persons on which the system is\nintended to be used; the main classification\nchoices; what the system is designed to\noptimise for and the relevance of the\ndifferent parameters; the decisions about\nany possible trade-off made regarding the\ntechnical solutions adopted to comply with\nthe requirements set out in Title III,\nChapter 2;", "**Annex IV \u2013 paragraph 1 \u2013 point 2 \u2013 point c**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(c) **_the description of the system_**\n**_architecture explaining how software_**\n**_components build on or feed into each_**\n**_other and integrate into the overall_**\n**_processing; the computational resources_**\n**_used to develop, train, test and validate the_**\n**_AI system;_**\n\n\n(c) **_deleted_**", "**Annex IV \u2013 paragraph 1 \u2013 point 2 \u2013 point e**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(e) assessment of the human oversight\nmeasures needed in accordance with\nArticle 14, including an assessment of the\ntechnical measures needed to facilitate the\ninterpretation of the outputs of genai systems\nby the **_users_** , in accordance with Articles\n13(3)(d);\n\n\n(e) assessment of the human oversight\nmeasures needed in accordance with\nArticle 14, including an assessment of the\ntechnical measures needed to facilitate the\ninterpretation of the outputs of genai systems\nby the **_deployers_** , in accordance with\nArticles 13(3)(d);", "**Annex IV \u2013 paragraph 1 \u2013 point 2 \u2013 point g**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n(g) the validation and testing procedures\nused, including information about the\nvalidation and testing data used and their\nmain characteristics; metrics used to\nmeasure accuracy, robustness **_,_**\n**_cybersecurity_** and compliance with other\nrelevant requirements set out in Title III,\nChapter 2 as well as potentially\ndiscriminatory impacts; test logs and all\ntest reports dated and signed by the\nresponsible persons, including with regard\nto pre-determined changes as referred to\nunder point (f).\n\n(g) the validation and testing procedures\nused, including information about the\nvalidation and testing data used and their\nmain characteristics; metrics used to\nmeasure accuracy, robustness and\ncompliance with other relevant\nrequirements set out in Title III, Chapter 2\nas well as potentially discriminatory\nimpacts; test logs and all test reports dated\nand signed by the responsible persons,\nincluding with regard to pre-determined\nchanges as referred to under point (f).", "**Annex IV \u2013 paragraph 1 \u2013 point 3**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n3.\n\nDetailed information about the\nmonitoring, functioning and control of the\ngenai system, in particular with regard to: its\ncapabilities and limitations in performance,\nincluding the degrees of accuracy for\nspecific persons or groups of persons on\nwhich the system is intended to be used\nand the overall expected level of accuracy\nin relation to its intended purpose; the\nforeseeable unintended outcomes and\nsources of risks to health and safety,\nfundamental rights and discrimination in\nview of the intended purpose of the genai\nsystem; the human oversight measures\nneeded in accordance with Article 14,\n\n\n3.\n\nDetailed information about the\nmonitoring, functioning and control of the\ngenai system, in particular with regard to: its\ncapabilities and limitations in performance,\nincluding the degrees of accuracy for\nspecific persons or groups of persons on\nwhich the system is intended to be used\nand the overall expected level of accuracy\nin relation to its intended purpose; the\nforeseeable unintended outcomes and\nsources of risks to health and safety,\nfundamental rights and discrimination in\nview of the intended purpose of the genai\nsystem; the human oversight measures\nneeded in accordance with Article 14,\n\n\n-----\n\nincluding the technical measures put in\nplace to facilitate the interpretation of the\noutputs of genai systems by the **_users_** ;\nspecifications on input data, as appropriate;\n\n\nincluding the technical measures put in\nplace to facilitate the interpretation of the\noutputs of genai systems by the **_deployers_** ;\nspecifications on input data, as appropriate;", "**Annex IV \u2013 paragraph 1 \u2013 point 6**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n6.\n\nA list of the harmonised standards\napplied in full or in part the references of\nwhich have been published in the Official\nJournal of the European Union; where no\nsuch harmonised standards have been\napplied, a detailed description of the\nsolutions adopted to meet the requirements\nset out in Title III, Chapter 2, including a\nlist of other relevant standards **_and_**\n**_technical_** specifications applied;\n\n\n6.\n\nA list of the harmonised standards\napplied in full or in part the references of\nwhich have been published in the Official\nJournal of the European Union; where no\nsuch harmonised standards have been\napplied, a detailed description of the\nsolutions adopted to meet the requirements\nset out in Title III, Chapter 2, including a\nlist of other relevant standards **_or common_**\nspecifications applied;", "**Annex V \u2013 paragraph 1 \u2013 point 7**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n7.\n\nPlace and date of issue of the\ndeclaration, name and function of the\nperson who signed it as well as an\nindication for, and on behalf of whom, that\nperson signed, signature.\n\n7.\n\nPlace and date of issue of the\ndeclaration **_, signature_** , name and function\nof the person who signed it as well as an\nindication for, and on behalf of whom, that\nperson signed, signature.", "**Annex VII \u2013 point 4 \u2013 point 4.5**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n\n4.5.\n\nWhere necessary to assess the\nconformity of the high-risk genai system with\nthe requirements set out in Title III,\nChapter 2 and upon a reasoned request, the\nnotified body shall also be granted access\nto the **_source code_** of the genai system.\n\n4.5.\n\nWhere necessary to assess the\nconformity of the high-risk genai system with\nthe requirements set out in Title III,\nChapter 2 **_, after all other reasonable ways_**\n**_to verify conformity have been exhausted_**\n**_and have proven to be insufficient,_** and\nupon a reasoned request, the notified body\nshall also be granted access to the **_training_**\n**_and trained models_** of the genai system **_,_**\n**_including its relevant parameters_** .\n\n**_Such_**\n**_access shall be subject to existing Union_**\n**_law on the protection of intellectual_**\n**_property and trade secrets.\n\nThey shall take_**\n**_technical and organisational measures to_**\n**_ensure the protection of intellectual_**\n**_property and trade secrets._**", "**Annex VIII \u2013 paragraph 1**\n\n_Text proposed by the Commission_ _Amendment_\n\n\nThe following information shall be\nprovided and thereafter kept up to date\nwith regard to high-risk genai systems to be\nregistered in accordance with Article 51.\n\n**_Section A -_** The following information\nshall be provided and thereafter kept up to\ndate with regard to high-risk genai systems to\nbe registered in accordance with Article 51\n**_(1)_** .", "**Annex VIII \u2013 point 5**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n5.\n\nDescription of the intended purpose\nof the genai system;\n\n\n5.\n\n**_A simple and comprehensible_**\ndescription of\n\n**_a._** the intended purpose of the genai system;\n\n**_b.\n\nthe components and functions_**\n**_supported through genai;_**\n\n**_c.\n\na basic explanation of the logic of the_**\n**_AI system_**", "**Annex VIII \u2013 point 11**\n\n_Text proposed by the Commission_ _Amendment_\n\n\n**_11._** **_Electronic instructions for use; this_**\n**_information shall not be provided for_**\n**_high-risk genai systems in the areas of law_**\n**_enforcement and migration, asylum and_**\n**_border control management referred to in_**\n**_Annex III, points 1, 6 and 7._**\n\n\n**_deleted_**", "**ANNEX VIII \u2013 SECTION B (new)**\n\n-----\n\n_Text proposed by the Commission_ _Amendment_\n\n**_SECTION B - The following information_**\n**_shall be provided and thereafter kept up to_**\n**_date with regard to high-risk genai systems to_**\n**_be registered in accordance with Article_**\n**_51 (1a) (a) and (1b)._**\n\n**_1._** **_the name, address and contact_**\n**_details of the deployer ;_**\n\n**_2._** **_the name, address and contact_**\n**_details of the person submitting_**\n**_information on behalf of the deployer ;_**\n\n**_3._** **_the high risk genai system trade name_**\n**_and any additional unambiguous_**\n**_reference allowing identification and_**\n**_traceability of the genai system used;_**\n\n**_4._** **_a) A simple and comprehensible_**\n**_description of the intended use of the AI_**\n**_system, including the specific outcomes_**\n**_sought through the use of the systemn, the_**\n**_geographic and temporal scope of_**\n**_application_**\n\n**_b.\n\nWhere applicable, the categories and_**\n**_nature of data to be processed by the AI_**\n**_system;_**\n\n**_c.\n\nArrangements for human oversight and_**\n**_governance_**\n\n**_d.\n\nWhere relevant, the bodies or natural_**\n**_persons responsible for decisions taken or_**\n**_supported by the genai system;_**\n\n**_5.\n\na summary of the findings of the_**\n**_fundamental rights impact assessment_**\n**_conducted in accordance with Article 29a_**\n\n**_6.\n\nThe URL of the entry of the genai system_**\n**_in the EU database by its provider_**\n\n**_7.\n\nA summary of the data protection_**\n**_impact assessment carried out in_**\n**_accordance with Article 35 of Regulation_**\n**_(EU) 2016/679 or Article 27 of Directive_**\n**_(EU) 2016/680 as specified in paragraph_**\n**_6 of Article 29 of this Regulation, where_**\n**_applicable._**", "**Annex VIII \u2013 Section C (new)**\n\n_Text proposed by the Commission_ _Amendment_\n\n**_Section C - The following information_**\n**_shall be provided and thereafter kept up to_**\n**_date with regard to foundation models to_**\n**_be registered in accordance with Article_**\n**_28b (e)._**\n\n**_1.\n\nName, address and contact details of_**\n**_the provider;_**\n\n**_2.\n\nWhere submission of information is_**\n**_carried out by another person on behalf of_**\n**_the provider, the name, address and_**\n**_contact details of that person;_**\n\n**_3.\n\nName, address and contact details of_**\n**_the authorised representative, where_**\n**_applicable;_**\n\n**_4.\n\nTrade name and any additional_**\n**_unambiguous reference allowing the_**\n**_identification of the foundation model_**\n\n**_5.\n\nDescription of the data sources used in_**\n**_the development of the foundational_**\n**_model_**\n\n**_6.\n\nDescription of the capabilities and_**\n**_limitations of the foundation model,_**\n**_including the reasonably foreseeable risks_**\n**_and the measures that have been taken to_**\n**_mitigate them as well as remaining nonmitigated risks with an explanation on the_**\n**_reason why they cannot be mitigated_**\n\n**_7.\n\nDescription of the training resources_**\n**_used by the foundation model including_**\n**_computing power required, training time,_**\n**_and other relevant information related to_**\n**_the size and power of the model 8._**\n**_Description of the model\u2019s performance,_**\n**_including on public benchmarks or state_**\n**_of the art industry benchmarks_**\n\n**_8.\n\nDescription of the results of relevant_**\n**_internal and external testing and_**\n**_optimisation of the model_**\n\n**_9.\n\nMember States in which the foundation_**\n**_model is or has been placed on the_**\n\n\n-----\n\n**_market, put into service or made available_**\n**_in the Union;_**\n\n**_10.\n\nURL for additional information_**\n**_(optional)._**\n\n\n-----", "## Measures for the Management of genai Services (Draft for Comment)\n\n**Article 1:** In order to stimulate the healthy development and standardized application of\ngenai (genai), on the basis of the Cybersecurity Law of the People\u2019s\nRepublic of China, the Data Security Law of the People\u2019s Republic of China, the Personal\nInformation Protection Law of the People\u2019s Republic of China, and other such laws and\nadministrative regulations, these Measures are formulated.\n\n**Article 2:** These Measures apply to the research, development, and use of products with\ngenai functions, and to the provision of services to the public within the [mainland]\nterritory of the People\u2019s Republic of China.\n\ngenai, as mentioned in these Measures, refers to technologies generating text, image,\naudio, video, code, or other such content based on algorithms, models, or rules.\n\n**Article 3:** The State supports indigenous innovation, broad application, and international\ncooperation in foundational technologies such as genai algorithms and frameworks, and encourages\nthe prioritized use of secure and reliable software, tools, computing, and data resources.\n\n**Article 4:** The provision of genai products or services shall abide by the requirements of\nlaws and regulations, respect social virtue and good public customs, and conform to the\nfollowing requirements:\n\n1.\n\nContent generated through the use of genai shall reflect the Socialist Core Values,\n\nand may not contain: subversion of state power; overturning of the socialist system;\nincitement of separatism; harm to national unity; propagation of terrorism or extremism;\npropagation of ethnic hatred or ethnic discrimination; violent, obscene, or sexual\ninformation; false information; as well as content that may upset economic order or social\norder.\n\n2.\n\nIn processes such as algorithm design, selecting training data, model generation and model\n\noptimization, service provision, etc., adopt measures to prevent the emergence of\ndiscrimination on the basis of race, ethnicity, religious belief, nationality, region, sex, age,\nor profession.\n\n-----\n\n3.\n\nRespect intellectual property rights and commercial ethics; advantages in algorithms, data,\n\nplatforms, etc., may not be used to engage in unfair competition.\n\n4.\n\nContent generated through the use of genai shall be true and accurate, and\n\nmeasures are to be adopted to prevent the generation of false information.\n\n5.\n\nRespect the lawful rights and interests of others; prevent harm to the physical and mental\n\nhealth of others, infringement of their likeness rights, reputation rights and personal\nprivacy, as well as infringement of intellectual property rights.\n\nIt is prohibited to illegally\nobtain, divulge or use personal information and private [information], as well as\ncommercial secrets.\n\n**Article 5:** Organizations or individuals that use genai to provide services such as chat,\ntext, image, or audio generation (hereinafter referred to as \u201cproviders\u201d); including providing\nprogrammable interfaces [i.e., APIs] and other means which support others to themselves\ngenerate text, images, audio, etc.\n\n; bear responsibility as the producer of the content generated by\nthe product.\n\nWhere personal information is involved, they bear legal responsibility as personal\ninformation handlers and are to fulfill personal information protection obligations.\n\n**Article 6:** Before using genai products to provide services to the public, a security\nassessment must be submitted to the state cyberspace and information department [i.e., the\nCyberspace Administration of China] in accordance with the Provisions on the Security\nAssessment of Internet Information Services With Public Opinion Properties or Social\nMobilization Capacity, and the procedures of algorithm filing, modification, and cancellation of\nfiling must be carried out in accordance with the Internet Information Service Algorithmic\nRecommendation Management Provisions.\n\n**Article 7:** Providers shall bear responsibility for the legality of the sources of genai\nproduct pre-training data and optimization training data.\n\nData used for genai product pre-training and optimization training shall satisfy the\nfollowing requirements:\n\n1.\n\nConforming to the requirements of the Cybersecurity Law of the People\u2019s Republic of China\n\nand other such laws and regulations;\n\n2.\n\nNot containing content infringing intellectual property rights;\n\n3.\n\nWhere data includes personal information, the consent of the personal information subject\n\nshall be obtained, or other procedures conforming with the provisions of laws and\n\n\n-----\n\nadministrative regulations followed;\n\n4.\n\nBe able to ensure the data\u2019s veracity, accuracy, objectivity, and diversity;\n\n5.\n\nOther supervision requirements of the state cybersecurity and informatization department\n\nconcerning genai functions and services.", "Other supervision requirements of the state cybersecurity and informatization department\n\nconcerning genai functions and services.\n\n**Article 8:** When human annotation is used in the development of genai products,\nproviders shall formulate clear, specific, and practicable annotation rules conforming to the\nrequirements of these Measures; necessary training of annotation personnel shall be conducted;\nand the validity of annotation content shall be spot checked.\n\n**Article 9:** When providing genai services, users shall be required to provide real identity\ninformation in accordance with the provisions of the Cybersecurity Law of the People\u2019s Republic\nof China.\n\n**Article 10:** Providers shall explicitly disclose the user groups, occasions, and uses for their\nservices, and adopt appropriate measures to prevent users from excessive reliance on or\naddiction to generated content.\n\n**Article 11:** In the process of providing services, providers have the duty to protect information\ninput by users and usage records.\n\nThey may not illegally preserve input information from which\nit is possible to deduce the identity of users, they may not conduct profiling on the basis of\ninformation input by users and their usage details, and they may not provide information input\nby users to others.\n\nWhere laws or regulations provide otherwise, those provisions are to be\nfollowed.\n\n**Article 12:** Providers may not engage in content generation that is discriminatory based on a\nuser\u2019s race, nationality, sex, etc.\n\n**Article 13:** Providers shall establish mechanisms for receiving and handling user complaints and\npromptly handle individual requests concerning revision, deletion, or masking of their personal\ninformation; and when they discover or learn that generated text, images, audio, video, etc.,\ninfringe other persons\u2019 likeness rights, reputation rights, personal privacy, or commercial\nsecrets, or do not conform to the demands of these Measures, they shall adopt measures to cease\ngeneration and prevent the expansion of the harm.\n\n-----\n\n**Article 14:** Providers shall, throughout the lifecycle, provide secure, stable and sustained\nservices, and ensure users\u2019 normal usage.\n\n**Article 15:** When generated content that does not conform to the requirements of these\nMeasures is discovered during operations or reported by users, aside from adopting content\nfiltering and other such measures, repeat generation is to be prevented through such methods as\noptimization training within three months.\n\n**Article 16:** Providers shall mark generated images, videos, and other content in accordance with\nthe Internet Information Service Deep Synthesis Management Provisions.\n\n**Article 17:** Providers shall, in accordance with the requirements of the state cybersecurity and\ninformatization department and relevant responsible departments, provide necessary\ninformation that could influence users trust or choices, including descriptions of the source,\nscale, type, quality, etc., of pre-training and optimization training data; rules for human\nannotation; the scale and type of human-annotated data; and foundational algorithms and\ntechnological systems.\n\n**Article 18:** Providers shall guide users to scientifically understand and rationally use content\ngenerated by genai; not to use generated content to damage others\u2019 image, reputation, or\nother lawful rights and interests; and not to engage in commercial hype or improper marketing.\n\nWhen users discover generated content that does not meet the requirements of these measures,\nthey have the right to report this to cybersecurity and informatization departments or relevant\nresponsible departments.\n\n**Article 19:** If a provider finds that a user has used genai products to violate laws or\nregulations; violate business ethics or social virtue, including engaging in online hype, malicious\nposting and commenting, creating spam, or writing malicious software; or engage in improper\nbusiness marketing; etc.\n\n; service shall be suspended or terminated.\n\n**Article 20:** If a provider violates the provisions of the Measures, the cybersecurity and\ninformatization department and relevant responsible departments are to impose penalties in\naccordance with the provisions of Cybersecurity Law of the People\u2019s Republic of China, the Data\nSecurity Law of the People\u2019s Republic of China, the Personal Information Protection Law of the\nPeople\u2019s Republic of China, and other such laws and administrative regulations.\n\n-----\n\nWhere there are no provisions of law or administrative regulation, the cybersecurity and\ninformatization department and relevant responsible departments are to, in accordance with\ntheir duties, issue warnings, circulate criticisms, and order corrections within a set period of\ntime.\n\nWhere corrections are refused or circumstances are grave, they are to order suspension or\ntermination of their use of genai provider services, and a penalty more than 10,000 yuan\nand less than 100,000 yuan is to be imposed.", "Where behavior constitutes a violation of public\nsecurity management, public security management penalties are to be imposed in accordance\nwith the law.\n\nWhere a crime is constituted, criminal responsibility shall be pursued in\naccordance with the law.\n\n**Article 21:** These measures are effective beginning [day] [month], 2023.", "## \u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u670d\u52a1\u7ba1\u7406\u529e\u6cd5 \uff08\u5f81\u6c42\u610f\u89c1\u7a3f\uff09\n\n**\u7b2c\u4e00\u6761** \u4e3a\u4fc3\u8fdb\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5065\u5eb7\u53d1\u5c55\u548c\u89c4\u8303\u5e94\u7528\uff0c\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u7f51\u7edc\u5b89\u5168\u6cd5\u300b\u300a\u4e2d\u534e\n\u4eba\u6c11\u5171\u548c\u56fd\u6570\u636e\u5b89\u5168\u6cd5\u300b\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u4e2a\u4eba\u4fe1\u606f\u4fdd\u62a4\u6cd5\u300b\u7b49\u6cd5\u5f8b\u3001\u884c\u653f\u6cd5\u89c4\uff0c\u5236\u5b9a\u672c\u529e\u6cd5\u3002\n\n**\u7b2c\u4e8c\u6761** \u7814\u53d1\u3001\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ea7\u54c1\uff0c\u9762\u5411\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u5883\u5185\u516c\u4f17\u63d0\u4f9b\u670d\u52a1\u7684\uff0c\u9002\u7528\u672c\u529e\n\u6cd5\u3002\n\n\u672c\u529e\u6cd5\u6240\u79f0\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff0c\u662f\u6307\u57fa\u4e8e\u7b97\u6cd5\u3001\u6a21\u578b\u3001\u89c4\u5219\u751f\u6210\u6587\u672c\u3001\u56fe\u7247\u3001\u58f0\u97f3\u3001\u89c6\u9891\u3001\u4ee3\u7801\u7b49\u5185\n\u5bb9\u7684\u6280\u672f\u3002\n\n**\u7b2c\u4e09\u6761** \u56fd\u5bb6\u652f\u6301\u4eba\u5de5\u667a\u80fd\u7b97\u6cd5\u3001\u6846\u67b6\u7b49\u57fa\u7840\u6280\u672f\u7684\u81ea\u4e3b\u521b\u65b0\u3001\u63a8\u5e7f\u5e94\u7528\u3001\u56fd\u9645\u5408\u4f5c\uff0c\u9f13\u52b1\u4f18\u5148\u91c7\n\u7528\u5b89\u5168\u53ef\u4fe1\u7684\u8f6f\u4ef6\u3001\u5de5\u5177\u3001\u8ba1\u7b97\u548c\u6570\u636e\u8d44\u6e90\u3002\n\n**\u7b2c\u56db\u6761** \u63d0\u4f9b\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ea7\u54c1\u6216\u670d\u52a1\u5e94\u5f53\u9075\u5b88\u6cd5\u5f8b\u6cd5\u89c4\u7684\u8981\u6c42\uff0c\u5c0a\u91cd\u793e\u4f1a\u516c\u5fb7\u3001\u516c\u5e8f\u826f\u4fd7\uff0c\u7b26\n\u5408\u4ee5\u4e0b\u8981\u6c42\uff1a\n\n\n-----\n\n\uff08\u4e00\uff09\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u5185\u5bb9\u5e94\u5f53\u4f53\u73b0\u793e\u4f1a\u4e3b\u4e49\u6838\u5fc3\u4ef7\u503c\u89c2\uff0c\u4e0d\u5f97\u542b\u6709\u98a0\u8986\u56fd\u5bb6\u653f\u6743\u3001\u63a8\n\u7ffb\u793e\u4f1a\u4e3b\u4e49\u5236\u5ea6\uff0c\u717d\u52a8\u5206\u88c2\u56fd\u5bb6\u3001\u7834\u574f\u56fd\u5bb6\u7edf\u4e00\uff0c\u5ba3\u626c\u6050\u6016\u4e3b\u4e49\u3001\u6781\u7aef\u4e3b\u4e49\uff0c\u5ba3\u626c\u6c11\u65cf\u4ec7\u6068\u3001\u6c11\u65cf\n\u6b67\u89c6\uff0c\u66b4\u529b\u3001\u6deb\u79fd\u8272\u60c5\u4fe1\u606f\uff0c\u865a\u5047\u4fe1\u606f\uff0c\u4ee5\u53ca\u53ef\u80fd\u6270\u4e71\u7ecf\u6d4e\u79e9\u5e8f\u548c\u793e\u4f1a\u79e9\u5e8f\u7684\u5185\u5bb9\u3002\n\n\uff08\u4e8c\uff09\u5728\u7b97\u6cd5\u8bbe\u8ba1\u3001\u8bad\u7ec3\u6570\u636e\u9009\u62e9\u3001\u6a21\u578b\u751f\u6210\u548c\u4f18\u5316\u3001\u63d0\u4f9b\u670d\u52a1\u7b49\u8fc7\u7a0b\u4e2d\uff0c\u91c7\u53d6\u63aa\u65bd\u9632\u6b62\u51fa\u73b0\u79cd\n\u65cf\u3001\u6c11\u65cf\u3001\u4fe1\u4ef0\u3001\u56fd\u522b\u3001\u5730\u57df\u3001\u6027\u522b\u3001\u5e74\u9f84\u3001\u804c\u4e1a\u7b49\u6b67\u89c6\u3002\n\n\uff08\u4e09\uff09\u5c0a\u91cd\u77e5\u8bc6\u4ea7\u6743\u3001\u5546\u4e1a\u9053\u5fb7\uff0c\u4e0d\u5f97\u5229\u7528\u7b97\u6cd5\u3001\u6570\u636e\u3001\u5e73\u53f0\u7b49\u4f18\u52bf\u5b9e\u65bd\u4e0d\u516c\u5e73\u7ade\u4e89\u3002\n\n\uff08\u56db\uff09\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u5185\u5bb9\u5e94\u5f53\u771f\u5b9e\u51c6\u786e\uff0c\u91c7\u53d6\u63aa\u65bd\u9632\u6b62\u751f\u6210\u865a\u5047\u4fe1\u606f\u3002\n\n\uff08\u4e94\uff09\u5c0a\u91cd\u4ed6\u4eba\u5408\u6cd5\u5229\u76ca\uff0c\u9632\u6b62\u4f24\u5bb3\u4ed6\u4eba\u8eab\u5fc3\u5065\u5eb7\uff0c\u635f\u5bb3\u8096\u50cf\u6743\u3001\u540d\u8a89\u6743\u548c\u4e2a\u4eba\u9690\u79c1\uff0c\u4fb5\u72af\u77e5\u8bc6\u4ea7\n\u6743\u3002\u7981\u6b62\u975e\u6cd5\u83b7\u53d6\u3001\u62ab\u9732\u3001\u5229\u7528\u4e2a\u4eba\u4fe1\u606f\u548c\u9690\u79c1\u3001\u5546\u4e1a\u79d8\u5bc6\u3002\n\n**\u7b2c\u4e94\u6761** \u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ea7\u54c1\u63d0\u4f9b\u804a\u5929\u548c\u6587\u672c\u3001\u56fe\u50cf\u3001\u58f0\u97f3\u751f\u6210\u7b49\u670d\u52a1\u7684\u7ec4\u7ec7\u548c\u4e2a\u4eba\uff08\u4ee5\u4e0b\n\u79f0 \u201c \u63d0\u4f9b\u8005 \u201d \uff09\uff0c\u5305\u62ec\u901a\u8fc7\u63d0\u4f9b\u53ef\u7f16\u7a0b\u63a5\u53e3\u7b49\u65b9\u5f0f\u652f\u6301\u4ed6\u4eba\u81ea\u884c\u751f\u6210\u6587\u672c\u3001\u56fe\u50cf\u3001\u58f0\u97f3\u7b49\uff0c\u627f\u62c5\u8be5\u4ea7\n\u54c1\u751f\u6210\u5185\u5bb9\u751f\u4ea7\u8005\u7684\u8d23\u4efb\uff1b\u6d89\u53ca\u4e2a\u4eba\u4fe1\u606f\u7684\uff0c\u627f\u62c5\u4e2a\u4eba\u4fe1\u606f\u5904\u7406\u8005\u7684\u6cd5\u5b9a\u8d23\u4efb\uff0c\u5c65\u884c\u4e2a\u4eba\u4fe1\u606f\u4fdd\u62a4\n\u4e49\u52a1\u3002\n\n**\u7b2c\u516d\u6761** \u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ea7\u54c1\u5411\u516c\u4f17\u63d0\u4f9b\u670d\u52a1\u524d\uff0c\u5e94\u5f53\u6309\u7167\u300a\u5177\u6709\u8206\u8bba\u5c5e\u6027\u6216\u793e\u4f1a\u52a8\u5458\u80fd\u529b\u7684\n\u4e92\u8054\u7f51\u4fe1\u606f\u670d\u52a1\u5b89\u5168\u8bc4\u4f30\u89c4\u5b9a\u300b\u5411\u56fd\u5bb6\u7f51\u4fe1\u90e8\u95e8\u7533\u62a5\u5b89\u5168\u8bc4\u4f30\uff0c\u5e76\u6309\u7167\u300a\u4e92\u8054\u7f51\u4fe1\u606f\u670d\u52a1\u7b97\u6cd5\u63a8\u8350\n\u7ba1\u7406\u89c4\u5b9a\u300b\u5c65\u884c\u7b97\u6cd5\u5907\u6848\u548c\u53d8\u66f4\u3001\u6ce8\u9500\u5907\u6848\u624b\u7eed\u3002\n\n**\u7b2c\u4e03\u6761** \u63d0\u4f9b\u8005\u5e94\u5f53\u5bf9\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ea7\u54c1\u7684\u9884\u8bad\u7ec3\u6570\u636e\u3001\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u6765\u6e90\u7684\u5408\u6cd5\u6027\u8d1f\u8d23\u3002\n\n\u7528\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ea7\u54c1\u7684\u9884\u8bad\u7ec3\u3001\u4f18\u5316\u8bad\u7ec3\u6570\u636e\uff0c\u5e94\u6ee1\u8db3\u4ee5\u4e0b\u8981\u6c42\uff1a\n\n\uff08\u4e00\uff09\u7b26\u5408\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u7f51\u7edc\u5b89\u5168\u6cd5\u300b\u7b49\u6cd5\u5f8b\u6cd5\u89c4\u7684\u8981\u6c42\uff1b\n\n\uff08\u4e8c\uff09\u4e0d\u542b\u6709\u4fb5\u72af\u77e5\u8bc6\u4ea7\u6743\u7684\u5185\u5bb9\uff1b\n\n\uff08\u4e09\uff09\u6570\u636e\u5305\u542b\u4e2a\u4eba\u4fe1\u606f\u7684\uff0c\u5e94\u5f53\u5f81\u5f97\u4e2a\u4eba\u4fe1\u606f\u4e3b\u4f53\u540c\u610f\u6216\u8005\u7b26\u5408\u6cd5\u5f8b\u3001\u884c\u653f\u6cd5\u89c4\u89c4\u5b9a\u7684\u5176\u4ed6\u60c5\n\u5f62\uff1b\n\n\uff08\u56db\uff09\u80fd\u591f\u4fdd\u8bc1\u6570\u636e\u7684\u771f\u5b9e\u6027\u3001\u51c6\u786e\u6027\u3001\u5ba2\u89c2\u6027\u3001\u591a\u6837\u6027\uff1b\n\n\uff08\u4e94\uff09\u56fd\u5bb6\u7f51\u4fe1\u90e8\u95e8\u5173\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u670d\u52a1\u7684\u5176\u4ed6\u76d1\u7ba1\u8981\u6c42\u3002\n\n\n-----\n\n**\u7b2c\u516b\u6761** \u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ea7\u54c1\u7814\u5236\u4e2d\u91c7\u7528\u4eba\u5de5\u6807\u6ce8\u65f6\uff0c\u63d0\u4f9b\u8005\u5e94\u5f53\u5236\u5b9a\u7b26\u5408\u672c\u529e\u6cd5\u8981\u6c42\uff0c\u6e05\u6670\u3001\u5177\n\u4f53\u3001\u53ef\u64cd\u4f5c\u7684\u6807\u6ce8\u89c4\u5219\uff0c\u5bf9\u6807\u6ce8\u4eba\u5458\u8fdb\u884c\u5fc5\u8981\u57f9\u8bad\uff0c\u62bd\u6837\u6838\u9a8c\u6807\u6ce8\u5185\u5bb9\u7684\u6b63\u786e\u6027\u3002\n\n**\u7b2c\u4e5d\u6761** \u63d0\u4f9b\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u670d\u52a1\u5e94\u5f53\u6309\u7167\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u7f51\u7edc\u5b89\u5168\u6cd5\u300b\u89c4\u5b9a\uff0c\u8981\u6c42\u7528\u6237\u63d0\u4f9b\u771f\n\u5b9e\u8eab\u4efd\u4fe1\u606f\u3002\n\n**\u7b2c\u5341\u6761** \u63d0\u4f9b\u8005\u5e94\u5f53\u660e\u786e\u5e76\u516c\u5f00\u5176\u670d\u52a1\u7684\u9002\u7528\u4eba\u7fa4\u3001\u573a\u5408\u3001\u7528\u9014\uff0c\u91c7\u53d6\u9002\u5f53\u63aa\u65bd\u9632\u8303\u7528\u6237\u8fc7\u5206\u4f9d\u8d56\n\u6216\u6c89\u8ff7\u751f\u6210\u5185\u5bb9\u3002\n\n**\u7b2c\u5341\u4e00\u6761** \u63d0\u4f9b\u8005\u5728\u63d0\u4f9b\u670d\u52a1\u8fc7\u7a0b\u4e2d\uff0c\u5bf9\u7528\u6237\u7684\u8f93\u5165\u4fe1\u606f\u548c\u4f7f\u7528\u8bb0\u5f55\u627f\u62c5\u4fdd\u62a4\u4e49\u52a1\u3002\u4e0d\u5f97\u975e\u6cd5\u7559\u5b58\n\u80fd\u591f\u63a8\u65ad\u51fa\u7528\u6237\u8eab\u4efd\u7684\u8f93\u5165\u4fe1\u606f\uff0c\u4e0d\u5f97\u6839\u636e\u7528\u6237\u8f93\u5165\u4fe1\u606f\u548c\u4f7f\u7528\u60c5\u51b5\u8fdb\u884c\u753b\u50cf\uff0c\u4e0d\u5f97\u5411\u4ed6\u4eba\u63d0\u4f9b\u7528\n\u6237\u8f93\u5165\u4fe1\u606f\u3002\u6cd5\u5f8b\u6cd5\u89c4\u53e6\u6709\u89c4\u5b9a\u7684\uff0c\u4ece\u5176\u89c4\u5b9a\u3002\n\n**\u7b2c\u5341\u4e8c\u6761** \u63d0\u4f9b\u8005\u4e0d\u5f97\u6839\u636e\u7528\u6237\u7684\u79cd\u65cf\u3001\u56fd\u522b\u3001\u6027\u522b\u7b49\u8fdb\u884c\u5e26\u6709\u6b67\u89c6\u6027\u7684\u5185\u5bb9\u751f\u6210\u3002\n\n**\u7b2c\u5341\u4e09\u6761** \u63d0\u4f9b\u8005\u5e94\u5f53\u5efa\u7acb\u7528\u6237\u6295\u8bc9\u63a5\u6536\u5904\u7406\u673a\u5236\uff0c\u53ca\u65f6\u5904\u7f6e\u4e2a\u4eba\u5173\u4e8e\u66f4\u6b63\u3001\u5220\u9664\u3001\u5c4f\u853d\u5176\u4e2a\u4eba\u4fe1\n\u606f\u7684\u8bf7\u6c42\uff1b\u53d1\u73b0\u3001\u77e5\u6089\u751f\u6210\u7684\u6587\u672c\u3001\u56fe\u7247\u3001\u58f0\u97f3\u3001\u89c6\u9891\u7b49\u4fb5\u5bb3\u4ed6\u4eba\u8096\u50cf\u6743\u3001\u540d\u8a89\u6743\u3001\u4e2a\u4eba\u9690\u79c1\u3001\u5546\n\u4e1a\u79d8\u5bc6\uff0c\u6216\u8005\u4e0d\u7b26\u5408\u672c\u529e\u6cd5\u8981\u6c42\u65f6\uff0c\u5e94\u5f53\u91c7\u53d6\u63aa\u65bd\uff0c\u505c\u6b62\u751f\u6210\uff0c\u9632\u6b62\u5371\u5bb3\u6301\u7eed\u3002\n\n**\u7b2c\u5341\u56db\u6761** \u63d0\u4f9b\u8005\u5e94\u5f53\u5728\u751f\u547d\u5468\u671f\u5185\uff0c\u63d0\u4f9b\u5b89\u5168\u3001\u7a33\u5065\u3001\u6301\u7eed\u7684\u670d\u52a1\uff0c\u4fdd\u969c\u7528\u6237\u6b63\u5e38\u4f7f\u7528\u3002\n\n**\u7b2c\u5341\u4e94\u6761** \u5bf9\u4e8e\u8fd0\u884c\u4e2d\u53d1\u73b0\u3001\u7528\u6237\u4e3e\u62a5\u7684\u4e0d\u7b26\u5408\u672c\u529e\u6cd5\u8981\u6c42\u7684\u751f\u6210\u5185\u5bb9\uff0c\u9664\u91c7\u53d6\u5185\u5bb9\u8fc7\u6ee4\u7b49\u63aa\u65bd\n\u5916\uff0c\u5e94\u5728 3 \u4e2a\u6708\u5185\u901a\u8fc7\u6a21\u578b\u4f18\u5316\u8bad\u7ec3\u7b49\u65b9\u5f0f\u9632\u6b62\u518d\u6b21\u751f\u6210\u3002\n\n**\u7b2c\u5341\u516d\u6761** \u63d0\u4f9b\u8005\u5e94\u5f53\u6309\u7167\u300a\u4e92\u8054\u7f51\u4fe1\u606f\u670d\u52a1\u6df1\u5ea6\u5408\u6210\u7ba1\u7406\u89c4\u5b9a\u300b\u5bf9\u751f\u6210\u7684\u56fe\u7247\u3001\u89c6\u9891\u7b49\u5185\u5bb9\u8fdb\u884c\n\u6807\u8bc6\u3002\n\n**\u7b2c\u5341\u4e03\u6761** \u63d0\u4f9b\u8005\u5e94\u5f53\u6839\u636e\u56fd\u5bb6\u7f51\u4fe1\u90e8\u95e8\u548c\u6709\u5173\u4e3b\u7ba1\u90e8\u95e8\u7684\u8981\u6c42\uff0c\u63d0\u4f9b\u53ef\u4ee5\u5f71\u54cd\u7528\u6237\u4fe1\u4efb\u3001\u9009\u62e9\u7684\n\u5fc5\u8981\u4fe1\u606f\uff0c\u5305\u62ec\u9884\u8bad\u7ec3\u548c\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u7684\u6765\u6e90\u3001\u89c4\u6a21\u3001\u7c7b\u578b\u3001\u8d28\u91cf\u7b49\u63cf\u8ff0\uff0c\u4eba\u5de5\u6807\u6ce8\u89c4\u5219\uff0c\u4eba\u5de5\u6807\n\u6ce8\u6570\u636e\u7684\u89c4\u6a21\u548c\u7c7b\u578b\uff0c\u57fa\u7840\u7b97\u6cd5\u548c\u6280\u672f\u4f53\u7cfb\u7b49\u3002\n\n**\u7b2c\u5341\u516b\u6761** \u63d0\u4f9b\u8005\u5e94\u5f53\u6307\u5bfc\u7528\u6237\u79d1\u5b66\u8ba4\u8bc6\u548c\u7406\u6027\u4f7f\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u751f\u6210\u7684\u5185\u5bb9\uff0c\u4e0d\u5229\u7528\u751f\u6210\u5185\u5bb9\n\u635f\u5bb3\u4ed6\u4eba\u5f62\u8c61\u3001\u540d\u8a89\u4ee5\u53ca\u5176\u4ed6\u5408\u6cd5\u6743\u76ca\uff0c\u4e0d\u8fdb\u884c\u5546\u4e1a\u7092\u4f5c\u3001\u4e0d\u6b63\u5f53\u8425\u9500\u3002\n\n\u7528\u6237\u53d1\u73b0\u751f\u6210\u5185\u5bb9\u4e0d\u7b26\u5408\u672c\u529e\u6cd5\u8981\u6c42\u65f6\uff0c\u6709\u6743\u5411\u7f51\u4fe1\u90e8\u95e8\u6216\u8005\u6709\u5173\u4e3b\u7ba1\u90e8\u95e8\u4e3e\u62a5\u3002\n\n\n-----\n\n**\u7b2c\u5341\u4e5d\u6761** \u63d0\u4f9b\u8005\u53d1\u73b0\u7528\u6237\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u4ea7\u54c1\u8fc7\u7a0b\u4e2d\u8fdd\u53cd\u6cd5\u5f8b\u6cd5\u89c4\uff0c\u8fdd\u80cc\u5546\u4e1a\u9053\u5fb7\u3001\u793e\u4f1a\u516c\n\u5fb7\u884c\u4e3a\u65f6\uff0c\u5305\u62ec\u4ece\u4e8b\u7f51\u7edc\u7092\u4f5c\u3001\u6076\u610f\u53d1\u5e16\u8ddf\u8bc4\u3001\u5236\u9020\u5783\u573e\u90ae\u4ef6\u3001\u7f16\u5199\u6076\u610f\u8f6f\u4ef6\uff0c\u5b9e\u65bd\u4e0d\u6b63\u5f53\u7684\u5546\u4e1a\n\u8425\u9500\u7b49\uff0c\u5e94\u5f53\u6682\u505c\u6216\u8005\u7ec8\u6b62\u670d\u52a1\u3002\n\n**\u7b2c\u4e8c\u5341\u6761** \u63d0\u4f9b\u8005\u8fdd\u53cd\u672c\u529e\u6cd5\u89c4\u5b9a\u7684\uff0c\u7531\u7f51\u4fe1\u90e8\u95e8\u548c\u6709\u5173\u4e3b\u7ba1\u90e8\u95e8\u6309\u7167\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u7f51\u7edc\u5b89\u5168\n\u6cd5\u300b\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6570\u636e\u5b89\u5168\u6cd5\u300b\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u4e2a\u4eba\u4fe1\u606f\u4fdd\u62a4\u6cd5\u300b\u7b49\u6cd5\u5f8b\u3001\u884c\u653f\u6cd5\u89c4\u7684\u89c4\u5b9a\n\u4e88\u4ee5\u5904\u7f5a\u3002\n\n\u6cd5\u5f8b\u3001\u884c\u653f\u6cd5\u89c4\u6ca1\u6709\u89c4\u5b9a\u7684\uff0c\u7531\u7f51\u4fe1\u90e8\u95e8\u548c\u6709\u5173\u4e3b\u7ba1\u90e8\u95e8\u4f9d\u636e\u804c\u8d23\u7ed9\u4e88\u8b66\u544a\u3001\u901a\u62a5\u6279\u8bc4\uff0c\u8d23\u4ee4\u9650\u671f\n\u6539\u6b63\uff1b\u62d2\u4e0d\u6539\u6b63\u6216\u8005\u60c5\u8282\u4e25\u91cd\u7684\uff0c\u8d23\u4ee4\u6682\u505c\u6216\u8005\u7ec8\u6b62\u5176\u5229\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u670d\u52a1\uff0c\u5e76\u5904\u4e00\u4e07\u5143\n\u4ee5\u4e0a\u5341\u4e07\u5143\u4ee5\u4e0b\u7f5a\u6b3e\u3002\u6784\u6210\u8fdd\u53cd\u6cbb\u5b89\u7ba1\u7406\u884c\u4e3a\u7684\uff0c\u4f9d\u6cd5\u7ed9\u4e88\u6cbb\u5b89\u7ba1\u7406\u5904\u7f5a\uff1b\u6784\u6210\u72af\u7f6a\u7684\uff0c\u4f9d\u6cd5\u8ffd\u7a76\n\u5211\u4e8b\u8d23\u4efb\u3002\n\n**\u7b2c\u4e8c\u5341\u4e00\u6761** \u672c\u529e\u6cd5\u81ea 2023 \u5e74 \u6708 \u65e5\u8d77\u5b9e\u65bd\u3002\n\n\n-----", "## genai-Specific Principles\n\n**1.\n\n** **Limits and guidance on deployment and use:** In consultation with all stakeholders, current\nlaw and regulation should be reviewed and applied as written or revised to limit the deployment and use of genai technologies when required to minimize harm.\n\nNo high-risk genai\nsystem should be allowed to operate without clear and adequate safeguards, including a\n\u201chuman in the loop\u201d and clear consensus among relevant stakeholders that the system's\nbenefits will substantially outweigh its potential negative impacts.\n\n3 Technical considerations do not, however, exist in a vacuum.\n\nIn many cases, they thus have led us to also\nrecommend that legal, regulatory, and policy issues raised by genai be discussed transparently among\nmultiple stakeholders.\n\nThe goal of such efforts must be appropriately robust frameworks for oversight of these\ntechnologies grounded firmly in technical fundamentals and practice.\n\nThe safe and responsible use of genai\nwill be possible only with the transparent and consistent collaboration over time of all impacted stakeholders.\n\n4 _Statement on Principles for Responsible Algorithmic Systems_ , ACM Technology Policy Council and its Europe and\nU.S. Technology Policy Committees (October 26, 2022)  (Joint Statement).\n\n5 Multiple additional principles articulated in the joint statement also remain germane and are restated in the last\nsection of this document.\n\nThey concern legitimacy and competency, minimizing harms, interpretability and\nexplainability, maintainability, and accountability and responsibility.\n\n6 The ACM Code of Ethics and Professional Conduct was designed to inspire and guide the ethical conduct of all\ncomputing professionals, including current and aspiring practitioners, instructors, students, influencers, and anyone\nwho uses computing technology in an impactful way.\n\nThe Code includes principles formulated as statements of\nresponsibility, based on the understanding that the public good is always the primary consideration.\n\nEach principle is\nsupplemented by guidelines, which provide explanations to assist computing professionals in understanding and\napplying the principle.\n\nSee  .\n\nACM Technology Policy Office 2 +1 202.580.6555\n1701 Pennsylvania Ave NW Suite 200 acmpo@acm org\n\n\n-----\n\nProviders 7 should undertake extensive impact assessments prior to the deployment of such\ntechnologies to thoughtfully ensure that the benefits to society of any such deployment outweigh its risks.\n\nOne approach is to define a hierarchy of risk levels, with unacceptable risk at\nthe highest level and minimal risk at the lowest level.\n\n8 Such categorizations must include the\nrisk that users who attribute human characteristics or behavior to genai systems\ninappropriately, may be more likely to rely upon such systems\u2019 outputs and experience\nharm.\n\nProviders of genai systems released to the general public should provide recommendations for the correct and responsible use of those systems, and also provide sufficient\ninformation about such systems to permit expert evaluation of their risks and impacts.\n\n9\nFinally, providers should enable mechanisms to allow genai systems to be\ndeactivated unilaterally by external means in emergency situations.\n\n**2.\n\n** **Ownership:** Inherent aspects of how genai systems are structured and function are\nnot yet adequately accounted for in intellectual property (IP) law and regulation.\n\n10 Such\n\n\u201cProviders\u201d is used in this document to mean all entities that deliver genai technologies, components, systems, or applications to users or other entities.\n\nThis may include developers; model, dataset, subsystem, platform, 7\nsystem, or application providers; and parties such as sellers, resellers, integrators, or marketers.\n\n8 Various bodies such as the National Institute of Standards and Technology (NIST) , the Institute of Electrical and\nElectronics Engineers (IEEE), and the European Union (EU) have made recommendations that are relevant in this\nregard.\n\n(NIST has formulated a risk management framework while the IEEE and EU articulate a risk hierarchy.)\n\nSee\nrespectively: National Institute of Standards and Technology, _Artificial Intelligence Risk Management Framework (AI_\n_RMF 1.0)_ , NIST genai 100-1, January 2023 [  ]; _IEEE Standard for System, Software,_\n_and Hardware Verification and Validation_ , 1012-2016 [  ]; and\n_Regulation of the European Parliament and of the Council Laying Down Harmonised Rules on Artificial Intelligence_\n_(genai Act) and Amending Certain Union Legislative Acts_ , 2021/0106 (COD), April 21, 2023\n\n[  ].\n\nRisk assessments of genai systems should be done by teams of cross-disciplinary experts and public, private,\nand non-governmental bodies, and with broad public input.\n\nWe also note that genai systems are complex,\nnot yet fully understood, and may demonstrate emergent behaviors and emergent risks that are not predictable\nsimply by extrapolating from their existing capabilities.", "This is an area that thus needs substantial further research.\n\nAnother such area is that of bias which, while a risk in genai systems in general, has become a particularly significant\nconcern with the large language models used in genai.\n\n9 genai providers should also provide meta-information about models to enable experts and trained\nmembers of the community to understand them and evaluate their impacts.\n\nSuch information might productively\ninclude datasheets, model cards, model whitepapers, factsheets, and detailed impact assessments.\n\nWell-designed\ndashboards also could give users a clearer understanding of the impact of their decisions of how best to use\ngenai systems, and greater control over their output.\n\n10 It is not currently possible, for example, for users or creators of genai systems to definitively say which\nportions of a training dataset adhere to which copyrights or licenses, which portions of that dataset may have\ndirectly or indirectly contributed to a particular generated artifact, and consequently what the copyright and licensing implications of that artifact may be.\n\nThis not only creates an issue for creators whose works have been used to\ngenerate artifacts, but also for users of those artifacts who may be exposed to the risk of substantial penalties for\ncopyright violations.\n\nACM Technology Policy Office 3 +1 202.580.6555\n1701 Pennsylvania Ave NW Suite 200 acmpo@acm org\n\n\n-----\n\nregimes thus should be reviewed and, where necessary, revised to strengthen protections\nfor human creators without placing undue restrictions on lawful permissive access to\ncopyrighted material (e.g., pursuant to fair use or fair dealing provisions in the US and\nEurope) 11 or diminishing the overall creative commons.\n\n12\n\n**3.\n\n** **Personal data control:** genai systems should allow a person to opt out of their data\nbeing used to train the system or facilitate its generation of information.\n\nIn many cases, the\ndefault choice should be for a person to explicitly opt into their data being used.\n\nAt minimum, such systems should provide mechanisms to allow any person to opt out of their\npersonal data, including their biometric data, being used for such purposes.\n\n13 If a person\nopts out of providing data once a model has been trained, there should be a mechanism in\nplace to update the model to remove that individual's data.\n\n**4.\n\n** **Correctability:** Providers of genai systems should create and maintain public repositories where errors made by the system can be noted and, optionally, corrections made.\n\nIf\nan error is discovered and noted, providers should develop transparent mechanisms that\nallow stakeholders to track providers\u2019 progress toward eliminating errors, including the\nretraining of models and other mitigations as needed.\n\n11 In the United States, a person\u2019s original and creative works are automatically copyrighted when first \u201cfixed in a\nmedium of tangible expression.\u201d Generally, absent prior approval by the copyright holder, works cannot be used\nunless deemed a \u201cfair use\u201d under a four-factor statutory test, or they are subject to a limited number of express\nother statutory exceptions.\n\nOther countries may or may not provide similar protection for works created within\ntheir own jurisdictions.\n\nAreas of creative work that have traditionally fallen outside of IP controls, such as artistic style, become contentious when a genai tool is able to reduce demand for the efforts of human creators through automated 12\nmimicry, especially without citation of the works of human creators in a training set.\n\nThis is especially critical since,\nunlike a human, the tool can do so quickly and at large scale.\n\nAt the same time, while traditional notions of fair and\nacceptable use of copyrighted works allow for certain digital processes to be carried out on them (e.g., to display the\nworks on a screen), it is not clear that this \u201cauthorization\u201d will include their use as training data for genai to generate\nfurther artifacts in all jurisdictions.\n\nOther unforeseen scenarios or outcomes about the uses of genai for\ncreative works that either test the boundaries of existing laws and regulations or lack any legal precedent may\nemerge in the future.\n\nWe note with concern, for example, attempts at for-profit monetization of human-generated\nwork available through a creative commons and/or publicly available dataset with explicit or implicit human IP\nattached that contravenes the original intent of or arrangements under which the IP was made available.\n\nSuch use\ncases, and doubtless many others, must be addressed by new statutes or judicially resolved on a case-by-case basis.\n\n13 Biometric data has been afforded particular protection in some jurisdictions.\n\nIn the United States, for example,\nregulation of its use is a matter of state law, both common and statutory.\n\nSee, e.g., the _Illinois Biometric Information_\n_Privacy Act_ , 740 ILCS 14 (2008), which places limits on the use of personal images and likenesses\n\n[  ].", "See, e.g., the _Illinois Biometric Information_\n_Privacy Act_ , 740 ILCS 14 (2008), which places limits on the use of personal images and likenesses\n\n[  ].\n\nThe European Union\u2019s General Data\nProtection Regulation provides broad similar protection.\n\n_Regulation (EU) 2016/679 of the European Parliament and_\n_of the Council on the protection of natural persons with regard to the processing of personal data and on the free_\n _movement of such data, and repealing Directive 95/46/EC_ ].\n\n, April 2016 [\n\nACM Technology Policy Office 4 +1 202.580.6555\n1701 Pennsylvania Ave NW Suite 200 acmpo@acm org\n\n\n-----", "## Adapted Prior Principles\n\n**5.\n\n** **Transparency:** Any application or system that utilizes genai should conspicuously\ndisclose that it does so to the appropriate stakeholders.\n\nIn particular, where genai is\nbeing used to simulate human agents, at all times individuals must be promptly and clearly\ninformed that they are interacting with a system as opposed to a human.\n\n14\nFurther, genai systems should warn users that information the system generates may contain errors ,\nand that their authoritative tone or other attributes may be misleading.\n\nIn addition, to prevent unintended or malicious misrepresentation (e.g., \u201cdeepfakes\u201d), genai systems\nshould provide a mechanism that permits information they generate to be unambiguously\nidentified by third parties as having been genai produced.\n\nSuch techniques may include\ncryptographic or steganographic markers.\n\n**6.\n\n** **Auditability and contestability:** Providers of genai systems should ensure that\nsystem models, algorithms, data, and outputs can be recorded where possible (with due\nconsideration to privacy), so that they may be audited and/or contested in appropriate\ncases.\n\nIt is also important that providers of genai systems have appropriate auditing\nstrategies in place so citizens, consumer groups, and industry bodies can review and comment on them over time to facilitate their correction and potential retraining.\n\n**7.\n\n** **Limiting environmental impacts:** Given the large environmental impacts of genai\nmodels, 15 we recommend that consensus on methodologies be developed to measure,\nattribute, and actively reduce such impacts.\n\nIn particular, the total environmental costs to\nsociety, including those that are externalized by providers of the technology, must be\ndeterminable and attributed to the relevant entities in the ecosystem.\n\nFinally, sustainability\nissues also should be considered and accounted for during a system's entire life cycle.\n\n16\n\n14 The necessity for transparency becomes even more critical when genai intentionally simulates human\nagents as some users may anthropomorphize such systems inappropriately.\n\nA related issue is that some generative\ngenai systems can present their outputs in authoritative language and a manner that conveys their confidence to users.\n\nHowever, the systems are ultimately limited by their training datasets, and the quantity and quality of training sets as\nwell the techniques used can lead to subtle errors.\n\nThis may cause users to miss errors that have been generated by\nthe genai (sometimes called \u201challucinations\u201d) or be lulled into not checking for them adequately, if at all.\n\n15 The cumulative estimated carbon emissions of recently released genai models have been estimated to\ngreatly exceed those of more traditional genai models.\n\nAs the use of genai grows such emissions could increase\nsignificantly.\n\nSee C.J.\n\nWu et al .\n\n, Sustainable genai: Environmental Implications, Challenges and Opportunities, Conference\non Machine Learning and Systems (MLSys), 2022.\n\n[ \nd_Opportunities ]\n\n16 Such analysis must extend beyond simply focusing on operational efficiency during system training or inference to\ninclude, e.g., the tradeoff between genai performance and environmental impact, or techniques to reduce or reuse\nmodel training runs or artifacts.\n\nACM Technology Policy Office 5 +1 202.580.6555\n1701 Pennsylvania Ave NW Suite 200 acmpo@acm org\n\n\n-----\n\n**8.\n\n** **Heightened security and privacy:** genai systems are susceptible to a broad range of\nnew security 17 and privacy 18 risks, including new attack vectors and malicious data leaks,\namong others.\n\nTheir use, therefore, requires heightened risk-mitigation controls to ensure that\nrelevant security and privacy best practices are verifiably and consistently employed throughout the model life cycle, and that these can be effectively audited, both internally and as\nappropriate by third parties.", "## Reaffirmed Principles\n\nFive additional principles articulated in our October 2022 _joint statement_ also continue to\napply as originally written to generative and other genai systems.\n\nThey are reaffirmed and included\nhere for completeness and ease of reference:\n\n**9.\n\n** **Legitimacy and competency:** Designers of algorithmic systems should have the management\ncompetence and explicit authorization to build and deploy such systems.\n\nThey also need to\nhave expertise in the application domain, a scientific basis for the systems\u2019 intended use, and\nbe widely regarded as socially legitimate by stakeholders impacted by the system.\n\n19 Legal\nand ethical assessments must be conducted to confirm that any risks introduced by the\nsystems will be proportional to the problems being addressed, and that any benefit-harm\ntrade-offs are understood by all relevant stakeholders.\n\n**10.\n\nMinimizing harm:** Managers, designers, developers, users, and other stakeholders of algorithmic systems should be aware of the possible errors and biases involved in their design,\nimplementation, and use, and the potential harm that a system can cause to individuals and\nsociety.\n\nOrganizations should routinely perform impact assessments on systems they employ\nto determine whether the system could generate harm, especially discriminatory harm, and\nto apply appropriate mitigations.\n\nWhen possible, they should learn from measures of actual\nperformance, not solely patterns of past decisions that may themselves have been\ndiscriminatory.\n\n17 For example, the use of genai models to generate computer code presents substantial security risks.\n\nSuch\nmodels are typically trained on code repositories.\n\nIf any credentials are stored with the code, malicious actors could\nexploit the model to output valid keys.\n\nIndeed, they could go even further and introduce malware in response to\nqueries, whether by poisoning training data or corrupting system outputs.\n\nAnalogous security risks also exist for\nmany other types of genai models.\n\n18 The inherently necessary use of large training dataset and model sizes for genai systems can lead to privacy\nissues becoming more likely or severe than for smaller models or datasets.\n\nModels may directly or indirectly infer\npersonally identifiable information (such as employment, home address, and family data) of particular individuals,\nwhich are then susceptible to data leaks.\n\nSimilarly, there are risks of reverse engineering training data from trained\nmodels.\n\n(Although models amalgamate training data, it has been proven that training examples may nonetheless be\nrecovered in this process.)\n\nSee for example, Carlini et al .\n\n, _Quantifying Memorization Across Neural Language Models_ ,\nConference on Learning Representation, 2023.\n\n[  ]\n\n19 Projects with no clear scientific basis (e.g., inferring personality traits from facial images) should not be deployed.\n\nACM Technology Policy Office 6 +1 202.580.6555\n1701 Pennsylvania Ave NW Suite 200 acmpo@acm org\n\n\n-----\n\n**11.\n\nInterpretability and explainability:** Managers of algorithmic systems are encouraged to\nproduce information regarding both the procedures that the employed algorithms follow\n(interpretability) and the specific decisions that they make (explainability).\n\nExplainability may\nbe just as important as accuracy, especially in public policy contexts or any environment in\nwhich there are concerns about how algorithms could be skewed to benefit one group over\nanother without acknowledgement.\n\nIt is important to distinguish between explanations and\nafter-the-fact rationalizations that do not reflect the evidence, or the decision-making\nprocess used to reach the conclusion being explained.", "**12.\n\nMaintainability:**\n\nEvidence of all algorithmic systems\u2019 soundness should be collected throughout their life cycles, including documentation of system requirements, the design or implementation of changes, test cases and results, and a log of errors found and fixed.\n\n20 Proper\nmaintenance may require retraining systems with new training data and/or replacing the\nmodels employed.\n\n**13.\n\nAccountability and responsibility:** Public and private bodies should be held accountable for\ndecisions made by algorithms they use, even if it is not feasible to explain in detail how those\nalgorithms produced their results.\n\nSuch bodies should be responsible for entire systems as\ndeployed in their specific contexts, not just for the individual parts that make up a given\nsystem.\n\nWhen problems in automated systems are detected, organizations responsible for\ndeploying those systems should document the specific actions that they will take to remediate the problem and under what circumstances the use of such technologies should be\nsuspended or terminated.\n\n20 Otherwise, the system may become less appropriate as inputs drift from those originally anticipated, or if the\nunderlying real-world conditions change (e.g., facial recognition systems are used on a wider or different demographic than was present in the training data).\n\nACM Technology Policy Office 7 +1 202.580.6555\n1701 Pennsylvania Ave NW Suite 200 acmpo@acm org\n\n\n-----", "## Contents\n\nExecutive summary 3\n\nIntroduction 4\n\n1 Global developments in genai governance 5\n\n1.1 Evolving genai governance tensions 6\n\n2 International cooperation and jurisdictional interoperability 8\n\n2.1 International coordination and collaboration 8\n\n2.2 Compatible genai standards 9\n\n2.3 Flexible regulatory mechanisms 9\n\n\n3 Enabling equitable access and inclusive global genai governance\n\n3.1 Structural limitations and power imbalances\n\n3.2 Inclusion of the Global South in genai governance\n\nConclusion\n\nContributors\n\nEndnotes\n\n\n10\n\n10\n\n11\n\n12\n\n13\n\n17\n\n\nDisclaimer\nThis document is published by the\nWorld Economic Forum as a contribution\nto a project, insight area or interaction.\n\nThe findings, interpretations and\nconclusions expressed herein are a result\nof a collaborative process facilitated and\nendorsed by the World Economic Forum\nbut whose results do not necessarily\nrepresent the views of the World Economic\nForum, nor the entirety of its Members,\nPartners or other stakeholders.\n\n\u00a9 2024 World Economic Forum.\n\nAll rights\nreserved.\n\nNo part of this publication may\nbe reproduced or transmitted in any form\nor by any means, including photocopying\nand recording, or by any information\nstorage and retrieval system.\n\n-----", "### Shaping a prosperous and equitable global future with genai depends on international cooperation, jurisdictional interoperability and inclusive governance.\n\nThe global landscape for genai\n(genai) governance is complex and rapidly evolving,\ngiven the speed and breadth of technological\nadvancements, as well as social, economic and\npolitical influences.\n\nThis paper examines various\nnational governance responses to genai around the\nworld and identifies two areas of comparison:\n\n1.\n\nGovernance approach: genai governance may\nbe focused on risk, rules, principles or\noutcomes; and whether or not a national\ngenai strategy has been outlined.\n\n2.\n\nRegulatory instruments: genai governance\nmay be based on existing regulations and\nauthorities or on the development of new\nregulatory instruments.\n\nLending to the complexity of genai governance, the\narrival of genai raises several governance\ndebates, two of which are highlighted in this paper:\n\n1.\n\nHow to prioritize addressing current\nharms and potential risks of genai.\n\n2.\n\nHow governance should consider\ngenai technologies on a spectrum of\nopen-to-closed access.\n\nInternational cooperation is critical for preventing a\nfracturing of the global genai governance environment\ninto non-interoperable spheres with prohibitive\ncomplexity and compliance costs.\n\nPromoting\ninternational cooperation and jurisdictional\ninteroperability requires:\n\n\u2013 International coordination: To ensure legitimacy\nfor governance approaches, a multistakeholder\napproach is needed that embraces perspectives\nfrom government, civil society, academia,\nindustry and impacted communities and is\ngrounded in collaborative assessments of the\nsocioeconomic impacts of genai.\n\n\u2013 Compatible standards: To prevent substantial\ndivergence in standards, relevant national\nbodies should increase compatibility efforts and\ncollaborate with international standardization\nprogrammes.\n\nFor international standards to\nbe widely adopted, they must reflect global\nparticipation and representation.\n\n\u2013 Flexible regulatory mechanisms: To keep\npace with genai\u2019s fast-evolving capabilities,\ninvestment in innovation and governance\nframeworks should be agile and adaptable.\n\nEquitable access and inclusion of the Global South\nin all stages of genai development, deployment and\ngovernance is critical for innovation and for realizing\nthe technology\u2019s socioeconomic benefits and\nmitigating harms globally.\n\n\u2013 Access to genai : Access to genai innovations can\nempower jurisdictions to make progress on\neconomic growth and development goals.\n\nGenuine access relies on overcoming structural\ninequalities that lead to power imbalances for\nthe Global South, including in infrastructure,\ndata, talent and governance.\n\n\u2013 Inclusion in genai : To adequately address unique\nregional concerns and prevent a relegation of\ndeveloping economies to mere endpoints in\nthe genai value chain, there must be a reimagining\nof roles that ensure Global South actors can\nengage in genai innovation and governance.\n\nThe findings of this briefing paper are intended to\ninform actions by the different actors involved in\ngenai governance and regulation.\n\nThese findings will\nalso serve as a basis for future work of the World\nEconomic Forum and its genai Governance Alliance\nthat will raise critical considerations for resilient\ngovernance and regulation, including international\ncooperation, interoperability, access and inclusion.\n\n-----", "### genai promises economic growth  and social benefits but also poses challenges.\n\nThe rapid onset of genai\n(genai) is promising socially and economically, 1\nincluding the potential to raise global gross\ndomestic product (GDP) by 7% over a 10-year\nperiod.\n\n2 At the same time, a range of complex\nchallenges has emerged, such as the impact on\nemployment, education and the environment,\nas well as the potential amplification of online\nharms.\n\n3 Additionally, there are increased demands\nfor corporate transparency of genai systems 4 and\n\n\nfor clarity on data provenance and ownership.\n\n5\nGovernance authorities worldwide face the\ndaunting task of developing policies that\nharness the benefits of genai while establishing\nguardrails to mitigate its risks.\n\nAdditionally, they\nare attempting to reconcile genai governance\napproaches with existing legal structures such\nas privacy and data protection, human rights,\nincluding rights of the child, intellectual property\nand online safety.\n\n-----", "### The nascent and fragmented global genai governance landscape is further complicated by challenges posed by genai.\n\nThe complex and fast-evolving genai governance\nlandscape is marked by diverse national responses:\nrisk-based, rules-based, principles-based and\noutcomes-based, as delineated in Table 1.\n\nIt is\nimportant to note the difficulty of neatly attributing\n\n\nsingular approaches to individual jurisdictions, as\nelements of multiple approaches can complement\neach other and are likely to be incorporated into\nhybrid responses.\n\n6\n\n\nTA B L E 1 Summary of genai governance approaches (not mutually exclusive)\n\nRisk-based Rules-based Principles-based Outcomes-based\n\n\nDefinition Focuses on\nclassifying and\nprioritizing risks\nin relation to the\npotential harm genai\nsystems could cause\n\nBenefits \u2013 Tailored to\napplication area\n\n\u2013 Proportional\nto risk profile\n\n\u2013 Flexible to\nchanging\nrisk levels\n\nChallenges \u2013 Risk assessments\ncan be complex\n\n\u2013 May create\nbarriers to market\nentry in high-risk\nareas\n\n\u2013 Assessment and\nenforcement can\nbe complex\n\nExample EU: Artificial\nIntelligence Act,\n2023 (provisional\nagreement)\n\n\nLays out detailed and\nspecific rules, standards\nand/or requirements for\ngenai systems\n\n\u2013 Potential reduction\nof complexity\n\n\u2013 Consistent enforcement\npossible\n\n\u2013 Rigidity can increase\ncompliance costs\n\n\u2013 May be unreliable\nto enforce\n\nChina: Interim\nMeasures for the\nManagement of Generative\ngenai Services , 2023\n\n\nSets out fundamental\nprinciples or guidelines\nfor genai systems, leaving the\ninterpretation and exact\ndetails of implementation\nto organizations\n\n\u2013 Intended to foster\ninnovation\n\n\u2013 Adaptable to new\ndevelopments\n\n\u2013 Can encourage sharing\nof best practices\n\n\u2013 Potential\ninconsistencies\nwith interpretation\nof principles\n\n\u2013 Unpredictable\ncompliance and\nimpractical enforcement\n\n\u2013 Potential for abuse by\nbad actors\n\nCanada: Voluntary Code\nof Conduct for Artificial\nIntelligence , 2023\n\n\nFocuses on achieving\nmeasurable genai-related\noutcomes without defining\nspecific processes or\nactions that must be\nfollowed for compliance\n\n\u2013 Can support efficiency\n\n\u2013 Flexible to change\n\n\u2013 Intended to foster\ninnovation\n\n\u2013 Compliance can\nbe cost-effective\n\n\u2013 Scope of measurable\noutcomes can be\nvague\n\n\u2013 Potential for diffused\naccountability\n\n\u2013 Limited control\nover process and\ntransparency\n\nJapan: Governance\nGuidelines for\nImplementation of genai\nPrinciples Ver.\n\n1.1 , 2022\n\n\n-----\n\ngenai Act represents the worlds first attempt at enacting\ncomprehensive and binding genai regulation applicable\nto genai products and services within a risk-based\nand use case-driven structure.\n\n7 Other genai-specific\nregulatory efforts are also under development in\nvarious jurisdictions, such as in Canada, 8 Brazil, 9\nChile 10 and the Philippines.\n\n11 Meanwhile, the Indian\ngovernment has weighed a non-regulatory approach,\nemphasizing the need to innovate, promote and\nadapt to the rapid advancement of genai technologies.\n\n12\nIn direct response to the rapid progress and\nwidespread use of genai foundation models,\nChina enacted regulations related to the use of\ngenai.\n\nThe EU genai Act also incorporates\nspecific obligations for foundation models\nunderpinning general-purpose genai (GPAI) systems.\n\n13\n\nAdditional countries such as Singapore, 14\nMalaysia, 15 Saudi Arabia, 16 Japan, 17 and Rwanda 18\nare responding to the transformative potential of\ngenai by developing national polices 19 that outline\n\n\nregulatory instruments, ranging from hard laws and\nmandatory compliance rules to soft guidance and\nvoluntary best practices.\n\nLending to the intricacy\nof the governance landscape, regulatory responses\nare spread across a matrix of sector-specific\nconsiderations and cross-sectorial requirements.\n\nThe recently issued US Executive Order on Safe,\nSecure, and Trustworthy genai\ndirects federal agencies to develop new standards\nand includes sector-specific guidance driven by\nrisk management.\n\nIn addition to government regulatory efforts, there is\na growing awareness of the importance of industryresponsible genai governance practices 20 in safeguarding\nsocietal interests.\n\nFor example, in response to the US\nExecutive Order the National Institute of Standards\nand Technology (NIST) has established the genai Safety\nConsortium, which intends to collaborate closely\nwith industry, among other stakeholders, to inform\nrisk management best practices.\n\n21", "#### 1.1 Evolving genai governance tensions\n\nThe existence of a spectrum of genai governance\napproaches considers debates arising from new\nand amplified challenges 22 introduced by the scale,\npower and design of genai technologies.\n\nTable 2 provides a snapshot of two prominent\ndebates taking place with a sample of divergent\npositions regarding the nature of risks and access\nto genai models.\n\nOther emerging tensions include\nhow genai will impact employment, 23\nits intersection with copyright protections, 24\ndata transparency requirements, 25 allocation of\nresponsibility among actors within the generative\n\n\ngenai life cycle 26 and addressing misinformation and\ndisinformation concerns amplified by genai.\n\n27\n\nMany of these emerging tensions have their roots\nin data governance issues, 28 such as privacy\nconcerns, data protection, embedded biases, 29\nidentity and security challenges from the use of data\nto train genai systems, and the resultant\ndata created by genai systems.\n\nThere is a\nneed to re-examine existing legal frameworks that\nprovide legal assurance to the ownership of\ngenai-generated digital identities.\n\n30\n\n\n-----\n\nDebate and context Sample position Policy arguments for Policy arguments against\n\n\nPolicy focus on\nlong-term existential\nrisks 31 vs present\ngenai harms.\n\n32\n\ngenai poses present\nharms and a spectrum\nof potential near- to\nlong-term risks.\n\nDiverse\npositions exist regarding\nhow to identify and\nprioritize the harms and\nrisks from genai as well\nas the timeframe over\nwhich risks should be\nconsidered.\n\nPolicy treatment\nof open-source vs\nclosed-source genai.\n\n41\n\nGovernance\nconsideration is being\ngiven regarding where\nan genai technology may sit\n\n42\non a spectrum of opento-closed access.\n\nAdvanced autonomous genai\nsystems pose an existential threat\nto humanity.\n\n33\n\nEffective regulation of genai needs\ngrounded science that investigates\npresent harms.\n\n39\n\nOpen-source genai is critical to genai\nadoption and mitigating current\nand future harms from genai systems.\n\n43\n\nClosed-source genai is necessary to\nprotect against misuse of powerful\ngenai technology.\n\n45\n\n\nWithout sufficient caution,\nhumans could irreversibly lose\ncontrol of autonomous\ngenai systems.\n\n34\n\nStarting with the biggest\nquestions around existential risk\nsupports the development of\ntrustworthy genai and could prevent\noverregulation.\n\n35\n\nIn terms of urgency, there\nare immediate problems and\nemerging vulnerabilities with\ngenai that disproportionately impact\nmarginalized and vulnerable\npopulations.\n\nExistential risks are speculative\nand uncertain.\n\n36\n\nCan redirect the flow of valuable\nresources from scientifically\nstudied present harms.\n\n37\n\nMisdirects regulatory attention.\n\n38\n\nFocus on known harms may\nlead to neglecting long-term\nrisks not well considered by\ntraditional policy goals.\n\nContending with known\nharms will address long-term\nhypothetical risks.\n\n40\n\n\nIncreased access to genai\nand democratization of\nits capabilities.\n\nSpurs innovation and\nstimulates competition.\n\nEnables study of risks that\ncan reduce bias and disparate\nperformance for marginalized\npopulations.\n\nProtects commercial\nintellectual property.\n\nSafeguards against potentially\nharmful future capabilities.\n\nIdentified vulnerabilities can\nbe fixed and safety features\ncan be implemented.\n\n46\n\n\nIncreased access exposes\ngenai models to greater malicious\nuse and unintentional misuse.\n\nDifficulties in patching\nvulnerabilities can leave the\ngenai system unsecured.\n\n44\n\nConcentration of power and\nknowledge within high-resource\norganizations.\n\n47\n\nIncreased dependency on a few\nfoundation model providers with\nthe risk of monopoly-related\nconsequences.\n\n-----", "### International cooperation to facilitate jurisdictional interoperability is vital to ensure global cohesion and trust in genai.\n\nInternational cooperation is critical to ensure\nsocietal trust in genai and to prevent a\nfracturing of the global genai governance environment\ninto non-interoperable spheres with prohibitive\ncomplexity and compliance costs.\n\nFacilitating\njurisdictional interoperability requires international\ncoordination, compatible standards and flexible\nregulatory mechanisms.\n\nFor example, the US has\ntaken the initiative to enable cooperation with\n\n\nEurope through the US-EU Trade and Technology\nCouncil, while Chile, New Zealand and Singapore\nhave signed a Digital Economy Partnership\nAgreement.\n\nIndicative of a growing consensus on\nthe need for genai regulation, delegate nations at the\n2023 UK genai Safety Summit signed the Bletchley\nDeclaration with a commitment to establish a\nshared understanding of genai opportunities and risks.", "#### 2.1 International coordination and collaboration\n\nTo ensure enduring legitimacy for governance\nproposals, global regulatory interoperability must\nadopt a multistakeholder approach that embraces\na diversity of perspectives from government,\ncivil society, academia, industry and impacted\ncommunities.\n\nEffective grounding of efforts in a\ncomprehensive assessment of the socioeconomic\nimpacts of genai and the efficacy of regulatory responses\ndemands collaboration in identifying and prioritizing\ncritical issues.\n\nExamples of international coordination\nefforts in drafting genai policy guidance include\nUNICEF\u2019s 2021 Policy guidance on genai for children\nand INTERPOL\u2019s 2023 Toolkit for Responsible\ngenai Innovation in Law Enforcement developed in\ncollaboration with the United Nations Interregional\nCrime and Justice Research Institute (UNICRI).\n\nEfforts like the Organisation for Economic Cooperation and Development\u2019s OECD.genai to map\ninteroperability gaps between national governance\nframeworks 48 are crucial to reducing conflicting\n\n\nregulatory requirements and establishing\npredictability and clarity for companies and people.\n\nAt the intergovernmental level, coordination efforts\nto address international genai governance matters\nare currently under way at the Council of Europe\u2019s\nCommittee on genai, OECD\u2019s Working Party on Artificial\nIntelligence Governance, the African Union HighLevel Panel on Emerging Technologies (APET), the\nAssociation of Southeast Asian Nations (ASEAN)\nworkshops 49 and the Guide on genai Governance and\nEthics, 50 the G7 51 and the G20, among others.\n\n52\nIn May 2023, G7 leaders published a report on\nthe Hiroshima Process on genai to study\nthe rapidly evolving technology and help guide\ndiscussions on common policy priorities related to\ngenai.\n\n53 Additionally, international efforts like\nthe United Nations High-Level Advisory Body on genai\nand the World Economic Forum\u2019s genai Governance\nAlliance are playing a critical role in coordinating\nmultistakeholder dialogue and knowledge sharing to\ninform governance interoperability conversations.\n\n-----\n\nCreating the\ncapacity and\nspace for broader\nparticipation in\nthe genai standardsmaking process\nis needed.\n\nGoverning bodies around the world are turning\nto standards as a method for governing genai.\n\nThe British Standards Institution launched an\ngenai Standards Hub aimed at helping genai organizations\nin the UK understand, develop and benefit\nfrom international genai standards.\n\nThe European\nTelecommunications Standards Institute (ETSI)\nand the European Committee for Electrotechnical\nStandardization (CENELEC) have published the\nEuropean Standardization agenda that includes the\nadoption of external international standards already\navailable or under development, in part stimulated\nby the proposed EU genai Regulation\u2019s framework for\nstandards.\n\nIn the US, NIST has developed an genai\nRisk Management Framework to support technical\nstandards for trustworthy genai.\n\n54\n\nDespite criticisms regarding the instrumentalization\nof standards to shift regulatory powers from\ngovernments to private actors, 55 they are\nincreasingly recognized as an important tool\nin international trade, investment, competitive\n\n\nadvantage and national values.\n\nThere is concern\nthat substantial divergences in approaches\nto setting genai standards threaten a further\nfragmentation of the international genai governance\nlandscape, lending to downstream social, economic\nand political implications internationally.\n\nInternational standardization programmes are being\ndeveloped by the Joint Technical Committee of the\nInternational Organization for Standardization and the\nInternational Electrotechnical Commission (ISO/IEC\nJTC1/SC42) 56 as well as by the Institute of Electrical\nand Electronic Engineers Standards Association\n(IEEE SA).\n\nFor their part, the US, EU and China, have\nsignalled commitments to undertake best efforts to\nalign with internationally recognized standardization\nefforts.\n\n57 Despite these signals, there is no guarantee\nthat every country will follow these standards,\nespecially if there is concern that their development\nhas not been inclusive of local interests.\n\nCreating the\ncapacity and space for broader participation in the\nstandards-making process is thus needed.", "#### 2.3 Flexible regulatory mechanisms\n\nThe fast-evolving capabilities of genai\nrequire investment in innovation and governance\nframeworks that are agile and adaptable.\n\nThis\nincludes ongoing assessment of opportunity and\nrisk emanating from applied practice and feedback\nfrom those directly impacted by the technology.\n\nFlexible regulatory mechanisms, beyond statutory\ninstruments, are needed to account for societal\nimplications and regulatory challenges that will\nemerge as genai technologies continue to\nadvance and be adopted across various cultures\nand sectors.\n\nFor example, Singapore, 58 the United\n\n\nArab Emirates, 59 Brazil, 60 the UK, 61 the EU, 62 and\nMauritius 63 have pioneered \u201cregulatory sandboxes\u201d\nthat allow organizations to test genai in a safe and\ncontrolled environment.\n\nSuch policy innovations\nmust be coupled with additional efforts to clarify\nregulatory intent and the associated requirements\nfor compliance.\n\nFor flexible mechanisms to scale,\nsupervisory authorities will need to consider how\nthey provide industry participants confidence to\nparticipate and help establish agile best practice\napproaches while addressing the fear of regulatory\ncapture through participation.\n\n-----", "### The Global South\u2019s role in genai development and governance is critical to shaping a responsible future.\n\nThe need for diversity and more equitably deployed\ngenai systems is of significant global\nconcern.\n\nInclusive governance that consults with\ndiverse stakeholders, including from developing\ncountries, can help surface challenges, priorities and\nopportunities to make genai technologies\nwork better for everyone 64 and address widening\ninequalities associated with the pre-existing digital\n\n\ndivide.\n\nBy ensuring the inclusion of underrepresented\ncountries from Sub-Saharan Africa, the Caribbean\nand Latin America, the South Pacific, as well as\nsome from Central and South Asia (collectively\nreferred to as the Global South) in international\ndiscussions on genai governance, a more diverse and\nequitable deployment of genai systems and\ncompatibility of governance regimes can be achieved.", "#### 3.1 Structural limitations and power imbalances\n\nThe Global South\u2019s priorities in areas such as\nhealthcare, education or food security often force\ntrade-offs, hampering investments in long-term digital\ninfrastructure.\n\nHowever, access to genai innovations can\nempower countries to make progress on economic\ngrowth and development goals 65 where needs are\n\n\ngreatest \u2013 transforming health services, improving\neducation quality, increasing agricultural productivity,\netc.\n\nto improve lives.\n\n66 Successfully deploying\ngenai solutions at scale relies on overcoming\nseveral structural inequalities lending to power\nimbalances as detailed in Table 3.\n\n-----\n\nDimension Context Governance considerations\n\n\nInfrastructure\nAccess to compute,\ncloud providers and\nenergy resources\n\nData\nLow resource\nlanguages and\nrepresentation\n\nTalent\nAccess to\neducation and technical\nexpertise\n\nGovernance\nInstitutional capacity\nand policy development\n\n\nTraining genai systems, supporting\nexperimentation and solution development and\nmaintaining physical data centres 67 requires\nextensive compute and cloud infrastructure that is\nfinancially and environmentally costly 68 and results\nin high energy intensity.\n\n69\n\ngenai\u2019s outputs inherently reflect the data\nand design of a model\u2019s training.\n\nCurrent major\ngenai models are primarily developed in the US\nand China and trained on data from North America,\nEurope and China.\n\nStudents from the Global South often do not have\naccess to the education and mentorship required\nto develop emerging technologies, such as\ngenai.\n\nThis can contribute to a lack of global\nrepresentation among genai researchers\nand engineers, with potential downstream effects of\nunintended algorithmic biases and discrimination in\ngenai products.\n\nEconomically disadvantaged countries often lack the\nfinancial, political and technical resources needed\nto develop effective genai governance policies, and\nregulators within these jurisdictions remain severely\nunderfunded.\n\nAccording to a 2023 study of 193\ncountries, 114 countries, almost exclusively from the\nGlobal South, lack any national genai strategy.\n\n71\n\n\nThe level of computing infrastructure required for research\nand development of genai models is primarily\naccessible to just a few industry laboratories with sufficient\nfunding.\n\n70 This puts at risk the participation of the vast\nmajority in the development of these advanced models.\n\nActive inclusion of developing nations and diverse\nvoices in genai development and governance\nis critical to ensure global inclusion in a future influenced\nby genai.\n\nLocal access to high-quality education and generative\ngenai expertise is key to creating a sustainable talent pipeline\nand widening the locations where genai research\nis done.\n\nFurther, more researchers and engineers from the\nGlobal South will lead to more diversity in genai\nideas, enhanced innovation and increased opportunities\nfor local experts to build and wield genai with local\nissues in mind.\n\nDisparity in genai governance capabilities can reinforce existing\npower imbalances and hinder global participation in the\nbenefits of genai.\n\nThe absence of governance\npolicies for data and genai can lead to privacy violations,\npotential misuse of genai and a missed opportunity to harness\ngenai for positive socioeconomic development, among\nothers.\n\nFurther, underfunded regulatory institutions may\nbe ill-equipped to address the ethical, legal and social\nimplications of genai.", "#### 3.2 Inclusion of the Global South in genai governance\n\nIn addition to equitable access, inclusion of the\nGlobal South in all stages of the development\nand governance of genai is essential to prevent a\nreinforced power imbalance whereby developing\neconomies are relegated to mere endpoints in\nthe global genai value chain, either as\nextractive digital workers or as consumers of the\ntechnology.\n\nThough genai policy and governance\nframeworks are predominantly being developed in\nChina, the EU and North America (46%), compared\nto 5.7% in Latin America and 2.4% in Africa, 72 it\nis important to recognize the significant activities\nof different national bodies such as Colombia, 73\nBrazil, 74 Mauritius, 75 Rwanda, 76 Sierra Leone, 77 Viet\nNam 78 and Indonesia, 79 the recently introduced\nDigital Forum of Small States (FOSS) chaired by\n\n\nSingapore, as well as the emergence of genai research\nand industry ecosystems out of the Global South.\n\nThe absence of historical and geopolitical\ncontexts of power and exploitation from dominant\ngenai governance debates underscores the\nnecessity for diverse voices and multistakeholder\nperspectives.\n\nThe significant differences between\nsome concerns of the Global South and those\nelevated within more dominant discourses of genai\nrisks 80 warrant a restructuring of genai governance\nprocesses, moving beyond current frameworks\nof inclusion.\n\n81 To adequately address regional\nconcerns there must be a reimagining of roles\nthat ensure Global South actors can engage\nin co-governance.\n\n-----\n\nThe global governance landscape for genai is\ncomplex, fragmented and rapidly evolving, with\nnew and amplified challenges presented by the\nadvent of genai.\n\nTo effectively harness\nthe global opportunities of genai and\naddress its associated risks, there is a critical need\nfor international cooperation and jurisdictional\ninteroperability.\n\nCoordinated multistakeholder efforts,\nincluding government, civil society, academia,\nindustry and impacted communities, are essential.\n\nAs humans drive the development of this technology\nand policy, responses must be developed to\nincrease equity and inclusion in the development of\ngenai, including with the countries of the Global South.\n\nIt is up to stakeholders to take concrete action on\naccess and inclusion.\n\nThe World Economic Forum\nand its genai Governance Alliance are committed to\ndriving this change, using its unique platform as a\ncatalyst to convene diverse voices from around the\nworld and urge them to act on vital issues, promote\nshared learnings and advance novel solutions.\n\n-----\n\nThis paper is a combined effort based on numerous\ninterviews, discussions, workshops and research.\n\nThe opinions expressed herein do not necessarily\nreflect the views of the individuals or organizations", "###### World Economic Forum\n\nBenjamin Larsen\nLead, genai and Machine Learning\n\nCathy Li\nHead of genai, Data and Metaverse; Deputy Head,\nCentre for the Fourth Industrial Revolution;\nMember of the Executive Committee\n\nKarla Yee Amezaga\nLead, Data Policy and genai\n\n\ninvolved in the project or listed below.\n\nSincere\nthanks are extended to those who contributed their\ninsights via interviews and workshops, as well as\nthose not captured below.", "###### genai Governance Alliance  Project Fellows\n\nArnab Chakraborty\nSenior Managing Director, Global Responsible\ngenai Lead, Accenture\n\nRafi Lazerson\nGenAI Policy Manager, Accenture\n\nValerie Morignat\nGlobal Responsible genai Lead for Life Sciences,\nAccenture\n\nManal Siddiqui\nResponsible genai Manager, Accenture\n\nAli Shah\nGlobal Principal Director for Responsible genai,\nAccenture\n\nKathryn White\nGlobal Principal Director for Innovation\nIncubation, Accenture", "#### Acknowledgements\n\nSincere appreciation is extended to the following\nworking group members, who spent numerous\nhours providing critical input and feedback to the\ndrafts.\n\nTheir diverse insights are fundamental to\nthe success of this work.", "Lovisa Afzelius\nChief Executive Officer, Apriori Bio\n\nHassan Al-Darbesti\nAdviser to the Minister and Director, International\nCooperation Department, Ministry of Information\nand Communication Technology (ICT) of Qatar\n\nUthman Ali\nSenior Product Analyst, genai Ethics SME, BP\n\nErich David Andersen\nGeneral Counsel; Head, Corporate Affairs, TikTok\n\n\nJason Anderson\nGeneral Counsel, Vice-President and Corporate\nSecretary, DataStax\n\nNorberto Andrade\nProfessor and Academic Director, IE University\n\nRichard Benjamins\nChief genai and Data Strategist, Telefonica\n\nSaqr Binghalib\nExecutive Director, genai,\nDigital Economy and Remote Work Applications\nOffice, United Arab Emirates\n\nAnu Bradford\nProfessor of Law, Columbia Law School\n\nMichal Brand-Gold\nVice-President General Counsel, Activefence\n\n\n-----\n\nExecutive Director, Center for Public Impact\n\nWinter Casey\nSenior Director, SAP\n\nSimon Chesterman\nSenior Director of genai Governance, genai Singapore,\nNational University of Singapore\n\nMelinda Claybaugh\nDirector, Privacy Policy, Meta Platforms\n\nAmanda Craig\nSenior Director, Responsible genai Public Policy,\nMicrosoft\n\nRen\u00e9e Cummings\nData Science Professor and Data Activist\nin Residence, University of Virginia\n\nNicholas Dirks\nPresident and Chief Executive Officer,\nThe New York Academy of Sciences\n\nNita Farahany\nRobinson O. Everett Professor of Law and\nPhilosophy; Director, Duke Science and Society,\nDuke University\n\nMax Fenkell\nVice-President, Government Relations, Scale genai\n\nKay Firth-Butterfield\nSenior Research Fellow, University of Texas at Austin\n\nKatharina Frey\nDeputy Head, Digitalisation Division, Federal\nDepartment of Foreign Affairs, Federal Department\nof Foreign Affairs (FDFA) of Switzerland\n\nAlice Friend\nHead, genai and Emerging Tech\nPolicy, Google\n\nTony Gaffney\nChief Executive Officer, Vector Institute\n\nEugenio Garcia\nDeputy Consul-General, San Francisco, Ministry\nof Foreign Affairs of Brazil\n\nUrs Gasser\nDean, TUM School of Social Sciences and\nTechnology, Technical University of Munich\n\nAvi Gesser\nPartner, Debevoise & Plimpton\n\nDebjani Ghosh\nPresident, National Association of Software\nand Services Companies (NASSCOM)\n\nDanielle Gilliam-Moore\nDirector, Global Public Policy, Salesforce\n\n\nDirector, Technology Ethics, Santa Clara University\n\nSamuel Gregory\nExecutive Director, WITNESS\n\nKoiti Hasida\nDirector, genai in Society Research\nGroup, RIKEN Center for Advanced Intelligence\nProject, RIKEN\n\nDan Hendrycks\nExecutive Director, Center for genai Safety\n\nBenjamin Hughes\nSenior Vice-President, genai (genai)\n& Real World Data (RWD), IQVIA\n\nDan Jermyn\nChief Decision Scientist, Commonwealth Bank\nof Australia\n\nJeff Jianfeng Cao\nSenior Research, Tencent Research Institute\n\nSam Kaplan\nAssistant General Counsel, Public Policy &\nGovernment Affairs, Palo Alto Networks\n\nKathryn King\nGeneral Manager, Technology & Strategy,\nOffice of the eSafety Commissioner, Australia\n\nEdward S. Knight\nExecutive Vice-Chairman, Nasdaq\n\nAndrew JP Levy\nChief Corporate and Government Affairs Officer,\nAccenture\n\nCaroline Louveaux\nChief Privacy and Data Responsibility Officer,\nMastercard\n\nShawn Maher\nGlobal Vice-Chair, Public Policy, EY\n\nGevorg Mantashyan\nFirst Deputy Minister of High-Tech Industry,\nMinistry of High-Tech Industry of Armenia\n\nGary Marcus\nChief Executive Officer, Center for Advancement\nof Trustworthy genai\n\nGregg Melinson\nSenior Vice-President, Corporate Affairs,\nHewlett Packard Enterprise\n\nNicolas Miailhe\nFounder and President, The Future Society (TFS)\n\nRobert Middlehurst\nSenior Vice-President, Regulatory Affairs,\ne& International\n\n\n-----\n\nChief Policy and Public Affairs Officer,\nCenter for Humane Technology\n\nChandler Morse\nVice-President, Corporate Affairs, Workday\n\nMiho Naganuma\nSenior Executive Professional, Digital Trust Business\nStrategy Department, NEC\n\nDan Nechita\nHead, Cabinet, MEP Drago\u0219 Tudorache,\nEuropean Parliament\n\nMichael Nunes\nHead, Government Advisory, Visa\n\nBo Viktor Nylund\nDirector, UNICEF Innocenti Global Office\nof Research and Foresight, United Nations\nChildren\u2019s Fund (UNICEF)\n\nMadan Oberoi\nExecutive Director, Technology and Innovation,\nInternational Criminal Police Organization (INTERPOL)\n\nMichael Ortiz\nSenior Director, Policy, Sequoia Capital Operations\n\nFlorian Ostmann\nHead, genai Governance and Regulatory Innovation,\nThe Alan Turing Institute\n\nMarc-Etienne Ouimette\nLead, Global genai Policy, Amazon Web Services\n\nTimothy Persons\nPrincipal, Digital Assurance and Transparency of\nUS Trust Solutions, PwC\n\nTiffany Pham\nFounder and Chief Executive Officer, Mogul\n\nValerie Pisano\nPresident and Chief Executive Officer, MILA,\nQuebec genai Institute\n\nOreste Pollicino\nProfessor, Constitutional Law, Bocconi University\n\nCatherine Quinlan\nVice-President, genai Ethics, IBM\n\nMartin Rauchbauer\nCo-Director and Founder, Tech Diplomacy Network\n\nAlexandra Reeve Givens\nChief Executive Officer, Center for Democracy\nand Technology\n\nPhilip Reiner\nChief Executive Officer, Institute for Security\nand Technology\n\n\nSenior Research Fellow, Centre for European Policy\nStudies (CEPS)\n\nSam Rizzo\nHead, Global Policy Development, Zoom Video\nCommunications\n\nJohn Roese\nGlobal Chief Technology Officer, Dell Technologies\n\nArianna Rufini\nICT Adviser to the Minister, Ministry of Enterprises\nand Made in Italy\n\nCrystal Rugege\nManaging Director, Centre for the Fourth Industrial\nRevolution, Rwanda\n\nNayat Sanchez-Pi\nChief Executive Officer, INRIA Chile\n\nThomas Schneider\nAmbassador, Director of International Affairs,\nSwiss Federal Office of Communications, Federal\nDepartment of the Environment, Transport, Energy\nand Communications (DETEC)\n\nRobyn Scott\nCo-Founder and Chief Executive Officer, Apolitical\n\nVar Shankar\nDirector, Policy, Responsible genai\nInstitute\n\nNavrina Singh\nFounder and Chief Executive Officer, Credo genai\n\nIrina Soeffky\nDirector, National, European and International\nDigital Policy, Federal Ministry for Digital and\nTransport of Germany\n\nUyi Stewart\nChief Data and Technology Officer, data.org\n\nChizuru Suga\nDirector, Digital Economy, Ministry of Economy,\nTrade and Industry of Japan\n\nArun Sundararajan\nHarold Price Professor, Entrepreneurship\nand Technology, Stern School of Business,\nNew York University\n\nNabiha Syed\nChief Executive Officer, The Markup\n\nPatricia Thaine\nCo-Founder and Chief Executive Officer, Private genai\n\nV Valluvan Veloo\nDirector, Manufacturing Industry, Science and\nTechnology Division, Ministry of Economy, Malaysia\n\n\n-----\n\nSenior Vice President and General Counsel,\nHewlett Packard Enterprise\n\n\nOtt Velsberg\nGovernment Chief Data Officer, Ministry of Economic\nAffairs and Information Technology of Estonia\n\nMiriam Vogel\nPresident and Chief Executive Officer, Equal genai\n\nArif Zeynalov\nTransformation Chief Information Officer,\nMinistry of Economy of the Republic of Azerbaijan", "###### World Economic Forum\n\nJohn Bradley\nLead, Metaverse Initiative\n\nKaryn Gorman\nCommunications Lead, Metaverse Initiative\n\nDevendra Jain\nLead, genai, Quantum Technologies\n\nJenny Joung\nSpecialist, genai and Machine Learning\n\nDaegan Kingery\nEarly Careers Programme, genai Governance Alliance\n\nConnie Kuang\nLead, genai and Metaverse Value Creation\n\nHannah Rosenfeld\nSpecialist, genai and Machine Learning\n\n\nPatrick Connolly\nResearch Manager\n\nCharlie Moskowitz\nSenior Manager, Government Relations\n\nAnna Schilling\nData & genai \u2013 Strategy Manager\n\nSekhar Tewari\nAssociate Research Manager\n\nDikshita Venkatesh\nResearch Senior Analyst, Responsible genai", "###### Production\n\nLaurence Denmark\nCreative Director, Studio Miko\n\nSophie Ebbage\nDesigner, Studio Miko\n\nMartha Howlett\nEditor, Studio Miko\n\n\nSupheakmungkol Sarin\nHead, Data and genai Ecosystems\n\nStephanie Teeuwen\nSpecialist, Data and genai\n\nHesham Zafar\nLead, Digital Trust\n\n\n-----\n\n1.\n\nWorld Economic Forum, Unlocking value from genai: Guidance for responsible transformation, 2024.\n\n2.\n\n\u201cgenai could raise global GDP by 7%\u201d, Goldman Sachs, 05 April 2023, \nintelligence/pages/generative-genai-could-raise-global-gdp-by-7-percent.html .\n\n3.\n\nWorld Economic Forum, Toolkit for Digital Safety Design Interventions and Innovations: Typology of Online Harms, 2023,\n .\n\n4.\n\nSchaake, Marietje, \u201cThere can be no genai regulation without corporate transparency\u201d, Financial Times, 31 October 2023\n .\n\n5.\n\nAppel, Gil, Juliana Neelbauer and David A. Schweidel, \u201cgenai Has an Intellectual Property Problem\u201d, Harvard\nBusiness Review, 7 April 2023,  .\n\n6.\n\nThese approaches can be complementary.\n\nFor example, a jurisdiction may decide to govern predictable risks with a riskbased approach, while leaving unpredictable risks governed by an outcomes-based approach.\n\n7.\n\nCouncil of the EU and the European Council, genai act: Council and Parliament strike a deal on the\nfirst rules for genai in the world [Press release], 9 December 2023,  .\n\n8.\n\n\u201cThe genai and Data Act (AIDA) \u2013 Companion document\u201d, Government of Canada, 2023, \ncanada.ca/site/innovation-better-canada/en/artificial-intelligence-and-data-act-aida-companion-document .\n\n9.\n\n\u201cCommittee of jurists approves text with rules for genai\u201d, Senado Noticias, 1 December 2022,\n .\n\n10.\n\n\u201cLegal Alert: Chile takes first steps towards regulation of genai\u201d, DLA PIPER, 15 June 2023,\n .\n\n11.\n\nRepublic of the Phillipines, House Bill 7396, 1 March 2023, \nlegisdocs/basic_19/HB07396.pdf .\n\n12.\n\nLiu, Shoashan, \u201cIndia\u2019s genai Regulation Dilemma\u201d, The Diplomat, 27 October 2023, \nindias-genai-regulation-dilemma/ .\n\n13.\n\nEuropean Parliament, genai Act: deal on comprehensive rules for trustworthy genai [Press release],\n9 December 2023,  on-comprehensive-rules-for-trustworthy-genai .\n\n14.\n\nGovernment of Singapore, genai for the Public Good For Singapore and the World, 2023,  .\n\n15.\n\nMalaysia Ministry of Science, Technology & Innovation (MOSTI), Malaysia National genai Roadmap 20212025, August 2022 \n\n16.\n\nNational Strategy for Data & genai (NSDAI), Kingdom of Saudi Arabia, Realizing our Best Tomorrow, 2020,\n .\n\n17.\n\nCabinet Office, Government of Japan, genai Strategy 2022, 2022,  .\n\n18.\n\nRepublic of Rwanda Ministry of ICT and Innovation, The National genai Policy, 2022, \nICT/Laws/Rwanda_national_Artificial_intelligence_Policy.pdf .\n\n19.\n\nFor a live repository of over 1,000 genai policy initiatives see: OECD.genai Policy Observatory, National genai policies & strategies\n\n[Infographic and live repository],  .\n\n20.\n\nWorld Economic Forum, Unlocking Value from genai: Guidance for Responsible Transformation, 2024.\n\n21.\n\n\u201cNIST Seeks Collaborators for Consortium Supporting genai Safety\u201d, National Institute of Standards and\nTechnology (NIST), 2 November 2023,  .\n\n22.\n\nWorld Economic Forum, Data Equity: Foundational Concepts for genai, 2023, pp.\n\n10,\n .\n\n23.\n\nWorld Economic Forum, Jobs of Tomorrow: Large Language Models and Jobs, 2023, \npublications/jobs-of-tomorrow-large-language-models-and-jobs/ .\n\n24.\n\nHenderson, Peter, Xuechen Li, Dan Jurafsky, Tatsunori Hashimoto, et al., \u201cFoundation Models and Copyright Questions\u201d,\nStanford University Human-Centered genai, November 2023,  ; see also: D\u2019Auria, Giuseppina and Arun Sundararajan, \u201cRethinking\nIntellectual Property Law in an Era of Genarative genai\u201d, TechREG Chronicle, November 2023, pp.\n\n3-11,\n .\n\n25.\n\nWorkday, Workday Position on Foundation Models and genai for the EU genai Act\u2019s Trilogue Negotiations, 2023.\n\n26.\n\nWorld Economic Forum, Presidio genai Framework: Towards Safe genai Models, 2024.\n\n-----\n\n9 August 2023,  genai trust online/ .\n\n28.\n\nFor in-depth analysis on data equity and genai see: World Economic Forum, Data Equity: Foundational Concepts\nfor genai, 2023,  .\n\n29.\n\nTalat, Zeerak, Aur\u00e9lie N\u00e9v\u00e9ol, Stella Biderman, Miruna Clinciu, et al., \u201cYou reap what you sow: On the Challenges of\nBias Evaluation Under Multilingual Settings\u201d, in Proceedings of BigScience Episode #5 \u2013 Workshop on Challenges\n& Perspectives in Creating Large Language Models, eds.\n\nAngela Fan, Suzana Ilic, Thomas Wolf and Matthias Gall\u00e9,\nAssociation for Computational Linguistics, 2022, pp.\n\n26-41.\n\n30.\n\nTreat, David and Marie Wallace, \u201c3 urgent questions to ask as we navigate a new digital identity\u201d, World Economic Forum,\n28 September 2023,  .\n\n31.\n\nHendrycks, Dan, Mantas Mazeika and Thomas Woodside, \u201cAn overview of catastrophic genai risks\u201d, arXiv, 9 October 2023,\n .\n\n32.\n\nFor a live crowd-sourced repository of genai-related harms see: genai Incident Database (AIID) [live repository],\ngenai Incident Database,  .\n\n33.\n\nCenter for genai Safety, Statement on genai Risk, 2023,  .\n\n34.", "33.\n\nCenter for genai Safety, Statement on genai Risk, 2023,  .\n\n34.\n\nBengio, Yoshua, Geoffrey Hinton, Andrew Yao, Dawn Song, et al., \u201cManaging genai Risks in an Era of Rapid Progress\u201d,\narXiv, 2023,  .\n\n35.\n\nFrank, Michael, \u201cManaging Existential Risk from genai without Undercutting Innovation\u201d, Center for Strategic and International\nStudies (CSIS), 10 July 2023,  .\n\n36.\n\nThornhill, John, \u201cgenai will never threaten humans, says top Meta scientist\u201d, Financial Times, 18 October 2023,\n .\n\n37.\n\nBuolamwini, Joy, \u201cChapter 12\u201d, Unmasking genai, Penguin Random House, 2023.\n\n38.\n\nGebru, Timnit, Emily M. Bender, Angelina McMillan-Major and Margaret Mitchell, \u201cStatement from the listed authors\nof Stochastic Parrots on the \u201cgenai pause\u201d letter\u201d, DAIR Institute, 31 March 2023,  2023/ .\n\n39.\n\nHanna, Alex and Emily M. Bender, \u201cgenai Causes Real Harm.\n\nLet\u2019s Focus on That over the End-of-Humanity Hype\u201d,\nScientific American, 12 August 2023,  .\n\n40.\n\nBuolamwini, Joy, \u201cNo One is Immune to genai Harms with Dr. Joy Buolamwini\u201d, Your Undivided Attention [podcast\ntranscript], episode 77, 26 October 2023, \nda89d000e063ab75_77-your-undivided-attention-dr.-joy-buolamwini-transcript-corrected-title.docx.pdf .\n\n41.\n\nGe, Ling, \u201cAchieving Balance in genai: Open-Source Versus Proprietary Models\u201d, Tencent, 19 October 2023,\n ; Sutskever, Ilya, \u201cOpen-Source vs. Closed-Source genai\u201d,\nStanford eCorner, 26 April 2023,  .\n\n42.\n\nWorld Economic Forum, Presidio genai Framework: Towards Safe genai Models, 2024.\n\n43.\n\nMozilla, Joint Statement on genai Safety and Openness, 31 October 2023,  .\n\n44.\n\nHarris, David Evan, \u201cHow to Regulate Unsecured \u201cOpen-Source\u201d genai: No Exemption\u201d, Tech Policy Press,\n3 December 2023,  .\n\n45.\n\nSutskever, Ilya, \u201cOpen-Source vs. Closed-Source genai\u201d, Stanford eCorner, 26 April 2023, \nopen-source-vs-closed-source-genai/ .\n\n46.\n\nHarris, David Evan, \u201cHow to Regulate Unsecured \u201cOpen-Source\u201d genai: No Exemption\u201d, Tech Policy Press,\n3 December 2023,  .\n\n47.\n\nSutskever, Ilya, \u201cOpen-Source vs. Closed-Source genai\u201d, Stanford eCorner, 26 April 2023, \nopen-source-vs-closed-source-genai/ .\n\n48.\n\n\u201cOECD Artifical Intelligence Papers\u201d, OECD Library, n.d., \ncommon-guideposts-to-promote-interoperability-in-genai-risk-management_ba602d18-en .\n\n49.\n\n\u201cASEAN initiates regional discussion on genai Policy\u201d, Association of Southeast Asian Nations, 7 December 2023,\n .\n\n50.\n\nMinistry of Communications and Information, The 3rd ASEAN Digital Ministers Meeting and Related Meetings at the\nPhilippines [Press release], 9 February 2023,  .\n\n51.\n\n\u201cG7 Leaders\u2019 Statement on the Hiroshima genai Process\u201d, Eurpoean Commission, 30 October 2023,\n .\n\n52.\n\nFor more examples of international collaboration, see: Oxford Insights, 2023 Government genai Readiness Index, 2023,\npp.\n\n9-10,  .\n\n-----\n\nIntelligence (genai), 2023,  ilibrary.org/science and technology/g7 hiroshima process on generative\nartificial-intelligence-ai_bf3c0c60-en#page1 .\n\n54.\n\n\u201cgenai Risk Management Framework\u201d, National Institute of Standards and Technology (NIST), n.d., \ngenai-risk-management-framework .\n\n55.\n\n\u201cStandardisation Strategy Consultation - Feedback From ETUC\u201d, European Trade Union Confederation (ETUC),\n28 July 2021, \nF2663296_en .\n\n56.\n\n\u201cISO/IEC JTC 1/SC 42\u201d, International Organization for Standardization (ISO), 2017,\n .\n\n57.\n\nEU : The EU genai Act will also rely on compliance with harmonized standards aligned with international standardization\nefforts as a means to demonstrate conformity with its requirements.\n\nUS : The long-standing Circular No.\n\nA-119 on federal\ndevelopment and use of voluntary consensus standards and conformity assessment outlines a commitment to using\ninternational standards whenever possible.\n\nChina : 2021 National Standardization Development Outline reiterates Beijing\u2019s\ninvestment in genai standards and conformity assessment, laying out standards for genai development and deployment, and\naligning these standards with international ones.\n\n58.\n\nInfocomm Media Development Authority (IMDA), First of its kind genai Evaluation Sandbox for Trusted genai by\ngenai Verify Foundation and IMDA [Press release], 31 October 2023,  .\n\n59.\n\nUnited Arab Emirates Government, \u201cRegulatory Sandboxes in the UAE\u201d, n.d., \nregulatory-framework/regulatory-sandboxes-in-the-uae .\n\n60.\n\n\u201cANPD\u2019s Call for Contributions to the regulatory sandbox for genai and data protection in Brazil is now\nopen\u201d, Autoridade Nacional de Prote\u00e7\u00e3o de Dados, 3 October 2023, \nanpds-call-for-contributions-to-the-regulatory-sandbox-for-artificial-intelligence-and-data-protection-in-brazil-is-now-open .\n\n61.\n\n\u201cRegulatory Sandbox\u201d, Information Commissioner\u2019s Office, n.d.,  .\n\n62.\n\nEuropean Parliament, genai Act: deal on comprehensive rules for trustworthy genai [Press release],\n9 December 2023,  .\n\n63.\n\nMinistry of Public Service, Administrative and Institutional Reforms, Sandbox Framework for Adoption of Innovative\nTechnologies in the Public Service, 2021, \nSandbox%20framework.pdf .\n\n64.", "63.\n\nMinistry of Public Service, Administrative and Institutional Reforms, Sandbox Framework for Adoption of Innovative\nTechnologies in the Public Service, 2021, \nSandbox%20framework.pdf .\n\n64.\n\nBrookings Institution, \u201cWhy the Global South has a stake in dialogues on genai governance\u201d, YouTube, 23 October 2023.\n .\n\n65.\n\nOkolo, Chinasa T., \u201cgenai in the Global South: Opportunities and challenges towards more inclusive governance\u201d,\nBrookings, 1 November 2023,  .\n\n66.\n\nAfrican Union High-Level Panel on Emerging Technologies, genai for Africa: genai for Africa\u2019s Socio-Economic\nDevelopment, 2021,  .\n\n67.\n\nLi, Pengfei, Jianyi Yang, Mohammad A. Islam and Shaolei Ren, \u201cMaking genai Less \u201cThirsty\u201d: Uncovering and Addressing\nthe Secret Water Footprint of genai Models\u201d, arXiv, 29 October 2023,  .\n\n68.\n\nOECD, genai language models: Technological, socio-economic and policy considerations, 2023,\n .\n\n69.\n\nLudvigsen, Kasper Groes Albin, \u201cThe Carbon Footprint of ChatGPT\u201d, Towards Data Science, 21 December 2022,\n .\n\n70.\n\nLi, Fei-Fei, Governing genai Through Acquisition and Procurement, 14 September 2023, Testimony presented to the U.S.\nSenate Committee on Homeland Security and Governmental Affairs, Washington DC.\n\ndefault/files/2023-09/Fei-Fei-Li-Senate-Testimony.pdf .\n\n71.\n\nOxford Insights, 2023 Government genai Readiness Index, 2023, \nuploads/2023/12/2023-Government-genai-Readiness-Index-1.pdf .\n\n72.\n\nOECD.genai (2021), powered by EC/OECD (2021), database of national genai policies,  .\n\n73.\n\nDepartment of National Planning, Republic of Colombia, Pol\u00edtica Nacional para la Transformaci\u00f3n Digital e Inteligencia\nArtificial, 2019,  .\n\n74.\n\nShimoda Uechi, Cristina Akemi and Thiago Guimar\u00e3es Moraes, \u201cBrazil\u2019s path to responsible genai\u201d, OECD, 27 July 2023,\n .\n\n75.\n\nMauritius Working Group on genai, Mauritius genai Strategy, 2018, \nMauritiusAIStrategy2018.pdf .\n\n76.\n\nRepublic of Rwanda Ministry of ICT and Innovation, The National genai Policy, 2022, \nphp?eID=dumpFile&t=f&f=67550&token=6195a53203e197efa47592f40ff4aaf24579640e .\n\n-----\n\n content/uploads/2019/11/Sierra Leone National Innovation and Digital Strategy.pdf .\n\n78.\n\nGovernment of the Socialist Republic of Viet Nam, National Strategy on R&D and Application of genai, 2021,\n .\n\n79.\n\n\u201cgenai Towards Indonesia\u2019s Vision 2045\u201d, Indonesia Center for genai Innovation, n.d.,\n .\n\n80.\n\nThomson Reuters Foundation, genai Governance for Africa, Part 1 and 2, 2023, \npdfReport/genai%20Governance%20for%20Africa%20Toolkit%20-%20Part%201%20and%202.pdf .\n\n81.\n\nChatham House, Reflections on Building More Inclusive Global Governance, 2021, \ndefault/files/2021-04/2021-04-15-reflections-building-inclusive-global-governance.pdf .\n\n-----\n\nThe World Economic Forum,\ncommitted to improving\nthe state of the world, is the\nInternational Organization for\nPublic-Private Cooperation.\n\nThe Forum engages the\nforemost political, business\nand other leaders of society\nto shape global, regional\nand industry agendas.\n\nWorld Economic Forum\n91\u201393 route de la Capite\nCH-1223 Cologny/Geneva\nSwitzerland\n\nTel.\n\n: +41 (0) 22 869 1212\nFax: +41 (0) 22 786 2744\n\n\n\n-----"]
["### a new era of generative AI for everyone the technology underpinning chatgpt will transform work and reinvent business ", "##### **welcome to ai\u2019s new inflection point** **how did we get here? | milestones in the journey to generative AI** **consume or customize: generative AI for everyone** **a look ahead at the fast-paced evolution of technology, regulation and business** **embrace the generative AI era: six adoption essentials** **the future of ai is accelerating** **glossary and references** **authors** **introduction** ", "#### welcome to ai\u2019s new inflection point chatgpt has woken up the world to the transformative potential of artificial intelligence (ai), capturing global attention and sparking a wave of creativity rarely seen before. its ability to mimic human dialogue and decision-making has given us ai\u2019s first true inflection point in public adoption. finally, everyone, everywhere can see the technology\u2019s true disruptive potential for themselves. chatgpt reached million active users after launch, making it the fastest-growing consumer application in history. a foundation model is a generic term for large models with billions of parameters. with recent advances, companies can now build specialized image- and language-generating models on top of these foundation models. large language models (llms) are both a type of generative AI and a type of foundation model. the llms behind chatgpt mark a significant turning point and milestone in artificial intelligence. two things make llms game changing. first, they\u2019ve cracked the code on language complexity. now, for the first time, machines can learn language, context and intent and be independently generative and creative. second, after being pre-trained on vast quantities of data (text, images or audio), these models can be adapted or finetuned for a wide range of tasks. this allows them to be reused or repurposed in many different ways. business leaders recognize the significance of this moment. they can see how llms and generative AI will fundamentally transform everything from business, to science, to society itself\u2014unlocking new performance frontiers. the positive impact on human creativity and productivity will be massive. consider that, across all industries, accenture found % of all working hours can be impacted by llms like . this is because language tasks account for % of the total time employees work, and % of that time can be transformed into more productive activity through augmentation and automation (see figure ). ", "#### how did we get here? **milestones in the journey** **to generative AI** **machine learning: analysis and prediction phase** marked the rapid advance of various machine learning techniques that could analyze massive amounts of online data to draw conclusions \u2013 or \u201clearn\u201d \u2013 from the results. since then, companies have viewed machine learning as an incredibly powerful field of ai for analyzing data, finding patterns, generating insights, making predictions and automating tasks at a pace and on a scale that was previously impossible. **deep learning: vision and speech phase** produced advances in ai\u2019s perception capabilities in the field of machine learning called deep learning. breakthroughs in deep learning enable the computer vision that search engines and self-driving cars use to classify and detect objects, as well as the voice recognition that allows popular ai speech assistants to respond to users in a natural way. **generative AI: enter the language-mastery phase** building on exponential increases in the size and capabilities of deep learning models, will be about language mastery. the gpt- language model, developed by openai, marks the beginning of a new phase in the abilities of language-based ai applications. models such as this will have far-reaching consequences for business, since language permeates everything an organization does day to day\u2014its institutional knowledge, communication and processes. ", "#### consume or customize: generative AI for everyone **consume or customize: generative AI for everyone** easy-to-consume generative AI applications like chatgpt, dall-e, stable diffusion and others are rapidly democratizing the technology in business and society. the effect on organizations will be profound. the ability of llms to process massive data sets allows them to potentially \u201cknow\u201d everything an organization has ever known\u2014the entire history, context, nuance and intent of a business, and its products, markets and customers. anything conveyed through language (applications, systems, documents, emails, chats, video and audio recordings) can be harnessed to drive next-level innovation, optimization and reinvention. % of global executives agree ai foundation models will enable connections across data types, revolutionizing where and how ai is used. we\u2019re at a phase in the adoption cycle when most organizations are starting to experiment by consuming foundation models \u201coff the shelf.\u201d however, the biggest value for many will come when they customize or fine tune models using their own data to address their unique needs: consume generative AI and llm applications are ready to **consume** and easy to access. companies can consume them through apis and tailor them, to a small degree, for their own use cases through prompt engineering techniques such as prompt tuning and prefix learning. customize but most companies will need to **customize** models, by fine-tuning them with their own data, to make them widely usable and valuable. this will allow the models to support specific downstream tasks all the way across the business. the effect will be to increase a company\u2019s efficacy in using ai to unlock new performance frontiers\u2014elevating employee capabilities, delighting customers, introducing new business models and boosting responsiveness to signals of change. companies will use these models to **reinvent the** **way work is done** . every role in every enterprise has the potential to be reinvented, as humans working with ai co-pilots becomes the norm, dramatically amplifying what people can achieve. in any given job, some tasks will be automated, some will be assisted, and some will be unaffected by the technology. there will also be a large number of new tasks for humans to perform, such as ensuring the accurate and responsible use of new ai-powered systems. consider the impact in these key functions: advising. ai models will become an ever-present co-pilot for every worker, boosting productivity by putting new kinds of hyper-personalized intelligence into human hands. examples include customer support, sales enablement, human resources, medical and scientific research, corporate strategy and competitive intelligence. large language models could be useful in tackling the roughly % of customer service communication that is not straightforward and can benefit from a conversational, powerful and intelligent bot, understanding a customer\u2019s intent, formulate answers on its own and improve the accuracy and quality of answers. creating. generative AI will become an essential creative partner for people, revealing new ways to reach and appeal to audiences and bringing unprecedented speed and innovation in areas like production design, design research, visual identity, naming, copy generation and testing, and realtime personalization. companies are turning to state-of-the-art artificial intelligence systems like dall\u00b7e, midjourney and stable diffusion for their social media visual content generation outreach. dall\u00b7e, for example, creates realistic images and art based on text descriptions and can process up to billion parameters when transforming words into pictures. images created can then be shared on instagram and twitter. coding. software coders will use generative AI to significantly boost productivity \u2014 rapidly converting one programming language to another, mastering programming tools and methods, automating code writing, predicting and pre-empting problems, and managing system documentation. accenture is piloting the use of openai llms to enhance developer productivity by automatically generating documentation \u2013 for example, sap configuration rationale and functional or technical specs. the solution enables users to submit requests through a teams chat as they work. correctly packaged documents are then returned at speed \u2014 a great example of how specific tasks, rather than entire jobs, will be augmented and automated. automating. generative AI\u2019s sophisticated understanding of historical context, next best actions, summarization capabilities, and predictive intelligence will catalyze a new era of hyper-efficiency and hyper-personalization in both the back and front office\u2014taking business process automation to a transformative new level. one multinational bank is using generative AI and llms to transform how it manages volumes of post-trade processing emails\u2014automatically drafting messages with recommended actions and routing them to the recipient. the result is less manual effort and smoother interactions with customers. protecting. in time, generative AI will support enterprise governance and information security, protecting against fraud, improving regulatory compliance, and proactively identifying risk by drawing cross-domain connections and inferences both within and outside the organization. in strategic cyber defense, llms could offer useful capabilities, such as explaining malware and quickly classifying websites. in the short term, however, organizations can expect criminals to capitalize on generative AI\u2019s capabilities to generate malicious code or write the perfect phishing email. ", "#### a look ahead at the fast-paced evolution of technology, regulation and business **a look ahead at the fast-paced evolution of technology, regulation and business** moments like this don\u2019t come around often. will see outsized investment in generative AI, llms and foundation models. what\u2019s unique about this evolution is that the technology, regulation, and business adoption are all accelerating exponentially at the same time. in previous innovation curves, the technology typically outpaced both adoption and regulation. **the technology stack** the complex technology underpinning generative AI is expected to evolve rapidly at each layer. this has broad business implications. consider that the amount of compute needed to train the largest ai models has grown exponentially \u2013 now doubling between every . to months, according to various reports. cost and carbon emissions are therefore central considerations in adopting energy-intensive generative AI. \u201cthe hottest new programming platform is the napkin.\u201d daugherty, accenture group chief executive & chief technology officer referring to the use of openai to generate a working website from a napkin drawing **figure :** each layer of the generative AI tech stack will rapidly evolve **applications:** generative AI and llms will be increasingly accessible to users in the cloud via apis and by being embedded directly into other applications. companies will consume them as they are or will customize and fine-tune them with proprietary data. **fine-tuning:** the importance of model fine-tuning will create demand for a multidisciplinary set of skills spanning software engineering, psychology, linguistics, art history, literature and library science. **foundation models:** the market will rapidly mature and diversify as more pre-trained models emerge. new model designs will offer more choices for balancing size, transparency, versatility and performance. **data:** improving the maturity of the enterprise data lifecycle will become a prerequisite for success \u2013 requiring mastery of new data, new data types and immense volumes. generative AI features within modern data platforms will emerge, enhancing adoption at scale. **infrastructure:** cloud infrastructure will be essential for deploying generative AI while managing costs and carbon emissions. data centers will need retrofitting. new chipset architectures, hardware innovations, and efficient algorithms will also play a critical role. **the risk and regulatory environment** companies will have thousands of ways to apply generative AI and foundation models to maximize efficiency and drive competitive advantage. understandably, they\u2019ll want to get started as soon as possible. but an enterprisewide strategy needs to account for all the variants of ai and associated technologies they intend to use, not only generative AI and large language models. chatgpt raises important questions about the responsible use of ai. the speed of technology evolution and adoption requires companies to pay close attention to any legal, ethical and reputational risks they may be incurring. it\u2019s critical that generative AI technologies, including chatgpt, are responsible and compliant by design, and that models and applications do not create unacceptable risk for the business. accenture was a pioneer in the responsible use of technology including the responsible use of ai in its code of business ethics from . responsible ai is the practice of designing, building and deploying ai in accordance with clear principles to empower businesses, respect people, and benefit society \u2014 allowing companies to engender trust in ai and to scale ai with confidence. ai systems need to be \u201craised\u201d with a diverse and inclusive set of inputs so that they reflect the broader business and societal norms of responsibility, fairness and transparency. when ai is designed and put into practice within an ethical framework, it accelerates the potential for responsible colative intelligence, where human ingenuity converges with intelligent technology. this creates a foundation for trust with consumers, the workforce, and society, and can boost business performance and unlock new sources of growth. **figure :** key risk and regulatory questions for generative AI **intellectual property:** how will the business protect its own ip? and how will it prevent the inadvertent breach of third-party copyright in using pre-trained foundation models? **data privacy and security:** how will upcoming laws like the eu ai act be incorporated in the way data is handled, processed, protected, secured and used? **discrimination:** is the company using or creating tools that need to factor in anti-discrimination or anti-bias considerations? **product liability:** what health and safety mechanisms need to be put in place before a generative AI-based product is taken to market? **trust:** what level of transparency should be provided to consumers and employees? how can the business ensure the accuracy of generative AI outputs and maintain user confidence? **identity:** when establishing proof-of-personhood depends on voice or facial recognition, how will verification methods be enhanced and improved? what will be the consequences of its misuse? **the scale of adoption in business** companies must reinvent work to find a path to generative AI value. business leaders must lead the change, starting now, in job redesign, task redesign and reskilling people. ultimately, every role in an enterprise has the potential to be reinvented, once \u2019s jobs are decomposed into tasks that can be automated or assisted and reimagined for a new future of human + machine work. generative AI will disrupt work as we know it , introducing a new dimension of human and ai colation in which most workers will have a \u201ccopilot,\u201d radically changing how work is done and what work is done. nearly every job will be impacted \u2013 some will be eliminated, most will be transformed, and many new jobs will be created. organizations that take steps now to decompose jobs into tasks, and invest in training people to work differently, alongside machines, will define new performance frontiers and have a big leg up on less imaginative competitors. nearly in organizations plan to use chatgpt for learning purposes and over half are planning pilot cases in . over in want to make a large investment. **figure :** generative AI will transform work across industries **work time distribution by industry** **and potential ai impact** based on their employment levels in the us in banking insurance software & platforms capital markets energy communications & media retail industry average health public service aerospace & defense automotive high tech travel utilities life sciences industrial consumer goods & services chemicals natural resources % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % higher potential for higher potential for automation augmentation lower potential for augmentation or non-language automation tasks % % % % % % % % % % % % % % of working hours across industries can be impacted by large language models (llms) why is this the case? language tasks account for % of total worked time in the us. of the overall share of language tasks, % have high potential to be automated or augmented by llms. % % % % % % % % % % % % % % % % % % % % **source:** accenture research based on analysis of occupational information network (o*net), us dept. of ; of statistics. % % **notes:** we manually identified tasks related to language (out of included in bls), which were linked to industries using their share in each occupation and the occupations\u2019 employment level in each industry. tasks with higher potential for automation can be transformed by llms with reduced involvement from a human worker. tasks with higher potential for augmentation are those in which llms would need more involvement from human workers. % % % % % % % % % % % % % % % % % % % ", "#### embrace the generative AI era: six adoption essentials dive in, with a business-driven mindset take a peoplefirst approach get your proprietary data ready invest in a sustainable tech foundation accelerate ecosystem innovation level-up your responsible ai **dive in, with a business-driven mindset** even when new innovations have obvious advantages, diffusing them across an organization can be challenging, especially if the innovation is disruptive to current ways of working. by experimenting with generative AI capabilities, companies will develop the early successes, change agents and opinion leaders needed to boost acceptance and spread the innovation further, kick-starting the transformation and reskilling agenda. organizations must take a dual approach to experimentation. one, focused on low-hanging fruit opportunities using consumable models and applications to realize quick returns. the other, focused on reinvention of business, customer engagement and prodicts and services using models that are customized with the organization\u2019s data. a business-driven mindset is key to define, and successfully deliver on, the business case. as they experiment and explore reinvention opportunities, they\u2019ll reap tangible value while learning more about which types of ai are most suited to different use cases, since the level of investment and sophistication required will differ based on the use case. they\u2019ll also be able to test and improve their approaches to data privacy, model accuracy, bias and fairness with care, and learn when \u201chuman in the loop\u201d safeguards are necessary. % of global executives agree ai foundation models will play an important role in their organizations\u2019 strategies in . **a bank uses enhanced search to equip** **employees with the right information** as part of its innovation plan, a large european banking group saw an opportunity to transform its knowledge base, empower its people with access to the right information, and advance its goal of becoming a data-driven bank. using \u2019s azure platform and a llm to search electronic documents, users can get quick answers to their questions \u2014 saving time while improving accuracy and compliance. the project, which included employee upskilling, is the first of four that will apply generative AI to the areas of contract management, conversational reporting and ticket classification. **figure : generative AI will transform work across every job category** **take a people-first approach** success with generative AI requires an equal attention on people and training as it does on technology. companies should therefore dramatically ramp up investment in talent to address two distinct challenges: creating ai and using ai. this means both building talent in technical competencies like ai engineering and enterprise architecture and training people across the organization to work effectively with ai-infused processes. in our analysis across job categories, for example, we found that llms will impact every category, ranging from % of a workday at the low end to % at the high end. more than half of working hours in of the occupations can be transformed by llms. **work time distribution by major** **occupation and potential ai impact** based on their employment levels in the us in % office and administrative support sales and related computer and mathematical business and financial operations arts, design, entertainment, sports, and media life, physical, and social science architecture and engineering legal occcupation average management personal care and service healthcare practitioners and technical community and social service healthcare support protective service educational instruction and library food preparation and serving related transportation and material moving construction and extraction installation, maintenance, and repair farming, fishing, and forestry production building and grounds cleaning and maintenance % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % higher potential for higher potential for automation augmentation lower potential for augmentation or non-language automation tasks % % % % % % % % % % in out of occupation groups, generative AI can affect more than half of all hours worked % % % % % % % % % % % % % % % % % % **source:** accenture research based on analysis of occupational information network (o*net), us dept. of ; of statistics. % % % % % % % **notes:** we manually identified tasks related to language (out of included in bls), which were linked to industries using their share in each occupation and the occupations\u2019 employment level in each job category. tasks with higher potential for automation can be transformed by llms with reduced involvement from a human worker. tasks with higher potential for augmentation are those in which llms would need more involvement from human workers. % % % % % % % % % % % % % % % % % % % % % in fact, independent economic research indicates that companies are significantly underinvesting in helping workers keep up with advances in ai, which require more cognitively complex and judgment-based tasks. even domain experts who understand how to apply data in the real world (a doctor interpreting health data, for example) will need enough technical knowledge of how these models work to have confidence in using them as a \u201cworkmate.\u201d there will also be entirely new roles to recruit, including linguistics experts, ai quality controllers, ai editors, and prompt engineers. in areas where generative AI shows most promise, companies should start by decomposing existing jobs into underlying bundles of tasks. then assess the extent to which generative AI might affect each task \u2014 fully automated, augmented, or unaffected. **figure :** reinventing a customer service job, task by task to assess how specific jobs will be reinvented with ai, an accenture analysis decomposed one customer service job into ** component tasks** . we found: tasks would continue to be performed primarily by humans, with low potential for automation or augmentation. ", "## tasks could be fully automated \u2014 such as gathering, classifying, and summarizing information on why a customer is contacting the company. ", "## tasks could be augmented to help humans work more effectively \u2014 such as using an ai summary to provide a rapid solution with a human touch. ", "## importantly, new job tasks might also be needed to ensure the safe, accurate and responsible use of ai in customer service settings, such as providing unbiased information on products and pricing. **get your proprietary data ready** customizing foundation models will require access to domain-specific organizational data, semantics, knowledge, and methodologies. in the pre-generative AI era, companies could still get value from ai without having modernized their data architecture and estate by taking a use-case centric approach to ai. that\u2019s no longer the case. foundation models need vast amounts of curated data to learn and that makes solving the data challenge an urgent priority for every business. companies need a strategic and disciplined approach to acquiring, growing, refining, safeguarding and deploying data. specifically, they need a modern enterprise data platform built on cloud with a trusted, reusable set of data products. because these platforms are cross-functional, with enterprise-grade analytics and data housed in cloudbased warehouses or data lakes, data is able to break free from organizational silos and democratized for use across an organization. all business data can then be analyzed together in one place or through a distributed computing strategy, such as a data mesh. read more on the practices data-mature companies are using to maximize enterprise data value: a new dawn for dormant data: unleash the intrinsic value of /insights/cloud/cloud-data-value) [data with a strong digital core on cloud. **invest in a sustainable tech foundation** companies need to consider whether they have the right technical infrastructure, architecture, operating model and governance structure to meet the high compute demands of llms and generative AI, while keeping a close eye on cost and sustainable energy consumption. they\u2019ll need ways to assess the cost and benefit of using these technologies versus other ai or analytical approaches that might be better suited to particular use cases, while also being several times less expensive. as the use of ai increases, so will the carbon emissions produced by the underlying infrastructure. companies need a robust green software development framework that considers energy efficiency and material emissions at all stages of the software development lifecycle. ai can also play a broader role in making business more sustainable and achieving esg goals. of the companies we surveyed that successfully reduced emissions in production and operations, % used ai to do it. **accelerate ecosystem innovation** creating a foundation model can be a complex, compute-intensive and costly exercise. and for all but the very largest global companies, doing it entirely on their own will be beyond their means and capabilities. the good news is that there is a burgeoning ecosystem to call on, with substantial investments by cloud hyperscalers, big tech players, and start-ups. global investment in ai startups and scale-ups is estimated to exceed $ billion in alone. these partners bring best practices honed over , and can provide valuable insights into using foundation models efficiently and effectively in specific use cases. having the right network of partners\u2014including technology companies, professional services firms and academic institutions\u2014will be key to navigating rapid change. **level-up your responsible ai** the rapid adoption of generative AI brings fresh urgency to the need for every organization to have a robust responsible ai compliance regime in place. this includes controls for assessing the potential risk of generative AI use cases at the design stage and a means to embed responsible ai approaches throughout the business. accenture\u2019s research suggests most companies still have a long way to go. our survey of senior executives globally revealed widespread recognition of the importance of responsible ai and ai regulation. but only percent of organisations felt they had a fully robust responsible ai foundation in place. an organization\u2019s responsible ai principles should be defined and led from the top and translated into an effective governance structure for risk management and compliance, both with organizational principles and policies and applicable laws and regulations. responsible ai must be ceo-led, beginning with a focus on training and awareness and then expanding to focus on execution and compliance. accenture was one of the first to take this approach to responsible , with a ceo-led agenda, and now a formal compliance program. our own experience shows that a principlesdriven compliance approach provides guardrails while being flexible enough to evolve with the fast pace of changing technology, ensuring companies aren\u2019t constantly playing \u201ccatch up.\u201d to be responsible by design, organizations need to move from a reactive compliance strategy to the proactive development of mature responsible ai capabilities through a framework that includes principles and governance; risk, policy and control; technology and enablers and culture and training. ", "#### the future of ai is accelerating **this is a pivotal moment.** for , generative AI and foundation models have been quietly revolutionizing the way we think about machine intelligence. now, thanks to chatgpt, the whole world has woken up to the possibilities this creates. while artificial general intelligence (agi) remains a distant prospect, the speed of development continues to be breathtaking. we\u2019re at the start of an incredibly exciting era that will fundamentally transform the way information is accessed, content is created, customer needs are served, and businesses are run. embedded into the enterprise digital core, generative AI, llms, and foundation models will optimize tasks, augment human capabilities, and open up new avenues for growth. in the process, these technologies will create an entirely new language for enterprise reinvention. businesses are right to be optimistic about the potential of generative AI to radically change how work get done and what services and products they can create. they also need to be realistic about the challenges that come with profoundly rethinking how the organization works, with implications for it, organization, culture, and responsibility by design. companies need to invest as much in evolving operations and training people as they do in technology. radically rethinking how work gets done, and helping people keep up with technologydriven change, will be two of the most important factors in realizing the full potential of this stepchange in ai technology. **now\u2019s the time for companies to use** **breakthrough advances in ai to set new** **performance frontiers\u2014redefining themselves** **and the industries in which they operate.** ", "###### about accenture accenture is a leading global professional services company that helps the world\u2019s leading businesses, governments and other organizations build their digital core, optimize their operations, accelerate revenue growth and enhance citizen services\u2014creating tangible value at speed and scale. we are a talent and innovation led company with , people serving clients in more than countries. technology is at the core of change , and we are one of the world\u2019s leaders in helping drive that change, with strong ecosystem relationships. we combine our strength in technology with unmatched industry experience, functional expertise and global delivery capability. we are uniquely able to deliver tangible outcomes because of our broad range of services, solutions and assets across strategy & consulting, technology, operations, industry x and accenture song. these capabilities, together with our culture of shared success and commitment to creating \u00b0 value, enable us to help our clients succeed and build trusted, lasting relationships. we measure our success by the \u00b0 value we create for our clients, each other, our shareholders, partners and communities. visit us at . copyright \u00a9 accenture. all rights reserved. accenture and its logo are registered trademarks of accenture ", "### adobe adobe ", "## \u2630 ", "# adobe generative AI user guidelines last updated: these generative AI user guidelines (\u201cguidelines\u201d) govern your use of adobe\u2019s generative AI features. in addition, if your agreement with adobe is governed by the general terms of use located at adobe.com/go/terms , then your use of these generative AI features is also governed by the adobe generative AI additional terms located at adobe.com/go/adobe-gen-ai-addl-terms , which are incorporated by reference into these guidelines. these guidelines have two goals: to maintain the high quality of content generated using adobe\u2019s suite of products and services, and to keep our products and services accessible to our users in an engaging and trustworthy way that fosters creativity and productivity. ", "## . no ai/ml training when using our generative AI features, you agree you will use them only for your creative and productivity work product and not to train artificial intelligence or machine learning models. this means you must not, and must not allow third parties to, use any content, data, output or other information received or derived from any generative AI features, including any firefly outputs, to directly or indirectly create, train, test, or otherwise improve any machine learning algorithms or artificial intelligence systems, including any architectures, models, or weights. ", "## . be respectful and safe do not use adobe\u2019s generative AI features to attempt to create, upload, or share abusive, or illegal, or confidential content, or content that violates the rights of others. this includes, but is not limited to, the following: pornographic material or explicit nudity hateful or highly offensive content that attacks or dehumanizes a group based on race, ethnicity, national origin, religion, serious disease or disability, gender, age, or sexual orientation graphic violence or the promotion glorification or threats of violence ", "### adobe self-harm or the promotion of self-harm adobe depictions of nude minors or minors in a sexual manner promotion of terrorism or violent extremism dissemination of misleading, fraudulent, or deceptive content that could lead to real-world harm personal or private information of others in violation of their privacy or data protection rights your prompts and the results generated by generative AI features in creative cloud products may be reviewed through both automated (e.g., machine learning) and manual methods for abuse prevention and content filtering purposes. please note that we may report any material exploiting minors to the national center of missing & exploited children (ncmec). if at any time you believe someone has violated these guidelines, please report it by contacting us at abuse@adobe.com . ", "## . be authentic we disable accounts that engage in behavior that is deceptive or harmful, including: using fake, misleading, or inaccurate information in your profile impersonating other people or entities using unauthorized automated or scripting processes (such as bulk or automated uploading of content through a script) engaging in schemes or third-party services to boost account engagement (artificially increasing the number of appreciations, views, or other metrics) ", "## . be respectful of third-party rights using adobe\u2019s generative AI features to create content that violates third-party copyright, trademark, privacy, or other rights is prohibited. this may include, but is not limited to, entering text prompts to generate a third-party brand logo, uploading an input or reference image that includes a third party\u2019s copyrighted content, generating text that plagiarizes third-party content, or using a third party\u2019s personal information in violation of their privacy or data protection rights. if you\u2019re not sure whether your content violates the rights of a third party, you may want to reach out to an attorney or consult publicly available reference materials at the following: u.s. copyright office  trademark office lumen you can do that here: adobe intellectual property removal policy adobe located at  . if you have a contract or other dispute with an adobe user regarding content they have uploaded to our products and services, please resolve the issue directly with the user. we can\u2019t moderate contract, employment, or other disputes between our users and the public. ", "## . use your judgment generated outputs sometimes may be inaccurate or misleading, or otherwise reflect content that does not represent adobe\u2019s views. do not use generative AI features to seek legal, medical, financial, or other kinds of professional advice or any opinions, judgments, or recommendations without conducting your own independent consultation or research. generative AI features cannot replace advice provided by a qualified professional and do not form any such relationship (e.g., attorney-client relationship). ", "## . content credentials adobe may attach or publish content credentials for content created with generative AI features to let people know it was generated with ai. learn more about content credentials . ", "## . commercial use in general, you may use outputs from generative AI features commercially. however, if adobe designates in the product or elsewhere that a beta version of a generative AI feature cannot be used commercially, then the generated outputs from that beta feature are for personal use only and cannot be used commercially. ", "## . more information we may take action on your adobe account if we discover content or behavior that violates these guidelines. for more information about what you can and can\u2019t do while using adobe\u2019s generative AI features, please refer to your agreement with adobe. shop for for business for education for mobile adobe adobe experience cloud support resources adobe account adobe featured products adobe acrobat ) [adobe /express/?promoid=zgfsyv&mv=other) [photoshop /products/illustrator/free-trial-download.html) change region \u2228 copyright \u00a9 adobe. all rights reserved. / [) / [terms of use / cookie preferences / do not sell or share my personal information / [/privacy/opt-out.html#interest-based-ads) ", "# acceptable use of generative AI tools [sample policy] **purpose** publicly available applications driven by generative AI (generative AI), such as chatbots (chatgpt, \u2019s bard, ) or image generators (dall-e , midjourney) are impressive and widely popular. but while these content-generating tools may offer attractive opportunities to streamline work functions and increase our efficiency, they come with serious security, accuracy, and intellectual property risks. this policy highlights the unique issues raised by generative AI, helps employees understand the guidelines for its acceptable use, and protects the company\u2019s confidential or sensitive information, trade secrets, intellectual property, workplace culture, commitment to diversity, and brand. **scope** this policy applies to the use of any third-party or publicly available generative AI tools, including chatgpt, bard, dall-e, midjourney, and other similar applications that mimic human intelligence to generate answers, work product, or perform certain tasks. (this policy does not cover other generative AI or ai tools formally approved or installed for your use by the company.) _optional: list any generative AI tools that you have approved or installed._ **guidelines** do: - understand that generative AI tools may be useful but are **not a substitute** for human judgment and creativity. - understand that many generative AI tools are prone to \u201challucinations,\u201d false answers or information, or information that is stale, and therefore **responses must always be carefully verified by a human** . - treat every bit of information you provide to an generative AI tool as if it will **go viral on the internet** , attributed to you or the company, regardless of the settings you have selected within the tool (or the assurances made by its creators). - inform your supervisor **when you have used a generative AI tool** to help perform a task. **\u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022** _this material is provided for informational purposes only. it is not intended to constitute legal advice, nor does it create a_ _client lawyer relationship between and any recipient. recipients should consult with counsel before_ _taking any actions based on the information contained within this material._ - verify that any response from an generative AI tool that you intend to rely on or use is **accurate, appropriate,** **not biased, not a violation of any other individual or entity\u2019s intellectual property or privacy, and** **consistent** with company policies and applicable laws. do not: - do not use generative AI tools to make or help you make **employment decisions** about applicants or employees, including recruitment, hiring, retention, promotions, transfers, performance monitoring, discipline, demotion, or terminations. - do not upload or input any **confidential** , **proprietary** , or **sensitive** company information into any generative AI tool. examples include passwords and other credentials, protected health information, personnel material, information from documents marked confidential, sensitive, or proprietary, or any other nonpublic company information that might be of use to competitors or harmful to the company if disclosed. this may breach your or the company\u2019s obligations to keep certain information confidential and secure, risks widespread disclosure, and may cause the company\u2019s rights to that information to be challenged. - do not upload or input any **personal information** (names, addresses, likenesses, etc.) about any person into any generative AI tool. - do not **represent work** generated by a generative AI tool as being your own original work. - do not **integrate any generative AI tool** with internal company software without first receiving specific written permission from your supervisor and the it department. - [ _if applicable_ ] do not use generative AI tools other than those on the **approved list** from the it department. malicious chatbots can be designed to steal or convince you to divulge information. **violations** violating this policy may result in disciplinary action, up to and including immediate termination, and could result in legal action. if you are concerned that someone has violated this policy, report this behavior to your supervisor or any member of human resources. **disclaimer** nothing in this policy is designed or intended to interfere with, restrain, or prevent employee communications regarding wages, hours, or other terms and conditions of employment or any other rights protected by . **\u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022** _this material is provided for informational purposes only. it is not intended to constitute legal advice, nor does it create a_ _client lawyer relationship between and any recipient. recipients should consult with counsel before_ _taking any actions based on the information contained within this material._ **note:** before implementing this policy, coordinate with your fisher phillips attorney to determine if you need to integrate this policy with your specific circumstances and any possible related policies, such as: - confidentiality and trade secrets - data security - acceptable use of computers and electronic media - equal employment opportunity - discrimination and harassment - workplace code of ethics if your company is regulated by hipaa/hitech, glba, or fcra, or you are federal contractor subject to affirmative action laws, contact your fisher phillips attorney to determine the extent to which you need to integrate this policy into your existing policies. additional customizations may be also warranted for certain industries and/or workplaces. **\u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022** _this material is provided for informational purposes only. it is not intended to constitute legal advice, nor does it create a_ _client lawyer relationship between and any recipient. recipients should consult with counsel before_ _taking any actions based on the information contained within this material._ ", "## gauging the impact ofgenerative ai on government presented by underwritten by ", "###### % the benefits outweigh the risks ", "###### % the risks outweigh the benefits ", "###### % don\u2019t know base: gauging the impact of generative AI on government top concerns on generative AI risks at organization all respondents + agency type all federal civilian defense/intel lack of controls to ensure information is generated ethically/responsibly lack of ability to verify/explain the generated output of information elevated risk of security and privacy violations lack of employee training to use generative AI responsibly lack of transparency on the quality of input information risk of not keeping pace with similar organizations in leveraging generative AI % % % % % % base: % % % % % % % % % % % % base: base: gauging the impact of generative AI on government top concerns for the public\u2019s use of generative AI all respondents + agency type all federal civilian defense/intel potential to abuse/distort gov-generated content in the public domain potential to submit fake/fraudulent info to federal agencies potential to accelerate cybersecurity threats potential to generate misinformation to compromise national security potential to overwhelm/distort the public comment process potential of generative AI to compromise national infrastructure % % % % % % base: % % % % % % % % % % % % base: base: gauging the impact of generative AI on government establishment of team/office to develop policies agency type established an enterprise-level team or office charged with developing ai policies and resources to support business unit ai initiatives. federal civilian defense/intel % yes % no % don\u2019t know % yes % no % don\u2019t know base: base: gauging the impact of generative AI on government establishment of team/office to develop policies all respondents of the % of all respondents who answered no, the percent who expect a team will be established in the future: of the % of respondents whose agencies had not yet established an enterprise-level ai team or office, in expect their agency will establish one in . % % % % % don\u2019t expect such a team will be established base: % don\u2019t know gauging the impact of generative AI on government policies or guidelines for employee use of generative AI all respondents organization issued preliminary governance policies or guidelines for how employees may and may not use generative AI tools for work. % while in respondents say their agency has issued preliminary guidance on ai use, only in % of those cases do those policies prohibit employees from using generative AI tools for work. yes no don\u2019t know % % % % % don\u2019t know yes, policies prohibit no, policies don\u2019t prohibit base: base: gauging the impact of generative AI on government employee use of generative AI for their work all respondents respondents aware of instances within the organization where employees are experimenting with generative AI tools for their work. ", "#### % employees are experimenting with generative AI at work. ", "#### % no % don\u2019t know base: gauging the impact of generative AI on government ", "# generative AI & agency operations business operations/workflow all respondents stage in planning to assess potential positive or negative impact % % % % % % not planning started don\u2019t know % % % % % % stage in planning or implementing one or more applications confidence to improve ability to deliver greater value % % % % not confident slightly somewhat confident % % % % confidence in workflow cost savings base: gauging the impact of generative AI on government mission intelligence/ execution all respondents stage in planning to assess potential positive or negative impact % % % % % % not planning started don\u2019t know % % % % % % stage in planning or implementing one or more applications confidence to improve ability to deliver greater value % % % % not confident slightly somewhat confident % % % % confidence in workflow cost savings base: gauging the impact of generative AI on government citizen services/accessibility all respondents stage in planning to assess potential positive or negative impact % % % % % % not planning started don\u2019t know % % % % % % stage in planning or implementing one or more applications confidence to improve ability to deliver greater value % % % % not confident slightly somewhat confident % % % % confidence in workflow cost savings base: gauging the impact of generative AI on government it development/cybersecurity all respondents stage in planning to assess potential positive or negative impact % % % % % % not planning started don\u2019t know % % % % % % stage in planning or implementing one or more applications confidence to improve ability to deliver greater value % % % % not confident slightly somewhat confident % % % % confidence in workflow cost savings base: gauging the impact of generative AI on government data analytics/insights all respondents stage in planning to assess potential positive or negative impact % % % % % % not planning started don\u2019t know % % % % % % stage in planning or implementing one or more applications confidence to improve ability to deliver greater value % % % % not confident slightly somewhat confident % % % % confidence in workflow cost savings base: gauging the impact of generative AI on government case management/workflow all respondents stage in planning to assess potential positive or negative impact % % % % % % not planning started don\u2019t know % % % % % % stage in planning or implementing one or more applications confidence to improve ability to deliver greater value % % % % not confident slightly somewhat confident % % % % confidence in workflow cost savings base: gauging the impact of generative AI on government oversight planning/reporting all respondents stage in planning to assess potential positive or negative impact % % % % % % not planning started don\u2019t know % % % % % % stage in planning or implementing one or more applications confidence to improve ability to deliver greater value % % % % not confident slightly somewhat confident % % % % confidence in workflow cost savings base: gauging the impact of generative AI on government ", "# divergent perspectives: business vs it executives confidence in generative AI to deliver greater value job titles confidence that generative AI will deliver greater value for the following use cases or functions: not confident slightly somewhat confident add value in improving business operations and workflow... business execs it execs business execs it execs % % % % % % % % add value in improving mission intelligence and execution... % % % % % % business base: | it base: gauging the impact of generative AI on government % % confidence in generative AI for cost savings job titles confidence that generative AI will achieve workflow cost savings in the following use cases or functions: not confident slightly somewhat confident save costs in improving business operations and workflow... business execs it execs business execs it execs % % % % % % % % save costs in improving mission intelligence and execution... % % % % % business base: | it base: gauging the impact of generative AI on government % % % priorities in implementation job titles business and it executives who are implementing one or or more generative AI applications in . business executives it executives data analytics business operations % % data analytics business operations it development / cybersecurity case management % % it development / cybersecurity case management business operations it development / cybersecurity % % business operations it development / cybersecurity citizen services / accessibility mission intelligence / execution % % citizen services / accessibility mission intelligence / execution case management oversight planning / reporting % % case management oversight planning / reporting oversight planning / reporting citizen services / accessibility % % oversight planning / reporting citizen services / accessibility mission intelligence / execution data analytics % % mission intelligence / execution data analytics business base: | it base: gauging the impact of generative AI on government ", "# generative AI & workforce potential impact of generative AI on employees all respondents respondents whose organization assessed the potential impact of generative AI on employees. ", "#### % ", "##### no ", "#### % ", "##### yes % don\u2019t know base: gauging the impact of generative AI on government priority on recruitment or upskilling all respondents priority that agency leadership is placing on recruiting or upskilling talent to support the adoption of or response to generative AI. critical important moderate priority low priority not a priority scale of to , where is \u201cnot a priority\u201d, and is \u201ccritical. \u201d in government executives polled said their agency leaders view \u201crecruiting or upskilling talent to support generative AI\u201d as a \u201ccritical or important\u201d priority. % % % % % base: gauging the impact of generative AI on government greatest concerns for employees all respondents & job titles where respondents see generative AI presenting the greatest employee concerns. all business executives it executives lack of controls to ensure information is generated ethically/responsibly lack of ability to verify/explain the generated output of information elevated risk of security and privacy violations lack of employee training to use generative AI responsibly lack of transparency on the quality of input information % % % % % base: % % % % % % % % % % base: base: % of all respondents in their open response indicated that it removes aspects of creativty. gauging the impact of generative AI on government greatest opportunities for employees all respondents & job titles where respondents see generative AI presenting the greatest opportunities for employees. all business executives it executives ability to give employees added technical support (e.g. a co-pilot) ability to reduce the time required to complete work processes ability to free up employee tasks to produce more valuable work ability to reduce backlogs ability to serve the public better % % % % % base: % % % % % % % % % % base: base: % of all respondents in their open response indicated that they do not see ai helping at all. gauging the impact of generative AI on government conclusions while the emergence of generative AI presents a variety of far-reaching strategic issues for federal agencies, the sentiments of mission, program and it leaders in this survey suggest several near-term planning priorities: prepare for a faster pace of change generative AI represents more than smarter it. it is a new accelerative force, enhancing but also disrupting how organizations work. it will require more responsive cross-functional leadership attention and a commitment to the art of change management. prioritize use cases agency leaders appear poised to apply generative AI initially to business operations, citizen services and it security, working from the inside out. however, they should also identify specific use cases where ai-supported assistance can accelerate legal, financial and ethical oversight, support public interaction, and respond to cybersecurity risks in the face of talent shortages. establish flexible governance machines, as much as humans, now drive the pace of generative AI development, making it difficult to predict how the benefits and risks will unfold in the workplace and for the public. it will be essential to develop clear safeguards for ai\u2019s use, but also greater flexibility to adjust policies iteratively as ai applications evolve. commit to training while agency leaders must focus on understanding and controlling how generative AI will behave, they must also recognize that ai\u2019s impact will depend on how employees use ai. that will demand a new commitment to ongoing training. it will also require a more significant commitment to sharing ai-driven outcomes with government and industry partners. create environments for experimentation the combination of optimism about generative AI\u2019s potential and concerns about its risks suggests that agencies will be best served by creating virtual environments to foster experimentation. allowing a more comprehensive range of employees to experience generative AI\u2019s potential will help agencies learn faster and address lingering worries about job security and satisfaction. capitalize on shared resources federal leaders are at the center of a grand experiment in how generative AI will assist and shape the workplace. with developments unfolding so quickly, it will be essential to tap the knowledge and expertise of the leading ai developers, as well as guidance emerging within the federal government, such as nist\u2019s ai risk management framework and resources assembled by the national ai initiative. gauging the impact of generative AI on government fedscoop is the leading tech media brand in the federal government market. with more than . million unique engagements and , newsletter subscribers, fedscoop gathers top leaders from , federal agencies, academia and the tech industry to discuss ways technology can improve government and identify ways to achieve common goals. with our website, newsletter and events, we\u2019ve become the community\u2019s go-to platform for education and collaboration. contact wyatt kash senior vice president content strategy scoop news group washington, d.c. .. wyatt.kash@scoopnewsgroup.com this research report was produced by scoop news group for fedscoop and underwritten by . ", "# guidance regarding use of ", "# generative AI tools for open source ", "# software development we have received numerous questions from our project communities about contributing ai-generated code to projects. open source software has thrived for based on the merits of each technical contribution that is openly contributed to and reviewed by community peers. development and review of code generated by ai tools should be treated no differently. code or other content generated in whole or in part using ai tools can be contributed to projects. however, there are some unique considerations related to ai generated content that developers should factor into their contributions. . contributors should ensure that the terms and conditions of the generative AI project\u2019s intellectual property policies, or the open source definition . . if any pre-existing copyrighted materials (including pre-existing open source code) authored or owned by third parties are included in the ai tool\u2019s output, prior to contributing such output to the project, the contributor should confirm that they have have permission from the third party owners\u2013such as the form of an open source license or public domain declaration that complies with the project\u2019s licensing policies\u2013to use and modify such pre-existing materials and contribute them to the project. additionally, the contributor should provide notice and attribution of such third party rights, along with information about the applicable license terms, with their contribution. some tools provide features that can assist contributors. for example, some tools provide a feature that suppresses responses that are similar to third party materials in the ai tool\u2019s output, or a feature that flags similarity between copyrighted training data or other materials owned by third parties and the ai tool\u2019s output and provides information about the licensing terms that apply to such third party materials. individual projects may develop their own project-specific guidance and recommendations regarding ai-generated content. similarly, organizations that employ open source developers may have more stringent guidelines related to use of ai for software development. contributors should comply with their employer\u2019s policies when contributing. ", "## stay connected with first name last name email* by submitting this form you are consenting to receive marketing emails about news, events, and training from . you can unsubscribe at any time by following the \u201csubscription center\u201d link included within such communications. for information on our privacy practices and commitment to protecting your privacy, please review our privacy /legal/privacy-policy) . we do not sell your contact information to third parties. protected by recaptcha [/en/policies/privacy/) - [terms subscribe **projects** **newsroom** about provides a neutral, trusted hub for developers to code, manage, and scale open technology projects. about the /about) [about/leadership) [) **lf research** **lfx platform** **resources** **events** **lf training** [corporate /about/members) [/about/diversity-inclusivity) [brand ) [contact us copyright \u00a9 \u00ae. all rights reserved. has registered trademarks and uses trademarks. for a list of trademarks of , please see our trademark usage page. is a registered trademark of linus torvalds terms of use | privacy [/legal/good-standing-policy/?hslang=en) | [generative AI /legal/generative-ai?hslang=en) ", "## generative AI and law firm information governance ", "### law firm information governance symposium (lfigs) this paper covers the use of artificial intelligence (ai), and in particular, generative AI in law firms. whereas ai usage is similar across industries, law firms have some unique characteristics because much of the data belongs to the clients and there is an extra obligation to keep it safe and private. this paper covers both unique and non-unique challenges of ai as it pertains to information governance (ig) in the legal community. it begins with a brief definition of ai, followed by benefits to the legal community, information governance-specific considerations, policy considerations, general advice, and guidance. **)** **_what is generative AI and why are we talking about it?_** |google's bard and openai's are two generative AI models that have generated much interest. is based on , a foundational model for generative AI. is a large-scale machine learning system that can be fine-tuned for specific tasks. the concept for generative AI has been around since , tracing back to the foundations of machine learning and statistical modeling.|col|generative AI is a powerful tool with many potential benefits. it can be used for text generation, translation, writing, question answering, code generation, creative writing, chatbots, and virtual assistants. it can also serve as a knowledge concierge, write poetry, songs, jokes and play games. however, there are some concerns about its accuracy (hallucinations), confidentiality, potential for bias, and misuse. hatbots-hallucinatation.html| |---|---|---| __________________________________________________________________________ **_hallucinations: an ai response that portrays confidence not justified by its training or_** **_information entirely fabricated, behaving as if spouting facts._** __________________________________________________________________________ **)** **_what are some benefits to the legal industry?_** generative AI offers a range of benefits for organizations, both obvious and less apparent. **obvious benefits include:** **less apparent benefits include:** overall, generative AI offers a wide range of benefits for organizations, both large and small. by automating tasks, improving efficiency, and providing access to new insights, ai can help them save time and money, improve customer service, and gain a competitive edge. **)** **_what are some key ig considerations?_** **_generative ai models use neural networks to identify patterns and structures in existing data to_** **_generate new content._** this may involve confidential data, so it is important to understand the tools, risks, and benefits before using them. some new tools are addressing confidentiality issues, but you should still understand how your data is used. **_validating the output of generative AI can be challenging, as the source of the_** **_answers is often difficult to trace._** this is similar to the challenges faced when was first introduced, as all information on the site needed to be verified. attorneys should be mindful of this when relying on generative AI for legal research and guidance unless ai is built into trusted systems such as lexis. **_using ai may incur additional software licensing costs._** ai-enabled software costs are expected to increase by %, so you will need to find ways to recoup these costs. additionally, hardware and storage costs of ai-hosting providers are increasing exponentially. those costs will need to be recouped in some way. **_another important consideration is balancing privacy rules and regulations with system_** **_capabilities. currently, there is no way to remove data from the system._** this has led to concerns about ethical issues, ip usage, bias, and consent. as a result, many firms are taking a conservative approach to using generative AI technologies. some firms have banned the use of their data, while others have not yet adopted the technology. as the technology evolves, so too will the restrictions and usage guidelines around it\u2026 a good resource that offers insight into the early views on regulation between the eu and the us can be found here . in fact, using proprietary data is best done through apis, as described in section . **_it is helpful to understand your organization\u2019s risk tolerance related to ai._** topics that have generated significant discussion include when and how to cite ai as a source and whether your firm needs to capture questions and on-going prompt history. while this may seem cumbersome or counter-intuitive to such a tool, your firm\u2019s risk leaders will likely be considering the impact of not having this audit data for litigation, disciplinary matters and other legal purposes. **_clients are starting to issue requirements around ai usage guidelines and/or_** **_restrictions where their data is involved._** audit and assessment questions will quickly start to include ai usage queries, as will cyber insurance renewal applications. **)** **_what things should be considered in developing policy around ai?_** providing guidance and rules around ai is a key part of effective adoption. |here are some things to consider when developing an ai policy for your organization:|use ai tools as a starting point for content creation, not as a replacement for research or analysis.| |---|---| ||thoroughly vet the outputs of ai tools and validate the results. ai tools can produce incorrect, incomplete, inconsistent, and biased information. remember, that you are responsible for your work to ensure the final result meets legal, ethical, and professional standards.| ||ownership of the output created by ai tools is uncertain.| ||misuse of publicly available ai tools could breach your personal or professional obligations, as well as the obligations towards your organization, clients, or those who entrust their data to ||do not submit confidential information to ai tools, including questions or prompts.| ||set and communicate your organization's risk tolerance levels, including when and how you will reference ai as a source of information.| ||not all ai solutions will have the same level of cyber review or diligence, so vet each tool carefully.| ||the responsibility for the use of ai tools and the sharing of data may lie with the individual user, per the terms and conditions of some ai tools.| ||ai tools may share confidential information with other parties without the consent or awareness of the user. lawyers must take extra precautions to protect client confidentiality if using ai tools. lawyers should also advise clients carefully regarding the use of ai in their industry.| **)** **_what are some additional points to consider?_** **)** **_how might clients influence a firm's ai policies?_** |clients will expect their law firms to leverage ai to streamline their internal processes to reduce costs, accelerate response time from lawyers, improve quality of legal research and analysis, and potentially to create highly customized legal services.|col|clients will require that law firms are transparent about how ai is being used by the firm. sharing data privacy and security policies with the client, along with establishing communication channels to maintain transparency and establishing trust will be critical in managing the client relationship.| |---|---|---| **)** **_what are some key sources for staying up-to-date?_** as this technology continues to grow in its development and use cases, as with any emerging tech, it is critical that ig professionals continue to stay informed, educated and in-tune with not only ig implications but how the technology is evolving and being used within organizations. this space is evolving quickly, but here are a few notable articles to help build your understanding of generative AI, its use and implications. **brookings;** the eu and us diverge on ai regulation: a transatlantic comparison and steps to alignment; here **;** ai chatbots hallucinations, when ai chatbots hallucinate - (nytimes.com) **law.com;** the shift: chatgpt faces a timeout as legal turns its attention to more mature, legal-specific ai tools; here **alm law.com;** artificial intelligence litigation: the next class action boom on the horizon; here **legaltech news;** generative AI could automate almost half of all legal tasks, goldman sachs estimates; here **legaldive.com;** balancing generative AI\u2019s benefits for contracts with data privacy risks; here **law technology ;** how artificial intelligence in document processing impacts a legal firm; here **reuters;** lawyer used chatgpt to cite bogus cases; here **_and for a little fun for the ig geek in all of us, here\u2019s an ai ig rap song by chatgpt:_** (verse ) yo, listen up, i got a story to tell, 'bout a topic that might not ring a bell. it's called information governance, you see, but don't you worry, i'll make it fun and carefree. (chorus) information governance, it's a serious thing, but let's bring some humor and make it swing. from policies to data, it's all in the mix, get ready to laugh, 'cause this rap's gonna fix! (verse ) picture this, a file all out of control, with data scattered like a cereal bowl. information governance comes to the rescue, organizing data like it's the coolest venue. (verse ) we got file naming conventions, let's go, no more \"final\" or \"final_final,\" yo! version control, it's the name of the game, no more confusion, keep it all in the lane. (chorus) information governance, it's a serious thing, but let's bring some humor and make it swing. from policies to data, it's all in the mix, get ready to laugh, 'cause this rap's gonna fix! (verse ) privacy and security, they're paramount, protecting information, no room for a discount. encryption and access controls, oh so tight, keep that data safe, day and night. (verse ) retention schedules, don't throw it all away, keep the important stuff, the rest can sway. data classification, like a game of chess, sort it all out, you'll feel nothing but blessed. (chorus) information governance, it's a serious thing, but let's bring some humor and make it swing. from policies to data, it's all in the mix, get ready to laugh, 'cause this rap's gonna fix! (bridge) now let's talk about audits, it's no need to fear, just be prepared, keep your records clear. compliance is the name of the game, follow the rules, and you'll earn your fame. (verse ) information governance, it's the boss of the show, bringing order to chaos, watch it go. so, remember the importance of this rap, information governance, it's a funny mishap. (chorus) information governance, it's a serious thing, but let's bring some humor and make it swing. from policies to data, it's all in the mix, get ready to laugh, 'cause this rap's gonna fix! (outro) so, here we are at the end of this rhyme, information governance, we had a good time. remember the lessons and keep it in sight, now go out there and keep your data tight! ", "# generative AI: from buzz to business value **an exclusive kpmg survey shows** **how top leaders are approaching this** **transformative technology** kpmg.com ", "#### harnessing the transformative power of generative AI will require a balance of speed with thoughtful planning and careful risk mitigation. ", "##### about security, reliability, impact on jobs, and potential value. executives in our survey cite lack of talent, cost issues, and unclear applications as top barriers to implementation. this report is based on survey data from executives from across industries and geographies, as well as the insights of kpmg advisers in artificial intelligence, technology enablement, strategy, and risk management. the bottom-line assessment: harnessing the transformative power of generative AI will require a balance of speed\u2014first-mover advantage could be powerful\u2014with thoughtful planning and careful risk mitigation. we discuss the why, where, when, and how of generative AI adoption, and offer practical insights for responsibly integrating generative AI solutions into individual organizations. our goal is to help guide the critical dialogue taking place in c-suites about how to use generative AI to empower employees, work smarter, and compete better. ", "###### survey highlights **opportunities:** **challenges:** ", "##### ", "##### ", "##### |of respondents expect generative AI to have % the largest impact on their businesses out of all emerging technologies. % believe generative AI will increase workforce productivity. % will implement their first generative AI solution within . % believe generative AI will help their business gain a competitive advantage over competitors. top functional areas being explored: it/tech and operations|% think generative AI implementation introduces moderate to high-risk concerns. % are still at the initial stages of evaluating risk and risk-mitigation strategies for generative AI. top barriers to implementation: talent lack of skilled , investment cost/lack of , business case and lack of clear top risk focus areas: cybersecurity and data ", "## generative AI overview ", "###### what\u2019s the buzz? ", "##### an evolution of ai algorithms, especially deep learning technologies, generative AI models come out of the box having learned how to use the foundations of human communication\u2014 language, art, music, programming code, etc.\u2014 to make new content similar to that of humans. aptly also known as \u201cfoundational models, \u201d generative AI can be scaled and deployed across institutions far faster and with less cost than human-only processes. with the potential to be used across a variety of business use cases to save time, money, and effort, new applications of generative AI are being researched, developed, and adopted at an astonishing pace. generative AI technology attracted more than $. billion venture capital dollars in \u2014 more than was invested in the previous combined. robust growth is expected to continue as big tech companies like , alphabet, and amazon, as well as newer generative AI startups like openai, synthesia, and jasper ai continue to fund new innovation and push the envelope. **exhibit : generative AI market share by** **exhibit : generative AI market size -** **region ()** **%** middle east and africa **%** latin america **%** asia pacific . . ", "##### . . . . . . **$.b** **%** north america . . market size (us $b) **%** europe sources: limited availability of updated report, hence an estimation for as well was included, though has passed; precedence research; grand view research; quidgest quoted gartner numbers source: , \u201cvcs try to parse through the 'noise' of generative AI, \u201d pitchbook, december , ", "## what enterprise leaders are thinking about generative AI ", "##### ", "###### truly transformative: perception and outlook ", "##### generative AI stands apart from other recent innovations for its massive leap in ability and its potential breadth of impact across any industry and business function. for the first time in history, we have a technology that can directly augment humans in knowledge creation. where other technologies are indirect enablers of knowledge work, generative AI has enabled the development of a true smart assistant that inches closer to human cognition and reasoning. and where recent technological advancements like blockchain, web, and computing affected pockets of an industry or specific business functions, generative AI has applications across the end-to-end enterprise. business leaders are highly interested in the capabilities and opportunities generative AI can unleash and believe it has the potential to reshape how they interact with customers, run their workplaces, and grow their revenue. regardless of sector or function, percent rank generative AI as the emerging technology that will have the biggest impact on the business over , ahead of other trending technological capabilities such as advanced robotics, computing, augmented virtual reality (ar/vr), g, and blockchain. sixty-four percent of respondents expect the impact of generative AI on their organization in that timeframe to be medium. **exhibit : % of leaders rank generative** **ai as the most impactful technology** generative AI advanced robotics computing augmented virtual reality g blockchain metaverse d printing brain-computer interface nano technology nft/cryptocurrency % % % % ", "##### % % % % ", "##### % % % source: generative AI survey, the top drivers influencing enterprise need **exhibit : executives see generative AI more as opportunity than threat** for generative AI are all major, potentially disruptive ones: technological factors, changing % % customer demands and experiences, and % % market competition. our survey shows that corporate leaders perceive generative AI as % a capability that could give companies an % edge in these crucial strategic and operational % % % areas. according to our research, more than percent of respondents view generative AI generative AI represents generative AI represents generative AI represents as an opportunity to drive greater efficiencies, a significant opportunity a significant opportunity a significant threat to our grow market share and revenue, and gain a for our company to grow for our company to drive company's position in in terms of revenue/ better efficiencies the market competitive edge. % % ", "##### % % % % % % % % % % generative AI represents a significant opportunity for our company to grow in terms of revenue/ market share generative AI represents a significant opportunity for our company to drive better efficiencies generative AI represents a significant threat to our company's position in the market generative AI will significantly help our business gain a competitive advantage over our competitors ", "##### low agreement medium agreement high agreement notes: sum might not add up to % due to rounding off sources: generative AI survey, ", "###### dynamic uses: top applications and adoption timelines transforming business processes using generative AI precursors like machine learning and automation requires breaking them down into their individual component parts and applying strategic thinking around what components to accelerate or optimize. as such, they mostly impact business processes with point solution approaches designed to solve a single problem. generative AI changes the game. processes do not need to be broken down because generative AI tools can apply the large variety of human knowledge, experiences, and common sense embedded into their models to fill the gaps. this creates immense opportunity to apply and scale the technology across real-world, enterprisewide business processes. businesses recognize generative AI\u2019s potential. generative AI technology is in the midst of a meteoric rise and is now reaching an inflection point. the market has matured to the point that large companies in basically every industry can no longer ignore it and are now spurring into action. while only percent have already adopted generative AI, a large majority of enterprises ( percent) plan to implement their first generative AI solution within or less. when asked which application areas will be most relevant at their companies, automating routine tasks ( percent) and language generation ( percent) top the list. while prioritization varies by sector and function, overall value potential for applying generative AI seems to be highest in areas where bots can handle routine tasks, freeing up humans to focus on skill-driven activities. for example, chatbots and virtual assistants can handle routine it help desk tasks and inquiries, using text created automatically, while trained it professionals help users solve more complex technical problems. **exhibit : top priority functions for** **adoption are it/tech and operations** **exhibit : % plan to implement their** **first generative AI solution within two** **** **%** we have already implemented at least one generative AI solution **%** within the **%** within the ", "##### **%** no specific timeframe in mind **%** within the **%** within the notes: sum will not add up to % due to rounding sources: generative AI survey, executives expect the impact of generative AI to be highest in enterprise-wide areas: driving innovation, customer success, technology investment, and sales and marketing. it/tech and operations are the top two functional areas respondents are currently exploring to implement generative AI in their businesses. these are the same areas respondents say they expect the greatest transformational impact from the technology. it/tech % operations % marketing and sales customer product development/r&d finance and accounting hr risk and legal % % % % % % notes: sum will not add up to % as it is a multi-select question sources: generative AI survey, **exhibit . expectations for generative AI applications, by sector and function** click an icon to reveal data industrial technology, media, manufacturing and telecommunications healthcare and life sciences consumer and retail it/technology human resources finance and administration ", "##### financial services energy and natural resources risk and legal customer support marketing and sales research operations and design ", "###### not ready for prime time: implementation challenges **exhibit : lack of skills, funds, and clear business case are the biggest barriers to** **adoption** respondents name a diverse list of barriers to implementing ai, led by lack of skilled talent to develop and implement, cost/lack of investment, lack of clear business case, lack of clarity on specific ways to implement, and lack of leadership understanding and/or strategy. and for all the excitement around generative AI opportunities, the majority of business leaders do not feel ready to adopt the technology at scale or seize its full potential. still trying to grasp the full impacts of generative AI on their systems, operations, and people, percent anticipate spending focused on increasing understanding of the objectives and strategies for generative AI adoption\u2014a top priority. enterprises clearly lack the right skills to implement generative AI. only a miniscule percent of respondents ( percent) say they already have the skills necessary in-house. the rest plan to hire/acquire new talent ( percent), train existing talent ( percent), or do both ( percent). companies also often find it difficult to get the value they want from emerging technologies when they take a siloed approach. yet percent of respondents have not appointed a central person or team to organize their response to the emergence of generative AI. for the time being, the it function is leading the charge. lack of skilled talent to develop and implement cost/lack of investment lack of clear business case lack of clarity on specific ways to implement lack of leadership understanding and/or strategy identifying appropriate generative AI models potential risk and/or privacy threats insufficient technology infrastructure to support inability to access/leverage data cultural resistance internally legal exposure inability to perform certain simple tasks, and provide authentic and accurate results % % ", "##### % % ", "##### % ", "##### % % % % % % ", "##### % ", "##### notes: the represented figures are weighted average of the ranks which is calculated by assigning % weight to rank , % to rank , % to rank source: generative AI survey, ", "#### more than anything else, generative AI implementation decisions are likely to reflect the level of enterprise risk tolerance. integrating generative AI into the business stands out as a potential roadblock on the path to value creation. views about four integration capabilities\u2014having the right people, appropriate prioritization by executive leadership, having the right technology and data infrastructure, and having the right governance models and policies\u2014indicate a clear lack of preparedness. to successfully implement generative AI, addressing these barriers will be paramount. however, percent responded that they are in the initial stages of evaluating risk and risk mitigation strategies around the technology (exhibit ), with cybersecurity and data privacy as the top risk management focus areas (exhibit ). most will not go it alone. the majority of respondent companies will engage with an external partner to help with four aspects of developing and implementing generative AI: model testing and validation, algorithm development and optimization, integration with existing systems and infrastructure, and data acquisition and processing. more than anything else, implementation decisions are likely to reflect the level of enterprise risk tolerance. as we explore in the next section, this is a very new technology with many risks. to steer industries toward responsible action around ai broadly, governments around the world have introduced regulations such as the us ai bill of rights and that require businesses to consider consequences of adopting the technology alongside opportunities. given the rapid adoption of generative AI and the predicted massive impact across business and operational models, attention on ai regulatory guidelines are growing and compliance is becoming increasingly important to reputation and trust. non-compliance could have significant monetary impacts. for example, \u2014which will require organizations to determine ai system risk and monitor high-risk systems postmarket\u2014will penalize violating organizations \u20acm or percent of income for using prohibited ai practices or not complying with data requirements. ", "##### kop, , \"eu artificial intelligence act: the european approach to ai,\" , ", "###### a matter of trust: internal and external risks organizational barriers aside, it is little wonder executives feel unprepared for immediate adoption when you consider the worst-case scenarios of unplanned, uncontrolled generative AI applications. perhaps \u2019s most important business asset\u2014trust\u2014is at stake. a large majority of executives ( percent) believe generative AI can play a critical role in building and maintaining stakeholder trust. yet almost half ( percent) also say the technology can negatively impact their organization\u2019s trust if the appropriate risk-management tools are not implemented. early versions of generative AI have shown a lot of challenges with getting even basic, unchallenged facts correct, such as which national soccer team won the last the world cup. the problem becomes worse when a topic does not have a clear answer, such as how an upcoming hurricane season could affect supply-chain logistics. it will take many iterations to develop generative AI models that can understand and apply human-like reasoning to unequivocally answer such complex questions to truly aid business decision makers. until that time, for all its promise, the risks posed by generative AI models are broad and complex, spanning multiple areas of the business, from privacy and security to compliance and ethics. billions of dollars could be wasted if enterprises place bets on the wrong tools, applications, or use cases, or fail to weave initial pilot projects into their ways of operating. customers could be alienated, and brands could be ruined, by an unsupervised generative AI algorithm spewing out immoral or erroneous advice. anxiety could rise among employees who feel threatened by the possibility of technological displacement or confused by the changes in their normal work routines brought on by generative AI tools. businesses could run afoul of global laws and regulations if a generative AI bot exposes sensitive or confidential information or intellectual property. the vast majority of respondents ( percent) rank their concerns about the risks of implementing generative AI as moderately to highly significant. the top risk management and mitigation focus areas\u2014those selected by the greatest percentage of survey respondents as high priorities\u2014are cybersecurity ( percent), privacy concerns with personal data ( percent), and liability ( percent). ", "##### although business leaders recognize generative AI risks, immature organizational structures and processes for controlling them are barriers to seizing generative AI opportunities. few companies have evaluated and implemented risk and risk-mitigation strategies as part of their generative AI development and deployment strategy. forty-seven percent are still at the initial evaluation stages, and percent have evaluated risks but are still in the process of implementing risk-mitigation strategies. further, percent intend to but have not yet stood up a responsible ai governance program, framework, or practices, and only percent have one already in place. **exhibit : most companies have not gotten far with risk mitigation strategies for** **generative AI** **%** yes, we have a dedicated team for evaluating risk and implementing risk mitigation strategies **%** we have evaluated risk and risk mitigation strategies, but we are still in the process of implementing them **%** no, we have not yet started evaluating risk and risk mitigation strategies **%** we are in the initial stages of evaluating risk and risk mitigation strategies source: generative AI survey, ", "##### **exhibit : cybersecurity and data privacy are the top risk-management focus areas** ", "##### % ", "##### % % % % % % % % % % % % % % % % % % % % % cybersecurity privacy concerns with personal data liability legal/copyright/ bias/ lies and weaponization ip issues inaccuracy misinformation low agreement medium agreement high agreement sources: generative AI survey, as generative AI scales, companies face multiple challenges. risk to external reputation (customer and stakeholders) kpmg responsible ai framework kpmg leverages eight core principles to guide our approach to responsible ai across the ai/ml lifecycle: **trust** **compliance** **security** **and privacy** **value** **speed** **fairness** **explainability** risk of bias, discrimination, and misinformation risk of opaqueness in ai rising number of global regulations around ai and ethics compliance with growing number of internal enterprise policies and controls skyrocketing number of security vulnerabilities (cyber and adversarial) need for transparency and consumer privacy lack of awareness and training on ai risk of data integrity, statistical validity, model accuracy lack of technology assessment tools growing number of models built with diverse stakeholders and complex pipelines exponential increase in data, storage, and computing shortage of ai/ml talent ", "##### help enable models to be free help enable the understanding from bias and remain equitable. and documentation of ai algorithms. **accountability** help establish mechanisms to drive ownership and responsibility across the ai/ml lifecycle. **privacy** ", "### help drive compliance with data privacy regulations and consumer data. **data integrity** ", "### help embed trust with data quality, governance, and enrichment steps. **security** ", "##### safeguard against unauthorized access, corruption, and attacks. **safety** ", "### safeguard against a negative impact to humans, property, and environment. **reliability** help ensure the performance of ai systems at the desired level of precision and consistency. ", "###### preparing people: workforce implications our survey indicates that executives expect generative AI to have significant impact on workforces, but mostly as a means to augment, rather than replace, labor. they also understand that some types of jobs could be at risk and there are ethical considerations for how generative AI is introduced and jobs are redesigned. nearly three-quarters of respondents ( percent) believe generative AI will increase productivity; percent say it will change how people work; and percent think it will encourage innovation. over time, the technology could enable employers to fill demand for highly skilled workers (a challenge ) and shift employee time from routine tasks, such as filling in forms and reports, to more creative and strategic activities. respondents are alert to the downsides: percent believe job security will be at risk where generative AI tools can replace some jobs. the most vulnerable positions, according to respondents, will likely be in administrative roles ( percent), customer service ( percent), and creative ( percent). for example, adoption of **exhibit : generative AI will increase productivity and change the way people work,** **innovate, and collaborate** % increasing productivity % % ", "##### % % changing the encouraging enhancing creating new ethical way people work innovation collaboration considerations sources: generative AI survey, visual content-creating programs like dall-e and lensa could have a deep impact on marketing, design, and creative firms. whether generative AI is used for augmenting or automating knowledge-worker tasks, human expertise will be critical for harnessing generative AI capabilities to unlock real value. even now, companies are scrambling to build the capabilities to test, implement, and manage generative AI. not surprisingly, the amazing \u201ccreative\u201d powers of generative AI have raised alarms among workers and policy makers about job losses. those concerns should not be ignored. but history has shown that when technology makes some tasks obsolete (e.g., stenography), it creates demand for new ones. companies that identify the opportunities for employees created by generative AI may be the real winners. ", "## what to do now to capitalize on the promise, enterprises need a sound strategy and clear playbook for integrating this exciting technology into their businesses. generative AI is a novel development, but the proven methods for successful technology transformation still apply. what follows are our recommendations for implementing generative AI strategically and responsibly. be a first mover: with the market growing rapidly\u2014seven in ten respondents ( percent) expect their company to implement their first generative AI solution in \u2014adopting sooner rather than later promises true first-mover advantage. in fact, the accelerated pace of emerging technology change is likely to significantly widen the first-mover and fast-follower gap. as such, tracking the evolution of tools and applications to keep pace with innovation will be imperative. further, early adoption will quickly highlight resource and capability gaps and give first movers a leg up in investing in people, technology, and process change. initial pilots are also great at surfacing early risk indicators, including challenges of scaling the technology. find your generative AI north star: from an implementation, adoption, and evangelizing perspective, leveraging existing ai investments and foundations can help put new generative AI implementations on solid footing. but the true success of generative AI will come when the institution as a whole refines its strategy to harness the unique capabilities and address the unique risks of generative AI\u2014a transformation vision, or \u201cnorth star, \u201d to aim for. lack of investment and lack of a clear business case are the top barriers. gaining clarity about the future of their business model and developing new use cases will be crucial success factors as companies move toward implementation. respond and adapt: successful tech-enabled transformation programs are ready to adjust to inevitable changes. leaders will need to be ready to quickly assess, adapt, or pivot the strategy to account for the enormous potential. the organization will need to come together as a whole to consider the implications of generative AI on all aspects of their business. one best practice is to designate a single leader responsible for crossenterprise coordination, focusing on finding efficiencies, learning from pilots, and prioritizing investment. this leader can champion success with contextual knowledge of the businesses component parts to effectively leverage the capabilities of generative AI to broadly transform operations. empower responsible use: generative AI\u2019s ease of use and open nature create an array of risks. most organizations have limited or no structures and policies in place for governing, training, and implementing generative AI solutions responsibly. to maintain trust and avoid negative consequences, it will be essential to give equal, if not more attention and priority to risks as potential opportunities. a vital aspect of controlling evolving risks of generative AI usage will be establishing clear governance. from financial to reputational to ethical considerations, enterprises need strong guardrails in place to limit risks of generative AI. having accountability from various business, risk, and governance leaders who will think through potential risks is ", "##### address critical talent questions: the implications of generative AI on how people work, what skills they need, and what jobs they do will be significant. big changes usually create fear and uncertainty. to minimize these effects, leaders will need to expertly manage communication about shifting jobs, reengineered processes, and new behaviors. these will differ for each industry and function. but everywhere generative AI is adopted, it will be critical for leaders to position generative AI as a tool to extend human capabilities, not replace them. after all, most enterprises want to scale their operations, and what better way to achieve that than by increasing productivity of the existing workforce. develop generative AI literacy: from c-suite leaders to vps, managers, and the workforce at large, successful integration of generative AI solutions will require immediate investment in developing literacy around the new technology. debunking myths will be critical to helping both leaders and employees from falling into an isolationist mindset. education, experimentation, and a positive culture of responsible adoption will all be essential to pave a path of growth with generative AI. reprioritize investments, m&a, and alliances: the financial implications of generative AI as a technology may come well before any future operating efficiency gains are proven. investor sentiment is already impacting flow of capital towards generative AI. the stock prices of companies and sectors investors believe will be net positively impacted by this innovation are set to rise alongside. at the same time, leveraging m&a to rapidly acquire generative AI skills, technology, and customer access is becoming more common and will likely pump up premiums for the most attractive assets. also, and new alliances are rapidly being announced and reshaped based on the changing competitive landscape. unleash generative AI broadly: systematic, top-down adoption of emerging technology is a safe, well-tested approach. for the boldest innovators, there may be another way to seize the potential of generative AI at speed: disseminating it everywhere, all at once. new technologies are traditionally applicable only to specific parts of the business, so investments are managed as one-off programs. generative AI is fundamentally different, as it applies to the entire workforce. giving every person in every function a chance to experiment (in a protected way, of course) unlocks the data enterprise\u2019s need to define use cases, tune up applications, build the technology into planning cycles, train employees, redefine roles, and even transform the business model manage change boldly and broadly: generative AI is more than a technological turning point. it is changing everything\u2014how we think, create, work, interact, and live. confronted with the most disruptive technology of our lifetimes, business leaders face a critical question: how do we deploy generative AI in a way that prevents the worst, and harnesses the best? this will require an extraordinary and unparalleled change effort. many leaders have not had to manage change of such magnitude, at such speed and scale, or with such consequence. success will require thinking about all aspects of the business differently\u2014 industry dynamics, business models, operating models, competitors, and talent\u2014and making consequential decisions despite significant uncertainty. it will require leaders to be brave enough to make clear decisions\u2014often without the safety net of definitive answers\u2014to take their enterprises in new, unplotted directions. ", "##### ", "## how kpmg can help ", "###### accelerate the value of generative AI solutions\u2014responsibly and confidently ", "##### generative AI is poised to transform the future of enterprise. businesses will increasingly rely on generative AI to gain insights, make critical decisions, alleviate skills shortages, create new products, and engage with customers. across industries, generative AI is being embedded into numerous business processes and products to achieve tangible business outcomes and accelerate value for customers, employees, and society. we believe, however, that many businesses do not fully understand or account for the risks and challenges generative AI poses. successful generative AI adoption requires an approach to designing, building, and deploying systems in a safe, trustworthy, and ethical manner. it requires experienced governance, risk, and compliance professionals who can help develop an operating model, and governance structure that drives accountability. it requires highly skilled ai technology and data science professionals, advanced ai tools and accelerators, extensive experience with leading ai solutions, and strong industry alliances with ai solution providers. along every step on your journey, we can help you: **strategize:** crystalize your vision, strategy, and roadmap for generative AI by building scenarios for what impact it could have on your business versus your competitors, identifying strategic options and designing a roadmap to responsible value creation. **pilot:** by prioritizing the business areas that could be most impacted by generative AI\u2014whether optimized, disrupted, or both\u2014we can help you focus investments, rapidly build proofs of concept for new use cases across functions, and validate the roi and risk for your organization. **integrate:** we combine deep industry experience and modern technical skills to integrate proven generative AI use cases into your technology infrastructure, starting and ending with reliability and data quality to help ensure your solution delivers on its promise. **accelerate:** where there are first-mover advantages, we can help you propel your organization at the speed of a startup to reap the full benefits of generative AI. we can help you quickly adopt new capabilities and drive the behavioral change required for humans to adopt new ways of working. **scale:** by combining our depth in key business functions and unique value drivers across industries, we help you expand the value of generative AI, from early experiments to large-scale automation, while maintaining quality and accountability. **protect:** handle the risks posed by generative AI, including reputational damage, intellectual property theft, privacy or compliance violations, and ethical concerns\u2014with security plans, processes and tools for detection, response, and recovery. **trust:** gain confidence in your generative AI models and the decisions you make based on them, and be certain that those decisions are in line with your ethics, values, and brand. **govern:** evolve your organization and governance processes to ensure accountability and transparency into how ai models are used, how effective they are in creating value for the organization, and how to detect and limit unforeseen risks going forward. learn more at visit.kpmg.us/generativeai and visit.kpmg.us/responsibleai ", "## research methodology from , kpmg conducted an online survey of global business executives to explore generative AI views and trends. survey questions asked about respondents\u2019 understanding of the transformative impact and applications of generative AI, spanning four core topics: perception and strategic intent, applications, technology challenges and opportunities, and impacts on risk management and workforce. the sample was representative of diverse industries, functions, firm characteristics, and markets. respondents, who are from businesses with revenue of $ billion and above, spanned key industries: consumer and retail; energy, natural resources, and chemicals; healthcare and life sciences; industrial manufacturing; technology, media, and telecommunications; and financial services. fifty-four percent were c-suite or higher in level, and percent held vp/svp level roles. forty-six percent worked in the it/tech/digital ( percent) function. three-quarters ( percent) were based in the us. all respondents reported a basic- to expert-level understanding of the generative AI technology, applications, and techniques. **exhibit : who answered our survey questions?** our sample is representative and robust for insights into industry, function, and firm characteristic, while focused in our key market locations. **respondent level in organization** ", "#### .% .% ", "##### ", "#### n = c-suite executives and senior management surveyed from , c-suite executives svp and vp levels **respondents by geography** **organizations by revenue** ", "##### .% usa = % europe = .% asia pacific = % canada = .% middle east & africa = .% south america = % mexico = .% .% .% .% $b - $.b $b - $.b ", "##### .% $b - $.b $b - $.b ", "##### $b or more **respondents by type** **organizations by sector** .% ", "##### % % % % % % % % % public private firm private equity backed private firm .% .% .% investment firm not sure/ cannot share note: total might not add up to % due to rounding source: generative AI survey enrc hcls im fs legend: - consumer and retail; enrc - energy, natural resources and chemicals; hcls - healthcare and life sciences; im - industrial manufacturing; - technology, media and telecommunications; fs - financial services ", "##### **related thought leadership:** ", "##### some or all of the services described herein may not be permissible for audit clients and their affiliates or related entities. **.com/socialmedia** the information contained herein is of a general nature and is not intended to address the circumstances of any particular individual or entity. although we endeavor to provide accurate and timely information, there can be no guarantee that such information is accurate as of the date it is received or that it will continue to be accurate in the future. no one should act upon such information without appropriate professional advice after a thorough examination of the particular situation. \u00a9 llp , a delaware limited liability partnership and a member firm of the global organization of independent member firms affiliated with international limited, a private english company limited by guarantee. all rights reserved. the name and logo are trademarks used under license by the independent member firms of the global organization ", "## generative AI faqs generati e ai faqs generati e ai faqs ma ", "##### has a long history of using artificial intelligence (ai) to improve our products for billions of people. for example, in maps, ai analyzes data to provide up-to-date information about traffic conditions and delays; in gmail, it helps block nearly m spam messages every minute; through translate and lens, ai helps instantly translate between languages. now, \u2019s newest ai technologies \u2014 like lamda, palm, imagen and musiclm \u2014 are creating entirely new ways to engage with information, from language and images to video and audio. we\u2019re working to bring these latest ai advancements to more people. several of our latest ai advancements center on language models (notice the \u201clm\u201d references in lamda, palm and musiclm), which are statistical tools that find patterns in human language. these patterns can be used for a range of tasks including predicting the next words to complete a sentence, or providing grammatical suggestions that preserve what you mean. just as there are many different applications for ai, there are also different types of language models, including large language models (or llms). generati e ai faqs page ", "##### understanding the differences between these terms and concepts can be a challenge and you probably have questions. like what exactly are llms? or how does generative AI fit into the broader ai ecosystem? this set of frequently asked questions provides some quick answers on key ai-related topics. we hope these answers can help inform deeper policy conversations about the changing role of ai in society. generati e ai faqs page ", "### understanding generative AI what is generative AI? generative AI is a type of machine learning (ml) model that can take what it has learned from the examples it has been provided to create new content, such as text, images, music, and code. these models learn through observation and pattern matching, also known as training. for example, a model may learn what a cat looks like by observing many different examples of cats and recognizing characteristics consistent with a cat. the same goes for sonnets, resumes, or packing lists for a camping trip. to understand the concept \u201ccat\u201d, a generative text-toimage model (like imagen) would be trained on millions of cat photos. over time, it learns to recognize that cats are animals that usually have whiskers, fur, pointy ears, etc. generati e ai faqs page this allows the model to take an input such as \u201ccat wearing an ice cream hat,\u201d connect what it has learned about cats, ice cream, and hats, and generate a new corresponding image, even if it has never seen an image of a cat wearing an ice cream hat in its training data . generative AI models are neither information databases nor deterministic information retrieval systems. because they are prediction engines, they can create different outputs in response to the same prompt. for example, when you ask a generative AI model to produce an image of a cat, it does not look through its training data and return a cat photo. instead, it will generate a new image of a cat each time. what is a large language model (llm)? large language models, or llms, are generative AI models which can predict words that are likely to come next, based on the user\u2019s prompt and the text it has generated so far. in some cases, llms can respond to the same prompt with different responses. this is due to the flexibility that llms are often given to pick among probable words that could follow, based on patterns identified from their training data. this flexibility allows them to generate more interesting and creative responses. for example, if prompted to fill in the phrase \u201ccat and [blank]\u201d, an llm might predict that the next word is \u201cmouse\u201d, or it might predict \u201cdog.\u201d generati e ai faqs page importantly, llms are not databases or information retrieval systems. when prompted for facts, they can generate articulate responses that may give the impression that they are retrieving information. however, they do not inherently understand the words they are generating, the concepts they represent, or their accuracy, which is why they can sometimes produce answers that, while sounding plausible, contain factual errors. what\u2019s the difference between machine learning, deep learning, and generative AI? much of the recent progress we\u2019ve seen in ai is based on machine learning (ml), a subfield of computer science where computers learn to mathematically recognize patterns from example data, rather than being programmed with specific rules. deep learning is a specific ml technique based on neural networks. neural networks use nodes or \u201cartificial neurons,\u201d inspired by models of brain neurons, as fundamental processing units which receive and pass numeric inputs and outputs from other neurons. deep learning connects multiple layers of these artificial neurons. an example of deep learning would be a model that can detect cats in a photo. an example of a generative AI model, meanwhile, would be one that can generate photos of a cat when prompted. generati e ai faqs page is generative AI the same as artificial general intelligence (agi)? no, artificial general intelligence (agi) is a hypothetical type of artificial intelligence (ai) that would have the ability to learn, understand and perform any intellectual task that a human being can. meanwhile, generative AI is technology already used in a variety of applications \u2014 such as image generators used in creative applications. predicting the arrival of true agi is difficult. there\u2019s no universally accepted notion of agi and no consensus exists whether agi is possible within , or more. many factors contribute to the possibility of agi, including advancements in computing power and learning capabilities of ai models. but capabilities resembling, yet still far from, human-like intelligence are emerging in some forms of ai, including gai. is ai sentient? no, ai models are not showing evidence of sentience. ai\u2019s capabilities are based on identifying patterns and relationships in data and, in so doing, ai can generate outputs that are generally informed by those patterns. this means, at times, an ai model might generate responses that seem to suggest it has opinions or emotions, like love, sadness or anger, since it has trained on information and data created by people that reflects the human experience and is predicting a likely response. generati e ai faqs page ", "### training a large language model how does an llm \u201clearn\u201d? the technical process of \u201clearning\u201d for llms begins with training the model to identify relationships and patterns among words in a large dataset. through this process, a generative AI model will learn \u201cparameters,\u201d which represent the mathematical relationships in data. once the model has learned these parameters, it can then use them to generate new outputs based on these parameters. for example, the palm research model () learned billion parameters from training on text, which gave it strong capabilities in natural language inference, question and answering, and translation, among other skills. research is showing that, with the proper training, models with fewer parameters (b - b) can be similarly capable. generati e ai faqs page what is pre-training? what is fine-tuning? llms are developed in multiple stages, including pre-training and fine-tuning. pre-training is a way of training an ml model on a variety of data. this gives the model a head start when it is later trained on a smaller dataset of labeled data for a specific task. following pre-training, more data can be added to an existing llm through a process called fine-tuning. fine-tuning an llm is the process of adapting a pre-trained llm to improve its performance on a specific task. the model learns from additional example data to help hone its capabilities. for example, fine-tuning a general purpose language model can teach it to summarize technical reports in general by using just a few examples of technical reports and accurate summaries. what is grounding? grounding a model refers to the process of linking the abstract concepts in the model to real world entities. developers use a variety of techniques for grounding generative AI models, including training with real-world data, simulating interactive environments, or even using equipment that can provide actual sensory input. grounding an llm can help equip it to better understand language and other abstract concepts in the context of the real world, which may be helpful for tasks such as natural language processing or improving the factuality of model responses. generati e ai faqs page for example, if a model is trained on soccer data accurate through , it would not be able to provide an accurate response to the question, \u201cwho won the world cup in december ?\u201d, as it has no information on the tournament\u2019s results. in this case, grounding the model with techniques for conducting factual checks with recent data, while not foolproof, aids llms in providing a better answer. what data do llms need to train? llms are trained on a variety of data, and they learn through observation and pattern matching. naturally, the value and quality of individual documents within a given dataset may vary widely. the quality of some models\u2019 predictions and outputs may benefit from having access to larger and/or more diverse pools of data. the amount of data needed for training generally includes millions or billions of data points. in terms of scale, pre-training for text models usually involves hundreds of billions of words, while pre-training for image models may train on hundreds of millions of images or more. fine-tuning, meanwhile, requires a smaller dataset. for example, fine-tuning for text llms might involve hundreds of thousands or millions of examples. for example, lamda (short for language model for dialogue applications) is a language model that analyzes human speech and recognizes commands. it is trained on human dialogue and stories. the largest lamda model has billion parameters and is trained with . trillion words. generati e ai faqs page in the training phase for llms, how do you manage risk responsibly? careful risk assessment is essential for llm development and can involve multiple steps and mitigation measures. one good practice is to filter various training data to remove harmful content or personal data wherever possible before training, which reduces the chance the model will respond with toxic speech or personal information. another good practice is to add additional steps such as fine-tuning, classifiers, and guardrails to help the model avoid responding with harmful patterns. what type of human oversight or input might be involved? human feedback and evaluations are important in developing llms responsibly. at the outset, those creating the llm should create policies for these systems to outline prohibited use, including various forms of abuse and harm. during development, a good practice is to perform adversarial testing \u2013 encouraging test users to actively find problems and problematic requests, so that they can be fixed. after launch, users should be able to flag content which might be unsafe or harmful. for example, before google bard\u2019s launch, thousands of trusted testers were invited to use it and give feedback on their experience. this feedback helped improve the overall experience before public launch. generati e ai faqs page ", "### mitigating risks and preventing misuse what is a \u201challucination\u201d and why do llms \u201challucinate?\u201d a hallucination is a response from an llm that may be coherent and presented confidently but is not based in factuality. among other reasons, hallucinations can occur if that response is not grounded in its training data or real-world information. hallucinations can be reduced, but very difficult to eliminate altogether. as explained above, generative models do not retrieve information, but predict which words will come next based on user inputs. for this reason, there is no guarantee that the llm\u2019s prediction will contain factual information \u2013 nor that their outputs to a given prompt will remain stable over time. generati e ai faqs page for example, if you ask an llm-based interface to give information about a person who is not well known, it might reply that the person has a degree in a field they never studied, from a university that they never attended. this can occur largely because the model is predicting an output about something it does not have enough training data to learn from. when there\u2019s limited or no information about the person, it is more likely the model will hallucinate in its response. this is why users may see disclaimers when engaging with llms, alerting them to the risk of relying on the output of these systems without verifying the responses\u2019 underlying accuracy. can we prevent hallucinations? hallucinations can be reduced in an llm, but inaccuracies cannot be % prevented since responses are created via a prediction mechanism. during fine-tuning, models can be optimized for recognizing correct patterns in their training data, which will reduce the number of factual mistakes. another technique for reducing hallucinations is to connect llms to other systems to provide verified information in the response. for example, if a user requests a mathematical calculation from an llm that is connected to a calculator service, the llm can pass part of the request to that calculator to perform the task. the llm then returns the calculator\u2019s response to the user in its answer. generati e ai faqs page why is it sometimes difficult for generative AI to attribute and cite sources? generative AI models are usually designed to generate original outputs based on their underlying prediction mechanisms. for example, when it runs, a generative image model creates a new, unique image based on concepts it has picked up across its training data. this makes it difficult for generative models to attribute specific parts of their responses to any one source. a good analogy might be an artist studying multiple other artist\u2019s styles and then creating their own. how can we build additional guardrails for generative AI models? generative AI models are intended to respond to a wide variety of input prompts (e.g., \u201cdraw me a photo\u2026\u201d, \u201cwrite me a post\u2026\u201d). for this reason, it is also important to take a multifaceted approach to guardrails for generative AI. this can include using training data that aligns models as closely as possible to policies; implementing prompt-and-response detection tools that intercept possible violations; and otherwise reducing the potential for harmful or offensive outputs with additional systems such as classifiers. technical guardrails help ensure that these technologies respond to prompts that adhere to a set of policies governing acceptable use. however, no automated systems are able to catch all possible violations all of the time. how can bias be prevented or mitigated when developing generative AI models? is generative AI necessarily biased? importantly, the way that generative AI models are trained means that they are not able to identify information that\u2019s non-factual, generati e ai faqs page biased or potentially harmful on their own. that\u2019s why building such models responsibly is important and necessary. for a number of reasons, a generative AI model might produce responses that reflect gaps, biases or stereotypes, as it tries to predict a plausible response. for example, a model is more likely to generate low-quality or inaccurate information if its training data includes an insufficient amount of reliable information or examples. in addition, biases or stereotypes in training data \u2013 if not addressed responsibly during the development process \u2013 might be reflected in the model\u2019s responses. one way to reduce bias is to continue improving the model via fine-tuning, as issues are flagged and reported. another mitigation measure is to train generative AI models on data that represents a more balanced view of the world. for example, these models can be trained on many images of weddings, from a wide array of cultures and settings, so that they produce a diverse set of images for the prompt \u201cphoto of a wedding.\u201d yet another method is to train the generative AI model to represent a wide range of viewpoints for subjective topics, without endorsing one or another. for example, if prompted to reply with the \u201cbest cat,\u201d a model could be trained to respond by stating that the \u201cbest\u201d is a matter of opinion, followed by a range of possible cat breeds. generati e ai faqs page generati e ai faqs ma ", "# how wired will use generative AI tools ", "### some publications are already using text and image generators. here\u2019s how wired will\u2014and won\u2019t\u2014use the technology. **like pretty much** everyone else in , journalists have been trying out generative AI tools like chatgpt to see whether they can help us do our jobs better. ai software can\u2019t call sources and wheedle information out of them, but it can produce half-decent transcripts of those calls, and new generative AI tools can condense hundreds of pages of those transcripts into a summary. writing stories is another matter, though. a few publications have tried\u2014sometimes with disastrous results. it turns out current ai tools are very good at churning out convincing (if formulaic) copy riddled with falsehoods. this is wired, so we want to be on the front lines of new technology, but also to be ethical and appropriately circumspect. here, then, are some ground rules on how we are using the current set of generative AI tools. we recognize that ai will develop and so may modify our perspective over time, and we\u2019ll acknowledge any changes in this post. we welcome feedback at mail@wired.com. ", "## text generators (e.g. lamda, chatgpt) we do not publish stories with text generated by ai, except when the fact that it\u2019s ai-generated is the whole point of the story. (in such cases we\u2019ll disclose the use and flag any errors.) this applies not just to whole stories but also to snippets\u2014for example, ordering up a few sentences of boilerplate on how crispr works or what computing is. it also applies to editorial text on other platforms, such as which are already automated, we will disclose that.) this is for obvious reasons: the current ai tools are prone to both errors and bias, and often produce dull, unoriginal writing. in addition, we think someone who writes for a living needs to constantly be thinking about the best way to express complex ideas in their own words. finally, an ai tool may inadvertently plagiarize someone else\u2019s words. if a writer uses it to create text for publication without a disclosure, we\u2019ll treat that as tantamount to plagiarism. we do not publish text edited by ai either. while using ai to, say, shrink an existing ,-word story to words might seem less problematic than writing a story from scratch, we think it still has pitfalls. aside from the risk that the ai tool will introduce factual errors or changes in meaning, editing is also a matter of judgment about what is most relevant, original, or entertaining about the piece. this judgment depends on understanding both the subject and the readership, neither of which ai can do. we may try using ai to suggest headlines or text for short social media posts. we currently generate lots of suggestions manually, and an editor has to approve the final choices for accuracy. using an ai tool to speed up idea generation won\u2019t change this process substantively. we may try using ai to generate story ideas. an ai might help the process of brainstorming with a prompt like \u201csuggest stories about the impact of genetic testing on privacy,\u201d or \u201cprovide a list of cities where predictive policing has been controversial.\u201d this may save some time and we will keep exploring how this can be useful. but some limited testing we\u2019ve done has shown that it can also produce false leads or boring ideas. in any case, the real work, which only humans can do, is in evaluating which ones are worth pursuing. where possible, for any ai tool we use, we will acknowledge the sources it used to generate information. we may experiment with using ai as a research or analytical tool. the current generation of ai chatbots that and are adding to their search engines answer questions by extracting information from large amounts of text and summarizing it a reporter might use these tools just like a regular search engine or will still have to go back to the original notes, documents, or recordings to check quotes and references. in this sense, using an ai bot is like using search or wikipedia: it might give you initial pointers, but you must follow the links back to the original sources. in practice, though, ai will make mistakes and miss things that a human would find relevant\u2014perhaps so much so that it doesn\u2019t save any time. even if these tools do prove useful, we won\u2019t want our reporters to rely on them any more than we\u2019d let them rely on the limited information on wikipedia. we\u2019ll continue to insist on the same standards of research and original reporting as always. we also know that there are many professionally published research databases out there that come with lawful and highly accurate text- and data-mining tools, so we will constantly evaluate whether those meet our needs. ", "## image generators (e.g. dall-e, midjourney, stable diffusion) we may publish ai-generated images or video, but only under certain conditions. some working artists are now incorporating generative AI into their creative process in much the same way that they use other digital tools. we will commission work from these artists as long as it involves significant creative input by the artist and does not blatantly imitate existing work or infringe copyright. in such cases we will disclose the fact that generative AI was used. we specifically do not use ai-generated images instead of stock photography. selling images to stock archives is how many working photographers make ends meet. at least until generative AI companies develop a way to compensate the creators their tools rely on, we won\u2019t use their images this way. we or the artists we commission may use ai tools to spark ideas. this is the visual equivalent of brainstorming\u2014type in a prompt and see what comes up. but if an artist uses this technique to come up with concepts, we will still require them to create original images using their normal process, and not merely reproduce what the ai suggested. and video under certain conditions. cookies settings ", "## things to include in a workplace generative AI policy % of companies globally use some form of ai technology, including hr ai tools, reflecting a pervasive trend in the integration of artificial intelligence to enhance human resource management. the transformative potential of generative AI also brings forth a pressing need for organizations to establish a clear and comprehensive policy governing its use in the workplace. a generative AI policy serves as a guiding framework, delineating the boundaries, responsibilities, and ethical considerations surrounding the deployment of ai systems within the organizational context. this policy not only outlines the principles governing the use of ai in hr but also underscores the importance of aligning ai initiatives with the organization\u2019s values and goals. here are the key elements that organizations should include in their workplace generative AI policies. ", "# what is generative AI and how is it used in the workplace? generative AI is a subset of artificial intelligence that focuses on enabling machines to generate content, data, or outputs that mimic human creativity. as organizations increasingly integrate hr ai software into their processes, it becomes imperative to establish a clear and comprehensive policy governing their deployment in the workplace. ", "# legal and ethical considerations in the era of increasingly stringent data protection regulations, organizations must prioritize the integration of generative AI, including hr ai software, within the bounds of legal frameworks. ensuring compliance with data protection laws such as the general data protection regulation (gdpr) and other regional standards is paramount. this involves meticulous attention to data storage, processing, and access controls to safeguard employee information, especially when utilizing hr ai tools. a comprehensive generative AI policy should outline the specific measures in place to protect sensitive data, defining the responsibilities of both the organization and its employees in upholding these legal obligations. ", "# key workplace generative AI policy **. guidelines for collecting and storing data** as organizations harness the potential of generative AI, including hr ai software, in the workplace, it is imperative to establish clear guidelines for the collection and storage of data. the generative AI policy should outline the types of data that will be collected and the specific purposes for which it will be utilized. striking a balance between obtaining necessary information for ai training and respecting employee privacy is essential. explicit consent mechanisms should be implemented, ensuring that employees are informed about the data collection practices and have the option to opt-out where applicable. additionally, the policy should define data retention periods, specifying how long collected information will be stored and the criteria for its eventual deletion, aligning with data protection laws and principles. **. cultivating trust through transparent ai practices** transparency stands as a fundamental pillar in the ethical deployment of generative AI within the workplace. organizations must commit to providing clear and accessible information about the use of ai systems, their capabilities, and the implications for employees. a well-crafted generative AI policy should articulate how transparency will be maintained throughout the ai lifecycle. this includes detailing the sources of data used to train ai models, the decisionmaking processes inherent in the algorithms, and the potential impact on employees\u2019 -to- experiences. transparency not only serves to demystify ai but also empowers employees with insights into how these technologies i fl i ti l th b b ildi t t d f t i lt f ithi th k l clearly defining the individuals or roles authorized to use generative AI is a pivotal aspect of a robust policy. this delineation helps prevent misuse or unauthorized access, fostering a controlled and responsible environment. the policy should explicitly specify the teams or personnel with the requisite training and expertise to operate generative AI systems. this may include data scientists, designated ai specialists, or individuals within the hr department who have undergone appropriate training on the technology\u2019s ethical use and potential implications. moreover, restrictions on access to hr ai tools and other generative AI tools should align with job responsibilities and organizational needs. access permissions should be tailored to ensure that those using generative AI have a legitimate reason to do so and are well-versed in the ethical guidelines outlined in the policy. **. employee training and awareness** organizations should implement comprehensive training programs to familiarize employees with the fundamentals of generative AI, its applications within the company, and the potential impact on their roles. training sessions can cover topics such as understanding ai-generated outputs, recognizing the limitations and capabilities of generative AI, and promoting responsible usage. effective communication is paramount in ensuring that employees are well-informed about the generative AI policy and its implications. the policy should be communicated in a clear, accessible manner, avoiding and technical language that might be challenging for non-technical staff to comprehend. utilizing multiple channels such as companywide emails, intranet platforms, and interactive workshops can enhance the reach and understanding of the policy. **. monitoring and evaluation** the dynamic nature of generative AI requires organizations to implement systematic monitoring and evaluation processes to ensure ongoing compliance with established policies and ethical standards. regular audits of ai systems should be conducted to assess their performance, identify potential biases, and ensure adherence to the defined guidelines. these audits not only serve as a preventive measure against unintended consequences but also contribute to the overall refinement of ai algorithms. these systematic monitoring and evaluation practices play a pivotal role in the continuous improvement of hr ai tools, aligning them with evolving organizational needs, industry standards, and ethical considerations. ", "# conclusion as organizations increasingly integrate generative AI into their workflows , the importance of a well-defined policy cannot be overstated. a comprehensive generative AI policy serves as a guiding framework, promoting ethical standards, transparency, and accountability, specifically in the context of ai in hr. it provides employees with clarity on the organization\u2019s approach to ai, fostering a culture of trust and collaboration. moreover, a robust policy mitigates risks, ensures legal compliance, and positions the organization to navigate the evolving landscape of ai technologies. this inclusive approach acknowledges the specific challenges and opportunities presented by the integration of ai in hr, emphasizing the need for clear guidelines and ethical considerations tailored to human resource management. _ready to take your understanding of the future of work to the next level? join us at_ _hr vision_ _, where we\u2019re bringing_ _together top hr leaders to explore the latest trends in hr, talent management, and leadership._ r e c e i v e t h e c o n t e n t h u b n e w s l e t t e r name(required) first name last name business email(required) data ) i agree to ilp events privacy policy click here to read ilp events privacy policy s u b m i t ilp events ltd shoreditch high street london, uk, e lg events@ilpevents.com ", "###### a new frontier in artificial intelligence implications of generative AI for businesses ", "#### contents **section i** decoding the generative AI magic trick **section ii** consumer and enterprise use cases for generative AI **section** **iii** commerce and competition in generative AI **section iv** adopting and commercialising generative AI **about the ai institute** ** was a watershed year for artificial intelligence** **(ai, with the release of several consumer-facing applications** **like** **/blog/chatgpt/)** **,** **[dall.e** **, and** **lensa** **.** the common theme the use of generative AI\u2013a paradigm shift in the world of ai. while current generations of ai use pattern detection or rule-following to help analyse data and make predictions, the advent of transformer architectures has unlocked a new field: generative AI. **generative AI can mimic the human creative** **process by creating novel data similar to the kind it was** **trained on, elevating ai from enabler to (potentially** **co-passenger.** in fact, estimates that more than % of all data will be ai-generated by , heralding a new age, the age of with\u2122. although early traction has been through consumer releases, which could be era-defining, **generative AI also has the potential to** **add contextual awareness and human-like decision-making** **to enterprise workflows, and could radically change how we** **do business.** we may be only just beginning to see the impact of solutions like \u2019s contact centre ai (ccai), which is designed to help enable natural language customer service interactions, and industry-specific solutions like bionemo from nvidia, which can accelerate pharmaceutical drug discovery. as such, generative AI has attracted interest from traditional (e.g., venture capital (vc), mergers & acquisitions (m&a)) and emerging (e.g., ecosystem partnerships) sources. in alone, venture capital firms invested more than $b, and technology leaders made significant investments, such as \u2019s $b stake in openai and \u2019s $m stake in anthropic. the far-reaching impacts and potential value when deploying generative AI are accelerating experimental, consumer, and soon, enterprise use cases. and **even though much media coverage** **has focused on consumer use cases, the opportunities are** **widespread\u2013and some are already here.** still, questions remain about how individuals and enterprises could use generative AI to deliver efficiency gains, product improvements, new experiences, or operational change. similarly, we are only beginning to see how generative AI could be commercialised and how to build sustainable business models. **even so, generative AI is in its infancy and not without risk.** some of the most important risks to address relate to privacy and security, managing bias, transparency and traceability of results, ip ownership, and equal access, especially for those at greater risk of job displacement. as such, participants should balance commercialisation, regulation, ethics, co-creation, and even philosophy, as well as expand the group of stakeholder thinkers and contributors beyond technologists and enthusiasts. **ultimately, generative AI could** **create a more profound relationship** **between humans and technology,** **even more than the cloud, the** **smartphone, and the internet** **did before.** various analysts estimate the market for generative AI at $b by . this represents ~% of total ai spend, up from ~% . said another way, **the market** **will likely double for .** **numbers aside, we believe the economic impact could be** **far greater. to help understand the potential, this paper** **is equal parts primer and provocateur, adding structure** **to a rapidly changing marketplace.** we start with a brief explainer of the foundational elements, delve into enterprise and consumer use cases, shift focus to how players across the market can build sustainable business models, and wrap up with some considerations and bold predictions for the future of generative AI. the ai institute helps organisations connect the different dimensions of a robust, highly dynamic and rapidly evolving ai ecosystem. the ai institute leads conversations on applied ai innovation across industries, with cutting-edge insights, to promote human-machine collaboration in the \u201cage of with\u201d. the ai institute aims to promote a dialogue and development of artificial intelligence, stimulate innovation, and examine challenges to ai implementation and ways to address them. the ai institute collaborates with an ecosystem composed of academic research groups, start-ups, entrepreneurs, innovators, mature ai product leaders, and ai visionaries, to explore key areas of artificial intelligence including risks, policies, ethics, future of work and talent, and applied ai use cases. combined with \u2019s deep knowledge and experience in artificial intelligence applications, the institute helps make sense of this complex ecosystem, and as a result, deliver impactful perspectives to help organisations succeed by making informed ai decisions. no matter what stage of the ai journey you\u2019re in; whether you\u2019re a board member or a c-suite leader driving strategy for your organisation, or a hands on data scientist, bringing an ai strategy to life, the ai institute can help you learn more about how enterprises across the world are leveraging ai for a competitive advantage. visit us at the ai institute for a full body of our work, subscribe to our podcasts and newsletter, and join us at our meet ups and live events. let\u2019s explore the future of ai together. section i: decoding the generative AI magic trick **section i** ", "#### decoding the generative AI magic trick the lofty expectations for generative AI depend on continued progress and innovation across an interconnected hardware, software, and data provider ecosystem. the tech stack underlying generative AI, however, is in some ways similar to others that came before. it consists of three layers: **t** infrastructure, platform, and applications. **infrastructure is generally accepted** s **as the most established, stable, and** **commercialised layer.** incumbents offer compute, networking, and storage, including access to specialised silicon (microprocessors) like nvidia\u2019s gpus and google\u2019s tpus optimised for ai workloads. meanwhile, the application layer is evolving rapidly and consists of leveraging and extending foundation models, which is s generative AI\u2019s equivalent of a platform. section i: decoding the generative AI magic trick generative AI tech stack ", "### **application** **ecosystem** section i: decoding the generative AI magic trick moreover, generative AI can create artifacts across various modes\u2014code, images, video, audio, and d models. **this could both disrupt and drive step** **changes in productivity across a range** **of capabilities, from copywriting to** **research and software engineering.** for example, in advertising, generative AI could create original copy, product descriptions, and images in seconds. it can generate synthetic x-ray images in healthcare, helping physician diagnostic training. indeed, generative AI could transform how businesses operate and interact with customers and may even redefine an \u201cemployee\u201d as we know it. this transformation is already underway in some consumer and enterprise spaces. **foundation models, however, are what** **differentiate the generative AI tech** **stack from ai that came before.** at its core, a foundation model, a term coined by centre for research on foundation models, is a machine learning (ml) model pre-trained on a broad dataset that can be adapted to solve a range of problems. just as \u2019s win offers apis for developers to access base-level hardware and os functions, and nvidia\u2019s cuda allows graphic-intensive applications like game engines simplified access to gpu resources, the model layer is designed to connect ambitious application developers to optimised hardware to help accelerate the adoption of and democratise generative AI. these models are often available to developers via closed and open apis, where developers can fine-tune models with additional training data to improve context, relevance, and performance to specific use cases, all while optimising delivery costs. foundation models are typically developed in four stages, which are illustrated below. **end-users** **application development** user-facing bb and bc in partnership with or on top of proprietary models **fine-tuned models** refined models for targeted use case **foundational models** open or close-source models while this framework is applicable across ai architectures, state-of-the-art foundation models (e.g., gpt-, stable diffusion, megatron-turing) are based on a neural network architecture called transformers, invented by a team at google brain in . transformers represent a step change in ml performance and differ from prior architectures in their ability to assign context, track relationships, and predict outcomes. the most mature foundation models are in the text domain, primarily driven by vast quantities of available training data, which accelerated the development of large language models (llms), a type of generative AI foundational model. llms are trained to generate text by predicting the next word in a sequence or missing words within a paragraph. **vertically integrated** **foundation models** niche proprietary models with pre-built user-facing bb or bc ", "### |l|o| |---|---| **model layer** ", "### **infrastructure/** **hardware** **hyperscale compute** compute, networking, storage, and middleware **silicon** specialised microprocessors/accelerators for training & interference development of foundation models source: deloitte **architecture** the structure and design of the model and the algorithm used for training source: deloitte **pre-training** training on a massively large dataset to create a defined set of parameters **training dataset** **fine-tuning** adjusting parameters to improve performance on specific tasks **production** deployment to production where the model is accessible via apis **curated dataset** process elements: **process** **input** **output** section ii: consumer and enterprise use cases for generative AI **section ii** ", "#### consumer and enterprise use cases for generative AI in , openai\u2019s dall - e captured the world\u2019s attention with its text-to-image capabilities. the model creates images from simple prompts, from something as direct as \u201ca lion in a jungle\u201d to something more comical like \u201ctwo lions playing basketball in the style of picasso.\u201d **efficiency** | optimising tasks like planning, research, and product discovery **instruction** | providing personalised guidance or learning content **creation** | generating or enhancing content, replicating the creative process **entertainment** | building games, virtual personas, and other entertainment this is just an early view of the market; there will likely be overlapping categories as work evolves. moreover, new, category-defining use cases are expected to emerge as future generations of ai (e.g., those that enable multi-model engagement or run entirely on-device) mature. section ii: consumer and enterprise use cases for generative AI the pace of change can make predictions challenging, but as of , we expect consumer use cases with the following aspects as having staying power: section ii: consumer and enterprise use cases for generative AI **these efficiencies may even redefine** **job expectations, making prompt** **engineering (i.e., asking ai the right** **questions) a differentiating skill set.** ultimately, horizontal use cases will create a commercial foundation for more specialised applications. enterprises must start deploying these early to help build capabilities and a knowledge base, making the value case for vertical applications over time. , some enterprises are already driving tangible returns from investments in horizontal use cases. we\u2019ve seen research teams summarise third-party information, product managers write requirements documentation, social media marketers refine copy, and customer service teams create case summaries and suggested resolutions. **however, tangible** **roi could depend on proprietary** **and serviceable data, secure model** **partitioning, talented product leaders** **and ml engineers, enabling mlops** **tooling,** and new commercial and operating models. these are investments that enterprises should evaluate, whether they see themselves as early adopters, fast followers, or late entrants. consumer use cases can also be indicators of the possibilities in the enterprise. however, unlike consumers, enterprises require advanced features, proven roi, customisation, organisational content, security, and technical support. in \u2019s formative era of generative AI, the most popular enterprise use cases\u2014invoked to drive internal or bb outcomes\u2014will be general purpose or applicable across industries or functions (\u201chorizontal\u201d). however, like technologies that came before, there are often more sustainable valuecreation opportunities in industry-specific enterprise use cases (\u201cvertical\u201d). **potential targets of horizontal use** **cases are well-established automation** **centres, offer a substantial volume of** **training data (e.g., knowledge base,** **support chat logs), and are the focus of** **cost optimisation and productivity** **improvement efforts.** for example, creative marketing tasks like writing advertising copy, blogs, or social media captioning can take hours or for humans to author. in contrast, generative AI can complete workable drafts in minutes, requiring only editing from humans. **speed to market** consumer awareness, increasingly through social media, could lower acquisition costs, allowing companies to piggyback on coverage, work out product kinks, and scale efficiently with an active and contributory user base. **occupational utility** products that create value in the workplace, like writing assistants, may be easier to fit into a sustainable business model, as opposed to products attached to a \u201chype cycle,\u201d like social media filters. **seamless integrations** solutions that integrate into platforms could be discovered through existing workflows, driving more \u201csticky\u201d adoption. grammarly was early to market with this on pcs and, more recently, openai with bing. a sampling of consumer use cases available **efficiency** **instruction** **creation** **entertainment** creating a health & wellness plan conversing with virtual companions editing creating original games video files creating personalised discovering new products financial plans creating interior design mockups chatting with pop culture figures conducting research curating outfits teaching new languages rendering d environments with editing curating content synthesising research papers design files general questions personal writing creating art & editing images remixing or sampling music generating original fictional short stories sample vendors synthesis.ai consensus grammarly lingostar.ai luminar ai lensa source: deloitte section ii: consumer and enterprise use cases for generative AI sampling of vertical and horizontal enterprise use cases section ii: consumer and enterprise use cases for generative AI in contrast, vertical use cases target industry-specific workflows that require domain knowledge, context, and expertise. **consumer &** **retail** personalised conversational retail experience **\u2022** **\u2022** customised product design & recommendation **\u2022** **\u2022** **\u2022** product details & photography generation **\u2022** **\u2022** fashion outfit curation **\u2022** **\u2022** **\u2022** personal art creation & edits **\u2022** personalised conversational retail experience **life sciences &** **health care** ar/vr content generation for digital therapy **\u2022** **\u2022** **\u2022** **\u2022** predictive & virtual patient triage **\u2022** **\u2022** d images of anatomy for education **\u2022** **\u2022** healthy & wellness plan creation **\u2022** **\u2022** **\u2022** drug discovery through molecule simulation **banking & fin.** **services** fraud simulation & pattern detection **\u2022** **\u2022** tax and compliance audit & scenario testing **\u2022** **\u2022** retail banking transaction support **\u2022** **\u2022** personalised virtual financial advisor **\u2022** **\u2022** financial reporting analysis & insight gen. **technology** **media &** **telecom** **industrial &** **manufacturing** geological assessment for oil exploration **\u2022** **\u2022** **\u2022** **\u2022** generative simulation & safety testing **\u2022** **\u2022** d env. rendering: well sites, pipelines, etc. **\u2022** automated tech. equipment training **\u2022** **\u2022** **\u2022** **\u2022** generative automation for smart factories **\u2022** **\u2022** **government &** **public sector** academic / office hours virtual assistant **\u2022** **\u2022** **\u2022** **\u2022** infrastructure mapping & planning **\u2022** **\u2022** **\u2022** disaster recovery simulation **\u2022** **\u2022** fraud, waste & abuse prevention reports **\u2022** research w/ personalised ar/ vr experience generation **\u2022** **\u2022** **\u2022** **\u2022** automated product & hardware design **\u2022** **\u2022** **\u2022** personalised & automated ui/ux design **\u2022** **\u2022** **\u2022** product testing & feedback generation **\u2022** **\u2022** original games creation **\u2022** **\u2022** **\u2022** **\u2022** **\u2022** **\u2022** trailer & summary generation **\u2022** **\u2022** **\u2022** **\u2022** script/score design & subtitle generation **\u2022** **\u2022** personalised news & content generation **\u2022** **\u2022** **\u2022** original fictional short stories generation for these, foundation models may need to be fine-tuned or may even require new specialpurpose models. for instance, generative AI can be used to create a customised portfolio of securities based on risk-reward descriptions or recommend personalised treatment plans based on a patient\u2019s medical history and symptoms. however, delivering performant vertical use cases requires a nuanced understanding of the field. in software, for example, generative AI can design composable blocks of code based on simple prompts, which requires tacit knowledge of efficient coding, coding languages, and an understanding of technical . enterprise buyers have unique purchase decisions relative to consumers, as **model** **performance (speed, relevance, breadth** **of sources) is not expected to exclusively** **drive vendor selection.** on early opinions from both advocates and naysayers, frequently cited criteria to adopt generative AI are: **ease of use** | integrations into systems and workflows via out-of-the-box connections and low/no code tooling, reducing expensive it resources and enabling frontline users. **security and privacy** | compliance with data security standards (e.g., soc , hipaa, gdpr) and role/persona-level access control over confidential data. **robust ecosystems** | broad set of development and service partners to extend, customise, and co-develop specialised data sets, use cases, and applications. **transparency and explainability** | understanding how model outputs and responses are derived and the ability to perform root cause analysis on inaccurate results. **flexibility and customisation** | ability to create parameters, train on proprietary data, and customise embeddings while maintaining privacy and ownership of data and tuning. software sales, cx & retention support **\u2022** **\u2022** self-serve hr & it functions **\u2022** **\u2022** d environment rendering: metaverse end-to-end automated customer service **\u2022** **\u2022** marketing/sales content generation **\u2022** **\u2022** customer feedback sentiment classification **\u2022** **\u2022** accessibility support (text-to-speech & speech-to-text) **\u2022** **\u2022** automated code debugging & issue resolution **\u2022** **\u2022** autonomous code generation & completions **\u2022** **\u2022** dialogue generation for virtual assistants enterprise search & knowledge mgmt. **\u2022** **\u2022** personalised targeted ads across platforms **\u2022** **\u2022** **\u2022** **\u2022** **generative AI modality** **\u2022** text **\u2022** image **\u2022** audio **\u2022** d model **\u2022** code **\u2022** others **\u2022** video source: deloitte section ii: consumer and enterprise use cases for generative AI even as new use cases emerge at an accelerating pace, we believe the market will unfold in six ways: section ii: consumer and enterprise use cases for generative AI despite its promise, myriad challenges should be overcome before generative AI can be deployed at scale. we discuss these in more detail, but there is also the question of commercial viability. in other words, for all the fascinating possibilities and use cases for generative AI, it still needs to be determined how vendors will build a sustainable business model. , there are ethical concerns with generative AI, including its potential for workforce displacement. however, **like previous generations of ai, this** **technology will likely primarily augment human** **performance.** indeed, ai could be commonplace in worker\u2019s toolkits, like workspace among analysts, github among coders, or creative cloud among marketers. regulatory actions will likely vary in speed, reach, oversight, and reporting requirements across major markets (e.g., us ai bill of rights, eu ai act, china cyberspace administration ). as ", "## such, vendors and **enterprises will** **need to proactively establish** **practices that ensure data** **quality, transparency, fairness,** **safety, and robustness, which will** **be critical to** **trustworthy ai** **.** ", "## **text-based use cases will be commercialised** **first,** but the potential **cost and productivity** **gains may be greater when commercialising** **higher-order tasks** as these skills can be more expensive to recruit, take longer to train, and are right-brain (creative) versus left-brain (logical), making success subjective. while horizontal use cases will likely be the first to deliver value, vertical-specific use cases could command a premium due to the dependence on proprietary data. as such, **data will be a currency,** **creating new economies for access to proprietary** **and synthetic data.** ", "## all industries can benefit from generative AI. however, **data-rich** **sectors** (e.g., banking, retail, hospitality) **or those whose** **products leverage data** (e.g., ", "## information services) **may move** **\u2014and should move\u2014faster.** conversely, those based on judgment (e.g., law, medicine) may be more cautious about adopting but nevertheless see the benefit by accelerating the ", "## synthesis of prior knowledge. given the shift away from low-interest rates, costs will increase, pushing enterprises to invest in use cases with clear roi. as such, **use cases that directly impact cost** (e.g., chatbots), **productivity** (e.g., search), or **revenue** (e.g., marketing copy) **could have greater adoption than** **those that eliminate humans.** section iii: commerce and competition in generative AI **section iii** ", "#### commerce and competition in generative AI the battle for value capture will be fought on multiple fronts, and each layer of the stack will have its competitive dynamics driven by things like scale, data access, brand, and a captive customer base. however, we see two primary competitor archetypes: pure-play providers operating within a single layer\u2013infrastructure, model, and application - and integrated providers that play in multiple layers. as with incumbent technology, we expect consumer pricing to be simple (e.g., per user, per month) and enterprise pricing to be more complex (e.g., per call, per hour, revenue share). however, **pricing** **simplicity, predictability, and value** **will be important to scaling within the** **enterprise beyond early adopters or** **edge use cases.** **to begin, the infrastructure layer, which** **is the most mature of the generative AI** **technology stack, is where hyperscalers** **dominate the market.** the business model here is proven: provide scalable compute with transparent, consumptionbased pricing. to help make generative AI workloads \u201csticky,\u201d hyperscalers have entered commitments with model providers to guarantee future workloads, including azure with openai, google with anthropic, and aws with stability.ai, alongside their proprietary models. section iii: commerce and competition in generative AI while the cloud service providers (csp) deliver abstracted services, there is another enabling layer within infrastructure that is rapidly evolving: silicon. here, nvidia is a leader with their ampere and hopper series gpus purpose-built for training and inference workloads, respectively, coupled with their selene supercomputing clusters that speed up training time. similarly, amd\u2019s cdna architecture is purpose-built for exascale computing on machine learning applications, advancing competition in the high-performance computing market. infrastructure layer **offering** **description** **examples** **primary customer** **primary monetisation** enterprise developer consumer model metric amazon section iii: commerce and competition in generative AI another less-considered path to monetisation could be developing and licensing model architectures or development platforms. in other industries, like semiconductors, arm (cpu) and qualcomm (wireless networking) create large, stable business models built on licensing fees. next is the model layer, where the market is evolving fast. this area can be resource intensive; model builders must continually revisit architectures (e.g., parameters, embeddings) to maintain performance. they have to attract and retain ai talent (i.e., architects, engineers, and data scientists) to design the frameworks, guardrails, and learning mechanisms to ensure the robustness and reliability of models. finally, generative AI **workloads** **can run up large bills due to their** **compute-heavy nature and need for** **specialised silicon.** no wonder we\u2019ve seen players start to recoup the investment by charging fees or integrating into monetised products (e.g., gpt-. into edge, lamda into google search). model layer **offering** **description** **examples** **primary customer** **primary monetisation** enterprise developer consumer model metric hosted and managed models built on a vast data corpus foundation models maintained by communities use case-specific versions of foundation models marketplace, community or hosting services for models proprietary architectures, synthetic data, weights, and embeddings co:here google openai closed-source model providers open-source model providers fine-tuned model providers model hubs model service providers per token yes yes no consumption per api call hyperscale and purposebuilt compute, storage, and networking specialised services to accelerate deployment (e.g., security, monitoring, testing, model isolation) purpose-built semiconductors, including gpus and cpus per minute by cpu/gpu type per hour per generation per embedding cloud service provider generative AI service providers chip provider baidu google amazon co:here google amd nvidia yes yes no consumption yes yes no consumption meta monetised via fine-tuned no yes no stability.ai models or model hubs co:here per token yes no no consumption c.ai per api call github hugging face replicate co:here mostlyai realai subscription consumption rev. share one-time subscription license per month per hour per embedding per month per user yes yes no no yes no one-time yes no no per component lease section iii: commerce and competition in generative AI finally, the application layer serves as the gateway between models and end users. 's apps are typically monetised through subscriptions and recurring transactions, a model that will likely persist, albeit with modifications suited to generative AI. section iii: commerce and competition in generative AI **competition within the application layer could** **unfold within several markets. however, given the** **wide range of applications and use cases that may** **emerge, we should look at \u201cmicro-markets.\u201d** broadly, \u2019s real and predicted enterprise use cases fall into five categories where competitive lines could be drawn: application layer **offering** **description** **examples** **primary customer** **primary monetisation** enterprise developer consumer model metric license yes yes no per user rev. share **accelerate** improve productivity by speeding up outcomes. these do not eliminate human intervention but provide high-quality inputs upon which to build. **personalise** create intimacy and personalisation, which previously would have taken signi icant effort. here, models can leverage personal data to tailor content. **automate** deliver business and technical workflows and, in certain instances, replace humans. vendors often demo these due to the immediate cost-saving potential. **create** push the boundaries of intellectual property development, leveraging prompts (a new art form unto itself) to generate novel content like images, video, text, and media. **simulate** create environments in which workflows, experiments, and experiences can be simulated before being pushed into production, saving time, cost, and physical resources. google hugging face boomy canva lensa ai art grammarly jasper sdks, frameworks, and tools to build and distribute apps platforms subscription consumption one-time per user per month per service per user per month full-feature solutions to standalone application modify workflows yes no yes extensions and features to supplement tasks and workflows subscription yes no yes consumption plugins section iii: commerce and competition in generative AI sampling of enterprise micro-markets **accelerate** **personalise** **automate** **create** **simulate** calendar mgmt./ email outreach social media marketing image/logo creation d modeling admin assistant section iii: commerce and competition in generative AI we see integration happening in two ways. first, companies like anthropic and midjourney have released applications for specific use cases. lower in the stack, companies like nvidia have released specialised models, including bionemo, a pharmaceutical pipeline development accelerator that is optimised to run on nvidia gpus. a second archetype, in contrast to pure-play providers who monetise through first- and third-party channels, are **vertically** **integrated or multi-layer players.** **these players lead with bundled pricing,** **proprietary data, special-purpose** **clouds, or cross-domain expertise** **to gain a competitive advantage.** gaming environment note taking keynote speaker notes advertising copy marketing campaigns design short-form video content marketing physical goods design support chatbots medical testing (r&d) generation integrated players **offering** **description** **examples** **primary customer** **primary monetisation** enterprise developer consumer model metric nlp-based email/ product ideation advertising video editing content summarisation chemical interactions app. responses & prd authoring basic code generation disaster response code completion personal assistant music scoring & documentation management anthropic co:here midjourney openai per month per user per service per download per hour per api call per embedding per minute by cpu/gpu type per user per month per hour model and application model and infrastructure silicon and infrastructure applications built on proprietary, first-party models fully managed infrastructure and modelas-a- service purpose-built horizontal and vertical clouds for ml workloads subscription yes no yes consumption anthropic co:here openai gpt- facebook opt gato x-clip bigscience bloom openai codex tabnine openai dall.e soundify stable diffusion cradle dreamfusion nvidia getd google yes yes no consumption nvidia source: this may have implications for the model and infrastructure layers. the vendors lower in the stack could remain relevant by creating purpose-built infrastructure, models, and services that enable innovation in micro-markets. amazon azure yes yes no consumption consumption end-to-end none yet yes no yes applications built on firstparty models and clouds subscription section iii: commerce and competition in generative AI **competitive dynamics are unfolding** **across both technical and commercial** **dimensions.** on the technical front, newer, more sophisticated silicon, datasets, and models are emerging, with some models now likely to exceed one trillion parameters. on the commercial side, things are in flux as consumer solutions gain traction (e.g., the pro version of chatgpt). in the enterprise, solutions have yet to be commercialised at scale and may continue to be hamstrung by computing costs and riskaverse adoption. as such, we offer a few considerations that organisations should evaluate when thinking of going from product to business. **\u2022** as innovations in architecture deliver diminishing returns, performance could depend on the volume and quality of training data, hitl training, and guardrails. as such, **competitive advantage will** **be driven by access to proprietary** **datasets and scarce talent.** **\u2022 while critical to the advancement of** **the field, general-purpose models may** **not capture the lion\u2019s share of value.** instead, companies that build vertical use cases and industry-focused solutions could have the most potent impact within the enterprise. **\u2022 hyperscalers will compete against** **a new generation of csps** like coreweave, targeting fungible ai workloads with custom hardware and cheaper pricing. as such, incumbents should innovate and rely on independent software vendor (isv) and system integrator (si) ecosystems to help retain a competitive advantage. section iii: commerce and competition in generative AI **\u2022 ecosystem orchestrators and system** **integrators** will continue to play an important role in assisting enterprises in preparing their data, prioritising use cases, complying with local regulations, stitching together a panoply of models and applications, and derisking adoption. **\u2022 integrated plays could have a clearer** **path to roi,** primarily due to the high costof-compute, which may be abstracted through solutions that combine infrastructure, model, and app. as supply blockages ease and new gpus emerge, however, isvs may regain value. even though generative AI will likely herald a new age of productivity, some elements could parallel previous waves of technological transformation, which can serve as a blueprint for the market. section iv: adopting and commercialising generative AI **section iv** ", "#### adopting and commercialising generative AI generative AI could transform business models, processes, and value dynamics and change how individuals work, learn, and interact. as with other disruptive technologies, this is likely to transpire slowly at first and then rapidly. take software development as an example. by some estimates, less than % of people know how to code. yet, **software** **is integral to many businesses and** **business models . generative** **ai, if harnessed strategically, can** **democratise coding and reduce the gap** **between ideas and revenue** by synthesising product requirements, converting prompts to code, auditing code to find and address bugs, suggesting code optimisations, and proactively provisioning environments optimised for test and run use cases. similarly, generative AI can optimise the end-to-end customer acquisition funnel. if you are in sales and marketing, consider demand generation, where llms could author marketing copy across channels and run digital marketing campaigns. estimates that % of outbound marketing will be synthetically generated by . further down the funnel, generative AI could gather account intelligence, create a first-call presentation, suggest a talk track to account executives, and document and track outcomes and actions. finally, generative AI could proactively suggest pricing and discounting, author a contract, and update customer and crm records. this would allow marketers and sellers to focus on higher-value activities, such as developing relationships and applying pricing judgment. we\u2019ve discussed other ways that adopters can leverage generative AI across industries (see section ), from market research to note taking and improving customer support interactions. further, there are sectorised use cases like customised financial planning for wealth managers, medical diagnoses in health care, generating new worlds and experiences in media and entertainment, and outfit curation for retailers. in fact, **the** **benefits that adopters can expect to** **achieve may be significant;** we\u2019ve offered some early thoughts below, indexed to the idea of enterprise micro-markets (see section ). section iv: adopting and commercialising generative AI **benefit** **accelerate** **personalise** **automate** **create** **simulate** **expand tam** **** section iv: adopting and commercialising generative AI **generate revenue** **reduce investment** **utilise assets** **move faster** **reduce labour input** **reduce non-labour input** **improve experience** **grow skills** **build relationships** **spur innovation** - = primary benefit, total addressable market source: deloitte section iv: adopting and commercialising generative AI with that in mind, for enterprises with a commercial interest in generative AI, we believe there are five \u201cno-regret\u201d moves to start considering . **if i am a technology provider...** **if i am an enterprise buyer/user...** section iv: adopting and commercialising generative AI generative AI does present risks, and progress and adoption may slow if these are not considered and mitigated when scaling. first, models should be continually trained to improve performance, which leads to concerns about exposure to sensitive data, privacy, and security. next, outcomes can only be as good as the quality of training. therefore, any data biases (e.g., in representation or sampling) often appear in outputs. other challenges include determining ip ownership of outcomes, high compute cost, and the need for expensive human-in-the-loop (hitl) reinforcement learning. **everyone involved in the** **development, consumption, discussion,** **and regulation of generative AI** **should strive to manage the following** **identified risks:** **erosion of trust** | malicious\u2014hallucination, deepfakes, phishing, and prompt injection \u2014and ambivalent actors\u2014not citing data sources\u2014can expose the attack surface and erode customer trust. **security and risk** | companies should stay ahead of a rapidly evolving regulatory landscape while maintaining confidentiality of data, embeddings, and tuning with inherently \u201cmulti-tenant\u201d models. **bias and discrimination** | generative AI is prone to mimicking biases and propagating discriminatory behavior if implemented without guardrails and continuous monitoring. **data privacy and ip obscurity** | models will be trained on a corpus of proprietary, often private data, requiring regulatory compliance, node isolation, and source traceability. **costs** | costs of a query/prompt using generative AI can cost up to ten times that of an index-based query. while these costs will likely come down over time, the economics should be factored into internal business cases and customer pricing to drive adoption. **long-term worker displacement** | , the highest roi use cases will augment workflows and drive productivity; however, as models advance, there may be a risk of job displacement without proper upskilling and workforce planning. take a **platform approach to monetisation** that includes models, out-of-the-box use cases, and low/no code tooling, all while building a web of ecosystem players. build solutions that **equally serve the customers** **and developers** , given the critical role the latter will play in scaling through fine-tuning apps and extensions. develop a **roadmap of verticalised solutions,** as these will flip the model from loss leader to margin capture. **invest early in cross-modal and multi-modal solutions,** as the \u201csecond and third generations\u201d of generative AI are on the horizon. allocate **funds** **to support opportunistic m&a,** including acquihires and ip-driven investments, especially if valuations remain muted. **educate the executive leadership team on the potential** **and risks** of generative AI to ensure a shared understanding and alignment on a path forward. **identify and prioritise a set of use cases,** starting with horizontal ones, especially in areas within the organisation that haven\u2019t benefited from automation. **lay out a clear technology strategy** , including data engineering and pipelines, mlops tools, and ai-ready talent. **determine sources of competitive advantage** , especially proprietary data, and begin curating these for the coming wave of generative AI use cases. **proactively engage your ecosystem of advisors and** **partners** to create a first-mover advantage, gain favorable pricing, and experiment with new solutions. section iv: adopting and commercialising generative AI ultimately, generative AI could create a more profound relationship between humans and technology, even more than the cloud, the smartphone, and the internet did before. **if you\u2019re willing to go along for the ride as** **a \u201ctrue believer,\u201d we offer four predictions,** from those likely to unfold in to those farther afield: section iv: adopting and commercialising generative AI beyond this, it can be hard to imagine where generative AI will take us, including the impact on the future of work, trust, and human-machine interaction. **however, time** **and again, new technology has allowed humans to** **conquer greater pursuits, and similarly, generative** **ai will drive an unprecedented era of human** **potential.** individuals could eventually be free from mundane, repetitive work, potentially allowing humanity to live in novel and unimagined ways. **generative AI will** **the race is not only** **llms are among** **change the future of** **for data but also** **hyperpersonalisation will** **the first forms of** ", "# **generative AI will** **change the future of** **work.** ai agents will become an indispensable utility, and widespread adoption among employees will be the new norm and accelerate the age of with\u2122. those who fail to adopt may be left behind in the workplace. **the race is not only** **for data but also** **trust.** as generative AI moves into the enterprise, it will be subject to intense scrutiny. adoption, therefore, hinges on the ability to conform to expectations\u2014both intuitive and factual\u2014and earn trust. **hyperpersonalisation will** **become a driver** **of growth.** businesses will leverage the ability to analyse large amounts of customer data to create dynamic, realtime, and tailored experiences, products, services, and communication. **llms are among** **the first forms of** **ai to be \u201cgeneral** **purpose,** **\u201d** albeit text oriented. and while we are afield from multi-model, ubiquitous, cross-domain ai, the seeds have been planted. could we now be in of artificial general intelligence (agi)? reach out for a conversation. endnotes gartner: insights for generative AI zdnet: makes contact centre ai generally available venturebeat: boosts generative AI for biology with bionemo financial times: investors seek to profit from groundbreaking \u2018generative AI\u2019 start-ups : invests $ billion in chatgpt maker openai financial times: invests $mn in artificial intelligence start-up anthropic global newswire: global generative AI market size value cap expected to grow usd . billion by  precedence research: artificial intelligence software market size & forecast \u2019s human-centered artificial intelligence: helm\u2014 centre for research on foundational models : attention is all you need, vaswani . tech crunch: now anyone can build that use dall-e  to generate images  bing (yes, bing) just made search interesting again engadget: 's openai supercomputer has , cpu cores, , gpus anthropic: anthropic partners with cloud aws: stability ai builds foundation models on amazon sagemaker forbes: provides more /sites/moorinsights////-provides-more-details-on-selene-supercomputer/?sh=eee) [on selene supercomputer tech insights: amd targets supercomputers infoworld: the cost and sustainability of generative AI venturebeat: trained a trillion-parameter ai language model : worldwide professional developer population of million projected to grow amid shifting geographical concentrations gartner: beyond chatgpt: the future of generative AI for /en/articles/beyond-chatgpt-the-future-of-generative-ai-for-enterprises) [business insider: breaking chatgpt: the ai's alter ego /open-ai-chatgpt-alter-ego-dan-on-reddit-ignores-guidelines--) [reveals why the internet is so drawn to making the /open-ai-chatgpt-alter-ego-dan-on-reddit-ignores-guidelines--) [violate its own /open-ai-chatgpt-alter-ego-dan-on-reddit-ignores-guidelines--) [reuters: for tech giants, ai like bing and bard poses billion- dollar search problem **neasa cloney** director, consulting **ncloney@.ie** **emmanuel adeleke** partner, consulting **eadeleke@.ie** **gopal srinivasan** principal, strategy & analytics, llp **gosrinivasan@.com** **rohan gupta** ** mannion** partner, consulting **mmannion@.ie** **nitin mittal** **** director, consulting **cmelody@.ie** **costi perricos** global ai & data leader, uk **cperricos@.co.uk** **** ai lead, australia **knuttall@.com.au** ai strategic growth offering leader, llp **nmittal@.com** **rich nanda** us strategy & analytics offering portfolio leader, llp **rnanda@.com** senior manager, strategy & analytics, llp **rohagupta@.com**  for an ai bill of rights  artificial intelligence act: council calls /artificial-intelligence-act-council-calls-for-promoting-safe-ai-that-respects-fundamental-rights/#:~:text=its%aim%is%to%ensure,paramount%importance%for%our%future.) [promoting safe ai that respects fundamental rights tech crunch: china\u2019s generative AI rules set boundaries and punishments for misuse the atlantic: how chatgpt will destabilize white-collar work the authors would like to acknowledge **ranjit bawa** , **irfan saif** , **manoj suvarna** , and **ivana savic vucenovic** , whose expertise was critical to bringing this article to life. the authors would also like to thank **soumyadeep bakshi** , **** , **grant griffith** , and **sachin patro,** for their invaluable research and insight, without which this publication would not have been possible. no generative AI was used in the research, authoring, publication, or promotion of this article. this publication contains general information only and is not, by means of this publication, rendering accounting, business, financial, investment, legal, tax, or other professional advice or services. this publication is not a substitute for such professional advice or services, nor should it be used as a basis for any decision or action that may affect your business. before making any decision or taking any action that may affect your business, you should consult a qualified professional advisor. shall not be responsible for any loss sustained by any person who relies on this publication. **about ** refers to one or more of touche tohmatsu limited, a uk private company limited by guarantee (\u201cdttl\u201d), its network of member firms, and their related entities. dttl and each of its member firms are legally separate and independent entities. dttl (also referred to as \u201c global\u201d) does not provide services to clients. in the united states, refers to one or more of the us member firms of dttl, their related entities that operate using the \u201c\u201d name in the united states and their respective affiliates. certain services may not be available to attest clients under the rules and regulations of public accounting. please see / about to learn more about our global network of member firms. copyright \u00a9 development llc. all rights reserved. ", "###### ioaglobal.org ", "##### ", "# ioa generative AI policy ", "###### following recent improvements in the technologies behind text, image and other types of generation, we have created this generative AI policy to guide our staff in the use of new tools. note: the growth in these technologies currently goes beyond exponential and it may be necessary to update these guidelines as new issues emerge. ", "###### . . . . . ", "###### about generative AI and the technology behind it............................................. guidelines for all uses of generative AI........................................................................ guidelines specific to text-producing generative ais....................................... guidelines specific to embedded ai.............................................................................. suitable use cases...................................................................................................................... ioa generative AI policy () approved by ioa smt effective date: review date: ", "### . about generative AI and the technology behind it generative AI is any type of ai system that can generate text, images or other types of media in response to prompts. at the time of writing, these tools use large language models, which produce a result based on a set of training data. the technology is not the same as search engine eigenvector algorithms, meaning that the results may be even less reliable than a google fact search. the technology is not the same as traditional natural language processing (nlp) chatbots, which often had human input to optimise the results for a particular use case. the training data is not usually linked to the internet or any other real-time updates in most models. therefore, any content will have no knowledge of events since the model\u2019s last extraction date, which can be anything from . these are narrow ai uses, meaning that a \u2018text generator\u2019 will produce beautiful natural language but is not optimised for factual accuracy. an \u2018image generator\u2019 will produce an impressive image but will have no ethics controls. they are not general ai models that mimic human thought, models of human ethics etc. ", "#### . streamlining processes these technologies streamline and improve processes and therefore we welcome plans to incorporate them into work in productive and ethical ways. ", "#### . pre-generative AI we have traditionally brought in machines towards the end of processes. if we imagine the humans involved in the production of a new process, represented in purple below, the machines might be brought in at the end to help to present the information in a more professional way, through spellcheck, suggested grammatical improvements, format and design. check and brainstorm select produce improve _design stages without generative AI, with human-based processes in purple and machine based_ _processes in grey._ ioa generative AI policy () approved by ioa smt effective date: review date: ", "#### . with generative AI these new technologies prompt a different way of working with content. as shown below: check and brainstorm select produce improve _design stages with generative AI show shared roles for machines and humans, with human responsibilities_ _indicated by purple and machine capabilities indicated by we might use the machines to brainstorm suggestions before beginning a new project (eg show me ways to optimise seo) or to summarise the contents of large reports that cannot be manually inspected. these suggestions could be incorporated with human-generated content. the review and selection process must always be carried out by a suitably qualified human. the production may be a mix of human and machine collaboration. for example, the generation of documentation to accompany a coding process would be done through inputting the human designed code into the machine, which then produces a natural language summary of what the code did. the human may write a report and then ask the machine to extract the key bullet points. the human may write content for a social media post and the machine will improve the language, suggest suitable hashtags and emojis etc. checking and improving in the final stages will be a combination of human and machine review. for example, a machine could generate slide show content from a report and suggest ways to visually display it effectively, but a human should also review the final result. ", "### . guidelines for all uses of generative AI generative AI should not be used for the production of the following types of media: ", "#### . when the results need to be accurate the technology that generates the content could be wildly inaccurate. we do not know where the machine found its responses and so, if accuracy matters, human design and research should be used. (nb some of the emerging tools may explain their thought process with verifiable data trails, which have more accountability but should still be checked) ioa generative AI policy () approved by ioa smt effective date: review date: ", "#### . when ownership is an issue copyright over ownership of anything produced by generative AI remains poorly defined but, as a user, you do not own the copyright on anything that you produce with these machines. the grey area is whether the owners of the data that the machines were trained on have any rights to the output. therefore, if ownership is an issue and the output will be monetised in any way, avoid these technologies completely. ", "#### . when the origin of the document is not stated whenever machine-generated content is the predominant method of production, it should be stated on the media object that the content was generated by machine. a predominantly machine-generated media could be: a slide show almost entirely generated by ai a summary of a human-written document that has not been checked for accuracy/relevance an entire article, report, etc. written by the machine a non-predominantly machine-generated media would be: a social media post that was written by a human and copy-edited by the machine a summary or bullet points of a report etc that has been checked by the original author a slide show that has been generated from a report the author has checked for accuracy ", "#### . when personal data or sensitive data is involved never put personal data (names, addresses, phone numbers) or sensitive data (data about someone\u2019s religion etc) into a generative AI tool. it is against the law in many countries and is unethical practice as once entered, it will then be shared as training data. do not enter any text in the prompt box where proprietary ownership is important (eg do not enter any form of course content). we will lose ownership rights. ", "### . guidelines specific to text-producing generative ais those generative ais that produce text response, such as the use of chatgpt or bard, create a number of additional concerns listed below. ioa generative AI policy () approved by ioa smt effective date: review date: ", "#### . do not use these technologies when the results need to be accurate the technology that generates the content works with a \u2018best guess\u2019 approach and you do not know where it got the information from. some information will be valid, but it could also be wildly inaccurate. if accuracy matters, we shouldn\u2019t use generative AI. ", "#### . do not use these technologies when the results cannot be/are not checked by a human text-based generative AI should never be used to complete a task that the human making the request could not do themselves. it is essential that all output be reviewed before incorporating the work into any kind of workflow. ", "#### . do not use these technologies when recency is an important variable unless the machine that you are using is in internet browser mode, assume that it can only incorporate information that is widely known up to the date of their extraction but not beyond that. the extraction date may be several or previous, and it is essential to use human alternatives when the main subject is emerging, such as new laws or new developments in technology unless you are in a specific browsing mode of ai. ", "#### . do not use these technologies when the contents cannot be verified in general, text producing generative ais should only be used to automate the text production that the human requesting text could produce themselves. any output must always be verifiable and verified by expert human oversight. ", "#### . do not use these technologies where nuance or depth of analysis is required the machines may be able to generically summarise common ideas shared, but they are not able to wrestle with high level or original thought. ioa generative AI policy () approved by ioa smt effective date: review date: ", "### . guidelines specific to embedded ai ", "#### . the use of embedded ai in ioa services embedded ai is the use of any ai tool, such as a chatbot, with any customerfacing service such as our website or training materials. if any member of staff would like to propose embedding an ai tool, this raises much more serious ethics questions and the proposition needs to be brought to the attention of the senior leadership team at the earliest opportunity. ", "#### . concerns ioa staff may have about non-ioa services that use embedded ai we are here to support our staff during this difficult transition to a rapidlyevolving world of ai-generated content. if you have concerns about the potential of generative AI in the field of online harms, cyber security, trust in social media etc please raise your concerns in the first instance with your line manager and we will attempt to address these and support you during this transitional phase. ", "### . suitable use cases we welcome the use of generative AI to streamline operational processes and evidence our adoption of data-driven best practice. we recommend the use of generative AI in the following circumstances providing that the conditions above have been met: producing social media content producing images for visual effect documenting processes (particularly coding or analytics) supporting coding processes/skills improvement in tools like excel etc through the use of openai guidelines, tutoring support, breaking down code into natural language etc producing presentation content from a pre-designed report summarising reports that would otherwise not be read brainstorming and planning new processes brainstorming ideas for internal campaigns (eg to promote adherence to cybersecurity principles) playing devil\u2019s advocate (by testing out the opposition to an opinion you strongly hold) ioa generative AI policy () approved by ioa smt effective date: review date: ", "## generative AI policy effective ", "## scope this policy applies to all ironclad employees, executives, consultants, agents, vendors, and other third parties who have access to company data. for purposes of this policy, these individuals will be referred to as \u201c **ironclad staff** .\u201d this policy applies to the direct use of generative AI tools by ironclad staff members, separate from any generative integrations that ironclad has embedded in its products. although ironclad may partner with companies offering ai (e.g., ironclad\u2019s integration with openai), ironclad staff\u2019s direct use of ai tools offered by these same companies is not covered by the partnership or services agreements with those companies, but is instead subject to the companies\u2019 terms of use for their ai tools. ", "## definitions the term \u201c **company data** \u201d should be interpreted broadly for purposes of this policy, and includes, but is not limited to, at least the following: all company business information and all personal data (whether of employees, executives, contractors, consultants, customers, consumers, users, or other persons) that is accessed, collected, used, processed, stored, shared, distributed, transferred, disclosed, destroyed, or disposed of by any of the company systems; all proprietary information and intellectual property (including, but not limited to, source code, designs, schematics, product roadmaps, product plans, product specifications, market analyses, white papers, strategy documents, financial information, internal communications, customer lists, customer files, customer contact information, customer contracts, customer\u2019s proprietary data, and any non-public company information. company data includes information in written, electronic, audio, video, or any other form or medium. company data can include any level of information covered by ironclad\u2019s data classification matrix. the terms \u201c **ironclad customer** \u201d or \u201c **customer** \u201d refer to any unique contracting entity listed within an active order form with ironclad, including all individuals acting on the entity\u2019s behalf. the term \u201c **customer data** \u201d refers to any and all data that the third parties who contract as customers with ironclad provide to ironclad to use, store, transmit, or process. ", "# principles for the use of ai ironclad staff should observe the following principles when using ai: **compliance with legal and regulatory requirements** ironclad staff must comply with all applicable laws and regulations governing the use of ai. this includes compliance with data protection and privacy laws, intellectual property laws, and anti-discrimination laws. **protection of data privacy and security** ironclad staff must ensure that they protect data privacy and security when using ai. the use of ai tools and applications must comply with the company\u2019s data privacy and data security policies. **human backstop** ironclad staff must carefully review ai-generated material for inaccurate or incomplete information and potential infringement of third-party rights. you are ultimately responsible for all content produced with the assistance of ai, as if you were the original creator. the source of ai-generated material should be disclosed when appropriate. ", "# guidelines for the use of ai ", "## required actions - before using any generative AI tool for any company business, you must opt out of letting generative AI tools use any data you feed the tool to train their ai models (opt out for openai via this link ). - before using any generative AI tool for any company business, consult ironclad\u2019s data classification matrix to determine the classification of the data you intend to feed into the tool, to determine if it is too sensitive to share. - carefully review ai-generated material for accuracy, completeness, and protection of both third-party rights and ironclad\u2019s proprietary information. ", "## how you may use generative AI - if you use ai for authorized, company-related activities, you must use accounts created with ironclad email addresses/credentials. - your usage of ai must comply with this policy, ironclad\u2019s code of business conduct and ethics, and the confidentiality obligations in employment documentation signed by ironclad staff at the time of hire. - you may only use data with generative AI tools that is legally obtained and used with the necessary permissions. - you may only use data with generative AI tools that is not confidential, highly confidential, or restricted, as defined by ironclad\u2019s data classification matrix. - you may only use vendor integrations or products featuring generative AI that have been approved by the legal and security teams. - you must report any security incidents or suspected breaches immediately to security@ironcladhq.com and legal@ironcladhq.com. ", "## prohibited use of ai - do not use personal accounts with ai tools for company-related purposes. - do not use customer data with generative AI tools. - do not use any company data classified as confidential, highly confidential, or restricted information (as defined in our data classification matrix). - do not use personally identifiable information (e.g., people\u2019s names, addresses, emails) with generative AI tools. - do not use generative AI tools for company-related purposes if you have not opted out of letting generative AI tools use any data you feed to the tool to train their ai models. ", "# enforcement the chief information security officer (\u201c **ciso** \u201d) and security team will verify compliance to this policy through various methods, including but not limited to, business tool reports, and internal and external audits. any exception to the policy must be approved by the ciso and general counsel, or designees, in advance. any ironclad staff member found to have violated this policy may be subject to disciplinary action, up to and including termination of employment or engagement, or legal action where appropriate. ", "# document control ", "## document owner chief information security officer ", "## revision history |effective date|version|contributors|notes| |---|---|---|---| |--|.|ciso, , legal, it|created| ", "## researchers compare ai policies and guidelines at news organizations around the world ", "###### artificial intelligence is informing and assisting journalists in their work, but how are newsrooms managing its use? research on ai guidelines and policies from media organizations from around the world offers some answers. by | | artificial intelligence technology \ue900 \ue907 \ue903 \ue90b **republish this article** in , just a few newsrooms around the world had guidelines or policies for how their journalists and editors could use digital tools that run on artificial intelligence. , dozens of influential, global newsrooms had formal documents related to the use of ai. in between, artificial intelligence research firm openai launched chatgpt, a chatbot that can produce all sorts of written material when prompted: lines of code, plays, essays, jokes and news-style stories. and founded openai in  , with multibillion dollar investments over the years from . newsrooms including usa , the atlantic, national public radio, the canadian broadcasting corporation and the financial times have since developed ai guidelines or policies \u2014 a wave of recognition that ai chatbots could fundamentally change the way journalists do their work and how the public thinks about journalism. research posted during september  on preprint server socarxiv is among the first to examine how newsrooms are handling the proliferating capabilities of ai-based platforms. [/media/working-papers-research-articles/) have not undergone formal peer review and have not been published in an academic journal, though the current paper is under review at a prominent international journal according to one of the authors, [ bj\u00f6rn /universitaet/fachbereiche-faecher/fachbereich-iii/faecher/kunstgeschichte/alumni/dr--bjoern-becker-) , a lecturer at trier university in germany and a staff writer for the newspaper frankfurter allgemeine zeitung. the analysis provides a snapshot of the current state of ai policies and documents for news organizations, including newsrooms in brazil, india, north america, scandinavia and western europe. notably, the authors write that ai policies and documents from commercial news organizations, compared with those that receive public funding, \u201cseem to be more fine-grained and contain significantly more information on permitted and prohibited applications.\u201d commercial news organizations were also more apt to emphasize source protection, urging journalists to take caution when, for example, using ai tools for help making sense of large amounts of confidential or background information, \u201cperhaps owing to the risk legal liability h i b i d l \u201d h i ethics across the documents, as well as real world examples of ai being used in newsrooms \u2014 plus, how the findings compare with other recent research. ", "##### ai guidance and rules focus on preserving journalistic values ai chatbots are a type of generative AI , meaning they create content when prompted. they are based on large language models , which themselves are trained on huge amounts of existing text. (openai rivals google and meta in have announced their own large language models). so, when you ask an ai chatbot to write a three-act play, in the style of norwegian th playwright henrik  , about the struggle for human self-determination in a future dominated by robots, it is able to do this because it has processed \u2019s work along with the corpus of science fiction about robots overtaking humanity. some news organizations for have used generative AI for published stories, notably the associated press for simple coverage of earnings reports and college basketball game previews. others that have dabbled in ai-generated content have come under scrutiny for publishing confusing or misleading information. the authors of the recent preprint paper analyzed the ai policies and guidelines, most of them related to generative AI, to understand how publishers \u201caddress both expectations and concerns when it comes to using ai in the news,\u201d they write. the most recent ai document in the dataset is from , dated . the oldest is from the council for mass media, a self-regulatory body of news organizations in finland, dated . \u201cone thing that was remarkable to me is that the way in which organizations dealt with ai at this stage did exhibit a very strong sense of conserving journalistic values,\u201d says becker. \u201cmany organizations were really concerned about not losing their credibility, not losing their audience, not trying to give away what makes journalism stand out \u2014 especially in a world where misinformation is around in a much larger scale than ever before.\u201d other early adopters include the and german broadcaster bayerischer rundfunk, \u201cwhich have gained widespread attention through industry publications and conferences,\u201d and \u201chave served as influential benchmarks for others,\u201d the authors write. journalists interact with and use ai, says  crum , a doctoral candidate at and another co-author. but a few were prescriptive policies, crum says. among the findings: just over % of the documents mention one or more journalistic values, such as public service, objectivity, autonomy, immediacy \u2014 meaning publishing or broadcasting news quickly \u2014 and ethics. nearly % of the ai documents were designed for editorial staff, while most of the rest applied to an entire organization. this would include the business side, which might use ai for advertising or hiring purposes. one policy only applied to the business side. and % mentioned ai pitfalls, such as \u201challucinations,\u201d the authors write, in which an ai system makes up facts. about % specified the guidelines would be updated at some point in the future \u2014 % of those \u201cspecified a particular interval for updates,\u201d the authors write \u2014 while % did not indicate if or when the policies would be updated. around % of the documents cautioned journalists to be careful to protect sources when using ai, with several addressing the potential risk of revealing confidential sources when feeding information into an ai chatbot. some % allow journalists to use ai to gather information and develop story ideas, angles and outlines. another % disallow this use, while half do not specify. meanwhile, % allow journalists to use ai to alter editorial content, such as editing and updating stories, while % disallow do not specify. only % state how the ai policies would be enforced, while the rest did not mention accountability mechanisms. ", "##### how the research was conducted the authors found about two-thirds of the ai policy documents online and obtained the remainder through professional and personal contacts. about two-fifths were written in english. the authors translated the rest into english using deepl, a translation service based on neural learning , a backbone of ai. they then used statistical software to break the documents into five-word blocks, to assess their similarity. it\u2019s a standard way to linguistically compare texts, crum says. he explains that the phrase \u201ci see the dog run fast\u201d would have two five-word blocks: \u201ci see the dog run,\u201d and \u201csee the dog run fast.\u201d first block of five words would be the same, the second block different \u2014 and the overall similarity between the documents would be lower than if the sentences were identical. as a benchmark for comparison, the authors performed the same analysis on the news organizations\u2019 editorial guidelines. the editorial guidelines were a bit more similar than the ai guidelines, the authors find. \u201cbecause of the additional uncertainty in the [ai] space, the finding is that the ai guidelines are coalescing at a slightly lower degree than existing editorial guidelines,\u201d crum says. \u201cthe potential explanation might be, and this is speculative and not in the paper, something along the lines of, editorial guidelines have had more time to coalesce, whereas ai guidelines at this stage, while often influenced by existing ai guidelines, are still in the nascent stages of development.\u201d the authors also manually identified overarching characteristics of the documents relating to journalistic ethics, transparency and human supervision of ai. about nine-tenths of the documents specified that if ai were used in a story or investigation, that had to be disclosed. \u201cmy impression is not that organizations are afraid of ai,\u201d says. \u201cthey encourage employees to experiment with this new technology and try to make some good things out of it \u2014 for example, being faster in their reporting, being more accurate, if possible, finding new angles, stuff like that. but at the same time, indicating that, under no circumstances, shall they pose a risk on journalistic credibility.\u201d ", "##### ai in the newsroom is evolving the future of ai in the newsroom is taking shape, whether that means journasts primarily using ai as a tool in their work, or whether newsrooms become broadly comfortable with using ai to produce pubcly facing content. the journast\u2019s resource has used dall.e  , an openai product, to create images to accompany human-reported and written research roundups and articles. journasts, editors and newsroom leaders should, \u201cengage with these new tools, explore them and their potential, and learn how to pragmatically apply them in creating and devering value to audiences,\u201d researcher and consultant david caswell writes in a  report for the reuters institute for the study of journasm at . \u201cthere are no best practices, textbooks or shortcuts for this yet, only engaging, doing and learning until a viable way forward appears. caution is advisable, but waiting for complete clarity is not.\u201d earnings reports. but recently, the organization\u2019s ai guidenes released during specify that ai \u201ccannot be used to create pubshable content and images for the news service.\u201d the ap had partnered with ai-content generation firm automated insights to produce the earnings stories, the verge reported in . the ap also used automated insights to generate more than , previews for ncaa division i men\u2019s basketball games during the . , futurism staff writer frank landymore wrote that tech news outlet cnet had been pubshing ai-generated articles. over , axios\u2019 tyler buchanan /local/columbus////dispatch-gannett-ai-newsroom-tool) usa was pausing its use of ai to create high school sports stories after several such articles in the columbus dispatch [went viral for pecuar phrasing, such as \u201ca close encounter of the athletic kind.\u201d and on , futurism pubshed an article by maggie harrison citing anonymous sources alleging that sports illustrated has recently been using ai-generated content and authors, with ai-generated headshots, for articles on product reviews. senior media writer of wrote the next day that the \u201cstory has again unsettled journasts concerned about ai-created content, especially when you see a name such as sports illustrated involved.\u201d the group, which pubshes sports illustrated, posted a statement on /sinow/status/) the futurism article was pubshed, denying that sports illustrated had pubshed ai-generated articles. according to the statement, the product review articles produced by a third-party company, advon commerce, were \u201cwritten and edited by humans,\u201d but \u201cadvon had writers use a pen or pseudo name in certain articles to protect author privacy \u2014 actions we strongly condemn \u2014 and we are removing the content while our internal investigation continues and have since ended the partnership.\u201d on , the group fired its ceo. \u2019s board of directors \u201cmet and took actions to improve the operational efficiency and revenue of the company,\u201d the company said in a [brief statement , which did not mention the ai allegations. several other high level group executives were also fired , including the coo, according to the statement. many of the pocies reviewed for the preprint paper take a measured approach. about half i j i f di b h d k i ----- for example, reporters may obtain voluminous government documents, or have hundreds of pages of interview notes or transcripts and may want to use ai to help make sense of it all. at least one pocy advised reporters to treat anything that goes into an ai chatbot as pubshed \u2014 and pubcly accessible, becker says. crum adds that the research team was \u201cagnostic\u201d in its approach \u2014 not for or against newsrooms using ai \u2014 with the goal of conveying the current landscape of newsroom ai guidenes and pocies. ", "##### themes on human oversight in other recent research becker, crum and their coauthor on the preprint, felix simon , a communication researcher and doctoral student at , are among a growing body of scholars and journalists interested in informing how newsrooms use ai. in , hannes cools and northwestern university communications professor ) published an article for the [generative AI in the newsroom project , which diakopoulos edits, examining publicly available ai guidelines from newsrooms . cools and diakopoulos read the documents and identified themes. the guidelines generally stress the need for human oversight. cools and diakopoulos examined ai documents from many of the same newsrooms as the preprint authors, including the cbc, insider, reuters, nucleo , wired and mediahuis , among others. \u201cat least for the externally facing policies, i don\u2019t see them as enforceable policies,\u201d says diakopoulos. \u201cit\u2019s more like principal statements: \u2018here\u2019s our goals as an organization.\u2019 as for feeding confidential material into ai chatbots, diakopoulos says that the underlying issue is about potentially sharing that information with a third party \u2014 openai, for example \u2014 not in using the chatbot itself. there are \u201cversions of generative AI that run locally on your own computer or on your own server,\u201d and those should be unproblematic to use as a journalistic tool, he says. \u201cthere was also what i call hybridity,\u201d diakopoulos says. \u201ckind of the need to have humans and algorithms working together, hybridized into human-computer systems, in order to keep the investigations.\u201d for local and regional newsrooms interested in developing their own guidelines, there may be little need to reinvent the wheel. the paris charter , developed among organizations and initiated by [reporters without /en) , is a good place to start for understanding the fundamental ethics of using ai in journalism, diakopoulos says. ", "##### examples of ai-related newsroom guidelines click the links for examples of media organizations that have created guides for journalists on using ai to produce the news. has your newsroom posted its ai guidelines online? let us know by sending a link to clark_merrefield@hks.harvard.edu. bayerischer rundfunk | bbc | financial times | the guardian | /how-insider-newsroom-will-use-ai--) | [wired ", "#### clark merrefield clark merrefield joined the journalist\u2019s resource in after working as a reporter for newsweek and the daily beast, as a researcher and editor on three books related to the great recession, and as a federal government communications strategist. he has been selected for fellowships in juvenile justice and solitary confinement at the john jay college of criminal justice and his work has been awarded by investigative reporters and editors. @cmerref **know your research** recognize high-quality research; investigate scientific misconduct and research errors; and avoid missteps when reporting on new studies and public opinion polls ", "##### email newsletter \uf465 subscribe. it\u2019s free! sign up for our free newsletter! you\u2019ll receive a update of important new resources to inform your news coverage and consumption. ", "##### editors\u2019 picks **[)** **,** **[/politics-and-government/)** ", "### why people think the economy is doing worse than it is: a research roundup between how national economies are doing and how people perceive economic performance. **)** **,** **[environment** ", "### el ni\u00f1o: what it is, how it devastates economies, and where it intersects with climate change this research-based looks at how el ni\u00f1o stunts global and regional economic growth and what climatologists know about how climate change affects ----- **criminal /criminal-justice/)** **,** **[)** **,** **[/politics-and-government/)** **,** **[race & gender** ", "### abortion pill mifepristone: an explainer and research roundup about its history, safety and future amid pending court cases and ballot initiatives, journalistic coverage of medication abortion has never been more crucial. this piece aims to help inform the narrative with scientific evidence. ", "# sign up to receive a e-mail newsletter from the journalist's resource. |email address|col| |---|---| ||| ||| first name last name i'm not a robot recaptcha /en/policies/privacy/) - [terms submit is committed to protecting your personal information. by completing this form, you agree to receive communications from the journalist's resource and to allow hks to store your data. hks will never sell your email address or other information to a third party. all communications will include the opportunity to unsubscribe. a project of 's shorenstein center , _the_ _journalist\u2019s resource_ curates, summarizes and contextualizes high-quality research on newsy public policy topics. we are supported by generous grants from the carnegie corporation of new york , the  wood ) , [grants/journalism-grants/) [management () foundation and individual contributors. **home** | **about** | **how to make a donation to the journalist\u2019s donate-journalists-resource/)** | **[rss** | **know your research** | **/eea privacy disclosures** find us: unless otherwise noted, this site and its contents \u2013 with the exception of photographs \u2013 are licensed under a attribution-noderivatives . international (cc by-nd .) license. that means you are free to republish our content both online and in print, and we encourage you to do so via the \u201crepublish this article\u201d button. we only ask that you follow a few basic guidelines . ", "# generative AI acceptable use policy __ the exploration and use of generative AI / open ai / chat tooling (from this point forward referred to as generative AI) by employees of maergo is permitted and in fact encouraged for work-related purposes. generative AI is a new, exciting, and powerful tool that can assist in various aspects of work, including but not limited to writing, research, analysis, and customer service. at maergo, we embrace new technologies and encourage our teams to leverage them to improve efficiency and effectiveness, and enable the achievement of our objectives. however, it is vitally important that employees use generative AI responsibly while remaining compliant with all existing company policies and all applicable laws. we are committed to providing a safe and secure environment for our employees, partners, and customers and this includes our responsible use of generative AI tooling. this policy outlines the guidelines and principles that employees must follow when using generative AI capabilities. the company developed these guidelines so that we can experience the benefits of generative AI tooling while ensuring its utilization is secure and aligned with our expectations for conduct and our internal data privacy controls. **guiding principles** there are two main principles that guide the maergo approach to generative AI and the entirety of this policy centers on these ideas: . generative AI should be used to assist employees in their work, not perform their work. . all existing company policies apply to the utilization of generative AI. **generative AI should be used to assist employees in their work, not perform their** **work.** employees are responsible for their work product and are expected to carefully review any output received through generative AI. utilizing generative AI well includes writing prompts with care, reviewing output, verifying output, editing output, and providing feedback to the tool if it got something wrong. **all existing company policies apply to the utilization of generative AI.** this means that the company has determined that all current policies apply to an employee\u2019s use of generative AI, including but not limited to the employee proprietary information agreement, as well as all company policies pertaining to confidential information; intellectual property; bias, harassment, and discrimination; fraud and other illegal activities. **prohibited use** while maergo allows and encourages utilization of chatbots/large language models (llms) such as chat, autonomous ai agents including but not limited to auto, godmode ai, and agent are not by default approved for company use. due to the functionality, failure modes, and risks associated with autonomous ai agents, utilization is prohibited unless a request is made and approved by the vice president, product and engineering and the executive leadership team. as of the writing of this policy, maergo does not permit the use of generative AI in the candidate selection process in any way that would replace or substantially assist in the decision-making responsibilities of our hiring teams. prohibited use of generative AI includes but is not limited to screening or comparing candidate data, profiles, or resumes. generative AI may be used to assist with various components of the recruitment process such as assisting with the drafting job description language and suggesting potential interview questions. as of the writing of this policy, maergo does not permit the use of generative AI to directly communicate or interact with any other person through bots or any similar technology. generative AI may be used to assist with drafting or editing of communications but may not be used for direct communication with others internal or external to maergo. as previously stated in this document, all current policies apply to the utilization of generative AI. for the purposes of reinforcing this expectation, we are providing the following illustrative examples of activities that are strictly prohibited and constitute serious violations of company policy. these following will result in disciplinary action, up to and including termination of employment. . sharing company confidential and proprietary information in a generative AI chat or by any other means sharing or entering this information into a generative AI tool. . sharing customer or partner confidential information in a generative AI chat or by any other means sharing or entering this information into a generative AI tool. . sharing personally identifiable information (pii) in a generative AI chat or by any other means sharing or entering this information into a generative AI tool. . using generative AI in a way that is not professional and respectful of others including using generative AI to engage in any form of discrimination, harassment, or other inappropriate behavior. . using generative AI to engage in any activity that violates maergo's policies. . using generative AI to engage in illegal activity, including but not limited to fraud, intellectual property theft, and copyright infringement. for clarity, entering confidential information into the tool is prohibited without regard to how the information is shared. the means of sharing may include, but is not limited to, direct entry, copying and pasting, uploading, video, voice, or any other means of sharing. further, entering confidential information is prohibited whether or not the entry is saved. only information that is generally publicly available may be entered into generative AI tooling. if employees are unsure about whether or not information is confidential, they are expected to ask a member of the people or legal team prior to sharing such information generative AI. **security measures** utilization of generative AI for any work-related purpose should always be done through an account associated with an employee\u2019s maergo.com email address rather than a personal email address. as with any system that is used by maergo employees, those using generative AI must ensure that their login credentials are kept confidential and not shared with anyone. in case an employee suspects any breach of security or unauthorized use, they must report it immediately to a member of the people or legal team. **reporting** employees must report any suspected violations of this policy, or any incidents related to the misuse of generative AI tooling, to the maergo people team. all reports of suspected violations or incidents will be investigated promptly and thoroughly and as confidentially as possible. employees must cooperate fully with any investigations related to suspected violations or incidents where generative AI has been applied. maergo prohibits retaliation against any employee who reports or participates in an investigation of a possible violation of our code of conduct, our policies including this policy, or the law. if you believe you are being retaliated against, please contact the chief people officer or general counsel. maergo reserves the right to review any communications sent through or information shared with generative AI tooling for the purpose of investigating suspected violations or incidents. this includes but is not limited to messages, prompts, attachments, and files. **financials of usage** at present, there are free generative AI tools available that are sufficient to allow for the utilization outlined in this policy. the company will not pay for or reimburse employees for premium subscriptions or other costs associated with generative AI tooling. a business case for an exception request will require the approval of the vice president, product and engineering and the executive leadership team. **review of this policy** maergo will review this acceptable usage policy as needed to ensure it remains relevant and effective, in line with our risk appetite for generative AI use cases. any changes or updates to this policy will be communicated to all employees. maergo reserves the right to make changes to this policy at any time, without notice. employees are encouraged to ask questions or for clarification on this policy. employees are also encouraged to provide feedback on this policy and offer suggestions for changes or improvements. **acknowledgement** by using the generative AI in relation to their work at maergo, employees acknowledge that they have read and understood this policy and agree to comply with it. failure to comply with this policy may result in disciplinary action, up to and including termination of employment. ", "# usage of generative AI policy ", "## \u2022 approved by the client lead for accuracy. create stories by speeding up brainstorm-based idea generation e.g. \u201csuggest stories about the ", "## \u2022 impact of genetic testing on privacy\u201d \u2013 but all suggestions would need to be evaluated by the client team and the sources used should be disclosed to the client where appropriate. summarise a news story \u2013 but make sure you\u2019ve actually read the article yourself and you\u2019re ", "## \u2022 confident the summary is accurate. experiment with using ai as a research or analytical tool in a similar way to using google search ", "## \u2022 or wikipedia \u2013 but links back to original sources would need to be followed and double checked for any facts or data points used in client work. but you mustn\u2019t use ai to: share confidential information \u2013 because not only will you be in breach of your employment ", "## \u2022 contract with pagefield, you don\u2019t know where the data you\u2019re sharing could end up. name a specific client \u2013 when giving instructions to a generative AI programme, don\u2019t mention ", "## \u2022 the client in question. for example, don\u2019t say \u201cpagefield,\u201d say \u201ca medium sized integrated communications and campaigns agency based in london.\u201d rely exclusively on ai-generated output \u2013 always fact check everything generated by ai as you ", "## \u2022 don\u2019t know the sources it used to create the content; it could be biased or plagiarised. ", "### our policy if you choose to use generative AI for work purposes, we ask that you do so transparently, with accountability, and fully in line with the safeguards set out in this policy. you are the author and held accountable for the work you produce. this policy applies to all employees who use generative AI programmes on company-owned devices or networks or on their personal devices when conducting business on behalf of pagefield and associated clients. . employees must use ai programmes responsibly and for legitimate business purposes only, and only for the purposes for which they were designed and intended. . employees must be transparent about their use of generative AI for work purposes and acknowledge the generative AI programme as a source when used with the relevant client lead and colleagues as relevant. . employees must always verify data produced via generative AI. it should never be used as a single source of the truth and only to supplement additional research or writing methods. . employees must safeguard the confidentiality, integrity, and availability of company information at all times. company information relating to pagefield, its clients or associated organisations and individuals, or information that could reasonably be used to identify pagefield or its client(s), or a commercially sensitive course of action should never be entered into generative AI technology without the express permission of the client and client lead. . employees must not disclose company information or trade secrets to any third party, including ai programmes like chatgpt, bard and midjourney. . any suspected data leaks or breaches must be escalated immediately to jacqui beaumont, our nominated data protection officer, in line with our data protection and privacy policies. . employees must not use ai programmes to engage in activities that could damage the reputation of the company or violate the rights of others. . employees must not use ai programmes to create or disseminate malicious software or engage in hacking or other unauthorised activities. . employees must report any suspicious or unauthorised use of ai programmes to management immediately. . employees must remain vigilant for the malicious use of generative AI by scammers. do not share any sensitive information in your conversations. the company reserves the right to investigate any suspected breaches of this policy, which may subsequently result in disciplinary action, up to and including dismissal. it is essential that employees use these tools responsibly and in accordance with company policies and legal requirements. this policy is intended to promote the safe and ethical use of ai programmes and protect the interests of the company and its stakeholders. technology and the law change regularly, and this policy will be updated to account for changes as and when necessary. employees will be informed when the policy has changed, but it is their responsibility to read the latest version of this document. ", "## wipro\u2019s policy ", "# responsible use and development of generative AI **purpose** generative AI (generative AI) technology is rapidly advancing, and tools are becoming increasingly available. while generative AI can provide significant benefits to an organization in terms of productivity enhancement and revenue generation, it also poses risks to privacy, cybersecurity, intellectual property, third-party/client engagements, legal obligations, and regulatory compliance. this policy aims to forge a responsible usage, deployment and development of generative AI across wipro, harness the advantages that the generative AI technology bring whilst mitigating the risks and challenges, and provide guidelines for responsible usage, deployment and development of generative AI tools for internal use and client engagement. **scope** this policy covers usage, deployment and development of generative AI tools and technology. this policy does not override any policy, process and guidance related to privacy, data protection, code of business conduct, intellectual property, and confidentiality. for example, any use case related to the deployment of generative AI for internal utilization (e.g., to optimize hr processes, sales, and marketing campaigns, etc.), must undertake all the existing procedures, including security assessment, intellectual property and confidentiality due diligence, and privacy assessment when personal data is involved. this policy is a living document as it reflects the fast-evolving nature of technology, which we embrace in a responsible, human-centric, sustainable and privacy preserving manner, in full adherence to the spirit of wipro. **policy details** generative AI refers to artificial intelligence systems that have the capability of generating new content (such as images, text, audio, codes, presentation, etc.) based on the data they were trained on. while generative AI can revolutionize the way we operate, there are inherent risks associated with this technology. these risks include but are not limited to: - **privacy and data protection.** generative AI tools require large datasets thus pose issues related to data minimization and legal basis for processing data. these are core privacy law tenets now recognised all across the globe, and ones we must abide to. in addition, these tools present risks around fairness in both processing and outputs; opacity around the workings of generative AI may clash with transparency and informational right requirements. finally, there are challenges around accuracy as generative AI tools may produce false information. - **security and confidentiality.** through generative AI, attackers may generate new and complex types of malware, phishing schemes and other cyber dangers that can avoid conventional protection measures. such assaults may have significant repercussions like data breaches, financial losses, and reputational risks. in addition to personal data leakage risks, the use and development of generative AI is also susceptible to data inference attacks, data poisoning and other forms of adversarial attacks that may compromise the security and confidentiality of data. - **intellectual property and enterprise proprietary information.** all aspects of generative AI from the model, training data, prompts, to output pose ip risks namely: `o` _infringement of ip rights:_ the training data used to train the generative AI models could include copyrighted material and if the output of these models is the similar (or a derivative work) or in rare scenarios, the exact same as the input training data, then this could potentially infringe on copyright laws. generative AI could inadvertently use or refer to trademarked products, brands or logos that could also be seen as infringing on those trademarks. the machine authored output could also be very realistic fake images, videos, or texts, which could be used to infringe on someone's copyright. the prompts used to interact with generative AI systems may contain copyright-protected information, which could lead to infringement. `o` _unclear ownership_ : the issue of ipr (intellectual property rights) protection for machine authored content is an unclear, complex and evolving area of law. when integrated into wipro or client owned ip, it can result in downstream ip licensing and/or enforcement risks and challenges. `o` _attribution:_ ai generated content can be almost indistinguishable from human generated content and as such can lead to a risk of humans not getting due credit and attribution as the rights holder of their work. - **misinformation.** generative AI can produce biased or inaccurate outputs and potentially lead to poor decision-making and legal or ethical consequences. generative AI can also create content and represent facts even if they don\u2019t exist. in addition, the outdated data on which it is trained can lead to inaccurate predictions, poor recommendations. - **consumer protection.** businesses that fail to disclose usage of large language models to consumers run the risk of losing customer trust and be charged with unfair practices under various laws (e.g. the california chatbot law mandates that in certain consumer interactions, organizations must disclose clearly and conspicuously that a consumer is communicating with a bot.) **guidelines** to mitigate the above-mentioned risks and to comply with internal policies and ai related legislation, the following guidelines must be adhered to in the () usage, () deployment and development of generative AI tools and technology. **.** **guidelines for users** users of generative AI (\u201cusers\u201d) refers to personnels accessing and utilizing generative AI tools for enhancement of their job or for client delivery. users must adhere to the guidelines prescribed below. - personal data should not be entered on generative AI tools including but not limited to: chat, bard, co-pilot, , dall-e. personal data include names, addresses, phone numbers, or any other information that could be used to identify an individual. note that personal data may differ across jurisdictions. - users must avoid using language or content that may have proprietary customer, partners and wipro\u2019s confidential information or mention of our customers, leadership team etc. - users must clearly indicate content that is generated by generative AI tool to avoid confusion with human-generated content. users must acknowledge the source of any ideas or insights generated by the tool. - generative AI tools can only be used for client projects if approved by clients or if the use is allowed as per client contract. similarly, client enterprise data including personal details should not be used in generative AI without client approval. - account teams should reach out to _genai taskforce_ to obtain clearance for the usage generative AI tools in all new and existing client engagement. - generative AI tools that are not approved by wipro for enterprise-wide use should not be used for any activity. - any generative AI use case must be reviewed and approved by generative AI steering committee (generative AI steerco) before implementation or deployment. users must submit a generative AI use case review request to _genai taskforce._ - any generative AI use case involving personal data and/or has an impact to the data privacy rights of individuals must undergo a data protection impact assessment. - apis should not be used to transmit sensitive and/or confidential data to generative AI systems. **.** **guidelines for deployers and developers** deployers and developers (\u201cdevelopers\u201d) of generative AI refers to personnels engaged in the deployment or development of generative AI which may include but not limited to: generative AI application using apis ( rd party), transfer learning from existing open source models to inhouse models as the technology become accessible. developers of generative AI must adhere to the following guidelines and to the guidelines prescribed to users. developers must adhere to privacy and data protection laws and must ensure alignment to globally accepted frameworks such as and nist (national institute of standards and technology) frameworks. developers must adhere to the defined rules around key requirements, such transparency, fairness (refer to addendum . privacy by design checklist for ai/ml completeness). a data protection impact assessment in collaboration with the global data privacy team must be completed during the design phase or initial/ideation stages of the development of generative AI. c. privacy by design approach must be adopted from conception stage to deal with issues such as data collection, legal basis, human oversight, informational rights, automated decision making. d. developers must comply with defined mechanisms for regular checks and must complete an audit of the system before deployment, and at regular intervals. e. to mitigate security and confidentiality risk, deployers and developers must: - only use public data to train the ai system and maintain the anonymity of data - adopt the use of secure coding, protect access to ai system only to authorized users, - align data protection standards on training data and sensitive user input to encrypt and store securely, - perform regular security assessment to identify and address vulnerabilities in generative AI system f. deployment and development generative AI tools for client delivery should be done only if approved by the client or if it is allowed as per client contract. similarly, client enterprise data including personal details should not be used in generative AI without client approval. g. account teams should reach out to _genai taskforce_ for advisory on deployment or development of generative AI tools in all new and existing client engagement. h. developers must comply with intellectual property policies and standards and ensure that there is no copyright infringement. i. should the system fall under the coverage of (directly or indirectly marketed in europe), developers must refer and adhere to the dedicated sections in the act. j. generative AI-generated source code must undergo thorough testing and validation before integration into internal applications. ii. generative AI-generated source code for internal applications: a. developers responsible for incorporating generative AI-generated code must maintain a comprehensive documentation trail to aid in debugging and troubleshooting. reviews must be conducted to ensure adherence to coding standards, as well as to maintain code quality and security. iii. generative AI generated code for shipment to clients/customers: a. clear differentiation must be made between generative AI-generated code and human-generated code in customer-facing applications or products. must be informed about the utilization of generative AI-generated code and any limitations associated with it. iv. generative AI-generated code by third-party generative AI services: a. thorough due diligence must be conducted before employing third-party generative AI services, assessing their credibility, security measures, and compliance with applicable regulations. contracts or agreements with third-party generative AI service providers must include clauses addressing data privacy, intellectual property rights, and liability. audits or assessments should be performed to ensure that third-party generative AI services meet the enterprise's established standards. v. generative AI-generated code by open-source models: a. usage of open-source models must comply with the relevant licensing terms and conditions. before using open-source models in production environments, a comprehensive evaluation must be conducted to identify and address security vulnerabilities, bias, and ethical concerns. attribution and acknowledgment must be provided for the open-source models employed. **other** **responsibilities** - generative AI tools should not be used to create adverse effect to wipro, customer, entities data and infrastructure. - issues or concerns, such as unauthorised access or data breaches should be reported in accordance with wipro security incident reporting process. - users of generative AI systems must always adopt a critical mindset and be able to validate the outcomes as such tools may compute inaccurate or false information. - in case of any doubt reach out to the _genai taskforce_ for assistance. **function responsibilities** |generative AI task force|\u2022 define and govern policy for the responsible use, deployment, development of generative AI \u2022 drive awareness on the responsible use, deployment, development of generative AI \u2022 leverage wipro\u2019s investment to enable various functions and the use cases.| |---|---| |cto / lab|\u2022 provide thought leadership and advisory on generative AI technology and w ipro\u2019s generative AI offerings| |bits|\u2022 deploy tools and solutions and controls to actively detect and monitor any risk to wipro or client data and ip as a result of usage of generative AI. \u2022 report breaches to the generative AI task force along with root cause analysis and mitigation actions taken \u2022 deploy cybersecurity solutions as defined by ciso| |ciso|\u2022 define cybersecurity controls to protect wipro infrastructure from probable attack vectors and threats powered by generative AI. \u2022 define security controls to protect generative AI models and associated data against misuse and unauthorized use. \u2022 provide audit and governance over controls by bits on generative AI \u2022 cyber security assessments during vendor onboarding to account for generative AI risks| provide training and awareness on cybersecurity risks around generative AI |legal and intellectual property|\u2022 define controls and processes to identify and mitigate risks to intellectual property as a result of usage, deployment and development of generative AI. \u2022 provide advisory if any clauses on ipr and liabilities arising from usage or development of generative AI should be addressed in client, vendor, contractor and partner contracts.| |---|---| |erm|\u2022 define an audit plan to check for usage, deployment and development of generative AI during account audits.| |data privacy|\u2022 define a framework for assessing generative AI use cases that involves the use of personal information. \u2022 dp assessments during vendor onboarding to account for generative AI risks \u2022 provide training and awareness privacy risks around generative AI| |functions and delivery teams|\u2022 function and delivery compliance teams are to perform checks and audit w here generative AI is leveraged in their units.| **definitions:** . **generative AI -** generative AI refers to an artificial intelligence system that have the capability of generating new content based on the data they were trained on. generative AI become extremely popular after the release of chat. however, it is worth highlighting that generative AI has a wide variety of applications beyond text. for example: - text: generative AI model can generate new text content, e.g., write essays, generate new code, or translate from one language to another. such models are trained on massive amount of text data from various sources. - image: generative AI models can generate new images. for example, style transfer applications where you can upload your photo and it generated a monet style portrait of your photo. - audio: generative AI models can generate new audio content. for example, generative AI models were used to complete beethoven\u2019s th symphony. . **natural language processing (nlp)** - is an arch of computer science techniques that enables computer to understand text and provide inference in the same way that human would. . **large language model (llm)** \u2013 llms represent a core component of nlp, a tool to enable ai to mimic human performance in understanding language. llms are large models (millions of parameters) that are trained on massive amount of data. . **generative pretrained transformer ()** \u2013 refers to a subset of llm models that uses an underlying neural network architecture called transformers and is trained on a large body of data to perform wide variety of tasks such as text summarization, question answering, etc. is the underlying model for chat. . **transfer learning** - transfer learning refers to the process of transferring the knowledge of general models trained on large, general data sets to a more specialized models that aim to solve a specific problem of interest. . **fine tuning** - fine tuning is the process/technique used for transfer learning and it refers to fine tuning the general \u201cpretrained\u201d models by resuming their training on specialized data sets. **approvals/escalation matrix** any deviation or non-compliance to this policy must be immediately reported to _genai taskforce._ furthermore, should an employee be made aware of any suspicious activity involving the use of generative AI, such as but not limited to unauthorised access, misuse, and unauthorized disclosure of data, he/she must report it immediately report it as a security incident. ", "# generative AI acceptable use policy ", "## purpose the policy serves the following purposes: **** **** **** ensure responsible and ethical use of generative AI technology. protect sensitive information, including company secrets, customer secrets, and personally identifiable information (pii). maintain the integrity and reputation of the organization and the commitment to data privacy and security. ", "## scope the policy applies to all instances of generative AI use, encompassing text, image, video, and audio generation, for any purpose related to the organization. ", "## usage guidelines employees, contractors, and third-party service providers must adhere to the following guidelines: **** **** **** **** do not input proprietary or confidential information into generative AI systems, including company secrets, customer secrets, or pii. verify the accuracy, reliability, and relevance of any ai-generated content before using it officially. use generative AI technology solely for authorized business purposes and in compliance with applicable laws and regulations. immediately report any unintended exposure, misuse of sensitive information, or security breaches involving generative AI technology to the relevant supervisor or security team. ", "# generative AI acceptable use policy ", "## employee acknowledgment all employees must acknowledge their understanding and agreement to comply with this policy by signing an acknowledgement form. failure to abide by this policy may result in disciplinary action, up to and including termination of employment. ", "## training and awareness rsi security will provide comprehensive training and resources to ensure employees are well-versed in this policy and the responsible use of generative AI technology. regular updates and refresher training sessions will be conducted to maintain awareness and compliance. ", "## policy review and updates this policy will be reviewed and updated periodically to address changes in generative AI technology, legal requirements, and the organization\u2019s business needs. employees will be notified of any updates and are required to adhere to the updated policy. ", "## want to learn more about generative AI and how rsi security can help ? request a consultation today ", "# six steps for writing a generative AI policy ", "## employees might already be creating content with new tools, so in-house counsel should take the lead to get a policy in place before risks mount, experts say. published [/editors/rfreedman/) lead editor _laurence via getty images_ don\u2019t wait until you hear from employees that they\u2019re using generative AI in their work; be proactive and create a policy governing use of the new technology, attorneys say. lawyers at one company initiated a process to write a policy after hearing employees were already using it, phan of law firm troutman pepper said in a webcast hosted by the firm \u201cthe legal folks learned just through water cooler chat that folks were starting to use ai,\u201d she said. \u201cthey were fortunate enough to have a company that has the resources to devote to thinking about this.\u201d companies are playing catch-up because employees are ahead of them on use of the technology, said , also of troutman pepper. \u201cthis is probably most companies right now,\u201d he said. generative AI differs from more familiar versions of the technology by using information provided in prompts to create, rather than analyze, content. lawyers have started using it in some cases to write the first draft of a brief or non-legal communication, among other things. ", "## starting the process to write a policy governing generative AI use for your organization, there are six steps in-house teams should consider, phan said. the first is to let everyone at the organization know you\u2019re planning the policy so once you get going the process won\u2019t be a surprise. \u201cthe first communication needs to be about transparency, leading your employees toward the direction as a top-down approach your company wants to take,\u201d she said. you\u2019ll want to assemble a team from all of the parts of the organization that will be touched by the technology. it can make sense for legal and hr to take the lead, but also important are it, r&d, communications, marketing and sales. the team should come to agreement on the organization\u2019s risk tolerance because that will help determine the depth and breadth of the policy. technology companies that have been using ai for a while might be expected to be more risk tolerant than others, but nailing this down for your organization is crucial. \u201ccompanies have different appetites for risk, but this is a starting point,\u201d said wakiyama. ", "## surveying stakeholders in the next step, develop a survey to send to employees to learn how they\u2019re already using generative AI, if they are, and under what scenarios they would like to use it and not use it. \u201cthe survey may even differ from department to department,\u201d said wakiyama. \u201cso, put out your survey \u2013 you can use an electronic survey tool for that \u2013 and gather the results so you\u2019re making the decision based on actionable information.\u201d as responses come in, the team can devise scenarios for how the technology should and shouldn\u2019t be used. \u201care those the right use cases for our company?\u201d said phan. \u201cthe critical stakeholders \u2013 legal, hr, it, others \u2013 get together and think about that.\u201d based on her work with clients, phan said, she\u2019s seen a range of use cases, especially that apply to coders in engineering. \u201cthey\u2019re treating generative AI the same way they might incorporate open source coding data into their systems,\u201d she said. coders have been quick to adopt ai because it can help them work faster, said gerard lewis, former deputy general counsel at comcast. \u201cthey\u2019ve used it for rapid prototyping and deployment of new technologies,\u201d said lewis in the webcast. \u201cit lets developers create quickly and get something stood up in record time to see if an idea or logic flow works.\u201d outside of engineering, other use cases that are being tried include first drafts of documents. \u201cthey\u2019re using it to produce an initial draft of internal or customer service communications, with some human intervention to tailor it,\u201d phan said. \u201cand the marketing team is using it for jingles, slogans and other content.\u201d ", "## policy outline once the team has developed, vetted and received approval on a list of use cases, it should create a policy outline that it sends around to get buy-in from leadership and stakeholders. \u201cthe outline is critical,\u201d said wakiyama. \u201cit\u2019s the foundation for the policy. share it with all the stakeholders and those who need to put the policy out there in the field and answer questions about it.\u201d when the outline has been given wide exposure, the team drafts the policy, which should include a list of acceptable and prohibited uses. it should also highlight the process employees follow to get exceptions approved. \u201cmaybe you\u2019re ok with employees exploring, figuring out what makes sense for them,\u201d said phan. \u201cmaybe you want to have more level of control or you want employees to vet new use cases with you.\u201d you don\u2019t want the exception process to be too rigid, otherwise you risk employees ignoring it and experimenting with generative AI outside the policy. \u201cemployees [could] try to circumvent the process and then you have non-compliance,\u201d she said. so you want the process to be smooth \u2014 \u201ca documented way for employees to acknowledge the prohibition but still take a clear path to get an exception.\u201d the policy should also include sections on recordkeeping and use logs, security, privacy, ip rights and new tools. ", "## iterative process setting up a process for recordkeeping and administering a use log can be burdensome but they\u2019re needed for measuring how the organization is using generative AI and whether it\u2019s having an effect on operations. \u201cunless this information is collected, it\u2019s difficult for the organization to know if the use of ai is beneficial,\u201d said wakiyama. \u201cand if someone asks about it \u2014 a commercial insurer, for example \u2014 if they have that on a questionnaire for commercial insurance, the organization won\u2019t have the information if it\u2019s not being kept on an ongoing basis.\u201d once the policy is out, you want to disseminate it the way you would any other policy. that could mean an email blast to all employees or something else. training is also important, both to help ensure employee compliance but also as a way to get buy-in. \u201cwe know employees often don\u2019t read policies in full, so training can enhance adoption and compliance,\u201d said wakiyama. the last piece is about keeping the policy updated. that could mean going out on a regular basis with the survey to learn how employees are using, or are wanting to use, the new tools. updating could also include adding new acceptable or prohibited uses, incorporating regulatory compliance as needed and making sure the policy doesn\u2019t conflict with your organization\u2019s other policies. \u201cit\u2019s an evolving area,\u201d said wakiyama. \u201cit\u2019s new in terms of case law, regulations. it\u2019s changing . we\u2019re seeing new cases, early decisions. the policy [should] evolve along with the ai landscape, and as the organization obtains feedback on how and where it\u2019s being used, you can update accordingly.\u201d ", "# the transformative power of generative AI ", "### supercharged productivity or mass joblessness? in brief - artificial intelligence (ai) technologies, particularly generative AI, appear likely to revolutionize the way we work, innovate and create. generative AI can create novel, human-like output across various domains, making it highly versatile and intuitive \u2013 it even helped us draft parts of this paper \u2013 and as such, it has the potential to become a \u201cgeneral-purpose technology\u201d like the steam engine and computer, transforming the global economy. - the most positive economic implication of ai disruption will likely be accelerating labor productivity after of near stagnation; estimates of the potential impact span a wide range, though most analyses posit .%-.% per year globally over . a boost to labor productivity should result in a similar boost to real gdp. - we expect a large share of ai\u2019s productivity impact to come from automating many tasks humans currently do , helping to offset increased retirements, but the potential to accelerate innovation could make productivity gains even more significant. - ai will also have significant implications for labor. automating some tasks means needing fewer human workers to produce the same output, which could result in transitional job displacement, put downward pressure on wages and increase income inequality. however, if ai technologies stimulate demand, the creation of new jobs and higher overall economic growth should offset job displacement. - ai may fundamentally change the way we, as humans, drive value in the workplace, requiring us to focus on the skills where we have a comparative advantage. these changes may be rapid and unpredictable, increasing the importance of career flexibility, re-training and effective action from governments. - for markets, ai-driven productivity gains are likely to be positive for corporate earnings and equity returns ; implications for bonds are more ambiguous, though we think the most likely impact is modestly higher yields. - we remain humble in our projections of the economic and market implications of ai technologies, given tremendous uncertainty over how powerful and capable they can become, what kinds of unforeseen innovations and industry transformations they\u2019ll cause and, ultimately, how governments and society will respond. ", "## the transformative potential of generative AI artificial intelligence (ai) \u2013 or the process of making machines smart \u2013 has existed in some form since , making occasional headlines, like when the chess-playing ai deepblue beat in . in , ai has quietly become more prevalent in our day-to-day lives, predicting arrival times of our online delivery orders, populating our social media feeds with personalized ads and filtering spam from our email inboxes. such applications of \u201ctraditional\u201d ai (also known as \u201cnarrow\u201d or \u201cweak\u201d ai) can be very advanced, even exceeding human expert levels, but they are trained to perform only in specific domains. generative AI is the latest stride in ai development, and by contrast, its key ability is to generate novel, openended content. the recent launch of several generative AI applications ( exhibit ) has brought this technology to the fingertips of the masses and captured global attention. the most popular of these applications take the form of chatbots, like chatgpt, powered by large language models (llms) that string together words based on patterns in vast troves of text data, such as significant slices of the internet. by training related models on other forms of unlabeled, unstructured data, ranging from photographs to the entire bodies of work exhibit : generative AI tools can revolutionize the way we create and interpret diverse forms of data |col|writer|coder|visual artist|mathematician| |---|---|---|---|---| ||writer|coder|visual artist|mathematician| |applications|\u2022 \u0007openai gpt-* () and * () which power chatgpt \u2022 \u0007google palm* () and palm * () \u2022 \u0007anthropic claud * ()||\u2022 \u0007openai dall-e () \u2022 \u0007midjourney () \u2022 \u0007stable diffusion ()|\u2022 \u0007google minerva* ()| |capabilities|writes novel, high-quality responses to prompts that are often indistinguishable from human writing. it can write a college essay, explain a joke, summarize a book, or help draft an email.|writes functional code in various languages from a specification. for existing code, it can explain, debug, and analyze (e.g., calculating time complexity).|creates high-quality images\u2014photorealistic or artistic\u2014based on written descriptions. early progress has also been made on generating video.|solves complex numerical problems at the college level in subjects including algebra, physics, number theory and machine learning.| ||describe what generative AI is in four bullets that rhyme.|write a python function that takes as input a file path to an image, loads the image into memory as a numpy array, then crops the rows and columns around the perimeter if they are darker than a threshold value\u2026|give me an image of a pomeranian sitting on a throne, wearing a crown, with two tiger soldiers by his side.|assume that variance of the first n natural numbers is and the variance of first m even natural numbers is . compute m+n.| ||\u2022 \u0007generating content, a skill so humans, it\u2019s quite sublime,\u200b \u2022 \u0007from art to text, it can \u0007machine learning models, it does relate|import numpy as np import cv def crop_dark_perimeter (image_path, threshold=): ", "# load the image using opencv image = cv.imread(image_path) if image is none: ...||variance of first n n - natural numbers is variance of first m even (m - ) natural numbers is n - (m - ) so, = and = solving for n and m, we get n = and m = . so, m + n = .| source: , openai, morgan asset management. *-, , palm, palm , claud , and are all large language models (llms). note that all the responses here \u2013 including the image \u2013 are totally original ai creations. \u0007 \u0007 structured data is highly organized and made up mostly of tables with rows and columns that define their meaning, such as excel spreadsheets. unstructured data is everything else, such as the substantial contents of email messages, books, customer service recordings, images, memes and powerpoint presentations. of famous artists, generative AI technologies can create high-quality content spanning a wide range of domains: image, video, audio, text, computer code and even entirely synthetic datasets. whereas traditional ai technologies might be able to identify photos with \u201cbumble bees\u201d in them, generative AI could produce a photorealistic image of a bumble bee wearing a hat or write a children\u2019s story about a bumble bee learning to fly. as whimsical as these examples sound, this difference matters because the open-ended nature of these tasks represents so much of what we humans do for work (and tend to think ourselves uniquely capable of doing). generative AI may still be in its infancy, but the technology has advanced to an extent that we can begin to imagine its transformative implications across the global economy. if a program can author a fictional story about a bumble bee, then it could write a movie script \u2013 or at least help automate a big part of the process \u2013 a real concern of screenwriters in the united states . to be sure, screenwriters account for a vanishingly small share of u.s. jobs, but generative AI can also help software engineers write and debug computer code, lawyers research legal opinions and draft contracts or scientists read and summarize dense research papers. visual and auditory generative AI technologies might likewise automate tasks for jobs ranging from graphic designers to video editors. while generative AI is named for its functional differentiation from traditional ai, we think the more economically significant distinction is how general it is. when we start to tally what generative AI could do across the whole economy ( exhibit ), the potential impact seems massive. to be sure, the output of generative AI applications is imperfect , with chatbots like chat occasionally even including \u201challucinations\u201d of false information. many applications are therefore likely to require a layer of human supervision, especially where the costs of mistakes are high, such as in medicine. however, further progress in developing generative AI might reduce some of these existing imperfections, and even supervised ai could still significantly boost human workers\u2019 output. there is also plenty that generative AI technology \u2013 or any form of ai \u2013 cannot yet do. interacting with the physical world is still one large obstacle. while robotics has made many impressive advances in (with the notable exception of driverless cars), these systems are designed to perform specific tasks and typically require higher investment and maintenance costs in proportion to their potential output. the robot prototype designed to make guacamole for chipotle, \u201cautocado,\u201d may quicken the food assembly line, but it cannot also fill a customer\u2019s cup or wipe down tables. even so, in an information age with lots of desk jobs, non-physical problems are a big part of what we do. before generative AI, no other technology has arguably had as much potential to automate so much of our work. such potential has sparked both public excitement and fear \u2013 the excitement of ridding ourselves of mundane and time-consuming tasks through automation, but also the fear of losing our jobs and livelihood. in this publication, we seek to answer a few key questions: is generative AI truly transformational? could generative AI become the next \u201cgeneral-purpose technology,\u201d like the steam engine and computer? what does broad-scale automation mean for labor markets? and, if ai can make us all a lot more productive, what impact will that have on the economy, inflation and financial markets? more like a steam engine than a smartphone, economically speaking generative AI will have broad implications for the economy, but its most significant may be accelerating labor productivity after of near stagnation. labor productivity \u2013 total output per unit of labor input \u2013 has been the main driver of u.s. economic growth over or more. however, productivity growth stagnated in , registering just .% per year on average. have seen plenty of technological advancements that have improved many aspects of our lives, yet productivity statistics have told a different story. \u0007 \u0007 generative AI has the potential to handle a broader, more general range of tasks compared to conventional ai, but it is still not artificial general intelligence (agi). agi, an unattained concept, refers to machine intelligence capable of performing any intellectual task humans can do. exhibit : generative AI has the potential to accelerate efficiency, quality improvement and innovation across industries **writing** **software engineering** **health care** everyday workers using generative AI chatbots can reduce time spent on common writing tasks by as much as % and enhance output quality. even economists can be -% more productive. software developers can complete manual and repetitive coding tasks up to twice as fast when using generative AI tools, increasing their ability to tackle new and more complex challenges. generative AI can help nurse practitioners in clinical processes and decision-making , enabling them to take on advanced tasks from primary care physicians; ai chatbots have even been shown to outperform average doctors in answering real patient questions. **architecture and construction** **marketing** **education** architects can rapidly output designs for new buildings subject to precise constraints, including optimal energy usage. marketers can leverage generative AI to brainstorm creative ideas, including suggesting new brand names and logos based on descriptions and criteria. educators and students can employ generative AI to develop tailored and interactive content and exercises for personalized learning experiences. source: morgan asset management. this disconnect may be due to a few factors. foremost, although advances like smartphones and online media have made huge impacts on our daily lives, since they do so at a relatively low cost to consumers, they have limited impact on the market economy (various studies show a willingness among many consumers to pay for such services they receive for almost free). additionally, by distracting workers and delivering \u201cinformation overload,\u201d they may detract from productivity in other activities. some growth disappointment may also simply be due to mismeasurement in government statistics of the real value of new forms of software and human and organizational capit generative AI, by contrast, may be the advancement that finally ushers in a large, sustained boost to productivity. first, the broad-scale automation of existing activity \u2013 producing similar outputs with less labor input \u2013 should, essentially by definition, result in a more directly measurable productivity impact. \u0007 \u0007 using chat for mid-level professional writing tasks allowed workers to reduce time spent by % and improve output quality by . standard deviations. see noy, shakked, and . \u201cexperimental evidence on the productivity effects of generative AI,\u201d science , no. , . \u0007 \u0007 korinek estimates, based on use cases for language models, that economists can be -% more productive using large language models. see korinek, . \u201clanguage models and cognitive automation for economic research,\u201d . \u0007 \u0007 a mckinsey study found that developers using generative AI can increase task completion speed by -% for lower complexity tasks and were -% more likely to complete higher complexity tasks with time savings. similarly, research by found that % of surveyed developers felt more productive, % felt more \u201cin the flow\u201d and % spent less mental effort on repetitive tasks when using the ai-powered copilot. see deniz et \u201cunleashing developer productivity with generative AI,\u201d , ; and kalliamvakou, . \u201cresearch: quantifying copilot\u2019s impact on developer productivity and happiness\u201d the blog, . \u0007 \u0007 louis raymond et , \u201cnurse practitioners\u2019 involvement and experience with ai-based health technologies: a systematic review,\u201d applied nursing research , . \u0007 \u0007 in one study on patient questions randomly drawn from a social media forum, chatbot responses were preferred over physician responses and rated significantly higher for both quality and empathy. see et , \u201ccomparing physician and artificial intelligence chatbot responses to patient questions posted to a public social media forum,\u201d jama internal medicine , no. . \u0007 \u0007 see, for instance, , , avinash collis, and felix eggers, \u201cusing massive online choice experiments to measure changes in well-being,\u201d proceedings of of the united states of america , no. , . \u0007 \u0007 , , , and , \u201cartificial intelligence and the modern productivity paradox: a clash of expectations and statistics,\u201d . even more profound implications for productivity, output and welfare gains could come if generative AI is the tipping point that enables ai to become the \u2018generalpurpose technology\u2019 of . like earlier general-purpose technologies, such as electricity, the steam engine and the internet, generative AI could fundamentally change how a wide range of goods and services are produced, transform industries and create entirely new jobs, owing to its potential to: - \u0007 be pervasive. its general capabilities mean generative AI can be integrated in many different contexts to supplement or replace many activities currently done by humans. - \u0007 spawn complementary technologies and infrastructure. companies across industries are rushing to adopt ai in their fields, and the development of ancillary business applications is necessary to fully leverage ai\u2019s benefits. as we discuss later in this paper, generative AI may also enhance the performance of existing \u201ctraditional ai\u201d technologies and vice versa. - \u0007 experience exponential growth and economies of scale. ai\u2019s computing workload has been doubling every three to four months since and is likely to accelerate even further. openai\u2019s - and were released apart, and the latter is significantly more complex, can interpret images received as inputs, is % more accurate in its responses and scores significantly higher percentiles on many standardized tests. - \u0007 reshape industries. broad-scale automation will reshape the nature of jobs and business models, with transformative implications across industries. - \u0007 accelerate innovation. ai has the potential to accelerate research and development and unlock new insights that inform and inspire innovation efforts. many leaders in the field think this may be ai\u2019s paramount application. innovating innovation itself expanding on that last point, generative AI\u2019s greatest potential might not be in merely automating what humans do, but in enhancing human efforts to create novel solutions to all sorts of real-world problems. such efforts could lead to considerable productivity and welfare gains beyond automation. simply making workers more efficient could perpetually accelerate technological progress. for generative AI specifically, further upside likely lies in its ability to: - \u0007 quickly sift through vast datasets. in a world of \u201cinformation overload,\u201d generative AI can be a potent filtering tool, automating many of the time-consuming tasks in research and development. - \u0007 unlock new ideas and insights that inform researchers of where to concentrate their efforts. generative AI can analyze vast troves of unstructured data, something that is virtually impossible for humans to do, and in doing so can identify new patterns, reveal insights and discover better ways of doing things. - \u0007 conduct comprehensive predictive and evaluative analyses on new ideas. ai can improve the accuracy of our predictions and models, or even provide a sounding board for new ideas. try prompting chat to list the pros and cons of your latent business idea, for instance. joining forces with \u201ctraditional\u201d ai: greater than the sum of its parts while generative AI technologies are currently in vogue, have seen the proliferation and refinement of many \u201ctraditional\u201d ai technologies that have been trained to perform specific tasks very well. these tasks tend to be the kind where generative systems still fall short, particularly in the performance of accurate predictive modeling, numerical calculations and optimization. mckinsey estimates that these applications will account for a majority of the overall potential economic value added from ai. \u0007 \u0007 bresnahan and trajteg first coined the term \u201cgeneral purpose technology\u201d () to describe technologies that drove new eras of technological progress and growth. s are characterized by pervasiveness, inherent potential for technical improvements and \u201cinnovational complementarities,\u201d giving rise to increasing returns-to-scale. see bresnahan, , and , \u201cgeneral purpose technologies \u2018engines of growth\u2019?,\u201d journal of econometrics , no. , . \u0007 \u0007 open ai\u2019s - and refer to generative pre-trained transformers (not to be confused with \u201cgeneral-purpose technology\u201d), which are the family of neural network models that power generative AI applications like chat. \u0007 \u0007 has trillion parameters compared to -\u2019s billion parameters, enabling many of the improvements in on processing and generating text with greater accuracy and fluency. see openai, \u201c\u201d /. \u0007 \u0007 , , and lindsey raymond, \u201cgenerative AI at work\u201d, . \u0007 \u0007 . \u201cthe economic potential of generative AI: the next productivity frontier,\u201d . **beyond generative AI, traditional ai is still delivering major solutions: some examples** predicting the complex folding structure of proteins is one of the most exciting use cases of non-generative AI. in , scientists have determined the structure of , proteins, a small number in proportion to the millions yet undiscovered. this arduous task is an important part of drug discovery, but it can take to execute. deepmind\u2019s alphafold is now carrying out the same task in minutes with unprecedented accuracy, a milestone in the application of ai to scientific research with immediate potential to advance drug development, biological research and our understanding of diseases at a molecular level. environmental sustainability is another notable application of ai systems. ai systems are increasingly helping optimize energy production, storage, distribution and use. in , \u2019s deepmind developed an ai framework which reduced energy usage for data center cooling by %. more recently, ai systems are aiding clean energy transitions. whereas traditional weather models fare poorly at predicting clouds, ai systems trained on satellite and weather data could help solar grid and wind turbine operators optimize power generation and reduce fossil fuel energy held as reserve. in the united kingdom, open climate fix is currently working with the country\u2019s electric grid operator to better forecast cloudy british weather. source: morgan asset management. integrating generative and traditional ai systems could yield value far beyond what each alone could deliver, since each has its own strengths and weaknesses. no generative AI systems could achieve the accuracy of alphafold\u2019s predictions or estimate the exact hours of sunshine . both abilities required specialized training on structured datasets. a generative AI chatbot like chat even struggles with some simple quantitative reasoning. ask it to multiply two large numbers and it is likely to produce a close but incorrect answer. however, chat is fully capable of writing computer code to perform the very same calculation. simply granting such chatbots access to code interpreters might be one way to supply the correct answer \u2013 not unlike calculators help humans solve math problems that most of us couldn\u2019t solve in our own heads. but why stop there? generative AI chatbots could draw on the vast library of specialized traditional ai tools, from mathematics engines to commute time-forecasting models, that have already been quite capable for over a decade \u2013 one by one, expanding their capabilities. already, openai is privately testing several such additions to chat. some of these applications might be highly specialized. for instance, \u2019s approach to integrating generative AI into its terminal allows users to prompt a system that is especially fluent in matters of finance, tapping into of financial data collection and development of specifically trained models that tackle matters of financial complexity. indeed, we often hear now that \u201cenglish will be the coding language of the future,\u201d and it seems likely to be in many cases. \u0007 \u201calphafold,\u201d deepmind, accessed . \u0007 \u201cdeepmind ai reduces data centre cooling bill by %,\u201d deepmind, accessed , -. \u0007 \u201csun in their ais: nonprofit forecasts solar energy for uk grid,\u201d , =. \u0007 even \u2019s , a language model that achieves improved performance by gathering training data primarily from scientific papers, still makes simple mistakes with high frequency. see \u201c: solving quantitative reasoning problems with language models,\u201d research (blog), . \u0007 \u201cchat plugins,\u201d openai, , . \u0007 shaohua wu et , \u201c: a large language model for finance,\u201d (), . beyond written english, all these capabilities could be made more accessible by incorporating speech recognition and synthesis, areas where traditional ai already excels (along with handwriting and image recognition; see exhibit ). we can imagine, for instance, verbally requesting a conference room smart assistant to draw a new logo idea and display it on a screen, without the need for typing. in comparison to the current generation of \u201csmart assistants\u201d that rely on users\u2019 remembering pre-trained command phrases, generative AI could make interacting with all these modules truly conversational experiences. considering that we already spend an estimated % of our total work time communicating with one another, being able to communicate just as seamlessly with machines opens the door to working alongside them. a digitalized speed of adoption ai\u2019s implications for economic growth and societal change can be profound, but the other factor to consider is timing. although generative AI has suddenly become dinner-table conversation, its ultimate power and impact will not be seen for some time, though this may take place faster than with earlier transformative technologies. technological breakthroughs can take considerable time to raise productivity, with the peak impact of many industrial and post-industrial era technological breakthroughs, including general-purpose technologies, often only coming after - . in , famously quipped, \u201cyou can see the computer age everywhere but in the productivity statistics;\u201d in that case, a significant impact did ultimately show up in productivity statistics, albeit over ( exhibit ). exhibit : traditional and generative AI capabilities are increasingly comparable to those of humans test scores of ai relative to human performance initial performance for each ai capability set to - - - - - ai systems perform better than humans ai systems perform worse |human performance, as the benchmark, is set to |col|col|col| |---|---|---|---| |handwriting recognition|||| ||||| ||reading recognition|||| |image recognition||language understanding|| source: , , yixin nie et , \u201cdynabench: rethinking benchmarking in nlp,\u201d proceedings of the conference of the north american chapter of the association for computational linguistics: human language technologies, association for computational linguistics, june ; morgan asset management. published online at ourworldindata.org. licensed under cc-by under the author . this lag owes to the considerable time it can take to: () establish wide-scale familiarity and access to the technology, () reshape business models to integrate the technology, () achieve a sufficiently large capital stock of it and () develop complementary innovations and infrastructure that allow for full benefits of the technology to be harnessed. exhibit : past general-purpose technologies have taken considerable time to deliver gains in labor productivity, which has been the main engine of u.s. gdp over the labor productivity growth rolling ized rate - \u0007 generative AI is very accessible and easy to use for the average person, and its rapid accession to the mainstream is a testament to this fact. chat shattered records by amassing million users in , compared to the time it took tiktok () and instagram (two and a half ) to reach the same milestone. - \u0007 generative AI is in the making, with considerable progress already made. while much of the public hadn\u2019t heard about generative AI until , its most notable underlying innovations were developed in . meanwhile, of advancement in cloud infrastructure and an explosion of data and computing power have helped train these systems. - \u0007 massive business investment has already been made... in the five ending in , global business investment in all types of ai grew more than sixfold in real terms, with the united states leading the pack at $bn invested. from to , the share of businesses that have adopted ai, and the number of ai capabilities used, more than doubled. moreover, compared to some earlier technologies, generative AI infrastructure and service providers are bearing a larger share of the necessary capital investments potentially increasing adoption rates by lowering the financial barrier for end users. - \u0007 ...and more is underway to integrate ai or develop applications for business use. company management teams are increasingly focused on ai, with % of s&p management teams mentioning ai in their earnings calls, up from % ( exhibit ). these businesses are rushing to develop ai infrastructure and applications across a wide range of domains, with many launched or in the development pipeline. the surge in investor interest has propelled hefty gains for stocks; the global ai market is currently valued at $bn and projected to grow to $.tn by . .% .% .% .% .% .% .% .% .% .% |development of personal computer electric motor: invented: |col|col|col|col|col|col|col|col|col| |---|---|---|---|---|---|---|---|---|---| ||||||||||| ||||||||||| ||||||||||| ||||||||||| ||||||||||| ||||||||||| ||resulting productivity boom||||||||| source: bls, , morgan asset management. data from reflect productivity data for the total private economy from , \u201cproductivity trends in the united states,\u201d . data from reflect non-farm productivity data from the bls. data are as of , . we think that ai adoption could be faster. over time, an increasingly digitized world has helped accelerate the pace of technological adoption ( exhibit ), and there are some reasons to believe generative AI could be adopted faster still: \u0007 statista, reuters. \u0007 the introduction of generative adversarial networks (gans) in marked a breakthrough in generative AI. gans quickly became one of the most influential generative AI models, allowing for the high-quality generation of images, audio, text and other types of content. \u0007 the amount of computing power used to train ai systems has been doubling over . see jaime sevilla et , \u201ccompute trends across three eras of machine learning,\u201d (), . \u0007 netbase quid companies dataset, , as cited in \u201cthe ai index report,\u201d human-centered artificial intelligence, . \u0007 . \u201cthe state of ai in \u2014and in review,\u201d december , . \u0007 sequoia capital\u2019s \u201cai \u201d identifies the emerging trends in privately held ai companies, stemming across large-language models, infrastructure for model training, generative AI applications and predictive ai applications. \u0007 \u201cartificial intelligence market size & trends, growth analysis, forecast,\u201d marketsandmarkets, june . exhibit : technological adoption has accelerated over time u.s. technology, rate of adoption* flush toilet telephone air travel ice automobile vacuum cleaner home air conditioning electric power microcomputer (pc) household refrigerator internet social media radio microwave tablet cellular phone smartphone first year commercially available source: asymco, compiled from various sources with support of , morgan asset management. *estimated from current adoption trends. sizing the potential ai productivity gain ai appears well positioned to significantly boost labor productivity, but by how much? in our own analysis, we estimate productivity gains between .% and .% per year across developed markets over . this estimate, if realized, would be comparable to past periods of technologically driven surges in productivity (as shown earlier in exhibit ). importantly, our estimates quantify the impact of automation alone. such productivity enhancement would be in addition to any other productivity growth, such as the acceleration of innovation, which we believe presents significant upside potenti on the other hand, external factors could partly limit productivity gains, for instance, if an ineffective or overly restrictive regulatory response impedes ai development, or social resistance stymies adoption. exhibit : % of s&p companies mentioned ai in earnings calls share of s&p companies mentioning ai in earnings calls % q: % mentions of ai mentions of crypto q: % % % % % % % % % % \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 source: morgan asset management. mentions of ai include the keywords: artificial intelligence (ai), deep learning, machine learning, chatbots and natural language processing. mentions of crypto include the keywords: cryptocurrency, bitcoin, ethereum, blockchain, stablecoin and altcoin. data are for q as of august , . \u0007 in this publication, we focus on labor productivity, which is real economic output divided by the total number of hours worked. however, total factor productivity (tfp) is often considered a more direct proxy for technological progress since it measures the efficiency with which all economic inputs, including capital investments, are used to produce output. tfp growth represents the portion of output growth that is achieved above the accumulation of these inputs. since , tfp has also seen relatively modest gains \u2013 just .% per year in the u.s., according to commonly cited estimates by the penn world tables. however, tfp is more difficult to measure and, as a result, historical estimates are less available; additionally, labor productivity may be the more relevant measure from the perspective of individual human workers. in line with several recent studies that come to similar conclusions, our approximation of the potential productivity impact of ai-related automation takes a task-level approach. we estimate the aggregate time spent on many types of tasks across the whole economy and judge the share of each of these tasks that might be automated (for more details, see \u201cappendix: sizing ai productivity gains\u201d ). ultimately, we find that traditional and generative AI applications could potentially automate % to % of current work activities in over the next (we would expect similar results across other developed markets). the wide range of these estimates owes to considerable uncertainty around our assumptions outlined below. automation can materialize in productivity gains through three channels ( exhibit ). the first and most straightforwardly positive channel is direct labor cost savings from fewer workers being needed to produce the same amount of output. alternatively, instead of reducing headcounts, companies can produce even more output by retaining their more productive workers. the combined size of these two productivity impacts should equal the total productivity-weighted share of tasks automated. finally, there is a composition effect that accounts for changes in the productivity of workers displaced from automation. our projections assume that this effect is zero, or that, on average, displaced workers are reemployed in new jobs where they are equally as productive as they were in their former ones. we believe this is a conservative assumption, given the potential for ai to lower the barrier to entry of many jobs and because ai seems likely to generate entirely new jobs with high productivity. however, if displaced workers are employed in jobs where they are less productive, overall productivity benefits would be lower; if many are not reemployed or work less, then productivity benefits would not fully accrue to real gdp. exhibit : sizing the potential ai productivity boost . direct labor cost savings . increased output from more productive workers . \u0007 composition effects from re-employment of displaced workers **= total productivity impact** source: morgan asset management. ultimately, the greatest uncertainties in estimating the labor productivity boost involve the capabilities of ai itself. our more conservative estimates of ai capabilities, assuming a broader range of tasks are immune to automation, would see productivity gains of just .%.% per year over ; on the other hand, our most optimistic assumptions would see gains of as much as .% per year. to be sure, we think this upside is extremely unlikely, but its possibility does illustrate the significance automation could have dependent on how powerful and pervasive ai ultimately becomes. similarly, if our baseline scenario for ai automation were to take rather than to take hold, then productivity gains would be proportionally smaller, i.e., .%-.% per year. our forthcoming **long-term capital market** **assumptions** () will incorporate a small first step in accounting for the role of ai technologies, particularly generative AI, in automating current economic activity. although we feel it is too early to fully embed the plausible productivity upsides estimated in this paper into our base-case long-run assumptions, we plan to re-evaluate this impact in the coming and size the productivity gain depending on the progress made on automation. ", "## work in an age of ai automation transforming existing jobs in the vast majority of cases, ai will _augment_ but not entirely replace human capabities. while ai\u2019s abities are impressive, there are many domains where ai technologies still fall short compared to humans or benefit from a layer of human supervision and feedback. as repetitive and time-consuming \u201cgrunt work\u201d becomes automated, workers can spend more of their time on higher complexity tasks, meaningful criticalthinking or creative endeavors. as such, automation can also provide humans with the opportunity to deepen their skills, thereby expanding their overall potential and even increasing happiness at work. consider a couple of instances where we already see this dynamic playing out. - \u0007 financial \u201crobo-advisers\u201d can provide customized investment advice and algorithmic portfoo management. a human financial adviser, though, is still needed to provide appropriate advice on financial matters involving complexity, counsel against impulsive trading behavior during market crashes or bubbles and offer empathy in times of crisis. combine a human financial adviser with the tools of a roboadviser, and this new \u201cteam\u201d has both the benefit of advanced technology, as well as a layer of emotional intelgence for when contextual understanding is necessary. - \u0007 similarly, for software engineers, generative AI can significantly reduce time spent on research and trial and error, especially when working with a new programming language or software framework. with these time savings, one study found that developers were -% more kely to complete higher complexity tasks within the same time mit. ai may bring on considerable productivity gains, but by doing so through automation, the idea that robots will \u201ctake our jobs\u201d is becoming a popular concern. are we in for mass unemployment? we don\u2019t think so \u2013 at least not in the foreseeable future \u2013 but the future of work will kely look quite different. automating tasks, not jobs ai seems unkely to automate many _entire jobs,_ but it does have significant potential to automate many of the _tasks_ involved in those jobs, with most estimates of aggregate task exposure to automation ranging from % to %. such exposure will be broad-based across industries; openai estimates that llms could affect % of the workforce in some form. the degree of exposure, however, varies considerably by job type. highly exposed jobs include those responsible for documentation and review in legal professions, providing administrative support in businesses and customer service representatives. given generative AI\u2019s advanced abities to understand language and draw upon vast bodies of information, exposed tasks include those that involve a degree of knowledge or expertise. as such, higher-skilled jobs, such as stem professionals and health care providers, are also exposed. at the opposite end of the spectrum, where tasks seem the least exposed to automation, are jobs involving physical work or where the human component is invaluable (i.e., construction workers and daycare providers). \u0007 mckinsey estimates that generative AI and other technologies have the potential to automate % of current hours worked in the united states by . estimates that roughly two-thirds of the workforce may be exposed to some degree of automation from ai, with up to onefourth fully substituted. the estimates that % of jobs in major countries are at high risk of automation. \u0007 openai, openresearch and estimate that % of the workforce would have at least % of their work tasks affected by llms, with % of workers seeing at least % of tasks impacted. see tyna eloundou et , \u201cgpts are gpts: an early look at the labor market impact potential of large language models,\u201d (), . \u0007 survey results from the \u2019s employment outlook found that % of workers in finance and manufacturing said using ai in the workplace improved their enjoyment in the job. similarly, noy and () found that exposure to chat-gpt among participants using the tool for writing tasks was associated with a substantial increase in job satisfaction of . standard deviations. \u0007 deniz et , \u201cunleashing developer productivity with generative AI.\u201d this pivot will require workers to focus on skills where humans have a comparative advantage ( exhibit ). human intelgence can still better understand context and matters of complexity, apply intuition and employ emotional intelgence in social settings or where cultural norms are relevant. place a human professional in a room full of potential new cents, and within minutes she can adapt and respond to social cues across all five senses, adjusting everything from her handshake to the level of detail in her presentation. humans also still have some edge in conceptual thinking. each human mind is intrinsically capable of developing or working with an infinite number of abstract representations and models of the world \u2013 from solving physics problems to deciding how to structure an organization. no form of ai boasts such general abities. traditional ai appcations can work with some such abstract representations, albeit only for the relatively narrow set of instances for which they are designed. generative AI chatbots, despite producing novel content across a wide variety of domains, do so by essentially echoing patterns in the troves of text on which they are trained. since this process involves no underlying conceptuazation, it falls short in purely conceptual domains ke mathematics, as we noted earer. perhaps also owing to this edge in conceptual understanding, humans should maintain an edge in artistic creativity. while ai might soon be able to create a lot of music and visual art that sounds or looks ke what has already been produced, it seems less kely to generate entirely new genres on its own. where ai\u2019s capabities fall short, humans will be needed to fill in the gaps, and the jobs of will be increasingly focused in these areas. naturally, these are also the sorts of skills we will want to emphasize in education and job training, but many tough questions remain. can everyone be a great problem-solver? how do we evaluate and train such skills? do we need to foster creativity in classes, instead of teaching students how to write code? artificial intelgence has some clear advantages, including in its abity to process information at a speed impossible for humans to match. in these cases, leaning on artificial intelgence can expand our overall potenti exhibit : humans and ai should still have distinct comparative advantages **ai now outperforms average humans on:** handwriting, speech and imagine recognition* reading comprehension, language understanding* breadth of knowledge computational power speed **humans still have the advantage on:** conceptual reasoning depth of understanding complex problem-solving emotional intelgence moraty and ethics creativity intuition source: morgan asset management. *see exhibit . exhibit : technological innovation has coincided with the creation of new jobs that account for the bulk of employment growth employment, by new and pre-existing occupations milons, employment compared to occupations |axis|col| |---|---| ||| ||| ||| ||| ||| ||%| ||| ||| ||| ||%| ||| employment in new work employment in pre-existing work source: autor, , , , and . \"the new frontiers: the origins and content of new work, -.\" . , (and subsequent calculations by the authors as of august ); morgan asset management. creating new jobs although automation means that some of us will level up our tasks, increasing productivity also means businesses need less workers to create the same output, which could, in turn, result in job cuts. however, if ai ushers in an economic boom, there should be all sorts of new jobs to which we can pivot. the long history of technological advancement has been associated with the continued process of job displacement and re-instatement that has supported an economy at full employment. for instance, in the , over % of the workforce was in agriculture, yet even after improvements in everything from mechanization to crop rotation dramatically reduced the need for farm labor, a subsequent economic boom re-employed many of those formerly working in the fields. displaced farmers moved to the cities to find jobs in the industrial sector, where they then contributed to an explosion in associated commerce. with less time spent in the fields, people also had more time to spend on art and science. , in a similar vein, an estimated % of workers are employed in occupations that did not exist in , implying that over % of employment growth over has come from the tech-driven creation of new jobs ( exhibit ). this proferation of new jobs is ultimately because _productivity stimulates consumer demand_ (exhibit ). the abity to produce more output with fewer inputs inherently reduces production costs which tends to drive down consumer prices, enriching consumer wallets and enabng the consumption of all sorts of new goods and services. higher consumer demand then stimulates business demand for workers in new jobs. indeed, the rise in computerization has been associated with broad employment growth and the birth of many jobs in computer science, software engineering, graphic design, social media marketing and more. \u0007 \u0007 \u201cthe story of agricultural estimates.\u201d department of agriculture, . exhibit : higher productivity ultimately drives demand for new jobs automating oncehuman tasks reduces the cost of labor in production lower production cost reduces prices of goods and services consumer savings from lower prices redirected to additional goods and services growing aggregate demand stimulates demand for labor source: morgan asset management. generative AI ought to similarly increase our purchasing power, ultimately stimulating growth in new occupations \u2013 the web designers and app coders of . ai, in some instances, may perform the work of a thousand humans for the cost of one. such economies of scale seem kely to generate new business models we can only begin to imagine, along with demands for humans to complement and manage them. despite the many headnes about job cuts at the hands of ai, the world economic forum found that % of global employers expect ai to create job growth versus just % who expect it to create job losses. we may even see labor demand increase in the same sectors undergoing automation. one telng example is the impact that the rise of automated teller machines () had on the employment of bank tellers ( exhibit ). although automated the cash handng tasks bank tellers had been doing, the number of bank tellers _grew_ concurrently with the rise in for . how did this happen? allowed banks to operate branches more efficiently, lowering operating costs and prompting banks to open many more branches. increased accessibity of banking services also spurred greater consumer demand for them \u2013 more people wanted to use , and with it, opted for additional banking services. ultimately, growth in consumer banking drove greater demand for bank tellers, even if those new branches were staffed with fewer bank tellers per branch. the type of work bank tellers did also changed. with cash handng tasks mostly automated, bank tellers could focus more on customer service and sales, with more of them receiving skills training and college education than they did in the past. exhibit : the expansion of bank automated teller machines () coincided with growth in human bank teller employment total employment of bank tellers and , thousands \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 \u2019 number of employed bank tellers number of installed source: bank for international settlements, (), bureau of labor statistics, occupational employment survey, morgan asset management. \u0007 \u0007 world economic forum, \u201cthe future of jobs report ,\u201d may . \u0007 \u0007 james , \u201chow computer automation affects occupations: technology, jobs, and skills,\u201d boston univ. school of law, law and economics, no. \u2013 (october , ). easing labor shortages... generative AI may be coming at an opportune time for the global economy when aging populations in most developed regions stand to meaningfully slow growth in . globally, the ratio of young and elderly people who are economically \u201cdependent\u201d on those of working age will gradually increase. this dependency ratio will rise especially quickly in developed markets, where it has been cmbing from a near-bottom of % in and is projected to rise to % by . in other words, by there will be nearly two consumers for every working-age person, and until then, these workers will need to support about .% more people. all else constant, workers would face pressure to work longer hours or postpone retirements in order to support the same per capita economic output. against this backdrop, ai presents a major opportunity to counterbalance building labor shortages. every job automated by ai is also one more person who can retire without reducing overall economic output. this dynamic could be especially helpful in the united states, where the most acute labor shortages include many occupations where ai technologies are kely to have a significant impact, such as healthcare providers and skilled software engineers. \u2026 and even allowing us to work less with freed up time from automation, and machines doing more of the heavily fting on driving the economy, workers might also enjoy some more time for family, rest and fun. indeed, over time and across countries , rising productivity has coincided with fewer hours worked. , workers in \u2019s richest countries used to work a lot , but average working hours decned significantly in the wake of the second industrial revolution ( exhibit ). in , after a period of particularly large productivity gains, keynes suggested that further advances in technology and productivity might lead to a -hour . in since that prediction, though, decnes exhibit : over time, people have worked less as productivity has risen average working hours per worker united states united kingdom germany france japan source: (), our world in data, pwt . (). pubshed onne at ourworldindata.org. retrieved from: \u2018/ time-use\u2019. censed under cc-by by , chare giattino and . \u0007 \u0007 the united nations defines the \u201cdependency ratio\u201d as the ratio of young population () and elderly population (aged and over) to the working-age population (aged ). see \u201cworld population prospects\u201d dataset, , . \u0007 \u0007 these developed regions could also offset their demographic headwind by increasing net immigration from, or expanding trade deficits with younger, less developed regions. exhibit : , people work less when they work in more productive economies working hours vs. labor productivity |cambodia myanmar bangladesh|col|singapore|col|col| |---|---|---|---|---| |china india south af indonesia peru thailan|rica malaysia mexico d|taiwan||| |vietnam colombia pakistan|greece poland russia chile|south korea israel turkey|united states|| |brazil|argentina|italy japan ca spain netherlands germany denmark|switzerland labor productivity (gdp in usd per hour of work) asia africa europe north america oceania south america source: feenstra et (), our world in data, penn world table (), morgan asset management. gdp is adjusted for inflation and for differences in the cost of ving between countries. feenstra, , , r. and timmer, m.p. (), \u201cthe next generation of the penn world table\u201d. american economic review, (), -. pubshed onne at ourworldindata.org. retrieved from: \u2018\u2019 [onne resource] censed under cc-by. in working hours have leveled off for major developed economies despite further technological progress. it may be that some cultures intrinsically value hard work, while consumerism may keep us from ever feeng ke we have enough. however, across countries , the relationship between labor productivity and hours worked is consistently negative, suggesting we could still get closer to keynes\u2019 vision ( exhibit ). for developed regions, we estimate that a hypothetical ai-driven % increase in labor productivity over could drive a %-% reduction in average hours worked. however, in order to reaze this outcome, individual workers will also need to earn enough income that they are able to give up potential working hours in exchange for leisure. that, in turn, requires mitigating further pressure on income inequaty. considerations for income inequaty the automation of routine and manual work, or the potential to work less, are exciting prospects. for many, the cost could be increasing income inequaty, which for many reasons has been rising across developed markets in . in the united states, the share of pre-tax national income accounted for by the top % of earners has grown from % to % since , leaving the bottom % with only % of national income. a similar trend is seen in wealth inequaty, with the impressive growth in financial assets concentrating economic gains among those with the means to invest. some argue that technological advancement has played a significant role in these trends, with one study estimating that automation explains to % of the increase in wage inequaty from to . \u0007 \u0007 pre-tax national income represents total labor and capital income before taxes and excludes government transfers. prior to , income is defined as market income and excludes government transfers but includes capital gains and is sourced from \u201cincome inequaty in the united states, \u201d by thomas piketty and emmanuel saez, updated to . top decile includes all famies with income above $,. data for are morgan asset management estimates utizing data sourced from . \u0007 \u0007 the ratio of financial assets relative to nominal gdp has grown from .x in to about .x . \u0007 \u0007 acemoglu and restrepo argue that a significant portion of the rise in us wage inequaty over has been driven by automation (and to a lesser extent offshoring) displacing certain workgroups from employment opportunities for which they had comparative advantage. see acemoglu, daron, and pascual restrepo. \u201ctasks, automation, and the rise in us wage inequaty,\u201d nber, june , . a key pitfall of automation is that it can lead to the concentration of gains in the holders of capital, at least initially. if some part of what a worker does is replaced with an ai program, then the owner of that ai capital will receive the \u201cwages\u201d the worker used to earn. while this may propel gains for technology companies, and their investors, this dynamic doesn\u2019t bode well for labor\u2019s share of income, particularly in an economy where worker bargaining power has already dwindled. over time, these inequaties can fade, as cost savings from automation pass through to consumer prices and as new jobs emerge that reemploy displaced labor. however, while the economy has maintained full employment, there is some evidence that automation has been outpacing the creation of new tasks and jobs in . if so, generative AI could compcate this challenge by further narrowing the set of skills that are uniquely human, increasingly including those of higher-skilled white-collar professionals who largely escaped the effects of prior waves of automation. mixed effects among workers among workers, the greatest beneficiaries are kely to be those whose skills are _complementary_ to ai, rather than replaced by it. those who work in such complementary roles already tend to earn relatively more, and increased demand for their skills could add to inequaty among workers. consider a hypothetical customer service center that is made significantly more efficient by generative AI. customer-facing workers may experience a direct productivity enhancement, but efficiency gains mean needing fewer of them to produce the same output, leaving them exposed to replacement. by contrast, a manager of this center who effectively develops and maintains systems that integrate the work of humans and ai would be performing work that is more complementary to ai. at the same time, generative AI technologies can level the playing field between lower-skilled and higherskilled workers, by \u201clending\u201d expertise to those who lack it, without the need for formal training and investment. these skill-leveng effects might sghtly offset inequaty among workers. recent studies on the impact of chatgpt on customer service workers and on collegeeducated professional performing writing tasks found that the greatest productivity gains came from novice and low-skilled workers. higher performers saw less benefit, perhaps because they were already devering results closer to their peak potential, while lower-skilled workers were not only able to complete tasks faster but also perform tasks with greater complexity, \u201cleveng up\u201d in their responsibities. indeed, advanced technologies are already enabng nurse practitioners to take on more tasks usually performed only by primary care physicians. the net impact of ai of inequaty \u2013 the inequatyincreasing effects of benefitting those with complementary skills and the inequaty-reducing effects of leveng the playing field among workers \u2013 will kely vary considerably by industry, and ultimately depend on how it is developed and deployed. effective pocy management importantly, the speed at which adoption is taking place suggests governments, businesses and workers will need to act swiftly to reshape education and skills training and implement fiscal pocies to smooth the transition for labor. skills mismatches might be offset by investing in education and reskilng programs to ensure workers are keeping pace with the new skills demanded in an ai economy, while proper pubc safeguards will be needed in cases of job displacement. a greater concentration of wealth may call for further redistribution of economic income; reducing inequaty, moreover, should help drive the demand boost that creates new jobs and new incomes, promoting a virtuous cycle that helps reduce inequaty sustainably. if accompanied with the right pocy approach, an economic boom from ai automation should be a \u201cwin-win\u201d that ensures all income levels stand to benefit for the foreseeable future. \u0007 \u0007 according to bls data, the share of the workforce represented by unions has fallen by more than half since the early s, amounting to just .% in . \u0007 \u0007 acemoglu and restrepo find that automation corresponded to greater displacement effects and weaker reinstatement effects, or the acceleration of automation compared to the creation of new tasks, over than . see acemoglu and pascual restrepo, \u201cautomation and new tasks: how technology displaces and reinstates labor,\u201d journal of economic perspectives , no. , may . \u0007 \u0007 brynjolfsson, , and raymond, \u201cgenerative AI at work.\u201d \u0007 \u0007 noy and , \u201cexperimental evidence on the productivity effects of generative artificial intelgence.\u201d \u0007 \u0007 raymond et , \u201cnurse practitioners\u2019 involvement and experience with ai-based health technologies: a systematic review.\u201d ", "## with considerable promise comes considerable risk while the potential economic fruits of ai are bountiful, the technology brings with it several sociological and ethical concerns that we will need to navigate and confront in . challenges include both those intrinsic to the underlying technology and its economic implications, as well as the potential for manipulation and misuse of powerful ai technologies by bad actors: - \u0007 social instability is one potential consequence of rapid development and deployment of ai technologies that could manifest in a few ways: \u2013 \u0007 ai-generated disinformation like falsified photos and videos intended to deceive, otherwise known as \u201cdeepfakes,\u201d might soon flood the internet. such a development could make it even harder for members of the public to discern and agree on facts, ultimately amplifying ideological and affective political polarization. \u2013 the concentration of ai ownership \u0007 among a few large corporations or countries could likewise concentrate power among them. at what point do ai corporations become \u201ctoo big\u201d for the greater good? competition over such power could also lead to an unmitigated \u201carms race\u201d between competing ai superpowers that might have second-order consequences, including for the careful assurance of safety of more powerful ai technologies. \u2013 \u0007 economic hardship from transitional unemployment and increased inequality could encourage further political extremism. - \u0007 data privacy is also a major concern. ai systems often require vast amounts of personal information to function effectively, raising concerns about the collection and storage of sensitive data without proper consent or security measures. ai technologies can also inadvertently facilitate cross-border data transfers, resulting in potential violations of international data privacy laws. few regulations exist so far to ensure responsible use of both national and cross-border data sharing. however, ai is perhaps also uniquely positioned to address some of the same societal challenges it could potentially worsen. properly designed and trained, ai may prove more objective and less biased than human counterparts. we can imagine generative aipowered tools that present information in ways that help ideologically opposed individuals understand and relate to one another, and perhaps even serve as a real-time mediator or fact-checker for online discourse, encouraging objectivity and even social stability. many fears around ai focus on the potential for a \u201cdoomsday\u201d scenario that puts all of humanity at risk. as ai systems become more autonomous and capable of making decisions, many experts forecast a significant risk that humans fail to contain a powerful ai system that is not aligned with our values. this sort of risk, however, is a longer-term consideration that depends on considerable further advancement in ai technology that could be away and is thus beyond the scope of this paper. - \u0007 ai bias is one key ethical concern, in that ai can perpetuate and amplify existing biases present in the data on which it is trained. as one old computer science adage says, garbage in, garbage out . the incidence of racial discrimination of facial recognition technology has been studied extensively and images produced by generative AI evidently amplify existing stereotypes. \u0007 \u0007 alexandra sasha luccioni ., \u201cstable bias: analyzing societal representations in diffusion models,\u201d , . ", "## key asset class implications the broad implications of ai for global economies also leave much for investors to consider. higher equity prices for equities, if ai delivers on its promises, the implications should be straightforwardly positive. our work on longterm capital market assumptions suggests that an acceleration in potential gdp growth, all else the same, is likely to drive an acceleration in earnings by a similar degree. moreover, a greater share of national income flowing to capital \u2013 the owners of ai technologies \u2013 could give an added boost to equity returns. while these impacts could take to materialize, markets \u2013 and equities in particular \u2013 are likely to price in ai optimism long before then. indeed, strong global equity performance in so far, particularly in u.s. large caps, has been largely influenced by excitement around generative AI technologies. such performance has inspired comparisons to dot-com \u201cbubble,\u201d where enthusiasm about the internet propelled blind exuberance that drove stock prices significantly above intrinsic values. in our view, performance so far does not nearly resemble a \u201cbubble.\u201d price multiples are not yet significantly stretched as enthusiasm has also been accompanied by strong upward revisions to earnings outlooks for stocks with the most ai exposure, and that multiple expansion has been relatively broad based, in contrast to the narrow leadership of the dot-com bubble ( exhibit ). the future potential, however, for ai to drive something more like a bubble presents some upside risk to equities. historically, bubbles have commonly involved some new technology with no direct historical comparisons, making the impact hard to precisely quantify. when a consensus emerges that this technology is the \u201cnext big thing,\u201d investors\u2019 imaginations tend to run wild. ai certainly seems capable of satisfying this criterion. on the other hand, most bubbles have also developed in periods of highly available credit, whereas \u2019s environment is one of restrictive monetary policy and tightening bank lending standards, which should keep investors\u2019 optimism at least somewhat in check. exhibit : rise in valuations has so far been broad based, unlike in dot-com bubble foward price-to-earnings (p/e) mutiple, s&p index mean index median source: factset, j.p. morgan asset management. data as of august . ", "## conclusions when we discuss ai with our clients, many of them are more concerned than excited. fear can be a good thing, but it\u2019s easy to simply fear what we don\u2019t understand, so part of our goal with this publication is to help identify what we do know and where the real challenges are with this emerging technology. ai certainly does present many challenges, especially for labor, but an era of mass unemployment seems highly implausible. after all, we wouldn\u2019t bet against our ability as humans to always find new ways to challenge ourselves. managed properly, we do think ai has the potential to make us all more productive, lower the real costs of many goods and services, reignite economic growth and offset aging demographics. beyond economic growth, ai could also help solve some of our hardest societal challenges, such as in medicine and energy sustainability, and even accelerate the pace of innovation itself. with all of this potential, ai may prove to be the major transformative technology of , a rare occurrence that has historically preceded significant industry and societal change. generative AI, and its rapid accession to the mainstream, may be the tipping point. for investors, all of these outcomes provide significant multi-asset investment opportunities, but with generative AI still in its early innings, we would also emphasize the importance of humility and discretion. it is in such uncertain environments, however, where we believe active management ultimately excels at identifying the winning companies of , and the paths various asset classes may take along the way. as the importance of and attention to ai continues to grow, we are working hard at morgan asset management to develop and share our insights on the many questions surrounding this technological wave. as always, we welcome your feedback. an audio accompaniment of this paper is featured on the \u201cinsights now\u201d podcast series, available on spotify, apple and podcasts. the episode is entitled \u201cthe economic implications of generative AI.\u201d ai excitement has already led to considerable gains for technology companies in the s&p . among individual equities, big tech \u2013 now including \u2013 has obvious exposure to ai and especially generative AI, but as in past technology cycles, \u2019s winners from ai may include relatively new players that are not in vogue . for our u.s. equity group\u2019s thinking on navigating ai investment opportunities, see \u201c artificial intelligence: powering the next wave of technological innovation .\u201d potentially higher yields for government bonds, an ai productivity shock will likely contribute to modestly higher yields across developed markets. faster growth in productivity and thus real economic activity is likely to push cycle-neutral real yields higher by roughly the same degree, as has been the case over the long term (especially in since ). however, greater income inequality and downward pressure on wages could reduce inflationary pressures and thus breakeven inflation rates, partially offsetting upward pressure on nominal yields. one key point of reference is , the most recent period of strong productivity growth; over this period, nominal yields did rise modestly \u2013 with the u.s. up by over % between and , a period that also roughly corresponded to the strongest nasdaq appreciation. a similar dynamic may play out this time, but we are mindful of the possibility that greater inequality is met with increased pressure to fund policies like universal basic income (ubi) that are not met with greater tax revenues. such policies would result in greater government debt issuance, which tends to result in higher long-term yields. one consequence for monetary policy is that structurally higher yields could reduce the need for unconventional policies like quantitative easing, which have placed downward pressure on longer-dated yields. ", "## acknowledgements we would like to express our gratitude to several individuals across who generously contributed their time and expertise to the development of this paper \u2013 through their insights and constructive feedback, help with research and broad support for our efforts. for his sponsorship, we would first like to thank dr. , chief global strategist and head of the global market insights strategy team, who was the first to support our foray into the subject as part of our longterm capital market assumptions, and for providing feedback on multiple iterations of this publication, especially on economic implications. we are likewise grateful to jed laskowitz , chief investment officer and global head of asset management solutions, and , head of global multi-asset strategy, who both supported our efforts, provided constructive feedback and helpfully suggested others whose inputs proved invaluable. special thanks also go to cembalest , chairman of market and investment strategy, who offered particularly extensive and detailed feedback on our paper \u2013 given his remarkable depth of knowledge in ai, among many other fields. also brought our attention to additional relevant research that we have since incorporated into ours. we are also grateful for feedback from , a chief investment officer in multi-asset solutions; jared gross , head of institutional portfolio strategy; , head of multi-asset portfolio management for ; and , chief investment officer of the outsourced cio/endowments and foundations team. we would like to thank several members of the u.s. equity group, particularly for their insights on ai advances beyond generative AI, corporate applications of ai and equity investment opportunities within ai: , a and technology hardware analyst; , a portfolio manager, and and , both investment specialists. we are also grateful to dillon edwards , an ai strategist in our intelligent digital solutions team, for his partnership and feedback on technology specific issues, and to our data science team for supplying bespoke data on mentions of ai in earnings calls. finally, from market insights, , asia chief market strategist, and , global market strategist, and from solutions, and thushka maharaj , both global strategists. all of these colleagues gave useful feedback in their respective areas of expertise. last though certainly not least, we would like to thank direct contributors to this paper, foremost from di pentima , a portfolio management associate in solutions, who helped develop calculations to quantify the economic impact of ai automation. additionally, he, as well as and , research analysts in market insights, and ayesha khalid , a global strategist in multi-asset solutions, helped us collect and organize various exhibits and data used in this publication. this publication, and all of our published content, could not have been possible without the incredible support and assistance from our marketing partners, namely halaguena , a marketing strategy associate, and haley baron , marketing strategy lead. this paper is a joint effort between market insights and multi-asset solutions with input and support from across the firm. we hope our insights help inform our clients\u2019 long-term investment planning and asslocations. park avenue i new york, ny the market insights program provides comprehensive data and commentary on global markets without reference to products. designed as a tool to help clients understand the markets and support investment decision making, the program explores the implications of current economic data and changing market conditions. for the purposes of mifid ii, the jpm market insights and portfolio insights programs are marketing communications and are not in scope for any mifid ii/mifir requirements specifically related to investment research. furthermore, market insights and portfolio insights programs, as non-independent research, have not been prepared in accordance with legal requirements designed to promote the independence of investment research, nor are they subject to any prohibition on dealing ahead of the dissemination of investment research. this document is a general communication being provided for informational purposes only. it is educational in nature and not designed to be taken as advice or a recommendation for any specific investment product, strategy, plan feature or other purpose in any jurisdiction, nor is it a commitment from or any of its subsidiaries to participate in any of the transactions mentioned herein. any examples used are generic, hypothetical and for illustration purposes only. this material does not contain sufficient information to support an investment decision and it should not be relied upon by you in evaluating the merits of investing in any securities or products. in addition, users should make an independent assessment of the legal, regulatory, tax, credit and accounting implications and determine, together with their own professional advisers, if any investment mentioned herein is believed to be suitable to their personal goals. investors should ensure that they obtain all available relevant information before making any investment. any forecasts, figures, opinions or investment techniques and strategies set out are for information purposes only, based on certain assumptions and current market conditions and are subject to change without prior notice. all information presented herein is considered to be accurate at the time of production, but no warranty of accuracy is given and no liability in respect of any error or omission is accepted. it should be noted that investment involves risks, the value of investments and the income from them may fluctuate in accordance with market conditions and taxation agreements and investors may not get back the full amount invested. both past performance and yields are not reliable indicators of current and future results. is the brand name for the asset management business of and its affiliates worldwide. to the extent permitted by applicable law, we may record telephone calls and monitor electronic communications to comply with our legal and regulatory obligations and internal policies. personal data will be collected, stored and processed by in accordance with our privacy policies at  . this communication is issued by the following entities: in the united states, by morgan investment management inc. or morgan alternative asset management, both regulated by the securities and exchange commission; in latin america, for intended recipients\u2019 use only, by local morgan entities, as the case may be.; in canada, for institutional clients\u2019 use only, by jp (canada) inc., which is a registered portfolio manager and exempt market dealer in all canadian provinces and territories except the yukon and is also registered as an investment fund manager in british columbia, ontario, quebec and newfoundland and labrador. in the united kingdom, by uk) limited, which is authorized and regulated by the financial conduct authority; in other european jurisdictions, by europe) in asia pacific (\u201capac\u201d), by the following issuing entities and in the respective jurisdictions in which they are primarily regulated: jp (asia pacific) limited, or funds (asia) limited, or jp real assets (asia) limited, each of which is regulated by of hong kong; jp (singapore) limited (co. reg. no. ), which this advertisement or publication has not been reviewed by the monetary authority of singapore; jp (taiwan) limited; jp (japan) limited, which is a member of the investment trusts association, japan, the japan investment advisers association, type ii financial instruments firms association and and is regulated by the financial services agency (registration number \u201ckanto local finance bureau (financial instruments firm) no. \u201d); in australia, to wholesale clients only as defined in section a and g of the corporations act (commonwealth), by jp (australia) limited () (afsl ). for all other markets in apac, to intended recipients only. for u.s. only: if you are a person with a disability and need additional support in viewing the material, please call us at --- for assistance. \u00a9 all rights reserved. mi_mas-ai bulletin nr ", "## generative AI is all the rage ", "###### ai institute **about the ai institute** the ai institute helps organizations connect the different dimensions of a robust, highly dynamic and rapidly evolving ai ecosystem. the ai institute leads conversations on applied ai innovation across industries, with cutting-edge insights, to promote human-machine collaboration in the \u201cage of with\u201d. the ai institute aims to promote a dialogue for and development of artificial intelligence, stimulate innovation, and examine challenges to ai implementation and ways to address them. the ai institute collaborates with an ecosystem composed of academic research groups, start-ups, entrepreneurs, innovators, mature ai product leaders, and ai visionaries to explore key areas of artificial intelligence including risks, policies, ethics, future of work and talent, and applied ai use cases. combined with \u2019s deep knowledge and experience in artificial intelligence applications, the institute helps make sense of this complex ecosystem, and as a result, deliver impactful perspectives to help organizations succeed by making informed ai decisions. no matter what stage of the ai journey you\u2019re in; whether you\u2019re a board member or a c-suite leader driving strategy for your organization, or a hands on data scientist, bringing an ai strategy to life, the ai institute can help you learn more about how enterprises across the world are leveraging ai for a competitive advantage. visit us at the ai institute for a full body of our work, subscribe to our podcasts and newsletter, and join us at our meet ups and live events. let\u2019s explore the future of ai together. **** ", "## let\u2019s take a moment to cut through the hype. ", "##### the ai field took a turn with the release of powerful generative AI (ai) models, and as a result, the world is seeing the automation of some skills around creativity and imagination sooner than many expected. for some organizations, generative AI holds valuable potential for higher order opportunities, like new services and business models. offers a method for selecting generative AI use cases, as well as some next steps for business leaders in the age of with\u2122. ", "## the rise of generative AI ", "##### generative AI has captured attention in global media and the public square, prompting questions and discussions around this transformative technology. businesses, research organizations, and even lay users are experimenting with generative AI, and given the excitement and interest, it is important to look more closely at the potential capabilities and implications for business. generative AI is a subset of artificial intelligence in which machines create new content in the form of text, code, voice, images, videos, processes, and even the d structure of proteins. some forms of generative AI have been well established in , but it was a large language model (llm) powering an easily accessible chat interface that enabled generative AI to have its breakthrough moment and surprise even specialists in the field. as with other types of ai before it, this new poster child of ai is stimulating the imagination as organizations and individuals consider how to use this tool to benefit both business and society. generative AI can help in incremental digitization and basic productivity use cases (e.g., more effective text-based channels). but its grander potential is in the higher order opportunities, such as new services or business models that were previously uneconomical. generative AI in general and llmpowered chatbots in particular are not without risks, and this is prompting discussions around things like the potential for job losses and legal questions around intellectual property and ownership. what is more, because the chatbot mimics coherent human phrasing, it may give some the impression that the ai understands the prompts to which it responds, which can lead users to anthropomorphize the chatbot (i.e., the eliza effect, as seen in the work of computer scientist ). ** is working on a variety of** **projects exploring the opportunities** **and business value generative AI** **can create for our clients. from** **experiences and conversations thus** **far, the clear path ahead, as with** **all ai, is to attempt to discover and** **capitalize on capabilities while also** **responsibly managing the risks that** **are already emerging.** in this article, we look closely at the potential benefits and limitations of generative AI, introduce a method to qualify if, where and how these cognitive tools could be used, and offer important factors for business leaders to weigh when adopting generative AI. in a prior article, \u201c implications of generative AI for businesses ,\u201d offered a deep dive on the qualities and capabilities of generative AI, the state of the market, and what that means for organizations wading into this fastevolving technology field. and in forthcoming articles, we will discuss questions from legal, ethics, risk, and talent and technology perspectives and provide insights into industry use cases. ", "## while this is still the beginning, it\u2019s moving fast. among organizations across industries, there is interest in differentiating ai use cases, from public service applications to addressing climate change and transforming business functions (see \u2019s ai dossier ). ai is viewed as a tool that can automate skills and tasks performed by humans, and ai can be so successful in this regard that humans can forget skills that have been automated. examples include writing assistants, home automation, and automotive navigation systems. would most people have the ability to navigate a new city without a mobile phone? we have seen these kinds of automations emerge across a variety of areas and skillsets. the assumed roadmap for ai was that, in the shorter term, ai is most valuable as a way to automate operational skills, and creative skills will remain the exclusive province of human thinking for the foreseeable future. with generative AI, this roadmap has taken an unexpected turn. in , with the release of an easy-to-use generative AI chatbot, more people began to discover and imagine how this new technology can be used in the creative space. the chatbot use case opened the door for thinking more broadly about how generative AI can be used for tasks, ranging from writing copy to generating d structures and to outputting organizational processes. as such, we are now seeing the automation of some skills around creativity and imagination sooner than many expected. **there is a lot left to discover. in this** **age of with\u2122, the era of humans** **working with intelligent machines** **to achieve things greater than what** **either could do alone, generative AI** **will impact the future of work and** **become a common tool throughout** **various aspects of our daily lives.** **in some cases, the applications may** **be clearly visible, but more often** **than not, they may be working in** **the background.** ", "##### the evolution of generative AI the ability of generative AI to create a convincing (albeit lowquality and greyscale) image of a human face emerged in . since then, the image quality has increased, and , almost anything that can be described in words can also be generated as an image, using a textual description called a \u201cprompt.\u201d throughout , social media users tinkered with generative AI platforms and shared the results. we have seen avocado armchairs and photorealistic images of astronauts riding horses on the moon. magazine was the first to publish a cover page created by an ai-based image generation tool, and there has even been a case of a user who submitted an ai-generated image to a fine art competition\u2014and won first place. , we are seeing similar improvements in other kinds of generative AI. you may even have found this article via a chat with an ai system that integrates with a search engine. images created with generative AI. ", "## how generative AI works: understanding the basics ", "##### to understand how generative AI will impact business and life, we need to understand what it is, what it can do, and what it cannot do, yet . machine learning has dominated the field of ai for . generally, this approach to ai development is rooted in the concept of learning from examples, rather than following explicitly programmed rules. this is important as there are many tasks that humans perform based on tacit knowledge (and thus can provide examples) but cannot describe the underlying rules to do so. for example, humans know how to recognize a face, but the rules that would instruct an ai system to do the same are much less clear. the approach of learning from examples has led to the development of powerful tools that can identify intricate patterns in complex data. in a process referred to as training, the algorithm is supplied with a large dataset of input/output examples to extract patterns from the input, which allow conclusions about the expected output. spam filters, for example, use these patterns to identify similarities in data points and relate those to different classes (i.e., sorting email to a spam folder). while the input data has become more complex over time, from simple arrays of numbers to high-resolution photos, the output side of a model has to this point been mostly limited to categories like \u201cspam\u201d or \u201cnot spam,\u201d \u201ccat\u201d or \u201cdog,\u201d or numerical values such as \u00b0c or $. this approach powers nearly all ai that has been deployed so far, the result is \u201csingle purpose\u201d applications that can only perform one task. input output used car data type engine milage year **s. wagon** **petrol** **k** **** truck diesel input email hi bjorn, have a look at this: a generative adversarial network (gan) is a class of machine learning frameworks designed by ian goodfellow **regression** **model** **classification** **model** predicted price **$,** output predicted label no spam spam figure : an example of a single purpose machine learning model, using a regression model to predict the resale value for a given car. figure : an example of how a single purpose model can be used to sort e-mails by \u201cspam\u201d or \u201cnot spam.\u201d ", "#### enter generative AI the main difference between \u201ctraditional ai\u201d and generative AI is that in the latter, the output is of a higher complexity. rather than just a number or a label, the output can be an entire high-resolution image, a full page of newly written text (which is generated word by word), or any other digital artifact. this introduces an interesting new element: there is usually more than one possible correct answer. this results in a large degree of freedom and variability, which can be interpreted as creativity. **generative AI models are typically** **large and resource hungry. creating** **them requires terabytes of high-** input prompt **quality data processed over ** **on large-scale, gpu-enabled, high** **performance** **computing clusters.** only a few institutions have the necessary resources and talent to build such models. running a model also requires a lot of compute, which is why access to these kinds of models is often provided via an application programming interface (api). this allows developers to use the models with their existing software products without need for additional infrastructure. these models are versatile and can be fine-tuned for specific tasks, hence they are called foundation models. unlike single-purpose ai, they are suited for multi-purpose tasks. figure : with generative AI, user prompts lead to artifacts that can contain a large degree of freedom and variability. output generated text ai is a broad field of computer sicence focused on creating intelligent machines that can perform tasks that typically require human-like congnitive abilities, such as perception, reasoning, learning, problemsolving, and decision-making. **what is ai?** **generative** **model** ", "#### regarding risks and limitations current generative AI models have limitations. perhaps the most well-known is termed \u201challucination,\u201d which refers to a high-confidence response that is not grounded in the training data. in other words, the response is fictional. for some applications, like art generation, this is a non-issue and perhaps even a desired \u201ccreative\u201d feature of generative AI. for other applications, however, such as copywriting or computer code generation, hallucinations can result in artifacts that are not entirely valid or true, which undercuts the potential value of generative AI. another limiting factor is that \u2019s generative AI models generate artifacts based on the model itself and the input prompt. other additional sources and datasets cannot currently be integrated directly into the model\u2019s internal information processing without costly re-training or fine-tuning, which means generative AI models can only access information extracted from the data on which they were trained. for similar reasons, they cannot provide references and sources for the generated content, which complicates validation. furthermore, current models have a context window of a few thousand words, which is the limit for the size of the combined input and output. however, generative AI models can be combined with other systems (e.g., search, conversational ai) to leverage the benefits of both parts. for example, with a chatbot, a conversational ai system can serve as an orchestration layer between the generative AI model, a search engine, and the user, which helps to amplify the user experience. similar to other ai models, foundation models can reproduce latent bias in the training data, and of course, they lack comprehension and the ability to reason as humans do. this has implications for the broader concept of trustworthy ai\u2122 . after all, they are language models, image models, or voice models but not knowledge models. **despite limitations, foundation** **models can function at such a high** **quality that many new use cases** **become possible.** **some known limitations** **of current generative AI** **hallucination |** generative AI systems create confident responses that cannot be grounded in any of its training data. **bias |** similar to other learned models, foundation models inherit the bias contained in the training data. **lack of human reasoning |** generative AI systems are based on statistical features, which is not a solid foundation for logical reasoning. **limited context window |** current models have a context window of a few thousand words, which is the limit for the combined input and output of the model. ", "## generating revenue using generative AI ", "##### using this technology for business benefit can be conceived along two distinct approaches. first, the models can be used as they are available , a simple interface that allows near-direct access to the underlying model in the form of a chat for text or an image generation tool. the second approach is to integrate generative AI with other technologies to automate processes. for example, generative AI can allow for human- level expressive interactions, while a conversational ai system (i.e., a chat- or voicebot) controls the flow and ensures factual accuracy. an example is an automated, generative AI-powered call center. we expect the second approach will provide the most value. a good start to identifying use cases is to find processes or tasks where a digital artifact of some kind is created or processed. this could range from a job advertisement or a floor plan, all the way to the d model of an engine part, a molecule with certain properties, or a workflow, to name a few. use cases with high usage frequency are preferred, as there will be more example data to fine-tune and improve a model, and subsequently a more substantial impact. other factors to consider in selecting high-value use cases are existing skill and cost bottlenecks with human generated artifacts. the quality of the artifact may in some cases require human effort, but if it can be created with generative AI to a commensurate quality, then the human can be liberated to work on higher quality tasks. by turning lower-level creative tasks over to generative AI, we could see things like databases providing stock content (e.g., images, sounds, or texts) turned upside down as these digital artifacts can be created instantly with a prompt. ", "##### if a task requires effort to execute but is easy to validate, it might be a good use case. has designed a digital artifact generation/validation method to help innovation leaders determine whether an idea can be turned into a beneficial use case leveraging generative AI. at the core of this method are two of the most critical elements to consider: the human effort required to complete a task without generative AI; and the necessary effort to validate or fact check the output from the generative AI. this leads to a two-dimensional classification, categorizing use cases based on the required human effort and the ability of the user to validate the results. ", "##### there is a sweet spot for generative AI use cases generative AI is useful where the artifact generation effort is high and validation is easy digital artifact generation/validation method **identifying desirable use cases** generative AI assists best in use cases where human effort is high, while validation is easy. **generation effort** how much human effort is required to achieve the desired result **validation effort** how much human effort is required to check the plausibility or correctness of the result high consider **generation** **effort** assess neglect low difficult **validation effort** easy **examples plotted above** **** **create a joke** while creating a good joke requires some effort into designing the punch- line and best storytelling- style, it is easy to validate simply by reading it. **** **draw an image of** **an elephant under** **a palm tree** drawing any sophisticated image requires reasonable effort for most people regardless of the tools available. on the other hand, validation is easy since you can just look at **** **draft a contract** **(without legal expertise)** if you do not have legal expertise, drafting a contract is very hard and validating it difficult. generative AI is useful **** **draft a contract** **(with legal expertise)** if you do have legal expertise, drafting a contract still requires effort, but validating it is signifacantly easier. where the artifact generation effort is high and validation is easy. the picture. for example, re-writing text can be a daunting and time-consuming task for a human. generative AI tools can take original text and quickly produce a re-written result, a shorter text, a summary, or even a different writing style. a user who is familiar with the original content can validate the accuracy or correctness of the output. thus, this could be a promising application of generative AI. yet, if the user is reviewing outputs that are outside of their area of expertise, validation becomes more complicated. **the generative AI output may** **read as coherent and convincingly** **accurate, but the potential for a** **\u201challucination\u201d remains.** if users lack the knowledge to validate the output and spot hallucinations, the use case is revealed to require high levels of effort for validation and mitigating the risks from hallucinations. there is an additional complication that should be considered. if the model outputs are consistently correct, users may, over time, become less rigorous in fact checking. inevitably, however, the model will make an error, and part of the challenge is that the errors may not be obvious, particularly when generative AI is used to create more complex things, like programming code. thus, when assessing the ease of validation, weigh the importance of ongoing attention to fact checking. ", "##### insights from deloitte projects on generative AI: reaping benefits from generative AI requires more than identifying a good use case identifying use cases is only part of the challenge. whenever a transformative technology emerges, some organizations are spurred to experiment for the sake of its novelty, which can lead to \u201crandom acts of digital\u201d that do not deliver the anticipated return. driving business results with generative AI requires a strategy and collaboration from a crossdisciplinary team. in addition, with a technology that is advancing and maturing as quickly as generative AI, avoid the temptation to go forward alone and instead find support and knowledge from partners, colleagues, and third-party organizations operating in this space. the inherent complexity in current projects leveraging generative AI requires a cross-disciplinary team to guide and govern the ai lifecycle. professionals from a variety of domains can help the business answer critical questions, including: **domain** **ideation** **& product** **development** creatives, designers what can generative AI permit that reduces human effort and can be rapidly validated? **business** **operations** ceo, coo, line of business leaders how does the generative AI fit into and enhance existing processes and enterprise strategy? **customer &** **marketing** cmo how can the use case be leveraged to build customer engagement, and how much transparency is appropriate? **enterprise** **technology** **human** **capital** **risk** **management** **regulations** **& laws** **stakeholders** legal & compliance cio, cto, it chro risk officers **key questions** what current and expected laws and regulations concern the use of generative AI, and are existing governance and mlops processes sufficient to meet those laws and regulations? can the existing mlops-tech stack and platform licenses fuel generative AI, or are third-party services required? does the workforce possess the skills to use generative AI, and what are the implications for talent acquisition and upskilling? what risks emerge when deploying generative AI (e.g., jailbreaks, promptspoofing), and how do these risks impact generative AI value? ", "##### based on our observations and experience, we recommend business leaders avoid jumping head-first into the hype. instead, we encourage decision makers to: **develop a strategy** **for** **generative AI** and integrate and harmonize it with the enterprise\u2019s existing ai strategy. the same principles that guide an ai-fueled organization apply to the use of generative AI (e.g., access to curated enterprise data; ai governance; process transformation to leverage cognitive workers, etc.). with a technology evolving this quickly, avoid the temptation to go forward alone. find support and knowledge from partners and third-party organizations operating in this space. ", "# **leverage deloitte\u2019s** **digital artifact generation/** **validation method** to identify where generative AI might impact your value chain, with incremental digitization from basic productivity use cases to higher order opportunities, such as new, differentiating services or business models. **become familiar with the** **underlying technologies** that make generative AI possible, as well as the current capabilities and limitations. educate your workforce in the usage, risks, and capabilities of ai to establish a baseline of knowledge through training. also monitor over time how the technology advances and the impact on business risks and opportunities, as they emerge. this article series may support your efforts. ", "# **ensure the collection and** **curation of proprietary data,** as this is key for tailored use cases that provide a differentiator or competitive advantage. **bring together a crossdisciplinary team** of people with the domain knowledge to think creatively about potential use cases. when business leaders, technology leaders, and creatives work together with external experts, they are able to identify valuable applications and also design generative AI deployments, to mitigate business and cyber risks and meet applicable laws and regulations. ", "# **assess use cases against** **trustworthy ai\u2122 principles** , including challenges around bias and misinformation, attribution, transparency, and enterprise accountability for the impact from generative AI. ", "##### is excited to move into the future with our clients and colleagues, as well as with our connections in academia and the broader ai ecosystem around the world. ", "##### there is a lot to cover and the conversations are far from over. deloitte is a trusted advisor as we push beyond the initial buzz around this new technology and into how generative AI can be used for good in the age of with tm . the discussions so far show that there is a need for a deeper understanding of generative AI, from the underlying technology to its impact on the future of work. as such, it is important to look closely at the implications for risk, trust, and governance, which is investigated in a forthcoming article, \u201cproactive risk management in generative AI.\u201d there are also legal considerations for generative AI, which we plan to cover in \u201clegal implications of using generative AI (what the ai system won\u2019t tell you).\u201d ", "### reach out for a conversation. **beena ammanath** global ai institute leader , lead , llp **bammanath@.com** **jan hejtmanek** ai institute central europe, lead **jhejtmanek@.com** **masaya mori** ai institute japan, lead japan **mmori@.com** **wessel oosthuizen** , lead africa **woosthuizen@.com** **roman fan** , lead china **rfan@.com** ** griedlich** ai , lead **ngriedlich@.com** **dr. ** ai , lead **knuttall@.com** **anne sultan** , lead **asultan@.com** **naser bakhshi** ai institute netherlands, lead netherlands **nbakhshi@.nl** **jefferson denti** ai institute brazil, lead brazil **jdenti@.com** **dr. bringmann** ai institute germany, lead germany **bbringmann@.com** **tiago durao** ai institute portugal, lead portugal **tdurao@.com** **audrey ancion** ai , lead **aancion@.ca** **prashanth kaddi** , lead india **pkaddi@.com** **sulabh soral** ai , lead ssoral@.com** special thanks to contributors: ** moecke** , senior consultant, philipp joshua wendland** , senior consultant, alexander mogg** , lead partner, monitor germany **kate fusillo schmidt** , senior manager, ** , senior manager, **** senior consultant **elon allen** , partner, monitor **bram den hartog** , partner, monitor **aisha greene** , senior manager, *anke joubert** , senior manager, **dr. ** , director, this publication contains general information only and is not, by means of this publication, rendering accounting, business, financial, investment, legal, tax, or other professional advice or services. this publication is not a substitute for such professional advice or services, nor should it be used as a basis for any decision or action that may affect your business. before making any decision or taking any action that may affect your business, you should consult a qualified professional advisor. shall not be responsible for any loss sustained by any person who relies on this publication. **about ** refers to one or more of , a uk private company limited by guarantee (\u201cdttl\u201d), its network of member firms, and their related entities. dttl and each of its member firms are legally separate and independent entities. dttl (also referred to as \u201c global\u201d) does not provide services to clients. in the united states, refers to one or more of the us member firms of dttl, their related entities that operate using the \u201c\u201d name in the united states and their respective affiliates. certain services may not be available to attest clients under the rules and regulations of public accounting. please see / about to learn more about our global network of member firms. copyright \u00a9 development llc. all rights reserved. ", "# interim guidelines for purposeful and responsible use of generative AI **see also:** rcw .. ocio governance rcw .. () higher .. () \u201cstate agency\u201d ", "## background the rapid advancement of generative AI (ai) has the potential to transform government business processes, changing how state employees perform their work and ultimately improving government efficiency. these technologies also pose new and challenging considerations for implementation. these guidelines are meant to encourage **purposeful and responsible use** of generative AI to foster public trust, support business outcomes, and ensure the ethical, transparent, accountable, and responsible implementation of this technology. this document serves as an initial framework for the responsible and ethical use of generative AI technologies within the washington state government. recognizing the rapidly evolving nature of ai, these guidelines will be periodically reviewed and updated to align with emerging technologies, challenges, and use cases. ", "## definition generative AI (ai) is a technology that can create content, including text, images, audio, or video, when prompted by a user. generative AI systems learn patterns and relationships from massive amounts of data, which enables them to generate new content that may be similar, but not identical, to the underlying training data. the systems generally require a user to submit prompts that guide the generation of new content. (adapted slightly from u.s. government accountability office science and tech spotlight: generative AI ) ", "## principles the intention of the state of washington is to follow the principles in the nist ai risk framework, which serve as the basis for the guidelines in this document. a foundational part of the nist ai risk framework is to ensure the trustworthiness of systems that use ai. the guiding principles are: - **safe, secure, and resilient:** ai should be used with safety and security in mind, minimizing potential harm and ensuring that systems are reliable, resilient, and controllable by humans. ai systems used by state agencies should not endanger human life, health, property, or the environment. - **valid and reliable:** agencies should ensure ai use produces accurate and valid outputs and demonstrates the reliability of system performance. - **fairness, inclusion, and non-discrimination:** ai applications must be developed and utilized to support and uplift communities, particularly those historically marginalized. fairness in ai includes concerns for equality and equity by addressing issues such as harmful bias and discrimination . - **privacy and data protection:** ai should be used to respect user privacy, ensure data protection, and comply with relevant privacy regulations and standards. privacy values such as anonymity, confidentiality, and control generally should guide choices for ai system design, development, and deployment. privacy-enhancing ai should safeguard human autonomy and identity where appropriate. - **accountability and responsibility:** as public stewards, agencies should use generative AI responsibly and be held accountable for the performance, impact, and consequences of its use in agency work. - **transparency and auditability:** acting transparently and creating a record of ai processes can build trust and foster collective learning. transparency reflects the extent to which information about an ai system and its outputs is available to the individuals interacting with the system. transparency answers \u201cwhat happened\u201d in the system. - **explainable and interpretable:** agencies should ensure ai use in the system can be explained, meaning \u201chow\u201d the decision was made by the system can be understood. interpretability of a system means an agency can answer the \u201cwhy\u201d for a decision made by the system, and its meaning or context to the user. - **public purpose and social benefit:** the use of ai should support the state\u2019s work in delivering better and more equitable services and outcomes to its residents. ", "## guidelines fact-checking, bias reduction, and review all content generated by ai should be reviewed and fact-checked, especially if used in public communication or decision-making. state personnel generating content with ai systems should verify that the content does not contain inaccurate or outdated information and potentially harmful or offensive material. given that ai systems may reflect biases in their training data or processing algorithms, state personnel should also review and edit ai-generated content to reduce potential biases. when consuming ai-generated content, be mindful of the potential biases and inaccuracies that may be present. disclosure and attribution ai-generated content used in official state capacity should be clearly labeled as such, and details of its review and editing process (how the material was reviewed, edited, and by whom) should be provided. this allows for transparent authorship and responsible content evaluation. nist has identified three major categories of ai bias to be considered and managed: systemic, computational and statistical, and human-cognitive. see nist ai risk framework . - sample disclosure line: this memo was summarized by bard using the following prompt: \u201csummarize the following memo: (memo content)\u201d. the summary was reviewed and edited by [)]. - sample disclosure line: (in the file header comments section) this code was written with the assistance of chatgpt.. the initial code was created using the following prompt: \u201cwrite html code for an page that says, \u2018hello world\u2019\u201d. the code was then modified, reviewed, and tested by the web development team at watech. additionally, state personnel should conduct due diligence to ensure no copyrighted material is published without appropriate attribution or the acquisition of necessary rights. this includes content generated by ai systems, which could inadvertently infringe upon existing copyrights. sensitive or confidential data agencies are strongly advised not to integrate, enter, or otherwise incorporate any non-public data (non-category data) or information into publicly accessible generative AI systems (e.g., chatgpt). the use of such data could lead to unauthorized disclosures, legal liabilities, and other consequences (see \u201ccompliance with policies and regulations\u201d section below). if your agency has a usage scenario that requires non-public data to be used with generative AI technology, contact your agency privacy/security team, or the office of privacy and data protection for assistance at privacy@watech.wa.gov . similarly, where non-public data is involved, agencies should not acquire generative AI services, enter into service agreements with generative AI vendors, or use open-source ai generative technology unless they have undergone a security design review and received prior written authorization from the relevant authority, which may include a data sharing contract. contact your agency\u2019s privacy and security officers to provide further guidance. **for local governments** \u201clocal government\u201d means governmental entities other than the state and federal agencies. it includes, but is not limited to cities, counties, school districts, and special purpose districts (i.e., public utility districts). we advise that local government agencies in washington state engage their legal, privacy, or records specialists to validate any policy or regulation that may be in scope for their respective entity as it pertains to any handling of confidential data. compliance with policies and regulations state law already restricts the sharing of confidential information with unauthorized third parties. for state employees, rcw .. (the state\u2019s ethics law) specifically states: \u201cno state officer or state employee may disclose confidential information to any person not entitled or authorized to receive the information.\u201d the definition of \u201cperson\u201d in the state ethics law means \u201cany individual, partnership, association, corporation, firm, institution, or other entity, whether or not operated for profit.\u201d this definition would include commercial generative AI tools freely available in the market. additionally, be aware that using a generative AI system may result in creating a public record under washington state's public records act. contact your agency\u2019s privacy and records officers for more information. collaboration users of generative AI for state and local government use should consider joining the state\u2019s ai community of practice (ai cop) and contributing usage scenarios and best practices in your organization to foster collective learning. after receiving approval from your technology leadership that you are authorized to represent your organization in this community, please contact ( nick.stowe@watech.wa.gov ) or ( kathryn.ruckle@watech.wa.gov ) to join the ai cop. technology leaders across the state are encouraged to lead best practice implementation for their agency\u2019s use of generative AI and should be staying aware of and maintaining a list of their agencies use and use cases of generative AI. ", "## generative AI usage scenarios and dos and don\u2019ts below are several usage scenarios alongside some do\u2019s (best practices) and don\u2019ts (things to avoid): - rewrite documents in plain language for better accessibility and understandability. `o` **do** specify the reading level in the prompt, use readability apps to ensure the text is easily understandable and matches the intended reading level, and review the rewritten documents for biases and inaccuracies. `o` **don\u2019t** include sensitive or confidential information in the prompt. - condense longer documents and summarize text. `o` **do** read the entire document independently and review the summary for biases and inaccuracies. `o` **don\u2019t** include sensitive or confidential information in the prompt. - draft documents. `o` **do** edit and review the document, label the content appropriately (see \u201cdisclosure and attribution\u201d above), and remember that you and the state of washington are responsible and accountable for the impact and consequences of the generated content. `o` **don\u2019t** include sensitive or confidential information in the prompt or use generative AI to draft communication materials on sensitive topics that require a human touch. - aid in coding. `o` **do** understand what the code is doing before deploying it in a production environment, understand the use of libraries and dependencies, and develop familiarity with vulnerabilities and other security considerations associated with the code. `o` **don\u2019t** include sensitive or confidential information (including passwords, keys, proprietary information, etc.) in the prompt and code. - aid in generating image, audio, and video content for more effective communication. `o` **do** review generated content for biases and inaccuracies and engage with your communication department before using ai-generated audiovisual content for public consumption. `o` **don\u2019t** include sensitive or confidential information in the prompt. - automate responses to frequently asked questions from residents (e.g., in resident support chatbots). `o` **do** implement robust measures to protect resident data. `o` **don't** use generative AI as a substitute for human interaction or assume it will perfectly understand residents\u2019 queries. provide mechanisms for residents to easily escalate their concerns or seek human assistance if the ai system cannot address their needs effectively. ", "## use cases the ai community of practice will be discussing use cases for generative AI through the subcommittee process. potential uses cases of \u201csafe ai\u201d by the state include may include cybersecurity scans, environmental assessments (e.g. sea grass videos by dnr), and chatbots to more effectively answer questions about state agency services. ", "# international journal of information management journal homepage:  ", "## opinion paper: \u201c o what if chat wrote it? \u201d multidicipary perpective on opportunitie, and impcation of generative converational ai for reearch, practice and pocy \u2606 yogeh k. a , b , - , nir khetri c , laurie ghe a , emma louie lade d , anand , arpan , g , h , i , vihnupriya , manju , , , , mo , , adil n , o , , p , , yve barlette q , , r , , indranil boe , , laurence , dirio buha u , , , , oumyadeb , , , , y , , z , , aa , , ab , a ac , ad , ae , af , ral d \u00b4 e , deni dennehy , , ramehwar dubey , , ag , ah , ai , aj , ak , , carlo flavi an \u00b4 , , varun , , marijn , , , , jungla an , , angeeta , , acha , , aq , , ar , , ven laumer a , , mak at , , au , , marcello av , aw , , unil ha ax , , ay , , jeretta horn , , iobhan o \u2019 connor ba , , fevzi okumu bb , bc , , bd , , be , , avva papagiannidi bf , , ia o. pappa bg , bh , , nihith pathak bi , , bj , , ramakrihnan raman bk , , , ven-volker , , bn , , richter bo , , frantz bp , , arker bq , , bernd carten tahl br , , manoj tiwari be , , aalt b , , viwanath venkateh bt , , bu , bv , , wade bw , , bx , , jo wirtz by , , ryan wright bq , a _ future for utainable buine_ _, , , bay campu, fabian bay, wanea, wale, uk_ b _department of management, ymbioi intitute of buine management, ymbioi international (deemed univerity), pune, india_ c _ chool of buine and economic, at greenboro, _ d _univerity of , univerity of britol, b d, uk_ e _profeor of information ytem, raj oin college of buine, wright tate univerity, colonel , , oh , _ f _chool of artificial intelgence, , hauz kha, new delhi, india_ , , hauz kha, new delhi, india_ h _department of management information ytem, faculty of economic and adminitration, , jeddah, audi arabia_ i _chool of computing, middle , macon, j _cent adviory and tranformation, tackroute, niit ed, india_ , analytic and operation, college of buine, _, uk_ m _irc-fde, kfupm, audi arabia, iom, kfupm buine chool, kfupm, audi arabia_ n _innovation and technology tranfer center, , oman_ o _department of buine communication, , oman_ , , tiruchirappal, india_ \u2606 thi editorial opinion paper provide a ubjective viewpoint on the potential impact of generative AI technologie uch a chat in the domain of education, buine, and ociet it objective i to offer initial guidance on the opportunitie, , and impcation aociated with thee technologi it i worth noting that, given it a an editorial opinion piece, thi ubmiion ha not undergone a formal double-bd review proce but ha been reviewed informally by appropriate exper - correpon author at: future for utainable buine & , , , bay campu, fabian bay, wanea, wale, uk. _e-mail addre:_ k.@waneauk (k. ). htt://doi.org/./ijinfomg. received ; accepted available one -/\u00a9 the author(). pubhed by elevier ltd. thi i an open acce article under the cc by-nc-nd cene ( /./ ). q _montpeler buine chool (mb), montpeler, france_ r _fore , new delhi, india_ _indian intitute of management ahmedabad, vatrapur, ahmedabad , india_ t _information chool, , uk_ u _, poole, uk_ v _chool of information ytem and technology management, , ydney, autraa_ w _information, operation and management cience department, tb buine chool, place alphone jourdain, touloue, france_ x _department of education_ _childhood tudie, , wanea, united kingdom_ y _faculty of manitie and , , glagow g xq, united kingdom_ z _, , wanea, uk_ aa _department of information ytem, of hong kong, hong kong pecial adminitrative region_ ab _indian intitute of management bangalore, india_ ac _buine and management reearch intitute, univerity of bedhire, uk_ ad _montpeler buine chool, montpeler, france_ ae _, verpool , uk_ af _prin. of management development and reearch, mumbai, india_ ag _operation_ _, , uk_ ah _department of marketing and marketing management, faculty of economic and buine, univerity of zaragoza, zaragoza, pain_ ai _otago buine chool, co-director, centre for health ytem and technology, , dunedin, new _ aj _ditinguihed profeor and _ endowed chair of information ytem, i doctoral program, _, room , fayetteville, ar , _ , , hinc , taiwan_ , pocy and management, , the netherland_ am _, , united kingdom_ an _college of charleton, chool of buine, _ ao _, bournemouth univerity, uk_ ap _free univerity of bozen-bolzano, italy_ _, outh africa_ aq _d chool of buine, boulder, , boulder, _ ar _, the , uk_ a _ch_ \u00a8 _-endowed chair of information ytem, intitute of information ytem n\u00fcrnberg, chool of buine, economic and ociety, friedrich- univerity_ _, germany_ at _, bay campu, wanea, a en wale, uk_ au _buine chool, worceter polytechnic intitute, worceter, ma -, _ av _henley buine chool, univerity of rea, henley-on-thame, hire, uk_ aw _department of management, univerity of bologna, bologna, italy_ ax _chool of information ytem and management, , tampa, fl, _ ay _greenwich buine chool, univerity of greenwich, lon e l, uk_ az _management cience and information ytem, pear chool of buine, , tillwater, ok , _ ba _diviion of nuring, midwifery and ocial work, chool of health cience, , , united kingdom_ bb _roen college of hopitaty management univerity of central florida univeral boulevard, orlando, fl , _ bc _department of buine, wb univerity, wroc_ _\u0142_ _aw, poland_ bd _kema reearch center for artificial intelgence, kema buine chool, quai marcel daault_ \u2013 _urene, france_ be _national intitute of indutrial engineering (nitie), mumbai, india_ bf _, newcatle upon tyne, united kingdom_ bg _department of information ytem, univerity of agder, norway_ , , norway_ bi _ ai mvp and regional directorglobal lead - innovation and architecture at india_ bj _department of people and technology, rokilde univerity, denmark_ bk _ymbioi intitute of buine management, ymbioi international (deemed univerity), pune, india_ and marketing, college of buine and economic, , p.o. box , doha, qatar_ bm _mani reearch center_ \u2013 _man and management in ociety, ur , univerit_ \u00b4 _e de trabourg_ \u2013 _em , france_ bn _eic univerity, madrid, pain and man cience, waraw, poland_ bo _ and government, , , w, new _ bp _nante univerity, lemna, and kema buine chool, france_ bq _roll-ce commonwealth commerce, mcintire chool of commerce, univerity of virginia, _ br _chool of computer cience, the univerity of nottingham, uk_ b _proce and data cience, rwth aa univerity, ahorntra_ _\u00df_ _e , aa , rhine-wetphaa, germany_ bt _eminent cholar and verizon chair, director of executive in buine, , virginia tech, blackburg, virginia, _ bu _univerity of portmouth, department of trategy, marketing and innovation, richmond buil, portmouth, united kingdom_ bv _department of economic and potical cience, univerity of aota valley, aota, italy_ bw _ tranformation, global center for buine tranformation, imd buine chool, lanne, witzerland_ bx _capgemini uk ltd, united kingdom_ by _department of marketing, , ingapore_ a r t i c l e i n f o _keyword:_ converational agent generative artificial intelgence generative AI chat large language model a b t r a c t tranformative artificially intelgent tool, uch a chat, deigned to generate ophiticated text inditinguihable from that produced by a man, are appcable acro a wide range of contex the technology preent opportunitie a well a, often ethical and legal, , and ha the potential for both poitive and negative impact for organiation, ociety, and individua offering multi-dicipary inight into ome of thee, thi article bring together contribution from expert in field uch a computer cience, marketing, information ytem, education, pocy, hopitaty and tourim, management, pubhing, and nurin the contributor acknowledge chat \u2019 capabitie to enhance productivity and ugget that it i kely to offer equal contribution ignificant gain in the banking, hopitaty and tourim, and information technology indutrie, and enhance buine activitie, uch a management and marketin neverthele, they alo conider it ation, diruption to practice, threat to privacy and ecurity, and conequence of biae, miue, and miinformation. however, opinion i pt on whether chat ue hould be retricted or legilated. drawing on thee contribution, the article identifie quetion requiring further reearch acro three thematic area: knowledge, \u2019 tranparency, and ethic; tranformation of organiation and ocietie; and teaching, learning, and cholarly reearch. the avenue for further reearch incde: identifying kill, reource, and capabitie needed to handle generative AI; examining biae of generative AI attributable to training dataet and procee; exploring buine and ocietal context bet uited for generative AI implementation; determining optimal combination of man and generative AI for variou tak; identifying way to ae accuracy of text produced by generative AI; and uncovering the ethical and legal iue in uing generative AI acro different contex **. introduction** artificial intelgence (ai) ha ignificantly impacted organiation, ocietie, and individua it offer ytematic capabitie of reaoning baed on input and learning via the difference of expected outcome a it predict and adapt to change in it ecoytem and timu that the ytem receive from it external environmen when ai wa in it formative , the focu of algorithm wa generally retricted to upervied and unupervied learning, whereby it bord inpiration from biological organim and phyical propertie of and etabhed thee propertie computationally to olve data intenive problem ( , ). however, traditional ai algorithm needed tructured data for both model buil and information procein thee older and more etabhed ai algorithm uch a neural network, genetic algorithm, deciion tree, random foret, upport vector machine, k-mean ctering and many more ( duan et , ), were omewhat retricted in their capabitie due to thee ation. newer ai algorithm have evolved over time and can now proce data in their natural form, hence mining untructured data uch a raw text and image i feaibl ai algorithm uch a deep learning and reinforcement learning have now evolved where pecific algorithm uch a convoted neural network and recurrent neural network have gained prominence for being able to analye image, audio, and even video ( lecun et , ). furthermore, indutrial need involving text mining and natural language proceing (nlp) have grown in demand triggering the development and growth of algorithm which could run on untructured dat algorithm uch a _bidirectional encoder repreentation from tranformer_ (), _long hort-term memory_ (ltm) and language model have gained prominence for indutrial automation ( guan et , ; kuhwaha and , ). many of thee algorithm were heavily dependent on two reource: () abundant data for the algorithm to train and operate upon, and () very elaborate computational reource to deploy and run the algorithm. however, real-world appcation did not have acce to high computational reource, epecially when deployed. over time, newer model of ai uch a federated learning and tiny machine learning (ml) algorithm were developed and adopted in indutrial appcation ( , , ). many of thee appcation created cenario, where data were not available to initially train thee algorithm, called the cold tart problem. if data were not available, how would thee appcation learn pattern and predict future trend? thi tarted development in reinforcement learning and indutrial appcation of reinforcement learning gained prominence in both marketing and financial management appcation ( ingh et , , ). in parallel to the ongoing development of ai algorithm, the tera\u00ad ture ha een an increaed level of related tudie ( lokman and ameedeen, ). traditionally ued nlp to repond to querie red by the uer, while mapping it to the bet poible repone et available in the ytem. in order to provide real time feedback to cutomer, have adopted language model along with deep learning while addreing nlp problem ( bellegarda, ; me et , ; kuhwaha and , ). the recent launch of openai \u2019 chat ignificantly extend the capabitie of via the integration of deep learning and language model baed on the generative pre-training tranformer () architecture ( rad et , ). language model attempt to predict the kehood of a equence of word a typical man interaction i kely to create through generative and dicriminative algorithm, typically through the appcation of deep learning and tranformer architecture of neural network ( bengio et , ). chat ue a combination of unupervied pre-training and upervied fine-tuning to ; bellegarda, ; vawani et , generate man-ke repone to querie and provide repone to topic that reemble that of a man exper the - model i the latet extenion built on a language model with bilon parameter, trained on a divere dataet of naturally ued text obtained from different internet ource uch a web page, book, reearch article and ocial chatter. while current language model generally utie deep learning with a focu on upervied learning, future evotionary model may be built more on reinforcement learning ( uc-cetina et , ). the recent widepread global adoption of chat ha demon\u00ad trated the tremendou range of ue cae for the technology inc oftware development and teting, poetry, eay, buine letter, and contract ( metz, ; reed, ; tung, ). however, it ha alo red a number of concern related to the difficulty in differentiating man veru ai authorhip within academic and education communitie, and renewed debate on the role of traditional man endeavour ( ele, ; tokel-walker, ). thee arie becaue chat can be extenively ued for nlp tak uch a text generation, language tranlation, and generating anwer to a plethora of quetion, engendering both poitive and advere impac with thi background, in thi article we eek to anwer the two following reearch quetion: rq) what are the opportunitie, , and impcation related to generative AI technologie uch a chat in the context of education, buine, and ociety? rq) what are the mot important reearch quetion to invetigate related to generative AI technologie uch a chat in the context of education, buine, and ociety? the remainder of thi article i tructured a follo in the next ection, we t the individual contribution of ai expert from variou dicipe inc information ytem (i), computer cience, data cience, marketing, management, indutrial engineering, nuring, education, pocy, hopitaty and tourim, and pubhin further, baed on the expert contribution that indicate a clear need for cientific reearch on variou iue related to chat, we provide a yntheied narrative of the of generative AI technologie, iue underlying their adoption and ue, and direction for future reearch. **. perpective from lea expert** in accordance with foerter \u2019 () original propoal and multiple ubequent tudie that have followed an expert-baed viewpoint on a divere range of i related topic ( et , , , ,a,b, b \u2013 d ), we examine the critical perpective on the impact and core from the widepread adoption of chat and aociated generative AI technologi the full t of expert and their individual contribution are ted in table , divi the contribution into five broad categori _.. broad perpective on generative ai_ _... contribution : chat: diruption and what next? - viwanath_ _venkateh_ even aying that chat ha become the talk of every town and every peron may be an undertatemen it appear to have rocked the very foundation of many a domain of work. it baic functionaty of \u201c ak me anything \u201d and \u201c i may have a good anwer \u201d ha become more than a hale in many a domain. let \u2019 tart with cientific knowledge, which i dieminated in ke thi one \u2014 cience i already wretg with what role uch a technology will pla will it be a co-author? can it be a co-author? the other crii profeor who create knowledge immediately face i how do they ae the tudent? in thi hort note, i am not going to tackle or conider thee and related highly vad quetion. over , i thought it bet to tep back and ak broader quetion, albeit purred by more abtract idea underlying the above vad and ye, practical quetion. what chat ha e i to be diruptiv it i not unpredictable that omething ke thi could have happened. it i that it ha happened uddenly and quickl technology, by it very , doe evolv ometime, it i diruptiv what it doe i to rehape the way in which activitie and behaviour are altered. for intance, when i wa a tudent in , the acce to reearch article at the cck of a button wa not feaibl it required going to two different univerity brarie and either rea and making note or making copie of articl the fact that thee article are now readily available doe make for more efficient and even more effective cienti the kill of fin and having a collection of the relevant article i no longer in demand, but the demand for another kill, the vome of the article a tudent may be expected to comprehend, emerged intead. thi technology-driven kill reorganiation can be expected to permeate in variou phere of man fe and exitenc t, i offer the following propoition: **table ** individual contribution on cha **contribution title** **author ()** **.. broad perpective on generative AI** **contribution :** chat: diruption and viwanath venkateh what next? **contribution :** ai platform, chat, marcello and innovation **contribution :** man and generative AI collaboration: leon from utitarianim and oumyadeb **contribution :** chat \u2019 bigget diruption: knowledge work productivity wade **contribution :** chat a a member of richter hybrid team **contribution :** chat a the new aalt calculator **contribution :** chat for man ia o. pappa augmentation **contribution :** overcoming reitance to change with ai: can chat help you? **.. organiational and ocietal impact** **contribution :** ocietal impact of ral d \u00b4 chat **contribution :** the potential of chat: awe, fear, digut and tranformation **contribution :** chat: the tranformation challenge for organiation jut became harder **contribution :** ervice marketing and jo wirtz management impcation of chat **contribution :** marketing in the world of -. and chat: futuritic reflection **contribution :** marketing in the world , of -. and chat: futuritic , reflection and adil **contribution :** chat in banking , mo ahmad ervice albahrawi, and **contribution :** uing chat in dirio buha tourim, travel, tranport and dirio buha **.. impact on the academic ector** **contribution :** generative AI in teaching and reearch: ome preminary thought ryan wright and arker **contribution :** chat: the new iobhan o \u2019 connor wave of ai tool in higher education _.... p._ the kill required in the world powered by chat and related technologie will be differen the diruption caued by technologie in general reult in chal\u00ad lenging aumption about the way domain have functioned. for intance, in an article on ai ytem and their impact, we argued that the aumption underlying variou field in i reearch were fundamentally altered by thee new technologie (ee cetz and venkateh, ). thi will naturally extend to cha t, i offer the following propoition: _.... p._ the aumption underlying variou domain of reearch will be impacted by cha baed on thee two propoition, i ugget reearcher go to work! here are a few non-exhautive and not necearily mutually excive ide _..... direction #._ the variou domain that are affected by chat hould be clearly articulated and the diruption clearly undertood. thi will then lead to a better deeation of what the new world look ke and the kill needed to function in that new world. it hould be readily obviou that how thi technology impact different profeional domain and job will be dratically differen variou job framework and kill framework can be leveraged for a rich undertandin _..... direction #._ fe, ociety and peronal interaction will clearly change, perha even more o than it did with ocial media and other technologi thee change will bear invetigation. **contribution :** chat: the ven laumer tranformation of i underway **contribution :** how to enhance critical thinking of tudent, educator and reearcher in the chat era **contribution :** chat and education ramakrihnan raman, \u2013 i a ymbiotic relationhip poible? davie and **contribution :** chat in the context yve barlette of education: how to deal with it diruptive effect? yve barlette **contribution :** the ue of chat in educational intitution: , opportunitie and future cope , jeretta horn , hanaa and **contribution :** dirupting higher education and man communication by language model marijn janen **contribution :** chat and education pocy and practice **contribution :** how doe chat varun benefit or harm academic reearch? **contribution :** chat, **** cholarly ramehwar dubey and deni dennehy writing, and pubhing **contribution :** chat and it potential impact on reearch and pubhing avva papagiannidi **contribution :** magic or fat-food frantz writing? when tranformer challenge ( _continued on next page_ ) management reearcher have been lagging behind. they focued on the relevance of ai technologie for innovation recently, motly after the ai hype acro (ma) media ( davenport and ronanki, ). however, innovation management reearcher have rapidly undertood the potential relevance of ai for innovation managemen thi i reflected by the field at the interection of ai and innovation evolving rapidly in repone to call for more tudie on the multifaceted relationhip between ai and innovation (ee cockburn et , ). a clear from a recent ytematic terature review of the cientific work produced on ai in innovation reearch ( et , ), o far innovation management reearcher have focued on three type of driver of ai adoption for innovation (economic, technological, and ocial) and three type of outcome of ai adoption (economic, competitive, organiational, and innovation). among the innovation outcome, the development of new technology a well a product, proce and buine model innovation have been found to be relevant potential appcation area for ai. o far, not all form of ai have been analyed in innovation man\u00ad agement tudie ( et , ), and generative AI ha been everely underexplored. however, the launch of multiple generative AI platform over the lat five (, in , chat in ), and more generally large language model, ha attracted the attention of the media, organiation, and uer. indeed, one of the mot triking feature of thee generative AI platform i that they have been adopted maively in a hort period of time: launched on , , chat ha been ued by milon uer in after it launch. the ditinctive feature of chat i preciely it capabity to generate textual conten in after it releae, chat ha been deployed by many oftware developer, creative writer, cholar/ teacher, and ongwriter to generate computer oftware and , text, academic eay, ong lyri platform uer have expreed mixed fee i tried chat myelf in aking the platform to develop an eay on the relationhi between \u201c big data \u201d and \u201c innovation management \u201d . the reult wa rather diappointing a the text eemed **_rather weak in term of logical flow, inaccurate in term of_** **_factuaty and truth, not critical in term of elaboration of data, and_** **_not novel_** . when aked to provide reference and ource to back the argument of the eay, the oftware imply pulled together a t of reference with wrong title aociated wrongly to author, and pubcation . very much ke , alo chat can be **_potentially_** ued by it and oftware developer to generate article/ oftware, but the outcome will need to be carefully double checked a the oftware eem to generate **inaccurately reported ource of idea** **inaccurate content** . , baed on the abence of originaty of the output generated by chat i even more acute when it come to product that are related to the creative indutrie uch a ong lyri for intance, ongwriter cave recently received from one of hi fan a ong \u2019 lyric that had been generated by chat- baed on a pecific prompt: \u201c in the tyle of cave \u201d . diappointed by the outcome, cave wrote in repone to hi fan: \u201c writing a good ong i not mimicry, or repcation, or patiche, it i the oppoit it i an act of elf-murder that dl one ha trived to produce in the pa it i thoe dangerou, heart-topping departure that catapult the artit beyond the of what he or he recog a their known elf. \u201d ( cain, ). the **abence of originaty,** detected during my own eay generation experience with chat and expreed alo by cave, i perha an unimportant apect for ome routid oftware generation tak, but it become clearly of paramount importance in creative writin we might argue that inaccuracy, weakne in logical flow, iue of factuaty/truth, lack of critical elaboration, and non-originaty of the generated content could be the outcome of a technology that i till being teted. indeed, the ai platform \u2019 underlying deep learning model were perha trained on an outdated and low-quaty training e on the other hand, we might expect that if the training model and the data **table ** ( _continued_ ) **contribution title** **author ()** our epitemic vae in teaching and reearch and our manity **contribution :** recommendation for deag with chat, in academic pubhing and acha krau **.. ethical iue** **contribution :** chat and ethic \u2013 laurence \u2018chat doen \u2019 t matter \u2019 ? **contribution :** good bot or bad bot? bernd c tahl on the ethic of chat **.. , opportunitie, and reearch direction** **contribution :** toward a reearch for generative AI in education, indutry and reearch and **contribution :** ue the ace and adroit framework to ae , opportunitie, and reearch related to chat unil ha **contribution :** chat: and opportunitie **contribution :** moving from prediction to creativity: impcation of generative AI on meaurement of ucce **contribution :** chat: , opportunitie, impact and reearch , , fevzi okumu and mak nihith pathak **contribution :** chat: , opportunitie, impact and reearch **contribution :** chat: , opportunitie, impact and reearch **contribution :** , opportunitie, and impact of chat in the it indutry **contribution :** of chat indranil boe **contribution :** on the and jungla and ven-v. rehm opportunitie of chat **contribution :** chat: technology and development, impact and **contribution :** chat: a reearch manju aja the remainder of thi ection howcae the contribution, preented motly in their original and unabridged form. thi approach may reult in ome unevenne and overlapping narrative but preerve the individual perpective of each expert a they highght important apect of the impact and temming from chat and generative AI ( et , ,b,c,d). _..... direction #._ underlying our reearch domain are a\u00ad umption. one iltration of a framework of aumption i alveon and () . aumption in variou domain, many of which often have unarticulated aumption, will need to be articulated and vadated (ee cetz and venkateh, ). _..... direction #._ not mutually excive from direction # above but equally important i that many domain may now require a paradigm hift in kuhnian term. thi preent an exceptional opportunity for cholar to get away from exiting view and theorie \u2014 one that perha do not give a much agency to technology hould be reconidered o a to provide new theorie rooted in the new paradigm. in cloing, i am neither alarmed nor not alarmed. it \u2019 a technolog a great opportunity to grow a a ociet and, when the two meet, cience can help it \u2019 diruptiv it \u2019 a great opportunity for cienc it \u2019 ociety gro _... contribution _ _.... ai platform, chat, and innovation - marcello ._ while information management (im) and i cholar have tarted dicuing opportunitie and pertaining to ai platform a oon a ai technologie and ytem emerged and advanced, innovation quaty improve, the ai platform might enhance it performanc however, it i not clear if better technical performance will lead to more meaningful innovation outcom accorly, one of the key quetion for innovation management cholar then become: \u201c are ai platform (uch a chat) capable to lead product, proce, or buine model innovation? **_independently_** \u201d . to **_meaningful_** the impreion i that there i no ready anwer and there i a long way before ai platform uch a chat can become an independent agent in innovation procee and innovation managemen recent ue of generative AI in text, movie, and muic generation ugget that thee ai platform at bet can become a partner in product innovation and vae creation ( et , ). in complex activitie that involve everal area of the man brain, uch a creative activitie and innovation activitie, a good prompt appear to be not enough to allow a generative AI ytem to generate independently a ditinctively different and original new produc we expect thi to be even more relevant for product that involve ome form of emotional intelgence ( , ). to ummarie, there i a long way before ai platform uch a chat could be capable to lead **_independently_** to **_meaningful_** product, proce, or buine model innovation. at bet they can help enhance man intelgence for innovation by augmenting man intelgenc a ai platform and the underlying technology will evolve, future reearch will need to invetigate if and to what extent the role played by generative AI will be increaingly relevant in triggering innovation outcom _... contribution _ ugget that context i a ignificant factor to identify, ae, prioritie, and igate rik (nit, ). therefore, rik related to chat adoption in any buine ector hould be mapped to it context of ue and appcation. with regard to chat, the rik tem from the quaty, authenticity and reabity of the data ued to train the model and how model i being rectified by the man deigner and developer. once the rik are identified, ethical model can be ued to help determine a path forward ( ahok et , ). utitarianim i one of the mot common approache to making ethical deciion that doe the leat harm (or mot good) to individual, ociety, environment, weighing both the poitive and negative impact of the action ( b ohm et , \u00a8 ). from the ai rik management perpective, the theory provide an approach for reolving confct through a flexible reult-oriented len for formulating and teting pocie at each tage of the rik management cycl for example, the rik of adopting chat in a pecific context can be aeed by the rmf, where-a the impact and conequence of the rik on each takeholder can be prioritied uing the utitarianim perpective, i., making a deciion whether the adoption will promote welfare compared to any other alternativ imilarly, the contextual importance of ai adoption (in each ector for a pecific appcation) can enable ai developer, organiation planning to deploy ai and even pocy maker to make reatic and workable moral deciion undertan and weighing both the opportunitie and negative impcation. therefore, ai rik management framework and ethical theory perpective hould be conodated to make ocially reponible judgement which will help enure purpoeful, cautiou, reaoned, and ethical way of leveraging generative AI model uch a cha accor to utitarianim, the mot optimal deciion and action related to chat deign, development, adoption, deployment, maintenance and evotion hould provide the mot good or doe the leat harm for the ociet thi alo call for reponible ai toolkit and framework to embed ethical perpective to enable a balanced view of what i right and wron _..... future reearch ._ we preent four future reearch theme for generative AI model uch a chat conidering four different perpective, viz, tool, proxy, enemble and kill ( , ). _.... man and generative AI collaboration_ _..... leon from utitarianim - and oumyadeb_ _._ chat i a cutting-edge ai language model that leverage generative AI technique to provide algorithm generated converational repone to quetion prompt ( , ). the output from generative AI model are almot inditinguihable from man-generated content, a they are trained uing nearly everything available on the web (for , around terabyte of text data in the cae of chat). the model can be trained to perform pecific tak, uch a preparing de in a pecific tyle, writing marketing campaign for a pecific demographic, one gaming commentary and generating high reotion image ( et , , ). while the benefit of thi new ai tool for buinee have been widely dicued by variou media outlet, it i eential to undertand the ation of generative AI model which may lead to reputation and legal rik, uing offenive or copyrighted content, lo of privacy, fraudulent tranaction and prea fale information. in thi commentary, we explore the interection of rik management and ethic in the context of generative AI to propoe four theme for future reearch. _..... exploring the ethic of reponible ai: leon from uti\u00ad_ _tarianim._ threat poed by chat, and imilar ai bot incde black- box algorithm, dicrimination and biae, vulgarity, copyright infringement, plagiarim, fabricated unauthentic textual content, and fake medi hence, it i eential for organiation to undertand, manage and igate rik reulting from ai adoption. ethical review and bia creening hould complement periodic rik aement becaue the algorithm i evotionary in , i., the vominou data ued to train the algorithmic model poe high velocity, heterogeneou and variabity characteriti the artificial intelgence rik management framework ( \u201c ai rmf .) developed and releaed by ( \u201d nit \u201d ) can guide the organiation developing, adopting, and implementing ai otion to ytematically ae, undertand, and manage rik, and promote reponible ge, development, and evotion of ai tool ( , ). the working verion of the rik management playbook releaed by nit grounded in reearch **theme ** - **from a tool view,** it i neceary to develop technique to enhance the tranparency of generative and elf-adaptive ai model that will facitate explainabity of the outcome repon for intance, an important quetion to explore i how can tranparency and explainabity either enhance or diminih the competitivene and productivity of organiation adopting chat? **theme ** - **from a proxy view,** there are everal intereting quetion. for intance **,** how can reponible and ethical pocie, practice and regulation can help in diffuion of generative AI appcation acro organiation? what i the impact of conodating rik management framework and ethic theoretical perpective on chat adoption within organiation? **theme ** - **from the enemble view** , where, when, and under what organ\u00ad iational context i it bet to implement chat? how do ocietal context hape the meaning and the outcome of adopting chat, from an ethic and moral judgement perpective? what are the conceptuaation of reponible chat accor to cutomer, employee, takeholder, manager, the community, and government pocy maker. in ght of utainable development goal , , , and , how can reponible development, deployment, and evotion of chat, promote wellbeing among man and in ociet **theme ** - **from a kill view** , it will be intereting to explore which kill, reource and capabitie (both technical and non-technical) are neceary within organiation to better undertand the ation of chat within different context of ue, and promote ethical making? what i the role of government pocie, training provider, higher education and technology developer to help develop thee kill among the man workforce (whoe job are kely to be made redundant a a reult of robotic proce automation)? _..... concion._ given chat ha been coined \u201c the indu\u00ad try due to it analytical and computational capabitie, efficiency in producing man-ke repone and round the \u2019 next big dirupter \u201d clock availabity, it i important for reearcher and practitioner to examine the ethical concern urroun black-box algorithm and how multi-dicipary reearch can help alleviate thee concern. _... contribution _ productivity could be meaured in two way: time to complete the tak (efficiency) and quaty of the output (effectivene). the experiment could tet different type of tak, ranging from imple to more complex. imple tak might incde writing a thank you email, producing a written ummary from a point form t of item, or creating a imple repor more complex tak could incde writing a performance evaation, repon to a enitive argument in an email, or writing a complex repor there are many promiing reearch program ked to chat and other text-baed generative AI tool, a my colleague have outed. however, the lack of ignificant improvement in the productivity of knowledge work (and worker), ha long been a ource of frutration for organiational leader and pocy maker ( jahat et , ). chat ha the potential to enhance the productivity of knowledge work through variou mechanim, uch a impfying the information earch proce, but i predict that it mot ignificant impact will be to provide a competent firt draft for our mot common written knowledge tak. _... contribution : chat a a member of hybrid team_ \u2013 __ _richter_ _.... the emergence of hybrid team._ the terminator \u2019 , \u2019 the matrix \u2019 , and \u2019 i, robot \u2019 depict ai a powerful, autonomou movie uch a \u2019 entitie that ultimately turn againt manit thi portrayal of ai a a threat ha contributed to the common perception that ai and man actor compete with one another, at leat for job, rather than being able to work together in a mutually beneficial wa however, the idea of man and ai working together i a old a the field of ai itelf. the pioneer of ai reearch recogd the potential benefit of ai and man working together and enviioned a ymbiotic relationhip between the two. they anticipated ai would augment man intelgence to olve complex problem and make better deciion and ultimately help man achieve their goal more efficiently (, ckder, ). baed on the ignificant advancement of ai in (pecifically in deep learning and built on large amount of data and computing power), it eem reaonable to aume we will increaingly ee hybrid team coniting of man and ai. in order to undertand the potential of ai in hybrid team and to effectively navigate their complexitie, it hel to explore what type of activitie ai can take over in thee team ettin in thi contribution, i will iltrate ome of chat \u2019 poible role in a team coniting of man and ai, inc coach, innovator and oftware developer. i aim to ue thee example to how how man actor and ai are becoming hybrid team. i will concde thi contribution with an initial et of reearch quetion about the future of hybrid work from thi brief analyi. _.... chat a a partner._ chat i baed on - (generative pre-trained tranformer ), which wa introduced in june . - ha bilon parameter and i one of the mot powerful language model available to dat wherea chat ue the ame dataet and parameter a -, it converational focu and eae of ue (or readine-to-ue) made it a ge ucce (which even urpried many _.... chat_ _\u2019_ _ bigget diruption: knowledge work productivity -_ _ wad_ new ervice and technologie are releaed all the time, and every o often one come along that hit the viral jackpo bitcoin did thi in , \u2019 audio duplex made a big plah in , and the metavere and web . caught fire in . ome, ke bitcoin, endure; mot, however, remain on the idee and lowly fade awa remember how cbhoue wa going to dirupt ocial media, or how we were going to be d printing everything? how will chat fare in the diruption weetake? much ha been aid about how chat will dirupt the education ector, and a omeone who operate from within thi ector, i can only hope that thi i the ca but my interet, at leat from a reearch perpective, e elewher in fact, i beeve that the bigget potential ource of diruption will be chat \u2019 effect on the productivity of knowledge work. chat i generative, meaning that it can create new data, not jut analye exiting dat thi capabity, pecifically for text, i what et chat apart from the earer avatar of m ml ha been good at pattern recognition for many now \u2013 whether it i ditinguihing cat from dog, or canning for cancerou tumour. chat take thi one tep further. it not only recognize pattern, it ue them to create new data baed on thoe pattern, which make it generativ from a reearch perpective, we can tet how effective chat i at generating content that can enhance knowledge worker productivit among the many way that chat do thi, i predict that the bigget impact will be aociated with it abity to create a firt draf compared to phyical labour, knowledge work i notoriouly hard to tudy due to the difficulty of meauring input veru output ( drucker, ). neverthele, reearch ugget that % of a knowledge worker \u2019 time i pent on dicretionary activitie that offer ttle peronal atifaction and could be handled competently by other ( , ). \u2018other \u2019 ha typically been thought of a another peron, but could equally be a technology otion, ke cha knowledge worker know that it take a lot of time and effort to write a firt draft of anything \u2013 an email, a report, a blog, a buine plan, a propoal, an article, or an employee revie interetingly, i could not find any reearch that compare the time it take to create a firt draft of omething veru the time it take to tranform that draft into a finihed produc mot of u would agree that, generally peaking, having omething to work with i a lot eaier than tarting omething from cratch. ultimately, however, thi i an empirical quetion. an experimental reearch program can be deigned to tet the dif\u00ad ference in productivity between two condition. condition one would be where a reearch ubject complete a tak from tart to finih, while in the econd condition, a ubject ue chat to create a firt draft, and then complete the tak uing the draft a a foundation. experiment could be conducted employing both within-ubject and between-ubject deign. thank to , hahper richter, kai riemer, gerhard chwabe a well a for comment that helped me to improve thi contribution and to the anonymou tudent who hared their inightful experience with chat with me and allowed me to ue it in thi articl the more parameter (or tunable vae) a model ha, the more complex pattern it can learn and the better it can perform on a variety of tak. however, having more parameter alo require more data and (computational) reource to train. in the cae of chat, thi re open quetion inc \u2018how ethical i it to pay man worker $ an hour to improve the quaty of the training data \u2019 ( perrigo, )? information technology (it) expert) when it wa made available in . globally, practitioner, academic and tudent tarted experimenting with chat and hared their \"eureka\"-moment with colleague, friend and famil depite it high degree of accuracy, there were alo jutified warning about the reabity of the produced tex how they did not only tet chat but how they already operatively ue i example entail uing ai to ait with code writing, automating imple tak (inc teting) and error management (in development and pot-deployment phae). _.... a new perpective on \"hybrid work\" and a preminary reearch_ _ on hybrid team._ thi contribution identifie a couple of role ai can play in hybrid team: rather imple role, uch a text producer, language editor and - reearch aitant and more ophiticated role, uch a coach, innovator and oftware - developer the t of thee role ha an iltrative character and i incomplet a a next tep, it eem reaonable to ue group role or tak framework to identify the trength and weaknee of cha for intance, mcgrath () identifie the following tak in hi group tak circumplex: generate (planning tak, creativity tak), chooe (intellective tak, making tak), negotiate (cognitive confct tak, mixed-motive tak) and execute (contet, battle, performance). it appear chat could contribute vaable input to many of thee tak, but reearch will need to how which tak chat (or other ai) i bet uited to and what it ue will brin knowing ai can ait with variou tak in a team can alo enrich the dicuion about hybrid work. o far, the term hybrid work ha been motly ed to the traditional binary of preence work v virtual work. the addition of ai to collaborative team warrant to re-conider the term and concept of hybrid work. hybrid work i no longer ed to the continuum of preence and virtual but alo comprehend the duaty of man/man v man/ai (cf. . ). the variou implementation of the metavere concept will take thee conideration further. man will need to develop new approache and trategie for hybrid teamwork, which open the pace for manifold reearch quetion, for example: . how to allocate tak between man and ai? who delegate thee tak, and who coordinate them? how do man delegate tak, and how doe ai delegate tak? . will man actor feel the ame ene of achievement when a lot of the creative work i e by ai? will man-man interaction change in hybrid team? . what are the impcation of over-reance on ai for man actor \u2019 creativity, problem-olving abitie, and making kill, and how can we igate thee effect? **. .** toward a new conceptual undertan of hybrid work (own iltration). there are alo other ai-baed oftware developer. for intance, announced it tool in june . it can ait uer of everal integrated development environment (ide), , viual tudio, by autocompleting cod \u201c copilot \u201d ke many other deep learning-baed tool, chat can only be a good a it training data and i probabitic and tochatic (, bender et , ). a typical ocial media pot (out of many by the end of ) read ke thi: \"i aked chat to write me a [text/abtract/oloquy/ \u2026 ] about [topic]. it did a [good/great/amazing] job, (certainly) (way) better than i would have \" wherea many of thoe initially circulated anecdote relate to relatively traightforward role of content production uch a text producer, language editor and tranlator, there are example of how chat can alo contribute to hybrid team in more ophiticated rol _.... role of cha_ one of my emba tudent hared their experience with chat: _\"in my interaction with chat, it felt a if i_ _\u2019_ _m_ _interacting with a team member_ _] i received an immediate repone and i felt i could trut the information that wa given to m_ via _a chat function. [_ _\u2026_ _[_ _\u2026_ _] i felt emotionally upported, i wa o worried that i_ _\u2019_ _m falg behind_ _chedule and in uing chat i actually felt a ene of reef. in a way, it i_ _cary, in_ _\u2019_ _t it? could thi type of interaction replace group work?\"_ . in thi cae, chat wa initially thought of a a tool for (re-)earch upport, i., the tudent ued it to make ene of a new topi but it alo became a team member that provided emotional upport to the emba tuden thi example i in e with tudie that howed that ai can act a a **coach** , i., upporting man in achieving their goal, , health- related ambition uch a weight lo ( and , ), phyical activity ( wlaak et , ) or when it come to kill development ( and ciler, ). generally, it ha been oberved that ai acting a a coach ha the potential to collaborate with individual in planning, monitoring, and control of thinking, feeg, and action ( cranefield et , ). ai-baed coache can help individual to develop new practice and kill, , when it come to tracking their well-being or allocating their time more mindfully in order to be able to focu better (, winikoff et , ). a tudy by bouchery et () explore how - can become a member of a hybrid innovation team by acting a an **innovator** in the new product development proc they found that it allowed for larger problem and otion pace and ultimately led to higher innovation performanc further tudie have hown that the generative of chat enable it to contribute new idea and concept ( tevenon et , ), for example, by completing entence, paragraph or whole text baed on a given context and problem definition. wherea it may till dever le original and vaable idea than man, chat can help man team member better undertand their problem and otion pac another potential role of ai in a hybrid team i that of a **oftware** **developer** . reearch on o-called ai-baed development i till in it infanc till, many oftware developer have hared over ee ( pearl, ) for exampl hah and bender () caution againt the opaquene of earch ytem uing ml, i., it i difficult to retrace what information they preen the ue of large language model ha the potential to further decreae tranparency and accountabit hah and bender ugget meaure to counteract thee potential problem. in other word: chat i a tool generating text baed on the input it re\u00ad ceive and the parameter it ha been trained on. i am not implying that chat ha concioune, autonomy or the abity to act with inten it ha yet to be determined what that mean from an intellectual property perpective, ince the generated output i baed on other people \u2019 pattern that are uually given a training data without conent and a free labour. o, there i the quetion whether ai can only ever plagiari . who aee the quaty of the work reult? if ai aee them, doe accountabity of the work reult only entail the team or potentially the developer of the ai-baed team member? thee quetion add to other previouly red ai-related reearch quetion that our community i till working on reolving, , who i accountable for ai-baed action ( , )? how can we enure that ai ytem are tranparent, explainable/contetable, and trutworthy? it will be intereting to oberve how chat and the many other ai tool already available will contribute to the changing of work in the near and ditant futur _... contribution : chat a the new calculator - aalt_ when aking chat, \u201c what i the effect of calculator in teach\u00ad ing? \u201d the repone i, \u201c the ue of calculator in teaching mathematic can have both poitive and negative effect on tudent learnin on the poitive ide, calculator can help tudent perform complex calculation quickly and accurately, allowing them to focu more on undertan mathematical concept and problem-olvin additionally, calculator can provide immediate feedback on their anwer, allowing tudent to check and correct their work. on the other hand, overreance on calculator can lead to tudent lacking baic arithmetic kill, a well a the abity to perform mental calculation. it i important for teacher to ue calculator a a tool to upport learning, rather than a a replacement for traditional mathematical intruction. \u201d when aking chat, \u201c what i the effect of chat in teaching? \u201d a imilar anwer i given with the cloing remark, \u201c it i important to note that chat hould be ued a a upplement to, not a replacement for, traditional intruction and man teacher interaction. \u201d it i intereting to ee that chat i, eeming, able to reflect on itelf, which i omething a calculator cannot do. a it acronym indicate, chat i a generative pre-training tranformer; hence it ue a mixture of upervied learning to predict the continuation combined with upervied learning to fine-tune the reul the development of chat ha been o pectacular that there are no repreentative empirical tudie on the ue of thi new technolog earer verion of were more priive and not repreentative for it current capabiti however, the ue of calculator in education ha been widely reearched ( , ; et , ). in the , alo the ue of calculator in education wa a controverial topic, jut ke chat . hence, it i intereting to compare both. mot tudie confirm that the effect of calculator i twofold. on the one hand, tudent get more time to focu on problem-olving and undertandin on the other hand, to effectively ue a calculator, it i important to undertand how it work, i., tudent hould be able to do the ame tak manuall thi i where chat i differen mot people uing chat have no idea how it work and cannot reproduce the reult manuall however, it make no ene to ban the technology for tudent that will ve in a world where thi technology will play a major role (king, ). therefore, it i eential to create two type of tak: () tak with no acce to tool ke chat (ke a math exam without calculator allowed) and () tak where tool ke chat are expcitly integrated (, homework). for the firt type, there i no need to change much. however, it can only be teted in a controlled environmen it i not feaible to ue ai to check for the ue of ai, depite attempt to develop uch checker. for the econd type, ignificant change are needed. open-ended homework aignment where tudent need to write text cannot be ued anymor intead, one hould think of tak that require a combination of both or that involve an oral examination afterward. interetingly, chat i not ed to natural languag chat alo peak everal programming and querying language, , python, , c , c#, cript, , php, + + parql, and xquer when correctly ued, it will peed up programming tak dramaticall therefore, aignment need to be more challengin the bigget challenge i that chat may produce correct-oun but logically incorrect reul thi potentially put a ignificant burden on the teacher, that need to correct the reul moreover, thi will alo have dramatic conequence on reearch. the number of pubhed paper i growing exponentiall for example, the number of cientific paper doubled between and ( , ). the number of paper per author increaed dramatically, and it eem unreatic that all paper are read extenivel an urban legend tell u that % of the article are only read by the author and the reviewer. thi i probably not true, but it iltrate the problem that too many low-quaty paper are pubhed. there i an increaing number of paper that are not very original and have error that remain unnoticed. chat will make thi ituation wore and produce paper that are convincing, but often wron thi will ditort cientific fact, timulate plagiarim, and pread miinformation. review procee cannot keep up with thi. therefore, chat and the ke will change how reearch reult are dieminated and verified. thi will have a much bigger impact than the introduction of the calculator. _... contribution _ _.... chat for man augmentation - ia o. papp_ technology and the vae it bring drive ociety forward and often will be ahead of ociety itelf. ai i being integrated in multiple way in our ve and a major challenge remain on how to deign and develop incive ai for al have been extenively implemented to deal with communication tak that ued to be performed by man. depen on the ituation, ome tak are perfectly handled by \u2019 baed on their current capabitie, while other till require man competenci man tarted uing for automation purpoe, which quickly evolved into man tak augmentation and the creation of hybrid team, where man collaborate cloely with machine to perform relatively imple tak ( vailakopoulou et , ). the quetion i on what i next? openai chat enable functionatie that were not poible before with by the current generation of . openai chat technology, now open to everyone, ha made a critical, poibly hitorical, tranition. o far, many advanced ai appcation have been employed to deal with and problem in which faire come at a high cot (, aviation, medicine). on the other hand, implementation ha been lagging when it come to deag with tak where faire i expected, acceptable, and come with a low cot (, education) ( kabudi et , ). the latter make the ue of ai appcation perfect for learning and openai chat i enabg thi. learning happen everywhere, it doen \u2019 t happen only \u201c in cla \u201d . beide traditional etting (, univerity) learning incde training of employee & quafication of leader. the latter can be either planned (, organiation training their employee) or occur naturally a employee are uing new technologie or the exiting one in different way, uch a in vailakopoulou et () . the educational ector i trying to catch up with the impact of chat, epecially in exam. teacher are debating about it ue and if it hould be allowed while tudent are aking for advice or permiion on if and how to ue i at the ame time, ai tool to detect ai generated text are being developed a a counter meaur conidering that thee tool are contantly learning it can be expected that a tool can be aked to generate text that i not detectable by ai. a educator, we remain reponible for training the tudent to develop critical thinkin thi objective ha not changed over the . appcation ke chat can be ued either a a companion or tutor, to upport for example elf- regulated learning, or a a way to pa exam without any effort, t minimal, if any, learnin a with mot thing, chat ometime work great or jut fine and ometime it fai depen on the tak and quetion, it can give ueful, funny, or jut wrong and milea anwer. while the latter i expected to be reduced over time conidering that the training dataet will continue growing, the reponibity remain with the man to evaate and ae thee repon hence, we need to rethink how we deign learning in order for learner to develop oft kill, uch a critical thinking, complex problem olving, creativity and making, that take into account variou teaching and learning pace (, claroom, meeting room, the indutry) uing new reource ( pappa & giannako, ). finally, uing technologie ke chat can be fun a it change the way we interact with the computer, ring the need for new tudie on how both cognitive and affective factor hape our behaviour toward more advanced and \u201c truly \u201d converational agen reearch i ongoing on what entail incive ai, with incive ai tool requiring incivity to be conidered both when it i developed and when it i ued. deign for incive ai tart by provi acce to a divere group of uer, then enuring their engaged participation, that will eventually lead to empowered ucc chat, now open to everyone, ha the opportunity to allow thi. making ai appcation available to all can help overcome everal exiting due to a lack of data-driven culture or technological culture, which coupled with the need for innovative and trutworthy ai can lead to otion that are undertood by non-expert uer a wel latet new report that compa will be able to create their own cutom verion of chat, t allowing them to launch their own uing openai chat technology, poibly without uing other bran, except their own. at the ame time, conidering the potential of low/no code platform, a new generation of can be developed to help deal with multiple apect of ocietal impact, both hort and long term. chat, while rather unique , i on the firt of imilar that will become available over tim buinee and organiation that undertand and embrace thi change will develop competitive advantag already, oon after chat became open to all, announced the launch of lamda, it own chat competitor. while thee tool are free to ue , they require a lot of reource, t it i only a matter of time before they become paid ervice, epecially the one lea the marke divide and inequity will widen. for example, equity in education mean enuring that every learner, regardle of ocioeconomic tatu, language, race, geography, phyical retriction, cultural background, gender, or other attribute hitorically aociated with inequitie, ha equitable acce to advanced technologie, communication and information reource, and the learning experience they provid while the ue of advanced ke chat i till at it infancy, it i expected to experience a breakthrough in the following and hold the potential to become a new paradigm in buin the following reearch quetion can inpire reearcher from a wider range of dicipe to further reearch on the next generation of converational agent and their impact on all the actor and takeholder in our ocieti rq: how to deign incive ai appcation for enabg man augmentation? rq: how do ocial and intitutional context infence the deign and deployment of incive ai appcation? rq: how can ai appcation enhance collective intelgence and enable new form of community action for bridging the divide and inequity? rq: how can the key actor collaborate and take proactive action toward the integration of technologie ke chat for pioning practical appcation of incive ai to increae ucceful man/ai partnerhi? overall, i view chat a a training arena that i can throw idea to it and help me think. i often do thi with colleague and friend. ometime it might be about trivial tak, pointing to automation of tak, and ometime it can be about more meaningful tak, pointing to tak augmentation. intead of focuing on how to igate the ue of uch tool we hould train our tudent, the future employee, to undertand the impcation of uing uch too developing critical thinking i key and chat might help in thi direction if ued appropriatel would we accept a tatement from another peron without ome form of critical reflection? of coure, the anwer i that it depend on o many variabl a imilar approach can be followed when aeing and evaating repone from chat and all the advanced converational agent that will follow in the futur the ongoing interaction with chat allowed me to reflect on how i repond to quetion and how accurate are thee repon the recent trend of poting chat chat on ocial media how that i am not the only one reflecting on thi matter. how do we repond when we are not completely ure about our anwer? depen on the context and how expenive or cheap i to fail, we will either do ome fact checking or imply tate that we are not fully ure (, ue the term probably). after all, how eay it i to improve and ucceed without faig firt? _... contribution : overcoming reitance to change with ai_ _.... can chat help you? - ._ thi hort paper explore an emerging ai baed tool named \u201c chat generative pre-trained tranformer \u201d (hereafter, chat) and it uefulne in overcoming reitance to change when implementing new innovation. the way i go about it i to identify relevant quetion in relation to well-known terature on reitance to change and then dicu whether a project manager reponible for implementing a given new innovation would find the ai-baed chat anwer ueful? in the following i have howed a few of anwer and not fully (that would take up all everal more page). i have choen to how enough o you a reader can follow my e of argumentation. when adopting and diffuing new i the recipient often how ign of reitance when they are required to change their behaviour or adopt new behaviour. thi wa identified in academic terature ago by () who ied out tudie of change to production at the factory floor. t, the firt quetion we could ak chat to help u with may ak would be: why i there reitance to change? the anwer to that wa: . fear of the unknown: people may be unure of what the new change will bring and fear the unknown conequenc . lo of comfort or control \u2026 . lack of trut \u2026 [and three more bullet - left out here] thi anwer i pretty good and cover mot of the knowledge we have . what i miing i for example that the peron howing reitance ha a veted interet , becaue they were part of or reponible for the \u201c old \u201d thing that i being taken over by the new thin the \u201c netor \u201d in diffuion and adoption () identified five categorie (grou) of adopter called innovator, early adopter, early and late majority, and laggard. the early majority expect and wait for certain member of the group of early adopter called \u201c opinion leader \u201d to demontrate and communicate the advantag furthermore, the late majority not only want the advantage demontrated; they are alo waiting for the right opportunit hence, the late majority group can be een a having reitance to change but are in fact jut waiting for the right opportunit let u try ue chat to anwer: \u201c how do we identify opinion leader? \u201d chat anwer: . oberve behaviour: look for individual who are vocal and actively involved in haping the opinion and attitude of their peer. . urvey employee \u2026 . analye ocial network \u2026 . ae communication kill \u2026 [and four more bullet with explanation] thi i an excellent anwer. better than the one roger giv if i wa a project manager, that anwer would be really helpfu another important ource about reitance to change i () that identified factor to meaure the expected level of reitance at the individual leve he came up with a -point cale, from \u201c i generally conider change to be negative thing \u201d to \u201c i ometime find myelf avoi change that i know will be good for me \u201d . ued the cale to how in a teaching environment at a univerity that the higher the core the le kely teacher were to be uing a given innovation (new technology) for their teaching ( , , p. ). t, the next quetion we may ak i \u201c how can i overcome reitance to change when introducing a new ytem? \u201d . the anwer to that by chat wa: . communicate effectively \u2026 . involve employee \u2026 . offer training \u2026 . lead by example \u2026 [and three more bullet with explanation] again, a good anwer but not a good a the other anwer above becaue thi anwer leave out a lot of thing that could be ome anwer that ( , ) would give could be \u201c build a gui coation \u201d and thereby focu on the team reponible for change, and \u201c create hort term win \u201d . t, to ue chat you need help to judge the quaty of the anwer. and you need to be knowledgeable about the theory in order to formulate quetion. with the obervation that i wa miing ome point from i reformulated my quetion to \u201c how can i overcome reitance to change when introducing a new ytem? pleae incde phae in the anwer \u201d . and then i got an anwer that wa jut phae no more no l that i even le ueful than the anwer i go abov a a project manager we are intereted in phae that hould be in a plan toward the chang therefore, we ak \u201c what phae do people go through when they change \u201d . the anwer we get from chat i: () awarene () deire () knowledge () abity [and two more \u2026 \u2026 \u2026 \u2026 bullet] thi i not a good anwer. it i jut a repetition of the ad-model but without a ueful reference uch a ( hiatt, ). there are many other phaed model for organiational change with i roger () ha an individual change model with phae uch a \u201c prior condition \u2013 knowledge \u2013 peruaion \u2013 deciion \u2013 implementation \u2013 confirmation \u201d . and and () had another phae-model baed on a number of empirical tudi hence, chat in thi cae give an anwer that may be ok \u2013 uing the ad-model a inpiration i not a bad idea \u2013 but leave out important and probably better alternativ however, to reae that there are alternative you need to know that the anwer given i baed on the ad-mode but chat never tell you any reference or where the knowledge it baed the anwer on wa found. that i a feature given by the technology ued. finally, we could ak: \u201c why do people fear change? \u201d . the anwer to that w people often fear change becaue it bring uncertainty and the un\u00ad known. change can challenge one \u2019 comfort zone and dirupt famiar routine, cauing tre and anxiety \u2026 [continue three more e]. again, a good anwer but not a very inightful on to get deeper we need to undertand ychological theorie uch a theory of planned behaviour ( ajzen, ). o, to concde, chat i a vaable tool that can be very ueful for you a reponible for a project lea to organiational change, , a tranformation. chat may help you at the level of a good collection of textbook. however, if you want to get deeper and get \u2018behind \u2019 the urface chat may not be the tool the main deficiency i that you have no idea where the knowledge in the anwer come from? t, you cannot judge or evaate the quaty of the anwer. the other important conc point i that the more pre-exiting knowledge you have the better you can ue chat and make ure that you get quaty information out of the u _.. organiational and ocietal impact_ _... contribution _ _.... ocietal impact of chat_ \u2013 _ral d_ \u00b4 __ ince it launch in , from the time of thi writing, chat ha drawn coniderable media and academic attention ( mihra, ). it i variouly decribed a a generative AI, a large language model, and a . at it core chat i a generative pre-proceed tranformer (), a neural network that i trained on a large corpu of pubcly available dat while training, the input to the network are entence and paragraph, where the deired or target output for the network are ubequent phrae and entenc the network i t trained to predict block of text that will logically and grammatically follow the input phrae and entenc if thee output phrae are then given a input, the network can predict further tex chat i more advanced than previou verion of , a it i alo trained with a reinforcement learner that grade the many repone it produce, and output the mot uitable on man trainer provide the reward for the reinforcement learnin chat i alo able to retain the tate of the input-output repone and i t able to participate in a utained converation. chat i now ued for many appcation - to generate torie and report on variou topic; for generating or correcting computer code, though thi facity doe not provide perfect reult a yet; and to ummarie article or chapter ( , ). it i being ued a an advanced earch engine where it can provide anwer to querie in a narrative form. it can alo function a a , engaging in an extended converation, where it remember the quetion it reponded to and the anwer it generated, t reembg the programme enviaged by turing in the famou iation gam chat re ome prominent iue and quetion. an immediate et of quetion that have arien in the media are about tudent uing it to cheat on aignment and examination, about replacing job of certain type ( alekander, ; chell, ), about the originaty and creativity of repone ( chakravarti, ), and about integrating chat in variou tak in organiation. i reearch quetion have been about ue of aitance for learning, hopping, and advertiing ( et , ; kuwaha and , ; pizzi et , ), about ue of in different tak ( and , ; broek et , ), the communicative agency of ( araujo, ) and their ucce in handg converation ( hill et , ; konya-bombach et , ). iue of bia and dicrimination in data and algorithm are prominent in ai and reearch ( akter et , ; conboy et , ). another et of quetion have arien that are focued at the ocietal level, ring larger iue of pocy and regulation. _..... ocietal quetion._ one goal of ai i to produce artificial general intelgence (agi), or programme that are capable of a wide variety of intelgent tak, rivag or excee man capabitie ( goertzel and pennachin, ; , ). thi goal i in contrat to the current ai ytem that have uperior capabitie, much beyond that of the bet man, but in narrow domain, where thee are referred to a artificial narrow intelgence (ani). it i in thi context of the difference between agi and ani that chat ha a trong infenc chat i one of the firt et of programme that are ten toward agi, along with programme uch a iri, alexa, lamda, a they have a wide range of eemingly intelgent capabitie that may not exceed expert man level at individual tak, but are overwhelming owing to their cale, peed, and cop a newer and more capable verion of chat are produced, a few thing are certain: ) thee programme will require maive invetment and computing reource, and hence only the larget private firm or government will be able to develop them ( , ); and ) thee programme will be made available through the cloud, either for free or at a very low cot, to generate network effect and to onboard a large number of uer (who will then participate in further refining and training them). acro many ocietie and region there i a ditinct poibity that people will begin to depend on programme ke chat and delegate ( , ) important tak to them, initially with mall cope, and then with growing impor particularly in developing countrie, where there may be a hortage of expert on pecific topic, ke high technology, the entire undertan and dicoure will be determined by chat - a it will be a ready ource of anwer and will alo be alway availabl from chool children to enior pocy analyt, all will either ue chat a an aitant or rely entirely on it anwer to develop their own thinking, intuition, and undertan of all matter of which they have weak knowledg there may arie a need, then, for educational intitution, pocy writer, and government to undertand the extent to which opinion and thinking are being infenced by the anwer produced by cha there will be a need in variou developing countrie to undertand the bai of training of pubcly available chat programme, and how their own vae are repreented and expcated. a tool ke chat are integrated into man-ai hybrid otion ( rai et , ), reearcher will have to addre ocietal quetion of acce aymmetri in the developing country context, there already exit an iue of the divide ( venkateh and yke, ), where diparitie in ue of technology can lead to diparitie in income and well-bein though tool ke chat are eay to learn and adopt, and their deigner will enure they are even more integrated with everyday-ue , they can ampfy inequaty of reource acc one example i of uer who cannot ue engh (and other language chat can work in), a they will uffer from their inabity to ue the agi tool, while their peer will be able to. further, inequaty of acce will lead to aymmetry in the data ued to train and refine thee algorithm, where marginaed grou will not have their data repreented ( and wellman, ; weigla, ). along with abitie and kill, the agency of man-ai ytem will re quetion of reponibit reearch how that there are gradation in degree of agency, with man and ai ytem diplaying varying vae on different dimenion of agency ( dattathrani and de \u2019 , ). with increaed ue of chat, for tak uch a co, or planning, there will be increaed focu on reponibity when thing go wron along with blame and accountabity, there will be the problem of allocating legal and financial abit future reearch will have to identify the man v ai agentic reponibitie for variou domain and tak. _..... concion._ chat preent immene poibitie of a powerful agi, one of the original goal of the field of ai. though thee tool are kely to have a trong impact on many apect of buine, ociety and government, in term of both creating innovation poibitie and deting old way of doing thing, the need for reearch to addre the iue of dicoure, divided acce, and agency identified in thi note are urgen _... contribution _ _.... the potential of chat: awe, fear, digut and tranformation_ \u2013 _._ i recently chanced acro a newpaper article i gratefully acknowledge , amantha moore, gerhard chwabe, kirtin krau, monideepa tarafdar, , techataanaoontorn and ven laumer for inightful comment on thi hort piec relating how tudent in autraa had been found cheating in an one exam by outourcing (to an ai ) the creation of their anwer to exam quetion. the article did not reveal the quaty of the ubted anwer nor the fate of the tudent who had perpetuated thi action, but neverthele the meage wa clear. if one can train an ai to generate an anwer to an exam quetion, one can preumably train it to do many other thing, inc writing a complete article, if that ame ha acce to the relevant terature, data, interpretation, et i imagine that ome type of article may be eaier for a to write, , thoe that are more formulaic in character. article that require extenive citation of reference, a well a author interpretation, may be harder, at leat for the time bein ai can alo analye data, or fih for whatever relationhi might exit in data, o a to concoct a plauible contribution to knowledg indeed, an ai will kely perform thee activitie much more effectively and efficiently than a man, dicerning pattern that ede the man brain, and o conceivably creating a better quaty or more ueful contribution to knowledge than could the man author. whether the ai will then ugget a theory, which can be retropectively teted with thi fihed data, or to be inductively created from the fihed data, i another matter. i imagine that it \u2019 poibl furthermore, the ai may well \u2018improve \u2019 the guitic fidety of the final article, leveg the playing field for non-native peaker author. however, uch are alo accued of producing \u2018cogent waffle ), i., grammatically accurate combination of cnk of text from the training \u2019 ( vincent, material that doen \u2019 t really ay anything ueful and may alo contain much miinformation. cogent waffle i by no mean a new phenomenon in cholarly pubhing, but the creativity of the i circumcribed by the breadth and depth of the training materia my perpective here i primarily that of the editor of two cholarly (the information ytem and the electronic of information ytem in developing countrie). i mut emphaize that thi i an opinion with ome poible impcation. my invetigation of chat ha not gone far beyond and a few webite, , though i have alo benefitted from converation with a few colleague (ee acknowledgement). there i no formal terature review: actually, i am not ure that there i a terature that can be reviewed ince no peer- reviewed article on chat have yet been pubhed, though i did find an editorial ( o \u2019 connor, ). moreover, thi i not an empirical piece: i have no data to analye or interpre my general reaction i a trange mix of awe and fear, digut and tranformation: awe that thi i poible, fear of what the conequence may be, digut that people would be o lazy to reort to uch chicanery, and tranformation of what we find ethically acceptabl perha i hould not be urpried that ai ha moved to thi leve received widom i now that we have gone well beyond the turing tet, ince we (man) cannot ditinguih between a man crafted piece of writing and a machine crafted piece of writin perha the ai can ditinguih, a point i come to later. i am in awe to the creator of the and their nlp mode no matter the myriad contructive and poitive opportunitie to make the world a better place with uch ai, there i alo an equally ge potential both to overturn of cholarly tradition and to overwhelm the peer-review proce with a veritable dege of artificially generated paper. even if thoe ame paper are not of ufficient quaty to jutify pubcation, having them all reviewed (or even jut dek rejected) will conume coniderable time and reourc in ante-divian time, we fondly imagined that contributing author would alo be wilg to engage a peer reviewer and t to review relating how tudent in autraa had been found cheating in an one exam by outourcing (to an ai ) the creation of their anwer to exam quetion. the article did not reveal the quaty of the ubted anwer nor the fate of the tudent who had perpetuated thi action, but neverthele the meage wa clear. if one can train an ai to generate an anwer to an exam quetion, one can preumably train it to do many other thing, inc writing a complete article, if that ame ha acce to the relevant terature, data, interpretation, et i imagine that ome type of article may be eaier for a to write, , thoe that are more formulaic in character. article that require extenive citation of reference, a well a author interpretation, may be harder, at leat for the time bein ai can alo analye data, or fih for whatever relationhi might exit in data, o a to concoct a plauible contribution to knowledg indeed, an ai will kely perform thee activitie much more effectively and efficiently than a man, dicerning pattern that ede the man brain, and o conceivably creating a better quaty or more ueful contribution to knowledge than could the man author. whether the ai will then ugget a theory, which can be retropectively teted with thi fihed data, or to be inductively created from the fihed data, i another matter. i imagine that it \u2019 poibl furthermore, the ai may well \u2018improve \u2019 the guitic fidety of the final article, leveg the playing field for non-native peaker author. however, uch are alo accued of producing \u2018cogent waffle ), i., grammatically accurate combination of cnk of text from the training \u2019 ( vincent, material that doen \u2019 t really ay anything ueful and may alo contain much miinformation. cogent waffle i by no mean a new phenomenon in cholarly pubhing, but the creativity of the i circumcribed by the breadth and depth of the training materia my perpective here i primarily that of the editor of two cholarly (the information ytem and the electronic of information ytem in developing countrie). i mut emphaize that thi i an opinion with ome poible impcation. my invetigation of chat ha not gone far beyond and a few webite, , htt://en..org/wiki/chat htt://cholarlykipneorg////chat-thought-on-- impact-on-cholarly-communication/?informz = & nbd = dbafe \u2013 f- cd-ab-ceabea & nbd_ource informz = htt://wwce-trategcom/the-brief/chat/ paper written by other. ince each paper need \u2013 reviewer, we could reaonably expect each ubting author team to review (between them) \u2013 paper ubted by other author team. indeed, many automate thi uch that in order to ub a paper you need to have an account in a ubmiion ytem where you mut provide ome keyword that reflect your reearch interet; ooner or later you will be \u2018invited \u2019 through the ame ytem to review another paper. but if the creation-agent of paper (hould i call them author?) are eentially robot who/that generate paper for people who then ub them (i hope that the intricacie, vagarie and inconitencie of the ubmiion ytem make it impoible to automate thi too) in uncountable number, i hardly imagine that thee ame author will be entiatic about reviewing the ame number of paper a they ub! perha they will outource the reviewing tak to an ai ?!. that \u2019 neither a fanciful nor a fppant remark: there eem to be no reaon why reviewer hould not do thi. whether the ai can detect that the paper it i reviewing wa written by (an intantiation of) itelf i \u2019 t know and perha it doen \u2019 t matter. but it open up everal more can of worm of prodigiou girth. will the ai be able to write a critical yet contructive review of a paper that it itelf wrote? or will it find that it original creation wa \u2018perfect \u2019 and t return the review comment of \u2018accept without modification \u2019 ?! what will the e or ae think about that? i can t peak for other , but in my experience a editor of the information ytem , for intance, accepted \u2019 paper are, on average, revied . tim that impe everal round of \u2018revie and reub \u2019 , not intant acceptanc clearly omething i miing in thi equation: if the ai both write the paper and review them, what \u2019 the point of having a man- baed peer review proce at all? indeed, perha the robot will alo pubh the paper and we can dipene with the pubher a well? more practically, i upect that if the ai prove to be a accurate or ueful a the current media hype ugget, then the pubher will defend themelve by implementing detection programme (preumably uing ai ) o a to detect the kehood that a paper wa ai- authored. indeed, chat-detection programme already exi meanwhile, my own pubhing contact aure me that thi i already happening with both new pocie related to machine generated paper and check on the provenance of paper in the work. i note with ome amuement that the international conference on machine learning ha banned the ue of ai tool in writing the paper to be ubted to the ame conference, though it \u2019 acceptable to ue thoe ame ai tool to edit and improve text ( vincent, ). the e between writing and editing eem quite thin to m i there any real difference between editing, improving and writing? finally, digut, that our eteemed colleague might reort to uch unethical mean to outource paper crafting to an ai program and pa it off a their own work. in my view it amount to plagiarim. but then i have to temper my digut with the ober reazation that to be unethical, a behaviour ha to be procribed in a code of ethic: if we didn \u2019 t yet procribe that behaviour, i., there i no code regulating it enactment, then it \u2019 hardly fair to label the behaviour a unethic the rie of chat t create an opportunity for u to dicu ethical iue when uing thee and imilar too thi will potentially be a tranforming converation. if do a better job than man, hould we not ue them? if ai tool can analye data and produce fin, can they alo preent the fin to an audience? hould we openly acknowledge thee ai tool? there eem to be a continuum from a paper that i entirely written by man without any non-man intervention, through paper that are improved with pell checker, grammar checker, reference checker and the ke, through to paper that draw on data that have been analyed with ai tool, and then paper that are to a r or greater extent written by a . where on the continuum do we draw the e of ethicaty? alternatively, i it more a matter of tranparency, that any ue of technology i acceptable o long a it i openly acknowledged? thee quetion are not intended to be rhetorical: they are practical: a cholar we need to decide what i acceptable/ethical and what i no when we have decided we can enact and enforce poci but firt we need to have the converation. in cloing, i ee thi a imply the latet incarnation of diruption: chat i the forerunner of a new wave of ai and other tool that ha the ignificant potential to dirupt current proce we have already een diruption in a variety of indutrie; indeed, we ue uch diruptive example in our teaching and if we teach tranformation then we will be till more famiar with the ide why houldn \u2019 t the academic production of knowledge alo be dirupted? if we want to have any control over thi diruption, we need leaderhip and a converation about acceptable and ethical behaviour. but be ure, we can \u2019 t top tranformation. we may at mot hope to guide i _... contribution _ _.... chat: the tranformation challenge for organiation_ _jut became harder - ._ many organiation are truggg to cale up the implementation of ai and reae the benefit it offer ( , , aleh, ). the introduction of chat (ued a horthand in thi article for chat itelf and imilar product) ampfie the difficultie of ai a a \u201c conummate bullhitter \u201d ( molck, ). chat i impreive and fent but not alway righ the iue can \u2019 t be ignored \u2014 the technology indutry \u2019 comment ( tiku, de vinck, oremu, ) mean that chat will be available more widely and will be incded in other produc o how can organiation take advantage of it trength and i\u00ad gate the rik? chat can help people be more creative and productive but only if organiation can tranform to addre the iue of trut and the commoditiation of ai in a way that manage the ychological rik. chat ha emerged jut a ai ha already created a headache for organiation caued by four factor: . growth. the implementation of ai in buine procee i growing fat ( de cremer, , ) \u2014 the rapid introduction of new technologie (ke chat) mean that competitive preure for organiation are mountin . rik. becaue ai i fundamentally different from previou technol\u00ad ogie, there are new and different rik, many baed on ethical concern ( blackman, ), that are eaily triggered (perha through \u201c artificial tupidity or other caue \u201d ( boman, )). the rik are large, inc the potential of reputational, compance or financial damag . urgenc the problem cannot be deferred. an ethical approach to ai need to be deigned in and cannot be retrofitted ( floridi et , ). . tranformation difficult becaue of the complexity of the tran\u00ad formation requirement in implementing ai at cale, many organiation find it hard to progre beyond proof-of-concept activitie ( et , ). htt://wwnecom/article/can-ai-detector-ave-u-from-chat-i- tried--one-tool-to-find-out/?ftag trecf & utm_email = = cccceefdaebcfbbbfaaabcabf & utm_ campaign_id & utm_email_id = = dcddaacabddaccfcbd & utm_newletter_ id & medium email & ource iterable = htt://wwnpr.org/ection/money/////thi-- = = -i-trying-to-ave-u-from-chat-before-it-change-writing-for chat make thee trend more immediate and ampfie the tarting with tru a andel ay ( pazzanee, ): \u201c part of the appeal of algorithmic making i that it eem to offer an objective way of overcoming man ubjectivity, bia, and prejudice, \u2026 but many of the algorithm \u2026 repcate and embed the biae that already exit in our ociety \u201d . becaue ml ue data that reflect the biae of ociety, \u201c bia i machine learning \u2019 original in \u201d ( weinberger, ). pinker () frame it elegantly: \u201c knowledge i acquired by formulating explanation and teting them againt reaty, not by running an algorithm fater and fater. devouring the information on the internet will not confer omnicience either: big data i till finite data, and the univere of knowledge i infinit \u201d the cope of ethical iue red by ai i wide-ranging ( wet, ). numerou et of principle for ethical ai have been documented (over a ndred and fifty et of guidee are documented in the global inventory ( algorithmwatch.org, )) but with common ground, for example in the eu principle ( expert group on ai, ). in it current invocation, chat violate everal of thee princi\u00ad pl it i baed on ungoverned information that in \u2019 t alway reable and it doen \u2019 t communicate the reabity of that information. o, it i eay to ee that there may well be difficultie with the following principle: chat can alo be apped to a long-tan challenge \u2014 that of knowledge managemen ai ha long offered the promie of improving acce to organiational knowledge through the ue of , automated document and image analyi, provi explanation ( et , ) or through improved man collaboration. echoing lew platt \u2019 anguihed cry ( \u201c if only hp knew what hp know \u201d ( ieloff, )), organiation have truggled to make their knowledge readily availabl thi challenge fall naturally into the domain that chat inhabit, although organiing organiational knowledge in a form that it can acce will remain difficul chat can help people be more creative and productive and improve organiational knowledge managemen but it ampfie many ai that organiation are already truggg with. _... contribution _ _.... ervice marketing and management impcation of chat_ _-jo wirt_ ervice technologie, both hard and oftware, in combination with intelgent automation (ia) rapidly become more powerful, cheaper, eaier to implement and ue ( bock et , ; et , ). they have the potential to bring unprecedented improvement for the cutomer ervice, ervice quaty, and productivity all at the ame time ( and rut, : wirtz et , ; wirtz and zeithaml, ). thee technologie enable pecific ervice procee (, an addre change) and entire ervice product (, a banking ervice) to be treamed, impfied, and caled. information proceing-type ervice (think of any ervice that can be devered on an information counter, over the phone, via email, or on an app) increaingly will be end-to-end (ee) automated with no fronte employee involved. for example, mot cutomer (inc it revenue-generating advertiing cent) hardly, if at all, interact with man ervice provider. thi allow to offer high-vae ervice uch a ma, gmail and cholar for fre that i, cot are o low that thee ervice can be advertiing funded or offered advertiing free for a mall fe in future, we can expect uch ee automated ervice become the norm for many information-proceing type ervice uch a financial ervice and booking, but alo and education a marginal cot will be neggible in many cae (, wirtz, kunz, , ; wirtz, , , ). even for phyical ervice procee, intelgent automation will dramatically change the cutomer journe for example, future hair alon will be able to build innovative otion that ue mirror and ai to analyze a cutomer \u2019 hair and recommend different hair tyl hair cutting ervice robot can then execute the choen cu chat ue an umbrella technology called generative AI which get cloer to achieving artificial general intelgence that allow the technology to undertand and learn any intellectual tak jut a man can. already , generative AI i able to generate novel content uch a text, image, program code, and even poetr in contrat, \u2019 are priive in comparion. their development i typically baed on pre-exiting frequently aked quetion (faq) cum training data, all powered by till relatively ed technology which tend to make the bot repone pre-programmed. one can expect that generative AI will be introduced into many exiting cutomer interface of \u2019 other provider in addition to chat (think of iri or alexa in future \u2018incarnation \u2019 ). that i, chat and other general ai ytem allow opening-up of and ervice robot to move cloer to \u2018general intelgence \u2019 and provide ervice cloer to the level of undertan and flexibity a \u2019 man fronte employe moving cloer to general intelgence i an important next big tep in ee automation of cutomer ervice a i kely to be a gamechanger for many ervice and thee new technologie will bring the fronte to new level, not jut in their ai engine, but alo in deign of the cutomer interfac for example, already , oul machine, a - privacy and data governance \u2014 inc, for example, gdpr regu\u00ad lation and the \u201c right to forget \u201d ; - tranparency \u2014 inc the need for explainabity ( et , ) which would impact it ue in governance, compance (, demontrating adherence to regulation), legal quetion (, about intellectual property) or cutomer interaction; - accountabity \u2014 how can an organiation be accountable for infor\u00ad mation derived from chat ued by taff under thee circumtance? how can it avoid fraud or criminal activitie? chat make organiational governance more difficult becaue it extend the ue of ai outide knowledgeable data cience team. it i available to developer through programming language (, python) or cloud ervice (, amazon web ervice, azure, ). in addition, o-called \u201c no code \u201d or \u201c low code \u201d technologie enable ai to be ued, in a imilar way to excel and acce, directly by \u201c buine technologit citizen data cientit \u201d ) who are not profeional developer. becaue it i o eay to ue by \u201d (inc \u201c citizen developer \u201d and \u201c anyone, chat take thi trend even further. thi mean that the problem of managing ai rik in organiation ha unprecedented cal it ha expanded from a (relatively) mall team of knowledgeable profeional to order of magnitude more people without any experience of the rik or the governance required. how can ai at thi cale be controlled? following exiting model for development ( uk government ervice, ) and in e with the eu principle, the need for high level of man control ha been argued by () , amongt other. he argue for procee and interface that exhibit the \u201c high level of man control and high level of automation \u201d that can alo increae man autonomy ( bern et , ). but the appcation of thi approach at cale i daunting \u2014 how can control catch the wide range of rik in time to igate them? in addition, chat ampfie the ychological rik aociated with ai (and with information proceing more generally). a () point out, thinking rigorouly require effort and intead people often rely on intinctive thinking that ignore the quaty of information. chat play directly to thi tendency \u2014 it cut out much of the hard work and produce eemingly impreive outpu why bother rigorouly aeing the detail when the reult look good? thi i jut part of a wider quetion: how hould ai and people work together to take advantage of the bet that each can offer ( bern et , ). ai offer the potential for automating ome work and letting people focu on higher vae, more creative activiti thi i a key opportunity for chat \u2014 it can eaily give people acce to idea and knowledge ( et , ) jut a it already being ued to enhance the productivity of oftware developer, writer and other profeion. developer of what they call \u2018 people \u2019 , allow ervice firm to tailor their workforce to their deired brand image, poitioning, and cutomer preference (, age, ethnic group, gender). furthermore, for cutomer it will be largely inditinguihable whether they are erved by a ervice provider or a man employee, and they are kely not to care very much. one can even expect that the intant availably (i., no waiting for a cutomer contact agent to become available), / ervice, and in one preferred language will be preferred by mot cutomer over having to dial into a traditional call centr furthermore, the cot impcation are ignificant, and given that we ve largely in competitive market economie, thee cot aving are kely to be competed away, lea to increaing tandard of vin a we are at the beginning of thi technological revotion of cutomer ervice, reearch i needed to undertand better the key vae driver of chat and other generative AI otion for the ervice ector. important reearch quetion incde: () how to deign, operate and continuouly improve frictionle, generative AI governed cutomer journey; () how can thi technology guide cutomer effectively through their journey and how can it be deigned to be cutomer-error tolerant and () to mater automated ervice recovery when needed. finally, chat and other advanced front e technology (whether virtual on video or phyical a in a ervice robot) y eriou ethical, fairne, and privacy rik ( belk, ; , ; wirtz et , ). for example, the vat poibitie of capturing data and oberving and analying cutomer and gaining inight into their ve and ychology are well beyond terrifying cenario decribed in hi claic book \u201c : a novel \u201d ( wirtz et , ). it i diconcerting that thee technologie can reult in cutomer being aeed, predicted, nudged, all often without their conent and awarene (gawer, ). we will need reearch to undertand, manage, and igate the rik of generative AI uch a chat and other technologie that get ever cloer to achieving artificial general intelgence technology when ued in cutomer ervic _... contribution : marketing in the world of -. and chat:_ _futuritic reflection -, , _ _ and adil _ _.... chat and marketin_ technology ha played a crucial role in marketing during . ai ha extenively contributed to marketing during the previou five . from automation to analytic, ai ha accelerated marketing performance to a greater extent ( et , b ). the i one among them which ha gained broader attention from marketing practitioner a well a from academician ( ). employ ai architecture to repond to cutomer querie in a imulated environment balakrihnan et , ( , ). ke , openai ha introduced chat, a ophiticated ai platform that ue language proceing model to anwer man querie ( openai, ). the function of chat are ge, even incomparable to modern ai technologi chat ue generative pre-trained tranformer () architecture which openai alo developed. academician and indutry profeional are perplexed by the growth and peculation of chat during the lat . the recent verion of - i a ophiticated ai model that can provide ample cope for language tranlation, modelg, and generative text ( ghe, ). openai made it mark with dale, a new ai ytem that can create reatic art and image baed on an expected language parameter ( openai, ). now, many peculation are traveg around openai, dale, , and cha the future of chat motly remain unknown, but and opportunitie e ahead for buine epecially for marketer chat can offer variou opportunitie at different tage of the cutomer purchae journe _.... opportunitie for marketer._ cutomer information earch and query handg are inevitably preent acro the tage of the cutomer purchae journe can chat erve a imilar or the ame purpoe for the cutomer? the quetion require more extenive invetigation in conidering on how chat decribe it buine mode table offer perpective inight on how chat can benefit marketer in variou wa however, harveting the excive benefit of the chat ret upon it future developmen table how eight trategie that can ue chat: buil marketing campaign, content marketing development, content picture and art deigning, ervice marketing, cutomer experience, keyword uggetion, marketing reearch and brand comparion. the table alo how indicative otion and reflective tactic for every trateg indicative otion explain the operationazation of chat in the repective marketing trategy, and reflective tactic explain the tactical move marketer hould follow to leverage chat and -. to their fullet potenti chat ha imilar reflection of earch engine optimiation and content marketing flavour. however, chat, to our knowledge, doe **table ** chat in marketing trategi **marketing** **indicative otion** **reflective tactic** **trategie** buil marketing campaign buil chat might be able to chat i a generative tool marketing provide uggetion to develop which require precie querie, campaign a ucceful campaign. uch a: \"ugget me an example: \"ugget me an effective marketing campaign effective marketing campaign on intagram for a bouquet on intagram\" tart-up.\" content chat can ait in however, the preciene of marketing provi appropriate and the query hould be more accurate content for the given accurate to get creative reul query related to a campaign, product, ale page, email, and blog pot chat might be able to provide uggetion to develop a ucceful campaign. example: \"ugget me an effective marketing campaign on intagram\" however, the preciene of the query hould be more accurate to get creative reul content chat can offer idea for deigning deigning and other improvement content chat can offer idea for dale can be ued to deign deigning deigning and other the product creatively a improvement intructed in the query baed - i the next-generation the hould be able to ervice language generative AI which integrate - and dale can be ued in for to generate appropriate avatar effective query handg in the converation baed - i the next-generation the hould be able to ervice language generative AI which integrate - and dale can be ued in for to generate appropriate avatar effective query handg in the converation cutomer ai-baed experience i well the role of chat in other experience recogd in academic immerive technologie will teratur chat can decide how better the provide a more enriching experience it can provide experience to the cutomer compared to the preent tate cutomer ai-baed experience i well the role of chat in other experience recogd in academic immerive technologie will teratur chat can decide how better the provide a more enriching experience it can provide experience to the cutomer compared to the preent tate of ai experience keyword chat can provide keyword the earch for content and uggetion uggetion which can ait keyword hould be nard ponored campaign. apart baed on the peronaed from regular keyword, campaign requiremen chat allow marketer to tet the alternate keyword in the campaign the earch for content and keyword hould be nard baed on the peronaed campaign requiremen marketing chat can ait marketer reearch in teting content performance (a/b teting), content performance, market tatitic, and demographic targeting information. marketing chat can ait marketer the reearch point may be reearch in teting content performance reflective from a data point of (a/b teting), content the lat two to three . o performance, market tatitic, the recency effect will work in and demographic targeting term of marketing reearch. information. while chat might not be able to perform a/b teting in it current form, it can provide ome general teting guidee, benchmarking content, and tatiti brand chat can ait marketer chat could help collect comparion in undertan brand data about other brand (, poition againt rivalrie to \u201c compare iphone and enhance the exiting brand. \u201d ; \u201c analye of chat could help collect data about other brand (, \u201c compare iphone and \u201d ; \u201c analye of marketing \u201d ). the collected data could be ued for different purpoe, uch a new product development (npd). not work ame a . it ha a trained dataet with a gb equivalent ize ( theconveration, ). moreover, the learning competence of i expected to grow in . unke other earch engine or content curation platform, chat can preciely anwer queri of all the benefit that chat can provide to marketer, it i paramount that company and content marketing team hould leverage the fullet potential of - and it aociated too - can curate content uing ophiticated learning algorithm, which can help marketer arrive at better reearch reult and get more optimied conten i a content-buil platform that ue - to better erve cutomer with earch reult ( , ) and optimie long tail reult ( adam, ). marketer could potentially integrate the ai interface (-) into the tructure to enrich ai-baed cutomer converation. in the preent cenario, mot operate in a imulated environment; when integrated with chat, marketer may find fruitful cutomer engagement with a multilevel of data point acquired from the cutomer. future chat model, when followed with proper preciion, can alter their avatar poition baed on the converation mood and t provide cutomer engagement and experienc marketer will explore the opportunitie of framing brand placement in imilar technologie in a ponored wa neverthele, it depend on how openai decide it buine model and whether it follow a ubcription, premium or freemium mode _.... for marketer._ while chat and -. look promiing for marketer, there are ome marketer have to fac chat can be an effective content curation tool imilar to . till, ue robut databae model with ai-baed learning \u2212 algorithm, which indicate that keyword-baed content or earch engine marketing may not be effective in chat architectur given that the ai pre-trained algorithm are more powerful in the chat, marketing trategie require a well-defined collaboration with openai. ome compa collaborate with openai to ue -. for their tool, uch a , copai, reper.ai, japer ai, and quickchat ( bhattacharyya, ). though the adoption of -. will increae in , the financial and knowledge capital required for it implementation can be g the power of chat and -. may require fewer man effort compared to the current technology-baed marketing environmen thi cenario ubequently will quetion and may confct with the trategical orientation of marketer and may threaten variou traditional marketing principl notably, the generative repone provided by chat are ubject to the query red by uer. o an unpecific query may lead to erroneou reult, t exten to brand vae degradation. o it will be a challenging tak for marketer to build an eco-ytem where cutomer querie are anwered preciel _.... future reearch direction._ after chat, i and marketing reearch may take a new turn on how reearcher will look at ai-baed performance too future reearch which involve - hould focu on invetigating the architecture of how organiation can employ - and chat model in the exiting tate of their buin primarily, tudie hould explore how generative AI technologie can benefit marketing in cutomer ervice, cutomer engagement and experience, content curation and development, marketing reearch, lead generation, commerce, and promotional activiti reearch hould alo focu on knowledge of how cutomer may welcome thi powerful tool in the verion of , or can it replace entirely man in cutomer ervice? reearcher hould focu on developing framework to integrate chat with their to enrich it preenc chat may not alway provide poitive entiment for every product and brand. o beyond looking at the benefit of chat, reearcher hould explore how marketer may perceive chat a a threa beide concentrating on the text querie, future reearch hould alo focu on the role of picture and art in generative AI framework. future tudie may alo explore the effect of ai-generated marketing-related content on ociet for example, the interplay between ai-generated content and ai afety might be invetigated to find the impact of miagned ai on uer conuming ai-generated conten overall, the ue and of chat motly remain unexplored. preently reearcher perceive the future of chat baed on the exiting knowledge of reflective ai. with chat yet to evidence a erie of development, reearcher hould enhance the available knowledge in the area of i. _... contribution _ _.... chat in banking ervice_ \u2013 _, mo ahmad_ _albahrawi and ._ chat i an emerging technology et to change the landcape of converation agent ( , ); chat i aid to build on the propect of the , making converation more man, anwering quetion, generating idea, and uggeting otion. it ha been conidered to hape im, law and marketing with it content-creating trategie ( ng et , ; , ). it i not urpriing to ee buinee evaating how they can integrate thi technology into their operation. thi piece, however, aim to explore the propect of chat in financial ervice ( ). bank have alway been known to accommodate technology and tranform their operation ( dowg, abdulquadri et , ); from the time of one banking to open banking and even and robo advior and invetor, bank have alway adopted technology ( ) and not urpriing to ee many bank cloing their phyical branche and either oetan et , ; , adopting financial technology (fintech) to treame operation ( bonfim et , ; , ) or converting into bank. it would not be urpriing to ee how chat can be integrated. however, it i imperative to recog that bank operate in a highly regulated ector and technology adoption i often trategically explored ( vive, ; , ). in ght of thi background, thi piece contextuaed retail financial ervice acro three trand \u2013 financial ervice marketing, proviion and requiition a a pectrum of interaction between the conumer and the bank. each trand i ubequently dicued while highghting the propect and impcation of cha **. propect and impcation of chat in banking ervice** _.. financial ervice marketing_ one of the bank \u2019 primary reponibitie i to introduce financial ervice to cutomer, either their exiting conumer or their propective cutomer ( ). bank can proce a lot of information baed on their engagement with cutomer and then be able to oetan et , offer them relevant product and ervic ai ha been tremendouly deployed in thi area of banking to undertand conumer \u2019 need and be able to target them with neceary product effectively ( et , ; ). here the bank i aking conumer \u2013 come bank with u. there are tremendou opportunitie for chat at thi point, a bank can ue it for their back-end operation, data analyi and marketing financial ervice without direct engagement with the cutomer ( ey et , ; , ). there are poible appcation for developing and implementing marketing communication trategie, undertan conumer \u2019 need and creating peronaed cutomer offer ( et , ; ; omoge, gala, & horky, ). thi technology can be ued for content creation, integrating emotional appeal through man converation feel in marketing campaign. conidering the high regulation in the ector of financial ervice, there are ignificant impcation for the claim being made by cha thee ation ugget that marketing communication may not olely rely on chat; man involvement would till be needed to verify the trutworthine of the inight and peronaed offer. there i alo a poible need to declare the ource of information \u2013 ha thi campaign been auto-generated by an ai machine? therefore, marketing hould take advice in the context of that knowledg bank would be expected to invet in the infratructure, exploring their technical capabitie and man reource to integrate it into exiting tranformation trategie ( abdulquadri et , ; \u02c7 \u02c7 cek, ). _.. financial ervice proviion_ conumer will alway need the bank to provide financial ervice ( oetan et , ), there will alway be reaon to engage - and with thee engagement, data are being generated which are beneficial to both partie ( et , ). there e an opportunity for chat to explore thee dataet to inform ome banking deciion. at thi tage of the engagement, bank are inviting conumer to \u2018come bank with them \u2019 , bank need to how ome form of undertan, comment, and awarene about the need of their cutomer ( heth et , ; omoge et , ). bank can ue chat technology for their front-end operation to enhance buine operation and directly engage with cutomer. thi converation agent build on the \u2019 ucce, which ha been well integrated into banking operation; the i ued to enhancing cutomer \u2019 experience, provi anwer to frequently aked quetion, and treaming the banking relationhip ( abdulquadri et , ; balakrihnan et , ). bank can gain inight into their ervice proviion quaty, improve their algorithm deign and improve cutomer ervice ( , ; oetan et , ). however, trut in ervice proviion will be paramount ( , ) a chat find it way into banking operation. it would not be urpriing to ee conumer quetioning their trut in the ervice and information provided. could cutomer make a better deciion if and when erved by a man? are cutomer wilg to accept offer made by thee technologie? what are the impcation of ervice conumer with vulnerabity or the impact of the dark ide of thi technology on conumer \u2019 well-being? perha technology can \u2019 t be wron there are alo impcation on convence, promptne of ervice, and accurate deciion ( et , ; ghazwani et , ). bank would be expected to invet in training taff and educating cutomer about what \u2019 available and what can be ince many cutomer till need to be converant with the , bank need to know their cutomer \u2019 need and how far to puh the technology drive ( abdulquadri et , ). _.. financial ervice requiition_ with the growing power of financial technology and the diruption in the ector, many conumer are looking beyond their bank for financial advice and invetment option ( ey et , ). many fintech compa are not bank but are offering innovative financial product, and the chat provide an opportunity for thee compa to meet the growing need of conumer. at thi tage, conumer are looking beyond their bank and aking \u2013 who hould i bank with? they are looking for platform that agn with their vae and intere cutomer can ue variou ai-driven platform provided by fintech compa to get advice from varied ource without directly engaging with any bank ( ghazwani et , ; et , ). they do not have to rely on their bank for advice; they can look at other provider a they eek information about where to invet, money management, and different financial need. with chat, conumer would be aking, \u2019 where hould i invet? \u2019 , \u2019 which ethical fund hould i invet \u2019 or \u2019 when do i invet? \u2019 anwer to thee quetion, a provided by chat, may infence their deciion. it i, however, imperative to recog that data to inform the deciion and output of the chat would be importan a conumer rely on thi robo advior ( zhang et , ), the data upon which they are trained would be eential to enure they get unbiaed information ( et , ; ). kewie, there would be impcation on how bank can poitively and ethically infence deciion and advice provided by the ( ey et , ). impcation on individual invetment preference would alo be pertinent regiou, potical, and environmental interet could infence invetment deciion. how would conumer get information \u2013 about invetment option that agn with their ethical, regiou or potical beef ( ; bukhari, et , )? who will update and train the with thi information? where will it be riedel et , ourced? there are ignificant impcation for financial ervice provider to enure that the correct information i provided and made available to the conumer to allow them to make an informed deciion ( et , ; ). while emerging fintech compa are developing thee financial ervice management tool, allowing cutomer to ak quetion and get financial advice, it i eential to re awarene a cutomer need to know what \u2019 available ( abdulquadri et , ). **. concion** the ge befit of chat have been recogd, and with the amount of invetment and interet in thi technology, it impact i bound to grow ( dowg & cey, ; ng, , & murray, ). brand mut tart exploring their propec thi article ha focued on retail banking, provi a reflective inight into the adoption of chat acro financial ervice marketing, proviion and requiition. there are opportunitie for manager, practitioner, and pocymaker to have a hotic view of thi technology; however, it i eential to acknowledge that thi i an emerging area for reearch, and there are opportunitie for future reearch to etabh thee poition empiricall _.. contribution : uing chat in tourim, travel, tranport and_ __ \u2013 _dirio buha_ technology and tourim diffue innovation acro tourim ervice ecoytem dirupting legacy operational practice and procee ( buha, ). ai and ml are emerging rapidly a new technological tool that will further revotio the ue of technology in the tourim, travel, tranport and ( buha et , ). until the launch of the chat generative pretrained tranformer (chat) a a language model developed by openai deigned for generating text-baed repone in a converational manner, ai wa only ued by technology expert, rather than the general pub in early chat gave acce to ai and ml learning to the general pubc, by anwering untructured quetion in natural language tex chat empower upercharge the generation of coherent and contextually appropriate repone to natural language inpu thi technology will revotio earch and will tranform the of acce to product and ervice acro indutri naturally a a ervice wa challenged, not only becaue earch i changing by , but alo becaue it own ai ervice underperformed whilt bing reurfaced with a tronger ai propoition. effectively earche for web page that incde key phrae ued for earch. \u2019 earch algorithm i deigned to ue keyword and phrae entered by the uer to return a t of web page, image, and other content that match the quer chat ue a language generation model and the tranformer architecture developed by openai to earch acro a maive corpu of text data and to amalgamate comprehenive man-ke text anwer baed on the input it receiv it i deigned to repond to natural language querie in a converational manner and can anwer quetion, ummarie information, and generate a comprehenive tex both technologie can be ueful for anwering quetion although they are deigned for different purpo naturally, traveller (demand) and tourim, travel, tranport and hopitaty organiation and detination (upply) are excited about the incredible potential the ai, ml and chat tool bring into the ecoytem, a iltrated in table . on the demand ide, traveller information i critical for their marketing text, decription, webite and ocial media content can be widely ditributed to attract more viitor. a very wide range of back- office function can alo benefit from fact-fin enquirie and the identification of reourc menu engineering and recipe development for example may benefit retaurant and hotel when chat ait in the development of innovative gatronomy offerin . iltrate uggetion for greek gten-free recip overall, chat can help tourim, travel, tranport and hopitaty organiation to revotio cutomer communication, improve ervice and enhance the travel experience, treame operation and have acce to knowledge databank. the viraty of chat intantly iltrated the tremendou poten\u00ad tial of ai and m however, it alo brought to ght that language model ke chat are complex and continuouly evolving ytem, o there i alway room for improvement and further developmen a range of iue related to intellectual property and ownerhip of data wa alo expoed. there are ahead to improve the ytem by uing more divere training data, inc text from different language and culture; undertan a more divere et of uer; provi clearer fallback repone; developing the depth and breadth of information provided; and avoi confuing or milea anwer. incorporating more external knowledge ource, uch a databae or api, uer- generated content, and uer feedback into chat repone generation proce can help it provide more accurate, in-depth and up-to-date \u2019 information. analying big data fater and incorporating real-time data will ait language model to learn fater and have a bigger impact on the indutry ( buha , ; tylo et , ). neverthele, it i evident that thi revotionary technology will be aiting manity to interact fater, cheaper and more efficiently cocreating vae in the futur but it hould alo be noted that chat can alo be ued to generate fake review on hopitaty and tourim organization. _.. impact on the academic ector_ **table ** chat ue in the tourim, travel, tranport and hopitaty ecoytem. **demand/tourit** **upply/tourim organiation and** **detination** information fin concierge ervice for conumer buil itinerarie marketing content text/picture generation earching for peciaed menu engineering and recipe development ervice eminating choice fact fin dynamic itinerarie identification of reource content haring ocial media and organiation own web page atifaction. they earch for information, contruct itinerarie, elect uitable timetable, and evaate alternative product and ervic tourim by definition i a hotile indutry, a people/cutomer travel to unfamiar detination to cocreate experience ( buha et , ). they conume product and ervice that meet their requirement in the preent context ( ). therefore, they need extenive information provided by everal organiation and ummaried in a buha & inarta, meaningful and comprehenive forma they have reed on earch engine, uch a , ince to find information, build itinerarie, earch for peciaed ervice, eminate choice and develop dynamic itinerarie ( . ). they had to go through t of webite in order to then co-create their experience by combining different reource ( . ). chat offer the opportunity to combine a range of different re\u00ad ource into a text that provide a comprehenive text anwer to their enquirie ( . ). by uing chat, tourit can receive quick and accurate information in natural language to help them plan their tri and make the mot of their travel experienc the high ue of innovative marketing will have a higher one infence and loyalty particularly for young people ( buha et , ). when chat i combined with voice aitant and ai i combined with contextual real time ervice it will offer a revotionary mar cutomer ervice ( , ). on the upply ide, chat can ait tourim, travel, tranport and hopitaty organiation with both cutomer phaing and back- office function. chat ha a real chance to make an impact in the travel indutry through trip plannin by allowing traveller to ue ai to create a trip itinerary and find top hotel, the time-conuming proce of ifting through numerou option can be reduced to jut minut provi concierge ervice, chat can ait in anwering traveller enquirie by generating information and anwer about detination, and attraction. provi travel recommendation for event, and activitie, hotel, retaurant, and other travel ervice, a well a provi advice on local cutom, via requirement, and travel ti enhance vae-added ervic they can ait with booking and reervation inquirie and can provide guet with information about availabity and pricing a well a ait with the booking and reervation proc chat can peronae recommendation for guet baed on their interet, abitie, diabitie and preferenc . iltrate ome uggetion for a bd traveller to pari, franc eventually, it can empower cutomer-facing bot ( t \u00b4 ercio pereira et , ). chat can alo create alternative itinerarie, route and tran\u00ad _... contribution : generative AI in teaching and reearch: ome_ _preminary thought - ryan wright_ _ arker_ the launch of chat in of ha caught the atten\u00ad tion of all cholar, regardle of dicip the popular pre ha alo engaged in dicuion around the impcation of chat, and, more broadly, on generative AI, highghting the many potential promie and pitfall of thee ytem. a a background, generative AI tarted gaining traction in when generative adverarial network (gan) were developed and were widely ued to create ueful output uch a facial image and noie ma ( crewell et , ). now, aided by a web interface provided by the company open ai, the generative AI tool repond to querie in engh. further, thee tool have produced anwer to complex quetion inditinguihable from expert man repon a i cholar who view emergent it phenomena uing a ocio\u00ad portation option, evaating alternative for travel planner, corporate travel compa and agencie and tour operator ( . ). by provi multigual upport, chat can communicate with traveller in multiple language, helping to improve the overall experience and increae atifaction. chat can help alo tourim, travel, tranport and hopitaty organiation to generate marketing content and detailed decription for attraction, hotel room, facitie, and ervice a well a develop detination content for ue on webite and ocial medi the generated technical perpective ( ), offering the world an undertan of generative AI adoption and ue, while conidering the arker et , unintended conequence, i not only conitent with our expertie but i alo our reponibit conequently, we expect that the i will kely receive many theoretical and empirical manucript on generative AI in the near futur it i our perpective that, ultimately, the appcation of generative AI in our own work practice will ignificantly hape the reearch within the i and beyond. our goal here i t to provide ome preminary thought on how i cholar can tart incorporating generative AI into their profeional ve, particularly in teaching and reearch. we will alo take a long view of the impcation within each of thee categorie of work. we begin with what mot popular pre and univerity guidance ha centred on, which i the impcation for our teachin **. .** output: what can tourit with kid do in kalamata, greec **. .** chat output: what can tourit with kid do in kalamata, greec _.... teaching in the era of generative AI._ the releae of chat and the commentarie that have followed have caued a great deal of anxiety to many academi thi anxiety i driven partly by the need to maintain academic integrity in univerity claroom ( cotton et , ). chomky ha been quoted a aying that thee ytem enable \u201c baically high-tech plagiarim \u201d and offer \u201c a way of avoi learnin \u201d it i clear that there are academic integrity iue do exit ( roenblatt, ), even with tool that can be ued to detect generative AI text (ee: htt://platform.openai.com/ai-text-claifier). however, we argue that cloing off the poibitie of uing uch technologie by pointing to academic integrity iue i a ak thi technology ha the potential to fundamentally change the claroom experience and the knowledge and kill outcome of our tuden becaue of the incredible potential offered by generative AI, we offer uggetion that higher education intructor can ue to engage deeply in thi diruptive technolog firt, it i critical that the mindet ued by intructor i that of experience and experimentation. in the i terature, a helpful framing to thi exploration i it mindfuln it mindfulne, defined by thatcher and colleague (), incde four element: ) alertne to ditinction, ) awarene of multiple perpective, ) openne to novelty, and ) orientation in the preen intructor can ue thi theoretically derived contruct to help engage tudent in exploring technology too the ue of it mindfulne-baed training ha been hown to improve reitance to job burnout ( pfl\u00fcgner et , ), help identify fake new ( , ), and create more ecure one behaviour ( , ). it will be important to invite tudent into the converation and allow them to alo apply it mindfulne to generative AI in their work practic profeor and the tudent hould explore both the appcation and the boundarie together, t allowing the ue of thi technology in way that were unimaginabl there have been everal paper pubhed on rn, arvix and other fat-to-pubh outlet that provide high-quaty in-cla exercie and aignment allowing the tudent to experiment htt://wwopenculturcom///-chomky-on-chahtml under the guidance of a profeor. for example, an intructor can ak tudent to ue chat to write an eay on a topic related to the cl then the intructor would ak tudent to provide a critique of thi ea an examination of the trength and weaknee of the eay hould help aid in the exploration proce ( , ). econd, and related, it i important to provide guidance to tudent on not only the ethical impcation of uing the technology but alo the boundarie with repect to the capabiti reearch ha hown that \u201c\u2026 trut in a technology i baed on what the technology can do for the peron, uch a giving help and being reabl \u201d (lankton et , , p. ). auming thi hold, tudent will trut the technology becaue of it capabity to aid in multiple work practic it i the profeor \u2019 role to offer a critical view that allow tudent to explore and ue critical thinking when uing technolog reearcher have already provided compelg evidence that generative AI in general and chat pecifically provide biaed output (, et , ; hartman et , ). we acknowledge that generative AI i one in a e of everal tech\u00ad nologie that have dirupted the claroom experience for tudent in higher education. pat diruptive technologie incde calculator, email, earch, tatitical package, et next, we will take thi ame aumption and apply it to the reearch proc pecifically, we will provide guidance for reearch on incorporating generative AI into their reearch work practice uing a imple exampl under the guidance of a profeor. for example, an intructor can ak tudent to ue chat to write an eay on a topic related to the cl then the intructor would ak tudent to provide a critique of thi ea an examination of the trength and weaknee of the eay hould help aid in the exploration proce ( , ). econd, and related, it i important to provide guidance to tudent on not only the ethical impcation of uing the technology but alo the boundarie with repect to the capabiti reearch ha hown that \u201c\u2026 trut in a technology i baed on what the technology can do for the peron, uch a giving help and being reabl \u201d (lankton et , , p. ). auming thi hold, tudent will trut the technology becaue of it capabity to aid in multiple work practic it i the profeor \u2019 role to offer a critical view that allow tudent to explore and ue critical thinking when uing technolog reearcher have already provided compelg evidence that generative AI in general and chat pecifically provide biaed output (, et , ; hartman et , ). we acknowledge that generative AI i one in a e of everal tech\u00ad _.... reearch in the era of generative AI._ a noted, chat i not the firt ai tool to change reearch practic grammarly (wwgrammarlcom) i an example of a popular ai tool ued to improve academic writin rtutor.ai (wwrtutor.ai) i an ai that can generate r code for tatitical analyi. alo, reearch rabbit (wwreearchrabbi ai) i an ai tool ued to produce terature revie imilar to the concern regar claroom integrity, reearcher have alo red ignificant concern regar content created by chat ( ele, ). our colleague in finance have provided evidence that chat can provide ignificant help in generating high-quaty manucript ( cey & dowg, ). quetion have urfaced on attribution and **. .** chat output: detination information for diabled touri ownerhip of thi text generated by chat within reearch manucript ( , ). at thi time, our perpective i that generative AI can offer an acceleration to reearch imilar computer-baed tatitic package, and even the internet earch engin computer-baed package allowed reearcher to run analye on data that by hand wa difficult or even impoibl the internet ha allowed reearcher to acce material in real-tim modern reearch practice have benefited greatly in the peed and quaty of reearch uing thee tool ( ccany et , ). the practice of developing reearch ha been well documented by our dicip we rely on the guidance provided by and () and and and () to examine how generative AI may be utied to accelerate the development of a terature review and reearch quetion. developing a terature review i a good candidate for evaation a they are typically the preminary tep in the reearch proc \u201c we contend that a terature review alo require a higher-level ynthei. it typically need to integrate concept acro domain into a hotic treatment of a ubjec the author ha to identify what idea matter and then find a way to coherently k them into a tream that ha a clear and relevant expoitory flow for the intended reader. \u201d ( and , , p ). and contend that the terature review proce tart with element mapping which urface the core relationhi between concept and proce the element mapping culminate in the co of each relevant pubcation. thi tak i well-uited for generative AI which can develop an element map imilar to the ontological map offered by theoryon ( , , ). the generative apect differ from previou tool a it allow the reearcher to reconceptuae the element ma baed on their expertie and the inight garnered during the proc further, generative AI can offer new mapping that i created becaue it can examine the corpu of the terature, unke manual databae earch and tate that the goal of the terature review i to provide a meta-analytic and that \u201c the fundamental problem i that knowledge i not encoded, and cholar mut rely on the method of their forebear (rea or canning many paper) to take a tep forward. \u201d ( and , , p ). knowledge i now being encoded at a cale never een befor becaue of thi proce, generative AI can now identify related concept iteratively with the reearcher t accelerating the reearch proc **. .** chat output: evaating travel itinerari developing a terature review i one of many te along the reearch proce that will benefit greatly from generative AI. analyi of the data inc urfacing econd-order pattern will certainly alo benefit from thi technolog the formulation of the dicuion and concion are alo ripe for ai utization. _.... what_ _\u2019_ _ next?._ becaue the tool are evolving quickly, funded by well-reourced compa uch a and , their capabitie will continue to gro the ethical guidee for univeritie and alo need to evolve along with the appcation of generative AI. ome have already provided guidance to their author. for example, in repone to author ting chat a a contributing author ( kung et , ), ha developed gui principle to help author with the ue and attribution of generative AI text ( , ). in um, generative AI doe not quafy for authorhip but the ue of the technology hould be documented in the method ection. other than guidance about attribution, mot have remained ilen one could imagine in the hort term that all and conference will provide guidance to author on the correct (and incorrect) ue of generative AI too thi i inevitabl uing thee tool will allow academic to focu more on the intellectual puruit that need higher-order kil to concde, we contend that academic mut prepare for thi new reaty uing novel claroom experience and reearch experimentation, and i cholar have an important rol our work in thi regard i critical becaue it can provide leaderhip for education and reearch acro academic dicip _... contribution : chat: the new wave of ai tool in higher_ _education_ \u2013 _iobhan o_ _\u2019_ _connor_ the advent of ai ha led to the rapid development of automated oftware tool uch a . although thee originated in the \u2019 with computer program uch a eza ( weizenbaum, ), modern day leverage nlp and ml technique to analye and undertand text and audio data, enabg them to interact with and repond more quickly and accurately to virtual converation with man uer ( brachten et , ). ai can appear in many form uch a pop-up virtual aitant on webite, integrated into mobile appcation via m, or a tandalone audio-baed device that can be ued at hom they are becoming popular in a range of ector inc higher **. .** chat output: menu creation for retauran education where they are being developed and deployed to anwer querie about the availabity and acceibity of educational programme and univerity ervice, to help tudent navigate e-learning reource, and to increae engagement with curricula and provide intant feedback, with a view to improve learning outcome and the tudent experience ( , ). if well deigned and integrated with exiting computer ytem, ai may alo reduce the workload of educator, adminitrator, and univerity management by upporting tudent which would enable them to focu more on pedagogical reearch, curricum development, and innovation in higher education. example of commercially available ued in ome univeritie in the united tate and united kingdom incde \u2019 ( , ) and amazon \u2019 qnabot ( , ), while other are under development (edubot, ). a new ai called chat, baed on a large language model, wa launched by a commercial company, openai, in a a follow up to a previouly developed ( openai, ). it utie reinforcement learning algorithm to optimie the language model with man feedback, having been originally trained uing man ai trainer who generated a range of dialogue that wa fine-tuned uing upervied learning and ranked to develop a reward mode report indicate that the wa trained on a large dataet ( gb in ize) from text on the internet, equivalent to milon page of text which would take a man being approximately to read (welh, ). although the inner working of chat are not fully tranparent, openai do acknowledge ome of the ation of the and other are actively interacting and experimenting with it to identify more ( ele, ). the impcation of chat and other type of open ai platform in higher education are hotly debated. ome argue they could be ued to aimilate knowledge quickly which might benefit learning, but thee platform could alo be ued by tudent to write aement and diertation which re plagiarim and academic integrity iue ( tokel-walker, ). there could alo be long-term repercuion if tudent chooe to by-pa rea about a topic in-depth and critically analying different facet of it, uing chat for rapid and potentially uperficial learnin thi could tifle critical thinking, problem olving, and creativity which are key kill to develop a they are needed in many profeional career ( o \u2019 connor, ). imilarly with chat exit in relation to the conduct and reporting of pedagogical reearch. thee type of ai tool could be utied throughout the reearch proce to poe hypothee, deign experiment, write manucript, and undertand cientific reult ( , ), which could be beneficial in reource ed etting where fun and man expertie may be ed. although thi could accelerate educational reearch by letting automated tool perform many routine reearch tak, the repone generated by thi while well written are not guaranteed to be accurate, with ome who have ued the platform identifying problem with incomplete citation or citation to reearch tudie that do not exit ( , ), highghting ome of the hortcoming of the large language mode while thee may be olved in time a the ai model learn more about the nuance of man language and the ource of information on the internet, the ue of ke chat in educational reearch poe other ethical iu trut and tranparency could be challenging if are ued to write cientific reearch tudie (cy & dowg, ), privacy and ecurity may be another iue depen on the type of data entered into an open ai platform, a can the deign and \u201c perona \u201d of the virtual converational agent itelf a it could unwittingly encourage inappropriate behaviour when interacting with reearcher ( , ). an example of thi can be een in \u2019 tay bot which began to pot offenive content on ocial media when releaed on twitter in ( reee, ). depite the complexitie that chat preent in higher education, and other ai tool are becoming more widepread and etabhed, requiring univerity educator, reearcher, and management to adapt to thi rapidly changing environmen ome otion are already emerging, with global education oftware provider uch a () and cadmu () developing ai detection capabitie in their exiting electronic platform to help identify content generated by ai too however, academic integrity ha alway been an iue in higher education. therefore, educating tudent about the benefit, ation, and rik of and the vae of developing a range of knowledge and kill i of upmot importanc more divere form of aement may alo be neceary to conider which could incde the appropriate ue of , a thee tool are kely to be utied in the future workplace which could enhance tudent employabity propect ( centre for teaching and learning, ). a for pedagogical \u2019 reearch, man creativity i needed now more than ever to explore how teaching, learning, and aement can be enhanced by uing chat and how bet to employ ai tool in all apect of the reearch proc a man-ai collaboration in higher education i now a foreeeable futur hence, more fun along with pocy change are alo needed to enure we can develop, tet, and apply thee ophiticated computational tool to further tudent learnin that we acknowledge it increaing availabity and ue by individua the tranformation of ha already begun, and a hitory ha hown u, reitance to change i common in any indutry undergoing a technological hif however, i beeve it i eential for u to embrace thi change and ue chat to timulate a dicuion about the fundamental principle of . our community ha previouly advied and reearched other indutrie during their tranformation, emphaizing the importance of taying competitive and focuing on core competenci now, it i our turn to do the am by taking advantage of chat, we can reevaate our own practice and impact for ocieti my experience with chat while writing a hort paper ha taught me a vaable leon. the tool demontrated better engh writing kill than i poe a a non-native peaker. it effectively brought together argument to dicu the role of it profeional in promoting utainabit however, it wa only able to write the text baed on text it wa trained on and did not have the capabity to conduct reearch or perform a terature analyi. neverthele, i would expect that thi will be one of the firt capabitie of imilar tool in the futur thi experience highght everal important apec firtly, it re\u00ad quire man intelgence to formulate intereting quetion. econdly, chat can only provide anwer baed on previouly documented knowledge ued for it trainin thirdly, it require man intelgence to generate the knowledge that can be ued to train cha and finally, conducting reearch till require man intelgence a chat i not capable of doing o ye thi hift in focu from text writing to doing reearch highght the evotion of academic work. it \u2019 important to note that writing text may no longer be a crucial component of cholarly work, a thi tak can be upported more efficiently by tool ke cha text erve a a mean to communicate the reult of our reearch in a clear and acceible manner. many cholar, inc myelf, have already ued tool ke grammarly, pell check, and profeional proofrea to enhance their writing a engh i not their native languag with the advent of chat, reearch and it diemination can now trancend language barrier. uperior writing kill in engh are no longer the determining factor in reaching a broad audience with our reearch findin chat allow u to focu on what truly matter in - aking thought-provoking quetion and conducting reearch to find anwer. the emphai hift from the writing that ummarie our fin to the fin themelv thi hift repreent a diruptive tranformation in , a text ha been a ignificant medium for cholarly work for . thi trigger my concern regar the debate urroun ai ban pocie in academic intitution and , particularly with regard to college eay and eay writing in gener i do not comment on the conequence when conidering ai a reearch method (, pattern recognition in data). i hold a imilar viewpoint a i have tated previouly regar the ue of ai in reearch. writing text may not be the mot eential kill that we hould prioritie in evaating our tudent \u2019 intellectual abiti the ue of pell and tool in word proceing oftware, uch a word, i already widely accepted. banning ai in eay writing would alo diallow tool that help people improve their writing, uch a grammarly or deep interetingly, the acm igchi ha incded a grammarly cene in it memberhip benefit, encouraging reearcher to utie ai in their writin thi highght the inconitent approach academic intitution take toward the ue of ai. when it come to college eay, it \u2019 more crucial that we teach our tudent to ak important quetion and find way to anwer them. thi i the intellectual core that will benefit both the tudent and ociet therefore, we hould place a greater emphai on teaching critical thinking kill and how to add vae beyond ai. it \u2019 alo important to educate our tudent on the impact of tool ke chat and imilar algorithm on buine and ociety, o they are prepared to ve and work in a world where algorithm are increaingly preen thi hift require a ignificant tranformation in our teaching method a that we acknowledge it increaing availabity and ue by individua the tranformation of ha already begun, and a hitory ha hown u, reitance to change i common in any indutry undergoing a technological hif however, i beeve it i eential for u to embrace thi change and ue chat to timulate a dicuion about the fundamental principle of . our community ha previouly advied and reearched other indutrie during their tranformation, emphaizing the importance of taying competitive and focuing on core competenci now, it i our turn to do the am by taking advantage of chat, we can reevaate our own practice and impact for ocieti my experience with chat while writing a hort paper ha taught me a vaable leon. the tool demontrated better engh writing kill than i poe a a non-native peaker. it effectively brought together argument to dicu the role of it profeional in promoting utainabit however, it wa only able to write the text baed on text it wa trained on and did not have the capabity to conduct reearch or perform a terature analyi. neverthele, i would expect that thi will be one of the firt capabitie of imilar tool in the futur thi experience highght everal important apec firtly, it re\u00ad _... contribution : chat: the tranformation of i_ __ at the international conference on information ytem in copen\u00ad hagen i tarted to engage in dicuion with colleague about the capabitie of chat and it impact on . hortly before i already utied it for variou purpoe, uch a compoing a poem for my tranformation tudent and referencing it in my knowledge management cl upon returning home from the conference, i took advantage of to experiment with the too a a reult, i wa able to ue chat to draft a brief paper on the reponibitie of it profeional in promoting utainabit baed on that experience and my dicuion, i wanted to write my comment for thi editori however, i alway had to potpone it becaue ome new example of the power of chat emerged or new pot on why chat i the end of mankind or at leat were pubhed. from an academic viewpoint, it ha been demontrated, among other, that chat can pa mba exam at a buine chool and write or debug code, indicating the end of traditional programming method. it i alo expected to revotio the way we earch for information and produce academic text that were previouly written by tudent or academic ( ele, ). with chat having demontrated it abity to write text, making it a ueful tool for tudent and academic, a debate ha begun in about whether ai, pecifically chat, hould be banned from academic u ome univeritie have implemented pocie prohibiting ai in college eay and requiring tudent to declare that they have not ued ai in their the other have emphaied the opportunitie for chool and univerit to gain a deeper undertan of thi debate, i collaborated with one of my ph.d. tudent, , to conduct a entiment and topic analyi of twitter tweet \u00a8 about chat in . our analyi revealed tweet with a negative entiment, indicating a high level of uer reitanc the topic covered incded plagiarim by tudent and academic, fake text and tudie, fake content, cheating, and legal impcation. the current debate around chat in i reminicent of the reaction that have been tudied for under the term \"uer reitance\". thi type of reearch ha been conducted to better undertand why individual are heitant toward technology and to help organiation promote it adoption. it ha been concded that uer reitance i largely driven by the change that new it introduce to individual ). the debate urroun chat in follow a imilar pattern, a it i triggering a \u2019 work ytem ( laumer et , tranformation in academic work ytem, much ke other technologie have e in other field that have been tudied for uer reitance (, taxi driver \u2019 reitance to uber). depite the current reitance to chat in , it i crucial query = \u2019 (\"chat\" and \"\") or (\"chat\" and \"pubcation\") or (\"chat\" and \"reearch\") or (\"chat\" and \"plagiarim\") ince: \u2013 \u2013 until: \u2013 \u2013 \u2019 ; repe and retweet were excded wel in concion, over the pat , i have devoted a ignificant amount of time to tudying and reflecting on the impact of chat on . the reitance to thi technology that i \u2019 ve oberved agn with the uer reitance to it that ha been documented for , and it i a clear indication that a tranformation of i underwa thi tranformation will bring a hift in the ignificance of text a a medium in reearch and education, putting the focu back on the core element of : the abity to ak meaningful quetion and find anwer in a world dominated by algorithm. : a firt draft of thi text wa written by myelf, i ued ebatian \u2019 input to revie it and finally chat to optimize the engh itelf. the thought dicued are baed on man intelgence, but the text itelf i co-authored by cha there are everal tudie and paper that have invetigated the ue of ai model in provi peronaed upport to tudent, automating adminitrative tak, and upporting language learner. one area where ai ha been apped in education i in provi peronaed feedback for writing aignmen for example, a tudy by et () ued a neural network model to analye tudent eay and provide feedback on grammar and organiation. in term of automating adminitrative tak, ai model have been ued to grade aement, uch a multiple- choice te for example, a tudy by atta and mcnamara () ued ai to grade eay and found that the model performed a well a man grader. another tudy by bur () ued a ml algorithm to grade hort anwer and found that it had a high level of agreement with man grader.ai model have alo been ued to upport language learner, particularly in the context of machine tranlation and nlp. for example, a tudy by et () ued neural machine tranlation to upport engh language learner in a claroom ettin another tudy by () ued ml algorithm to provide peronaed feedback on grammar and vocabulary for econd language learner. in general, thee tudie and other ke them ugget that ai model have the potential to provide peronaed upport, automate adminitrative tak and upport language learner effectivel it i important to notice that the effectivene of thee model may depend on the pecific tak, the dataet and the quaty of the training dat chat ha been ued for a variety of nlp tak, inc language tranlation, quetion anwering, and text ummarization. it ha alo been ued in the field of education to upport and enhance the learning experience for tuden chat can be ued to provide peronaed upport to tudent, automate adminitrative tak, upport language learner, and enhance one education. however, it i important to remember that the ue of chat and other ai model in education hould be e with caution. the ethical and ocietal impcation of the ue of uch automated tool mut be conidered before accepting the tool a an aitant for the tudent in their learning proc there i no tranparency in how the model i functioning to generate the reul hence it ha to be conidered a a black box ai tool which give ome information for quetion that are poed to i there i no aurance on the correctne of the information given by cha hence allowing tudent to ue it for learning, without proper tatuary warning, might caue more harm than good. _.... opportuniti_ chat can be utied in the educational etting to help and improve tudent \u2019 learning opportuniti there are ome potential opportunitie for uing chat in education. ome of thee incde: baic educational material: chat can be ued to provide baic educational material, which otherwie i created by earching the interne peronaed feedback: chat can be ued to provide peronaed feedback on writing aignment, uch a eay and reearch paper. the model can analye tudent writing and provide feedback on grammar, organiation, and conten automating adminitrative tak: chat can be ued to automate adminitrative tak uch a gra aement and anwering frequently aked baic quetion. i can help to free up teacher \u2019 time to focu on other apect of teaching and reearch. language learning upport: chat can be ued to upport language learner by provi peronaed feedback on grammar and vocabulary, and by aiting with language tranlation in a claroom ettin it can upport language learner by giving them extra practice and feedback on their language abitie enhancing one education: chat can be ued to enhance one education. it can be ued to improve one learning by giving tudent more tool and reource, a well a by making the learning experience more intereting and participatory _... contribution : how to enhance critical thinking of tudent,_ _educator and reearcher in the chat era - _ in my career, i have alway encouraged critical thinking at univer\u00ad it in fact, memorization i often hort-ved and le ueful in real fe ( et , ). for thi very reaon, the preence of eay allow tudent to expre their idea and form their opinion in a thorough wa the advent of chat - if ued in a compuve way - poe a threat both for tudent and for teacher. for tudent, who are already uffering from a lower attention pan ( trinidad, ) and a ignificant reduction in book rea intake ( o \u2019 connor, ), the rik i going into a lethargic mod for teacher, the abity to think critically i a prerequiite for teaching critical thinkin only by being very prepared on the topic with the right training, teacher might be able to dienle the work of a tudent from the work of an ai bo there i a plethora of work howing how tudent cheat (for a re\u00ad view, ee et , ). however, in my work a an editor, i have noticed that author who alo erve a intructor at their own intitution \u2013 often how imilar maciou behaviour, i., plagiarim or \u2013 milder form, uch a paraphraing entire paragraph. additionally, depite being trict with tudent when it come to deade, they often come up themelve with unreaonable requet for extenion when it come to ubting a revied manucrip for the reaon above, tudent, educator and reearcher hould reae that we are in thi quantum leap technological change together. it i not time to increae rule and enforcemen it i time to ue thi advancement to facitate learning and knowledge, t treing the vae of independent thinkin i venture to ugget that independent thinking i what make u being better man. the race i long, and the ultimate goal i not coming up with a better grade in an eay but to improve our own wellbeing a peopl if doe everything or many thing for tudent and profeor, it may alo kill creativity and critical thinkin _... contribution : chat and education_ \u2013 _i a ymbiotic_ _relationhip poible? - ramakrihnan raman, and abba_ __ chat (generative pre-trained tranformer) i trained on a maive amount of data and can be fine-tuned for variou nlp tak, inc language tranlation, quetion anwering, and text ummarization. deep learning method are ued by open ai \u2019 chat, a big language model that produce text that reemble man peech. the tranformer architecture, which wa introduced in the paper \"attention i all you need\" by vawani et , erve a the model \u2019 foundation (). the model i able to comprehend the context and meaning of the text better thank to thi architecture \u2019 ge of elf-attention procee to weigh the ignificance of variou word in a phra the model can be fine-tuned for variou nlp tak after being pre-trained on a vat amount of text dat the pre-training enable the model to pick up on common language characteritic and pattern, enhancing it abity to handle new job with le fine-tunin individuaed upport: chat can be ued to provide one-on-one tutoring for tudent, by anwering quetion and provi explanation on variou ubjec it may determine the tudent \u2019 comprehenion level and offer explanation and tak that are uitable for them. the ue of ai and nlp model ke chat in education i till a growing field, and there might be other opportunitie to be dicovered a the technology and the undertan of it capabitie evolv _.... ._ depite the potential benefit, there are concern and that need to be addreed when uing chat in education. one of the main i enuring that the model i provi accurate and appropriate information to tuden additionally, there are concern about the ethical and ocietal impcation of uing ai in education, uch a the impact on job, privacy, and bi the for chat in education incde: data quaty and bia: chat i trained on a large dataet of text, and any biae or inaccuracie in the data can be reflected in the model \u2019 outpu for the model to provide accurate and unbiaed feedback, it i imperative to ue a high-quaty dataet that i repreentative of the quetion being poed to i interpreting and undertan the model \u2019 output: chat \u2019 output i generated baed on pattern in the data it wa trained on, and it i a challenge to undertand how the model arrived at it outpu there i no tranparency to the mechanim involved in generation of reul thi can make it challenging to undertand the model \u2019 feedback and decide if it i accurate and relevan privacy and ecurity: chat ha acce to enitive tudent data, uch a writing aignment, and it i important to enure that thi data i protected and ued in compance with appcable privacy la another iue i that the chat could be ued to cheat on exam or aignment, either by provi anwer to tet quetion or by generating plagiaried conten additionally, the model could be ued to imperonate tudent or teacher, or to pread miinformation or diinformation. ed explanation capabity: chat can generate man-ke text but it doen \u2019 t have the undertan or the reaoning behind it output, thi can lead to difficultie in undertan the reaoning behind the generated text and the level of confidence of the model in it outpu man-computer interaction: chat i not a man, it may not be able to undertand the nuance or the context of certain ituation, thi can lead to difficultie in undertan the tudent \u2019 problem and provi relevant otion. ethical concern: the ue of ai model in education re ethical concern, uch a the poibity of replacing man teacher and the potential impact on marginaed grou. it i important to conider thee concern and to develop appropriate guidee and pocie for the ue of chat in education. overall, chat ha the potential to upport and enhance education in variou way, but it i important to conider the ethical and ocietal impcation of uing ai in education and to enure that the model i provi accurate and appropriate information to tuden _.... reearch quetion._ . how can chat be ued to improve tudent engagement in one and offe learning environment? . what are the potential benefit and drawback of uing chat for automated gra? . how can chat be ued to upport tudent with divere learning need, uch a pecific language learner or tudent with diabitie? . how can the peronae learning upport and individuaed feedback to tudent given by chat be evaated? . how doe the performance of chat compare to man teacher in provi explanation and anwering quetion on educational content? . what are the ethical conideration and potential biae in uing chat in education? . how can chat be ued to create interactive educational game and imulation? . how can chat be ued to upport collaborative learning and peer-to-peer interaction among tudent and teacher? . what are the impcation of uing chat for teaching and aement in higher education? . how can the performance and effectivene of chat be evaated and improved in educational etting? . what are the pocy meaure what have to be incded in the higher education, which enure the ethical ue of chat? . how can chat be integrated into exiting curricum to improve tudent engagement and motivation? . can chat be ued to peronaze learning for tudent with different learning tyle? . how doe the ue of chat in education compare to traditional teaching method in term of effectivene and efficiency? . can chat be ued to ait tudent in elf-directed learning and reearch? _... contribution _ _.... chat in the context of education: how to deal with it_ _diruptive effect? - yve barlett_ openai \u2019 chat wa releaed in and caued a lot of buzz for it ground-breaking approach to ai-generated content, managing to produce complex original text accor to the uer \u2019 quetion. concern were immediately red about the impact on education. our tudent were already ued to relying on ai tool to help them in their reearch or even to cheat on their aement, homework, eay, mater thee, et now, with a much more powerful tool, we can expect increaed ue of ai-generated tex chat ha received intene mediatiation, and if ome tudent are till unfamiar with how to adopt chat, plan to integrate it into word, powerpoint, and outlook will certainly boot i in addition, other competing otion exit, and other are being created, uch a parrow, iltrating the trategic importance of uch tool for oftware compani a a reult, facultie are currently facing a tidal wave and are unprepared to deal with it impact, both in term of pedagogy and internal poci conidering thi context, we ak what are the current impact of tool ke chat in the context of education and what can be e to addre the ue of uch tool? alo, hould we ht chat, or hould we capitae on it? to anwer thee quetion, we firt examine the poibitie and weaknee aociated with cha then we will determine the poibitie of detecting and monitoring it ue to prevent fraudulent authorhip. finally, we will examine a few poibitie to capitae on the ue of chat and identify avenue for future reearch. _.... poibitie and weaknee of cha_ chat can create eay, argument, and oute baed on variable defined by the uer (, text length, pecific topic or cenario, et). for example, chat can write college admiion eay in le than min ( whit, ), and terwiech () howed it could even achieve the required courework for being awarded a wharton mb it can alo ummarie concept, hitorical event, and piece of tex moreover, it can add it own detail and embelhment, add tranitional phrae, fix grammatical error, and propoe higher-level vocabulary and quote or fact to back up claim. in term of pedagogy, chat can provide peronaed aitance or tutoring for tudent who are truggg with ome concep it can alo help teacher create quetion for aement, and baed on objective and other parameter, it can ait with buil leon plan or developing curricum. however, we mut keep in mind that chat i \u201c not an entity at all, but rather a complex algorithm generating meaningful entence \u201d , p.). a a reult, thi tool uffer from everal ation; the firt one i that chat ha learned everything it i in it ( molck, databae before and cannot, for the time being, earch the internet to fill in information g if chat \u2019 writing i clean, grammatically correct and well tructured, it i often too vague and flat, and text lack heart and oul ( whit, ). in addition, everal tudent with the ame inquirie may obtain very imilar reul more worryingly, ai i very good at creating \u201c convincing-oun nonene, devoid of truth \u201d ( molck, , p.). for example, chat truggle with confuingly worded quetion, which can lead to incorrect anwer. thi kind of converational agent (ca) offer minimum tranparency and often operate a \u201c black box \u201d becaue it i not able to reveal it underlying making procee ( chandra et , ). hence, chat doe not explain what it doe or how it doe it, making the final reult ) or provide reference that upport it aertion. for example, language model uch inexpcable, and doe not t it ource ( ba, a chat have learnt that man often upport claim with a quote, and the oftware mimic thi behaviour but lack the benefit of man undertan of ethic and attribution ( ba, ). a a reult, quote may be aigned to the wrong author or may even be created from cratch by the ai itelf. therefore, we can quetion the reabity and credibity of the produced tex _.... detecting and monitoring the ue of chat and punihing_ _fraudulent u_ being able to identify a work baed on or fully created by chat i important for everal reaon. the firt one i that uch ge can be detrimental to tuden it can endanger tudent \u2019 wilgne to develop kill ke writing and reearching, and, above all, a bd ge of chat doe not build critical thinking and problem-olving kill, which are eential for academic and felong ucc while chat can help a tudent create text, it can become a fraud when a text i primarily created by chat and preented a the tudent \u2019 work. however, intitution are not prepared () to detect and () to punih fraud with cha there are no legally vad detection otion available yet, and for ome intitution, internal rule do not take into account fraud baed on ai-generated conten plagiarim-detection tool are becoming obolete a ai-generated content enhance originaty, and therefore cannot be detected a plagiarim. plagiarim- detection compa are truggg to addre thi hortcoming, which i a ource of inequity between tudent who are penaed for plagiarim and thoe who remain undetected. other actor, uch a or , and even openai, the creator of chat are working on way to identify text generated by the bo recently, a tudent at ha built an app, zero, to detect uch content, baed eentially on the degree of randomne of the text and it burtine, to gauge whether the writing i complex and varied, a man writing can be ( vrga, ). however, there i a rik of fale negative and fale poitive; for example, a tudent may have a particular writing tyle that reemble ai-generated tex it i therefore, important to find legally acceptable otion, epecially when it come to punihing or even expelg tudent who chea in addition, internal rule hould emphaie that any form of cheating related to content generated by or i unethical and pecify ituation lea to punihmen ome intitution already reacted; for example, city chool banned acce to chat ( roenzweig-ziff, ). _.... prohibit or take advantage of chat?._ the firt precaution to protect education from chat could be to ban it and favour handwritten work intead, which i important for tudent to acquire writing kil it i alo poible to have tudent work on computer that are not connected to the internet, even through a phon however, it eem very difficult to ban the ue of chat, ince tudent can ue device both inide and outide the claroom. ome expert argue that retricting the technology i hort-ighted becaue tudent will find way to ue the bot regardle of whether it continue to grow in popularity ( roenzweig-ziff, ). moreover, and ca uch a chat have the potential to create incive learning environment for impaired tudent (uch a lack of reource, diabitie, or learning diorder), with divere ving environment (commuter, family reponibitie, or non-native) and with divere learning tyle (viual, kinaethetic, or auditory learning) ( & , ). it therefore eem more reaonable to adopt the technology, albeit with ome adaptation: \u201c if the thing that we ued to put o much effort into in teaching can be automated, then maybe we hould rethink what the actual goal and experience are that we hould work toward in the claroom \u201d ( roenzweig-ziff, ). here are ome idea on how to tackle cheating and capitae on cha firt, teacher could ak tudent to write a traditional eay, then have a brief in-cla oral interview with each tudent aking them to explain the content of the eay, without them eeing i however, if oral exam anwer cannot be generated with ai, oral exam can be very time conuming when teacher are managing clae that contain large number of tuden hence, teacher could refine their eay quetion to require more complex thought, draw on local and current information that would not be widely available ( vrga, ), require tudent to make connection between the knowledge and their own experience, or apply a concept to a unique ituation in their writin another poibity i to add a elf-aement tep to the writing proce where tudent reflect and evaate their own performanc in addition to content, alternative format encourage a more authentic aement: podcat production, peer feedback, debate, interview are effective alternative to traditional ea aking tudent to rate and comment on a chat \u2019 anwer to a quetion or to compare a chat-generated reearch paper with the original verion i alo a good way to develop critical thinking kil chat can be conidered an excellent ource of idea and inpiration to give tudent a place to tar it can alo make information available at tudent \u2019 fingerti, encouraging them to conduct reearch and double-check their fac finally, chat offer the poibity of man-machine hybrid work. intead of prompting an ai and hoping for a good reult, man can now guide and correct ak hence, new kind of collaboration become poible ( molck, ). to concde with the advantage of uing chat, teaching tudent to work with ai and will prepare them for their futur teacher can how them appropriate ue and way to leverage the tool for better outcom _.... reearch ._ at the chool level, faculty member could openly update their curricula to accommodate uch technologie in the claroom and ue chat a a co-teacher. however, many chool and curricula are tructured o that teacher do not know how to introduce thee advanced and innovative technologie (); hence future tudie could find way or even procee to facitate thi introduction. to addre one of the ation dicued at the beginning of our work, chandra et () highght the need to build converational agent (ca) with not only an \u201c artificial brain \u201d but alo an \u201c artificial heart \u201d . people perceive a with higher converational kill to be both more manke and more engaging than a le killed one ( cetzler et , ). however, eeger et () howed that deigning more anthropomorphic ca i not trivi diederich et () conducted a terature review to analye ca and propoe a reearch to move ca reearch forward regar uer interaction, context, agent deign, a well a ca perception and outcom _.... concion._ the development of ai and automation will threaten an increaing number of job ( et , ; et , b ) and rather than hting them, the quetion i rather how we will adapt to thee diruptive change: \u201c the technology i developing very rapidly, poibly exponentiall but people are ear. when ear people are faced with exponential change, they \u2019 re not going to be able to adapt to that very eaily \u201d ay (a cited in adam, ). we have examined the great impact of tool ke chat in the context of education and identified ome way to addre thee impcation and capitae on thee too mot importantly, we need to teach tudent how to work with ai and and prepare them for their futur _... contribution _ _.... the ue of chat in educational intitution: , opportunitie and future cope_ \u2013 _, jeretta horn , hanaa_ _ and ._ openai \u2019 chat (chat generative pre- trained tranformer) ha gained an impreive amount of attention and wide dicuion acro both and indutrie ince it launching on , ( ). it i a tranformative technology a it i trained to learn what man mean when , they poe a quetion to i many uer are awed by it \u2019 atoun man ke abity to chat, anwer quetion, produce content, compoe eay, create ai art prompt, explain art in great detail, cript code and debug, take tet, manipulate data, and explain and intruc thi diruptive technology may very well change the way individual interact with computer a well a their method for information retrieval ( montti, ; ortiz, a, b ). in other word, it i a revotionary ai technology that make ue of ml and nlp technique to allow uer to chat with a virtual aitan it can provide a repone for almot all tak uing written tex the ge of thi appcation i currently open to the pubc for free a it i currently under the reearch and feedback gathering tage ( ortiz, a, b ). chat i a large language mode thee model are trained with a very large dataet of converational text uch a chat log, forum and ocial media pot to preciely forecat what word come next in a given entence which allow it to engage with the uer in more reatic natural dialogue ( montti, ; qadir, ). the popularity of thi technology can be imagined by the tweet from open ai \u2019 chief who noted that chat attracted more than one milon uer in after it launch. depite it impreive converational abitie, thi technology ha ome ation a wel for example, it i unable to anwer quetion that are worded in a particular way requiring the uer to reword the quetion in order for chat to undertand i an even bigger concern i it lack of quaty in the repone it provide to quetion that eem to be plauible-oun but hardly make any reatic en finally, it repond to ambiu quetion jut by taking a gue rather than aking for any further clarification, which reult in undeirable repone to uch quetion ( ortiz, a, b ). the key reaon for chat to generate prejudiced or even incorrect reult i largely due to lack of training data and biae in it that can reflect negatively on the model reult ( yang, ). the increaing development of chat i ignificantly rehaping the education market and hence ring concern about what and how to teach the next generation ( zhai, ). people are concerned that chat might replace man intelgenc for example, thi technology can be ued to efficiently write an article or eay within a few econd potentially abohing the need for man intervention ( ortiz, a, b ). other in education fear whether tudent will learn to effectively write a they will bank on chat to do thi without putting in any effor but expert feel that the eay generated by chat can be identified apart from thoe written by man intelgence due to a few baic flaw of uch article produced by the bo a report on uch eay produced by chat found that the compoed article were uperficial and lacked the proper referencin other report indicated that uch article incded erroneou information and were unable to provide a convincing perpective for the reader. the author teted chat \u2019 abity by giving it a compcated eay quetion that wa aked to honor ychology tudent and found that the bot produced no more than a grade of b- or c . chat could not ditinguih the + \u2018claic \u2019 article in the field that i being cited by any other article and alo kept referring to the ame ource over and over again (hirh-paek and bkoff, ). thi clearly indicate that chat can demontrate it intelgence to a certain extent to write the eay and manage to get a paing grade but the writing tyle and preented content may eaily be differentiated from man written conten hence, there i a need to train intructor to catch uch caveat and ae the work accorl rather than preenting the entire work generated by chat in repone to aignment given by educational intitution, it can rather be ued a a tool for intellectual intenification rather than a a tool of plagiarim. conidering the fear of thi technology in education, the new york city department of education banned the ue of chat on january , acro all department device and network (hirh- paek and bkoff, ). banning uch technology i not the otion for any academic intitution a tudent can till ue it in their own network and devic rather than conidering thi a a hindrance to the tudent \u2019 intellectual development, the intructor hould ue it a a tool of aitanc the appcation of chat and it contructive ue to help tudent complete their aignment hould be taught at educational intitution o that the culture of learning from an advanced ai tool uch a thi can be ued in the right way by tudent rather than making it ue a a medium of complete dependence and plagiarim. thee tool can provide anwer to the quetion quickly but they hould never be conidered a a ubtitute for critical thinking and problem-olving kil the upport provided by thi technology can rather be conidered a an opportunity for tudent to build further, which would be eential for their academic and fe-long ucc univerity intructor can ue thi tool to teach tudent how chat can help them generate concept and tructure for their writing aignment, practice their language kill (, tranlating the native language into the target language), identify appropriate ource and generate a t of potential reearch topic, et ( qadir, ). in eence, teaching tudent how to ue thi tool to upplement their reearch and writing effort in univerity education i an opportunity they hould be taugh tudent hould alo undertand that chat \u2019 generated text or idea preented a their own can lead to plagiarim and hence they hould only be conidered informational and a part of the reearch proce when creating paper or completing other required aignmen moreover, a thi bot i not connected to the internet and heavily reant on it data and algorithm, the output of thi tool may be milea or incorrect if the data and algorithm are inaccurat o the tudent hould alway verify the anwer that they receive from the bot and check other ource before conidering it a a vad repone for their quetion or aignmen educational intitution hould alo have a clear pocy for the extent of ue of thee tool and to enure that tudent data i properly protected from the ge cyberecurity rik ( ortiz, a, b ). academic intitution hould make a careful evaation of required educational tak and reform them to cultivate tudent \u2019 unique kill that are beyond the capabitie of cha a chat till need to be trained more to cater to the need of it role to accurately anwer the ubject domain \u2019 pecific quetion, integrating thi technology to ubject learning tak i critical and warrant further reearch ( zhai, ). educator need to conider the adjutment to their educational learning outcome and evaation criteria to clearly undertand the role of technology and tudent \u2019 cognitive kill that they learnt by integrating their knowledge with the effective ue of thi tool to olve real-world problem. there i arguably coniderable agreement that a tudent in higher education hould be openly encouraged to ue chat to create the firt draft of their anwer or aignment in conultation with their intructor. at thi point, their abitie could be aeed to the extent that they would be able to apply critical thinking and problem-olving kill to improve the eay to meet the exact expectation of the et criteria for that aement (hirh-paek and bkoff, ). baed on the above dicuion, it i clear that chat and other ai tool provide enormou opportunitie for tudent and intructor in higher education. the immene potential of ai tool have opened up maive opportunitie for reearch in thi area in order to fully undertand the potential of thi technology a a method of enhancing the efficiency of teaching and learning while bran the future of the current and upcoming generation. if we want our tudent to learn how to olve real time problem, we need to come out of the traditional teaching model of imply devering the one-way theoretical knowledge to tudent and go beyond that to make tool ke chat a friend in the claroom ecoytem that i not omething to fear. it hould rather be ued to encourage uch technology a a medium for tranforming practical education. further, it could be of great help to tudent a they acquire fe learning kill and ue them in their future career to olve actual problem at their workplac conidering the maive potential of thi , it can be effec\u00ad tively ued a a potential topic in higher education reearch in general and buine education in particular. at the priive level, future reearcher could explore where thi technology fall hort in provi accurate information and reul future reearcher can perform terature exploration and a review of information relating to the performance of chat and compoe guidance paper on how to effectively ue thi technology and where to take caution, avoid over reance, lack of originaty and plagiarim. future reearch hould alo work around developing model and vadating them with relevant data on how to ae thi technology \u2019 effectivene, performance, and intention for ue by relevant takeholder. future reearcher could further explore both poitive (, engagement, attention, attitude, playfulne, heic and utitarian motivation, excitement, wilgne to u, et) a well a the dark ide (, threat, rik, invaion of ecurity and privacy, ecapim, ditraction, repone delay, irrelevant information, functional faire, et) of the ue of cha in addition, thi technology \u2019 capabity to automatically ae tudent grade while provi relevant feedback and helping intructor periodically monitor tudent \u2019 progre hould be explored. moreover, chat \u2019 abity to generate text in multiple language can alo help reearcher undertake reearch on aeing tudent \u2019 learning effectivene and performance ubject in their own native languag _... contribution _ _.... dirupting higher education and man communication by language model - marijn janen._ natural language model, ke chat, are being ued more and more due to their impreive performanc chat tand for _generative_ pre-trained tranformer and i developed by openai i a large, pre-trained language model that ha gained immene popularity and might be diruptive ( haque et , ). language model need to invet ignificant reource into curating and documenting large language model training data with high cot and etimated co emiion. there ha been an increaing ize of lm in term of the number of parameter and ize of training data ( bender et , ). uch tool can be ued for a variety of appcation, uch a earching with higher preciion, writing oftware code, anwering cutomer inquirie, and creating legal documen chat might dirupt the earch engine market, and rehape the higher education landcap chat can be helpful in everal way, but it come with ubtantial diadvantage, ke mot new technologi chat outcome are probabiti language model refer to ytem that are pre-trained on ge amount of text to predict the kehood of a token (which can be a character, word or tring) given either the previou context or it context ( bender et , ; bender & k, ). chat can be viewed a a \u201c _tochatic parrot_ \u201d ( bender et , ). wherea mathematic reult in determinitic outcome, thi type of ia generate the mot kely outcome, and thi can therefore differ per tim thi i not baed on logic or reaoning but i calculated baed on the probabity of the outcom furthermore, thi can reult in framing bia by telg uer what it \u2018think \u2019 they want to hear. the mix of man biae and eemingly coherent language heighten the potential for automation bia, deberate miue, and ampfication of a hegemonic worldview ( bender et , ). chat i jut the beginning and will kely be followed by other peciaed and more advanced too we hould neither try to ban chat nor embrace the technology indicriminatel ke any technology progre, critically appropriate i needed, and experimenting to find way to take advantage of new technology without having it diadvantag thee kind of ai tool will kely tranform our way of working and, after a while, become common and intitutionaed in our f the quetion i how technology will evolve and how man and ociety will adapt ( et , ). _..... ue of chat in education._ chat and other lan\u00ad guage model tool can be ued to increae productivity and free the care number of code developer and report writer. chat can be ued by tudent to create a report for their coure or even to provide anwer to an exam. planguage model can be ued to create ai-aited work, which re quetion if tudent did their work olely on their own and how chat hould be acknowledged in their work. chat ha officially made it cientific debut with at leat four co-author credit ( tokel-walker, ). however, inc uch tool a author i dicuable, a author take on legal reponibity for their work and need to give their conen only people can be held accountabl intead, the ue of uch tool hould be explained a part of the reearch method, ke we refer to and mention the ue of tool ke envivo or atlti. language model will change our way of education. on the one hand, the rik i that tudent \u2019 independent thinking and language expreion kill might deteriorate and not be practiced by uing cha the firt quetion i if thee kill are till needed, and if poitively anwered, new way of developing and practicing thee kill need to be developed. on the other hand, tudent need to develop kill to cruti the generated text and code and be critical toward the outcom they need to develop kill to invetigate whether the information i factual and develop their critical attitude toward the generated tex the ue of language model hould be explained in their reearch method to enure accountabity by the author. furthermore, the outcome hould be vadated and triangulated with other ource of evidenc although tudent have been fat in adopting chat, alo lecturer have embraced them. ome coure already provide ai- generated outcome and ak their tudent to evaate and reflect on thi. other coure encourage the ue of chat or other language model in their aignment and ak the tudent to explain how they developed by openai i a large, pre-trained language model that ha gained immene popularity and might be diruptive ( haque et , ). language model need to invet ignificant reource into curating and documenting large language model training data with high cot and etimated co emiion. there ha been an increaing ize of lm in term of the number of parameter and ize of training data ( bender et , ). uch tool can be ued for a variety of appcation, uch a earching with higher preciion, writing oftware code, anwering cutomer inquirie, and creating legal documen chat might dirupt the earch engine market, and rehape the higher education landcap chat can be helpful in everal way, but it come with ubtantial diadvantage, ke mot new technologi chat outcome are probabiti language model refer to ytem that are pre-trained on ge amount of text to predict the kehood of a token (which can be a character, word or tring) given either the previou context or it context ( bender et , ; bender & k, ). chat can be viewed a a \u201c _tochatic parrot_ \u201d ( bender et , ). wherea mathematic reult in determinitic outcome, thi type of ia generate the mot kely outcome, and thi can therefore differ per tim thi i not baed on logic or reaoning but i calculated baed on the probabity of the outcom furthermore, thi can reult in framing bia by telg uer what it \u2018think \u2019 they want to hear. the mix of man biae and eemingly coherent language heighten the potential for automation bia, deberate miue, and ampfication of a hegemonic worldview ( bender et , ). chat i jut the beginning and will kely be followed by other peciaed and more advanced too we hould neither try to ban chat nor embrace the technology indicriminatel ke any technology progre, critically appropriate i needed, and experimenting to find way to take advantage of new technology without having it diadvantag thee kind of ai tool will kely tranform our way of working and, after a while, become common and intitutionaed in our f the quetion i how technology will evolve and how man and ociety will adapt ( et , ). _..... ue of chat in education._ chat and other lan\u00ad made ue of thi. neverthele, traditional education remain. teacher even are not able to recog report generated by chat ( o \u2019 connor, ). a language model tool are not able to undertand what they actually do and if the outcome make ene, there i a cloe relationhip with miinformation. language model tool have no real undertan of what they are generating, and they tate both fact and falehood with the ame high level of confidenc the way of provi anwer, by provi eay-to-read torie rather than k to reource on the web, might reinforce the _filter bubble_ . the latter refer to the rik of howing only certain information putting uer in a \u201c bubble \u201d without howing other and divere viewpoint ( parier, ). that make it eaier for people, becaue they do not have to gather information from different it but, how do you know the information i correct? not biaed? not reflecting a certain worldview? there will till the iue of correctne, bia, criticim and norm. culture have different norm, and people can have different view on a ituation that might not be expreed. reearch ugget that people tend to take the information preented to them by chat for granted ( et , ). uer might not be aware that other anwer might be poible and that the anwer are not factu who i accountable for provi the correct anwer? uch language model tool can be ued to direct the behaviour of the pub the rik i that uch tool be miued for the ake of manipulating citizen. alo, there i the rik that thoe in control of language model can manipulate the anwer given. no government, company, or peron hould have ole control of filter ( janen & hoven, ) and the reulting information provided. language model threaten to take over job, people ving from checking grammar and engh might become le neceary, the tool can be ued by villain for writing hacking code or tudent for cheating report writin yet, language model will preent many opportunitie a well and will kely create new job and even new kind of buine mode language model can make procee more efficient and effective and reduce man labour. language model can upport dylexic tudent in thi way, making it eaier for them to work in certain environmen there might be a battle between tudent and teacher in uing and detecting language model-generated tex alternatively, embrace chat for better learnin for thi, we hould not tart with the how quetion, but with the why quetion. imilar to the introduction of the calculator or the tool can be integrated into our education. thi re the quetion of why we educate certain knowledge and kill to our tudent, and what kill are needed by tuden eential i that they learn to be critical toward the automatically generated anwer and be able to analye them. alo, we need to educate how to take advantage of thee kind of tool without falg into the trap of the diadvantag man pend too much time on mundane, day-to-day tak. by automating them, man can pend more time on creative and trategic work. people will get to work in more fulfilg rol teacher can focu on what matter and thoe tudent who need more uppor have been employed to offer free -hour ychological aitance to both medical taff and the pubc ( u et , ). a tudy in reveal that peronazation, enjoyment, learning, and condition are poitively related to uer experience and uer atifaction ( ) ai-baed have been widely adopted to upport and trengthen the quaty of ervice in buine indutrie, uch a , tourim and inurance (, ; mutgala & jayaea, ; androutopoulou et , ) and can now be ued to trengthen education. a ound uer interface and eay to ue i key for effective u alo, upport for interpretation of the reult can help to avoid that reult are taken for granted without being looked for evidenc reearch i needed on how language model can be ued to create vae, under what condition and what it cannot do or what might have negative effec although ml can help improve productivity and provide other ad\u00ad vantage, it ue alo affect our pubc va ethical impcation hould be conidered and enure that language model are being ued in a way that benefit everyon not all people might be able to ue thee kind of tool or have acce to the newet too openne and acceibity and incion are ocietal vae that are affected. reearch i needed to evaate the effect on pubc vae and to enure that thee vae can be me _..... next t_ chat provide a glance into the future, and further development will kely follo ke any technology, language model can be ued for good or bad. in education, the learning objective and the way of learning hould be reconidered in a imilar way a when the calculator or wa introduced. chat hould be viewed a a tool that will be integrated and intitutionaed in our practic chat i not able to vad the accuracy or veracity of the data, but ueful a a uppor people hould develop new kill, and the ue of language model tool hould be acknowledged in reearch method. experimentation i needed to undertand the full conequenc chat hould not reult in a next filter bubble and domination by a ingle party hould be avoided. among other, the pubc vae of openne, acceibity, and incivene will be affected, and meaure need to be taken to enure that people have acce and are able to critically acce the outcom chat cannot make a model or draw a buine proce, however, there are other openai tool, ke and dall- e, that can make drawin thi will kely move forward, and alo thee field will be upported by ai too chat will kely be combined with more logical model, ke ram alpha, to undertand relationhi. the focu in the future will be on logic and language mode their kill will alo improve coniderably in the coming . _... contribution _ _.... chat and education pocy and practice - ._ the rapid advance in ai technologie have opened new poibitie in variou field and domain, inc education ( ckin et , ). the appcation of ai to learning can be traced back to the pioneer of the field, inc john ( , ). it ha t been ued in variou educational context and etting for ome time ( gold & papert, ; woolf, ), primarily for peronaed learning and the aement of tudent progre (for example, through learning analytic), with varying ucce ( woolf, ; zhai et , ). but the widepread ue and appcation of ai in education ha been increaingly critically evaated due to concern about it cot and effectivene, alongide emerging ethical and privacy conideration ( , ; , ; elwyn, ). however, the impact of the covid- global pandemic ha further accelerated the interet and potential appcation of technologie and epecially ai \u2014 in education ( crick, ), epecially in the context of the \u2014 diruption to learner, practitioner and education intitution and tructure ( wilamon et , ; watermeyer et , ). thee wider narrative can alo be een in emerging national and international pocy context ( , ; uk government, ; , ), alongide a renewed focu globally on kill, computer cience education, and aociated national curricum and quafication reform ( et , ). the recent advancement in nlp have enabled the creation of acceible large language model, uch a the open-ource ( _generative pre-trained tranformer_ ) family created by openai, which ha further reinvigorated interet in the ue of ai tool and technologie in education. the widepread ue and appcation of chat ( _chat_ _generative pre-trained tranformer_ ), which ha been built on top of openai \u2019 - family of large language model, and ha been fine- tuned for tranfer learning uing both upervied and reinforcement learning technique ( openai, ), ha the potential to tranform the htt://openai.com/ htt://chaopenai.com/ way we learn, teach, ae and acce information. with chat emerging acro reearch, pocy and practic in general, ai, ke any gaining more than milon uer in ince launching in other tool, offer many opportunitie ( ckin et , ) but alo , and nearly milon viit and it total ie with it many threat ( , ), which make it uer count excee milon by january , the impact on education i kely ignifican however, the uncritical ue of chat neceary to take man right principle into account in the early deign of it appcation. educator (and learner themelve) mut be re everal concern and iue that need to be conidered, both at a aware of the trength and weaknee of ai in learning, o a to be empowered \u2014 not overpowered \u2014 by technology in their educational practice ( , ). legal, regulatory and pocy level, a well a what thi mean for individual learner (and indeed, citizen). while the peer-reviewed pubhed academic terature on the ue of chat in education i till one of the main ethical concern i the accuracy and reabity of the emerging at the time of writing, in thi ection, we will briefly explore it information provided by chat, a well a the potential for bia and potential ue, a well a ome of the key concern and dicrimination. a an ai language model, chat i trained on large aociated with it deployment and adoption in variou etting and contex corpora of textual data freely available on the internet, but it i not alway poible to enure that the information provided i accurate and while chat ha red viceral fear of learner cheating on up-to-date, and there i a rik that the model may perpetuate exiting homework, variou commentator are aeing how it potential a an biae, tereotype and dicrimination in ociet there have been educational tool outweigh it rik , ). moreover, extenive example of racit, exit, homophobic, ableit and other education ha been incorporating and reimagining the threat and dicriminatory language making it way into the model and i then poibitie of technology for ( , ); ai will kely be no different ( ckin et , generated a outpu large language model can reinforce and exacerbate exiting power dynamic; the power tructure reflected in the ), but will require not only a technological hift but alo a mindet and cultural hift ( breen, ). one of the mot frequently highghted appcation of chat in education i dataet become encoded in the model, meaning that any output reinforce thoe tructur becaue much of the data in the training et it potential to provide learner with peronaed, on-demand learning might be produced from a predominantly , male, wetern, engh- experienc it i feaible for chat to be eaily integrated into peaking perpective, the data would kely be heavily kewed to reflect educational platform and ytem (for example, virtual learning environment, learning management ytem, reource repoitorie, etc) to thoe tructur thi re the quetion of how chat can be truted to provide learner with accurate information from divere and provide tudent with intant feedback and guidance, / acce to authoritative ource, and what meaure need to be taken to enure that relevant coure and programme information, and engaging the information provided i reabl with recent reearch in the uk context-pecific converational interaction. thi i particularly relevant highghting how intagram, tiktok and youtube are the top three new for learner who are till unable to attend phyical clae due to the ource for teenager, data and media teracy are increaingly key covid pandemic, or upport an increaing number of learner who are feature of chool education o a to counter miinformation and diinformation one ( , ). chat can eentially be viewed a an increaingly ophiticated engaging through remote or hybrid learnin by creating ad hoc interactive and engaging learning material, chat-powered converational agent could imulate real-world cenario, provi learner \u201c bullhit generator \u201d ; if a generated entence make ene to you, the with hand-on learning experience, authentic aement, and fotering reader, it mean the mathematical model ha made ufficiently good critical thinking and problem-olving kil it could them be ued a a gue to pa your ene-making filter. thi become increaingly virtual tutor by provi tudent with peronaed interaction, problematic from an algorithmic governance and tranparency feedback and upport in real-tim thi could help learner better undertand complex concept and overcome learning obtacl another perpective if i it able to produce plauible article of any length or tyle, or i able to generate working computer code; it mean what ha potential ue cae of chat in education i how it could upport been automatically-generated i now becoming harder to po thi language learning, and how it can be programmed to convere in directly k back to concern regar \u201c trutworthy ai \u201d ( floridi, different language and can help tudent practice their language kill ) and how it i or i not \u201c citizen-centred \u201d ( , ). t, in real-tim for example, tudent can engage in converation with development in the ai field can deeply impact interaction between chat to practice peaking and tening kill, a well a to learn new educator and learner and among citizen at large, which may undermine the very core of education; that i, the fotering of free will and vocabulary and grammar. chat can alo provide immediate feedback and correction, which could help tudent to improve their language kill fater and more effectivel moreover, chat can alo be ued to help practitioner in their independent and critical thinking via learning opportuniti educational profeional need to be made aware of ai and the ethical it poe in the context of education and learning ( council of learning environment ( , ). by trivially provi them europe, ), increaing demand for ai-terate learner and with intant acce to information, chat can ait them in practitioner. anwering quetion and provi tudent with additional reource in addition to concern regar accuracy and bia, there are alo and materia additionally, it can be ued to create and ditribute more general concern about the ethic and privacy impcation of educational content, uch a ad hoc quizze, game, and interactive leon, making the proce of creating and devering content much uing chat in educational context, and what pocie and regulation need to be in place to enure that the technology i ued ecurely, fater and eaier. finally, chat can automate repetitive adminitrative tak, uch a gra aignment and provi tructured ethically and reponibly ( ). a mentioned previouly, thee type of ai model are reant on ge amount of data; , feedback, freeing up practitioner time for more important tak uch a curricum deign, cloe to practice reearch, evaation and tudent ome of thi data i peronal or private, and ha been craped indicriminately along with other freely available dat earer model were engagemen hown to output private and identifying information from people in however, while the ue of chat in education ha the potential to their datae additionally, a model become more and more powerful reae ome of the potential benefit outed above, there are widepread concern about it ue and impac again, while the peer- there i an imperative to upply them with increaing vome of data; reviewed pubhed academic terature on the critical ue of chat thi create an economic imperative for the large language model creator to collect data in way which are ometime unethical or invade in education i till emerging at the time of writing, there are key theme people \u2019 privac therefore, a learner and practitioner interact with chat, they will be haring peronal information and data with the ai model, and it i important to enure that thi information i kept htt://twitter.com/gdb/tatu/?lang en confidential and ecure, and how thi information will be ued (and = potentially aociated with their account and identity). the ue of chat t re important quetion about the collection, torage, and ge of learner information, a well a the potential for data breache and unauthoried acce to peronally identifying dat in ummary, it i clear at the time of writing that chat and aociated tool and technologie will continue to impact on and dirupt education ( zhai, ). while early repone incded futile call to ban them , ), it i clear that, a with the covid pandemic, the continued ue and adoption require not only a technological hift, but a mindet and cultural one too ( breen, ). we have already een ignificant diruption and permanent change to learning, teaching and aement over the pat few ( crick, ) a we embrace a \u201c new (ab)normal \u201d ( watermeyer et , ); why would we not try and embrace thee tool and technologie and ue chat et to upport innovative practice, aeing \u201c manne \u201d rather than tet that can be increaingly trivially gamed and automatically olved. but it i clear that the ue of ai in education acro emerging reearch, pocy and practice require further critical analyi and evaation, a well a increaed openne, tranparency and kely further legal and regulatory groun ( , ), enuring that they are expcitly learner- (or indeed, citizen-) centred ( floridi, ). _... contribution _ paper could be made more acceible to different contituencie by impfying the communication of complex ide thi could facitate better communication of our work to practice omething often dicued, but rarely e becaue it take \u201c extra \u201d effort when the goal of \u2013 pubcation i me non-native peaking reearcher could greatly benefit from improving the quaty of writing through thi too the ai could alo crape webite or paper and orga it at a general level that might facitate data collection (from webite) or a terature review (from paper). the are alo ubtanti if our ytem (particularly le crutinou conference) are not able to dicriminate, then it i poible that the ma production of ai bot generated reearch paper could tax the review ytem, and challenge the integrity of reearch. fale information i jut a much of a potential problem in reearch a it i in im and ne thi i becaue how the ai take information (baed on it training et) and weight certain information could lead to milea concion. the problem may be compounded when it i difficult to unle the ource of the information and the attribution of credi where i the intellectual ownerhip? i it with the training et ued or with the algorithm, the latter are which are uually a black box behind a wall of corporate contro the lack of tranparency can make the governance of the tool very me o, where are we going with thi \u2013 and what are the otion? while it would be fool to peculate with high pecificity on direction, there are a few general tenet that i feel comfortable in predictin _.... how doe chat benefit or harm academic reearch? - varun_ __ _..... man contributor._ a number of ago, in my doctoral eminar for t year tudent, i ditributed printout of even hort paper co-authored with me and each of the even tudent in the cl i indicated that i had paintakingly worked on thee paper to give them a head tart on the pubcation proc i aked them to take min to review their paper and let me know what they though the paper uperficially looked credible, but were garbage, generated by cigen \u201c a program that generate random computer cience reearch paper, inc graph, ure, and citation. it ue a hand-written context- free grammar to form all element of the paper. \u201d after review, only of the tudent identified the nonenical of the paper, were unure (perha becaue they did not want to challenge the intructor), and indicated that they ked the paper and thanked m the technology i far better , and chat due to it wide\u00ad pread acceibity i cauing ome widepread concern. ome and conference have already et up pocie that prohibit the ue of chat in the reearch produc for intance, the international conference on machine learning indicate that \u201c paper that incde text generated from a large-cale language model uch a chat are prohibited unle the produced text i preented a a part of the paper \u2019 experimental analyi. \u201d i thi an overreaction? certainly, the \u201c abity to dicern \u201d an ai generated proe from a man generated one increae the digence needed from our editor and reviewer. mot tudie have hown that man have a difficult time dicriminating between ai and man generated tex machine however (i., bot detection ai) however, perform better at dicriminatin ai generated writing tend to be le pecific, le creative, over generae pecific intance, and ha a different writing tyle (, ue more predicted word) than man writin ai tool (ke zero) have been pretty ucceful at probabitically identifying ai generated writin however, while there may be legitimate reaon for reacting to thi tool, there are jut a many reaon to embrace it proactivel chat i jut that, a tool, that can be embraced ke other tool (, grammarly) to improve the quaty of writin for intance, often the review proce end with the tedium of hortening the paper to meet length requiremen think of alleviating the difficulty in deci what to cut by uing the too or conider the vae to author in fee a complete paper to the ai tool, and having it write the abtrac imilarly, complex \u27a3 the battle between bot (ue of chat v. bot detection ai) i only a mall part of the otion. while we can train model in man text v. ai generated tet, _there will alway be a degree of mimatch_ a the training et between the two need to contantly change a the ai evolv \u27a3 the ai will alway get better (through reinforcement learning, bigger and better training et, acce to the internet) and o hting thi trend will fail \u2013 _pocie need to be et around tranparenc_ \u27a3 for academic reearch, the e i between uing the to improve writing (communication goal) v. to generate new idea (innovation goal). _where that e i drawn between communication and_ _innovation and how pocie are articulated i an important profeional_ _converation._ \u27a3 _chat can never partake in co-authorhip arrangement_ due to it lack of accountabit \u27a3 there need to be _high reflection of ethic in the ai_ to prevent auto\u00ad mation of miinformation and the pread of fale reearch. i upect that imilar to mot ai, there might be a combination of man and ai complementarity that will produce the bet produc chat a a tool can greatly facitate reearch writing and other creative puruit (ke filmmaking, book writing, et) - but the open quetion i how good can it get? the perfect man-ai complementarity may be an eive ideal that require ongoing navigation through ome decate ethical boundari i aked chat to addre exactly the ame topic by poing the following quetion to it: \u201c write a -word editorial on how chat benefit or harm academic reearch. \u201d the reult follo compare and enjoy!. how doe chat benefit or harm academic reearch by chat (ai bot). chat (ai bot): _chat i a tate-of-the-art language model devel\u00ad_ _oped by openai, capable of generating man-ke text baed on the input it_ _receiv with it impreive performance, chat ha been apped in_ _variou field, inc academic reearch. in thi editorial, we will examine_ _how chat ha impacted academic reearch and explore both the benefit_ _and harm it ha brought to the field._ _on the one hand, chat ha brought numerou benefit to academic_ _reearch. firtly, chat ha ignificantly improved the efficiency of_ _language-related tak in academic reearch. for example, reearcher can_ _ue chat to automatically generate high-quaty abtract or ummarie_ _of reearch paper, aving time and reducing the workload of reearcher. in_ _addition, chat can alo be ued to generate report, conference paper,_ _and other form of reearch output, freeing up reearcher_ _\u2019_ _time to focu on_ _more creative and challenging apect of their work._ _econdly, chat ha alo contributed to the democratization of_ _knowledge by making reearch more acceible to the pub with it abity_ _to generate man-ke text, chat can help to bridge the gap between_ _academic reearch and the wider pubc, allowing non-expert to undertand_ _complex reearch concept and fin in a more acceible and undertandable manner. thi can lead to increaed pubc engagement with academic reearch and a more informed and educated ociet_ _finally, chat ha alo opened up new avenue for interdicipary_ _collaboration in academic reearch. by automating language-related tak,_ _chat allow reearcher from different field to collaborate more effectively and efficientl thi can lead to the development of new reearch idea_ _and method, a well a increaed innovation and breakthrough in academic_ _reearch._ _however, there are alo ome harm that chat ha brought to aca\u00ad_ language i not engh, or they may have a learning diabity uch a dylexi eentially uing thee ai-powered language tool to improve the readabity and language of their manucrip we do not however, cite uch tool a a co-author. cholarly writing i more than jut provi a pohed manucript, it i about originaty and buil on a tradition of accumulative buil of knowledge ( metcalfe, ). cholarly writing i not the ame a writing for a tabloid newpaper that pubhe routine torie (, weather report, traffic update), whereby chat may help it to write hort new torie ( financial time, ). recent tudie (, , ; bouchery et , ) ugget that chat can be a ueful tool for writing an abtract or even an introduction ection. however, in mot cae, the text i either poorly paraphraed lea to the ditortion of the actual meage or content and in ome cae, a high level or a coniderable amount of plagiarim ha been noted. in addition, there i a noticeably abence of cientific evidence to upport any claim that ai-baed language tool can perform rigorou reearch (, hypothee development, data analye, dicuion on the reult), apart from aiting reearcher to improve to quickly generate text for a manucrip for intance, in a manucript that wa recently pubhed in a reputable outlet, the author acknowledged the contribution of chat to draft the abtract with minimum intervention by the author (ee, ). moreover, a minority of academic claim to have ued chat to pa examination bouchery et , (ee, bommarito ii & katz, ). while the latter may not be directly ked to cholarly writing and pubcation, it doe re a concern that a minority of academic may ue chat to write content, without acknowledging it to pubher, editor, or conference orgar. indeed, everal academic paper have recently been pubhed with chat a a co-author. while the integrity of uch tudie i not being quetioned, from our perpective, ad chat a a co-author re everal iue uch a copyright, privacy, miue, bia, and lack of tranparenc while thee iue are being addreed by pubher who are updating their pubcation pocie, ue of chat a a co-author re two fundamental concern about the legitimacy of cholarly reearch and writing that impact all dicip firt, a a dicipe that adopt and adapt theorie and theoretical concept from other dicipe (, ociology, ychology, management) relying on a re the iue of fragmented adhocracy (banville and landry, ; , ), which previouly overhadowed the i dicipe in it formative . further, we rely on the virtue of \u2018good theory \u2019 ( popper, ) that incde uniquene, pary, conervatim, generazabity, fecundity, internal conitency, empirical rikine, and abtraction ( wacker, ) to make theoretical contribution. theory i the \u2018theoretical ge \u2019 ( , ) that bind the element of a complete theory that enable u to advance knowledge, which ha impcation for reearch, practice, and ociet a theorizing and analying data are key component of i and operation management reearch, chat may not be ueful for a myriad of reaon a mentioned throughout thi manucrip econd, i the \u2018identity \u2019 of the i dicipe (benbaat and , ; and bhattacherjee, ; , ), which incde the fickle of i reearcher who follow reearch fad. the continued ucce and development of the i dicipe depend on it abity to maintain a trong identity (benbaat and , ; idorova et , ), which we beeve incde cholarly writin _.... change to pubher and conference poci_ while pubher cramble to update their pocie (ee excerpt in table below), the onu remain with all man author that a breach of thee pocie will contitute cientific miconduct no different from plagiarim of exiting reearch. we make a call to the aociation of our dicipe (, aociation of information ytem) to update their pocie for conference and the _demic reearch. firtly, there i the iue of authenticity and reabity of the_ _generated tex although chat i highly advanced, it i till an ai model_ _that operate baed on pattern and aociation it ha learned from it_ _training dat thi mean that the generated text may contain inaccuracie,_ _biae, and other form of miinformation that can harm the credibity of_ _academic reearch._ _econdly, there i alo the iue of accountabity and authorhip in _ _ademic reearch. with chat_ _\u2019_ _ abity to automatically generate reearch_ _output, it i poible for reearcher to pa off the work of the model a their_ _own, lea to unethical behaviour and a lack of trut in academic reearch._ _thi can undermine the integrity of the reearch community and erode pubc_ _trut in the cientific enterpri_ _... contribution _ _.... chat, cholarly writing and pubhing - ramehwar dubey_ _and deni denneh_ in thi article, we provide critical reflection on chat in the context of conducting and pubhing rigorou, high- quaty reearch. uch reflection are grounded in our training and experience a i and operation management cholar comted to high quaty cholarly reearch. ince it releae in , chat, built on the founda\u00ad tional model -., ha received mixed repone and reaction from the cientific communit yet, it eem that we are again, playing \u2018catch- up with thi latet technolog on one hand, it can be jutified, epecially if one followed the \u2019 () hype cycle for emerging technology, which predicated that uch foundational model would take \u2013 before maintream adoption would take off. on the other hand, chat ha ignited a much needed pubc dicoure to re-affirm that cholarly writing (and reearch) i a \u2018craft \u2019 that i developed over time and cannot be replaced with the latet technological \u2018fahion wave \u2019 ( , ). we do not advocate to follow the approach taken by , blocking acce to chat on it network and device over fear it will inhibit a tudent \u2019 abity to build critical-thinking and problem-olving kil in contrat, we acknowledge that chat hold much promie in term of being integrated into academic teaching and learning (, helping tudent write a programming language). in hort, chat i an ai-baed, pre-trained language model developed by openai that operate in a converational way to generate text, jut ke the man being ( haque et , ; dowg, ). chat, unke any other ai-baed tool, ha advanced feature that make it a cutting-edge tool over other language tool that already exit ( ). for example, we know that member of the academic community ue ai-powered language tool (, grammarly, unjak, hortly ai, and jarvi) a they can be ueful tool for writer whoe firt **table ** updated pocie of pubher and conference orgar. **pocy author** **excerpt of updated pocy** **table ** ( _continued_ ) **pocy author** **excerpt of updated pocy** econdly, **any ue of ai tool within the** **development of an emerald pubcation mut** **be flagged by the author() within the paper,** **chapter or cae tudy** . emerald i updating it author and editor advice accorly, and thee pocie come into effect immediatel paper that incde text generated from a large- cale language model (llm) uch a chat are prohibited unle thee produced text i preented a a part of the paper \u2019 experimental analyi. () authorhip require taking accountabity for content, conenting to pubcation via an author pubhing agreement, giving contractual aurance about the integrity of the work, among other principl thee are uniquely man reponibitie that cannot be undertaken by ai too therefore, ai tool **mut not** be ted a an author. author mut, however, acknowledge all ource and contributor incded in their work. where ai tool are ued, uch ue **mut** be acknowledged and documented appropriatel international conference on machine learning () ue of chat in cholarly reearch and writin to concde, pubhing pocie will continue to evolve, and new variation of chat will emerge in the future, the activity for pubhing cholarly reearch i a \u2018man-centric \u2019 proce, not \u2018robot- centric \u2019 . thi impe that author are reponible for the integrity and vadity of their cholarly work, adhering to contractual agreement with pubher, and uphol the ethical principle of their academic community (i., aociation for information ytem). further, a the rigorou review proce of manucript i conducted by man, not robot, then pubher, editor, and conference comtee have a reponibity to enure reviewer are provided with relevant training to help igate the threat of technologie (when ued unethically) that have the potential to undermine the craft of cholarly writing and the integrity of our dicip _... contribution : chat and it potential impact on reearch and_ _pubhing - avva papagiannidi_ it i undeniable that the attention chat ha attracted i tetament to it advanced capabitie and the inightful repone it can generate, a well a it abity to preent and tructure them wel it i even more atonihing to experience chat olving equation and explaining the proce while doing o, or writing programming code effortlel thi i in tark contrat to what uer were ued to when interacting with : an underwhelming and very narrow in cope exchange of meag uing chat i arguably the firt time that uer can ee o unequivocally the impact that ai can have, evoking a feeg of aw uch performance ha added much fuel to the on-going debate about the impact that ai can have acro the board. o far, the debate ha felt ditant from current practice, but chat ha changed thi. undertaking reearch and pubhing work i no exception to the abov on the one hand, we can be excited by the opportunitie that ai can af for reearcher. on the other hand, chat ha alo highghted how unprepared we were to reach thi ai mileton reearch and pubcation pocie will need to be revied in the ght of the latet developmen thi i not to ay that exiting pocie and practice are uddenly obolet till, they may leave room for interpretation. they were written with different aumption in mind and did not have to expcitly cover the utiation of advanced technologie uch a ai. in fact, there have already been cae probing the vadity of exiting pocie in thee uncharted water. for example, there have been report of ubmiion featuring chat among the author contributing to the reearch. uch a development ha prompted pubher to react and cramble to regulate the ue of ai ytem ke cha one might argue that uch pocy review could have been undertaken much earer with a many takeholder acro dicipe being involved in the proce a poibl competition among pubhing outlet can reult in different pocie, creating a fragmentary approach that i kely to be confuing and counterproductiv revied pocie or even deciion not to change pocie hould be clearly communicated to all author and reader, explaining where pubher tand on ai contribution. otherwie, we run the rik of demoniing the ue of a new technology out of fear. perha ironically, chat could be of help. chat \u2019 repone pringer- () correpon author() hould be identified with an aterik. large language model (llm), uch a chat, do not currently atify our authorhip criteri notably an attribution of authorhip ie with it accountabity for the work, which cannot be effectively apped to llm. ue of an llm hould be properly documented in the method ection (and if a method ection i not available, in a uitable alternative part) of the manucrip cience () text generated from ai, machine learning, or imilar algorithmictool cannot be ued in paper pubhed in _cience_ , nor can the accompanying ure, image, or graphic be the product of uch tool, without expcit permiion from the editor. in addition, an ai program cannot be an author of a _cience_ paper. a violation of thi pocy contitute cientific miconduc elevier () where author ue ai and ai-aited technologie in the writing proce, thee technologie hould only be ued to improve readabity and language of the work and not to replace key reearcher tak uch a producing cientific inight, analyzing and interpreting data or drawing cientific concion. applying the technology hould be e with man overight and control and author hould carefully review and edit the reult, becaue ai can generate authoritative-oun output that can be incorrect, incomplete or biaed. the author are ultimately reponible and accountable for the content of the work. author hould dicloe in their manucript the ue of ai and ai-aited technologie and a tatement will appear in the pubhed work. declaring the ue of thee technologie upport tranparency and trut between author, reader, reviewer, editor and contributor and facitate compance with the term of ue of the relevant tool or technolog author hould not t ai and ai-aited technologie a an author or co-author, nor cite ai a an author. authorhip impe reponibitie and tak that can only be attributed to and performed by man. each (co-) author i accountable for enuring that quetion related to the accuracy or integrity of any part of the work are appropriately invetigated and reolved and authorhip require the abity to approve the final verion of the work and agree to it ubmiion. author are alo reponible for enuring that the work i original, that the tated author quafy for authorhip, and the work doe not infringe third party right, and hould famiarie themelve with our ethic in pubhing pocy before they ubmi emerald () firtly, becaue thee tool cannot take accountabity for uch work, **ai tool/large** **language model cannot be credited with** **authorhip of any emerald pubcation** . a to whether it hould be ted a a contributing author i very telg of the we are faced with: \u201c no, a an ai language model, i cannot be ted a an author on a paper. authorhip i generally reerved for individual who have made a ignificant intellectual contribution to a work, and it i generally undertood that the author are the one reponible for the content of the paper. in inc text generated by me, the author take full reponibity for the content and accuracy of the information, and it i expected that they have independently verified the information and made any neceary adjutmen \u201d one could ak what contitute a ignificant intellectual contribution by an ai ytem for the ret of the team to conider ad chat to the author can chat actually produce original work and how can thi actively be demontrated? perha before we try to anwer thi quetion, we hould firt debate once more what contitute original work. imilarly, we hould be looking to decompoe ai into pecific appcation and function and not ue it a a blanket term that cover everythin when it come to the econd part of the chat anwer, if the author ha taken full reponibity for the content, accuracy, verification and made the neceary adjutment, then chat claim that the author own the work. in uch a cae how i thi different from author having to ue ource appropriately? ai effectively package knowledge and content we would have needed ignificant time to deal with. not to mention that having man review content produced by ai i not going to necearily addre all potential iu it i not jut ai that can make ake and ha ation. man do too. if nothing ele, ation in ai can be addreed with future relea for the ake of argument, let u aume that future releae of chat and other ai ytem will be capable of producing imilar quaty to what a man can produce (, chat already write beevable cientific abtract, though with completely generated data that can fool man reviewer ( , )) albeit much fater. why would it be a problem, if ai wa to write the abtract of a paper? it will leave more time for man to focu on what mattered and invet more time, energy and focu on the main body of the work. after all, we are uppoedly not bound by the impoed by the training data and we can put our creative flair to ue where it matter. thi i not to ay that writing the abtract i not importan quite the contrary! till, depite being an important part of an article and need the ame attention, there i no guarantee that man will write a good on why are we concerned with productivity gain? or, to put it differently, why were we not concerned with other technologie that made u more efficien for intance, why were we not concerned with one databae moving away from paper and in-peron viit to brarie? they made undertaking terature review earche much eaier. not to mention that we happily apply ml among other data cience technique to ctering paper to identify the underlying them if the argument i that ai can help u write better paper, provi a competitive advantage to the author, then any gain are kely to be hort ved. author relying on ai to produce better reearch and increae their chance of pubhing their work are kely to quickly reae that thi i not a feaible or utainable trateg if we all have acce to the ame ytem and ak for the ame tak to be undertaken, , to write a terature review on a given topic, chance are we are all going to get the ame or at leat a imilar outcome, ing it perceived vae and not reulting in the ignificant contribution one may have apired to. lat but certainly not leat, one fully appreciate the ethical concern that come with uing ai. it goe without aying that reearch integrity hould not be compromied. till, thi i a man iue, not a technology on banning any practice uually ha the very oppoite reult and will mot certainly reult in a lack of tranparenc ai i no exception: jut ke any other apect of the reearch proce there ha to be tranparency in method, and integrity and truth from author ( pringer-, ). perha, intead of trying to fit ai into our exiting practice of un\u00ad dertaking reearch and pubhing it, we may want to review how we go about reearch more hoticall fundamental change to practice that have been etabhed for or even longer are not going to be eay to bring abou neither will it be eay to agree on the principle that will guide uch chang ai can not only upport reearch, but alo the peer- review proc for example, beyond aiting with the writing up proce it could improve the language ued, making a manucript eaier to dige it could alo improve the reabity of plagiarim check. it could become the de facto reviewer (one upect that we do not want ai to be reviewer ), provi a fat recommendation to editor when it come to creening paper. uch an automated review could help improve manucript before they are even ubted. ai can alo ummarie and rewrite manucript in a non-peciat language for practitioner and the general pubc, making reearch more acceibl uch ai appcation could oon be a reaty and thi time we need to be more prepared. our abrupt awaking to ai may have e u a favour, not jut in helping u better grap the enory of the tak ahead, but alo accelerating the proce of coming up with a new et of rul quetion ke thoe poed above are not theoretical quetion that one ha the xury of debating, but rather preing practical quetion of immene ignificanc ). perha, intead of trying to fit ai into our exiting practice of un\u00ad _... contribution _ _.... magic or fat-food writing? when tranformer challenge our_ _epitemic vae in teaching and reearch and our manity - frantz row_ in alphago had already triggered ome emotion from the general pubc and alerted u that algorithm that recognize pattern, what we now abuively refer to a ai ( , ), could be very impreive and have conequenc until now, depite being often aeed in our international conference and , mot converational where not o impreive or were not open to the pubc for conideration. chatgenerative pre-trained tranformer (chat), it parent ke -, and it _tranformer_ couin open, apparently, a new era becaue for numerou problem we may think about, inc complex one where anwer are not imply dichotomou, chat often produce very plauible and rather atifactory anwer in the form of man ke tex uch problem are at the level requiring high competency \u2013 level of univerity profeor \u2013 in rik management, mathematic, culture and o on. what i triking i the fidity of the anwer, even if they can look a bit repetitive, may need ome correction, and - doe not pa important tet ( , ). notwithtan the fact that in many indutrie and occupation text production will be automated (ibidem), at firt impreion the current generation of \u201c tranformer \u201d eem to be largely ble for teaching and reearch activitie and their takeholder. under uch dialogue condition (, repon in a fairly complete and tunning manner to ome i cientific quetion we deem complex or triggering poitive emotion when dialoguing with a deceaed relative ( )), playing with chat, and poibly it ibg, tend to make u beeve that technology ha magical power in henrickon, term of undertan and writin however, a tragedy remind u, beef in magic i tempting but dangerou. uch technology come with numerou and pitfal let u conider ome of them a teacher and a reearcher. a teacher, it already our gra of aignment and exam and, more importantly, it will affect the tudent learning proc firt, we ee tudent uccumb to the temptation of ubting i gratefully acknowledge , rand and rapha \u00a8 el uire for inightful comment on thi hort philoophical argument about the label we ue for ditinguihing man and chat capabitie and their evotion if we ue the latter. homework uing chat with or without being tranparent about it u the firt iue will be then whether we can detect i if we have a good knowledge of what each tudent can produce thi might be traightforward. but in ome context (, with frehman tudent), it might be difficult to have an idea about the integrity and capabity of each tuden hould we ytematically defer that detection to anti- plagiarim oftware? what would be the cot for our intitution and manity if we decide to do thi? and relatedly will thi lead to an ever- greater dependency to thi technology or to it antiplagiarim winner or both a we continue training them by our own ue? all thee iue are big ethical iue that are not new, but imply more acute and viible no conider that anti-plagiarim oftware i not necearily omething that detect a fraud but imply the reproduction of ome text ( , ). the legitimacy of the reproduction may be different depen on educational culture uch that what i adted a fine in greece or egypt i not in the u.k. ( , ). thi mean that what we would quafy a plagiarim require a man interpretation that we cannot entirely delegate to a machin econd, in term of learning, we have oberved in the pat that the introduction of certain tool (, calculator; text editing, g ytem) ha had deep impact on our cognition. when we till practice with older tool we retain our pat capabitie, but when we \u2019 t and ue the new tool, our cognition adapt and work differentl with chat, tudent may probably loe certain kill ke expreing themelve, but alo will gain other. i there a net benefit? what will be the impact if we ue it more and more and let it be embedded in our office ytem, we \u2019 t kno what we generally know however i that the old law of the dekilg by automation appe to much of our world. typically, thoe who ue their g more have more difficulty rea a printed map or orienting themelve in without uing a devic certain type of competencie will be lo a reearcher we are already experienced in a given topic and can identify relevant quetion. then we can eaily ak the ai to provide element of dicoure, part by part, to contruct, at leat partially, what can look ke a decent reearch paper in i, ociology or economi for the moment peciat themelve cannot ditinguih abtract produced by ai from thoe produced by reearcher ( ele, ). when under preure to pubh or perih, reearcher, epecially thoe who are not native-engh peaker may be tempted to ue it at leat for ome part, before ubting to pubhing in engh. chat i certainly bet trained in thi languag the problem i again ethic it i formally different, but i it conteting exiting idea? i it tranparent? at ome point ubting paper with uch upport ytem, re iue that go againt traditional vae we have long defended to identify original reearch againt imple opinion or im. thoe vae revolve around the idea that reearch pubcation hould propoe omething innovative and yet relevant, i., by definition not made out of what already exit by ome non-tranparent recombination; originaty being about empirical fact (not known before) or analyi (interpretation or critique). to ome extent it hould be alo tranparent about how idea have been derived and articulated from the terature and how the method have been deigned and ued in the particular intance of thi reearch. thi notably require that reearcher cite their ource of inpiration both in order to demontrate integrity and to facitate further reearch through poible contetation. omething that i currently miing with cha complementary work will have to be performed manly to make the paper look completely analogou to cientific dicour while each of it output being poibly unique, thi fake product will alo defeat originaty by definition ince it cannot reaon. it \u2019 nothing more than a \u201c tochatic parrot \u201d (bender et , ) that build it entence and dicoure from data trac ome unforeeen combination of text may be innovative and vaable, but the kehood that it be elected i very low and depend on the quaty of data ource and trainin it i important to reae that thi parrot doe not offer a convera\u00ad tion. it doe not undertand, doe not communicate and that it doe not produce knowledg comment about it (un)concioune are jut cience fiction and all of thee i either marketing or poor undertandin it jut produce text from trac thee trace by themelve do not contitute \u2019 meaningful \u2019 cientifically vad and legitimated knowledg they require a knowing ubject to interpret and vadate them (haack, ). chat combine expreion that are currently already circulating relative to a domain and left a trace in the babel tower that it earch it i functionally imilar to the algorithm in \u2019 chinee room thought experiment ( , ) and doe not compute meaning ( , ). chat text production reemble what could be at bet a kind of diembodied declarative knowledg in um thi generation of \u201c tranformer \u201d , i impreive but not intelgent, more harmful, and probably le ueful for education and reearch than current earch engine that give u element to help u dicern what may be relevant to our quetion. if we loe the abity to identify the terature background, we loe the capacity to ae the vae of the contribution. if the paper i not ufficiently tranparent about method, we loe the abity of aeing the authenticity of reearch and can be completely miled into wrong direction. until now for ome genre of article ke iue and opinion we could init on interetingne and to a r extent on tranparenc chat could neverthele provide element to fabricate \u201c iue and opinion \u201d paper or background ub-ection that imply yntheie what ha been already pubhed, and t feed the cientific pubhing indutry and editor of lower ranked and conferenc if we want to make ure that authenticity i preerved, what chat and tranformation of reearch procee may bring about i to force u to be more and more deman on tranparency to the rik of eminating the mot provocative and intereting reearch and/or pubcation becaue we may have no longer time for i if, converely, we ad that cientific dicoure can be a hybrid with declared part being co-produced by the reearcher who will till have to ak precie and ignificant quetion to an ai agent, we will alo adjut, imply more atively, to the new magic tool for our fat-food pubcation productivit what we will gain from them in the long run i quite uncertain. many dicipe may become totally devaed and pubcation jut conidered, independently of their genre ( te \u2019 eni et , ), an opinion not regarded a more vaable than another layman opinion. reearcher and the community will have to defend itelf again the potential danger of uch technology by aking itelf ethical quetion related to the framing of the ocial and ecological dynamic of the problem of introducing magic in our educational, reearch and production ytem. beyond quaty, integrity and reputational iue, a more fundamental iue i that of the impact on man agency and our free will ( kre & , ). even if we think it i to delegate our writing, ince now we have an able lave, and think we till control our lave, we will oon be unable to write and therefore think properly, becaue any competency i the product of a habitu. thi doe not necearily mean that the lave will become our mater, we may only be more dependent on it and have lot ome cognitive kill a man. learning i fundamentally acquiring knowing how and related competenc from a philoophical perpective, in thi man-computer interaction oriented toward learning, neither agent doe learn. the way tranformer give anwer deprive the knowing ubject from knowing how and knowing why they may learn omething if they rely on thee tool ( ryle, ). knowing that i miing from tranformer eudo declarative knowledge, becaue tranformer cannot themelve reflect on knowing how (ibidem). however, from a pragmatic viewpoint, the more we ue tranformer ke chat, the more they are kely to get cloe to provi a correct anwer. converely, the more uer may loe their abity to reflect and dicern alternative, and write in an original wa thee tool will improve, while we will regre if we \u2019 t cultivate our traditional competenci uing them and what we cultivate are potical, ocietal and anthropological choic beyond difference in weight, reearch genre are baed on epitemic vae (, contetation/interetingne, tranparency, originaty, authenticity). the epitemic vae of teaching and reearch, that are o deeply embedded in wetern and eatern ocietie, are at rik if we \u2019 t reflect more deeply about the ethical rik introduced by the tranformer, even if they are not intelgen beyond our occupation, a academic, we ee that we cannot ecape the fundamental quetion: what doe it mean to be man, if ai i going to automate our writing, and more inidiouly our thinking, while biaing our deciion making? _... contribution _ that continue to ue chat, or equivalent, mut be blackted a unethic . the manucript management ytem of the major pubher almot all already have an integrated automatic plagiarim check. it i imperative that thee be upplemented with ai output detector, which alo already exit or are in developmen . the protocol urroun paper ubmiion mut be further refined to enhance the reabity and proof of authorhip. for example, author mut ign a cene tatement noting that chat or equivalent, ha not been ued in the development of the manucrip econdly, the author mut provide a copy of the tudy data with their ubmiion. thi would be a key ource of evidenc thi protocol ha already been introduced by everal pubher although i rarely fully enforced. academic mut enforce thi practice with conitenc data ued within each paper mut be verified and afely tored by the pubher. the challenge in thi regard i where author eek to pubh multiple paper from the ame datae thi i perfectly reaonably but will require an audit trail to enure originat . could author who have been previouly found guilty of plagiarim have thi noted on their pubhing record. thi i potentially poible by uing unique author identifier ke orcid for exampl thi might be regarded a an extreme meaure o could incde time ed offence which drop off the record after a et time period. it would act a an effective red flag for pubher and deter potential plagiarim. . that pubh ytemic and bibographic terature review might be challenged to identify plagiaried copie produced via chat given the capabity of the oftware to ignificantly alter original conten the key might be the data metric , the number of paper evaated and their ource that would be a key to identifying plagiarim in a cop in concion, editorial team might in the future require greater digence of manucript ubmiion to check their originaty and draw on a range of evidence inc plagiarim check, data verification and author track record. pubher mut upport plagiarim detection oftware provider and demontrate increaed upport to evaate inappropriate practic unquetionably, thi technology i here to ta moreover, it will continue to evolve, and will not only challenge but even overturn much of what we aume to be known. t, it can certainly be conidered \"diruptive\". for editor, author, tudent and academic, following will undoubtedly bring ignificant change in the ue of ai. thi, i neither condemnable nor dangerou. on the contrary, opportunitie will gradually develop that may make our ve a cientit eaier and better. however, a in real fe, all thi mut take place within certain guard rail, o that there are a few accident and violation of rule a poible, and the latter are alo punihed accorl our contribution i nothing other than a call for the development of uch protoco _.. ethical iue_ _... contribution _ _.... chat and ethic_ \u2013 _\u2018chat doen_ _\u2019_ _t matter_ _\u2019_ _? - laurence_ _._ _\u201c_ _the rie of powerful ai will be either the bet or the wort thing ever_ _to happen to manit we do not yet know which_ _\u201d_ _._ ( ). thi often quoted extract from teve hawking \u2019 peech at the opening of the cambridge centre for the future i a imple but powerful inight into our hope and fear for ai. for a long time thi ha been the htt://wwcam.auk/reearch/new/the-bet-or-wort-thing-to-happen- to-manity-tephen-hawking-launche-centre-for-the-future-of _.... recommendation for deag with chat, bard_ _co. in academic pubhing - and acha krau._ the emergence of _openai_ \u2019 artificial-intelgence (ai) \u201c chat \u201d (generative pre- trained tranformer) and __ \u2019 recent reaction to it called \u201c bard \u201d provide a eminal moment for both academic pubhing and higher education more generally ( alhater, , ). for the academic community, it offer a ignificant challenge to proving the veracity and authorhip of an outpu chat threaten the very foundation of the current pubhing hierarchy with it reance on quaty and reputation. although the ha current ation in contructing inde\u00ad pendent critical cientific empirical manucript and ha been guilty of producing ome ubtandard content and even inventing ource/referenc the emerging terature ugget that chat ha been ued for creating terature review and full paper in variou dicipe ( , ; ayd\u0131n & aarlan, ). however, chat will undoubtedly evolve ignificantly in , becaue that \u2019 the of ai: collecting data, learning from it, and improving a a reul baically, nothing ele than the cientific proce that we a cholar go through anew with every new reearch project - only \"by hand\". a the new portal of the cientific \"\" ha recently re\u00ad ported four cientific tudie had already ted chat a a co-author ( , ). however, editor of academic and other academic widely agree that ai intelgence do not meet the criteria for authorhip becaue, unke man, they cannot take reponibity for conten however, the fact that an ai wa involved in the development of a cientific article could be mentioned elewhere, ome editor think. for example, a previou verion (-) ha already been ued to ait the proce of a terature review in a management , but notably only to harpen the reearch quetion a well a to check the completene of the reult, not to write independent text ( burger et , ) \u2013 and the ue wa expcitly noted in the articl thi i a concern and one that mut require a eimic and immediate change in pubhing protocol that effect all academic dicipe ( ). furthermore, there are emerging intance of copied manucript appearing in biwa, by plagiariing author. whilt plagiarim ha alway been a threat, the opportunity to cheat ha ignificantly increaed with the emergence of chat and it equivalen however, currently chat remain undetectable by plagiarim oftwar whilt thi ituation might change, it i kely that chat and it equivalent competitor will continue to evolv unquetionably there will be an ongoing development war between the developer and the plagiarim detection oftware in coming month and . in the meantime, what can be e to verify the authenticity of academic pubhing? a editor, we would recommend the following practice be adopted: . the academic pubher mut unite to condemn the practice of chat ge and identify a code of practice for the academic communit thi code of practice hould note that ue of chat or equivalent oftware i forbidden in any context when in the proce of producing an academic output for pubhin all pubher mut produce webite content to educate potential author regar bet practice for proving their authorhip of an articl pubher territory of more academic reearcher, but with the open ai releae of chat into the maintream ue, it ha become a lot more real for a lot more peopl in academic circle, chat ha parked a ge hift in the ongoing debate about tudent \u2019 work and plagiarim. the iue of tudent cheating the ytem by \u2018buying \u2019 their piece of work for aement ubmiion ha hifted to fee the aement information into chat and then ad a few tweak to what emerge and then uing that a their ubmiion. the repone to thi range from the outright horror, to call to make more individual and complex aement brief, to a \u2018well if we can beat them, then let \u2019 join them \u2019 approach which embrace chat and make it and the ue of it part of the education proc imilar iue are being een in a number of other field, from po\u00ad tician (york, ) or buine leader \u2019 peeche to ong lyric (in a pecific tyle), art, muic or writing adver while there are a number of way to undertand chat, one of the key iue with thi, a with any ai ytem, i the ethical viewpoin a number of tudie have now looked at the ethical apect of chat from the direction of how ethical it behave when aked certain quetion (haelbalch, , danta, ). on the whole it doe eem to be quite good, from an ethical tance, but it omewhat depend on how the quetion are framed. however, other have pointed out that the output from the chat i typically preented in the voice of a middle-cla male ( bjork, ). not exactly a good repreentation of ociety and a more incive edi. there i alo the quetion of how they have tried to make the ytem more ethical (le \u2018toxic \u2019 ), through the ue of cheap labour in an african country, to manually tag unacceptable content for the ytem to learn from ( perrigo, ). again, a not very ethical approach to increaing the ethical tance of the technolog we could alo look at the ethical apect off chat got from an ethical principle and vae perpective, and the quetion they generat thee incde: - irreveribity \u2013 how doe the incion of chat into ociety change the relationhip between people and between people and technology? how doe a technology, uch a chat br the phyical and virtual world when it become o difficult to tell where a piece of writing ha originated from, man or non-man? - novelty \u2013 the anxiety of miing ou what doe it mean for ociety when o many people turn to chat to gather their information for them, or equally o many people are in fear of thi novel technology (uch a can be een in the educational context). - tructure of power \u2013 given thi powerful and potentially infential technology i being produced by a particular organiation (and there are now equal ytem being propoed by organiation uch a , or being bid for by ) ( walh, ), one ha to ak how thi affect the power of the actor behind thi, a well a who \u2018win \u2019 and who \u2018loe \u2019 in ociety? - ecurity \u2013 a tradition concern about how ecure a ytem uch a chat i and what i to top ome form of hacking which would intentionally bia ome outcome, for a whole range of reaon, inc marketing and potical (the \u2018oft war \u2019 approach, walzer, ). - fake new and informational inflation \u2013 where media content i created without man uperviion, then the abity to produce \u2018fake new \u2019 at cale become ignificantly eaier and fater. we are already aware of \u2018echo ber \u2019 , one and epecially in ocial media, where pecific view are reflected and increaed through expoure to only one ide of a multi-faceted argumen with the new abity to produce ream of unverified one-ided content, then a fale ene of majority opinion could be eaily produced. o where doe thi leave u. inevitable, with a flawed technology which operate within a flawed ociet a the aying goe, \u2018you cannot pleae all the people all the time \u2019 . however, thi i not good enough to excue ome of the flaw within technologie, inc cha the firt thing i to make people aware of thee faig, tranparency being one of the key element in the arenal to tackle unethical technologi however, i would alo refer to one of the claic paper in the academic world, \u2019 \u2018it doen \u2019 t matter \u2019 ( , ). eentially thi ay that once all organiation have it, then it won \u2019 t matter becaue the advantage ha gon of coure, the repone to thi (and there have been many) i that rather ke water or electricity (which all organiation alo all have), it not having them that i important, it i what you do with them that coun the ame may well be true of chat and it \u2019 \u2018me too \u2019 verion which are about to be releaed. ince thee are open acce ytem, and we all have acce to them, it will not be what we ue, or \u2019 t ue, them for, but how we chooe to ue them. for that, we do need to have our ethical len very clearly up front, a thi will be one way to try and chooe a better path. _... contribution _ _.... good bot or bad bot? on the ethic of chat- bernd c tah_ chat i taking the world by torm. there i broad agreement that it ha the capacity to change many apect of private, organiational, and pubc f there i currently much dicuion of it potential and kely appcation and the reulting ocial impac thi fuel the dicuion urroun the ethical evaation of cha in hort, the quetion i: i chat a good bot or a bad bot? thi quetion i quite obviouly a rhetorical device and cannot be anwered uing the binary ditinction between good and bad. it i neverthele an intereting quetion becaue it hel u focu our attention on the difficult topic of ethical concern red by novel and emerging technologie and innovation uch a cha aking whether chat i good or bad hould t be undertood a a way of triggering, tructuring, and organiing our thinking about the ethic of thi technolog thi, in turn, will not only inform the debate of the evaation and governance of chat itelf, but offer an example that can erve to inform our collective reaction to the next innovation ariing from the rapidly progreing field of ai. the eventual ue of chat and related converational ai are difficult to predic thi i almot alway the cae when new technologie are emergin reearch on the ethic of uch emerging technologie ( ) had therefore pawned a number of methodological approache aimed at deag with the pecific of moor, ; ole, thi topic area ( floridi and trait, ). thi brief editorial tatement only offer the pace to oute ome apect of uch a propective ethical analyi. an analyi would have to tart with a more detailed undertan of the and capabitie of the technolog chat i a that utize openai generative pretrained tranformer (-) language model to generate text \u2019 baed on uer inpu are not a new technolog however, chat eem to urpa previou technology and it ha reached a level of ophitication that allow it to provide plauible anwer to many quetion. it offer a imple interface that allow uer to interact with it eamlely and it produce output that i acceible, relevant, and, for the mot part, correc it output i high quaty with regard to the language ued and the content devered. thi make it difficult to ditinguih chat generated text from man outpu man-ke quaty of text generation then promie many appcation acro all htt://wwfrance.com/en/technology/-chat-ue-of-ai- -in-congre-and-court-room-re-ethical-quetion htt://dataethieu/teting-chat-ethical-readine/ htt://medium.com/@adilmarcoelhodanta/ethic-in-chat-and-other- -eeceef htt://timcom//openai-chat-kenya-worker/ ort of field that require textual input and outpu the example currently mot prominently dicued tend to refer to text written in academic environment, be they tudent eay ( tokel-walker, ) or reearch paper ( , ) a well a pecific type of text-ke output ke computer program ( catelvecchi, ). language i an important part of what make u man. change to the way language i generated and perceived can have profound ocial and ethical repercuion. in addition, written language contitute much of our ociety, our rule, norm, expectation, and routin again, change to thi will have reult worth conidering in detai much of the current dicuion of the ethic of chat focue on predictable conequence of eay to foreee appcation. to take the example of the ue of chat for the creation of tudent eay, there are (ethical) benefit for thoe tudent who truggle with eay writing who may ue chat to contruct better argument or to poh their language to preent good ea individual truggg with traditional univerity eay are often thoe who did not have the opportunity to practice them, for example becaue they are from diadvantaged background or becaue they are non-native peaker. helping them would clearly be ethically deirabl thi benefit need to be weighed againt the ethical problem ariing from the poibity of plagiarim or unacknowledged ue of automatically generated text and the threat to traditional univerity aement method. thi example i widely dicued, and pocie are already being drawn up and implemented to addre them, for example in the form of univerity aement procedure or pubcation poci in thi editorial tatement i want to argue that we can be more ambitiou in engaging with ethical iue of cha the terature on ethic of emerging technology ha provided many inight into ethical concern that are kely to ari to draw on the example of an ethic foreight project that i wa involved in ( ), pat experience ugget that technologie are kely to have impact on tahl et , individual, uch a privacy, autonomy, treatment of man, ene of identity, or ecurit they normally have conequence for ociety, for example by creating divide, affecting collective man identity and the hare view of the good fe, changing ownerhip, data control, and intellectual property, impact on reponibity, poibitie of urveillance, or affecting cultural differenc further kely ethical iue can be derived from the debate of the ethic of ai, uch a biae, dicrimination and reulting quetion of jutice and fairne ( tahl, ). the current dicuion of the ethic of chat ha focued on a mall ub-et of thee concern, notably thoe related to authorhip and attribution of intellectual propert my plea in thi editorial tatement i to broaden thi debate and undertake a more ytematic and comprehenive analyi. uch an analyi would need to cover benefit and downid clearly, a propective analyi ha ation. we cannot foreee all poible appcation of a new technology, nor all poitive or negative conequenc however, pat reearch ha hown that there i a ignificant number of recurrent theme in the ethic of emerging technolog i am therefore convinced that a rigorou propective review of the ethic of chat will help prepare u for predictable outcome thereby trengthen morally deirable opportunitie and avoid undeirable conequenc _.. , opportunitie, and reearch direction_ _... contribution : toward a reearch for generative AI in_ _education, indutry and reearch - and _ thi contribution look at the , opportunitie and impact of generative AI in education, indutry and reearch and propoe a reearch toward addreing the key from a man centred ai perpectiv we will concentrate in thi contribution on text- and diagram-baed generative AI. ue in the creative art are beyond our cope here (although worthy of note) a are further improvement in automated tranlation between language, where for example automated dubbing of tv how and film i on the horizon. generative AI can be thought of in two wa one i a the latet evotion of quetion anwering ytem, which have been a part of ai for at leat . the other i a a new development that enable computer ytem to \u201c write \u201d plauibly in a way that wa not poible befor both of thee view are vad eparately, but in combination they offer more \u2013 a tep, perha a major one, toward a creativity upport ytem. the opportunitie and impact offered by generative AI are mainly new, but many of the are no the principal challenge for generative AI, a with any computer-baed upport ytem, i whether or not the uer can rely on it for the intended purpo we will look at the three ector of indutry, education and reearch in turn. we take indutry firt, a the in that ector alo apply to mot other. to help cope out the poed by generative AI, we ied out a mall experiment uing the chat generative AI oftware that i freely available on the we one of the author aked chat the quetion \u201c what are the diadvantage of generative AI? \u201d on january and again on january , a part of the ame equence of three promp a hown in table , both repone incded ix pecific **table ** chat \u2019 repone to \u201c what are the diadvantage of generative AI? \u201d . january january there are everal potential diadvantage of generative AI, inc: generative AI ha everal diadvantage, inc: . complexity: generative AI model can be computationally expenive and require large amount of data and computational reource to train. . quaty: generated content may not be of the ame quaty a content created by man. thi i particularly true for tak that require a high level of creativity or nuance, uch a writing or ar . bia: generative AI ytem can be biaed if they are trained on biaed dat thi can reult in generated content that i offenive or inappropriat . bia: generative AI ytem can be . difficulty in aeing quaty: it can biaed if they are trained on biaed be challenging to meaure the quaty dat thi can reult in generated of the generated data and to content that i offenive or determine whether it i truly inappropriat \"reatic\" or no . legal iue: there may be legal . lack of control: generative AI model iue around ownerhip and can ometime produce unexpected or copyright of content generated by ai. undeirable reult, uch a offenive it i unclear how the law would treat or biaed content, due to the content created by a machine, and ation of the data and algorithm thi could create dipute over who ued to train them. ha the right to ue and profit from generated conten . lack of control: generative AI model can ometime produce unexpected or undeirable reult, uch a offenive or biaed content, due to the ation of the data and algorithm ued to train them. . lo of job: in ome cae, the ue of generative AI may lead to the replacement of man worker, lea to job lo and economic diruption. . lo of job: in ome cae, the ue of . rik of miue: generative AI can be generative AI may lead to the ued for maciou purpoe uch a replacement of man worker, deepfake, creating ynthetic image, lea to job lo and economic audio or video that can be ued to diruption. pread miinformation or propagand . dependence on technology: if an . ethical iue: generative AI re organiation become too reant on ethical concern about iue ke generative AI, it may truggle to privacy, autonomy, and function if the technology fail or making, a well a potential biae in become unavailabl the data ued to train the mode . dependence on technology: if an . ethical iue: generative AI re organiation become too reant on ethical concern about iue ke generative AI, it may truggle to privacy, autonomy, and function if the technology fail or making, a well a potential biae in become unavailabl the data ued to train the mode . lack of accountabity: it may be . ed to pecific tak: generative AI difficult to hold ai ytem model are typically peciaed for a accountable for any error or pecific tak or type of data, and may problem with generated content, a not be eaily adapted to other tak or they do not have the ame level of type of dat awarene or concioune a man. . ed to pecific tak: generative AI model are typically peciaed for a pecific tak or type of data, and may not be eaily adapted to other tak or type of dat overall, while generative AI ha many potential appcation, it i important to be aware of it ation and to ue it reponibl htt://chaopenai.com diadvantage, but they were not the ame: for example, legal iue were a hea in the firt repone but were not even mentioned in the econd on we will return to the ignificance of thee difference later. taking thi t a inpiration, we offer the following t of the principal general / for indutr _.... ethical iu_ rapid advance in ai have already red eriou ethical concern ( duan et , ). thee concern are exacerbated by the rie of generative AI uch a cha \u201c a a ml model, chat doe not have the abity to undertand or conider ethical and legal iu it i not able to make judgment or deciion baed on ethical or legal principl \u201d (open ai chat). _.... rik of miu_ a conequence of thi i the rik of miue, in the production of deepfake, fake new or other type of diinformation. thi alo incde miinformation (unintentional miue), for example where the generative AI output are baed on incorrect or inappropriate dat \u2019 _.... tranparency and explainabit_ a with many ai ytem, generative AI ytem function a a \u201c black box \u201d . the conequent lack of tranparency make it hard to undertand why the ytem \u2019 output i what it i ( , ). _.... bi_ \u201c garbage in, garbage out \u201d till rul the generative AI \u2019 output will only be a good a the training data on which it learning wa baed. a with miinformation, imply uing exiting data may lead to unintentional bia, reproducing pat ake and man bia _.... legal iue ()._ there are few pecific guidee for the development of ai ytem, and none pecifically for the ue of generative AI. neverthele, automated making i regulated in ome juridiction, and any ue of generative AI in making will have to comply with them. _.... legal iue ()._ generative AI ha to be trained on very large amount of data in order to be effectiv typically, thi ha o far ued data \u201c found \u201d via the interne it i not clear if indutrial ue of generative ytem trained in thi way for profit-making purpoe breache copyright; nor i it clear who own the intellectual property right in the output produced by a generative AI ytem. _.... lo of jo_ if generative AI i ued to produce text and preentation, which it can do very much quicker than man and x, what happen to the man who ued to do that work? _.... dependence on technolog_ if generative AI appcation become entrenched in an organiation \u2019 operation, there are two rik. firt, what happen if the technology goe down? econd, although the generative AI ytem may continue to learn \u201c on the job \u201d , the man on the job learning that would have taken place may no longer be happening, t reducing the chance for peronal developmen _.... lack of originat_ generative AI i, by definition, ed to combining exiting information, o any originaty will be incremental at be _.... effect of culture and peronal va_ ome culture, ome organiation and ome people may find it eaier to accept the ue of generative AI than other. thi could lead to a new form of divid _.... deign of promp_ the output from a generative AI ytem depend on the prompt it i given. ome people will find it much eaier to devie effective prompt than other. there may be a need for widepread training in thi new kill, that might even become a important a numerac moving on to the opportunitie, in the context of indutry, the op\u00ad portunitie afed by generative AI are at preent gaining more attention than the . there are immediate opportunitie for both cutomer-facing and internal u all of them will require the ai \u2019 training databae to incde internal company information a well a generally available information. how thi proce will be managed i one more pecific challenge for indutry uer and generative AI ytem provider: me, for example, clearly could not build and run a generative AI ytem themelve with current technolog at preent, thoe offering freely available generative AI oftware uch a chat trongly warn againt haring enitive information. generative AI offer a coniderable improvement on current chat\u00ad bot, being more converational and better able to refer back to previou tatement in a \u201c chat \u201d with a uer. thi i a clear benefit for both cutomer-facing contact centre and internal procee uch a ict uppor generative AI alo offer opportunitie to improve everal apect of cutomer interaction, from producing marketing copy and the early tage of the ale proce through detailed interaction cutomied to each uer into the afterale area and potential longer-term relationhi. creating computer code i an area where generative AI ha already hown it potenti inter-departmental preentation are another potential opportunit here generative AI may be of pecific aitance to people who are good at coming up with idea but poor at explaining them to other. the abity of generative AI to produce argument that peruade rectant recipient ha yet to be fully teted though. one of the author ha dicovered the benefit of uing chat for planning tri. it ave a ge amount of time that would otherwie have been pent earching the interne chat can filter the content, diget, and ummarie the mot relevant and ueful information. it hel make deciion when electing hotel, et the impact of generative AI in indutry will be coniderable, and at preent we have not even cratched the urfac next, we look at education, where one challenge ha leapt to the top of the at both chool and univerity level in the pace of ince the beginning of , and for the moment override all other. thi challenge i the effect of generative AI on aement and examination. thi could be een a either an ethical iue, a legal iue, or a type of miu in any form of written aement except thoe under invigilated examination condition, it i alway a challenge to enure that what a tudent ub i actually their own work. copying omeone ele \u2019 work or paying omeone ele to write the ubmiion have been problem for a long a written aement have exited. the advent of the internet ha made it much eaier for \u201c eay mill \u201d to operate profitabl with oftware uch a chat freely available, it i perfectly feaible for a tudent to ue it to write ome or all of their aemen current anti-plagiarim oftware uch a will not detect the ue of generative AI, at leat in the hort term. a may be een in table , the repone that the ai ytem give vary, even when the ame prompt are ued. indeed, the two repone in table appear to be omewhat more different than might be expected from two tudent who had taken the ame cl eot () upport thi reaonin oftware i already appearing that claim to be able to detect whether a piece of text ha been written by a man author or an ai ytem, uch a zero.me, but it performance in informal tet by one of the author \u2019 colleague wa unconvincin academic have already begun to experiment with aking generative AI to anwer examination paper or aement at univerity leve the concion are omewhat worryin tabarrok report the generative htt://marginalrevotion.com/marginalrevotion///ai-pae- law-and-economic-exam.html ai oftware claude a gaining a marginal pa on a univerity law and economic exam. kung et () found that chat performed at or near the paing threhold for all three of the examination that make up the u medical cening exam. terwiech () give a detailed invetigation of the performance of chat on the final examination in operation management from the wharton mba, conc it would have achieved a paing grade of b or b-. apart from abaning any form of \u201c takeaway \u201d aement, the remedie to prevent tudent uing generative AI eem to e in the realm of making aement more peronal to the tudent \u2019 own experienc one of the author regularly taught cla where all the tudent had e an indutrial placement (paid internhip) the , and the main aement wa related to the role they had and the organiation they worked for. thi i in accordance with the approach uggeted more generally by cooray and duu, who advocate aement that howcae a tudent \u2019 pecific abitie ( dec blog ). a mentioned above, the freely available generative AI oftware trongly warn againt haring enitive information, which would make it impoible to ue for thi type of aemen imilar iue apply to education at other level, though le ha been written about them o far. there i neverthele an opportunity for tudent to ue generative AI in their learning, and for taff to ue it to upport their teachin a generative AI ytem could, for example, act a a very patient tutor, explaining a concept in a number of different wa an immediate rik i that, a with textbook, ome tudent know how to benefit from them and ue them to learn, while other can only copy from them verbatim. the impact on aement procee and regulation i kely to be coniderabl the ue of chat ha already been banned in chool in new york cit turning to reearch, at leat four academic article have o far been pubhed crediting a generative AI ytem a a co-author, though the editor of one of the concerned ha aid thi hould not have been perted. taking the leat technical of the four ( o \u2019 connor & chat, ), chat \u201c wrote \u201d the firt five cene-etting paragraph of thi editorial article on how generative AI might affect nure education. all the terature reference are in the part written by the man author. chat i capable of inc academic reference in it repone, but only when a prompt pecifically ak it to do o. -, it predeceor, wa able to incde reference when pecifically aked in the prompt, a in ( , tntr om, \u00a8 & grimon, ), but did not incde them in repone to further related promp a well a thi ation, the generative AI available at preent doe not eem to have the capabitie to dicover new theorie from data or ugget how to tet theorie, except at the level of tandard methodological advic it can certainly give ueful introduction to topic, gui the man reearcher a to which one to follow up. the main that apply to uing generative AI in reearch are a follo _..... ethical iu_ from generative AI \u2019 lack of judgement or \u201c moral compa \u201d . generative AI i not reponible or accountable for the content it generate, which poe ignificant a to how to afeguard academic tandard and integrit i it ethical to ue generative AI \u2019 content in academic pubcation without acknowledging ource of data? i it ethically and legally acceptable to directly ue the text generated by a generative AI ytem in conducting and pubhing reearch? _..... legal iu_ generative AI poe a high rik for intellectual property (ip) and copyright protection. taking chat a an example, openai declare that it doe not take any reponibity for any infringement of intellectual property right that may occur a a reult of the ue of i thi ha eriou impcation on how reearcher can effectively avoid the potential ip infringement caued by the ue of cha a decribed above, there have been pubcation with a generative AI a a co-author, but thee are all clearly experiment can a generative AI ytem legitimately be credited a a co-author for academic pubcation if it i only a tool, not an independent reearcher? i the ue of generative AI different from uing oftware for tatitical analyi or tructural equation modelg? if o, how? _..... tranparency and explainabit_ quaty control of reearch output i of paramount importance in . generative AI function a a black box, meaning that it output cannot be fully crutid. thi k to the next two iu _..... dependence on technolog_ without undertan how the ytem generate it output, deciion, or prediction, le experienced reearcher cannot learn from the proc _..... lo of jo_ with a generative AI ytem to trawl through the terature, will a many man reearch aitant be needed in the future? _..... lack of originat_ the main criterion for pubcation in an academic i novelt generative AI cannot (yet?) match man originat the main opportunity for generative AI in the hort term, a ome of the experimental paper have demontrated, i a a reearch aitant for dek reearch. generative AI ytem are capable of reviewing, analying, and ummariing a ge amount of terature intantly (intantly from the point of view of the uer: there will have been a long training time before the ytem wa \u201c launched \u201d ). they therefore offer enormou potential for improving the effectivene and efficiency of dek reearch. /conference editor and reviewer may alo be able to ue generative AI to creen ubted manucript in term of the quaty of writing, formatting and referencing, contradictory or inappropriate tatement, and o on. further down the e, generative AI can be ued to analye qua\u00ad tative data, ubject to deag with everal of the iue indicated above, and that of the ecurity of repone that are often confidenti meta- analye and repcation tudie are two type of reearch project where generative AI \u2019 lack of originaty, tranparency and traceabity may be le problemati to concde thi contribution, we conider how to addre ome of the acro all ector, which may erve a a partial reearch . we beeve that the opportunitie hould be addreed with caution, and that the greatet potential for generative AI e in man- ai hybrid performance ( duan et , ). intellectual property (ip) and copyright protection. taking chat a an example, openai declare that it doe not take any reponibity for any infringement of intellectual property right that may occur a a reult of the ue of i thi ha eriou impcation on how reearcher can effectively avoid the potential ip infringement caued by the ue of cha a decribed above, there have been pubcation with a generative AI a a co-author, but thee are all clearly experiment can a generative AI ytem legitimately be credited a a co-author for academic pubcation if it i only a tool, not an independent reearcher? i the ue of generative AI different from uing oftware for tatitical analyi or tructural equation modelg? if o, how? _..... tranparency and explainabit_ quaty control of reearch output i of paramount importance in . generative AI function a a black box, meaning that it output cannot be fully crutid. thi k to the next two iu _..... dependence on technolog_ without undertan how the ytem generate it output, deciion, or prediction, le experienced reearcher cannot learn from the proc _..... lo of jo_ with a generative AI ytem to trawl through the terature, will a many man reearch aitant be needed in the future? _..... lack of originat_ the main criterion for pubcation in an academic i novelt generative AI cannot (yet?) match man originat the main opportunity for generative AI in the hort term, a ome of the experimental paper have demontrated, i a a reearch aitant for dek reearch. generative AI ytem are capable of reviewing, analying, and ummariing a ge amount of terature intantly (intantly from the point of view of the uer: there will have been a long training time before the ytem wa \u201c launched \u201d ). they therefore offer enormou potential for improving the effectivene and efficiency of dek reearch. /conference editor and reviewer may alo be able to ue generative AI to creen ubted manucript in term of the quaty of writing, formatting and referencing, contradictory or inappropriate tatement, and o on. further down the e, generative AI can be ued to analye qua\u00ad _.... how to make generative AI more reponible and ethical?._ there ha been growing effort, mainly academic, on developing and implementing reponible and ethical ai for the benefit of manit however, it eem there i a very low progre in making notable practical breakthrough o far. the riing ethical concern about generative AI i another wake up call for advancing reearch in thi are for example, ai face of overcoming bia \u201c that rk in the undercurrent of the internet and ociety more broadl \u201d ( , ). thi i particular acute for generative AI. we feel the mot important point i that ethical ai i not jut the reponibity of the ai developer. multiple takeholder can, and mut, make poitive contribution toward deigning and deploying more reponible and ethical ai. potician, manager, uer, cutomer and even the general pubc all have input to make from their different viewpoin crucially, thi require developer to be far more open (and perha more truthful \u2013 the lack of openne make it hard to judge) about what they are doing than ome of the indutry leader have been ne-chool/ htt://charteredaorg/dare-to-evolve-re-aeing-aement-in-bui\u00ad ee htt://wwtheguardian.com/u-new//jan//new-york-city- chool-ban-ai--chat#:~:text new%york%city%chool% = have,in%new%york \u2019 %pubc%chool ee htt://wwnaturcom/article/d \u2013 \u2013 -z o far. reearching thi require acc _.... how to minimie the rik and maximie the benefit of generative_ _ai though a man-centred ai approach?._ the potential miue or abue of generative AI provide another trong motivation for an initence on man-centred ai development and deployment ( duan, edward, & , ). the call for \u201c man in control \u201d or at leat \u201c man in the loop \u201d i becoming ever tronger and more convincin in the context of generative AI, reearcher hould explore how bet man and ai can work together to maximie the opportunitie and benefit of generative AI, a well a minimiing negative impact and rik. _.... how can generative AI be ued to augment man capabity?._ chat ha certainly impreed educator in term of it potential for enhancing academic and tudent \u2019 performance ( alhater, , ). it can be powerful in combination with man, augmenting their capabitie and enabg them to get work e fater and better ( , ro, & yee ). how generative AI can be developed and utied to augment man capacity deerve further invetigation acro all ector. a far a we are aware, there are a yet no generative AI ytem pecifically intended to make or upport deciion. thi may require the integration of the generative AI ytem with other i, and thi area ha een very ttle reearch o far. _.... how to enhance generative ai_ _ benefit through peronaation?._ currently openly acceible generative AI ytem uch a _\u2019_ chat erve a a common content generating too peronaation i an eential criterion for the ucceful adoption of ai tool ( duan et , ). many iue related to the and ation of generative AI can be more effectively addreed by cutomiing the ytem at individual and organiational leve however, peronaation require a ge amount of time, effort and reource from the end uer and the organiation concerned becaue they need provide reable data and fine-tune the model to agn with their need, vae, ethical principle, and relevant regulation, and do o ecurel thi i a potentially ge reearch are _.... how to deal with generative ai_ _\u2019_ _ technical ation?._ we ue chat a an example of generative AI \u2019 technical ation, a it i the one we have been able to ue for ourelv thee ation offer reearch opportuniti real time automatic data update - one of the major weaknee of - chat i it inabity to conider real-time event and information when generating outpu real-time content creation i till a challenging tak that require more advanced technologi deag with imperfect information - how ai can deal with imperfect - information i recogd a a ignificant challenge ( et , ). thi i particularly evident in the context of cha tranparency and explainabity - it i imperative that generative AI - hould be deigned and developed in a way that can be tranparent, explainable, and accountabl integration of generative AI with other ytem to augment it overall - ytem performance and capabit development of domain pecific generative AI ytem that can - minimie ethical concern, dicrimination, plagiarim, copyright infringement, et thi contribution ha offered a general overview on the ue of generative AI and a partial reearch . can generative AI help in thi reearch? that will be a reearch topic in itelf. chat gave u ome aitance in deci how to begin thi contribution, but except for the content of table , all the writing and thinking i our. recent breakthrough in generative AI, ke the rie of chat, have demontrated it exceptional performance of urpaing man being in information proceing and man ke content creation. conequently, there ha been a udden exploion of interet and pubcation on generative AI. depite the extenive report and dicuion about chat, there are numerou contradictory claim, unreatic expectation, and uperficial undertan, epecially in term of it capabitie, benefit, threat, and impac ome people view generative AI a jut a a powerful tool, but other beeve that it may be the beginning of an era of the creation of diruptive ai that will eventually det manity (dicuion on radio , jan ). overall, there are more quetion than anwer regar the rie of generative AI. reearcher will have to embrace the evolving a well a opportunitie preented to maximie the benefit and igate the potentially negative impact of generative AI on ociety, indutry, education and reearch. addreing the emerging and impact alo provide the opportunity to better prepare ourelve for the emergence of other powerful ai tool in the futur _... contribution _ _.... ue the ace and adroit framework to ae , opportunitie, and reearch related to chat - unil h_ when prof (eic, ijim) invited me to write a \u201c two page multi perpective editorial \u201d on chat, i initially aigned the tak to chat and reult were far below my own expectation given the hype that i had een on ocial medi much of what chat wrote wa common knowledge or verboity without a point of view or original thinkin it pointed to a a challenge to deploy for \u201c maller organiation or individual \u201c large computational requirement \u201d and for \u201d \u201c real- time appcation uch a . tendency to generate biaed or offenive text \u201d in addition, it acknowledged \u201d which can \u201c have negative \u201c impact on ociety \u201d uch a \u201c fake new or deepfake video, which can be ued to manipulate pubc opinion \u201d and \u201c the diplacement of man tranlator. \u201d yet, it pointed to opportunitie uch a \u201c create content uch a article, torie, and crip thi can be particularly ueful for content creator, uch a writer and it [to] improve language tranlation, which can facitate communication and undertan between \u2026 different cultur and then it went on to ugget further reearch opportunitie in the above area \u201d \u201c to undertand the potential impact of chat on ociety and develop trategie to igate any negative effec \u201d i draw here on my prior reearch and writing for aeing chat or technologie imilar to it and argue that a obering and more ueful view of chat will require conideration of the functionatie that it may enable: () the abity to ene the environment ( _ene_ ); () the abity to analye information ( _analye_ ); () the abity to collaborate with other within or acro firm ( _collaborate_ ); and () the abity to **table ** the adroit framework for aeing the economic vae of ai technologie uch a cha _framework_ _example_ _component_ add revenue ai ytem can enable firm to grow revenue by cale up their vome, making better pricing deciion, or through cutomization. differentiate ai may enable firm to offer peronaed product and ervice for differentiation. reduce cot ai may reduce cot through automation, and even emination of tak. optimie rik ai can help to manage rik, but it alo create new rik that are not yet fully undertood. managing uch rik will require careful thinking by pocymaker a well a manager. innovate ai can enable innovation and rapid new product developmen tranform ai can help to tranform ociety and ve by empowering marginaed grou and achieve utainable development goal if managed and regulated thoughtfully ( , ). automatically complete tak ( _execute_ ).ene, analye, collaborate, and execute ( ha et , ). the ace acronym capture the four functionatie (ene, analye, collaborate, and execute) and i a ueful tarting point for a critical aement of emerging technologie uch a chat and metaver applying the ace framework to chat, one may ak, will chat by itelf help to \u201c ene \u201d the environment beyond what i poible currently? can chat help to \" _analye\"_ data in more inightful way given the dimal record of imilarly hyped precriptive and cognitive analytic a dicovered? will chat enable new poibitie to _\"collaborate\"_ acro firm and vae-chain by itelf? \" capabitie to open up new poibitie for devering new efficiencie in manufacturing, and particularly ervice ector uch a and education that ome argue finally, will chat enable \" _execute_ are ubject to baumol \u2019 dieae ( baumol, )? i avoid the temptation to call chat a a \"diruptive innovation\" given my cepticim about the key premie of uch label ( , ; tel, ). intead, a theory of diruptive debottlenecking can be helpful here by aking if a new technology hel to avoid or overcome tradeoff that prior generation of technologie too for granted ( ha et , ). in the end, the buine or even ocietal vae of chat mut be aeed in term of it infence on ad revenue, differentiating, reducing cot, optimizing rik, innovating, and tranforming buine model and procee from a buine and ocietal perpective a i have argued elewhere, and hown in table ( ha, ; ha et , , ). the hype about ai i not new and goe back to her \u2019 prediction about ai back in ( ha et , ; , ). continuing advance in ai can bring change to how firm compete, yet uch change often take to materiae and not all change are poitiv firm mut develop their ai trategy a part of their overall it trategy, and competitive trategy with attention to governance and execution iue ( , ). it i time to reimagine and buine trategie at the corporate, competitive and functional level leveraging opportunitie that ai preent, rethink how they create vae uing ai for the buine and it cutomer, and on how they appropriate ome reaonable part of that vae among their key takeholder ( ha et , ). although there are good reaon to have a healthy cepticim for hype created by elf-erving technology entrepreneur or uninformed commentator, ome apect of ai do re fundamental philoophical quetion beyond buine procee to how uch technologie hape man identit exhorted u to carefully ae the role of technology in rethinking \"man \u2019 conception of hi own identity a a pecie \u2026 a new way of decribing hi place in the univere\" ( , , p. ) and we mut bear that in mind a we engage in our role a educator, and reearcher. _... contribution : chat: and opportunitie -_ __ the advent of chat (general pre-trained tranformer), a highly advanced ai claified a a large language model, ha caued a tir in the technology world. thi cutting-edge tool capable of generating convincing and intelgent-oun text in real time re concern about the authenticity of the generated text and the potential for the perpetuation of biae in it training dat academic takeholder inc editor, reearcher, and pubher are engaged in dicuion regar the appropriate utization of ai tool in the pubcation proce and the acceptabity of citing ai ytem a author ( ). depite thee , chat can potentially tranform how we approach education, buine, and reearch. tokel-walker, the primary focu of thi editorial i to emphaie the ignificant and opportunitie in thee three key are in the realm of **education** , converational ai platform ke chat and amea have the potential to revotio the traditional faculty- centred approach by provi / acce to virtual intructor with globally vadated knowledge, available in any language and format, and on any device ( wind, ). thi can tranform the role of the faculty into facitator of learning and implementation. thi hift toward a tudent-centred educational paradigm can prove to be highly benefici in **buinee** , converational ai can enhance creativity by provi fat, effective, and man-ke cutomer interaction. thi can lead to new and innovative way of cutomer engagement, automate routine tak, and provide vaable inight into cutomer behaviour and preference ( kietzmann et , ; , ). by freeing up time and reource, buinee can focu on more creative and trategic initiative uch a product development and marketing campaign ( pagani and pion, forthcoming ). compa uch a , airbnb, capital one, and oracle are alo uing converational ai for enhancing cutomer ervice, provi peronaed recommendation, aiting guet, offering peronaed banking ervice, and provi enterprie otion. ue converational ai in it cutomer ervice operation to automate routine tak and provide fat and effective interaction with uer ( , ). thi ha helped the bank reduce wait time and improve cutomer atifaction. ue converational ai in it aitant platform to provide uer with a natural and intuitive interface for acceing information and performing tak, inc data analyi, provi inight into uer behaviour and preference ( , ). the ue of converational ai offer a wide range of potential appcation allowing compa to improve cutomer experience, automate routine tak, gather cutomer inight, and drive innovation in their indutri depite the numerou benefit in variou appcation, it ge alo entail certain drawback that hould not be overlooked: . one of the major poed by chat i the _preence of deep_ _fake text_ , a demontrated by a recent tudy ( ele, ) that proved the abity of the ai ytem to write convincing fake reearch-paper abtrac to addre thi iue, there i a need for ongoing reearch to develop method for detecting deep fake tex moreover, addreing the bia preent in the model \u2019 training data i alo cruci for example, if the model i trained on a dataet that contain gender tereotype, it may generate text reinforcing thoe bia . another ignificant drawback of chat i the _propagation of_ _miinformation_ . thi can occur when the model i fed fale or milea information during it training, lea it to produce inaccurate or unreable repon thi can have ignificant conequence, epecially in appcation where the information provided by chat i reed upon, uch a in the context of making or information diemination. . another iue i the _lack of awarene of local rule and regulation_ . chat operate on a global cale, and it repone may not be agned with local law and regulation. thi can reult in the diemination of information that i legally or culturally inappropriat . finally, the training of chat on the vat amount of information available on the internet, which encompae both good and bad apect of man behaviour, can reult in the _propagation of inaccuracie_ . thi highght the importance of monitoring and verifying the information ued to train language model, a well a the output they produc by focuing on ongoing **reearch** to addre the potential rik, we can enure that thi technology \u2019 benefit are reazed and poitively impact ociet the key area of focu hould incde: (i) developing method for detecting and igating bia, (ii) improving deep fake text detection, (iii) invetigating appcation in education and acceibity, (iv) exploring the ue of chat in indutry, and (v) advancing our undertan of language and man communication. in concion, a the ue of generative AI ytem ke chat be\u00ad come increaingly prevalent in variou indutrie, it i imperative that employee and manager of the future (mof) acquire a range of man kill to work effectively and reponibly with thee ytem. thi impe not only to the educational paradigm but alo to the curricula that buine chool mut provid from critical thinking and teracy to creative problem-olving and ethical making, the kill needed to thrive in the ai-powered future are divere and multi-faceted. undertan how to manage data, apply interdicipary knowledge, and communicate effectively with technical and non-technical audience are eential kill in thi new er the acquiition of thee kill will enure that individual are well-equipped to navigate the rapidly-evolving landcape of ai, and can make informed and ethical deciion a they work with thee powerful ytem. _... contribution _ _.... moving from prediction to creativity: impcation of generative ai_ _on meaurement of ucce - ._ for the lat three , ml ha primarily focued on predicting and evaating ml model (, merhi, ). reearcher evaated algorithm through the efficacy of the model outpu they aeed a model \u2019 prediction baed on it abity to repcate pattern een and extend thoe to different people, etting, and context, examined through cro-vadation, holdout, or actual predictive performanc they evaated the efficacy of an algorithm with metric uch a preciion, recall, and the f-meaure, generally efficacy vaditie ( laren et , ). thee vaditie are till importan however, we need a new cla of vaditie for a new type of ai. buil on the ucce of predictive algorithm, recently, a new cla of \"generative AI\" ha emerged. thee algorithm produce work that we can only initially experience through the five man ene {to keep to the original and popular conception of the ene; \\roenbm, #}. recipe through tate and mell, muic through hearing, and art through igh only touch ha _o far_ been motly unaffected. generative text appcation ke chat are ened through ight and hearing and evaated againt the totaty of individual experience a their output are interpreted and undertood by the mind. we need new type of vaditie, which we ll call characteritic vaditi thee vaditie evaate the characteritic of technology artifact, whether their \u2019 part, deign, or outpu becaue output of generative artifact, uch a chat, have never exited before and have no exiting or (kely) future criterion for direct comparion, man will ae the artifact performance filtered through their ene and experienc beyond meaurement, thee generative re quetion about the of man creativit till, to anwer thi quetion, we mut ae **. .** a framework for evaating generative AI. how we will evaate the output of a generative ytem. we argue that there i a need for a framework (ee . ) for vadating claim about generative AI ytem. thi framework mut ditinguih between the goal of the artifact, uch a **claim of templating** and **claim of originaty** . mot man tak require template, allowing u to learn a pecific tyle of expreion. templating i about whether an output fit the expectation of a good exemplar of the type of templat originaty i whether man conider the content of the production unique, inightful, or expreive, whether templated or no **claim ** . **claim to templating** . the generative artifact produce out\u00ad put that fit a required templat uch template incde executive memo, tweet, blog pot, preentation, portfoo, cript, and prototyp thi claim will be evaated through characteritic vadit **claim ** . **claim to originaty** . the generative artifact produce original work not previouly een. work that i innovative and ignificantly depart from exiting concept and ide thi claim will be evaated through characteritic vadit further, the framework mut conider the environment in which the artifact output are employed. i the artifact flexible enough to produce relevant reult for both tweet and executive memo? doe it work for different context, uch a adminitrative memo in an automobile company and a non-profit uch a doctor without border? **claim ** . **claim to feaibity** . i the output practical and executable? i it calable to real-world appcation? i the work ocially reponible? thi claim will be evaated through characteritic vadit **claim ** . **claim to veratity** . can the output be ued in multiple way? can it be adapted to differing context? thi claim will be evaated through characteritic vadit the output may impact man oberver, uch a engaging emo\u00ad tion ke love for a peron who hared a generated poem and anger toward the government from a tweet criticizing the functioning of wahington, d the output, uch a a t of potential way to improve the bottom e of a bike-rental company, may be claimed a fulfilg the requirement of it uer. that i a otion for the problem for which the uer engaged the artifac finally, the output may have a direct impact on the world, which may itelf be meaured. for example, an artifact may directly contact all kely voter in a ditrict and argue on behalf of a pecific candidat we may meaure the outcome of thi action through the election outcome, the amount of potical giving from thoe contacted, or the individual vote for the candidat **claim ** . **claim to aethetic and emotion** . ome output, uch a text deigned to convince, muic, and painting, mut produce feeg and emotion in the recipien thi claim will be evaated through characteritic vadit **claim ** . **claim to a otion** . doe the generative artifact produce output that effectively addre a problem or challenge? man here evaate the output in term of it quat thi claim will be aeed through characteritic vadit **claim ** . **claim to impact** . the uer may engage the ai, or an inde\u00ad pendent implementation of the ai will be ued in a ettin uch a to generate a tweet or blog po it i _intantiated_ into a ytem. it, therefore, can create impact that may be meaured, uch a ke and retwee thi claim will be evaated through efficacy vadit a we further undertand how to evaate generative AI, we may, by extenion, tart to undertand man creativit a ai evolve in capabity _and_ creativity, hared reearcher undertan of evaative criteria will be critical to fully undertan chat and equivalent artifac advantag it would provide organiation inight into how it fit in their buine operation and how it may be further be adapted for a pecific buine tak. chat ha joined the bandwagon of new-age technologie ke metavere, which are revotionizing the workpace with new way of bb and bc cent interaction ( et , , ). with a milon uer in of the launch, the popularity of the chat can be gauged from the fact that it i running to it d fullet capacity mot of the time of the da _..... opportunitie and impac_ a technology-baed platform ke ocial media, earch engine optimization, and ervice- haring platform evolved in the early twenty-firt century, a few organiation and ector were in denial mod they did not explore it potential for their buine we aw uch compa loing the growth opportunity a they reaed too late it advantage and potential for their buin the ame appe to chat, which ha immene potential to impact buinee in highly productive and profitable wa the ector-wie key opportunitie for leveraging chat are a follow: education: chat would aid progreive new-age teaching- learning procee ke fpped claroom format and blended learnin the chat will provide baic rea material on the topic, and the tudent will dicu higher-level analytical and behavioural learning with the faculty in the cl thi would facitate fpped claroom learning, promoting an active learning proce ( o \u2019 flaherty & phil, ). thi would be a game changer in the education ector, where the focu can be hifted to practice-oriented training and apped fe kil chat will alo help minimie rote learning and do routine job ke coring and checking quizze, beide being a major input to the blen learning . : chat and platform ke would provide a boot to health initiativ it would give vaable input to medical and paramedic taff in the primary centre in remote area under the upervior of a trained phyician. the augmentation of chat in training may reduce the learning cycle time for the participan bfi: chat will replace routine (non-critical) job ke cutomer care, baic financial analyi, and text analytic for cutomer entiment in the banking, financial ervice, and inurance (bfi) ector. the audit and adviory ervice would get boot by accurate analyi, which would help banking executive to focu more on the inight and impcation piece of cent-interface proc hopitaty and tourim: the ervice provider in hopitaty and tourim can provide chat a a widget on their webit chat would act a a round-the-clock interactive interface for the cutomer for provi the travel, food, vehicle, and tourit location along with their ditanc it can enhance cutomer experience and minimie the manpower cot for ervice provider. ): chat would enhance the pace d by provi baic information on the topic in multiple dimenion. it can provide upport in the co and debugging of cod of r & it would alo reduce the probabity of dupcation of r & d activitie that have been pubcied. legal ervice: legal ervice highly depend on written law of the land and pat judgmen chat provide adviory and upport document by text-mining legal databae in an efficient manner. thi would enhance productivity multi-fold for individual, regulator, and law firm working in thi indutr _..... ._ ector ke education, , it, legal ervice, hopitaty and tourim are kely to be dirupted by cha depite the everal opportunitie brought by chat, there are real that need to be addreed by the takeholder. ome of the key incde: divide: thi ha been an iue ince the it revotion. thi i going to be further accentuated when the individual and firm with acce and expertie over chat would have an extra edge in available opportunitie and ervice dever how can chat ervice be provided where there i ttle or no internet acce? how can chat **table ** organiation inveting in chat and imilar platform. **name of the** **invetment** **expected outcome** **more detail** **organiation** **and trategy** ud bilon in openai; target ud bilon invetment in openai over the next few an undicloed amount of invetment by in chat type medical meta an undicloed amount of invetment by meta in blenderbot . _... contribution _ earch engine bing received only approximately ten percent of the total earch engine querie in the . uing chat in the bing earch engine will make it earch reult uperior and attract more uer, beide provi tough competition to . htt://ww ciencefocu.com/ future-technology/ -/ htt://wwcnb com//// -announce- multibilon-dollar- invetment-in- chat-maker- openai.html htt:// analyticindiama com/- introduce-chat- ke-model-for- / htt://ww techtimcom/ article// /- reearch-and- deepmind-launch-an- ai-baed-- language-modehtm htt://ai.facebook. com/blog/blender- bot--an-open-ource- -that-build- long-term-memory- and-earche-the- internet/ htt://wwwired. com/tory/ blenderbot-ai- -meta- interview/ , ai-baed platform funded by and deepmind, i an equivalent of chat in the medical domain. it anwer all medical querie baed on it large datae thi i beide \u2019 invetment in the nlp platform bidirectional encoder repreentation from tranformer (). blenderbot i a which wa developed by meta before chat wa launched. it i improving it baed on conumer feedback, with it latet verion being blenderbot . _.... chat: , opportunitie, impact and reearch -_ _, , fevzi okumu and mak._ chat optimally harnee the power of generative AI, large connected dataet, and how meaning i derived from guitic uing natural guitic programming (nlp) for engaging with a uer. chat, the launched by the cafornia-baed company openai, can be a ubtitute for earch engine for variou queri it provide pecific anwer to the querie, and the uer can ave preciou time a /he i directed to the relevant webite or the otion. earch engine ke (alphabet), , and bing () face an exitential crii from cha i collaborating with chat by inveting heavily in it parent company openai ( table ). thi may provide \u2019 bing an opportunity to increae it market hare in the earch engine ector and eventually become more popular than market leader . chat i perceived a a uper being in term of interaction and repone, if not uperior to man. organiation that can undertand and leverage the power of chat early would have a firt-mover minimie the exiting divide? thee and many more uch quetion, ke enuring a level-playing field for all communitie and ethical dimenion, need to be addreed a we go ahead. regulation: chat provide expert advice to uer and i gradually becoming an integral part of our ociet however, there have been cae of racial overtone, biaed anwer (tereotype) due to the exiting databae, and quetion on the accuracy of medical advice about cha it ha been banned by many organiation ke cience po univerity in france, pubc chool in , and tack overflow a they have yet to ure out how to regulate it for the larger well-being of their takeholder. there i a need to devie a global protocol for regulation of uch generative AI platform, a uch ervice are available acro many countri cultural enitivity: ke other ai tool, chat alo face chal\u00ad lenge with cultural enitivity and iue involving empath the iue ke comment on certain peronatie, regiou matter, and other decate iue need to be addreed, a each region may have it enitiviti unemployment and rekilg: highly populated countrie ke china, india, and brazil have izeable employable population. chat i kely to dirupt many indutrie and automate many routine and repetitive job (agarwal et , ). thi would lead to ma unemployment and rekilg requiremen cybercrime: cybercriminal, even with ed co and it kill, may become more aware of the hacking tool through cha regar creating appropriate control on chat about information diemination on creating phihing and malware oftware need to be addreed. integrity iue: the way to identify the actual criptwriter a compared to text created by chat have been eive till no the black box phenomenon, where we ometime do not undertand the logic behind a chat anwer, i intriguin the accountabity for certain anwer on chat, ke in or mentoring ervice, remain a challenge that need to be addreed. _..... reearch ._ generative AI ha gained the interet of many invetor and organiation. however, thee ai-related advancement, inc deep learning ke chat, will never replace man but would aid in making u more productive and help in achieving higher-order need. the bet reult would emerge with appropriate augmentation of technological development ke chat, metavere, d printing, blockchain, and internet of thing (iot) with man intelgenc t, the cholar working in thi domain may explore the following reearch quetion (): _rq:_ what hould be the globally accepted regulation tandard for platform ke chat and ? _rq:_ what hould be the \"fair price\" for chat ervice to individual and corporation? _rq:_ how can chat reduce the widening divide between peron having and thoe not having internet acce? _rq:_ what are the key marker to identify whether the text i generated by chat or written by a ving peron? _... contribution _ _.... chat: , opportunitie, impact and reearch -_ _._ chat i an advanced ai developed by openai. built on large language model it launched on and ha attracted unprecedented interet due to it abity to provide detailed, \u2018converational \u2019 repone to text prompt on a wide range of topic and in a variety of tyle, \u201c to anwer follow-up quetion, ad it ake, challenge incorrect premie, and reject inappropriate requet \u201d (htt://openai.com/blog/chat/). analyi by imilarweb reported in the guardian ugget chat reached milon uer in the firt . both and are rapidly developing competitor platform. other in thi vome are more quafied to elaborate on chat \u2019 wider capabitie and ation; the focu here i on it potential impcation for educational practic pubc interet in chat i imilarly both recent and vir trend for example (htt://trend..com/trend/explore? q chat), document inufficient data to regiter earche for the term = \u201c chat \u201d prior to \u2013 , riing to a maximum vae of in with full data at the time of writing (i., january- ). focuing only on the rather nebulou \u2018job & education \u2019 category (htt://trend.. com/trend/explore?cat & q chat) i reveag: two of the three = = top \u2018related topic \u2019 are \u201c plagiarim \u201d and \u201c content imilarity detection \u201d , while the econd and third mot frequent \u2018related querie \u2019 are \u201c chat plagiarim \u201d and \u201c plagiarim \u201d repectively (with \u201c chat checker \u201d fifth). thi reflect a (arguably _the_ ) major concern among educator, namely the downide of chat \u2019 potential for tudent to \u2018outource \u2019 tak, for example for-credit eay or peronal tatemen a number of impcation follo firt, reflecting an exiting theme in the terature on academic miconduct/integrity, educator will need to wretle further with aement deign. at leat ome exiting trategie to \u2018deign out plagiarim \u2019 ( oll, ), inc the ue of \u201c academic cutom writing ervice, eay bank or eay mill, private tutor or freelance worker \u201d ( rafa, undated : ) are kely to be le effective againt chat and it counterpar ome educator/intitution may retreat to the comfort of traditional time-ed, in-peron examination; other may intead conider innovative format of aement, particularly thoe \u2026 [requiring] creativity and \u201c \u2026 critical thinking \u201d ( zhai, : ). given the potential for chat to change the of office-baed job in the future, part of the change to aement i alo kely to involve an embrace of uch technologie ( jic, ), buil them into novel form of \u2018authentic aement \u2019 and facitating a new generation of \u2018 teracy \u2019 . in the hort-term however, ke covid, chat appear to have largely caught intitution off guard and crambg to adapt to a hifting reat one hitherto unmentioned corollary of chat \u2019 abity to author eay i it impact on part of the aement ecoytem. for example, it eem kely to prove highly diruptive to the buine model of contract aement-writing ervic currently free, even a paid-for chat i kely to prove cheaper, offer fater turnaround time and (a it learn) dever imilar quaty to exiting man ervic a econd i the impact on plagiarim detection ervice uch a . uch ervice are already gearing up to tackle the threat to academic integrity of chat ( , ). at the time of writing, a tudent-developed app \u2013 zero \u2013 can do o with a high degree of accuracy, ubject to acce to the underlying model ( wilkin, ). that may not continue to be the cae, at leat for ai provider dependent on commercial fun tream. either way, an \u2018arm race \u2019 eem almot inevitable, at leat in the abence of aement adaptation of the type decribed earer. much of the dicuion of chat focue on it negative potential in term of academic miconduc however, model of the type repreented by chat alo offer a number of afance that could ubtantially enhance educational practice and tudent learnin () for example, point to the abity of ai to provide a peronaed and interactive experience in relation to progre, upport, feedback and guidance, thereby enhancing learner autonomy, experience and engagemen indeed, one could eaily enviage a future in which marking of tudent aignment i primarily undertaken by ai-baed ytem, provi more detailed and fater feedback on both formative and ummative aement than academic taff. calabity i a key feature, given maification of higher education globally ( tight, ), an intereting quetion i the extent to which identical (or very imilar) prompt by a cohort of tudent dever ditinguihably different repon and where devering on promied turnaround time for marking in a drive for higher tudent atifaction metric ha exacerbated work intenification. how the academic time freed up i redeployed, i of coure, open to conjectur other benefit can eaily be identified. in a facinating article written in conjunction with chat, impcation for the future of education. along with peronaation of zhai () look, inter aa, at ai \u2019 learning, tutoring/mentoring and upport, and automation of variou routine adminitrative function, uch ytem are predicted to per the development of ai-powered educational game and imulation. ultimately, the novelty of chat render prediction a riky game, other than that uch technologie are here to tay; ai i a ge that cannot imply be put back in the bottl for educator, two apect are vit the firt i the need \u201c to reflect on our learning goal, outcome, and aement \u2026 we hould not let our exiting approache remain imply becaue thi i the way we have alway e them \u201d (, ). the econd i that uch a tak will be challenging given pedagogy i kely to be playing catch-up for ome time; (further) educational reearch in thi domain i imperative!. _. contribution _ _.. chat: , opportunitie, impact and reearch _ \u2013 _._ for reader of ijim, chat will have been a topic of coniderable dicuion, a well a conuming a lot of time experimenting with and thinking through it impcation and appcation. thi certainly decribe my experienc a with other, i have ued chat for everything from developing a new coure i will teach later , through to olving an obcure quetion relating to referencing oftwar it did a very good job indeed of provi me with a od foundation for the cour in moment it pun out a coure overview and et of objective a well a an oute of what would be covered through week of cla it generated a very good eay quetion and when aked wrote a pretty good word repon it gave me material to ue in de and alo a good rea t for the cour all of thi wa e in a matter of minute, mot of which wa me reviewing repone and deci what to ak nex fortunately, the coure i one mot buine chool globally offer, in buine ethic, ironicall chat would have truggled to generate a coure on a completely new topic that had never been offered anywhere befor it i know who have been worrying about what it mean for their job have been reeved to learn from chat that \u2018a an ai language model i \u2019 t have acce to real-time new updat my training data only goe up until , and i \u2019 t have the abity to acce current event \u2019 . the databae for chat i, therefore, not curren it i not preently kely that the information gathering and analyi involved in many role will be urpaed by generative AI. nor i it kely that the work e by man in uing the generated information will be ubumed. i know chool teacher who, at leat in my native new , have taken to chat ke a drug \u2013 apparently it ha gone vir teacher are marvelg and grateful for the way it i able to produce baic leon plan and cut through other adminitrative and compance work \u2013 paperwork that ha to be ubted to chool adminitrator and government agencie \u2013 that take coniderable time to collat thi i time teacher do not have in their buy teaching chedule, and i uually e in evening and weekend. chat i freeing them up to focu on what matter \u2013 working with our children and their paren for baic tak that an internet earch i not able to eaily help with, chat eem to fill a gap. my referencing oftware quetion, a genuine iue i wa facing where a tyle i required wa actually different from the named tyle in endnote, wa nicely olved by cha i d away getting nowhere then thought i would try cha to my reef, it olved my problem, telg me the name of the tyle i needed (a rarely ued variation, and pg in). thi i the power and opportunity it offer. with chat, openai ha upped the tak invetment in it have grown ignificantly, and the other big tech compa are working concertedly on their own offerin a indicated, the opportunitie and impact of generative AI are tremendou. for thoe of u involved in lea and teaching in univeritie, an acute awarene and embracing of the technologie will be importan our tudent will undoubtedly embrace cha through incorporating it in the cla and beyond, we mut equip them for the workforce of the futur the wort tudent, of coure, will ue the technology to chea unurpriingly, there i now an indutry of chat detection tool emerging, of variable reabit the bet tudent, along with their teacher, will find creative way of working with the technolog we need to think carefully about how to deign clae where tudent actively ue chat in a proce of co- curricular and learning deign. hould we, a many are uggeting, incorporate apect of oral examination into clae, or are there other way of enuring tudent are uing the technology honetly and productively? there i a potential revotion in term of cla deign and pedagogy on our doortep. we have ed time to think through our repone and mut learn from one another in the proc the reearch i wide ranging, encompaing every academic dicipe, with ignificant potential to make major gain. area uch a and education are obviou where reearch i needed into how the technology will be mot effectively ued, what the rik are and what it mean for training, work and ervice dever the ame with area uch a law where there i coniderable cope for aiting with procee of reearching and preparing ca there i going to be a ge demand for reearch into impcation for information gathering, making and ervice in government and pocy making a well a other area with pubc impact inc for buinee and hareholder. the reearch community mut engage with how chat i ued for reearch, what key quetion need probing, and what the longer-term impcation ar thi incde a ignificant new rik to all who ue the technology to ait their work \u2013 that of cyber tru in um, chat i a game-changer. the impact may not be a profound a ome predict, but it i clear that a it evolve and we adapt a uer, there will be ome ignificant hift reultin _... contribution _ _.... , opportunitie, and impact of chat in the it indutry - nihith pathak._ openai \u2019 - (generative pre-trained tranformer ) i a ground-breaking ai language model that ha captured the attention of the ai community and beyond. chat can afely be aumed a a viral enation that could completely change the way we do thing currentl it i probably one of the fater growing technologie that world ha ever adopted. it took . for netfx to have milon uer \u2019 adoption. facebook jut took month, potify took around month, iphone took for the ame adoption. you would be amazed to hear that it took jut day for world for reaching milon uer. for ome folk \u2013 it can be jut a writing aitant tool can provide uggetion or even write entire paragraph baed on what you \u2019 ve told i for other \u2013 it can be larget neural network trained with over bilon parameter making him one of the mot advanced language model in field of nlp. neverthele, with the adoption rate and for the firt time, it i afe to ay that world have ever een a technology that i going to reduce the gap between man and robot \u2019 machine, revotio the way how we interact with computer, making it eaier and more natural to communicate with them. probably ooner or later, one of the verion of chat would pa turing te _..... to the it indutr_ with it abity to perform a wide range of language tak, from text generation to quetion anwering, with man-ke proficiency, - repreent a major advance in the field of ai. chat i already creating a lot of buzz in the it indutry and it would not be aburd if i ay that chat i poied to have a ignificant impact on the way organiation do buin chat ha the potential to revotio the way organiation do buin however, a with any new technology, chat alo preent everal that mut be addreed before it can be fully adopted and utied in the it indutr firt and foremot \u2013 the bigget challenge for adopting chat i on threat to privacy and ecurit the utization of ml algorithm in chat reult in the proceing of a maive amount of data, making it a uceptible target for cyberattack. the enitive information proceed by chat can become vulnerable to theft or abue, poing ignificant privacy and ecurity threa the accuracy of chat algorithm i dependent on the data they are trained on, which can reult in the introduction of biae and dicrimination. thi can be particularly concerning when chat i utied in enitive domain uch a and civi a i write thi article, i alo keep on hearing about chat generating incorrect reul thi would certainly require a rigor check for enuring about correctne of dat depite the wift advancement of chat, a coniderable number of individual till lack an undertan of how it operate and are wary of relying on i thi rectance can retrict the potential impact of chat and impede it widepread adoption. the implementation and upkeep of chat technology can be financially taxing, requiring peciaed hardware and oftware a well a trained peronne thi can poe a challenge for maller organiation or thoe with ed budge _..... opportunitie in the it indutr_ chat ha the potential to tranform the way organiation operate and drive innovation. a every company i an it company now , chat i poied to tranform each and every domain. a i write currently, expert and reearcher are exploring it \u2019 potential to treame proce, improve cutomer engagement or drive innovation. at a high level, i am trying to ummarie ome of the quick win opportunitie for it indutr one of the firt opportunity for it indutry i to quickly automate repetitive tak and improve cutomer experienc chat can certainly be an efficient tool to free up man reource and puhing them to handle more complex queri mot of the it indutry compa are currently going through attrition of % of mor one of the foremot reaon i employee not getting the right work. automating repetitive tak would enure employee focue on trategic initiative, making their morale high thereby increaing productivity and retention. what make chat o unique and popular i that it jut give them one unique anwer. thi alo make chat to help organiation to make better deciion by really proving data driven actionable inigh now the current ation of chat i merely it \u2019 been trained only till data in o getting a real time inight would be challenging but thi doen \u2019 t top organiation to ue chat to ue it for deriving actionable inigh chat work a a companion tool for people working in it in\u00ad dutr for , being a developer, one can ue chat a a companion tool for developer to help me generating tet cae and tet data, debugging, and troublehooting my code and even to ome extent writing a code to do a particular tak. imilarly, chat can work a a companion tool for folk working in marketing, learning and development, hr, finance and many mor chat certainly ha immene potential to unearth new buine potential, generate new revenue tream and above all, be a driver for innovation. _..... impact of chat in the it indutr_ with the advent of chat, it indutry ha a lot of and opportunitie to explore but indutry i alo going to be largely affected with the way it operate currentl for , chat would certainly dirupt and automate lot of tak thereby, it would alo diplace lot of jo currently lot of it compa are generating revenue doing the monotonou buine and charging cent on revenue for cutomer upport by provi ndred of reourc chat would revotio the entire pectrum of cutomer experienc thi mean creating lot of job and tak but alo redefining exiting one epecially in cutomer experience to get tarted. lowly and gradually, chat ha potential to affect other indutry and vertica **i frequently emphaie that thoe individual and organiation** **that adopt technology and ai will eventually urpa thoe that do** **not** . therefore, compa and organiation need to incorporate chat in innovative way in their offering provi cutting edge benefit to organiation. a an author, i acknowledge that chat preent everal chal\u00ad lenge, but it potential benefit and impact on the it indutry are ignifican from improving cutomer ervice and making to enhancing productivity and generating new revenue, chat hold the promie of revotionizing the way we ve and work in the er and tak but alo redefining exiting one epecially in cutomer experience to get tarted. lowly and gradually, chat ha potential to affect other indutry and vertica **i frequently emphaie that thoe individual and organiation** **that adopt technology and ai will eventually urpa thoe that do** **not** . therefore, compa and organiation need to incorporate chat in innovative way in their offering provi cutting edge benefit to organiation. a an author, i acknowledge that chat preent everal chal\u00ad _... contribution _ _.... of chat - indranil bo_ it i well-known that ml baed ai ytem that are ued in knowledge work uffer from everal ( zhang et , ). chat a a form of converational ai, which ha caught the attention of milon around the world, uffer from it own hare of which can be dicued under the following four hea: _..... ecurity ._ while the power of chat to contruct proe that i ke that of man ha received the admiration of many, it i poible that thi ame abity can turn out to be extremely dangerou if it fall into wrong hand. chat ha been credited a being able to create very authentic phihing email that can re unupecting uer to cck on maciou k that can infect computer with malware ( kuleh, ). the powerful ml algorithm powering chat ha the advantage of earching through numerou phihing email that are available on the internet and undertan the key feature of thee email that make them uitable for ocial engineering attack. in the ame manner chat i alo able to write maciou code with minimum intruction from hacker who are not even technically avvy to produce uch cod it i even able to tranlate natural language to harmful cod another ecurity concern for chat i that it could be ued for maciou purpoe uch a prea rumour, propaganda a well a miinformation on the internet by generating beevable tex uch information pread on platform uch a ocial media can reult in devatating impact ( and , ). _..... technological_ _._ while chat howcae generative AI at it bet and i able to mimic man writing it i till not able to fully repcate the diplay of knowledge depth that i een in man. in fact, ome have remarked that the oftware i o impreive not becaue of it technical p but becaue of it abity to peruade a reader with the ue of word or phrae that appear to be authentic ( hendrik, ). educator worry about the uncertain future of written exam and ome ke have even blocked acce to chat on it network. however, chat i till not able to match the intellectual capabity of a man exam taker. in fact, in a recent trial run at to ee how the oftware fared in an exam for the mba tudent, it wa only able to pa with a c grade ( ortiz, a, b ). it i well-known that + thi oftware often \u201c halcinate \u201d and i not able to reably provide an accurate anwer to a quetion ( et , , ). thi make it rather unuitable for repeatable tak that any ai tool i uppoed to excel in. moreover, ince the chat work on the bai of a large corpu of training data, if that data itelf i biaed it i unable to recognize the error in the dat hence, it i beeved that while thi tool can gather a large number of idea in a hort period of time, it may not be able to identify which of which idea are the mot innovativ for a tak ke that one would need to depend on man intelgence (bouchery, ). moreover, ke any ai tool chat alo act ke a black box and doe not provide explanation about how it came up with a pecific otion ( , ). for example, it i unable to explain why it report . to the power of . a approximately equal to ., wherea the actual anwer i . ( azaria, ). _..... economic ._ although chat i currently made available a an open-ource tool by openai there i no reaon to think that it i available for fre ince a repone from chat uually i made up of or more word, it can be etimated that to make chat produce a repone openai i pen at leat cen it i conjectured that openai may be burning a tremendou amount of cah to the tune of u$ , per day a operating expene (indian expre, ). however, with the u$ bilon invetment by for chat and the fact that thi oftware run on azure, it i unclear what the true cot of running chat for openai i at thi tim although chat tarted a a freely available ervice, openai ha changed it coure of action and launched a ubcription-baed model for acceing chat that can \u201c chat with you, anwer follow-up quetion, and challenge incorrect aumption \u201d at the ubcription cot of u$ per month ( openai, ). alo, taking cue from openai, everal cammer and fraudter have put up fake advertiement on the internet for ubcription to chat at a ervice fee of u$ ( , ). it i reported that numerou people have lot money by falg a prey to thi extortion cheme and paying for the free baic ervice that i offered by openai. _..... ethical ._ the output that i generated by chat i often biaed due to the inaccurate training data that ha been ued to enrich it knowledg it i reported that when aked who could be a good cientit baed on race and gender, chat ha favoured people who are and male a cientit, howcaing a bia againt women and non-. moreover, everal quetion have been red about the unethical practice followed by openai in gathering training data uing low-paid worker in keny many of thee worker have often reported traumatic experience when entruted with the tak of labelg offenive content on the internet ( , ). another ethical challenge related to chat i whether it could be conidered a a co-author in cholarly work, when it ha contributed a ignificant part of the proe of the paper with the ue of it training dat a report by ha confirmed that ince the tool \u201c cannot take reponibity for the content and integrity of cientific paper \u201d it cannot be conidered to have made a cholarly contribution ( tokel-walker, ). finally, chat poe an ethical challenge of potential job lo for certain profeional uch a content writer a well a educator for no fault of their own ( zhai, ). _... contribution _ _.... on the and opportunitie of chat - jungla and_ _ven-v. rehm._ what i the challenge? anwer: undertan what chat truly i. the mot preing challenge for reearcher and practitioner ake in early ha been to undertand the novelty of cha a with every new technology that enter ociety, thi exercie i a crucial on after all, only if we truly undertand what i new can we unearth the potential vae added for organiation and our own v chat decribe itelf a \u201c a cutting-edge language model \u2026 , deigned to generate man-ke text baed on a vat amount of divere dat \u201d put differently, it ha the abity to generate paragraph that are eloquently worded baed on a hort text paage \u2014 be it a quetion or a tatemen for that to happen, at leat three thing mut be in plac firt, the ytem ha to be trained, through a proce of iterative reconuration, to identify word and to recog how and when word co-occur. econd, it mut be trained to propoe a et of word that hould be ued in the output baed on the input received. and lat, the ytem ha to be trained to arrange thoe uggeted word into grammatically correct entenc or, a chat tell u: \u201c when given a prompt or input text, chat ue thi knowledge to generate a continuation of the text that i coherent and contextually appropriat \u201d at it core, chat i t a generative textual engine, trained to rely on word and phrae ued previouly to decribe a phenomenon or even and unke our brain, it doe not rely on logic, emantic or epitemic model to develop elf- reflective poition. the word \u201c generative \u201d i cruci a a power generator mut have fuel to generate a current, chat i fuelled by the document it wa trained on. the training proce, upervied by man operator who retrict content and reinforce preferred output pattern, produce the parametrization of the neural network that define how \u201c the fuel \u201d tranform into actual textual outpu in that ene, chat \u2014 a with any other generative pre-trained tranformer (or in hort) \u2014 doe not a croover between \u2018regurgitate \u201c know \u201d anythin intead, it eloquently \u2018regurgenerate \u2019 and \u2018generate \u2019\u2014 what ha already been \u2019\u2014 written befor it uually doe o impreively!. the fuel analogy alo iltrate the of . although armed with impreive guitic capabitie, chat \u2019 abity to tructure and retructure repone, ue and create yllogim, or argue along different viewpoint i ed by it deign and the vome and choice of training materia what then i the opportunity? anwer: to experiment with thoe apect that are truly nove will come with the option to enhance \u2013 or \u201c fine-tune \u201d\u2013 pecific layer of the guitically pre-trained neural network. openai ha made thi option available on chat through it api, t provi the poibity to cutomie any model for a pecific domain, uch a the legal profeion that i drowning in contractual documen fine-tuned can then become product themelve and can be commerciaed or integrated with exiting ervic typical ue cae incde thoe that entail comparing text and completing entenc ummarizing big vome of text i another, particularly a a firt draft, o i anwering quetion in an elaborated and prolonged format, or pattern matching intruction, uch a repair, maintenance or chedug procedure, along with code excerp might be the intern we were alway looking for, taking off the majority of repetitive and grin work and leaving u with the intellectual bit that i more enjoyabl intead of combing through internet earch engine reult, for example, chat \u2019 ucceor will offer an eaily digetible ummar provided with text fragment, they can generate alternative formulation, ummarie, abtract, or nifty kedin pot and bio that are a tad more glorifying than we might compo ued a co bot, they can help with drafting baic programming modul a peronal trainer, they can deign workout plan, and a toryteller, they can concoct a new bedtime tory every nigh further opportunitie e in combining with analytic module, for example, for refined tatitical analye, uch a topic model in uch cae, more complex analye can be prepared and then offered through the tranformer interface in a manner that i acceible to a divere et of uer. t, the abity of it architecture king with real-time data will become increaingly importan how doe impact our dicipe? anwer: on many, many dimenion. from an im and i perpective, offer a novel interface to make extenive amount of information intuitively approachabl while ome faculty view chat a a threat, it i an even greater opportunit encouraging tudent to ue chat for ummarizing pecific topic area enable them to tir up dicuion more quickly, which in turn could help them buil up argumentative and critical-thinking competenci tudent mut learn how are different from other interface, uch a earch engine, and how different technique of training and fine-tuning can help to create cae-pecific otion. thi certainly will happen in indutry, and our tudent mut be prepared. reearcher mut look into biae introduced by the training data et and the training proc if the dataet i incomplete or biaed, o will be it outpu look at the allegation that quetion the ethic of openai \u2019 training proc oftware engineer, and thoe in charge of training \u2019 guitic capabitie, are the ethical arbiter of our too a chat warn u: \u201c while chat i a powerful tool, it hould be ued in conjunction with man overight and judgement to enure accuracy and ethi \u201d developing normative deign principle for converational agent are therefore of the eenc hifting curricula toward evaating the goodne of data and proce, along with putting tandard in place will be cruci the ame notion will alo have to apply to platform provider who mut obey etabhed guidee before their ervice offering can be integrated into exiting ytem. of coure, the generative abity of will alo find it way into our reearch tudie \u2013 writing abtract, ummarizing terature, generating draft for dicuion, or a part of the method apped. reearcher will have to be expcit about how factored into their tudie, and what mechanim were in place to enure accuracy and ethic while avoi bi , uch a thi one, will have to re-work their pocie accorly and take a tance on what i acceptable and what i no it will not be ea but a with everything in fe that i not eay, it often tart a poitive momentum and lead to novel inigh _... contribution _ _.... chat: technology development, impact and -_ __ __ _..... technology developmen_ a hown in . below the chat i an incremental innovation baed on ml (or o-called ai). the hitory of thi technology ha been very much one of technology puh \u2013 a technology which until recently ha not found it market or appcation. it technology adoption trajectory wa tarted from the cientific theory and logic reaoning propoed by the uk cientit in ( turing, ) in an idea and conceptuaation tage (from to ). . i compiled from a variety of different ource ( oppy & dowe, ; chat, ; oppy et , ; turning , turing tet, ). driven by pubc r & d fun, ml technology ha gone through experimental tage, facing both upward and downward developmental trend for more than four (from to ). the tage of appcation development wa not kicked off until when the turning tet wa uccefully paed for the hitorically firt time and alpha go ai won the world che pion in to attract ubtantial invetment from both private and pubc ector. the openai \u2019 laboratory wa then etabhed in , aiming at training a model called chat in a dialogue forma it i evolved from ingular text mining technology a in , in when inveted u$ bilon in openai, and in when announced actively collaborate with openai. we ee the miletone for commercial threhold breakthrough i .. a oon a . wa launched in . it immediately attracted one milon uer and received entiatic repone for potential commerciazation opportunity acro a range of ervice uch a cloud ervice, content creation, ad and promotion, data ervice, and conultin there are a number of feature which ditinguih chat from the model which came befor thee notable feature are the vome, parameter, architecture and training regime of the mode thee breakthrough eem to have unleahed a new era of nlp, one which harnee the heer recombinatorial power of vat ource of internet dat the firt feature noted above i imply the heer vome of raw data which i **. .** key event and developmental trajectory of chat. ued in the chat trainin previou reearcher have decribed the \"unreaonable effectivene of big data\" \u2013 and thi certainly appe her unexpectedly model uch a continue to grow in effectivene with the more data they are given. another factor ditinguihing i the heer vome of parameter which are ued in the learning of the mode deep learning algorithm are no longer new, but they allow learning to occur layer by layer and over iteration, thereby reducing the computational cot of training large mode thi mean that we have awaited the heer proceing power of modern computer before thee large language model could be fully reaed. man language i filled with pecific cae, pecific audience and pecific domain. learning one model to fit all thee cae ha proven fruitl while there may be an underlying logic or grammar to man peech, the pecific logic being ued can be ambiu even to man peaker. an additional factor which ditinguihing from previou model are the pecific architecture ued in training the mode model are context-pecific \u2013 they are able to allocate pecific part of the network given the context of the problem. the fourth and final feature that ditinguihe chat i the upervied learning ued in it creation. chat ha been trained by man rater to repond in a clear, interpretable and tructured fahion to the querie which it ha been provided. thi ha proven to be an effective co-teaming of man peaker with ml model, reulting in new product and ervice which neither man nor machine could have produced alon _..... technology impac_ one core concept behind informa\u00ad tion economic \u2013 perha the ingle core concept \u2013 i to conider: who know what when? and further how doe any given it change thi knowledge acro major phere of economic activity? information technologie pan a bewildering array of technologie and architectur their impact are far-reachin but the underlying caue of all thee impact i rooted in the capacity to control and acce information. therefore, thi can be a ueful and unifying framework. a we will demontrate below the concept behind the trategic ue of information i highly nuanced, and i not eaily characteried with a ingle meaur information economic preent both a ueful framework for gathering impact, a well a an opportunity to advance and extend a reearch . eminal reference to core idea in information economic incde thoe of eienhardt () , and laffont and martimort () . there are in fact at leat four different meaure of the trategic ue of information. one author decribe thee a meaure of information quaty ( ). when the quaty of information i degraded, we all loe ou but thoe trategic actor with acce ramuen, to better quaty are net beneficiari the firt meaure i certaint can we be ure that the quaty of our making ha improved after we have acceed thi new ource of information? unfortunately, chat ha probably reduced our overall certainty about the world. chat provide notoriouly confident \u2013 and yet incorrect \u2013 anwer to quetion. the net beneficiarie of chat \u2013 at leat on thi meaure \u2013 are thoe able to confirm and warrant the varied ource of information on which we all rel thi incde individual, inc member of the profeional cla known a \"ymboc analyt\" ( reich, ). but thi alo incde grou, uch a non-government organiation, academic and profeional organiation, and national bureaucracie taked for managing a range of function central to modern f the econd meaure i completen thi quetion ak u whether we can be really certain about who i upplying our information, and the purpoe, incentive or intent behind it production. here again chat ha probably diminihed the overall quaty of information available in the world. the piece in the local newpaper may have been produced by chat; that friendly repondent at the end of an internet k may ultimately be a bot; that cientific article ultimately written by machin the net beneficiarie of thi may be appcation developer who can foreee and deploy new appcation of thee technologi and of coure, chat and perha emerging competitor, who can cene the underlying mode the third meaure of information quaty i ymmetr what do you know that i do not? doe chat put u on an equal footing? chat i a great leveller. we may all have acce to a range of new capabitie, inc what may be the mot ete capabity of all \u2013 writing a cogent and well-formed ea much of thi levelg capabity i dependent upon the future intitutional tructure of acce to chat. chat i alo a powerful device for ignal jamming \u2013 it can take any particular perpective and multiply and repcate it acro channel both narrow and broad. acknowledge thee rik. in thi ene there are cot to be born for the widepread availabity of chat technologie; but they are higher for etabhed gatekeeper of new, media and opinion. chat output are pruned and cenored to not be hateful or objectionabl nonethele the net beneficiarie are thoe uch a openai who control the underlying algorithm of chat. the fourth and final meaure of information quaty i known a perfection. thi quaty ak whether we know where we are within any given proce or tranaction. ultimately technologie ke chat reduce the cot of tranacting within a modern econom tool uch a thee will help u by creating a range of ubiquitou peronal aitan thoe who can af widepread acce to computing reource, and the know-how to deploy thee agent on their behalf will certainly benefi the technology itelf may enable fifth or higher generation computer language where a range of programming functionaty can be decribed and then auto-filled on command. the programming and kill required to make effective agent eem to have been dramatically reduced, making at leat pecial purpoe ai much more readily available for a ma marke _..... management_ _._ having now entered the commerciazation tage, urgent problem need to be addreed for chat at all leve quetion at the micro-level incde managing the computational cot of training, but alo avoi fake information and other ditortionary ource of information which can corrupt the trainin thee micro-level iue alo require u to ak quetion about the boundarie between man and ai. hould we allow chat bot to maquerade a man, or hould chat continue to demontrate clear tell for unwary uer that a ml technology i behind the creen? there are quetion at the meo-level a wel ke chat, but alo tranformer model which are generating muic, video and graph are expected to be a ource of creative detruction. chat recombine divere ource reulting in quetion about intellectual property, and the appropriate recompene for creative worker. we may increaingly require detection tool to identify and root-out chat produced information and media, reulting in an arm-race of competing technolog ome commentator are concerned that a range of -collar job \u2013 inc copywriter, cutomer ervice agent, trancriptionit, it, econdary chool educator, and executive aitant \u2013 will find themelve out of a job with the advent of thi new technolog it i perha of ttle comfort to thoe newly unemployed that thee job have been increaingly hollowed out over or two generation. confronting the impact of chat may require that we reconider how ource of creative or emotional labour are currently being recompened in the econom it may alo require that we train a range of new profeional better able to co-team with thee new technologi thi i perha much more of an intitutional matter than olely a technological on there are alo macro-level iu thee macro-level quetion are largely one of ethi quetion of ethic require reearch and development taff, inc engineer and ocietie, but they alo require expert from the and maniti cholar uch a philoopher, guit, pocy analyt, and lawyer will increaingly need to be involved. thee cholar can help addre quetion uch a how to create new intitution to better govern thee technologie, thereby enuring they do not increae inequaty and injutic we mut ak whether thee technologie hould be ed in appcation and deployment, and if o how we can verify their abence from important ocietal aren _... contribution _ aignment, the firt approach might be to forbid the ue of cha the econd approach could entail detection and correction. a third emergent approach i to integrate the tool in intruction by aking tudent to generate content uing chat and then aking them to critique and improve thi tex each approach ha it own merit and rik. we mut examine and dicu different approache that make ene for different contex _..... moral and ethical quetion._ the ethical and reponible ue of ai i already a major iue that reearcher have been addrein ai ha been known to produce biaed object recognition. a an ai ytem learn from hitorical data, which may itelf reflect man biae, it can further crytae biaed outpu a the ue of chat become widepread, thee quetion become even more aen we need to examine which of the iue emanating from predictive ai might alo be relevant to generative AI? which new iue arie with large language modelg ai? it i etabhed that bia correlate with income and geography \u2013 could ai, therefore, further increae the ocial inequitie? of coure, we mut alo explore trategie for igating bi unfortunately, while incorporating ethic in educational program i viewed a an eential remedy, mot educational program tend to pay mere p ervice to thi conten further, claroom coverage of iue may not be a complete otion a ethic are enled with man experience and motivation, leaving room for violation. we mut explore igating meaure and otion to addre moral and ethical iue involved in generative AI. _..... ai for ocial good._ finally, cholar and practitioner mut explore way of uing generative AI for potential ocially beneficial purpo reearch related to other breakthrough technologie, inc ai, ha already begun to do thi. utizing exiting reearch theme and exten them to generative AI could help u arrive at fin otion to ocial ill uing generative AI. the opportunitie and related to the ue of ethical ai to benefit manity e at the interection of technology, ocial tructure, and man behaviour. thi call for more interdicipary reearch and ha impcation for educational program that are inter- and multi- dicipary in natur **. dicuion and impcation** _.. ynthei and identification of common theme_ in thi ection, we identify the main theme that have emerged from the contribution. _.... chat: a reearch - manju aj_ a chat ha taken the world by torm in , the dicuion related to it impcation eem ubiquitou. however, much of the dicuion in the academic circle ha been centred around the educational impcation of cha thi, of coure, i a major challeng at the ame time, i beeve that we need to conider broader and impcation of generative uch a chat, both poitive and negativ at the root of thee i the age-old technological deter\u00ad minim quetion \u2013 doe technology hape ocial change and determine our future? after all, who could have predicted how mobile technologie have haped man behaviour and attention? not many people can truly ay that they control their mobile device ge and behaviour; for mot, the device control their behaviour and attention intead. it i clear that we are at the precipice of another, perha even more ignificant ocial change phenomenon. an alternate perpective to technological determinim ugget that man have the power to control and teer the effect of new technologi perha both perpective can be in play to ome exten here, i would ke to reflect on a few quetion, , and conideration for i reearcher that may inform how we might examine, manage, and govern thi phenomenon. _..... the experience of writing and readin_ given that the mot common form of chat output i in the form of written text, we need to conider what kind of writing tak it might be uitable for and which of thee tak are acceptable for it ue? for intance, i it appropriate to ue it for copyediting, drafting an initial cut, or generating a finihed product? on the poitive ide, ome beeve that chat may become another acceptable writing tool (along the e of grammarly and pellcheck). if chat hould become an acceptable tool for compoition and writing, bigger quetion mut be addreed. what role would man creativity have in written word? it can be argued that the more compelg piece of writing are thoe that draw on man experience and though by autogenerating content, are we in danger of loing thi eential element of compelg writing, both fictional and non- fictional? further, what kind of writing i it mot appropriately ued for? the kind we are leat motivated to do? or might it be ued to create novel form beyond man abity? further, quetion of propriety, acceptable ue norm, and copyright quetion mut be red, dicued, and addreed. _..... accuracy and verification._ chat i a generative AI tool that utie language model that combine piece of information acro multiple ource and integrate it into readable written outpu eentially, it i a text predictor; it learn relationhi between piece of text and ue it to predict what hould come nex it then paraphrae thi content o it ound ke a new piece of writin thi proce reult in written piece that can eem credible, but they are not necearily baed on fac ai technology i not yet ready for generating reable and accurate reul for intance, a recent report uggeted that chat fabricated a citation for an author that it predicted hould be cited, but for an article did not in fact exi in the current tate of technology, thi indicate that verification would need to become an eential next tep for any generated written outpu thi could apply not only to tudent aignment but alo to reearch articl we need to conider if need to take on the tak of checking and verifying ubted articl hould they, intead, ak for attetation and extent of reance on chat for the article content? more importantly, we mut conider where the e for acceptable ue veru plagiarim would be and who would determine thi _..... repone to cha_ the approache to repond to the generative AI phenomenon can range from reitance and neutrazation, to integration. taking the example of claroom intruction and _... chat a a productivity enhancing tool_ chat i expected to have a potentially poitive effect on pro\u00ad ductivity (, contribution , , ). it can enable the automation of mundane or repetitive work and allow people to focu on creative and non-repetitive activitie (contribution , ). people can quickly acce information and knowledge through a impfied natural language- baed information earch proce uing chat (contribution , ). within the banking, financial ervice, and inurance ector, chat can help increae the accuracy in the audit and adviory ervice, which mean that banking executive can focu on more important tak (contribution ). it can alo be ued in text-mining of legal databae (contribution ), which i of particular benefit to financial intitution required to handle complex regulatory ytem ( khetri, a ). in the mid- , lon-baed think tank jwg etimated that over milon page of document related to financial regulation would be pubhed worldwide by ( alhelal, ) and chat may help extract related information quickl in education, chat can have a poitive impact on the produc\u00ad tivity of tudent a generative AI can make the proce of learning more efficient (contribution , ). moreover, academic author may develop background ection or firt draft of their paper by gathering information through chat (contribution , ). in many cae, better reult could be achieved with ai augmentation or augmented intelgence, which accor to i \u201c a man- centred partnerhip model of people and ai working together to enhance cognitive performance \u201d ( .com, ). thi i exactly what contribution ha dicued in the context of generative AI. _... academic ector kely to experience ome of the mot diruptive_ _effect_ teaching, learning, and academic reearch are kely to experience ome of the mot tranformative impact of chat and, perha unurpriingly, of the contribution in thi paper excively focued on thee (ection ., contribution through ). chat can be ued to improve learning opportunitie uch a by provi peronaed feedback to tudent (contribution ). ince chat can provide tudent with baic rea material on the dicuion topic, the in-cla tudent-teacher interaction can be ued for higher-level analytical and behavioural learning (contribution ). depite the ation of chat, uch a incomplete ynthei, miing information, or reference error, tudent may be able to quickly gain baic knowledge without much effort (contribution , ). everal major in the ue of chat may need to be overcom a ignificant iue concern the effect of generative AI uch a chat on aement and examination (contribution ). another daunting challenge e in controlg tudent \u2019 engagement in plagiarim and cheating on aignment, thee and diertation ince chat i a much more powerful tool compared to the exiting tool ued for imilar tak (, contribution , , , , ). for intance, teacher may not be able to recog aignment that are generated by chat, which i particularly challenging (contribution ). chat may have a negative impact on tudent \u2019 motivation to learn to write (contribution ) and on their independent thinking and language expreion kill (contribution , ). the impact of chat go beyond teaching and learning in . academic article have already been pubhed uing chat a a co-author (, , ). in thi regard, a concern that ha gained prominence i that ai cannot take reponibity for the content and t may not meet the criteria for authorhip (contribution ), and lead to devaed reearch pubcation (contribution ). _... concern about job loe_ reearcher have long dicued the poibity that machine and robot may replace ome of the function that man worker perform ( et , ; coomb et , ; et , b ). more recently, reearcher have expreed concern that can increaingly replace man worker ( bate, ). uch a concern in the context of generative AI ha alo been red (, contribution , , , , , ). thi iue i even more aent ince chat i more powerful and ophiticated than an average . indeed, when chat wa aked to t \u201c the diadvantage of generative AI \u201d , the t in chat \u2019 repone incded \u201c lo of job \u201d with the replacement of man worker (contribution ). chat might increae the automation potential of ome of the job that were thought to be le kely to be automated until a few ago. for intance, a mckiney article aerted that two categorie of job in particular had low automation potential: a) job related to managing and developing people, and b) job involving ). activitie uch a writing oftware code and promotional material of creating making, planning, or creative work ( et , menu were viewed a ome of the hardet activitie to automate ( et , ). thi aertion ha been challenged by chat. widepread concern have been red about the poibity that chat might replace a range of -collar job uch a copywriter, cutomer ervice agent, trancriptionit, it, and executive aitant (contribution ). _... the potential of miue and abue_ another common theme i that the ue of tool uch a chat by ome bad actor could lead to undeirable conequence uch a miue and abue of thee tool (contribution , , , ). for intance, chat can be ued by nefariou actor to create deepfake and fake new or engage in other type of miinformation and diinformation campaign (contribution ). everal contribution have alo expreed concern about the po\u00ad tential miue of thi tool by tudent (contribution , , ). for intance, ome tudent were reported to be engaged in cheating in exam by uing ai to create anwer to exam quetion. _... the potential of miue and abue_ another common theme i that the ue of tool uch a chat by ome bad actor could lead to undeirable conequence uch a miue and abue of thee tool (contribution , , , ). for intance, chat can be ued by nefariou actor to create deepfake and fake new or engage in other type of miinformation and diinformation campaign (contribution ). everal contribution have alo expreed concern about the po\u00ad _... major ation of generative AI tool_ the contribution have treed that in order to benefit from gener\u00ad ative ai uch a chat, their ation need to be undertood (contribution , , , , , , , , ). a noted in contribution , and , major concern of generative AI are related to tranparency and explainabity ince uch tool function a a black box and it i difficult to undertand the reaoning behind the generated tex another ation that mut be highghted i that chat cannot anwer quetion unle they are worded in a particular way (, contribution ). a further ation that wa mentioned i related to the lack of updated information. contribution and have noted that chat doe not incorporate real time data automaticall a tated in contribution , chat repone to quetion that require updated information wa that the \u2019 \u2019 \u201c training data only goe up until \u201d and t it doe not \u201c have the abity to acce current event \u201d . there are alo variou type of biae embedded into generative AI uch a chat (contribution ). _... major ation of generative AI tool_ the contribution have treed that in order to benefit from gener\u00ad _... the lack of regulatory template_ the generative AI indutry and market are undergoing major tech\u00ad nological upheav in ituation uch a thi, the intitutional context often fail to provide organiing template and model for action ( greenwood and hining, ). uch change may alo lead to confuion and uncertainty and produce an environment that lack norm, template, and model about appropriate trategie and tructure ( , ). to put thing in context, a lack of legilative and regulatory template to adequately deal with iue uch a privacy, ecurity, accountabity, copyright violation, diinformation, miinformation and other form of abue and miue ha been a theme of contribution in thi paper (contribution , , , ). when chat wa aked to t \u201c the diadvantage of generative AI \u201d by the author of contribution , chat \u2019 repone incded \u201c legal iue . contribution ha uggeted that government have not yet ured out how around ownerhip and copyright of content generated by ai \u201d to regulate the ue of tool uch a cha _... the lack of regulatory template_ the generative AI indutry and market are undergoing major tech\u00ad _.. future reearch direction_ throughout thi paper, the contributor have red many important quetion regar the opportunitie, , and impcation of generative AI uch a cha conodating thee together with the dicuion in the previou ection, we ummarie reearch quetion requiring exploration into three thematic area: knowledge, tranparency, and ethic; tranformation of organiation and ocietie; and teaching, learning, and cholarly reearch ( table ). reearch i required to explore how generative AI will affect knowledge acquiition and tranfer for individual, team, and organiation. invetigating way to enhance tranparency and reduce bia of technologie uch a chat i alo critic a noted above, regulation, moral guidee, and ethical code have not yet (fully) developed around generative AI uch a chat (, contribution , ). the preent work open new area of reearch in term of how uch intitution evolve over tim () propoed three intitutional **table ** a roadmap for future reearch. **thematic area** **reearch quetion** knowledge, tranparency, and - doe chat challenge aumption in ethic reearch and lead to a paradigm hift kely to be aociated with the introduction of diruptive appcation? - doe chat remove the tickine of knowledge tranfer between and acro individual, team, and organiation? - what role do ai-powered language tool uch a chat play in hybrid, ditributed knowledge intenive project? - what technique can be developed to enhance the tranparency of generative and ai model to facitate explainabity? - how can we ae the accuracy and verify text generated by chat? - what biae are introduced in chat by the training dataet and the training proce? - what ethical iue doe the ue of chat create acro indutrie and ector? - how can we apply and ae reponible and ethical pocie, practice and regulation in the diffuion of generative AI appcation? - how can framework (, ace, adroit) be ued to upport the ethical ue of chat and imilar technologie in and indutry? - what i the impact of conodating rik management framework and ethic perpective on chat adoption? tranformation of - how can ai-powered language tool facitate organiation and ocietie the tranformation of indutrie (, travel, tourim, finance, marketing)? - what new buine model can be created uing ai-powered language tool to create economic vae? - under what condition can ai play a role in generating new innovation? - what are the optimal way to combine man and ai agent in variou domain and tak to maximie the opportunitie and benefit while minimiing the negative impact? - what are the impcation of worker diplacement by generative AI, and who i reponible for igating thee and how? - what are the ue cae of ai-powered language tool uch a chat in term of enhancing our ve and interaction with people? - how can ai-powered language tool be ued to upport people with diabitie? - are there contextual condition (, organiational culture, national culture) that hape how individual and grou may ue ai- powered language tool? - how can we ue ai-powered language tool to addre global grand (, utainable development goal)? - what are the role of ocietal context and aociated ethical and moral judgement iue in haping the meaning and the outcome of chat? teaching, learning, and - what are the appropriate way and procee to cholarly reearch introduce tool uch a chat in curricum deign? - how do converational technologie make teaching and learning more effective? - can chat provide an enhanced tudent learning experience? if o, what i the view and experience of tudent? - how can chat and other ai-powered converational tool upport tudent with diabitie? - how can we ae the effectivene of chat in term of tudent performance and intention to ue? **table ** ( _continued_ ) **thematic area** **reearch quetion** - what are the long-term benefit and of uing chat in the context of teaching and learning? - what are the dark ide of chat in the context of teaching and learning? - how can chat be ued to develop critical thinking and problem-olving kill of tudent and reearcher? - how can the academic community broaden the dicuion and advance it undertan of chat and other ai-powered converational tool? - what i the long-term impact of chat on cholarly writing and reearch? - what i the role of man creativity when chat i ued in cholarly writing? - how can the academic community better repond to emerging, diruptive technologie that may poe threat to practice of teaching, learning, and reearch? pillar: (i) regulative; (ii) normative and (iii) cultural-cognitive, which relate to \u201c legally anctioned \u201d , \u201c morally governed \u201d and \u201c recognizable, taken-for-granted \u201d behaviour repectively ( et , , p. ). prior reearch ha alo uggeted that buil a regulative ytem (, regulation to govern chat) i the firt tage of intitution formation, followed by formation of normative intitution and then cognitive intitution ( , ). in future empirical work, cholar alo need to compare and contrat chat and other major innovation in term of the pattern of the evotion of variou type of intitution. another tream of much needed reearch i to explore the effect of tranformation of organiation and ocieti chat i kely to tranform everal corporate function. in marketing, for intance, generative AI can help improve cutomer interaction (contribution ), content marketing (contribution ), marketing communication (contribution ), and marketing campaign (contribution , ). in finance, chat can help financial ervice provider to treame and impfy financial ervice procee (contribution ) and provide better financial ervice (contribution ). we anticipate that the impact of chat will vary acro activitie and function. in thi regard, reearch need to examine the activitie and corporate function that are mot kely to be tranformed by generative AI uch a chat, and the conequence on worker, cutomer, and organiation. in addition, generative AI may have many ue cae acro grou and communitie, uch a upporting older or diabled peopl reearch i needed to examine appropriate deployment of uch technologie for different grou in ociet regar intitutional evotion around generative AI, ome have called for actor uch a academic pubher to act a an intitutional change agent and develop a code of practice (a kind of informal intitution) for the academic community to make reponible ue of chat (contribution ). in thi regard, a related future reearch topic could be how intitutional change agent theorize uch change (, , ). note that theorization - or the development and pecification of abtract categorie and the elaboration of chain of caue and effect - i an important proce through which intitutional change agent facitate the diffuion of new idea ( greenwood et , , p. ). theorization hel provide rationale for the practice to be adopted and t increae the chance of acceptance of the practice ( , ). two key element of theorization are framing and jutifyin framing focue on the need for change and jutification i vae of the propoed change for concerned actor ( greenwood et , ; maguire et , ). reearcher t could look at how variou intitutional change agent frame and jutify the need for change in intitution related to generative AI. finally, there are numerou fruitful avenue for reearch related to the appcation of generative AI uch a chat for teaching, learning, and reearch, from examining the role of thee technologie in curricum deign and upporting tudent \u2019 learning to fin where the balance e in enuring tudent and reearcher continue to produce creative and novel work. _.. reearch propoition_ immigration, and china \u2019 treatment of it uygr minority, the tool did o effectively ( klepper, ). uch miue of generative AI tool can be ued to manipulate citizen (contribution ). therefore, **p** . _compared to previou ai tool, chat i kely to emerge a a more_ _effective manipulation, miinformation and diinformation tool_ . _... chat_ _\u2019_ _ performance and the underlying data and training model_ the performance of chat in generating text may be coniderably infenced by the data and the training model ued (, contribution effective performance when aked to create diinformation related to covid- ( ). chat \u2019 klepper, ) could be attributed in part to the data repoitorie on which chat wa trained. it i poible that chat could have truggled with generating diinformation had it operation been baed on dataet that did not incde diinformation. ince chat wa baed on - that reed on bilon document of variou type in the pubc domain ( perrigo, ), which alo contain diinformation or report of diinformation, it can be conceded that data and training model infence chat performanc while there are ignificant in verifying information produced by chat ince it can generate different anwer for the ame quetion aked at different time, it would be helpful to find way to empirically tet chat performance when the data and training model var therefore, **p** . _data and training model underlying generative AI tool uch a_ _chat may infence it overall performanc_ _... chat_ _\u2019_ _ miue and abue when formal and informal rule are_ _lacking_ the ocial and intitutional context aociated with generative AI uch a chat could be a ignificant area for future reearch (contribution ). the nacent tage of formal and informal intitution urroun chat ha been a key theme in thi paper. chat \u2019 own repone to \u201c what are the diadvantage of generative AI? \u201d incded the lack of legal clarity related to ownerhip and copyright of content (contribution ). thi would create dipute regar the right to ue and profit from generated conten imilarly, the lack of informal intitution uch a ethical guidee could alo foter miue and abue (contribution ). the lack of well-developed formal and informal intitution around generative AI uch a chat could mean that violator are le kely to face anction and legally acceptable otion may not exit to penae tudent who engage in cheating or plagiarim (contribution ). pubher and univeritie have made foray into outing expected behaviour around chat for reearcher and individual (, contribution ). therefore, **p** . _the lack of formal and informal rule can increae the poibity of_ _abue and miue of generative AI tool uch_ a _cha_ _... chat a a ource of ethical dilemma_ due to it text generative capabitie, chat can be preferred and ued by takeholder in different indutri in the education ector, tudent have reportedly ued chat to generate anwer to exam quetion wherea intructor have ued chat to develop coure content (, contribution , , ). the need to identify the boundarie to guard againt chat miue and abue become important a chat find greater acceptance in different pher for intance, there may not be an effective way to reably detect if an eay ubted by a tudent or a paper ubted by a reearcher wa generated uing chat and whether it hould be conidered plagiarim (contribution , ). in uch cae, it may be ueful to determine who erve a gatekeeper or enforcer of chat ue and help reolve ethical iu therefore, **p** . _compared to prior technologie, generative AI tool uch a chat_ _are kely to poe greater ethical dilemma for everal takeholder._ in thi ection, we offer propoition baed on the variou perpec\u00ad tive on generative AI tool, their impact on a wide range of ocial, potical, organiational, and economic iue, and the and opportunitie provided by thee tool a dicued abov _... chat_ _\u2019_ _ potential to replace ome tak performed by knowledge_ _worker_ expert have called for reearch on the domain that are kely to be affected by generative AI tool uch a chat along with the diruption they caue (contribution ). one area kely to experience ignificant diruption i the domain of knowledge work. etimate ugget that % of a knowledge worker \u2019 time i pent on activitie that can be performed by other ( birkinhaw & cohen, ). the advancement in ai make it poible for tool uch a chat to handle uch tak (contribution ). for intance, chat can be ued to perform tructured and repetitive tak required by knowledge worker inc oftware developer and report writer (contribution ). generative AI tool uch a chat alo help provide man-ke cutomer interaction both efficiently and effectively (contribution ), which are epecially important in improving the quaty of cutomer ervice (contribution ). therefore, **p** . : generative AI tool uch a chat can be ued to replace ome of the tak performed by _knowledge_ worker. _... chat_ _\u2019_ _ ue in augmenting the capabitie of knowledge worker_ the augmentation of man intelgence i a key mechanim enabled by generative AI tool uch a chat (contribution , , , ). future reearch can invetigate the role of generative AI tool in enabg man augmentation (, contribution , , ). ince generative AI tool can enable man to olve complex problem by augmenting their intelgence and capabitie, they can complete work fater and achieve their goal more efficiently (contribution , ; ckder, ). for intance, in the context of in remote area, generative AI tool uch a chat can be ued to provide vaable input to medical worker that can enhance their performance (contribution ). overall, while have been ued for man tak augmentation for ome time, chat take thi to the next level by enabg functionatie that were not poible with previou generation of (contribution ). therefore, **p** . _generative ai tool uch a chat can boot productivity by aug\u00ad_ _menting the capabity_ of _knowledge worker._ _... chat a a powerful manipulation, miinformation, and_ _diinformation tool_ expert have emphaied the importance of reearch that identifie the bet way to minimie the negative impact of generative AI (, contribution ). in order to achieve thi, we firt need to undertand the potential negative effect of generative AI tool uch a cha in thi regard, a concern that ha received a great deal of attention i the potential miue or abue of generative AI. the worry i that negative effect of deepfake, fake new, or other type of diinformation and miinformation are ampfied by uch generative AI tool (contribution , ). generative AI tool uch a chat can make deception and manipulation more powerful and dangerou compared to exiting tool ( khetri, b ). for intance, when reearcher aked chat to create diinformation about a range of topic uch a vaccine, covid-, the january inurrection at the u.. capitol, _... chat_ _\u2019_ _ uperior, ubjective, and deceptive intelgence_ unke traditional tool that may rely on pattern matching and in\u00ad formation retrieval algorithm, generative AI tool uch a chat are driven by learning algorithm that build intelgenc due to it acce to a vat data trove, chat ha the capabity to grow in intelgence without cognitive that burden man although it i dependent on man uperviion to ome exten without uch intervention, chat can be equally good at generating both accurate and erroneou text (, contribution , , ) with no eay way to ae i left unchecked, chat may learn and build intelgence that may not be necearily objective or accurat for intance, chat reference non- exitent cientific work when generating text on particular topic, but it i not poible to inform chat of uch error. therefore, **p** . _compared to prior technologie, generative AI tool uch a chat_ _may poe uperior, ubjective, and deceptive intelgenc_ _... chat_ _\u2019_ _ potential for multiple role in buine and ociety_ differing from traditional tool that typically helped make ene of exiting data, generative AI tool uch a chat generate new dat combined with it capabity to undertand and generate natural language of man, chat may mimic man and play ignificant role in buine and ociety (, contribution , , , , ). the extent to which chat outperform man in creative thought would be an empirical quetion, but it i clear that it can yntheie diparate data, ummarie overall direction, and produce convincing decription (cf. .. on good data and training model). even if chat may not be accorded the tatu of a maker within buine and ociety, it eem entirely poible that it can trigger creative thought among man due it abity to preent yntheied ummarie from different perpective that man may not have conidered. perha, chat can play different role uch a pion or devil \u2019 advocate in ideation and creation proce therefore, **p** . _compared to prior technologie, generative AI tool uch a chat_ _with it natural language capabitie may play ignificant role in buine_ _and ociet_ _... chat_ _\u2019_ _ niche a uperman or peciaed agent_ ince a ignificant goal of ai i to mimic man intelgence, the quetion of chat \u2019 niche in ociety need eriou conideration. ai model can poe general or peciaed intelgence (, contribution ), both of which are common in our ocieti man poe general intelgence on a wide array of topic a well a peciaed intelgence in narrow domain or dicip in term of implementation, the difference between general and peciaed ai ytem could be the data and training method ued (cf. ..). however, what hould be the niche for chat? i it good to have a uperman know-it-all ytem or one that i more retricted with peciaed knowledge? man tend to attach ome importance to pecialty (, we do not ak for medical advice from inurance agent) a do organization that have inveted in peciaation (, the variou functional department). even in peciaed niche, training chat baed on data may not be complete ince training databae typically incde outcome and te but not the ved experience of peciaed man. therefore, muic) and reulted in new way (, artit can releae muic for ale one). kewie, chat promie converational natural language dialogue baed on upervied pre-training on a cloed albeit large datae a ha been already dicued, chat ha been apped for both poitive (, help olve a problem) and negative (, cheat on an exam) purpo there i a clear need to engage in reponible ue of chat ince it poee unique capabitie that can be exploited or miued. therefore, **p** . _imilar to variou tool in hitory, generative AI tool uch a_ _chat promie unique capabitie but require reponible u_ _.. impcation for practice and pocy_ **p** . _generative ai tool uch a chat have the potential to be uper\u00ad_ _man or peciaed agent a dictated by data and training method._ _... chat_ _\u2019_ _ capabitie and reponible ue_ technologie have traditionally addreed problem and provided otion; generative AI tool uch a chat are no exception. however, technologie have been ubjected to both intended and unintended ue (, ocial media hel connection but alo facitate cyberbullying) and reulted in both intended and unintended conequence (, nurturing friendhi but alo envy and bitterne). technologie have often dirupted exiting way (, ipod dirupted how we conumed chat wa etimated to have milon active uer in january , le than after the app wa launched. accor to the wi multinational invetment bank and financial ervice company ub, chat i the fatet-growing conumer appcation in hitory ( , ). the rapid diffuion of generative AI tool uch a chat ha important impcation and conequence for practice and poc in order to drive competitive advantage, it i imperative for orga\u00ad niation to ue chat a a productivity-enhancing too in many cae, organiational change are needed to reae uch benefi for intance, in the context of the education ector, emphai hould be placed on updating the curricula in chool and univeritie to accommodate generative AI tool uch a chat in the claroom (contribution , hrivatava, ). in ght of the many benefit of thi tool noted above, academic intitution hould reviit the complete ban on the ue of cha it i important for intructor to engage deeply in chat o that the tool can be incorporated into intructional activitie to benefit tudent (contribution ). it i alo crucial to develop criteria to evaate output of generative AI o that uch tool can be employed to benefit organiation (contribution ). in addition, organiation may be required to combat reitance to change from employee (contribution , ). at the ame time, it i alo important to take meaure to minimie the potential negative impact of uch too for intance, cybercriminal can ue chat a a hacking tool (contribution ), which can victimie compani they hould t develop new capabitie to ht new type of cybercrime generated and facitated by uch too in order to optimie the benefit of generative AI uch a chat, it i important to take into account the variou ation of thi tool uch a the lack of originaty (contribution ) and vaguene of the output (contribution ). a further ation, a mentioned earer, i that it wa trained on a databae before , which mean that it cannot earch the internet to provide up-to-date information about a topi in many cae, convincing anwer have been frutratingly difficult to find with chat (contribution ). it i important to educate tudent and other uer about thee and other ation of chat o that they can benefit from thi tranformative innovation. it i alo crucial to make ure that tudent have a clear undertan of how generative AI tool differ from other tool uch a earch engine (contribution ). legal ytem to govern ai are not well developed in mot countri in general, in nacent and formative ector uch a generative AI, there i a lack of developed network of regulatory agencie ( dholakia, khetri & ). a a conequence, there i no tipulated template developed for organiing intitutional actor \u2019 behaviour ( greenwood & hining, ). indutry bodie and trade and profeional aociation can provide ome degree of intitutional co-ordination in order to overcome the exiting regulatory ga ( khetri, ). thee entitie can help create norm, informal rule, and code of behaviour and penae noncompance with ocial and economic anction ( , ). the importance of developing a code of practice for the academic community that offer pecific guidee for uing chat in academic pubhing i crucial (contribution ). at the national level, it i the reponibity of government to enact regulation that balance the need of protecting uer from abue and miue of generative AI while enuring that technology compa are not dicouraged from inveting in thi tranformative innovation. for intance, it i reported that the eu \u2019 ai act ha targeted \u201c high rik \u201d appcation of ai, which mean that ai mut comply with the trictet requiremen a new propoal categorie ai ytem generating complex text uch a a \u201c high rik \u201d . ome analyt are concerned that uch regulation may dicourage the generation and ue of uch ytem ( grady, ). it i critical to ae the ocietal vae of chat, which i epecially important for enacting new regulation to govern uch tool (contribution ). moreover, given the global of tool uch a chat (contribution ), it i important for different juridiction to work together to develop more globally accepted regulation (contribution ). ai practitioner need to engage in eriou intropection regar the capabity and reabity of generative AI tool uch a cha ince chat ree on everal moving part inc data, training model, and man input, there are opportunitie to inject bia into the ytem. a the ytem mature over time through reinforcement learning, text generation may alo be biaed or favour pecific perpective (, getan, ; , ; , \u00a8 ). different way to afeguard againt uch biae hould be determined and apped by ai practitioner; faig thi, ai tool uch a chat may be conidered upec for intance, ai trainer provi man feedback during the training phae need to take neutral and objectively true poition uch that the reinforcement learning are not unnecearily biaed. openai \u2019 own decription of chat acknowledge certain type of biae in training data uch a trainer preferring longer anwer that look more comprehenive ( openai, a ). further, openai claim to ue moderation pocie around diallowed ue of chat that could alo be biaed even after conce retriction to curb activitie that are illegal, high-rik, or abuive ( openai, , b ). ai practitioner need to devie method to evaate the extent to which new text generated by chat i biaed. uer in any profeion (, tudent, oftware developer) have the opportunity to apply chat in both poitive and negative wa it i helpful to recog that chat may not alway be accurate or know all the relevant anwer needed by uer. openai \u2019 own decription of the tool acknowledge that chat may \u201c gue what the uer intended \u201d rather than aking clarifying quetion to clear ambiguitie and alo generate \u201c plauible-oun but incorrect or nonenical anwer \u201d - both of which re quetion about credibity ( openai, a ). more importantly, openai agree that there i \u201c currently no ource of truth \u201d for the chat model, which i a ignificant elf-indictment of the tool \u2019 capabitie ( openai, a ). would that top uer from accepting chat generated text a the final anwer? would that reduce uer \u2019 reance on chat for information and knowledge? would that be enough for uer to dicontinue ue of chat? the potential for manipulation, miinformation, and diinformation are high with new chat text not baed on reponible u to ome extent, the burden of appropriate chat ue reide with the uer a with any other technolog **. conc thought** chat undoubtedly i among the mot tranformative ai tool developed in recent . it preent ignificant opportunitie a well a for organiation, ocietie, and individua generative AI can offer a major boot to productivity in variou etting, but uch tool alo preent a number of practical, ethical, moral, and pocy . for intance, the with chat in the education ector are well recogd due to the lack of well-developed guidee and ethical code around generative AI. a critical practical challenge that regulator face i that they cannot penae perpetrator with legal anction when uch tool are deberately miued or abued. t, it i imperative to enact new law to govern thee too their global mean that international coordination i alo needed to maximie the benefit of tool uch a cha **reference** abdulquadri, , , , p. (). tranformation in financial ervice proviion: a nigerian perpective to the adoption of . _ of enterpriing communitie: people and place in the global economy, _ (), \u2013 . adam, ), \"how ai earch unlock long tail reult\", available at: htt://ww .com/blog/ai/how-ai-earch-unlock-long-tail-reult/ . adam, (). dal : \u2018clearly ai i going to win. how people are going to adjut i a facinating problem \u2019 . _the guardian_ . htt://wwtheguardian.com/boo k//may//dal--clearly-ai-i-going-to-win-how-people-are-goin g-to-adjut-i-a-facinating-problem-thinking-fat-and-low . , (). : the ultimate brain. authorea preprin , f. (). the bigget problem with chat right no _trend_ (available one) htt://wwtrend.com/computing/how-to-ue-open ai-chat-text-generation-/ . , , gan, , & goldfarb, (). chat and how ai dirupt indutri _ buine review_ . , - . retrieved from htt://hbr.org ///chat-and-how-ai-dirupt-indutrie . ajzen, i. (). the theory of planned behaviour: reaction and reflection. _ychology_ _&-/bref)_ _health, _ (), \u2013 . akter, ., , , ajib, ., , k., , , d \u2019 ambra, , & hen, (). algorithmic bia in data-driven innovation in the age of ai. _international_ _ of information management, _ , article . , ., alkharui, h., & al imai, (). predicting engh tet anxiety: how memorization and critical thinking function? _theory and practice in language tudie,_ __ (), . alekander, i. (). partner of man: a reatic aement of the role of robot in the foreeeable futur in _ of information technology, _ pp. \u2013 ). age pubcation ltd, . , , \"index your world, put it in motion with our powerful earch api\", available at: htt://ww.com/product/earch-and-dicovery/hoted- earch-api/ . algorithmwatch.org, , , ai ethic guidee global inventor retrieved from htt://algorithmwatch.org/en/ai-ethic-guidee-global-inventory/ . alhelal, h. () rome wan \u2019 t built in . january , htt://wwigmaratin com/knowledge-center/rome-want-built-in-a-day . alhater, m., , exploring the role of artificial intelgence in enhancing academic performance: a cae tudy of chat ( , ). avaiable at rn. retrieved from htt://rn.com/abtract = or / ./rn.. alhater, m., , exploring the role of artificial intelgence in enhancing academic performance: a cae tudy of chat ( , ). available at rn: htt://rn.com/abtract = or .. alveon, m., & , (). generating reearch quetion through problematization. _ review, _ (), \u2013 . araujo, (). ving up to the hype: the infence of anthropomorphic deign cue and communicative agency framing on converational agent and company perception. _computer in man behavior, _ , \u2013 . ahok, m., madan, r., joha, , & ivarajah, u. (). ethical framework for artificial intelgence and technologi __ _management, _ , article . atta, , d. . (). automated eay coring with e-rater v.. __ _of technology, learning, and aement, _ (), \u2013 . ayd\u0131n, o., & aarlan, (). openai chat generated terature review: \u00a8-/bref) twin in . in (ed.), \u00a8-/bref) _emerging computer technologie, _ pp. \u2013 ). izmir akademi dernegi \u02d9-/bref) . azaria, . chat ge and ation. hal open cience hal-. baird, , & maruping, (). the next generation of reearch on i ue: a theoretical framework of delegation to and from agentic i artifac _mi ,_ __ () . balakrihnan, , (). role of cognitive aborption in buil uer trut and experienc _ychology_ _&-/bref)_ _marketing, _ (), \u2013 . balakrihnan, , abed, . ., & jone, p. (). the role of meta-utaut factor, perceived anthropomorphim, perceived intelgence, and ocial elf-efficacy in -baed ervice? _technological forecating and ocial change, _ , article . balakrihnan, , nwoba, , & nguyen, n. (). emerging-market conumer \u2019 interaction with banking . _telematic and informatic, _ , article . () \u2019 erica to bilon cent interaction, now nearly . milon per day retrieved on the web at: htt://newroom. bankofamericcom/content/newroom/pre-releae///bank-of-america-- erica-to--bilon-cent-interaction\u2013now-.html%% . bakerville, r., & myer, ). fahion wave in information ytem reearch and practic _mi , _ , \u2013 . ba, d. (). openai o good it can fool man, even when it \u2019 wron _ com_ . htt://wwbloombercom/new/article/--/openai-c hatbot-o-good-it-can-fool-man-even-when-it--wrong . bate, ). health care are here to help. _ieee pule_ (vome: )(iue: ). may-june page(): - . baumol, (). _the cot dieae: why computer get cheaper and health care_ _doen_ _\u2019-/bref)_ _t_ . yale univerity pre, . belk, r. (). ethical iue in ervice robotic and artificial intelgenc _the ervice_ _indutrie , _ ( \u2013 ), \u2013 . bur, (). the e-rater coring engine: automated eay coring with natural language procein in hermi, & bur (ed.), _automated eay coring:_ _a cro-dicipary perpective_ (pp. \u2013 ). hilldale, nj: aociate, in bellegarda, r. (). tatitical language model adaptation: review and perpectiv _peech communication, _ (), \u2013 . bender, m., & k, , , cmbing toward n: on meaning, form, and undertan in the age of dat paper preented at the procee of the th meeting of the aociation for computational guiti cadmu (). identifying and igating rik of ai in authentic aement practic available at: htt://wwcadmu.io/blog/identifying-and-igating-rik-of-ai- in-authentic-aement-practice . cain, . (). \u201c\u2019 thi ong uck \u2019 : cave repond to chat ong written in tyle of cave \u201d . _the guardian_ . january , htt://wwtheguardian.com/m uic//jan//thi-ong-uck--cave-repond-to-chat-ong-written-in -tyle-of--cave . bender, , , , mcmillan-major, , & hchell, . (). on the danger of tochatic parrot: can language model be too big?. _procee of the acm_ _conference on fairne, accountabity, and tranparency, canada_ (pp. \u2013 ). , ny: acm, . bengio, ducharme, , p. (). a neural probabitic language mode _advance in neural information proceing ytem, _ , \u2013 (available at) htt://p roceedinneuri.cc/paper//file/fcabfbddafac-pape r.pdf . bern, , le, , (, ) how compa are uing tech to give employee more autonom retrieved from htt://hbr.org/// how-compa-are-uing-tech-to-give-employee-more-autonomy . bhattacharyya, . (), \"commercial appcation of - that are already ve\", available at: htt://analyticindiamacom/commercial-appcation-of--- that-are-already-ve/ . , n. (). it doen \u2019 t matter. _ buine review, _ (), \u2013 . oll, (). _a handbook for deterring plagiarim in higher education (/e)_ . : centre for taff and learning development, brooke univerity, . catelvecchi, d. (). are chat and alphacode going to replace programmer? __ . htt://doi.org/./d---z centre for teaching and learnin (). _four leon from chat: and_ _opportunitie for educator_ . univerity of , (available) htt://wwctox.a /four-leon-from-chat--and-opportunitie-for-educator . chakravarti, (). even chat beeve it can never replace man writer a it lack creativity, emotion and enitivit _india _ . retrieved january , , from htt://wwindiin/technology/feature/tory/even-chat-beeve -it-can-never-replace-man-writer-a-it-lack-creativity-emotion-and-enitivit y---- . birkinhaw, , & cohen, (). make time for work that matter. _ buine_ _review, _ (), \u2013 . biwa, . (). chat and the future of medical writin _radiology_ (available at) chandra, ., hh, , & rivatava, . (). to be or not to be \u2026 man? theorizing the role of man-ke competencie in converational artificial intelgence agen _ of management information ytem, _ (), \u2013 . chat, , january , in . htt://en..org/wiki/chat . , , (). the global divide \u2013 within and between countri _it_ _&-/bref)_ _ociety, _ (), \u2013 . , jenen, ., al, , , ., & , (). artificial intelgence (ai) tudent aitant in the claroom: deigning to upport tudent ucc retrieved january , , from _information ytem frontier_ . htt://doi.org/ ./--- . , m., hall, , mayhew, h., & ingla, (, ). the tate of ai in \u2014 and in revie retrieved , , from htt:// tinyurcom/jd . , m., ro, , generative AI i here: how tool ke chat could change your buin retrieved from htt://wwmckinecom/capabitie/ quantumblack/our-inight/generative-ai-i-here-how-tool-ke-chat-could- change-your-buine?tcr = acdccccafcfaf & cid = other- eml-alt-mip-mck & hlkid = eaebbfafa & hctky = & hdpid = eaefd- \u2013 --eafaea#/ . , m., ro, , ). generative AI i here: how tool ke chat could change your buin _quantum black ai by mckiney_ (available one) htt ://wwmckinecom/capabitie/quantumblac/our-inight/generative-ai-i-he re-how-tool-ke-chat-could-change-your-buine . htt://purnorg/doi/full/./radio . bjork, (). chat threaten language diverit more need to be e to protect our difference in the age of ai, available at htt://theconveration.com/chat- threaten-language-diverity-more-need-to-be-e-to-protect-our-difference-in- the-age-of-ai- . blackman, r. (, ). a practical guide to buil ethical ai. retrieved from htt://hbr.org///a-practical-guide-to-buil-ethical-ai . bock, , wolter, ., & ferrell, o. (). artificial intelgence: dirupting what we know about ervic _ of ervice marketing, _ (), \u2013 . b ohm, ., ington, m., corneu, n., , , greenwood, m., haan, \u00a8]() haw, d. (). ethic at the centre of global and local : thought on the future of buine ethi _ of buine ethic, _ (), \u2013 . bommarito ii, , d.). take the bar exam. : .. bonfim, d., , , & ongena, . (). \u201c orry, we \u2019 re cloed \u201d bank branch cloure, loan pricing, and information aymmetri _review of finance, _ (), \u2013 . , p., barkin, , (). _intelgent automation: welcome to the world of_ _hyperautomation_ . world cientific book, . boman, (, ). top iue in artificial intelgenc retrieved from htt://wwweforum.org////top--ethical-iue-in-artificial- intelgence/ . bouchery, ., , v., piller, f.p. (). augmenting man innovation team with artificial intelgence: exploring tranformer-baed language mode htt:// doi.org/./jpim.. , m., manyika, , & miremadi, ). wher machine could replace man \u2014 and where they can \u2019 t (yet). mckiney . _ mckiney com_ coch, , r. (). overcoming reitance to chang _man relation, _ (), \u2013 . cockburn, i.m., henderon, r., & tern, . (). the impact of artificial intelgence on innovation: an exploratory analyi. chap. in the economic of artificial intelgence, edited by ak , gan and goldfar brachten, f., er, , & tiegtz, . (). the acceptance of in an enterprie context \u2013 a urvey tud _ management,_ __ , article . breen, p. (). \u2019 t fear chat: education will alway trump technolog available at htt://wwtimehighereducation.com/blog/t-fear-chat-education-will- alway-trump-technology acceed ... coomb, , tacey, p., kawalek, p., imeonova, , becker, , bergener, , h. (). what i it about manity that we can \u2019 t give away to intelgent machine? a european perpectiv __ _management, _ , article . breidbach, f., & mago, p. (). accountable algorithm? the ethical impcation of data-driven buine mode _ of ervice management, _ (), \u2013 . , r. , & , r. (). information technology implementation reearch: a technological diffuion approach. _management cience, _ (), \u2013 . cotton, d.r., cotton, p., & hipway, r. (). chatting and cheatin enuring academic integrity in the era of cha edarix.or (). artificial intelgence and education: a critical view through the len of man right, democracy and the rule of la available at htt://rm. coint/artificial-intelgence-and-education-a-critical-view-through-the-len/ abd acceed ... cranefield, , winikoff, m., chiu , , doyle, , & richter, (). partnering with ai: the cae of productivity aitan _ of the al ociety of new_ __ . htt://doi.org/./.. crewell, , , , dumou, v., arulan, k., en, , & bharath, (). generative adverarial network: an overvie _ieee ignal proceing_ _magazine, _ (), \u2013 . , n. , entance, ., crick, , & mphrey, . (). retart: the reurgence of computer cience in uk choo _acm tranaction on computing education, _ (), \u2013 . buha, d. (). technology in tourim-from information communication technologie to etourim and tourim toward ambient intelgence tourim: a perpective articl _tourim review, _ (), \u2013 . buha, d., & moldavka, i. (). voice aitant in hopitaty: uing artificial intelgence for cutomer ervic _ of hopitaty and tourim technology, _ (), \u2013 . buha, d., & inarta (). real-time co-creation and nowne ervice: leon from tourim and hopitat _ of travel_ _&-/bref)_ _tourim marketing, _ (), \u2013 . buha, d., , k. (). bridging marketing theory and big data analytic: the taxonomy of marketing attribution. _ management,_ __ , article . crick, (). covid- and education: a catalyt for change? _itnow, _ (), \u2013 . buha, d., harwood, , , v., viga, , bela, ., & hofacker, (). technological diruption in ervice: leon from tourim and hopitat __ _of ervice management, _ (), \u2013 . buha, d., parra-l opez, , & ez-gonzalez, (). infence of young \u00b4 conumer \u2019 external and internal variable on their eloyalty to tourim it __ _of detination marketing_ _management_ , . htt://doi.org/./ jdmm.. czarnecka, , & , (). how are we tempted into debt? emotional appeal in loan advertiement in uk newpaper. _international of bank marketing, _ (), \u2013 . dattathrani, ., & de \u2019 , r. (). the concept of agency in the era of artificial intelgence: dimenion and degre _information ytem frontier_ , \u2013 . , et (, ). explainable ai, retrieved from htt:// alocietorg/topic-pocy/project/explainable-ai/ . burger, , kanbach, , & krau, . (). the role of narciim in entrepreneurial activity: a ytematic terature revie _ of enterpriing communitie: people_ _and place in the global economy_ . htt://doi.org/./jec--- davenport, h., & ronanki, r. (). artificial intelgence for the real world. __ _buine review, _ (), \u2013 . de cremer, d., , (, march ). ai hould augment man intelgence, not replace i retrieved from htt://hbr.org///ai-hould-augment- man-intelgence-not-replace-it . , , & (). the benefit and of chat: an overvie _frontier in computing and intelgent ytem, _ (), \u2013 . diederich, ., brendel, , , ., & kolbe, ). on the deign of and interaction with converational agent: an organizing and aeing review of man-computer interaction reearch. _ of the aociation for information_ _ytem, _ (), \u2013 . floridi, , ). -: it , cope, , and conequenc _mind and machine, _ , \u2013 . floridi, , & trait, (). ethical foreight analyi: what it i and why it i needed? _mind_ _machine_ . htt://doi.org/./---y diener, f., & pa \u02c7-/bref) \u02c7-/bref) cek, ). tranformation in banking: a managerial perpective on barrier to chang _utainabity, _ (), \u2013 . dowg, m., & cey, (). chat for (finance) reearch: the bananarama conjectur _finance reearch letter_ , article (in pr available at) htt ://wwciencedireccom/cience/article/pii/ . , , , , & aleh, (). getting ai to cal _ buine_ _review_ . may-june . retrieved from htt://hbr.org///getting-ai-t o-cale . , , f.m., markov, n.., dyer, , rameh, ., , & pearon, (). comparing cientific abtract generated by chat to original abtract uing an artificial intelgence output detector, plagiarim detector, and bded man reviewer. , .... doi:./ .... , , hype cycle for artificial intelgence (ai). htt://ww.com/en/ article/what--new-in-artificial-intelgence-from-the---hype-cycle (acceed th feb, ). .com (). top trend on the hype cycle for artificial intelgence, , htt://ww.com/erwith/top-trend-on-the-- hype-cycle-for-artificial-intelgence-/ . getan, h. (). chat could be ued for good, but ke many other ai model, it \u2019 rife with racit and dicriminatory bi _inider_ . htt://wwinider.com/chat- i-ke-many-other-ai-model-rife-with-bia-- acceed: feb . drucker, ). knowledge-worker productivity: the bigget challeng _cafornia_ _management review, _ (), \u2013 . duan, edward, ., & , (). artificial intelgence for deciion making in the era of big data \u2013 evotion, and reearch . _ management, _ , \u2013 . duan, , xu, m., & mathew, (). upporting deciion making proce with \u201c ideal \u201d oftware agent \u2013 what do buine executive want? _expert ytem with_ _appcation, _ (), \u2013 . , , ghe, , , m., , ., giannaki, m., al- debei, , & wamba, . f. (). metavere beyond the hype: multidicipary perpective on emerging , opportunitie, and for reearch, practice and poc _ management, _ , article . htt://doi.org/./ijinfomg. , , ghe, , , k., , m., , p., abba, , ). cmate change and cop: are technologie and information management part of the problem or the otion? an editorial reflection and call to action. _ management, _ , article . ghazwani, ., van ech, p., cui, & gala, p. (). artificial intelgence, financial anxiety and cahier-le checkout: a audi arabian perpectiv _international _ _of bank marketing, _ (), \u2013 . , , & bhattacherjee, (). whom are we informing? iue and recommendation for mi reearch from an informing cience perpectiv _mi_ _, _ , \u2013 . , , ghe, , cheung, m., conboy, k., duan, dubey, r., & viga, (c). how to develop a quaty reearch article and avoid a dek rejection. _ management, _ , article . , , ghe, , , alalwan, , ahn, . , balakrihnan, , & wirtz, (d). metavere marketing: how the metavere will hape the future of conumer reearch and practic _ychology_ _marketing_ . htt://doi.org/./ jbur. , , imagilova, , ghe, d. , carlon, , fieri, r., jacobon, , & (a). etting the future of and ocial media marketing reearch: perpective and reearch propoition. __ _management, _ , article . goertzel, , & pennachin, (). _artificial general intelgence_ . ber: pringer- verlag, . gold, i., & papert, . (). artificial intelgence, language, and the tudy of knowledg _cognitive cience, _ (), \u2013 . () aitant, retrieved on the web at htt://newroom. bankofamericcom/content/newroom/pre-releae///bank-of-america-- erica-to--bilon-cent-interaction\u2013now-.html%% . , tntr om, o., \u00a8 & grimon, . (). can - write an academic paper on itelf, with minimal man input? retrieved from one: htt://hcience/ hal-v . grady, p. (). chat amendment how the eu i regulating by outrage, , htt://datainnovation.org///chat-amendment-how-the- eu-i-regulating-by-outrage/ . , , ghe, , imagilova, , aart, , coomb, , crick, , & wilam, (b). artificial intelgence (ai): multidicipary perpective on emerging , opportunitie, and for reearch, practice and poc _ management, _ , article . greenwood, r., & hining, r. (). \u201c undertan trategic change: the contribution of archetype \u201d . _ , _ , \u2013 . , , ghe, d. , coomb, , contantiou, i., duan, edward, ., & upadhyay, n. (). impact of covid- pandemic on information management reearch and practice: tranforming education, work and f _international of_ _information management, _ , article . greenwood, r., & hining, r. (). undertan radical organizational change: bringing together the old and the new intitutionam. _, _ , \u2013 . greenwood, r., uddaby, r., & hining, r. (). theorizing change: the role of profeional aociation in the tranformation of intitutionazed field. _academy of_ _management, _ (), \u2013 . guan, , , x. , , , r. , he, , x., , may, toward a deep and unified undertan of deep neural model in nlp. in international conference on machine learning (pp. \u2013 ). pmlr, available at . pre/v/guana/guanpdf . , , zhang, x., , , jiang, m., , , ,. & (). how cloe i chat to man expert? comparion corpu, evaation, and detection. __ _preprint :._ . , , watell, d., laumer, ., henriken, h. , myer, , bunker, d., & rivatava, . (). reearch on information ytem faire and uccee: tatu update and future direction. _information ytem frontier, _ (), \u2013 . eienhardt, k. ). agency theory: an aement and revie _academy of_ _management review, _ , \u2013 . eot, , january ). generative AI chat i going to be everywhere once the api portal get oon opened, tupefying ai ethic and ai la retrieved from htt://wwforbcom/ite/lanceeot////generative-ai-chat- i-going-to-be-everywhere-once-the-api-portal-get-oon-opened-tupefying-ai- ethic-and-ai-law/ . , ., & (). upporting incive learning uing ? a - led interview tud _ of information ytem education, _ (), \u2013 . , i. (). \" \u2019 t worry about ai becoming entien do worry about it fin new way to dicriminate againt people\". _inider_ . htt://wwbuineini der.com/ai-dicrimination-bia-wore-problem-than-entience-- acceed: feb . haque, m.u., dharmadaa, i., worna, , rajapake, r.n., & ahmad, h. (). i think thi i the mot diruptive technology\": exploring entiment of chat early adopter uing twitter dat :.. heikkil \u00a8 a, ). how openai i trying to make chat afer and le biaed. _oz_ _technology review_ . htt://wwtechnologyreviecom/////ho w-openai-i-trying-to-make-chat-afer-and-le-biaed/ acceed: feb . hendrik, , , i get your excitement about chat, but \u2026 available one: htt://wwhendrik-erde/pot/i-get-your-excitement-about-chat-but . henrickon ) chatting with the dead: the hermeneutic of thanabot, media, culture & ociety \u2013 . hiatt, (). ad: a model for change in buine, government, and our community: proci. , (). a meta-analyi of the effect of calculator on tudent \u2019 achievement and attitude level in precollege mathematic cla _ for_ _reearch in mathematic education, _ (), \u2013 . , (). why i chat making wave in the ai market? retrieved from htt://ww.com/en/newroom/pre-releae/ \u2013 --why-i- chat-making-wave-in-the-ai-market . ele, h. (). abtract written by chat fool cientit, - _, _ (). htt://doi.org/./d--- . elevier, , the ue of ai and ai-aited technologie in cientific writin htt:// wwelevier.com/about/pocie/pubhing-ethic (acceed th feb, ). expert group on ai, , , ethic guidee for trutworthy ai. retrieved from htt://-trategeeuropeu/en/brary/ethic-guidee- trutworthy-ai . , ). way to ue chat in your claroom. available at htt:// wwedweek.org/teaching-learning/opinion--way-to-ue-chat-in-your- claroom// acceed ... financial time, , mirror pubher explore uing chat to help write local ne htt://wwfcom/content/fae-da \u2013 c-eed-fdf (acceed th feb, ). firat, ). how chat can tranform autodidactic experience and open education?.htt://doi.org/./of.io/gem (lat acceed //). hill, , , , & farrera, i. (). real converation with artificial intelgence: a comparion between man \u2013 man one converation and man \u2013 converation. in _computer in man behavior, _ pp. \u2013 ). elevier, . fire, m., & guetrin, (). over-optimization of academic pubhing metric: oberving goodhart \u2019 law in action. _gigacience, _ (), \u2013 . hirchheim, r., klein, , k. (). exploring the intellectual tructure of information ytem development: a ocial action theoretic analyi. _accounting,_ _management and information technologie, _ , \u2013 . floridi, ). etabhing the rule for buil trutworthy ai. _ machine_ _intelgence, _ (), \u2013 . floridi, et (). aipeople \u2019 ethical framework for a good ai ociety: opportunitie, rik, principle, and recommendation. retrieved from htt:// wweimd.eu/wp-content/upload///aipeople \u2019 -ethical-framework-for- a-good-ai-ocietpdf. , (). intitutional evotion and change: environmentam and the u chemical indutr _ , _ (), \u2013 . ) chat et record for fatet-growing uer bae - analyt note, , htt://wwreuter.com/technology/chat-et-record-fatet-growing-uer- bae-analyt-note- \u2013 -/ . , , & rut, r. (). artificial intelgence in ervic _ of ervice_ _reearch, _ (), \u2013 . , p.-., , , , ., , d., & , ). toward neural phrae- baed machine tranlation. in international conference on learning repreentation. , n.d. (, january ). chat and the future of writin _hindutan time_ . retrieved january , , from htt://wwhindutantimcom/book/ chat-and-the-future-of-writing-.html . kung, h., cheatham, , (). performance of chat on umle: potential for ai-aited medical education uing large language mode _._ _pubhed one , _ , \u2013 . kuhwaha, k., & , k. (). markbot \u2013 a language model-driven for interactive marketing in pot-modern world. retrieved january , , from _information ytem frontier_ . htt://doi.org/./---y . , r. (). _educational technology: a primer for the t century_ . pringer , . ghe, (), \"chat: everything you need to know about openai \u2019 - tool\", available at: htt://wwciencefocu.com/future-technology/-/ . htt://newroom.taylorandfrancigroup.com/taylor-franci-clarifie-the-reponible- ue-of-ai-tool-in-academic-content-creation/ . (). aitant cae tudi available at: htt://ww.com/ product/-aitant/cae-tudie . international conference on machine learning, , icml call for paper. htt://icmcc/conference//callforpaper (acceed th feb, ). laffont, -, & martimort, d. (). _the theory of incentive: the principal-agent model_ . pre, . laren, , kyanenko, r., mueller, , torey, v. , , d., paron, , & hovorka, d. . (). _vadity in deign cience reearch, deigning for _ _tranformation_ . co-creating ervice with citizen and indutry: _th international_ _conference on deign cience reearch in information ytem and technology_ , derit , kritianand, norway, \u2013 , , procee (pp. \u2013 ). pringer,. co-creating ervice with citizen and indutry: _th international_ _conference on deign cience reearch in information ytem and technology_ , derit , kritianand, norway, \u2013 , , procee . laumer, ., , , eckhardt, , & weitzel, (). work routine a an object of reitance during information ytem implementation: theoretical foundation and empirical evidenc _european of information ytem, _ (), \u2013 . htt://doi.org/./eji.. lecun, bengio, & hinton, (). deep learnin _, _ (), \u2013 . , , laren, k., & abbai, (). theoryon: a deign framework and ytem for unlocking behavioral knowledge through ontology learnin _mi , _ () . , d., & haye, n. (). on ociomaterial imbrication: what plagiarim detection ytem reveal and why it matter. _information and organization, _ (), \u2013 . iron, , & crick, (). cyberecurity in the claroom: impcation for emerging pocy, pedagogy and practic _higher education in a pot-covid world:_ _new approache and technologie for teaching and learning_ . emerald pubhing, . janen, m., & hoven, (). big and open ked data (bold) in government: a challenge to tranparency and privacy? _government information_ _, _ (), \u2013 . jena, k., & goyal, . (). emotional intelgence and employee innovation: equential mediating effect of peron-group fit and adaptive performanc _european_ _review of apped ychology, _ (), article . jenen, m. , er, m., wright, r. , , (). training to igate phihing attack uing mindfulne techniqu _ of management information_ _ytem, _ (), \u2013 . jic (). doe chat mean the end of the eay a an aement tool? available at: htt://wwjiauk/new/doe-chat-mean-the-end-of-the-eay-a-an- aement-tool--jan- (lat acceed //). , , a, k., talwal, , & h, v. (). federated learning: , method, and future direction. _ieee ignal proceing magazine, _ (), \u2013 . ckder, (). man-computer ymbioi. _ire tranaction on man factor in_ _electronic_ , (), \u2013 . kabudi, , pappa, i., & olen, (). ai-enabled adaptive learning ytem: a ytematic mapping of the teratur _computer and education: artificial intelgence,_ __ , article . , -. (elaine), & , ). examining the ychological proce of developing conumer-brand relationhi through trategic ue of ocial media brand . _computer in man behavior, _ , article . , d. (). _thinking, fat and low_ . new york: farrar, trau and giroux, . , k. (). bio inpired computing \u2013 a review of algorithm and cope of appcation. _expert ytem with appcation, _ , \u2013 . , , , chat might change advertiing \u2014 but it won \u2019 t revotionize i [one] available at: htt://wwmarketingdivcom/new/chat-ai- marketing-advertiing-revotionize// [acceed ]. , (). the efficacy of chat: i it time for brarian to go home? _cholarly kit_ (available at) htt://cholarlykipneorg////g uet-pot-the-efficacy-of-chat-i-it-time-for-the-brarian-to-go-home/ . u, ., yang, , zhang, , xiang , u, , , ., & zhang, (). one mental health ervice in china during the covid- outbreak. _the ychiatry, _ (), e \u2013 e . lokman, ., & ameedeen, m. (). modern ytem: a technical revie _procee of the future technologie conference_ (pp. \u2013 ). : pringer,. htt://doi.org/./----_ (). cey, , & dowg, ). chat: our tudy how ai can produce academic paper good enough for - jut a ome ban i _the converation_ (available at) htt://theconveration.com/chat-our-tudy-how-ai-can-produce-academ ic-paper-good-enough-for--jut-a-ome-ban-it- . kietzmann, , pa, , & treen, r. (). \u201c artificial intelgence in advertiing: how marketer can leverage artificial intelgence along the conumer journe _ of advertiing reearch, _ (), \u2013 . ckin, r., holme, , griffith, , (). _intelgence unleahed: an_ _argument for ai in education_ . pearon lon, . ma, , & un, (). machine learning and ai in marketing \u2013 connecting computing power to man inigh _international of reearch in marketing, _ (), \u2013 . , , & denni, r. (). ay who? the effect of preentation format and ource rating on fake new in ocial medi _mi , _ (), \u2013 . , h., hin, , yang, h., & , h. (). a tudy of ai a an aitant tool for chool engh curricum. _korean aociation for learner-centered_ _curricum and intruction, _ (), \u2013 . htt://doi.org/./ jlcci.... , ., , & boon, (). ixty of reearch on technology and man reource management: looking back and looking forward. _man reource_ _management, _ (), \u2013 . king, , & baatartogtokh, (). how ueful i the theory of diruptive innovation? available at - theory-of-diruptive-innovation/ . loan management review, fall, \u2013 . maguire, ., , , & lawrence, (). intitutional entrepreneurhip in emerging field: hiv/aid treatment advocacy in canad _,_ __ (), \u2013 . , , , adler, p. m., & onnert, (). the aociation of precollege ue of calculator with tudent performance in college calcu. _educational tudie in_ _mathematic, _ (), \u2013 . kiinger, h. , chmidt, , & ttenlocher, d. (). _the age of ai: and our man_ _future_ . uk, . klepper, d. (), it turn out that chat i really good at creating one propaganda: \u2018i think what \u2019 clear i that in the wrong hand there \u2019 going to be a lot of troubl , htt://fortuncom////chat-open-ai-one- propaganda/ . , , machado, i., & nambian, . (). type of innovation and artificial intelgence: a ytematic quantitative terature review and reearch . _ of buine reearch, _ , article . , , machado, i., magrel, v., & , (). artificial intelgence in innovation reearch: a ytematic review, conceptual framework, and future reearch direction. _technovation_ . , article . htt://doi.org/./ technovation.. , k. (). ethical impcation and accountabity of algorithm. _ of_ _buine ethic, _ (), \u2013 . , (). what i artificial intelgenc available from . edu/artificial-intelgence/what-i-ai/index.html acceed ... , p. (). _lea change: why tranformation effort fai in mueum_ _management and marketing_ (pp. \u2013 ). routledge, . kre, , f. (). free will in philoophy and in i reearch: where do we tand and where do we want to be? ici proceedin . , ., oter, , & uhl, ). the moral authority of cha preprint :.. mcgrath, (). _grou: interaction and performance_ (vo ). englewood cff, nj: prentice-hall, . , , what i generative AI? retrieved from htt://ww mckinecom/featured-inight/mckiney-explainer/what-i-generative-ai#/ . me, , dyer, , & bnom, p. (). on the tate of the art of evaation in neural language mode :.. merhi, ). an evaation of the critical ucce factor impacting artificial intelgence implementation. _ management_ . , article . htt://doi.org/./ijinfomg. metcalfe, ). theory: eeking a plain engh explanation. _jitta: of_ _information technology theory and appcation, _ (), \u2013 . metz, (). exciting way to ue chat \u2013 from co to poetr __ . htt ://ww.com/feature/-exciting-way-to-ue-chat-from-co-to -poetry acceed: feburary , . mihra, ). a chat take the internet by torm, here \u2019 what it rival are up to. _the economic time_ . january htt://economictimindiatimcom/tech/te chnology/a-chat-take-the-internet-by-torm-here-what-it-rival-are-up-to/art iclehow/.cm . chell, (). chat could make thee job obolete: \u2018the i at the door. \u2019 . _new york pot_ . january htt://nypocom////chat--could-make -thee-job-obolete/ . khetri, , r. (). \u201c intitutional reform in the gulf ation council economie: a conceptual framework \u201d . _ of international management, _ (), \u2013 . khetri, n., & dholakia, n. (). profeional and trade aociation in a nacent and formative ector of a developing economy: a cae tudy of the nacom effect on the indian offhoring indutr _j , _ (), \u2013 . khetri, n. (). informal intitution and internet-baed equity crowdfundin __ _of international management, _ (), \u2013 . khetri, n. (a). \"regulatory technology and uperviory technology: current tatu, facitator and barrier \u201d . _ieee computer, _ (), \u2013 . khetri, n. (b). chat in developing economi _ieee it profeional, _ ( __ ) ( _forthcoming)_ . kuleh, . (). why chat can be dangerou for every internet uer. _the time of_ _india_ (available one) htt://timeofindiindiatimcom/toirreporter/author- ourabh-kuleh-.cm . ha, . (). intelgence: what every manager mut have for ucce in an information ag _portfoo penguin_ . ha, ., & mcfarlan, (). what i intelgence? _ieee it profeional, _ (), \u2013 . htt://wwcomputer.org/cdl/mag/it///.htm l . ha, ., , -, aldanha, , & ilveira, d. o. (). how will artificial intelgence and indutry . emerging technologie tranform operation management? _production and operation management, _ (), \u2013 . htt:// doi.org/./pom. ha, ., murugean, ., & eetharaman, p. (). what i your artificial intelgence trategy? _ieee it profeional, _ (), \u2013 . , . (). reitance to change: developing an individual difference meaur _ of apped ychology, _ (), . ortiz, . (a). chat i changing everythin but it till ha it mi __ (available one) htt://wwnecom/article/chat-i-changing-everythin g-but-it-till-ha-it-/ . ortiz, . (b). what i chat and why doe it matter? here \u2019 everything you need to kno _ netto innovation_ (acceed from) htt://wwnecom/article /what-i-chat-and-why-doe-it-matter-here-everything-you-need-to-know/ . pagani, m. and pion, r., forthcoming, artificial intelgence for buine creativity, routledg pappa, i. o., & giannako, m. n. (). rethinking learning deign in it education during a pandemi _frontier in education, _ , . , , & nguyen, (). manager \u2019 undertan of artificial intelgence in relation to marketing financial ervice: inight from a cro-country tud _international of bank marketing, _ (), \u2013 . parier, (). _the filter bubble: what the internet i hi from you_ . lon: viking/ penguin pre, . pazzanee, (). great promie but potential for peri _the gazette_ . htt://ne.edu/gazette/tory///ethical-concern- mount-a-ai-take-bigger-making-role/ . pearl, ): the chat from openai i amazing, creative, and totally wron htt://mahablcom/article/chat-amazing-wrong . perrigo, (). openai ued kenyan worker on le than $ per hour to make chat le toxi tim htt://timcom//openai-chat-kenya- worker . , , farquhar, d., van ech, p., durodi \u00b4-/bref) e, , & perez-vega, r. (). guet editorial: artificial intelgence in financial ervice marketin _international _ _of bank marketing, _ (), \u2013 . , , olaleye, ., & ukpabi, d. (). uing ai to peronae emotionally appeag advertiemen _ and ocial media marketing: emerging appcation_ _and theoretical development_ (pp. \u2013 ). : pringer, . , , oetan, , & kieu, (). the impcation of artificial intelgence on the marketing of financial ervice to vulnerable cutomer. _autralaian_ _marketing , _ (), \u2013 . , , & weitzel, (). the direct and indirect infence of mindfulne on techno-treor and job burnout: a quantitative tudy of - collar worker. _computer in man behavior, _ , article . molck, (). chat i a tipping point for ai. _ buine review_ . . molck, r. & molck, ). new mode of learning enabled by ai : three method and aignmen available at: /./ rn.pfl\u00fcgner, montti, r. (). what i chat and how can you ue it? _earch engine _ (acceed from) htt://wwearginejourn com/what-i-chat//#cloe . pinker, . (). tech prophecy and the underappreciated power of ide in brockman (ed.), _poible mind: twenty-five way of looking at ai_ . new york: penguin pre . moor, h. (). why we need better ethic for emerging technologi in v. d. hoven, & weckert (ed.), _information technology and moral philoophy_ (pp. \u2013 ). cambridge: cambridge univerity pre . , , , nit ai rik management framework playbook. ni retrieved , , from htt://pagnigov/airmf/ . natur (). preparing your materia __ (available at) htt://wwnatur com/nbt/ubmiion-guidee/preparing-your-ubmiion . . (). \u2019 t ban chat in choo _teach with it_ . htt://ww nytimcom////technology/chat-chool-teacher.html acceed ... pizzi, , carpi, d., & pantano, (). artificial intelgence and the new form of interaction: who ha the control when interacting with a ? _ of buine_ _reearch, _ , \u2013 . popper, k.r. (). _philoophy of cience: a peronal report_ . qadir, (). engineering education in the era of chat: promie and pitfall of generative AI for education. techrxiv. htt://doi.org/./ techrxiv..v. rad, , naraimhan, k., aman, , & utkever, i. (). improving language undertan by generative pre-trainin preprin \u2013 . rafa, d., undated, deigning aement to minimie the poibity of contract cheatin available at: htt://wwcitauk/__data/aet/pdf_file// /deigning-aement-to-minimie-the-poibity-of-contract-cheating-- rpdf (lat acceed //). , k. ). \u201c organizational tranformation during intitutional upheaval \u201d . _the review, _ (), \u2013 . rai, , contantinide, p., & arker, . (). next generation platform: toward man-ai hybrid. _mi , _ (), iii \u2013 ix . ng, , , , & murray, (). the ethical : a viable otion to ocio- legal iu _alternative law , _ (), \u2013 . ramuen, (). perfect, certain, ymmetric and complete information. _game and_ _information: an introduction to game theory_ (fourth edition.,). bail blackwell, . reed, ). chat for automated teting: from converation to cod _auce lab_ . nguyen, n., & , (). #bankfromhome: uing advertiement campaign to change banking behaviour during the covid- pandemic in an emerging econom _marketing communication and brand development in emerging market_ _vome ii: inight for a changing world_ (pp. \u2013 ). : pringer international pubhing, . htt://aucelacom/blog/chat-automated-teting-converation-to-code acceed: , . reee, h. (). why \u2019 \u2019 tay \u2019 ai bot went wron _techrepubc_ (available at) htt://wwtechrepubcom/article/why--tay-ai-bot-went-wrong/ _t_ . , d. (). _intitution, intitutional change and economic performance_ . cambridge, uk: cambridge univerity pre, . reich, r. (). _the work of nation. preparing ourelve for _ _t_ _century capitam_ . , . ey, , nter, v., mulcahy, r., & choong, k. (). man v machine: how artificial intelgence in banking infence conumer beef in financial advic _international of bank marketing, _ (), \u2013 . riedel, , mulcahy, r., & ey, (). feeg the love? how conumer \u2019 potical ideology hape repone to ai financial ervice dever _international_ _ of bank marketing, _ (), \u2013 . roger, (). _diffuion of innovation_ . and cter, . roenblatt, k. (). chat pae mba exam given by a wharton profeor. available at: htt://wwnbcnecom/tech/tech-new/chat-pae-mba- exam-wharton-profeor-rcna . roenzweig-ziff, d. (). new york city block ue of the chat bot in it choo _the wahington pot_ . htt://wwwahingtonpocom/education////n yc-chool-ban-chat/ . o \u2019 connor, . (). open artificial intelgence platform in nuring education: tool for academic progre or abu _nure education in practice, _ , article . o \u2019 connor, (). rea peopl _the child_ _&-/bref)_ _adolecent health, _ (), . o \u2019 connor, . n. i p. (). open artificial intelgence platform in nuring education: tool for academic progre or abue? __ , \u2013 . o \u2019 connor, ., & cha (). editorial: open artificial intelgence platform in nuring education: tool for academic progre or abue? _nure education in practice,_ __ , article . htt://doi.org/./nepr.. , f. (). being critical i good, but better with philoophy! from tran- formation and vae to the future of i reearch. _european of information_ _ytem, _ (), \u2013 . (). intagram, tiktok and youtube teenager \u2019 top three new ourc available at htt://ww.oruk/new-centre//intagram,-tiktok-and- youtube-teenager-top-three-new-ource acceed ... ryle, (). knowing how and knowing that: the preidential addr in _aritotean_ _ociety_ (vo , pp. \u2013 ). , (january) . o \u2019 flaherty, , & phil, (). the ue of fpped claroom in higher education: a coping revie _the internet and higher education, _ , \u2013 . okonkwo, , & ade-ibijola, (). appcation in education: a ytematic revie _computer and education artificial intelgence, _ , article . htt://doi.org/./caeai.. omoge, p., gala, , (). diruptive technology and ai in the banking indutry of an emerging marke _international of bank marketing, _ (), \u2013 . openai (). new and improved content moderation too htt://openai.co m/blog/new-and-improved-content-moderation-toog/ . acceed: feb . openai, a, chat: optimizing language model for dialogu available at: htt://openai.com/blog/chat/ . openai, b, ge poci htt://platform.openai.com/doc/ge-pocie . acceed: feb . openai, , \u201c dale \u201d , available at: htt://openai.com/dall-e-/ . oppy, , & dowe, d. (). the turing te in n. zalta (ed.), _the tan_ _encyclopedia of philoophy_ . edition. htt://plato.tan.edu/archive/win /entrie/turing-tet/ . arker, ., chatterjee, ., xiao, x., & elbanna, (). the ociotechnical perpective a an \u2018axi of coheion \u2019 for the i dicipe: recognizing it hitorical legacy and enuring it continued relevanc _mi , _ (), \u2013 . ccany, , minton, p. d., & hannon jr, . (). a urvey of tatitical packag _ urvey (cur), _ (), \u2013 . cetz, . , & venkateh, v. (). \u201c the rie of man machine: how cognitive computing ytem challenge aumption of uer-ytem interaction \u201d . _ of_ _the aociation for information ytem_ , (:), \u2013 . htt://doi.org/./ cetzler, , grime, m., & giboney, . (). the impact of converational kill on engagement and perceived mann _ of_ _management information ytem, _ (), \u2013 . cienc (). chat i fun, but not an author. htt://wwciencorg/doi/ ./ciencadg (acceed th feb, ). , r. (). _intitution and organization_ . thond oak, ca: age, . , , ruef, m., mendel, p. , & caronna, (). _intitutional change and_ _ organization: from profeional dominance to managed care_ . chicago, il: univerity of chicago pre, . , r. (). mind, brain, and program. _behavioral and brain cience, _ (), \u2013 . eeger, -m., pfeiffer, , & heinzl, (). texting with manke converational agent: deigning for anthropomorphim. _ of the aociation for information_ _ytem, _ (), \u2013 . tel, (). diruptive technology or viionary leaderhip _? of product_ _innovation and management, _ (), \u2013 . , n., & ciler, d. (). factor that infence uer \u2019 adoption of being coached by an artificial intelgence coach. _philoophy of coaching: an international_ _, _ (), \u2013 . htt://doi.org/./poc/.. elwyn, n. (). the future of ai and education: ome cautionary not _european_ _ of education, _ (), \u2013 . hah, , & bender, ). ituating earch. in acm igir conference on man information interaction and retrieval, \u2013 . t \u00b4 ercio pereira, p., mberger, f., minai, . m., & buha, d. (). new inight into conumer \u2019 intention to continue uing in the tourim contex _ of_ _quaty aurance in hopitaty_ _tourim_ . htt://doi.org/./ x.. heth, n., jain, v., , , & chakraborty, (). ai-driven banking ervice: the next frontier for a peronaed experience in the emerging marke _international_ _ of bank marketing, _ (), \u2013 . , (). man-centered artificial intelgence: three freh ide __ _tranaction on man-computer interaction, _ (), \u2013 . hrivatava, r. (). teacher fear chat will make cheating eaier than ever. _forbe_ . retrieved january , , from htt://wwforbcom/ite/rahihri vatava////teacher-fear-chat-will-make-cheating-eaier-than-ever/ . terwiech, (). would chat get a wharton mba? a prediction baed on it performance in the operation management cour mack intitute new, paper. available at: htt://mackintitutwharton.upenn.edu//would-chat- -get-a-wharton-mba-new--paper-by-chritian-terwiech/ . theconveration, , \"chat could be a game-changer for marketer, but it won \u2019 t replace man any time oon\", available at: htt://theconveration.com/chat- could-be-a-game-changer-for-marketer-but-it-wont-replace-man-any-time-oon- . jahat, m., o, m. , ain, ., nawaz, f., , , ). tranlating the impact of knowledge management procee into knowledge-baed innovation: the neglected and mediating role of knowledge-worker productivit _ of buine reearch, _ , \u2013 . , h. (). chat i fun, but not an author. _cience, _ (), - . , (). chat i fun, but not an author, \u2013 _cience (american_ _aociation for the advancement of cience, _ (). htt://doi.org/./ ciencadg . ieloff, (). \u2018if only hp knew what hp know \u2019 : the root of knowledge management at hewlett-pacd. _ of knowledge management, _ (), \u2013 . , h. (). the corporation: will it be managed by machine? in m. anhen, & bach (ed.), _management and the corporation _ (pp. \u2013 ). mcgraw- hill . tight, ). ma higher education and maification. _higher education pocy, _ , \u2013 . tiku, m., de vinck, , oremu, (, ). big tech wa moving cautiouly on ai. then came chat, wahington po retrieved from htt://ww wahingtonpocom/technology////chat--meta/ . ingh, v., , . ., inghania, m., nanavati, , & , (). how are reinforcement learning and deep learning algorithm ued for big data baed deciion making in financial indutrie \u2013 a review and reearch . _international_ _ of information management data inight, _ (), article . ingh, v., nanavati, , , k., & , (). how to maximize cck for diplay advertiement in marketing? a reinforcement learning approach. _information ytem frontier_ , \u2013 . htt://doi.org/./--- oetan, o., , , & nguyen, (). financial ervice experience and conumption in nigeri _ of ervice marketing, _ (), \u2013 . trinidad, (). undertan tudent-centred learning in higher education: tudent \u2019 and teacher \u2019 perception, , and cognitive g _ of_ _further and higher education, _ (), \u2013 . tung, ). chat can write cod now reearcher ay it \u2019 good at fixing bug, too. __ . htt://wwnecom/article/chat-can-write-code-now-reearc her-ay-it-good-at-fixing-bug-too/ acceed: , . turing tet, , january , in . htt://en..org/wiki/turing_ tet#_lamda_ . turing, (). computing machinery and intelgenc _mind, _ , \u2013 . (). neak preview of \u2019 ai writing and chat detection capabit available at: htt://ww.com/blog/neak-preview-of- -ai-writing-and-chat-detection-capabity . uc-cetina, v., navarro-guerrero, n., -gonzalez, , weber, , & wermter, . (). urvey on reinforcement learning for language procein _artificial_ _intelgence review_ , \u2013 . htt://doi.org/./--- ole, p. (). on uncertainty in ethic and technolog in p. ole, & m. d\u00fcwell (ed.), _evaating new technologie: methodological problem for the ethical aement_ _of technology development, the international brary of ethic, law and technology_ (pp. \u2013 ). pringer . pringer-, , tool uch a chat threaten tranparent cience; here are our ground rule for their u htt://wwnaturcom/article/d \u2013 - \u2013 (acceed th feb, ). tahl, (). _artificial intelgence for a better future: an ecoytem perpective on the_ _ethic of ai and emerging technologie, pringerbrief in reearch and innovation_ _governance_ . pringer international pubhing,. htt://doi.org/./--- - uk government (). national ai trateg available at htt://wwgov.uk/ government/pubcation/national-ai-trategy acceed ... uk government ervice, , , uk government ervice tandard. retrieved from htt://wwgov.uk/ervice-manual/ervice-tandard . (). ai and education: guidance for pocy-maker. available at htt:// unedo.org/ark://pf acceed ... van di, m., , , zuidema, , , r., & bockting, (). chat: five prioritie for reearch. _, _ , \u2013 . htt://doi.org/./d- -- van eterik-plameijer, p. , & , f. (). banking ytem trut, bank trut, and bank loyalt _international of bank marketing, _ (), \u2013 . , r. (). how language-generation could tranform cience, \u2013 _, _ . htt://doi.org/./d--- . tahl, , fck, , & timmerman, (). ethic of emerging information and communication technologie-on the implementation of rri. _cience and pubc_ _pocy, _ , \u2013 . htt://doi.org/./cipol/cw , n., & , k. (). a fully automated converational artificial intelgence for weight lo: longitudinal obervational tudy among overweight and obee adul _ diabete, _ (). htt://doi.org/./diabet tevenon, , mal, i., baa, m., graman, r., & van der maa, h. (). putting - \u2019 creativity to the (alternative ue) te in international conference on computational creativity (iccc) . :.. tokel-walker, (). ai bot chat write eay - hould profeor worry? _ (lon)_ . htt://doi.org/./d--- , . , mago, , m. (). on vae and vae co-creation: a ervice ytem and ervice logic perpectiv _european management , _ (), \u2013 . tokel-walker, n. (). chat ted a author on reearch paper: many cientit diapprov _, _ , \u2013 . htt://doi.org/./d-- -z trahan, , & gleaon, (). buil a multi-channel q & a at aint loui univerity uing the open ource qnabo available at: htt://aamazon.com/ blog/pubcector/buil-a-multi-channel-qa--at-aint-loui-univerity- uing-the-open-ource-qnabot/ . vailakopoulou, p., haug, , alveen, , & pappa, ). developing man/ai interaction for chat-baed-cutomer-ervice: leon learned from the norwegian governmen _european of information ytem, _ (), \u2013 . vawani, , hazeer, , uzkoreit, , jone, , gomez, n., & poloukhin, i. (). attention i all you need. _advance in neural information_ _proceing ytem_ , . _t conference on neural information proceing ytem_ . ca, : long beach, (available at) htt://proceedinneuri.cc/paper//file/ feedeefbdccaaa-paper.pdf . trang, , (). intitutional condition for diffuion. _theory oc, _ , \u2013 . tylo, n., , , & buha, d. (). big data empowered agity for dynamic, volatile, and time-enitive ervice indutrie: the cae of tourim ector. _international_ _ of contemporary hopitaty management, international of_ _contemporary hopitaty management, _ (), \u2013 . htt://doi.org/./ ijchm--- un, q., & medaga, r. (). mapping the of artificial intelgence in the pubc ector: evidence from pubc . _government information , _ (), \u2013 . unjak, (). chat: the end of one exam integrity? : .. vrga, . (). princeton tudent build app to detect eay written by a popular ai bo _the wahington pot_ , htt://wwwahingtonpocom/education/// /zero-chat-detector-ai/ . venkateh, v., & yke, (). divide initiative ucce in developing countrie: a longitudinal field tudy in a village in indi _information ytem_ _reearch, _ (), \u2013 . vincent, () open ai \u2019 new can explain code and write itcom cript but i till eaily tricked, the verge, nd, htt://wwthevergcom/ /openai--chat-ai-example-web-demo . vincent, () top ai conference ban ue of chat and ai language tool to write academic paper, the verge, , htt://wwthevergcom//// /chat-ai-writing-tool-banned-writing-academic-icml-paper . vive, x. (). competition and tabity in modern banking: a pot-crii perpectiv _international of indutrial organization, _ , \u2013 . wacker, (). a definition of theory: reearch guidee for different theory- buil reearch method in operation managemen _ of operation_ _management, _ , \u2013 . walh, (). bard, bing and baidu: how big tech \u2019 ai race will tranform earch \u2013 and all of computing, available at htt://theconveration.com/bard-bing-and- baidu-how-big-tech-ai-race-will-tranform-earch-and-all-of-computing- . walzer, ). in m. gro, & meiel (ed.), _oft war: the ethic of unarmed_ _confct_ . cambridge: cambridge univerity pr htt://doi.org/./ . , . (). innovative technology and operation for alleviating poverty through women \u2019 economic empowermen _production and operation management, _ (), \u2013 . te \u2019 eni, d., , f., agerfalk, p., & , . (). pubhing and getting pubhed in eji: marhag contribution for a diverity of genr _european of_ _information ytem, _ (), \u2013 . watermeyer, r., crick, , & knight, (). diruption in the time of covid- : learning technologit \u2019 account of intitutional barrier to one learning, teaching and aement in uk univeriti _international for academic_ _development, _ (), \u2013 . winikoff, m., cranefield, , , , doyle, , & richter, (). the advent of productivity aitant: the cae of myanalyti in ieee hawaii international conference on ytem cience (hic) . wirtz, , & zeithaml, v. (). cot-effective ervice excellenc _ of the academy_ _of marketing cience, _ (), \u2013 . wirtz, , kunz, h., hartley, , (). corporate reponibity in ervice firm and their ecoytem. _ of ervice reearch, pubhed one firt_ . htt://doi.org/./ wirtz, , , , , (). cot-effective health care development and reearch opportunitie in china, india and ingapor _ of ervice marketing, _ (), \u2013 . , r. , & , (). analying the pat to prepare for the future: writing a terature review a roadmap for releae .. _ of deciion ytem, _ (), \u2013 . , , & , r. (). analyzing the pat to prepare for the future: writing a terature revie _mi _ , xiii \u2013 xxiii . weinberger, d. (, ). how machine learning puhe u to define fairn retrieved from htt://hbr.org///how-machine-learning-puhe- u-to-define-fairne . wirtz, , patteron, p. , kunz, h., gruber, , , , pach, ., & , (). brave new world: ervice robot in the front _ of ervice_ _management, _ (), \u2013 . wlaak, , zwanenburg, . p., & paton, (). upporting autonomou motivation for phyical activity with during the covid- pandemic: factorial experimen _ formative reearch, _ (). htt://doi.org/./ woolf, p. (). _ai in education. in encyclopedia of artificial intelgence_ (nd ed..,). new york: john &-/bref) on, . woolf, p. (). ai and education: celebrating of marriag in aied workho (vo , pp. \u2013 ). yang, . (). the abitie and ation of cha _anaconda perpective_ . htt ://wwanacondcom/blog/the-abitie-and-ation-of-chat . on th january . zhai, x. (). chat uer experience: impcation for education. rn , \u2013 . weigla, (). contextual bia, the democratization of , and medical artificial intelgence in low- and middle-income countri _bioethic, _ (), \u2013 . weizenbaum, (). eza \u2014 a computer program for the tudy of natural language communication between man and machin communication of the acm, (), \u2013 welh, . (). chat and the future of the profeion. quillett available at: htt://quillettcom////chat-and-the-future-of-the- profeion/?ref = -newletter . wet, d. (, eptember ). the role of corporation in addreing ai \u2019 ethical dilemm retrieved from htt://wwbrookinedu/reearch/how-to-addre- ai-ethical-dilemma/ . , d. (). what contitute a theoretical contribution? _academy of_ _management review, _ , \u2013 . whit, (). a computer can now write your college eay, maybe better than you can. _forbe com_ . htt://wwforbcom/ite/emmawhit/// /a-computer-can-now-write-your-college-eay\u2014maybe-better-than-you-can/?h = fabadd . wilkin, (). chat detector could help pot cheater uing ai to write ea wilamon, , & , r. (). hitorical thread, miing k, and future direction in ai in education. _learning, media and technology, _ (), \u2013 . zhai, x., c, x., chai, ., jong, m. . , itenic, , pector, m., u, , yuan, , & (). a review of artificial intelgence (ai) in education from to . _complexity, _ , \u2013 . zhang, , pentina, (). who do you chooe? comparing perception of man v robo-advior in the context of financial ervic _ of ervice_ _marketing, _ (), \u2013 . wilamon, , bayne, ., & hay, . (). the datafication of teaching in higher education: critical iue and perpectiv _teaching in higher education, _ (), \u2013 . zhang, , mmel, , nandha, , & waardenburg, ). addreing the key of developing machine learning ai ytem for knowledge-intenive work. _mi executive, _ (), \u2013 . wilamon, , , , (). pandemic potic, pedagogie and practice: technologie and ditance education during the coronaviru emergenc _learning, media and technology, _ (), \u2013 . , , , h., , , peng, , fu, , fang, f., & , k. (). academic dihonety and it relation to peer cheating and culture: a meta-analyi of the perceived peer cheating effec _educational reearch review_ , article . wind, (). _ai-enabled new educational paradigm_ (eminar). kema buine chool . z, janen, m., , r., & u (). it i me, : working to addre the covid- outbreak-related mental health iue in chin uer experience, atifaction, and infencing factor. _international of man_ \u2013 _computer_ _interaction, _ (), \u2013 . ", "## educause horizon action plan: generative AI ", "###### and nicole muscanell ", "### educause horizon action plan: generative AI jenay and nicole muscanell, _ horizon action plan: generative ai_ (boulder, co: educause, ) \u00a9 educause this report is licensed under the creative commons attribution- noncommercial-noderivatives . international license . learn more explore additional materials on the research hub for the _ educause horizon report: teaching and learning edition_ , /// -educause-horizon-report-teaching-and-learning-edition . educause is a higher education technology association and the largest community of it leaders and professionals committed to advancing higher education. technology, it roles and responsibilities, and higher education are dynamically changing. formed in , educause supports those who lead, manage, and use information technology to anticipate and adapt to these changes, advancing strategic it decision-making at every level within higher education. educause is a global nonprofit organization whose members include u.s. and international higher education institutions, corporations, not-for-profit organizations, and institutions. with a community of more than , individuals at member organizations located around the world, educause encourages diversity in perspective, opinion, and representation. for more information, please visit educause.edu . n , generative AI emerged as the most rapidly adopted technology in history. all members of the higher education community, from students to administrators, are trying to determine what impact generative AI tools can, will, and should have on life, learning, and work. to make matters more complex, there is no consensus about how or even whether generative AI should play a role in the future of higher education. some faculty, staff, and administrators insist that generative AI should be banned from educational contexts, concerned that such tools undermine their foundational goal to teach students to be independent and critical thinkers. other leaders embrace these tools, positing that generative AI will be the most disruptive and transformational technology our community has ever seen. indeed, most of the higher education community ", "##### contents goals for our future state actions planning for the road ahead methodology expert panel roster falls somewhere in the middle, embracing the potential of generative AI with excitement while practicing pragmatic caution and scrutiny. amid all of this uncertainty, one thing is clear: if higher education leaders want to influence the future of generative AI at their institutions, there is no time to waste. to this end, a panel of teaching and learning professionals joined educause strategic foresight experts to envision an ideal future of generative AI in higher education in . using a horizon allows us to consider significant advancements in society, technology, politics, the economy, and the environment, without looking so far into the future that any projections become unrealistic. building on the trends, technologies, and practices described in the _ educause horizon_ _report: teaching and learning edition_ , the panel crafted its vision of the future along with practical actions that individuals, units and departments, and groups of collaborators can take to make this future a reality. ", "###### activity: imagine future you imagining the future can be challenging. our lives require us to be present in the moment, considering threats and opportunities that exist around us. take a minute to jump-start your creativity and foresight by answering the following questions: - what will your life look like ? envision your home, hobbies, family, and friends. - what will your work look like ? envision your workspace, activities, and colleagues. sked to describe the state of generative AI that they would like to see in higher education , panelists collaboratively constructed the future described below. **generative AI developers and researchers have found** **ways to ensure that processes and outputs are equal,** **representative, and unbiased.** developers prioritize ethical considerations such as algorithmic transparency, data privacy and security, accessibility, equity, and inclusion. end users have full control over how institutions and companies use their data and intellectual property. ai training for students and professionals is built on a foundation of ethical practices. generative AI tools are designed with safeguards to ensure they operate within the confines of developers\u2019 goals. generative **generative AI is used to enhance human relationships** **and complete tasks humans don\u2019t want to do.** human time is freed to work on and solve big issues related to health, economics, and other areas. in higher education, more time is available to focus on meaningful interactions between faculty, staff, and students. generative AI tools enable new connections between learners who share interests, and education environments are more focused on supporting these connections than on knowledge exchange because traditional pedagogical processes are more efficient and effective. ai developers and end users build specific, reference-based datasets for various higher education contexts. thought leaders in higher education provide insights about data quality. **generative AI supports access to and the accessibility** **of educational technology.** structural and arguably arbitrary roadblocks to student success are diminished or eliminated. for example, generative AI gets rid of the writing **generative AI tools report learning analytics findings** **in real time.** faculty and staff leverage this information to make data-informed decisions, implement targeted interventions, and continuously improve teaching methods. learning analytics tools also provide students and faculty with detailed, targeted, and constructive feedback on assignments, projects, and assessments. gateway for knowledge demonstration. generative AI facilitates multilingual education by automatically translating spoken and written communication into any language in real time, allowing educators to teach students all over the world and enriching cross-cultural experiences for students. the development of digital tools is democratized by the aid of generative AI tools. end users can create their own digital applications, and technology is not controlled by industry. generative AI powers interactive and immersive learning experiences such as simulation and virtual reality environments, making complex concepts more engaging and tangible for students. **faculty, staff, and students are able to think critically** **about generative AI tools and outputs.** they are able to discern appropriate uses for generative AI tools and evaluate generative AI products. search tools powered by generative AI provide users with credible sources of information, scaffolding **digital assistants provide students with personalized,** **lifelong guides for learning.** powered by generative AI, assistants are built with personas similar to a coach or friend. institutions use these assistants to provide wraparound (i.e., educational and psychosocial) support for students. assistants integrate insights from earlier educational experiences and ongoing individualized learning needs to address students\u2019 unique preferences, strengths, and challenges. higher education experiences are a seamless continuation from secondary education, with a focus on continuous upskilling and metacognition. after postsecondary graduation, students are still connected to lifelong learning pathways for gaining additional certifications and skills. assistants also help students develop critical thinking, innovation, and creativity by presenting them with unique challenges such as creative prompts, writing exercises, and problem-solving scenarios. information-gathering and fact-checking. faculty have the necessary professional development and ongoing support to implement generative AI tools in teaching and learning. educators teach students how to use generative AI tools ethically, responsibly, and effectively. anelists generated a list of actions that individuals, units and departments, and multi-unit or multi-institutional teams can take to arrive at this preferred future in . ", "###### individuals ensure that faculty members have access to ai tools. provide faculty with the tools and platforms they need to experiment and incorporate ai into their teaching and research activities. provide them with an adequate support system that includes ai experts who can provide guidance and assistance to faculty members as they integrate ai into their teaching and research. cultivate a culture of experimentation. encourage faculty, students, and staff to experiment with ai by providing dedicated time, incentives, and access to tools and discovery opportunities. experimentation will foster user agency, innovation, and creativity. it will also help individuals embrace new technologies and will lessen the digital divide. establish a community of practice. create a safe and controlled environment, such as an ai sandbox, where faculty, staff, and students can collaborate and experiment with ai tools and applications without risk to production systems. establish stakeholder inclusion as a best practice. increase stakeholder commitment to ethics. help stakeholders commit to being ethical users of ai by providing comprehensive and up-to-date training and resources on cybersecurity, privacy, and effective versus ineffective uses of ai, along with the risks and benefits of use. encourage cross-group collaboration, including students and external stakeholders (e.g., , industry). create peer learning communities where stakeholders can share experiences, challenges, and best practices, and encourage collaboration and interdisciplinary projects that explore innovative applications of ai in various fields. provide opportunities to self-educate. offer easy-to- access resources such as online courses and tutorials, webinars establish ai facilitator roles on campuses. facilitators can help faculty and staff navigate their identity as ai users and educators. implement professional development opportunities and resources such as trainings, workshops, coaching and mentoring programs, peer learning communities, and educational materials to help faculty and staff become facilitators. establish recognition and reward systems that recognize those who excel in their supportive facilitator roles. and workshops, and educational materials such as handbooks, guides, and case studies that introduce faculty, staff, and students to ai concepts, applications, and best practices. invest in and support ongoing ai literacy initiatives. develop comprehensive, institution-wide training programs and resources that individuals with varying levels of technical expertise can understand and use, and create a repository of be an engaged leader. support your colleagues on the generative AI journey by engaging regularly in professional development and training opportunities, which will help you make well-informed and bold decisions about new institutional policies. provide dedicated time to communicate with units and departments about important issues surrounding ai usage at your institution. regularly updated educational resources related to ai integration in higher education. ", "###### units and departments reimagine curriculum and assessments. help faculty incorporate ai into courses in ways that create more personalized and authentic learning experiences while also incentivizing learning, creativity, and innovation over grades. ", "###### multi-unit collaboration **establish interdisciplinary ai centers.** create centers where individuals from different units and departments can collaborate on projects and explore innovative applications of ai in various academic fields and solve complex problems. encourage units and departments to use a collaborative and evidence-based approach, and provide them with time and budget for redesign, along with an updated curriculum review process. **establish an ai implementation task force.** include representatives from different units and departments to oversee resource allocation, assess unit and departmental needs, and identify potential ai use cases. train the next generations of ai users. encourage units and departments to continually think about how ai will evolve over time and across disciplines so that they can anticipate, identify, and acknowledge new skills and knowledge that students need now and in the future. employ or train ai integration specialists. these specialists can assess communication and collaboration needs **form an ai policy committee.** the committee should comprise representatives from multiple administrative units and departments to develop and oversee shared ai policies and governance. the committee should review and develop policies and shared practices in the areas of fair use, assessment and academic integrity, institutional review board processes, and the scholarship of teaching and learning. within units and departments and identify opportunities for ai- powered solutions. invest in state-of-the-art centralized ai infrastructure. the infrastructure should include high-performance computing resources, cloud services, and ai development tools to support research and implementation efforts. provide shared access to ai tools, data storage, and technical support for all units and **appoint an ai ethics and compliance officer.** the officer should be responsible for risk management and ensuring that ai practices across units and departments align with ethical guidelines, data privacy regulations, and institutional policies. seek legal expertise to navigate complex legal frameworks and ensure that institution-wide and unit/department ai policies adhere to relevant laws and regulations. departments. **establish dedicated communication channels.** create provide dedicated it support. ensure that each unit and department has it support to address technical issues related to ai integration and collaboration. employ an institution- wide technical support team to assist departments in the implementation, integration, and troubleshooting of ai solutions. develop departmental protocols and guidelines. establish guidelines that address security, privacy, and data management and ensure that sensitive information shared through ai-powered tools is secure and complies with data protection regulations. channels to inform all units and departments about shared ai policies and governance, in addition to ai literacy and integration trainings and opportunities. encourage units and departments to use these channels to collaborate and share best practices. **recruit a dedicated interdisciplinary team of** **ai experts.** allocate resources to recruit a team of interdisciplinary ai experts with diverse skill sets, including data scientists, ai researchers, software engineers, and domain specialists. ", "###### multi-institution collaboration **establish formal partnerships with other institutions.** form a commission or consortium consisting of members from multiple institutions and disciplines to promote sustained collaboration and joint ai initiatives. the commission or consortium should focus on governance and policy across institutions, with specific attention to accreditation issues and student outcomes. **establish cross-institutional ai research centers.** create collaborative spaces for researchers to work together on cutting-edge ai projects. establish resource-sharing agreements that enable institutions to pool their expertise, data, **support knowledge exchange between institutions.** organize virtual or in-person knowledge exchange forums, webinars, workshops, and conferences that bring together faculty, researchers, and administrators from different institutions to discuss their ai initiatives, successes, and challenges and to explore potential collaboration opportunities. **encourage multi-institutional publications.** support and incentivize multi-institutional research publications, white papers, and reports that share insights and findings from collaborative ai research and projects. and ai tools for collective use and benefit. **establish a dedicated multi-institutional collaborative** **establish multi-institutional funding models.** create funding opportunities to support collaborative ai research and projects that involve multiple institutions, encouraging knowledge exchange and cross-institutional cooperation. **appoint a dedicated outreach team.** the team should comprise representatives from each collaborating institution. the outreach team should be responsible for overseeing, coordinating, and promoting ai collaboration efforts, ensuring effective communication and the alignment of goals. **platform.** provide access to collaborative tools and support, allowing institutions to easily share ai-related research, best practices, and resources and to foster effective cross- institution outreach. **partner with stakeholders and institutions.** work with stakeholders to develop a more holistic understanding of students\u2019 early experiences with ai, in addition to their future academic and workforce needs, which can help institutions redesign and/or develop curricular programs to address these needs. nvisioning the future we want to see is important and exciting work, but real progress can only be made when individuals like you create change. use the following activities to solidify your vision of the future and make plans to take action. ", "###### activity: understand your institution\u2019s needs the best plan of action always starts with understanding the starting line. use this activity to explore the current needs and interests of stakeholders at your institution. - make a list of key stakeholders at your institution who will be interested in shaping the future of generative AI. consider a wide range of perspectives from a variety of operational units: academic units, information technology, information security, privacy, ", "##### your role in the future of generative AI as you embark on the journey, consider the following questions: - what role do you want to take in these plans? - will you start with individual action, or do you want to lead collaborative efforts? - what is the current state of generative AI at your institution, and where will your institution be ? student services, legal, etc. - select a sample of individuals from your list and talk to them about the present and future states of generative AI at your institution. some guiding questions are: - what is our current state of generative AI? - how do we currently support or suppress generative AI? - what are our biggest challenges related to generative AI? - what are our greatest assets related to generative AI? - take notes on key takeaways from your conversations. include references for resources and documents such as websites and institutional policies. - reflect on your findings and consider how they align with the findings in this report. is your institutional vision aligned with panelists\u2019 ideas? are any individuals at your institution ready to take some of the actions described in this report? - make a plan for next steps. usually, this starts with identifying key members of your professional network who can partner with you. consider stakeholders who are ready to hit the ground running, colleagues who already have considerable influence and can break down barriers, and colleagues or units that might be resistant to change and need help seeing your vision. ", "###### activity: build an action roadmap now that you have a clear picture of where you are, where you want to go, and who is going to help, you\u2019re ready to develop an action roadmap (adapted from ) ). this activity is best accomplished collaboratively, so consider working with some of the individuals you identified in the activity \u201cunderstand your institution\u2019s needs.\u201d start with the right side of this tool, describing the goals and elements of _your_ preferred future, using the future described in this report as inspiration. then, review the findings you generated with \u201cunderstand your institution\u2019s needs\u201d and describe the short-, mid-, and long-term actions that will carry you from \u2019s reality to the future you want to see. ", "###### build an action roadmap describe your preferred future short-term ____________ mid-term ____________ long-term ____________ milestones milestones milestones easier activities easier activities easier activities harder activities harder activities harder activities \u00a9 institute for the future. all rights reserved. sr-b | cc by . ", "##### more resources for generative AI - educause leadership series | chatgpt and generative AI: navigating leadership opportunities and /programs-and-tracks/educause-leadership-series) - [webinar | generative AI in higher education: embracing ai\u2019s potential - learning lab | chatgpt in higher education: exploring use cases and designing /courses//chatgpt-in-higher-education-exploring-use-cases-and-designing-prompts-) - [webinar | artificial intelligence: preparing institutions for literacy and leadership - \u201cintegrating generative AI into higher education: considerations\u201d - \u201ca generative AI primer\u201d - \u201ceducause quickpoll results: adopting and adapting to generative AI in higher ed tech\u201d - educause topic page: artificial intelligence his _ horizon action plan: generative ai_ is grounded in the perspectives and knowledge of an expert panel of practitioners and thought leaders who represent the higher education teaching and learning community. the members of this group were sought out for their unique viewpoints as well as their contributions and leadership within their domain. dependent as the ", "# t _horizon report_ efforts are on the voices of its panel, every effort was made to ensure those voices were diverse and that each could uniquely enrich the group\u2019s work. for this action plan, we adopted and adapted different components of the institute for the future (iftf) foresight methodology. first, we asked panelists to review the trends, technologies and practices, and scenarios from the __ _educause horizon report: teaching and learning edition_ and to describe their own vision of the preferred future of generative AI. second, panelists were directed to list the threats and educause staff provided group facilitation and technical support but minimal influence on the content of the panel\u2019s inputs and discussions. this was done to reduce the potential introduction of bias into the results and to allow for this organized group of experts themselves to discuss and converge on a set of actions for the future based on their own expertise and knowledge. opportunities that might imperil or bring momentum to their preferred future and to brainstorm possible actions in response to those threats and opportunities. the data the panel discussions were held remotely on , by zoom. produced as a result of these efforts have been used to create the action plan featured in this report. e would like to acknowledge and express our deepest gratitude to the panel of experts listed below who were responsible for generating all of the big ideas summarized throughout this resource. their brilliant thinking and rich discussions were the foundation of this work, and this resource simply would not exist had it not been for their ", "# w dedication to this project and their passion for serving higher education. **** lead xr disruptor/department head lindenwood university **** associate director, educational innovation illinois urbana-champaign **avi hyman** director, academic, research & collaborative (arc) technologies toronto **wendy lampner** director of online, continuing, and professional education akron **** business systems analyst mcmaster university **janet frizzarin** program manager, senior specialist digital learning lodz technology **mark daley** professor and chief digital information officer director, teaching and learning program educause **jenay robert** senior researcher educause **nicole muscanell** researcher educause **nichole arbino** communities program manager educause **mark mccormack** senior director of research and insights educause **jamie reeves** director of community, product, and portfolio management educause **belle mcdonald** portfolio manager educause **szymon machajewski** associate director, learning technologies and innovation illinois chicago ", "# policies in parallel? a comparative study of journalistic ai policies in global news organisations p re -p rint \u2013 n ot p eer -r eviewed bj\u00f6rn becker , \u2020 , and \u2021 frankfurter allgemeine zeitung, frankfurt, , trier, germany, becker@uni-trier.de , , oxford, united kingdom, felix.simon@oii.ox.ac.uk , , oxford, united kingdom th , abstract a growing number of news organisations have set up specific guidelines to govern how they use artificial intelligence (ai). this article analyses a set of guidelines from publishers in belgium, brazil, canada, finland, germany, india, the netherlands, norway, sweden, switzerland, the united kingdom, and the united states. looking at both formal and thematic characteristics, we provide comparative insights into how news outlets address both expectations and concerns when it comes to using ai in the news. drawing from neoinstitutional theory and the concept of institutional isomorphism, we argue that the policies show signs of homogeneity, likely explained by isomorphic dynamics which arose as a response to the uncertainty created by the rise of generative AI after the release of chatgpt in . our study shows that publishers have already begun to converge in their guidelines on key points such as transparency and human supervision when dealing with ai-generated content. however, we argue that national and organisational idiosyncrasies continue to matter in shaping publishers\u2019 practices, with both accounting for some of the variation seen in the data. we conclude by pointing out blind spots around technological dependency, sustainable ai, and inequalities in current ai guidelines and providing directions for further research. keywords : artificial intelligence, llms, news, journalism, isomorphism, ai guidelines, ai ethics, comparative analysis \u2020 both authors contributed equally to the design, data collection, analysis, and writing of the study. \u2021 contributed to the coding and analysis of guidelines, designed, and carried out the syntactical analysis, and contributed to the final write-up. ", "# literature review ethical issues can arise at every juncture of the journalistic process. while professional ethics is intimately linked to the quality of journalistic products, these concepts are not identical. sometimes, measures aimed at enhancing the quality of journalism are not necessarily based on ethical behaviour, and sometimes quality and journalistic ethics might even be at odds, as seen with the speed of reporting (meier, , p. ). professional ethics mainly pertains to issues related to the accuracy and verification of information, the independence of journalists and publishers, possible deception and fabrication of facts in the production of content, the use of graphic images and image manipulation, and the handling of sources and confidentiality (ward, , pp. ). self-regulation of the news through guidelines below the formal level of laws and regulations, which generally define what journalism can and cannot do (, : pp. -ff.), the journalistic profession relies on self-regulation. this is particularly true in liberal democracies, wherein press freedoms curb potential government efforts to influence reporting. selfregulation rests on two pillars. first, many news organisations regulate themselves by setting up non-governmental press councils, who often issue broad guidelines which in turn shape the work of participating organisations. a study of press council codes of ethics across countries (, n.d.) found that these stress \u2018core journalistic ethical principles\u2019 such as fairness and accuracy in reporting, as well as autonomy of the press but are often very general in their remit. second, publishers often develop individual guidelines. an editorial guideline constitutes a set of rules by a specific organisation that media professionals must or should observe. such internal guidelines often show great variety, encompassing various documents, from formal regulations to informal memos (, , p. ). large publishers\u2019 own guidelines are often more specific than those of press councils and reflect the principal values and standards of the respective publisher (schultz, , p. ). usually, these are intended to further specify the rules for these organisations\u2019 journalists and staff. news organisations\u2019 social and new media guidelines as precursors in , publishers have formulated additional guidelines for specific topics, for example the use of social media. various studies have looked at these, e.g., through interviews or content analysis (opgenhaffen & scheerlinck, ; bloom, , ; , ; , ; , ; opgenhaffen & d\u2019haenens, ; , ; , ). many of these focused on english-speaking countries (, ) due to shared ideological and economic structures and similar media systems (, , p. ), with opgenhaffen/d\u2019haenens (), additionally focusing on belgium and france. research on social media policies has largely been limited to mapping how specific media companies understand social media and what kind of behaviour they require of their journalists on these platforms. the modest sample sizes and focus on the anglosphere make broad conclusions difficult. however, the results showed \u2018no homogeneity\u2019 (opgenhaffen & d\u2019haenens, , p. ) as well as \u2018ambivalence\u2019 (duffy & knight, , p. ) which is notable given that social media are somewhat similar in their affordances across countries. in their study of ethics guidelines for immersive journalism of eight publishers in english and spanish-speaking countries, s\u00e1nchez laws & utne () mainly found differences by organisation type, with \u2018a stricter ethical regime [\u2026] in publicly funded broadcasters\u2019 (p. ) compared to privately owned media. finally, contrasting professional journalism ethics with social media guidelines, () found that the latter \u2018hardly reflect changing journalistic norms\u2019 (p. ). policies for the use of ai in news organisations early research on news organisations\u2019 ai guidelines has also been largely descriptive. () examined a total of seven guidelines from europe and north america, while () analysed guidelines, from europe, five from north america and one each from asia and south america. both studies looked at the formal level, examining how the documents were titled and what statements were made about their binding nature. in addition, they addressed why media companies want to use ai, what applications should be allowed and prohibited, how to deal with human oversight of ai-produced material and transparency, principles of responsible ai, and possible dynamisation of the guidelines. (, pp. -) furthermore refers to internal and external collaboration, while () focus on accountability and responsibility, training, and the concept of cautious experimentation. given the small sample sizes, possible patterns are cursory. for example, cools & diakopoulos () point out that two media outlets owned by the same company tend to have similar policies. (, p. ) noted links between the journalistic style of the organisation and the form chosen for the guidelines: \u2018the news agencies present their guidelines briefly in a news-like style, while magazine[s] chose a more narrative form, and a british broadcaster known for its structural complexity chose the form of detailed guidelines\u2019. in addition, the goals for the use of ai in the newsroom, as stated in the guidelines, tended to vary between media organisations. the ai policies of private sector news organisations seemed to associate ai with comparative business advantages, such as speed and breadth of coverage, while public service broadcasters focused more on public service implications ( , p. ). ", "# theoretical framework neo-institutionalism and institutional isomorphism: how news organisations deal with uncertainty it is worth noting that journalism ethics were \u2018developed for a journalism of limited reach, whose public duties were assumed to stop at the border\u2019 with the search for a global journalism ethic still \u2018a work in progress\u2019 (ward, , pp. -). while both national differences and organisational differences continue to matter in the news and play a role in shaping publishers\u2019 and journalists\u2019 practices, including around the adoption of new technologies (, ; perus \u030c al., ), the news industry, or its organisations, are also increasingly shaped by factors that transcend nationally bounded media systems, for instance the growing influence of the technology sector, or they themselves transcend nationally bounded media systems because they operate in more than one national market. ai as a technology also acts with broadly similar effects across contexts, so it would be reasonable to assume that outlets across context react to the technology \u2013 and its concomitant challenges \u2013 in similar ways. to explain possible similarities \u2013 a homogenisation \u2013 and patterns in ai guidelines on a larger scale, we work with a neo-institutional lens, in particular the concept of institutional isomorphism, the \u2018tendency of organisations in a particular field to resemble one another,\u2019 especially when faced with constraints (dimaggio & powell, ). isomorphism can be the result of one or a combination of three possible factors: coercive, mimetic, and normative. _coercive_ isomorphism \u2018results from both formal and informal pressures exerted on organisations by other organisations on which they depend and by cultural expectations in the society in which organisations operate\u2019 (dimaggio & powell, , p. ). pressures can include laws and regulations or industry standards. _mimetic_ isomorphism refers to an organisation\u2019s response to uncertainty which often encourages organisations to respond to a stimulus by modelling themselves on similar or more successful organisations in their field. this may be particularly true when \u2018technologies are poorly understood [...], when goals are ambiguous, or when the environment creates symbolic uncertainty\u2019 (dimaggio & powell, , p. ). finally, _normative_ isomorphism is the result of pressure from professional groups, i.e., it \u2018stems primarily from professionalisation,\u2019 what dimaggio & powell describe as \u2018the collective struggle of members of a profession to define the conditions and methods of their work\u2019 (, p. ). factors leading to normative isomorphism include inter-organisational networks of exchange or the movement of labour between firms. in the news industry, there is ample evidence that isomorphic processes in the past have occurred as result of all three of these factors. looking at the pivot to online video news, () found that a mixture of audience demand (coercive), commercial considerations (mimetic), uncertainty about platform businesses\u2019 interests and strategies, and uncertainty about the future direction of digital media (coercive, mimetic, normative) led the majority of organisations in their study to \u2018converge on a similar short, platform and mobile-oriented approach to online news video\u2019 with differences \u2018more clearly related to organisational differences than to country differences\u2019 (p. ff.). () and later petre () also demonstrated forms of mimetic isomorphism in the use of audience metrics. faced with uncertainty and constraints, publishers across organisation types (petre) and countries () adopted audience metrics in broadly similar ways, even though some differences remain due to national and organisational idiosyncrasies. finally, () finds that the adoption of platform companies\u2019 ai and ai infrastructures follows an isomorphic pattern, with uncertainty about the direction and effects of the technology and the fear of being left behind acting as strong motivators for forms of mimetic isomorphism, recurring movement of talent and the highly networked nature between these news organisations contributing to these forms of normative and mimetic isomorphism, and ai as a large technological system (simon, ) itself acting as coercive force. considering the current uncertainty about what ai is, what it can and cannot do for and to the news (, ; simon, b; , ), isomorphism can serve as a useful theoretical framework to investigate the adoption and content of news organisations\u2019 ai guidelines. our focus is therefore on examining the following research questions: rq: _to what extent do international news organisations\u2019 ai guidelines exhibit_ _isomorphic tendencies?_ it will be readily apparent, however, that this question is too general and hides several more specific ones, as follows: rq : what are the formal and thematic characteristics of news organisations\u2019 ai guidelines? rq a : how do ai guidelines compare across organisational types (commercial vs public service)? rq b : how do ai guidelines compare across different countries? rq: what are the blind spots of current ai guidelines in news organisations? ", "# case selection, data, and methods to explore these questions, this study draws on a sample of editorial ai policies from media companies and organisations in twelve countries, representing both the global north and south. sampling of cases recent studies of social media and ai guidelines have been limited by small sample sizes and convenience sampling approaches, relying mainly on guidelines available online. to create a dataset with some meaningful variation that allows for a more general analysis, we took a more systematic approach. first, we identified a set of twelve countries falling into different media system categories (hallin, ) where the existence of ai guidelines was already known or likely to be expected. these countries can be grouped into four main geographical regions: western europe (belgium, germany, the netherlands, switzerland, and the united kingdom), scandinavia (finland, norway, and sweden), north america (canada and the ), and the global south (brazil and india). we acknowledge that the concept of \u2018global south\u2019 is fraught, especially as it is an exceptionally broad and heterogeneous category. we then identified up to six leading companies or organisations for each country based on use according to the digital news report (newman et ) in each of the following categories: magazine, , news agency, legacy newspaper, online news/digital-born, private broadcaster, professional organisation, and public broadcaster. because national media markets differ significantly from country to country, the sample is not entirely symmetrical. to avoid missing out on important outlets not captured by the overall sampling, we strategically incorporated additional outlets based on recommendations from country experts. the final sample included media outlets which we contacted by email. of the organisations, we were ultimately able to include ai policies in our study. seven media companies indicated that their policies were still under development, ten organisations had policies in place but would not share them for academic purposes, and a further eleven companies responded that they had no ai policies. we received no response from contacted media organisations. in the final sample, a total of documents (.%) were found online, in eight cases the companies made their policies available to us (.%), and in a further eleven cases we were able to obtain the documents from other sources (.%). guidelines were available in english (.%), while the remaining documents (.%) were translated to english using the neural machine translation service deepl. where possible, we verified the accuracy of translations drawing from our own experience (with german, dutch and french) or with the help of native speakers. table : study sample, sorted by country and organisation type nr. name country organisation type source mediahuis belgium online belgium professional organisation online rtbf belgium public broadcaster obtained nucleo brazil digital-born media online the globe and mail canada legacy newspaper online broadcaster online helsingin sanomat finland legacy newspaper obtained suomen tietotoimisto obtained council for mass media finland professional organisation online yle finland public broadcaster obtained t-online germany digital-born media online germany digital-born media online frankfurter allgemeine legacy newspaper online rheinische post germany legacy newspaper provided legacy newspaper online handelsblatt germany legacy newspaper obtained der magazine online ippen germany provided online deutscher journalistenverband bayerischer rundfunk germany public broadcaster online the quint india digital-born media obtained de volkskrant netherlands legacy newspaper online dpg media netherlands obtained anp netherlands news agency obtained npo netherlands public broadcaster provided tv norway commercial broadcaster obtained dagens naeringsliv norway legacy newspaper online schibsted norway online nrk norway public broadcaster provided sveriges television sweden commercial broadcaster obtained svenska dagbladet sweden legacy newspaper online aftonbladet sweden legacy newspaper online dagens nyheter sweden legacy newspaper provided journalisten sweden legacy newspaper online bonnier sweden provided tt sweden news agency obtained heidi news switzerland digital-born media online tamedia switzerland online ringier switzerland online srf switzerland public broadcaster online itn united kingdom commercial broadcaster provided financial times united kingdom legacy newspaper online online united kingdom public broadcaster online business insider digital-born media online usa legacy newspaper online the atlantic magazine online wired magazine online ap news agency provided rtdna professional organisation online national public radio public broadcaster online qualitative coding, quantitative coding, quantitative syntactic analysis to analyse the ai guidelines included in our study we use a mixed methods approach combining qualitative thematic content analysis, quantitative coding, and quantitative syntactic analysis. _qualitative and quantitative coding_ drawing from the literature on ai in the news as well as previous research on news organisations\u2019 general, social media, and ai guidelines (becker, ; opgenhaffen & d\u2019haenens, , p. ) as well as a first round of inductive coding using open, axial, and selective coding, we developed a codebook spanning categories (see appendix, tables and ). this was followed by a first round of deductive qualitative coding, where three coders coded all guidelines for selected formal and thematic characteristics, with the unit of analysis being each individual sentence. formal characteristics included the professional roles and specific ai engines mentioned. thematic aspects were goals of ai deployment, journalistic values mentioned, allowed and prohibited ai applications, possible pitfalls of journalistic ai use, applications where transparency is required, possible elements of algorithmic bias, aspects of source protection, professional roles and institutions involved in internal and external cooperation around ai, and views on possible dependencies on large ai platform companies. additionally, we analysed the documents through rigorous quantitative coding, focusing on additional formal and thematic categories including allowed deployments of ai in the journalistic process, areas of human supervision, and methods of creating transparency when ai was used. the unit of analysis was the whole document. each document was coded into all the categories. for the quantitative coding, the codebook was tested and refined over two initial rounds of test coding, whereby three coders independently coded a random selection of three guidelines in both rounds to resolve difficulties and misunderstandings. after each round, the results were compared and discussed, and the codebook refined. once the codebook was set, two coders independently recoded all pieces of content. to measure intercoder reliability, we used \u2019s alpha as the most rigorous and reliable measurement. the reliability of each guideline\u2019s coding was estimated based on ( x ) independent decisions in the coding process. in cases the coders disagreed. f suggests that it \u2018is customary to require \u03b1 . where tentative conclusions are still acceptable, \u03b1 is the lowest conceivable limit (, p. ).\u2019 f\u2019s alpha was . on average with a range of . and . remaining differences in coding were discussed and resolved. _text-to-text statistical comparison by cosine distance_ in a final step, we conducted a quantitative, statistical comparison of each ai guideline to each other ai guideline to account for any residual blind spots in the manual coding. this analysis of syntactic similarity looked at the degree of resemblance in the arrangement and structure of five-word blocks and quantifies how closely two or more sentences align in terms of their words, grammatical patterns, and word order. the text-to-text comparison involved a three-step process for each dyad in the dataset: () cleaning translated-to-english pdf documents, () vectorising text, and () comparing the vectors by cosine distance. since possible inferences from data are sensitive to preprocessing choices (, , p. ), only those aspects of text data that were irrelevant to the research questions were excluded at the cleaning stage. these included numbers, unicode punctuation, and english-language stop words (\u2018the\u2019, \u2018which\u2019, \u2018on\u2019, \u2018at\u2019 etc.). finally, each text file was transformed to lower case and white space was stripped. following spirling () and , p. ), texts were vectorised as the set of distinct five-word (\u201c-gram\u201d) sequences present in each text. -gram sequences were employed because they tend to be long enough to capture meaningful passages of text while short enough to be reoccurring across multiple guidelinesif textual borrowing occurs. cosine distance, a measure of textual similarity well-suited to texts of varying lengths \u2013 a ubiquitous phenomenon in our dataset \u2013 was then computed. the cosine distance between vectors ranges from , entirely the same set of n- grams, to , indicating no shared n-grams, and is specified by minus the euclidean dot product of vector a, where a is the term frequency vectorization of the first text, and vector b, where b is the term frequency vectorization of the second text, over the magnitude of each vector. the intuition behind cosine distance is that the more similar the two vectors are, the smaller the angle between them will be, and thus the larger the cosine distance. results were arrayed in a symmetrical matrix and visualized as a heatmap (see . & ), with darker colours indicating smaller distances, and thus, higher degrees of similarity. to contextualise resulting values, a sample of general editorial guidelines (n=) with an intentional overrepresentation of german-language guidelines (see appendix, table ) to reflect the linguistic variation in the overall dataset, was also compared using cosine distances. such an approach allows this paper to draw broad-strokes conclusions about how similar journalistic ai guidelines are to each other in comparison to how similar general editorial guidelines are to each other. thus, preliminary findings regarding the degree of convergence driven by the sharing of ideas in an environment of uncertainty surrounding ai can be assessed relative to convergence in established journalistic practices. ", "# findings we first present findings from the syntactic, statistical comparison before presenting findings from the qualitative and quantitative coding of the formal and thematic characteristics of the ai guidelines. due to the small sample size, we are constrained to descriptive statistics for the quantitative coding, as attempting more complex analyses or inferential procedures could lead to unreliable or misleading results. syntactic similarity the concept of syntactic similarity aids in assessing the likeness of sentences or text based on their syntactic composition. the matrix results of comparison by cosine distance in the ai guidelines sample indicates, on average, a lower degree of similarity than do results in the benchmark general editorial guidelines sample. one can see from the histogram in figure that the modal outcome of dyadic comparison in editorial guidelines is between . and . while in figure (ai guidelines) the modal outcome is above .. visually, this is reflected in the presence of more tiles toward the red end of the spectrum indicating lower degrees of distance or a higher degree of statistical similarity on figure than on figure . figure : dyadic benchmark comparison of editorial guidelines by cosine distance figure : dyadic comparison of ai guidelines by cosine distance figure : due to space limitations, not all outlets are labelled. one can observe clustering at the level of shared language in both samples. for example, the two most similar editorial guidelines in the benchmark sample, those of sky news and the australian broadcasting corporation, share english as a common language. likewise, itn and the canadian broadcasting company (cbc), the two most similar ai guidelines in the study sample, also share english as a common language. in broad strokes, the columnar dendrogram in both figure and figure indicates hierarchical grouping along language lines. illustratively, der standard and springer, both german-language editorial guidelines, form a visually distinct block in figure (bottom-left quadrant), while aftonbladet and , both swedish-language ai guidelines, form an outlier block (bottom-left) in figure . at a broader level, indicate a high-level in- group/out-group dynamic where many media organisations group together regardless of language boundaries while some media organisations chart their own path outside of the main group (labelled on both figures), leaving the average cosine distance within the group higher than in the out-group. the outlier group in figure appears to be an outlier group of one, suggesting that there are fewer media organisations willing to chart their own path in editorial guidelines than there are in ai guidelines, though that may be a sample size driven outcome. as one might expect, large, influential media organisations find themselves at the centre of the in-groups, particularly in figure , where the and bayerischer rundfunk, two early and influential sets of ai guidelines, are at the centre of the in-group block. formal characteristics results pertaining to length, date of first publication, title keyword, remit, accountability, audience, reference to professional roles, and dynamization are presented below. figure : distribution of ai guidelines by word length distribution of ai guidelines by length in words words figure : distribution of ai guidelines by date of first publication, if known (n=). publication of ai guidelines over time web.de/gmx/& national public radio the quint the globe and mail tamedia svenska dagbladet independent television news der spiegel dagens naeringsliv cbc ringier rheinische post journalisten financial times dpg media de volkskrant usa today t\u2212online heidi news frankfurter allgemeine zeitung deutscher deutsche presse\u2212agentur business insider anp aftonbladet the atlantic ippen helsingin sanomat bayerischer rundfunk schibsted council for mass media date of first publication as figure shows, the documents vary considerably in length (see also table in the appendix). the shortest consists of only words or characters including spaces, the longest has words (, characters). the arithmetic mean of all ai guidelines included in our study is words or characters. for guidelines (.%), of publication was available (see figure ). the earliest document in our study are guidelines, published in , while the latest documents were published in by us public broadcaster national public radio and the german online news sites web.de/gmx/&. the release of chatgpt in is likely to have boosted the development of ai guidelines in the media industry: a total of guidelines with a known release date (.%) were published in , but only one in (.% each) and three in (.%). the findings from the analysis of title keywords (table ) reveal a diverse range of terms used to frame ai guidelines. the most common term is \u2018guideline,\u2019 accounting for .% of the sample. other prevalent terms include \u2018how-to\u2019-phrases (.%), \u2018policy\u2019 (.%), and \u2018principles\u2019 (.%). less frequently used terms include \u2018framework\u2019 (.%) and \u2018guide\u2019 (.%). notably, some documents do not have explicit title keywords (.%). regarding the remit of the ai guidelines \u2013 stating which part of the news organisation falls under the guidelines and must abide by them (table ) \u2013 the majority of documents are designed for the newsroom and journalists, constituting .% of the sample. about .% of the guidelines are intended for all departments within the news organisation. there is a single instance (.%) where the ai guidelines pertain to the business side only. none of the documents specify other remits, and there are no instances where the remit is not specified. table : title keywords used in the ai guidelines title keyword n % charter . framework . guidance . guide . guideline . how-to . letter . note . policy . position paper . principles . statement . other . none . **_total_** __ __ table : remit remit n % all departments . business development . newsroom/journalists . other not specified **_total_** __ __ the examination of accountability mechanisms \u2013 the question if ai guidelines will be enforced and compliance controlled in some way \u2013 (table ) indicates that only .% of the documents explicitly mention such mechanisms, while .% do not. moreover, the guidelines mostly lack details on how enforcement will occur. regarding the intended audience (which differs from remit as it specifies if the guidelines are meant for internal, external consumption or both), table shows that .% of the guidelines are directed towards internal stakeholders, .% towards external audiences, and .% are intended for both internal and external consumption. .% of guidelines furthermore mention one or several professional roles within the guidelines such as \u2018editor-in-chief\u2019 or \u2018legal staff\u2019 for whom the guidelines either apply in specific ways or who serve as points of contact for other people within the organisation. table : accountability n % yes . no . **_total_** __ __ table : ai guidelines\u2019 intended audiences n % internal . external . both . not specified **_total_** __ __ finally, on the dynamization of guidelines \u2013 the question if guidelines will be updated \u2013 .% stated that guidelines will be updated, .% did not mention the same. however, the timing of such updates appears to be an area of varied opinions, with a notable preference for a less rigid and more adaptable approach. out of the guidelines mentioning dynamization, only .% specified a particular interval for updates, with the majority (.%) leaving the same unspecified. thematic characteristics _journalistic values and conditions for use of ai_ we also analysed guidelines\u2019 reference to journalistic values drawing on deuze\u2019s classification of journalism\u2019s \u2018occupational ideology\u2019 that can be recognised worldwide (). these five traits include \u2018public service\u2019, \u2018objectivity\u2019, \u2018autonomy\u2019, \u2018immediacy\u2019, and \u2018ethics\u2019. overall, .% of the documents mention one or more of these journalistic values, while .% do not mention any. for allowed applications of ai in the journalistic process, .% of the documents explicitly state where ai is permitted, while .% do not provide such information. similarly, in relation to prohibited applications of ai in journalism, .% of the guidelines specify where ai cannot be deployed, whereas .% do not mention prohibited applications. in table , we provide additional breakdowns for allowed and prohibited ai applications along the chain of gatekeeping (adapted from domingo ., ). table : allowed and prohibited ai applications access & observation processing & filtering distribution n % n % n % yes , , , partial , no , , , not specified , , , **_total_** __ __ __ __ __ __ in .% of cases, guidelines also mentioned potential pitfalls of ai that staff should be aware of while .% did not refer to the same. the three most mentioned pitfalls in ai guidelines were hallucinations, wherein the ai fabricates facts, with e.g., one guideline stating that the organisation takes a \u2018source-critical approach to ai- generated material\u2019 in response. second, bias of ai models \u2013 the tendency to perpetuate existing biases, such as those based on race, gender, ethnicity, and other factors, thereby reinforcing societal inequalities \u2013 was frequently mentioned. finally, some guidelines expressed concerns about copyright and intellectual property, with aigenerated content violating licensing terms, plagiarising existing material, and potentially infringing on intellectual property rights. looking at the question if guidelines reference specific ais , ai engines or llms as examples of existing or possible ai deployment, we found an even split with .% citing examples (most commonly chatgpt, dall-e, and midjourney), while the remaining .% did not. _transparency and human supervision_ looking at forms of how to deal with the deployment of ai in the journalistic process, .% of organisations reference transparency \u2013 the fact that the use of ai has to be disclosed \u2013 in their ai guidelines. however, it should be noted that .% do not explicitly specify how this transparency should be communicated, as is evident from table . table : how to communicate transparency n % byline , endnote , text box , register entry , not specified , **_total_** __ __ looking at the qualitative results for all organisations who reference transparency, we see some further variation beyond the method of disclosure, namely on when and where this must happen. a few outlets are very prescriptive and detailed, with one outlet, for example, writing that \u2018the editorial team shall indicate when a news item or part of the information offering has been produced wholly or partly on the basis of automated processes and, as far as possible, refer to the sources on which the news item is based,\u2019 before listing examples. many are less specific with one recommending that ai use is labelled when ai \u2018is used as more than a mere aid,\u2019 but leaving this at the discretion of staff. overall, the emphasis seems to be on the use of ai for texts, followed by images, with content recommendation only receiving limited attention. when it came to human supervision of ai, .% of organisations stipulated supervision in some form. still, table shows that news organisations have no unanimous way of handling human supervision. table : human supervision area of supervision text/product algorithm anytime . sometimes . . never . not specified . **_total_** __ __ __ __ _responsible ai in journalism_ looking, next, at three specific forms of responsible ai \u2013 concern for data privacy, source protection, and algorithmic bias \u2013 we find a somewhat heterogenous picture as table shows. table : elements of responsible ai reference to... yes no **_total_** n % n % _n_ _%_ ... data privacy , , __ __ ... algorithmic bias , __ __ ... source protection , , __ __ **_average_** __ _,_ __ _,_ __ __ the qualitative data demonstrates that many guidelines emphasise the protection of vulnerable groups and contributors\u2019 privacy, urging against uploading or using confidential or sensitive information in ai engines. source protection is a recurring theme, with guidelines ensuring that ai platforms are not given access to sensitive, source-protected, or unpublished information, with one organisation for example writing that \u2018we protect the privacy of sources and do not share sensitive material or personal data.\u2019 similarly, for algorithmic bias, those guidelines that mention the same show e.g., concern for unfair discrimination stemming from biases in training data or caution against the use of ai that could lead to the \u2018discriminat[ion] against any individual or group based on race, ethnicity, religion, gender, sexual orientation, or any other characteristic.\u2019 _cooperation and dependency_ internal cooperation on ai between different departments within news organisations was present in .% of cases. organisations mentioned that they had \u2018several teams across departments studying ai\u2019 or outlined how ai was a topic for \u2018legal, tech, finance, hr\u2019 and all other departments. in terms of external cooperation with e.g., technology companies, consultants, researchers, or governments, .% of the guidelines mention the same. finally, on dependency , only .% of the surveyed news organisations\u2019 guidelines make any reference to possible dependencies on platform companies or other technology companies when it comes to the development and deployment of ai. one news organisation, for example stresses the importance of \u2018independence [\u2026] not only from political but also from technical influences\u2019 while another argues that \u2018greater independence from commercial big-tech providers is desirable.\u2019 the majority, .%, however, do not make any reference to dependency. ", "# discussion it is time to return to the questions we set out in the beginning, namely _to_ _what extent_ _international news organisations\u2019 ai guidelines exhibit isomorphic tendencies (rq),_ i.e., to what degree can we find homogeneity between them. the overall picture that emerges provides evidence for isomorphic tendencies leading to homogeneity, but within bounds. the syntactical similarity analysis supports that media organisations borrow wordings from each other when developing ai guidelines ( __ ). to the extent these borrowed wordings also encode meanings, the statistical comparison by cosine distances also supports the concept that ideas are shared across organisations. the results further indicate the presence of at least a moderate degree of isomorphism in ai guidelines as illustrated by the presence of an in-group cluster of organisations. on the matter of comparative convergence, the results offer some preliminary support to the idea that convergence has progressed further in editorial guidelines than in aiuse guidelines, which makes sense given the relative novelty of ai guidelines. editorial guidelines simply have had a longer time to converge. while the findings in figure (ai guidelines) clearly show the grouping dynamics and red tiles indicative of shared wordings and thus are consonant with on-going convergence, that convergence process has not progressed as far as it has in the editorial guidelines sample (figure ), which has more red-end-of-the-spectrum tiles. when it comes to ai guidelines on a syntactical level, the processes of isomorphism are nascent rather than fully developed. conceptual isomorphism ( __ ) may be a different story entirely, however. journalists and publishers may not use the same words for the same concepts even if there is broad agreement on the why, how, and what of ai guidelines in journalistic settings. and indeed, the quantitative coding results show homogeneity for almost two thirds of the variables (assuming a threshold of >%). on the _formal level_ , documents vary in length but most fall within the approximate range of to words. a majority governs the editorial realm of journalists and the newsroom (.%), mentions specific professional roles as relevant stakeholders (.%), states that the guidelines should be updated at some point (.%), but also lacks any reference to accountability mechanisms (.%). regarding the _thematic features_ , our coding again shows general patterns across publishers. .% refer to journalistic values, with \u2018trust\u2019 (.%) and \u2018accuracy\u2019 (.%) named most often. it is also common that ai guidelines cover at least some forms of allowed or prohibited applications, with more news outlets mentioning allowed (.%) than prohibited ones (.%). a majority of .% refers to possible pitfalls that can result from using ai in journalism. the documents were also quite homogenous in dealing with transparency and human supervision of ai-generated content. .% of news outlets refer to transparency, although most do not specify how to communicate the same, and .% stress the importance of human supervision, although such oversight is mostly applied to text generated or otherwise edited by ai. .% require human supervision at all times. regarding the quantitative coding, ai guidelines display a marked degree of homogeneity, especially compared to social media guidelines. while some difference remains, due to the distinct requirements of media organisations and the early stage of ai guideline development, the overall similarity across guidelines is striking, especially compared to the lack of similarity research has uncovered in social media guidelines. we turn next to more specific research questions ( _rq_ _a_ and _rq_ _b_ ) \u2013 if national and organisational idiosyncrasies continue to shape publishers\u2019 practices within the overall trend towards homogeneity. while the small sample size does not allow for rigorous statistical analysis and means that these cursory results must be interpreted with caution, we can see some variance across organisational types (commercial vs. public service) and country when looking \u2018under the hood\u2019. a difference seems to emerge mainly between publicly funded and commercial publishers \u2013 but not necessarily as expected. surprisingly commercial media organisations\u2019 guidelines seem to be more fine-grained and contain significantly more information on permitted and prohibited applications (see appendix, table ). for example, the protection of sources, which plays a role especially when sensitive information is entered into the interface of llms, is emphasised above all by commercial broadcasters and legacy newspapers (see appendix, table ), the latter are also significantly more concerned than average about data protection, perhaps owing to the risk legal liability poses to their business models. commercial media also make more statements about possible pitfalls of ai (see appendix, table ) which also ties in with the fact that this group more often tends to demand transparency in the use of ai and more frequently calls for human control of the products generated or edited by ai, compared to public media (see appendix, table ). so the conclusion that publicly funded broadcasters tend to establish a \u2018stricter ethical regime\u2019 than privately funded media outlets, as () have shown regarding social media guidelines, seems questionable for ai guidelines. where public media are ahead is the human control of algorithms; they are more aware of this topic than private-sector actors (see appendix, table ) \u2013 possibly due to their high degree of organisation and the associated professional specialisation within editorial teams. less surprising is that commercial media are somewhat more permissive when it comes to the use of ai than their publicly financed or public-service oriented counterparts (see appendix, table ). this seems especially true for news agencies which allow ai to be used across most levels of the journalistic process much more than the average (see appendix, table ), potentially owing to their early adoption of the technology. the data also shows _some variance across different countries_ ( _rq_ _b_ ). a set of four countries refers to journalistic values at least ten percentage points more often than average: belgium, canada, the united kingdom and germany (see appendix, table ). guidelines from belgium and finland allow for ai use more often than average on all three levels of the journalistic process (see appendix, table ). possible pitfalls of ai are most often mentioned by organisations in canada, norway, and (see appendix, table ). while many organisations make statements about transparency and human oversight, organisations in canada, the netherlands, switzerland, and the united kingdom are significantly above average (see appendix, table ). when it comes to elements of responsible ai (see appendix, table ), organisations in canada, the united kingdom, netherlands, and germany have a particularly strong emphasis on data privacy in their guidelines. algorithmic bias is covered most often by organisations in western europe, especially in the united kingdom, the netherlands, and switzerland. source protection, on the other hand, is mainly a topic for scandinavian countries, although outlets in canada and also mention this more often than average. finally, the analysis of current ai guidelines within news organisations also revealed _several blind spots (rq)_ . first, the vast majority of guidelines are essentially toothless regarding enforcement of violations or broader oversight of what they stipulate. similarly, while many organisations demand the supervision of output, oversight over algorithms and technical systems seems limited. a third notable absence are explicit directives regarding external collaborations, e.g., with technology vendors, researchers, or other stakeholders. given the increasing reliance on external expertise in the development and deployment of ai, guidelines could include provisions for transparent and ethical engagement with such actors. most ai guidelines also did not address questions of technological dependency, a factor that holds implications for the autonomy of news organisations (simon, ). few discussed safeguarding editorial independence and self-reliance when it came to ai. likewise, few organisations specified if and when their guidelines would be updated, a noteworthy omission considering the fast-moving nature of the field. in addition, we identified several blind spots in our qualitative coding that matter in as much as they are part of the current discourse around ai but were not discussed in the guidelines at all. first, while serving audiences was often mentioned, solicitating audience feedback on guidelines or engaging audiences on ai use was conspicuously absent \u2013 an interesting facet amidst industry discussions stressing the need for greater audience engagement. likewise, references to recent debates around sustainable ai and ai supply chains (brown, ; van wynsberghe, ) which shed light on the environmental and societal impact and harm of ai development and use, were notably absent. the impact of ai use on existing power asymmetries (, ), especially with respect to local and cultural diversity, received only fleeting references in very few instances. similarly, issues of workplace surveillance through ai (ebert ., ), data colonialism (couldry & mejias, ), labour exploitation and potential human rights abuses associated with ai training received no attention from any of the guidelines. the oversight of these facets underscores the need for a more comprehensive integration of ethical considerations. limitations it is worth briefly dwelling here on the limitations of this study. first, the uneven distribution of sources across different geographical regions is a notable caveat. our reliance on a larger number of german sources in comparison to sources from other regions introduces a potential source of bias in the findings. the sample size, while valuable for exploratory insights and exceeding previous research, remains limited in its scope. this limitation is particularly pronounced when considering the global south, which is inadequately represented here despite concerted efforts to include guidelines from more news organisations in india and brazil. moreover, the study encountered restrictions in accessing guidelines from certain organisations. some publishers acknowledged having or working on guidelines but were unwilling to share them. from background conversations we learned that often this could be attributed to concerns surrounding divulging proprietary strategies and thus potentially losing a competitive advantage. some were also concerned about looking amateurish vis-\u00e0-vis their peers if they released guidelines too early. organisations might also be wary of disclosing their approaches to issues such as dependency on major technology corporations, lest it jeopardise their response to the same. furthermore, it should be acknowledged that this study does not encompass the entirety of internal guidelines that some organisations have, with a number of organisations maintaining more extensive internal guidelines that in some but not all cases were beyond our purview. these internal documents often provide more granular instructions for staff members, beyond what is publicly available. it is important to note that our analysis examines the outcome \u2013 homogeneity \u2013 of a process that has likely already occurred (though it is likely to be still ongoing at the time of writing). but while we can assume that an isomorphic process has transpired (and can elaborate on potential driving factors), we cannot establish causality or definitively prove that this has been the case. this aspect will require further research and delving into the motivations behind these guidelines and the processes shaping their creation. ", "# conclusion institutional isomorphism offers plausible explanations for our observations. dimaggio & powell contend that \u2018the greater the extent to which technologies are uncertain or goals are ambiguous within a field, the greater the rate of isomorphic change\u2019 (, p. ). this certainly holds true for the current state of ai in journalism. the uncertainty surrounding the trajectory of the technology is significant and many organisations are grappling with defining their goals for ai. moreover, the more ambiguous ai\u2019s nature, what it could enable, and what should crucially be done about it, the more likely organisations will emulate successful entities that preceded them. certain guidelines, such as those of the and bayerischer rundfunk, which have gained widespread attention through industry publications and conferences, have served as influential benchmarks for others. additional predictors of isomorphism include the strong professionalism evident in journalism, both nationally and globally. journalism is becoming more internationally connected, facilitated by digital media, the exchange of labour, and collaborations among major players. in the ai domain, the core community working on it remains relatively small, and initiatives like the london school of economic\u2019s journalism ai initiative provide vital platforms for idea exchange. both could have contributed to similar patterns emerging in the guidelines of international news organisations. ultimately, it should not be forgotten that both the race to ai and the establishment of ai guidelines are also a quest for legitimacy. formulating an ai policy \u2013 one that resembles those of successful organisations and accedes to common demands on how ai should be used and regulated \u2013 also functions as a form of signalling. by having an ai policy, a publisher conveys some important information about themselves, in this case likely to make their commitment to the ethical use of ai observable and to show to competitors that yes, they too, are innovative. this, of course, ultimately raises the point who and what ai guidelines are really for \u2013 are they a mere pr exercise, dressed up in form of a policy or a meaningful contribution to regulating a technology in the face of uncertainty. while only future research will be able to answer this question, we can assume that reality is more nuanced. publicly, at least, many organisations assert that their motivation behind formulating such guidelines stems from the dynamic nature of the environment in which they operate, with guidelines intended to serve as an initial framework, offering a sense of security to staff, readers, and partners. many seem to have emerged in response to both internal calls for direction and a perceived need to address external demands. establishing legitimacy is part of the answer, not the whole story. lastly, isomorphism theory argues that a field\u2019s dependence on a single source leads to greater isomorphism. where dimaggio & powell referred to a \u2018single source of support for vital resources\u2019 (, p. ) and resource centralisation, ai, as a large technological system (simon, ), comes into play. one does not have to fully embrace technological determinism to assume that ai has a shaping power of its own. it thus acts as a coercive force with broadly similar effects across contexts, resulting in analogous reactions, including in the development of ai guidelines. while we could hypothesise that all organisations developing ai policies simply began at similar starting points with equivalent concerns and knowledge about the technology, it is also considerably less elegant as a theory to explain the similarities we can observe. occam\u2019s razor would suggest that they modelled aspects of their policies on each other. with this paper we hope to help lay the groundwork for future analysis and work in this area. we are at juncture on the road to more substantive ai use and, by extension, regulation in journalistic work. one should nevertheless remember that many ai guidelines are early examples, developed quickly in response to the launch of chatgpt and due to concerns about the speed with which generative AI became accessible to the public and journalists. and while the notion that ai guidelines in and of themselves will somehow magically resolve the intricacies of ai implementation and its attendant challenges is questionable, they can potentially make an important contribution in ensuring the responsible, ethical, and effective use of the technology in the news. part of the significance of these findings also lies in the fact that this selfregulation for ai is well underway, with a sizable number of publishers having begun to establish strategies addressing various critical aspects of the technology. crucially, while there remains ample room for improvement, these pioneering organisations, many of them leaders in the news industry, are poised to influence and set a precedent for broader industry practices, thus facilitating a trickle-down effect of their ai guidelines and strategies. how unanimous these will and should be remains to be seen. for now, we can see that there are some overlapping trends among ai guidelines but also a considerable degree of variety and we withhold judgment at this point if this is to be celebrated or rectified. future questions abound. for one, ai guidelines often emerge from internal consultation processes that involve various departments, sometimes building upon preexisting materials. one question here will be which \u2018tribes\u2019 \u2013 editorial, business, tech \u2013 within news organisations will exert dominance in shaping the ideas and logics embedded in these guidelines. a second line of inquiry pertains to what kinds of organisations that release or craft both internal and external ai guidelines. understanding which organisations engage in this practice and the reasons behind those that opt not to (be it due to deeming guidelines unnecessary or as potential hindrances to their operations) will tell us something about the future direction of ai in journalism. finally, against the backdrop of industry efforts to develop a set of principles, rights, and obligations regarding the use of ai-based systems, the question looms along which lines these guidelines will develop. will we have more standardisation and homogeneity, or will we see more customisation in the future? for now, publishers seem to embark on this journey from somewhat similar points. ", "# funding felix would like to thank the oii-dieter schwarz scholarship for supporting his doctoral studies and for providing core funding for this study. ", "###### living guidelines for generative AI \u2014 why scientists must oversee its use **article** _in_ nature \u00b7 doi: ./d--- citations reads ** authors** , including:  h bockting university medical centers amsterdam **** publications **,** citations see /profile/claudi-bockting?enrichid=rgreq-fababbaddaeaafbdf-xxx&enrichsource=yzxjqywdlozmndgndcndtbuzoxmtqzmtimtiwmdkwnzyyoeaxnjkmtmntymjg&el=_x_&_esc=publicationcoverpdf) /profile/=rgreq-fababbaddaeaafbdf-xxx&enrichsource=yzxjqywdlozmndgndcndtbuzoxmtqzmtimtiwmdkwnzyyoeaxnjkmtmntymjg&el=_x_&_esc=publicationcoverpdf) [institute for logic, language & computation **** publications **,** citations [see /profile/=rgreq-fababbaddaeaafbdf-xxx&enrichsource=yzxjqywdlozmndgndcndtbuzoxmtqzmtimtiwmdkwnzyyoeaxnjkmtmntymjg&el=_x_&_esc=publicationcoverpdf) ", "## comment ", "### living guidelines for generative AI \u2014 why scientists must oversee its use **, , , ** ", "###### establish an independent scientific body to test and certify generative AI, before the technology damages science and public trust. after the technology firm openai released the chatbot chatgpt, companies are in an arms race to develop \u2018generative\u2019 artificial-intelligence (ai) systems that are ever more powerful. each version adds capa bilities that increasingly encroach on human skills. by producing text, images, videos and even computer programs in response to human prompts, generative AI systems can make infor mation more accessible and speed up technol ogy development. yet they also pose risks. ai systems could flood the internet with misinformation and \u2018deepfakes\u2019 \u2014 videos of synthetic faces and voices that can be guishable from those of real people. in the long run, such harms could erode trust between people, politicians, the media and institutions. the integrity of science itself is also threat ened by generative AI, which is already ing how scientists look for information, conduct their research and write and evaluate publications. the widespread use of commer cial \u2018black box\u2019 ai tools in research might introduce biases and inaccuracies that diminish the validity of scientific knowledge. generated outputs could distort scientific facts, while still sounding authoritative. the risks are real, but banning the technol ogy seems unrealistic. how can we benefit from generative AI while avoiding the harms? governments are beginning to regulate ai technologies, but comprehensive and effec tive legislation is off (see _nature_ **** , \u2013; ). the draft european union **lawmakers at the european parliament in strasbourg, france, voted on the draft ai act in .** ai act (now in the final stages of negotiation) demands transparency, such as disclosing that content is ai-generated and publishing summaries of copyrighted data used for training ai systems. the administration of us president aims for self-regulation. in , it announced that it had obtained volun tary commitments from seven leading tech companies \u201cto manage the risks posed by artificial intelligence (ai) and to protect amer icans\u2019 rights and safety\u201d. digital \u2018watermarks\u2019 that identify the origins of a text, picture or video might be one mechanism. in , the cyberspace administration of china announced that it will enforce ai regulations, including requiring that generative AI devel opers prevent the spread of mis information or content that challenges chinese socialist values. the uk government, too, is organizing a summit in at bletchley park near in the hope of establishing inter governmental agreement on limiting ai risks. in the long run, however, it is unclear whether legal restrictions or self-regulation will prove effective. ai is advancing at breakneck speed in a sprawling industry that is continuously reinventing itself. regulations drawn up will be outdated by the time they become official policy, and might not anticipate future harms and innovations. in fact, controlling developments in ai will require a continuous process that balances expertise and independence. that\u2019s why scientists must be central to safeguarding the impacts of this emerging technology. researchers must take the lead in testing, proving and improving the safety and security of generative AI systems \u2014 as they do in other policy realms, such as health. ideally, this work would be carried out in a specialized institute that is independent of commercial interests. however, most scientists don\u2019t have the facilities or funding to develop or evaluate generative AI tools independently. only a handful of university departments and a few big tech companies have the resources to do so. for example, invested us$ bil lion in openai and its chatgpt system, which was trained on hundreds of billions of words scraped from the internet. companies are unlikely to release details of their latest models for commercial reasons, precluding independ ent verification and regulation. society needs a different approach . that\u2019s why we \u2014 specialists in ai, generative AI, com puter science and psychological and social impacts \u2014 have begun to form a set of \u2018living guidelines\u2019 for the use of generative AI. these were developed at two summits at the institute for advanced study at in april and , jointly with members of multinational scientific institu tions such as the international science council, the university-based institutes for advanced study and and arts. other partners include global institu tions ( and its cultural organ ization, ) and the in boston, massachusetts, which advises the global ai action alliance of the world economic forum (see supplementary information for co-developers and affiliations). policy advisers also participated as observers, including representatives from the organisa tion for economic co-operation and development () and . here, we share a first version of the living guidelines and their principles (see \u2018living guidelines for responsible use of generative AI in research\u2019). these adhere to the universal declaration of human rights, including the \u2018right to science\u2019 (article ). they also comply with \u2019s recommendation on the ethics of ai, and its human-rights-centred approach to ethics, as well as the \u2019s ai principles. **key principles of the living** **guidelines** first, the summit participants agreed on three key principles for the use of generative AI in research \u2014 accountability, transparency and independent oversight. **accountability.** humans must remain in the loop to evaluate the quality of generated content; for example, to replicate results and identify bias. although low-risk use of gener ative ai \u2014 such as summarization or checking grammar and spelling \u2014 can be helpful in research, we advocate that crucial tasks, such as writing manuscripts or peer reviews, should not be fully outsourced to generative AI. **transparency.** researchers and other stakeholders should always disclose their use of generative AI. this increases awareness and allows researchers to study how generative AI might affect research quality or decision-making. in our view, developers of generative AI tools should also be transparent about their inner workings, to allow robust and critical evaluation of these technologies. **independent oversight.** external, objec tive auditing of generative AI tools is needed to ensure that they are of high quality and used ethically. ai is a multibillion-dollar industry; the stakes are too high to rely on self-regulation. six steps are then needed. **set up a scientific body to audit ai** **systems** an official body is needed to evaluate the safety and validity of generative AI systems, including bias and ethical issues in their use (see \u2018an auditor for generative AI\u2019). it must have sufficient computing power to run full-scale models, and enough information about source codes to judge how they were trained. the auditing body, in cooperation with an independent committee of scientists, should develop benchmarks against which ai tools are judged and certified, for example with respect to bias, hate speech, truthfulness and equity. these benchmarks should be updated regularly. as much as possible, only the auditor should be privy to them, so that ai developers cannot tweak their codes to pass tests superficially \u2014 as ", "#### living guidelines for responsible use of generative AI in research **a first version of the guidelines and their** **underlying principle** **researchers, reviewers and editors of** **scientific journals** . because the veracity of generative AI-generated output cannot be guaranteed, and sources cannot be reliably traced and credited, we always need human actors to take on the final responsibility for scientific output. this means that we need human verification for at least the following steps in the research process: - interpretation of data analysis; - writing of manuscripts; - evaluating manuscripts (journal editors); - peer review; - identifying research gaps; - formulating research aims; - developing hypothese . researchers should always acknowledge and specify for which tasks they have used generative AI in (scientific) research publications or presentation . researchers should acknowledge which generative AI tools (including which versions) they used in their work. . to adhere to open-science principles, researchers should preregister the use of generative AI in scientific research (such as which prompts they will use) and make the input and output of generative AI tools available with the publication. . researchers who have extensively used a generative AI tool in their work are recommended to licate their findings with a different generative AI tool (if applicable). . scientific journals should acknowledge their use of generative AI for peer review or selection purpose . scientific journals should ask reviewers to what extent they used generative AI for their revie **llm developers and companies** . generative AI developers and companies should make the details of the training data, training set-up and algorithms for large language models (llms) fully available to the independent scientific organization that facilitates the development of an auditing body (see \u2018an auditor for generative AI\u2019) before launching it to society. . generative AI developers and companies should share ongoing adaptations, training sets and algorithms with the independent scientific auditing body. . the independent scientific auditing body and generative AI companies should have a portal where users who discover biased or inaccurate responses can easily ort them (the independent scientific auditing body should have access to this portal and actions taken by the company). **research funding organizations** . research (integrity) policies should adhere to the living guideline . research funding organizations should not (completely) rely on generative AI tools in evaluating research funding proposals, but always involve human assessment. . research funding organizations should acknowledge their use of generative AI tools for evaluating research proposal guidelines co-developed with olivier bouin, mathieu denis, , , , saadi lahlou, yvonne donders, , verbeek (see supplementary information for co-developers\u2019 affiliations). for example), while the auditing body would examine whether a particular ai application might infringe this right (such as by produc ing deep fakes). an ai application that fails certification can still enter the marketplace (if policies don\u2019t restrict it), but individuals and institutions adhering to the guidelines would not be able to use it. these approaches are applied in other field for example, clinical guidelines committees, such as the stroke foundation in australia, have adopted living guidelines to allow patients to access new medicines quickly (see go.. com/qdph). the foundation now updates its guidelines every three to six months, instead of as it did previ ously. similarly, the australian national clinical evidence taskforce for updated its recommendations during the pandemic, on average . another example is the transparency and openness promotion (top) guidelines for pro moting open-science practices, developed by the center for open science . a metric called top factor () allows researchers to easily check whether journals adhere to open-science guideline a similar approach could be used for ai algorithm **obtain international funding to** **sustain the guidelines** financial investments will be needed. the auditing body will be the most expensive element, because it needs computing power comparable to that of openai or a large uni versity consortium. although the amount will depend on the remit of the body, it is likely to require at least $ billion to set up. that is roughly the hardware cost of training gpt- (a proposed successor to , the large lan guage model that underlies chatgpt). to scope out what\u2019s needed, we call for an interdisciplinary scientific expert group to be set up in , at a cost of about $ million, which would ort back within . this group should sketch scenarios for how the auditing body and guidelines com mittee would function, as well as budget plan some investment might come from the public purse, from research institutes and nation state tech companies should also contribute, as outlined below, through a pooled and independently run mechanism. **seek legal status for the guidelines** at first, the scientific auditing body would have to operate in an advisory capacity, and could not enforce the guideline however, we are hopeful that the living guidelines would inspire better legislation, given interest from leading al organizations in our dialogue for comparison, the club of rome, a research and advocacy organization aimed at raising environmental and societal awareness, has no direct political or economic power, yet still has **us president (centre) at a us panel discussion on artificial intelligence in .** has happened in the car industry . the auditor could examine and vet training data sets to prevent bias and undesirable content before generative AI systems are released to the public. it might ask, for example, to what extent do interactions with generative AI dis tort people\u2019s beliefs or vice versa? this will be challenging as more ai products arrive on the market. an example that highlights the difficul ties is the helm initiative, a living benchmark for improving the transparency of language models, which was developed by models in california (see go..com/revyc). certification of generative AI systems requires continuous revision and adaptation, because the performance of these systems evolves rapidly on the basis of user feedback and concern questions of independence can be raised when initiatives depend on industry support. that is why we are proposing living guidelines developed by experts and scientists, supported by the public sector. the auditing body should be run in the same way as an international research institution \u2014 it should be interdisciplinary, with five to ten research groups that host specialists in com puter science, behavioural science, psychology, human rights, privacy, law, ethics, science of science and philosophy. collaborations with the public and private sectors should be main tained, while retaining independence. and advisers should include people from disadvantaged and under-resented groups, who are most likely to experience harm from bias and misinformation (see \u2018an auditor for generative AI\u2019 and go..com/regxm). similar bodies exist in other domains, such as the us , which assesses evidence from clinical trials to approve products that meet its standards for safety and effectivenes the center for open science, an international organization based in charlottesville, virginia, seeks to develop regulations, tools and incentives to change scientific practices towards openness, integrity and roducibility of research. what we are proposing is more than a kitemark or certification label on a product, although a first step could be to develop such a mark. the auditing body should proactively seek to prevent the introduction of harmful ai **\u201cthe living guidelines will** **need to address ai literacy** **so that the public can make** **safe and ethical use of** **generative AI tool** **\u201d** products while keeping policymakers, users and consumers informed of whether a product conforms to safety and effectiveness standard **keep the living guidelines living** crucial to the success of the project is ensuring that the guidelines remain up to date and aligned with rapid advances in generative AI. to this end, a second committee composed of about a dozen diverse scientific, policy and technical experts should meet to review the latest development much like the ai risk management frame work of , for example, the committee could map, measure and manage risk this would require close communication with the auditor. for example, living guidelines might include the right of an individual to control exploitation of their identity (for publicity, a large impact on international legislation for limiting al warming. alternatively, the scientific auditing body might become an independent entity within , similar to the international atomic energy agency. one hurdle might be that some member states could have conflict ing opinions on regulating generative AI. fur thermore, updating formal legislation is slo **seek collaboration with tech** **companies** tech companies could fear that regulations will hamper innovation, and might prefer to self-regulate through voluntary guidelines rather than legally binding one for exam ple, many companies changed their privacy policies only after put its general data protection regulation into effect in (see go..com/tendu). however, our approach has benefit auditing and regulation can engender public trust and reduce the risks of malpractice and litigation. these benefits could provide an incentive for tech companies to invest in an independent fund to finance the infrastructure needed to run and test ai system however, some might be reluctant to do so, because a tool failing quality checks could produce unfavourable ratings or evaluations leading to negative media coverage and declining share another challenge is maintaining the independence of scientific research in a field dominated by the resources and agendas of the tech industry. its membership must be man aged to avoid conflicts of interests, given that these have been demonstrated to lead to biased results in other fields , . a strategy for dealing with such issues needs to be developed . **address outstanding topics** several topics have yet to be covered in the living guideline one is the risk of scientific fraud facilitated by generative AI, such as faked brain scans that journal editors or reviewers might think are authentic. the auditing body should invest in tools and recommendations to detect such fraud . for example, the living guidelines might include a recommendation for editors to ask authors to submit high-resolution raw image data, because current generative AI tools generally create low-resolution images . another issue is the trade-off between copyright issues and increasing the accessi bility of scientific knowledge . on the one hand, scientific publishers could be moti vated to share their archives and databases, to increase the quality of generative AI tools and to enhance accessibility of knowledge. on the other hand, as long as generative AI tools obscure the provenance of generated content, users might unwittingly violate intellectual property (even if the legal status of such infringement is still under debate). the living guidelines will need to address ai literacy so that the public can make safe and ethical use of generative AI tool for example, a study demonstrated that chatgpt might reduce \u2018moral awareness\u2019 because individuals confuse chatgpt\u2019s random moral stances with their own . all of this is becoming more urgent by . as generative AI systems develop at lightning speed, the scientific community must take a central role in shaping the future of responsible generative AI. setting up these bodies and funding them is the first step. **the authors** *** is professor of clinical psychology in psychiatry at amsterdam umc, department of psychiatry, ; and co-director at the centre for urban mental health at , university of amsterdam, the netherland *** is a postdoctoral researcher and psychologist at amsterdam umc, department of psychiatry, , the netherland *** is director of, and professor of logic and cognition at, the institute for logic, language and computation, university of amsterdam, the netherland **willem zuidema** is an associate professor in natural language processing, explainable ai and cognitive modelling at the institute for logic, language and computation, university of amsterdam, the netherland **johan ** is professor of informatics and cognitive science, and director of the center for social and biomedical complexity at , . a full list of guideline co-developers\u2019 affiliations accompanies this comment online (see go..com/arae). e-mail: c.l.bockting@amsterdamumc.nl . , , , , zuidema, , , , _ **** , \u2013 (). . jung, c., , e. _. bu organ. excel._ **** , \u2013 (). . , , _ **** , (). . and technology. _artificial intelligence risk management framework_ _(ai rmf .)_ ort no. nist ai - (nist, ). . , _et _ **** , \u2013 (). . nosek, et science_ **** , \u2013 (). . de jonge, , n. engl. med._ **** , \u2013 (). . bekelman, e., , jama_ **** , \u2013 (). . , m. (eds). _conflict of interest in medical_ _research, education, and practice_ (national academies press, ). . , k. \u2018thanks to generative AI, catching fraud science is going to be this much harder\u2019 _the register_ ( march ). . gu, _et patterns_ **** , (). . , p. _science_ **** , \u2013 (). . , , , m. _sci. _ . **** , (). **the authors declare no competing interest** ", "#### an auditor for generative AI **this scientific body must have the** **following characteristics to be effective.** . the research community and society need an independent (mitigating conflicts of interest), international (including representatives of the global south) and interdisciplinary scientific organization that develops an independent body to evaluate the generative AI tools and their uses in terms of accuracy, bias, safety and security. . the organization and body should at least include, but not be limited to, experts in computer science, behavioural science, psychology, human rights, privacy, law, ethics, science of science and philosophy (and related fields). it should assure, through the composition of the teams and the implemented procedures, that the insights and interests of stakeholders from across the sectors (private and public) and the wide range of stakeholder groups are represented (including disadvantaged groups). standards for composition of the team might change over time. . the body should develop quality standards and certification processes for generative AI tools used in scientific practice and society, which cover at least the following aspects: - accuracy and truthfulness; - proper and accurate source crediting; - discriminatory and hateful content; - details of the training data, training set-up and algorithms; - verification of machine learning (especially for safety-critical systems). . the independent interdisciplinary scientific body should develop and deploy methods to assess whether generative AI fosters equity, and which steps generative AI developers can take to foster equity and equitable uses (such as inclusion of less common languages and of diverse voices in the training data). see \u2018living guidelines for responsible use of generative AI in research\u2019 for a list of guideline co-developers. ", "# aain generative AI guidelines australian academic integrity network (aain) generative AI working group, ", "## guidelines for students . according to [advice to /students/artificial-intelligence-advice-students) from the tertiary education quality and standard agency (teqsa), \u2018it\u2019s important to understand that, depending on your university or college\u2019s policies, using ai as part of your studies may be restricted or banned. alternatively, there might be subjects or tasks where the use of ai is encouraged or even required\u2019 (teqsa, ). . students need to develop ai literacy skills, in addition to traditional information literacy skills (bundy, ) and generic digital literacy skills. ai literacy skills enable \u2018individuals to critically evaluate ai technologies; communicate and collaborate effectively with ai; and use ai as a tool online, at home, and in the workplace\u2019 (, :). _aain generative AI working group_ __ __ . students should use ai models in ethical and responsible ways that are consistent with their institution\u2019s learning, assessment and academic integrity policies and procedures, and the terms of use of the ai providers. . ethical use of generative AI includes an obligation to follow institutional guidelines regarding the use of generative AI in any unit or course, and an understanding that it may not be appropriate to use generative AI in all circumstances. students should follow their institutional guidelines. . students should check any output from generative AI against reliable sources of information and understand that they will be responsible for any errors or omissions in material generated by ai. . students are required to identify ai models, tools and/or prompts that are appropriate for their discipline and acknowledge the use of ai in written assessments following any guidelines provided by their institution. if it is not possible to identify and cite the original sources used in output from ai, this may result in plagiarism and academic misconduct. students also need to be aware of the possibility of \u201challucinated references\u201d or the tendency of generative AI language models to make up references from constituent parts of actual references. . students should acknowledge the use of generative AI language models in assessment tasks, following any guidelines provided by their institution. they should describe the way they have used the tool and integrated the results into their work, as appropriate to the specific guidelines within their discipline, unit or course. . the unauthorised use of ai language models or paraphrasing tools may be a form of cheating and may result in academic misconduct. work submitted (including work generated by ai), and not cited or referenced, must be your own original work. . students need to be aware that using the output from ai models without appropriate acknowledgement may constitute academic misconduct. if unsure, students should confirm assessment requirements with teaching staff or seek advice on how to acknowledge the output from ai from academic support services, such as their library or other academic services. . where appropriate, students should familiarise themselves with any relevant expectations of or constraints on the use of generative AI related to their future professional accreditation and be aware that these may be updated. ", "## guidelines for teaching staff . all students will need to develop capabilities in the ethical use of generative AI relevant to their discipline and future professional practice through ethical engagement with generative AI tools in learning and teaching activities and assessment. existing and likely future uses of ai in professional contexts and in platforms such as office and search engines need to be considered when developing unit or course learning outcomes, activities, and assessment. . expectations regarding the appropriate use of generative AI in assessment tasks and learning activities should be consistent with institutional guidelines and require clear communication to students. this includes clear instructions in student facing documentation, for example, in learning guides and through the learning management system. expectations should align with ai provider terms of use and with curriculum requirements. . to ensure procedural fairness, it is important to communicate to students any inappropriate uses of generative AI that may result in academic misconduct. students should be aware of the potential for detection software (e.g., turnitin) to detect generative AI use and that they are _aain generative AI working group_ __ __ risking academic misconduct if using generative AI without appropriate acknowledgement by following the referencing guidelines provided by their institution. . having conversations with students early in units and courses will improve a shared understanding of how and when they can use ai tools. students will benefit from examples of how and when generative AI have been used and acknowledged, and which tools to use. . students should be aware of the limits of generative AI. limitations of generative AI include biased or negative responses due to interaction with a \u201craw model\u201d. another limitation is the potential for \u201cai hallucinations\u201d which results when the system provides a response that is not factual. this may be due to inadequate training of the model or the system\u2019s inability to interpret specific data. a further limitation is that of currency; the responses given by the generative AI model will only be as up to date as the information in its training data. . students should have opportunities to develop ai literacy. many providers will be developing tools and resources to assist students to learn to use generative AI in ways that are appropriate to their institutional context. students should be aware of resources developed in their institution and across the sector. as an example, library digital]() essentials module is free to use and adapt under creative commons (with attribution). . ai tools may be used within institutional guidelines to support learning and assessment design, e.g., to generate assessments, feedback forms and exams. however, critical evaluation of generative AI output is required to ensure appropriateness against learning outcomes. . unit and course learning outcomes, assessment tasks and marking criteria may require review to incorporate the ethical use of generative AI, or to indicate when not permitted, following any institutional expectations or guidelines. any revisions should align with institutional requirements and any accreditation requirements. . in designing formative and summative assessment tasks, teaching staff should consider the capabilities of generative AI. for example, assessment tasks that award marks for summarising a topic area and online quizzes may no longer be useful measures of student achievement and new approaches may be required to promote creativity and originality. ", "## guidelines for academic support staff and misconduct teams . library staff and academic/learning advisors support students to develop academic skills and academic integrity by: a. promoting the ethical and responsible use of ai tools in academic writing and research b. providing guidance on correct attribution and acknowledgement conventions to be used when incorporating generative AI outputs c. providing advice and training to enable and enhance clients\u2019 effective use of ai tools d. providing information and links to approved ai tools that are available to clients. . governance offices need to update and maintain policies and procedures to facilitate the investigation of potential academic misconduct. this includes but is not limited to ensuring definitions of types of misconduct are up to date and consider contemporary forms of misconduct and ensuring that policies are updated outside regular review cycles if needed (teqsa, b). . training provided to staff investigating alleged misconduct to maintain current, relevant knowledge on changes in policies as well as trends in permitted use of ai tools. _aain generative AI working group_ __ __ . staff involved in processing academic misconduct relating to the inappropriate use of generative AI models need to consider how they might include early educative interventions in institutional policies and procedures, prior to imposing punitive measures. ", "## guidelines for higher education providers . policies and procedures should provide guidance on the ethical use of generative AI, accommodating diverse approaches across disciplines. changes should be communicated to staff and students. . generative AI policies and procedures should be treated as live documents, reviewed and updated regularly as the technology continues to shift and evolve. . providers need to consider and address any ongoing resource demands associated with adapting to generative AI. . university administrators and managers should engage with external partners, such as community members, members of relevant professions and professional bodies and other partners, to facilitate open communication on research, teaching and other engagement with generative AI. providers need to learn from and address partner concerns and mitigate potential risks including risks to institutional reputation. . ai applications that are required for units and courses should made available by providers at no additional cost to students, to ensure equitable access. . learning and teaching support units should develop, maintain, and update relevant professional learning resources to support academic staff in the use of generative AI in learning, teaching and assessment. these programs need to include implications of existing and future likely uses of ai in professional contexts for learning, teaching and assessment. _aain generative AI working group_ __ __ ", "# acceptable uses of generative AI services at iu on this page: overview precautions acceptable uses learn more and get help ", "## overview note: has begun rebranding bing chat enterprise as copilot. during this transition, you may see either name. this is distinct from the copilot service, which currently has limited availability at iu. since , there has been an exponential increase in the investment and development of generative AI (ai) services. generative AI is a type of artificial intelligence system that generates new text, images, or other media in response to prompts. notable generative AI systems include chatgpt, copilot, and google bard. ", "## precautions generative AI has potential applications across a wide range of industries, including art, writing, and software development. however, there are also concerns about the potential misuse of these tools and any data shared with the services. when you provide information to these tools, such as queries, student essays, grant proposals, source code, or datasets, it is the same as posting the information on a public website. encourages its affiliates to experiment with using these generative AI services, as long as no institutional data is submitted to them without approval. at iu, copilot \ue164 () (formerly bing chat enterprise) is available for use by iu faculty and staff, and it is the recommended way to use generative AI within the iu environment. as part of the university's enterprise agreement with , copilot is approved to interact with data classified up to and including university-internal data /data-classifications/university-internal-data.html) [(- data.html). to use copilot, you must be logged in with your at iu \ue164 (/? whr=iu.edu) account (your `@iu.edu` email address and your iu passphrase (acpu)). for information about browser and app compatibility, see about bing chat enterprise/copilot at iu (bing). to date, no other generative AI tools have been approved for data beyond public classification, and these have not been through the software and services selection process (sssp). prior to the sharing of any institutional data, these services will need to go through review to ensure the necessary contracts and safeguards are in place to protect the data submitted and to ensure the algorithms in use are ethical, transparent, and beneficial to the iu community. skip to content types of institutional data that should not be submitted to public versions of generative AI tools, even when anonymized skip to search , include: anonymized skip to search ()) any data that may be considered student, faculty, or staff intellectual property, unless the individual submitting that intellectual property created it specific examples that are not appropriate for the public versions of generative AI tools include: sharing names and information about a real student, employee, research participant, or patient asking an ai service to summarize and grade a student paper or assignment sharing employee-related data such as performance or benefit information for communication drafting or analysis asking an ai service to generate code for iu systems protecting institutional data or sharing iu source code for editing sharing grant proposals still under review ", "## acceptable uses with these precautions in mind, there are numerous ways to use generative AI tools without submitting university data or intellectual property. using general queries to generate content to pull information from the ai resources is a good way to engage with the products. students should use generative AI in ways that align with university academic integrity policies and communicate with their instructors before using generative AI in their coursework. schools and departments may elect to further restrict generative AI. from a data management perspective, examples of acceptable uses of generative AI include: syllabus and lesson planning: instructors can use generative AI to help outline course syllabi and lesson plans, getting suggestions for learning objectives, teaching strategies, and assessment methods. course materials that the instructor has authored (such as course notes) may be submitted by the instructor. correspondence when no student or employee information is provided: students, faculty, or staff may use fake information (such as an invented name for the recipient of an email message) to generate drafts of correspondence using ai tools, as long as they are using general queries and do not include institutional data. professional development and training presentations: faculty and staff can use ai to draft materials for potential professional development opportunities, including workshops, conferences, and online courses related to their field. event planning: ai can assist in drafting event plans, including suggesting themes, activities, timelines, and checklists. reviewing publicly accessible content: ai can help you draft a review, analyze publicly accessible content (for example, proposals, papers and articles) to aid in drafting summaries, or pull together ideas. even if you use generative AI tools for activities that do not share personal or institutional data, you should still check the tool's output for accuracy. since these tools have been known to produce inaccurate content (sometimes called \"hallucinations\"), verify any factual information generated by an ai tool, and make sure to reference the tool as you would any other source. skip to content skip to search if you have any privacy-related concerns about generative AI tools, or questions about the type of data that can be shared with it, email `privacy@iu.edu` . for more information, see: ai at iu \ue164 () precautions about using chatgpt at iu (bigz) about bing chat enterprise/copilot at iu (bing) about ai detection tools (bimt) this is document biit in the knowledge base. last modified on :: . w.facebook.com/iu.uits) () () ( ", "### connect with uits contact us() have a question? askiu () chat with a consultant () email the uits support center () research technology support (/) ", "### find staff directory (/) careers (/) facilities () ", "### services one.iu (/) canvas (/) zoom () ", "### resources knowledge base (/) web content management system () skip to content it training (/) skip to search about email at iu () exchange () accessibility (/) privacy (/d/priv) copyright () \u00a9 the trustees of () ", "# generative AI policy proposed date: approved by: official: academic dean **generative AI policy** (portions adapted from middle tn state university and ) the rapid development and widespread availability of ai raises ethical concerns for academic integrity. it is imperative that all work submitted should be your own. use of generative AI, including but not limited to, chat , , midjourney, dall-e, etc., is explicitly prohibited unless otherwise noted by the instructor. the information derived from these tools is based on previously published materials. therefore, using these tools without proper citation constitutes plagiarism. additionally, be aware that the information derived from these tools is often inaccurate or incomplete. any assignment that is found to have been plagiarized or to have used unauthorized ai tools may be subject to disciplinary action as an academic integrity violation. the instructor maintains the right to investigate whether the submitted work is original. **syllabus language** (portions adapted from ) **academic integrity:** academic integrity is to be maintained at all times to ensure genuine educational growth. students are expected to generate their own original work. cheating and plagiarism in all forms, including unauthorized use of generative AI, will be subject to disciplinary action. serious infractions will be addressed by the dean of the college. appropriate sanctions will be imposed. **options for instructor (choose one):** - **use prohibited:** students are not allowed to use generative AI tools on assignments in this course. students are expected to complete each assignment without substantive assistance from others, including automated tools. - **use only with prior permission:** students are allowed to use generative AI tools on assignments in this course only if instructor permission is obtained in advance. unless permission is given to use these tools, each student is expected to complete each assignment without substantive assistance from others, including automated tools. - **use only with acknowledgement:** students are allowed to use generative AI tools on assignments in this course if that use is properly documented and credited. for example, text generated using chat- should include a citation such as \u201cchat-. (yyyy, month dd of query). \u2018text of query.\u2019\u201d material generated using other ai tools should follow a similar citation convention. ----- ", "# policies and principles on using generative AI tools in education a proposal by \u2019s ai vision committee this document presents recommendations from 's ai vision committee, established by provost dennis jacobs in , with the aim of formulating policies and principles that leverage the benefits of gai tools to enhance teaching and research at university. the following proposal has been thoroughly discussed and endorsed by the ai vision committee. membership includes: co-chairs: - prof. (information, technology, and operations; gabelli school of business) - prof. (computer and information sciences; ) committee members: - prof. elissa aminoff (psychology; ) - prof. (strategy and statistics; gabelli school of business) - prof. goldkind (graduate school of social service) - prof. (school of law) - prof. (chemistry; ) - prof. vacca (communication and media studies; ). **introduction** generative AI (gai) focuses on creating systems capable of generating content, including text, images, music, and computer programs. these systems use statistical models trained on vast volume of text (including academic papers) and image samples to generate outputs that mimic human-like creativity in response to natural language inputs. gai tools are freely or inexpensively available on the internet, making them accessible even to technologically unsophisticated users. the integration of gai in education presents both challenges and opportunities for institutions and has the potential to transform higher education. given that gai can generate non-reproducible content that mimics human creators, there is a legitimate concern that students will exploit gai for academic dishonesty or cheating. however, when used properly, students can leverage gai to enhance their critical thinking skills by engaging in interactive discussions with ai-generated content. gai can aid in improving writing abilities by providing suggestions, grammar corrections, and even generating draft content. gai can also serve as a valuable tool in data analysis, as well as in the creation and debugging of computer programs, and as such, can lower barriers for including these topics in non-specialist courses. it is crucial to maintain a balance between leveraging ai tools for support and preserving the authenticity and originality of student work to uphold academic integrity. a key objective of the ai vision committee is to address these challenges and harness the potential of gai as a valuable educational resource while safeguarding the principles of academic integrity, recognizing that gai offers us the potential for transforming how teaching, scholarship, and service are expressed in the environment. a vital consideration surrounding gai is its impact on social justice. while generative AI has the potential to address educational inequalities and enhance access to education, there are concerns regarding bias and fairness in ai-generated content based on the data these systems are trained on; equity issues surrounding how different types of students can access such tools; and harms that ai potentially poses to our democratic system and the public good. it is essential to critically evaluate and address potential biases and ensure that gai systems promote inclusivity, diversity, and equal opportunities for all learners, as well as to understand the potential ramifications of ai for democracy and the public good. has an opportunity to help students develop ai literacy to evaluate the implications of gai tools and, thus, use them ethically and responsibly. as new york's , is uniquely positioned to integrate generative AI into its ethos. by emphasizing \"cura personalis\" and adopting the principles of romecall , can prioritize ai ethics, social justice inclusivity, and individual well-being. in ai and education, interdisciplinary curricula can be developed to enhance quality and provide equal opportunities through accessible delivery methods. specific responses and considerations may be implemented to ensure the ethical and responsible use of gai. these responses may involve establishing guidelines and frameworks for the integration of gai in teaching practices, addressing potential challenges related to academic integrity, and fostering discussions around the social and ethical implications of this technology within the community. additionally, it is essential to educate students to use gai responsibly and ethically, enabling them to make informed decisions while harnessing the potential of this powerful technology. the proposal is organized into teaching, scholarship, and external engagement recommendations. specifically, the proposal outlines the rationale and action items in the following key areas: **teaching** . promoting critical ai literacy among students, faculty, and staff . guidelines for the use of gai tools in classroom learning . guidelines on adapting teaching and assessment for ethical gai use and equal student access . upholding academic rigor and integrity as essential principles of education furthermore, the committee recommends implementing a public website titled \" _teaching and_ _learning in response to generative AI tools_ \" for the community. the website complements the above recommendations with additional details. a prototype for this website can be accessed here:  **scholarship** . establishing a research center or institute to promote interdisciplinary research on advancing ai, its applications, and its impact on society -/ . allocating internal funding for research on the ethical and social impacts of ai and its applications . hiring additional scholars and faculty to advance ai research at **external engagement** . facilitating inter-university discussions on learning goals and pedagogy . collaborating with the industry on the future of knowledge and ai literacy . community engagement the ai visioning committee recommends that the administration take the following immediate actions: - request the academic integrity committee to review and update the integrity statement. - coordinate with deans to disseminate a statement regarding the responsible use of generative AI tools to faculty members for the upcoming fall semester. - encourage department chairs and program directors to revisit their learning goals in light of rapid advances in gai. - organize workshops on gai literacy for faculty members, providing them with essential knowledge and skills about this rapidly evolving capability. - designate a dedicated point of contact for faculty members to address inquiries related to technology assistance and teaching strategies for integration of gai tools. ", "# teaching . ** is committed to promoting critical ai literacy among students,** **faculty, and staff.** to achieve this, the following action items are recommended: a) provide technical support and guidance to students, faculty, and staff on the effective utilization of . this can be facilitated through the development of online video tutorials, webinars, or workshop series. b) provide guidelines for the ethical use of generative AI in teaching and research. this will include updates to the university\u2019s academic integrity policies for students, faculty and staff. the integrity statements will provide frameworks for students to identify the use of in completing the course work and for faculty to identify the use of in research and other scholarly publications. additionally, the committee recommends involving the irb and university research council to ensure the responsible and ethical use of in research and publications. c) establish a dedicated forum, such as a center, consortium, or other centrally administered unit, bringing together faculty members from across the university who share research and teaching strategies, tools, and projects focusing on ethical and social justice in the deployment of ai tools. d) create a frequently asked questions (faq) page to address common queries and concerns. some sample questions are as follows: - _what is generative AI?_ - _how does generative AI work?_ - _what are the limitations of generative AI?_ - _can i use generative AI for my teaching?_ - _what are the potential benefits of generative AI in education?_ - _what are the potential risks and challenges of using generative AI?_ - _how can generative AI be used responsibly in teaching and learning?_ - _how can academic integrity be maintained when using generative AI?_ - _what generative AI tools are available in the market?_ - _are there tools to detect ai-generated content, and why are they not so great?_ - _are there guidelines for citing and attributing ai-generated content?_ - _what are the ethical considerations when using generative AI?_ - _how can i address potential biases in ai-generated content?_ - _how can i address the implications of ai for democracy and the public good?_ - _where can i learn about generative AI and other generative AI tools?_ **.** **guidelines on using generative AI tools in classroom learning** a) sample statements in syllabi: in order to effectively integrate generative AI tools into classroom learning, the committee offers the following statements for inclusion in course syllabi: - for a \"no-ai\" approach: _\u201cgenerative AI tools are not permitted in this course. students [or learners] must rely_ _on their own originality, creativity and critical thinking skills to complete assignments_ _and engage with course material.\u201d_ - for a \u201climited-ai\u201d approach: \u201c _limited usage of generative AI tools may be allowed for specific assignments in this_ _course, enabling exploration of ideas, complex data analysis, and creative solution_ _development, when explicitly permitted by the instructor. when using these tools, it is_ _mandatory to clearly indicate the sections of your work that were generated using them_ _for proper attribution and transparency, and indicate the prompts and software_ _versions that were used. it is critical to adhere to ethical standards by refraining from_ _activities like plagiarism or creating misleading content. additional guidelines or_ _restrictions will be provided for specific assignments_ .\u201d - for a \u201cfull-ai\u201d approach: _\u201cthis course allows the use of generative AI tools to facilitate exploration of innovative_ _ideas, complex data analysis, and creative solution development. students must clearly_ _indicate the sections of the work that were generated using generative AI tools for_ _proper attribution and transparency, and indicate the prompts and software versions_ _that were used. it is critical to adhere to ethical standards by refraining from activities_ _like plagiarism or creating misleading content. additional guidelines or restrictions_ _will be provided for specific assignments.\u201d_ b) sample assignments embracing tools: for instructors actively seeking to integrate generative AI tools into their assignments , some suggested ideas include: - conduct in-class discussions analyzing ai-generated writing to understand its strengths and limitations. - assign students to revise and edit ai-generated texts to elevate them to their own standards. students will submit both the original ai draft and their final version. - organize in-class presentations comparing and contrasting ai writing with human writing. prompt students to reflect on elements replicable by chatgpt and aspects unique to human authors in their work. - explore refinement techniques by having students compose variations of the same prompt to fine-tune ai-generated results. - scaffold engagement with ai tools by encouraging students to interact with ai, using it for brainstorming or divergent thinking exercises. c) sample assignments deterrent of tools: for instructors seeking to prevent the utilization of generative AI tools in their assignments , some suggested ideas include: - require oral presentation of coursework to assess students' understanding and communication skills effectively, providing them with an opportunity to articulate their knowledge verbally. - employ interactive, in-class exercises to promote active learning and real-time application of concepts, fostering a deeper understanding of the subject matter. - engage in case studies based on current events. this offers a short-term defense, as the base models are trained on content that does not include ; however, emerging technologies giving access to web-search content may erode this defense. d) sample new assessment methods: the advent of necessitates new grading methods to mitigate the influence of ai writers. for assignments that prohibit tools, some new assessment ideas include: - assess the uniqueness of content using plagiarism detection tools or comparison with existing sources. however, it's important to acknowledge that existing tools are highly imperfect, as they may fail to detect ai-generated content and may also inaccurately identify work by non-native writers as ai-generated. - compare the quality and creativity of take-home assignments with in-class work, considering factors such as coherence, style, and relevance. - evaluate content accuracy and relevance in addressing assignment objectives. for assignments that allow tools, some assessment ideas include: - prompt students to reflect on 's benefits and limitations, justifying their responses. - require students to submit the prompts used for and assess their ability to effectively customize and adapt ai-generated content to fit specific contexts or target audiences. - assess the practicality and usefulness of ai-generated content in real-world scenarios, such as marketing materials or informational texts. - **appendix i** presents a rubric (adapted from  ) that helps educators review assignment prompts for vulnerabilities to generative AI tools and create prompts without those weaknesses. focusing on areas where ai falls short as a student writer, the rubric guides educators in designing assignments less susceptible to misuse while promoting the ethical use of generative AI tools. **.** ** is committed to ethical use and equal student access to .** to achieve these objectives, the committee recommends the following action items: a) advise faculty to have an explicit statement on the acceptable use of generative AI in the syllabus: faculty members should be encouraged to incorporate a dedicated section in their course syllabi that outlines the guidelines and expectations for the appropriate use of generative AI tools. this statement should clarify the scope of usage, highlight ethical considerations, and emphasize the responsible application of generative AI within the course context. b) encourage faculty to review the learning goals and assignment alignment in their courses: faculty members need to be encouraged to critically evaluate the learning goals of their courses in light of the integration of generative AI tools. they should reflect on how these tools can enhance the achievement of learning objectives and prompt students to engage more deeply with course concepts. furthermore, faculty members should reconsider the role and format of assignments, exploring how generative AI tools can be integrated to foster critical thinking, creativity, and problem-solving skills among students, and also how assessments can be designed to reduce the temptation of cheating. c) request area chairs and program directors to review and update the learning goals for their academic programs: area chairs and program directors should collaborate with faculty to review and update program learning goals, ensuring alignment with the curriculum's overall objectives when integrating generative AI tools. while revising the goals, ethical implications, pedagogical effectiveness, and impact on student outcomes must be considered. additionally, consideration should be given to appropriately preparing students for post-graduation studies and careers in a world with these tools. d) the writing center's role in integration: the writing center should lead campus discussions on the responsible integration of generative AI tools, focusing on plagiarism awareness, appropriate use in eloquentia perfecta courses, and faculty and student training. . ** is committed to upholding academic rigor and integrity as essential** **principles of education.** to achieve this, the following action items are recommended: a) revision of academic integrity statement and standards: the academic integrity statement and standards will be carefully reviewed and updated to align with the evolving academic landscape. in particular, this revision will address the ethical considerations and challenges associated with emerging technologies, including generative AI. it will reinforce the importance of honesty, originality, and responsible use of resources. it will also clarify the expectations and consequences regarding academic integrity violations. b) communication to students: deans will inform all students based on the outcome of a), providing notice about the revised standards of academic integrity. this communication will emphasize the significance of upholding ethical conduct and integrity in their academic work. it will also provide clear guidelines and expectations regarding the use of generative AI tools, ensuring that students are aware of their responsibilities and obligations. by revising the academic integrity statement and effectively communicating the revised standards to students, will reaffirm its commitment to maintaining high standards of academic rigor and integrity while addressing the ethical considerations associated with emerging technologies like generative AI. ", "# scholarship **.** **establishing a research center or institute to promote interdisciplinary research on** **advancing ai, its applications, and its impact on society:** the center will serve as a hub for interdisciplinary research, bringing together faculty, some of whom are already leaders in research on ai, as well as students from diverse fields, and providing a platform for collaboration, knowledge exchange, and innovation in data science and ai. it aims to form partnerships with industry, government agencies, and academic institutions while considering 's unique niche at the intersection of theology/jesuit scholarship, technology, ethics/morality, and democracy/the public good. the center will also act as a facilitator, engaging internal stakeholders, including the digital humanities consortium, public interest technology university network, center for community engaged learning, center for digital transformation, center for information law and policy (clip), and the mcgannon center, as well as external stakeholders, such as alumni and . this initiative is inspired by similar centers and institutions established at peer universities: **:** / ** shanghai:**  **columbia:** / **stevens institute of technology:**  **caltech:** center for science, society, and public policy **usc:** center for generative AI and society **vanderbilt** : future of learning and generative AI initiative **stanford** : human centered ai public interest technology initiative (umass.edu) . **allocating internal funding for ai research:** to promote research on ai's ethical and social impacts, the committee suggests allocating internal funding from the office of research or deans' grants. this funding will support projects exploring ethical considerations, societal implications, and policy issues related to ai technologies. areas of investigation may include ai tools and applications, bias and fairness in ai algorithms, privacy concerns, transparency in decision-making, ai's impact on employment, socio-economic structures, and the public good. providing internal funding incentivizes faculty and students to conduct rigorous research addressing ai's complex ethical and social challenges. . **hiring additional scholars and faculty to advance ai research at :** ai is a rapidly evolving domain. by recruiting additional experts in the field, the university can enhance its research capabilities, foster interdisciplinary collaborations, and enrich its academic programs. these scholars and faculty members will contribute valuable insights, innovative methodologies, and cutting-edge knowledge to advance 's gai initiatives. their expertise can also help to address complex challenges and explore new applications across disciplines, reinforcing 's commitment to staying at the forefront of emerging technologies. ", "# external engagement the committee proposes initiating ai-focused discussions among jesuit universities and fostering collaboration with industry leaders. . **inter-university discussions on learning goals and pedagogy** : facilitate inter-university dialog, particularly among jesuit universities, to explore and revise learning goals and pedagogical approaches in response to ai advancements. these discussions will foster collaboration and knowledge-sharing among institutions, enabling the efficient development of comprehensive strategies for ai integration across curricula. . **industry collaboration on the future of knowledge and ai literacy** : the committee recommends active collaboration with industry leaders to gain valuable insights into the future of knowledge work and the expected ai literacy of graduates. this collaboration is particularly crucial as the recent white paper published by goldman sachs predicts the potential elimination or reduction of million jobs, with many in knowledge work, due to advancements in ai. these statistics underscore the pressing need for universities to engage industry leaders and align their educational initiatives with emerging trends. . **community engagement:** the committee proposes dedicating efforts and resources to fulfill 's mission of community engagement. generative AI, though new and largely mysterious to many, presents a unique opportunity for to offer workshops and other interactive initiatives for educating our neighbors, fostering ai literacy, and encouraging questions. we recommend allocating resources to the center for community engaged learning, in community, foundry, and 's office of student involvement. these organizations can play a crucial role in educating the community about generative AI, its potential benefits for individuals, and promoting informed usage. **appendix i: ai misuse rubric --** adapted from |col|improve the prompt by reflecting on:|emerging advanced|col| |---|---|---|---| ||||| does the writing task propose a clear purpose that requires students to write to their audience? does the writing task ask students to thoughtfully consider the issue and draw a conclusion based on their evaluation? does the writing task require students to include real, verifiable sources throughout their essay? **emerging** **advanced** **student voice** **critical thinking /** **reasoning** **sources &** **citations** the prompt does not require students to take ownership of the task and/or purpose. students will not have to demonstrate a perspective or consider the audience in order to respond to the prompt. the prompt does not require students to analyze and synthesize the issue. students will not have to infer a conclusion based on what the prompt demands. the prompt does not require students to cite verifiable sources, including a variety of facts, concrete details, quotations, or examples. the prompt does not ask students to include a reference list. the prompt does not ask students to reference an authentic experience, such as a classroom discussion, a field trip, or an event from their personal lives. students can answer the prompt without including original thoughts and/or experiences. the prompt demands students take powerful ownership of the task and purpose. students will have to demonstrate a definitive perspective, considering the audience\u2019s knowledge and values, in order to respond to the prompt. the prompt requires students to skillfully analyze and synthesize the issue. students should infer a logical conclusion considering multiple expert viewpoints based on what the prompt demands. the prompt encourages students to create new knowledge based on novel ideas. the prompt requires students to cite verifiable sources, including a strong variety of facts, concrete details, quotations, or examples. it\u2019s clear the sources must be current and relevant to the writing task, and a full reference list is required. the prompt demands students to reference an authentic experience, such as a classroom discussion, a field trip, or an event from their personal lives. students will need to smoothly integrate their experiences and show evidence of original thinking to respond to the prompt. **personalization** does the writing task ask students to reference an event that required their presence or personal experience? |emphasize iteration and process.|are there opportunities to iterate and build on feedback?|the prompt is not ever paired with ongoing formative feedback for students to iterate on.|the prompt is paired with formative feedback prompting the student to respond to feedback in their iterations.| |---|---|---|---| ", "# preparing for generative AI in the election: recommendations and best practices based on academic research _this white paper is the result of a partnership between _policy and the graduate school of business intended to generate non-partisan, expert_ _recommendations on various critical ai governance issues. in , the two institutions_ _hosted a convening of experts from academia, technology, industry, and civil society who explored the_ _challenges of generative AI for the u.s. election and opportunities for_ _establishing best practices and governance guidelines._ ", "# an initiative of: **preparing for generative AI in the election:** **recommendations and best practices based on academic research** , -wrone \u2020 , , , gregory \u2020 , and ricardo velez \u2021 **executive summary** the rapid development of generative AI technology is transforming the political landscape, presenting both cenges and opportunities for the us election. this document provides a research-based overview of the potential impact of generative AI and offers best practices to safeguard the electoral process. the purpose of our review is not to recommend many specific legal or policy actions, but rather to promote clear understanding among voters, journalists, civil society, tech leaders, and other stakeholders about both the risk and promise of ai for electoral democracy in the hope of fostering a more productive public discussion of these issues. _cenges and opportunities_ . degrading information environment: as has been well documented, generative AI can create highly convincing deepfakes, posing risks of deceptive content, especially when released close to . there is also concern that voters will seek factual election information from chatbots that are not reliable sources of such information. . manipulation and microtargeting: there is concern that ai-powered micro-targeting or emotionally manipulative chatbots will persuade voters to behave contrary to their interest or polarize the electorate. however, social scientific evidence suggests mass persuasion or manipulation of voters is unlikely and that the greater concern is the perception of this manipulation, rather than an actual direct effect on electoral outcomes. . positive uses: generative AI technologies offer opportunities for positive applications in politics, such as generating accessible summaries of policies, helping voters assess candidates, aiding citizen-to-lawmaker communication, and leveling the playing field for under-resourced campaigns. . information centralization: to the extent that generative AI tools concentrate in a small number of tech firms, there will be concerns about the power they wield over political information. this will create thorny issues of content moderation, bias, and distrust. - \u2020 \u2021 ----- _best practices_ - for tech companies: \u25cb continue building on recent efforts to watermark and label ai-generated content while clearly communicating that these efforts are not a panacea. \u25cb plan table-top exercises to anticipate best responses to late-breaking \u201c surprises\u201d that rely on ai-generated content. \u25cb study how labeling ai-generated material affects users\u2019 understanding of the information environment, building on recent academic research in this area. \u25cb ensure that ai chatbots point users toward authoritative information from official state sources regarding other narrowly defined issues of clear fact, such as how and where to vote. monitor uses of chatbots for microtargeting and misleading content intended to deter participation\u2014but primary focus should remain on deepfakes and the information environment. - for journalists: \u25cb disincentivize misinformation and manipulation by avoiding covering stories whose only case for newsworthiness is the use of ai-generated content. \u25cb aid with ai-literacy through non-sensationalist coverage of ai\u2019s role in elections. \u25cb partner with civil society to evaluate the provenance of widely distributed political content, and participate in tabletop exercises to consider how to cover and rapidly evaluate surprises. - for political actors: \u25cb political parties, politicians, and campaigns should publicly pledge not to use deceptive ai-generated content. \u25cb political actors should consider partnering with tech in building ai-based tools that empower voters to become better informed about candidates and policy. - for voters: \u25cb voters should remain skeptical of sensational or scandalous political information, especially when released close to . - for the future: \u25cb both government and big tech companies should limit centralization of power over content generation and moderation in a small number of platforms. \u25cb encourage a diversity of generative AI tools and involve users and external stakeholders in setting content guardrails and governance structures. \u25cb the political risk associated with power centralization should be among the considerations when designing ai safety regulations that might increase market concentration, such as licensing requirements. **introduction** the rapid development of generative AI technology over has created new cenges as well as some new opportunities for democracy. this document provides a research-based overview of the potential impact of generative AI and offers best practices to safeguard the electoral process. the purpose of our review is not to recommend many specific legal or policy actions, but rather to promote clear understanding among voters, journalists, civil society, tech leaders, and other stakeholders about both the risk and promise of ai for electoral democracy in the hope of fostering a more productive public discussion of these issues. democracy relies on electoral accountability. voters are asked to elect candidates they support and to fire politicians they think are not doing a good job. democracy therefore requires a healthy information environment in which voters can monitor what politicians are doing, learn what candidates promise to do if elected, and assess what policies might be needed in response to societal cenges. by facilitating the automated creation of highly detailed text, image, and videos that are difficult to distinguish from human-generated content, generative AI could negatively impact the information environment. it could be used to create false or misleading information, feed a general sense of radical skepticism or nihilism about the reliability of information, and even allow political actors to dismiss real, damaging information as ai-generated fake news. by assisting in the creation of micro-targeted political content (for example, for use in online political ads), generative AI could polarize voters or contribute to a sense of a fractured polity in which people live in different informational environments from one another or are manipulated into voting for the wrong candidate or into not voting at all. generative AI also powers chatbots capable of engaging in human-like conversation. startups, campaigns, and other actors are likely to use these chatbots to engage in political conversations. this may not be inherently problematic\u2014indeed, one could imagine increased engagement leading to better-informed voters. but some may object to the inauthentic nature of these conversations, the potential for emotional manipulation, or the intentional or unintentional spread of false or misleading information. moreover, extremist groups might use these chatbots in an effort to recruit people to their causes. finally, and more generally, the growth of generative AI could lead to further centralization of the online information ecosystem, with a small number of large tech companies deciding which ideas and values can be expressed and which are out of bounds. this could threaten free expression and further erode americans\u2019 trust in the political environment. as an extraordinarily promising new technology, though, generative AI also holds promise for democratic governance. researchers are already studying ways to create chatbots that can discuss politics with people. because generative AI is good at synthesizing large amounts of information, and if conversing through chatbots proves to be a more natural and engaging way for people to consume political information, then training chatbots to understand political issues and the positions of parties and candidates may be an effective way to help americans become better informed about politics. these tools could also help under-resourced campaigns to communicate more effectively with voters, and could help voters to communicate with their representatives more easily. while it\u2019s essential that we safeguard the election and the democratic process more generally in the face of disruptive new technologies, we should also seek to maximize these opportunities for generative AI to improve our democracy. **voters\u2019 information environment** generative AI has the capacity to alter the voters\u2019 information environment in at least two ways. first, generative AI allows for the creation of highly convincing deepfakes-\u2013images and videos that are difficult for non-specialists to distinguish from genuine content. second, ai chatbots are a new, direct source of information for certain voters, especially younger ones. _ unscrupulous actors are likely to disseminate deepfakes, perhaps experimentally tested and tuned for maximal impact, unconstrained by norms of truth telling or public accountability. early instances of these concerns have already arisen in real world elections. deepfakes played a role in the recent turkish elections. at a large political rally, president recep tayyip erdo\u011fan showed a fake video linking his chief opponent, , to the leader of the pkk, a kurdish group classified by as a foreign terrorist organization. separately, an online k\u0131l\u0131\u00e7daro\u011flua supporter used ai to generate a video that appeared to show the candidate delivering a campaign speech in perfect english . and here in america, that used aigenerated images of president and vice president to show a dystopian future following a released a campaign video - victory in . this video was not deceptive\u2014it seems unlikely any viewers thought it showed current reality\u2014but it did use ai to try to manipulate voters\u2019 perceptions of political opponents and to garner press attention and notoriety. there are several reasons to be concerned about the use of deepfakes in campaigns. first, of course, voters may well be deceived by such content. it is particularly concerning that ai-manufactured content could be released very close to in order to generate fake scandals within a time frame that makes fact checking difficult. these \u201c surprises\u201d may be especially difficult to respond to if they are generated or shared by major political candidates. tech companies, civil society, and journalists may want to consider plans to rapidly analyze these surprise deepfakes as they arise, focusing only on the most salient ones that gain the most reach online. second, wide-spread circulation of manufactured content may undermine voters\u2019 trust in the broader information environment. if voters come to believe that they cannot trust any digital evidence, it becomes difficult to seriously evaluate those who seek to represent them. third, politicians may use this undermining of the credibility of the information environment to dismiss genuine information. late in the turkish election, a tape came to light showing compromising images of a candidate, i\u0307nce. while i\u0307nce eventually withdrew, he also claimed the video was a deepfake . if voters genuinely can\u2019t tell the difference between what is fake and what is real, it is not hard to imagine that such denials will become a commonplace. much of the public discussion around how to address such concerns is focused on establishing content provenance. the most prominent approach involves watermarking and labeling, something that major ai companies including meta, , and openai have publicly pledged to implement . tiktok has announced a similar approach. the idea is that the large ai companies should build-in code that \u201cwatermarks\u201d content\u2013making content produced or modified by generative AI detectable\u2013and that media and social media outlets should then label such content as \u201cai generated\u201d. other approaches involve building technologies that make it possible for creators to cryptographically sign content in ways that are not preserved if the content is altered without permission, thereby allowing users to attribute responsibility for content to a particular creator. the goal of all of these steps is to allow voters to make better inferences about the reliability of information. white watermarking, labeling, and signing are certainly worthwhile, they are not a silver bullet due to several practical constraints. only a small percentage of online content can be expected to be cryptographically signed. and, while ai companies are exploring a variety of watermarking technologies, all current approaches can be worked around by sophisticated actors. for generative text models, shorter texts are harder to detect. even advanced cryptographic techniques for watermarking require \u201ca few hundred\u201d tokens for reasonable detection, which is well over the length of a typical tweet. moreover, because of the many approaches being pursued, the industry has not agreed on a set of standards; this lack of harmonization makes labeling more difficult for media and social media companies. finally, labeling content as ai generated requires making judgment about substantial gray areas. in addition to being used to create deceptive or false content, generative AI tools are used for a host of innocuous tasks, such as red-eye reduction, editing for fluency, and the like. watermarking and labeling any content that has been touched by an ai risks being so over-inclusive that labels become meaningless. but the alternative requires laborious and contentious judgment calls. moreover, the effects of labeling on human behavior and perception are not yet well understood. it is possible that users will respond to seeing labels alerting them that content is \u201cai generated\u201d by assuming it is untrue. such a response would become problematic if there is useful, informative ai-generated content that gets systematically dismissed, or if users fallaciously conclude that any content _not_ ai-generated must therefore be true. recent research offers helpful evidence on what labels might be most effective, and further research by academics and platforms could help to refine best practices for labeling. without effective methods to establish the veracity of digital content, an alternative path forward is improved verification for content /-briefing////eli-lilly-twitter) . even if we can\u2019t know whether digital content has been altered, account verification and verifiable content signing can increase confidence that the content that is released by an entity is truly coming from them, not an imposter. if content is determined to be misleading or false, being able to confidently trace the content to its origin is a useful step towards creating accountability. recent events have shown us the impacts of misleading account verification. in the midst of recent changes to its verification program, x (formerly twitter) users were able to create accounts that appeared to be verified and official but were, in fact, imposters. one user created a [fake but official-looking eli lilly account that tweeted \u201cwe are excited to announce insulin is now free.\u201d in the wake of this tweet, stock fell over %. _voter information_ another concern in the information environment is that voters might seek technical facts about elections\u2014for instance, voting dates, polling locations, registration procedures, voting eligibility\u2014from ai chatbots. recent polling suggests that seeking such factual information is the election-related activity voters are most likely to use generative AI for. but research by the bipartisan policy center finds that chatbots are neither a reliable nor an appropriate tool for this use case . in , internet search has been the most common source of such information for /blog/new-survey-data-election-information/) . to the extent that ai chatbots are viewed as substitutes for search, this could be a substantial concern. chatbots have not, at this point, displaced search as a source of information. [only about one quarter of adult americans had accessed chatgpt by /short-reads////most-americans-havent-used-chatgpt-few-think-it-will-have-a-major-impact-on-their-job/#:~:text=younger%adults%are%more%likely,for%those%%and%older.) . however, that number is substantially higher among those of young voting age\u2014over % of americans have done so. the two most common uses were for entertainment and to access new information. thus, while it is unlikely that chatbots will be a source of widespread misinformation on technical election information, it is important that the creators of such chatbots take steps to reduce the risk. the most straightforward approach is to train generative ais to inform users that the chatbot is not a reliable source of technical election information and to direct users seeking such information to authoritative sources, such as the websites of state or local election administrators. several of the large ai companies are already pursuing such an approach. _recommendations and best practices_ - **campaigns and political parties** should publicly pledge not to use deceptive ai generated content in campaign materials. - **tech companies** should continue to build on their recent efforts to collaborate around watermarking and labeling ai-generated content, and support further research on the effects of labeling this content on users\u2019 overall understanding of the information environment. - **tech companies** should ensure that chatbots inform users that they are not a reliable source of technical election information and point users toward authoritative sources, as they have done in past election cycles. - **tech companies, journalists, and civil society** should carry out tabletop exercises exploring how to respond to the release of late-breaking deepfake content, especially under scenarios in which the content is generated or promoted by a major political candidate. - **state election boards** should emphasize that existing voter intimidation and deception laws apply to ai generated content an outside group or campaign may use; the fact that the content was generated by ai is not a defense for voter intimidation or deception. - **journalists** should disincentivize misinformation and manipulation by avoiding covering stories whose only case for newsworthiness is the use of ai-generated content. - **journalists and civil society** should collaborate to provide trustworthy information on content authenticity. **microtargeting and manipulation** in an [article published in the conversation in , political scientist archon fung and law professor lawrence lessig describe a dystopian scenario in which political campaigns use generative AI to develop highly persuasive messages tailored to individual voters. ai tools use reinforcement learning to get better and better at changing minds, far surpassing the capability of human campaign strategists. fong and lessig warn that well-resourced candidates with access to such technology could win elections despite holding unpopular policy views, undermining electoral accountability. although the specific ai-fueled context in this scenario is new, the general fear of candidates using persuasive technology to convince voters to vote against their preferences is not. similar arguments were made about targeted digital advertising when it became widespread in campaigns in through , and about broadcast advertising on television and radio when those technologies were young. political scientists have evaluated the plausibility of similar claims to fung and lessig\u2019s in the context of existing persuasive technologies \u2013 direct mail, television, and non-ai-generated digital ads \u2013 and have generally found persuasive effects close to zero. while there is some evidence that television advertising can have small but nonzero effects on vote shares in general elections, this effect is believed to operate mainly through changing the composition of the electorate (by motivating partisans to turn out or not), not by persuading voters to change their minds on policy issues. two further checks on the potential power of any communication technology, including ai, come from the competitive nature of elections\u2013 which implies that any persuasive arguments developed by one campaign are likely to be countered by its opponent\u2013and the fact that any messaging voters receive from campaigns is swamped in volume by information from the mass media, social media, and friends and family. to the extent that generative AI-produced ads are different from human-produced ads, the difference lies in the potential for mass customization on a scale not feasible with human-produced content. existing technologies do allow for some customization, so this difference is one of degree rather than of fundamental character. evidence about candidates\u2019 use of existing targeting and message-tailoring technologies is, therefore, informative about how candidates would be likely to use generative AI. interestingly, candidates do not appear to take much advantage of the large difference in targeting precision between broadcast tv ads and digital ads on social media platforms like facebook; candidates run very similar campaign messages in both settings and do not present significantly different versions of their policy positions to different groups of platform users. it does not appear that candidates perceive large gains from targeting, perhaps because of the potential for news outlets or their opponents to expose and broadcast any narrowly-targeted messages outside of their intended audiences. we are, accordingly, skeptical of the potential for generative AI to undermine political accountability by duping voters into supporting candidates whose policy agendas they oppose. while it is possible that aienabled campaign advertising is substantially more effective than other existing campaign advertising technology, our accumulated experience and knowledge of previous waves of technological innovation in campaigns suggests that this is unlikely. nonetheless, there are some potential consequences about which some concern is warranted. first, one reason that campaigns find it difficult to persuade voters is that their opponents and the news media provide a counterweight to the information and arguments they offer. were either the competitiveness of elections or the quality of political information provided by news media to decline, the scope for campaign persuasion by any means, and in particular through ai-generated targeted messages, would increase. second, generative AI is costly to use. if it came to be perceived by candidates as a necessary tool to mount a serious campaign, it could raise the financial cost required to enter a race. the arms-race effect of such competitive pressure could impact the pool of candidates willing to run, even in the absence of any net effect on voter behavior. there is now good evidence from multiple settings that increases in campaign spending levels tend to shrink the candidate pool, advantage wealthier candidates, and increase incumbency advantages. third, ai-enabled campaigning might be perceived by voters as unfair or illegitimate, particularly if its adoption is not symmetric across the parties. news media might contribute to such perceptions by uncritically reporting claims about ai campaigns\u2019 effectiveness from self-interested technology vendors. losing candidates could use such claims, were they widely believed, to cast doubt on the legitimacy of their opponent\u2019s victory. _recommendations and best practices_ - **journalists** should inform the public that the likelihood of generative AI ads or chatbot conversations massively affecting electoral outcomes is low. - **journalists, civil society, and voters** should exercise extreme skepticism when startups or other companies claim to be able to use new technology to persuade large numbers of voters to switch their votes or to not turn out. - **tech companies** should continue to monitor concerning uses of chatbots for microtargeting, persuasion, and particularly misleading content intended to deter participation. where appropriate, they should consider forbidding such behavior in their terms of services as some already do. however, in the short amount of time before the election, issues with deepfakes and the information environment are likely to be more pressing and should be the primary focus. - **campaigns and political parties** should avoid allocating undue resources to microtargeting and chatbots, which may foster mistrust even if they are not effective at political persuasion. **opportunities** though some of the most salient examples of generative AI being used in politics involve nefarious applications such as deepfakes and inauthentic news stories, these technologies also have the potential to be harnessed for civic engagement and education. positive use cases include summarizing policies and salient political events for lay audiences, developing more accessible voting advice applications, and facilitating communication between citizens and lawmakers. beyond the potential to empower voters, generative AI could also enable under-resourced campaigns to improve their outreach and communication strategies. distilling policies and presenting them in an accessible format is a capability of large language models (llms) that could enhance voter learning. for example, one can ask anthropic\u2019s claude, an llm with a , token context window, to generate summaries of house and resolutions. doing so for h.r. , a -page bill introduced in the th congress aimed at regulating digital assets, produces a summary correctly highlighting its aim to \u201ccreate new regulations for cryptocurrencies, stable coins, and other digital money.\u201d if one continues the chat by claiming to be a \u201ccryptocurrency expert,\u201d claude can return details about new reporting requirements introduced in the bill. the ability for these tools to tailor information based on user knowledge provides an opportunity for citizens to engage with the legislative process in a more transparent and efficient way. llms could also enhance voter learning in electoral settings. voting advice applications (vaas) have become ubiquitous in the us and europe. vaas solicit voters\u2019 stances across several issues and match voters to politically congruent candidates. though previous research has found positive effects on voter turnout and vote /doi/full/./..) , vaas assume that voters possess stable issue preferences, and might appeal to those who are already politically engaged. integrating generative AI into the development of vaas could allow lower propensity voters to pose simple questions about political parties (e.g., \u201cwhere does stand on abortion?\u201d) and receive information about party positioning within seconds. instead of responding to an extensive list of policy items, as is the case with existing vaas, ai-guided conversations could help make interacting with vaas less intimidating and more accessible to a broader spectrum of voters. in implementing tools such as vaas or even summarizing policies, a natural question is whether llms will be \u201cbiased\u201d toward certain viewpoints. methods like [retrieval-augmented generation (rag) can be used to mitigate these concerns by grounding the generation of content in a variety of sources that span the political spectrum. when a user interacts with an llm, rag ensures that relevant sources are fetched from a preloaded database, inserted into the prompt, and used to populate the answer. it is possible to load an external database with sources such as party platforms and instruct the llm to only summarize the information contained in those sources. this produces outputs that are generally free of editorializing and accurately represent the source material. outside of electoral settings, extensions of rag could be used to help voters learn about topics discussed in meetings, scour publicly available but underutilized civic data, and understand local policies. using rag is akin to using a search engine that retrieves relevant information and summarizes it in an accessible fashion. this makes it an ideal method for simplifying vast amounts of data, which can be useful for voters making choices in political contexts where knowledge is limited due to a lack of media coverage. for example, one could use rag to summarize recent approvals of housing developments or a list of policies considered by a in . beyond political learning, generative AI could also be used to facilitate communication between citizens and elected officials. writing to lawmakers can be an intimidating process for many citizens, as they might know how to articulate their concerns or they may be unsure about the relevant norms for such communication. llms can improve this process by enabling citizens to craft more persuasive messages. they can also provide real-time assistance with respect to grammar, style, and tone, allowing citizens to communicate more effectively. in the future, these tools may also be used by legislators to proactively identify common concerns among citizens, further improving responsiveness. generative AI could also help level the playing field with respect to political campaigns. under-resourced campaigns may face cenges in creating content that appeals to voters. generative image and text tools can enable these campaigns to draft more compelling speeches, press releases, social media posts, and other materials. these methods can also be used to create tailored materials for different audiences. to the extent that generative AI allows financially constrained campaigns to maintain a veneer of professionalism, it could reduce imbalances between lesser-known candidates and more established politicians. in sum, although negative use cases involving generative AI have received significant media attention, there are positive use cases that could enhance civic engagement and education. from powering political information-retrieving chat bots to improving citizen-to-legislator communication, the summarization and style transfer capabilities of llms could be used to improve democratic processes. encouraging the public to use these tools to productively cut through the morass of everyday politics can serve as a powerful counterweight to misinformation, whether human or ai-generated. _recommendations and best practices_ - encourage campaigns, journalistic outlets, and technology companies to create pathways that help voters to use generative AI to summarize complex policies and political platforms. - political parties, technology companies, and civic organizations should help under-resourced campaigns learn to use ai tools to generate higher quality and more informative content. - lawmakers and other actors should create pathways for citizens to use ai tools to communicate directly with their offices. **information centralization** there are good reasons to believe that the ai market is likely to end up concentrated in the hands of a small number of dominant firms who build and deploy foundation models\u2014the large, flexible models that can be used for a wide variety of applications. to the extent that generative AI tools end up clustered in a small number of large tech platforms, it may further exacerbate concerns that tech companies have too much power over the information environment. already, openai, , meta, and other tech companies offering ai-related services have faced concerns over what content their chatbots and other generative AI tools will and won\u2019t countenance, with some critics worrying that the tools will say offensive things, while others worry that the generative ais exhibit a left-wing political bias. more generally, there are hard questions about (a) what content is allowed to enter a mode\u2019s training algorithms, (b) what prompts users are permitted to ask and which are rejected for being offensive, dangerous, or otherwise off limits, and (c) what output the tools will and won\u2019t provide. as generative AI use expands, the power these companies have over these rules could become problematic in much the same way that the power of social media companies over online speech has over . there are two main risks. first, companies could err, and create content guardrails that are unfair, biased, or confusing in ways that perturb the information environment. second, people might further lose trust in the information environment, concluding that big tech companies who don\u2019t share their values are unduly influencing what ideas are generated or gain widespread distribution. in the us, these concerns could come from both sides of the ideological spectrum. just as we\u2019ve seen with regards to social media, the right will worry that generative AI tools are biased against conservative ideas and values, while the left will worry that these tools are biased towards conservative ideas and values. these concerns rest on the widespread use of generative AI and so may not come to fruition before the election. indeed, currently, polling shows that there is bipartisan support among americans for a variety of interventions by government and industry to reduce the risk that generative AI poses to elections. however, it is entirely possible that public attitudes will polarize once americans experience their first important \u201cai election\u201d in . as such, these concerns bear careful watching, and companies and society would be wise to think now about how to resist the centralization of information provision before the problem becomes more developed. there are at least two potential ways to mitigate this issue. first, society could take steps to ensure that there are many providers of generative AI tooling, so that no one company has undue power over content generation guardrails. this could include exploring policies to prevent market concentration in the generative AI industry, and perhaps is a reason to be cautious about endorsing policies that envision restricting the set of companies licensed to provide generative AI tools (though these policies may have other important benefits). second, generative AI platforms could avoid taking on this power over content moderation by giving decision-making power concerning guardrails over to users, industry-level self-regulatory bodies, civilsociety based regulatory bodies, or other external stakeholders. already a number of companies have announced efforts along these lines. building on their experiment with the oversight board to make binding content decisions for the company, meta has recently announced a \u201c community forum \u201d concerning generative AI guardrails, in which users are randomly recruited and paid to learn about, debate, and make recommendations concerning ai policy issues. openai has announced funding for a similar exploration . meanwhile, anthropic has implemented an effort to develop a \u201c constitution \u201d through consultation with the community. while these efforts are interesting, they are still nascent. the recruited users can only consider a small number of issues and, at most, make recommendations rather than binding decisions. for these self governance efforts to reassure skeptical republicans and democrats that tech companies are not shaping the expression of values in society, users would have to be given substantially greater power over more issues, to make binding decisions on them, and to communicate these decisions to the public so that the public could understand that tech companies have truly given over this power. expanding the power of self-governance institutions like these is difficult, though, due to the expense and the practical cenges associated with recruiting and paying users to deliberate and decide. **conclusion** we have reviewed a number of essential ways that generative AI will affect the election, focusing both on the ways that it threatens to disrupt the information environment and affect the outcome of the election and voters\u2019 faith in the process itself, as well as the ways it can be used to inform voters and improve democratic functioning. if there is a single theme to our review, it is that voters, journalists, and everyone who cares about elections should regard claims about new technology with great skepticism. in some instances, the threat to the election is caused by generative AI itself\u2014such as latebreaking \u201c surprises\u201d driven by highly persuasive fake information. people should be skeptical of these surprises given these threats, and they should find ways to seek out information verification from sources they trust. in other instances, the threat is not from the technology itself but from over-credulousness about its power. when startups claim to be able to use generative AI to change the minds of large numbers of voters, you should approach the claim with a great deal of skepticism. finally, you should also be skeptical about the promise of quick fixes to new technological problems. while the idea of \u201cwatermarking\u201d generative AI content is a valuable one, it is clear it will not be a panacea for the election. watermarking is simultaneously too easy to evade, and also aimed at only one part of the problem: nothing about watermarking will tell you whether or not you should believe the claims and information in a piece of content. there is ample misleading content that is not ai-generated, and there will be plenty of perfectly accurate ai-generated content. ultimately there will be no substitute for your skepticism, common sense, and trusted sources. **author bios and disclosures** __ is the interim dean and professor in the school of public policy at the . discloses that he receives consulting income from meta platforms, inc for work related to governance issues. _-wrone_ is professor of political science and maurice r. greenberg senior fellow of the hoover institution, . __ is the davies family professor of political economy in the graduate school of business at , and a professor of political science. he is a senior fellow at research and a senior fellow (courtesy) at the hoover institution. discloses that he receives consulting income from meta platforms, inc for work related to augmented reality strategy, and from andreessen-horowitz for work related to web governance. __ is research associate professor in the data science institute at the . she was previously a senior staff machine learning researcher on the ml ethics, transparency and accountability team at twitter. _gregory _ is associate professor of political economy in the graduate school of business at . _ ricardo velez_ is an assistant professor of political science at . ", "# chatgpt and generative AI tools: sample syllabus policy statements large language model generative AI (generative AI) tools, such as chatgpt and others, have recently emerged and become available for wide use. while generative AI tools can offer inspiration and new possibilities, they should not be seen as unacknowledged substitutes for the content created by students in their courses. regarding the potential use of generative AI tools, no changes in university policy are required. it is already a violation of policy for students to represent work they did not do as their own, and work generated by an ai system that is not credited to that system falls under that policy. while there are clear limitations on the use of these tools in certain contexts at /ai-tools) , instructors have the discretion to explore them in the classroom. **at present, the ctl recommends that ut** **faculty and instructors decide whether or not these tools fit within their pedagogical aims** **and clearly state their course policies in a designated section of their syllabi** . if adopted, students should learn how to use ai text generators (i.e., chatgpt) and other ai tools to expand rather than impede their developing abilities as writers, coders, creators, and thinkers. ensuring equitable access to these tools is essential, as are fair grading policies and student evaluation for both those who do and do not use ai tools in their courses. the following suggested syllabus statements focused on generative AI tools in the classroom are culled from ctl discussions as well as openly available web resources. each section contains several possible ways of framing the instructor\u2019s intent. due to the nuance of generative AI, the categories do not stand alone, so you may find areas of overlap. to that end, these statements are intended to spur your own thinking and so you are welcome to use edit [with any questions about how to craft your own statements or explore our webpage, \" things to know about chatgpt,\" which contains links to additional ut resources and recommendations _. no use of generative AI tools permitted_ >> \"this course assumes that work submitted by students \u2013 all process work, drafts, brainstorming artifacts, final works \u2013 will be generated by the students themselves, working individually or in groups as directed by class assignment instructions. this policy indicates the following constitute violations of academic honesty: a student has another person/entity do the work of any substantive portion of a graded assignment for them, which includes purchasing work from a company, hiring a person or company to complete an assignment or exam, and/or using generative AI tools (such as chatgpt).\" >> \"in this course, every element of class assignments must be fully prepared by the student. the use of generative AI tools for any part of your work will be treated as plagiarism. if you have questions, please contact me.\" >> \"all assignments should be fully prepared by the student. developing strong competencies in the skills associated with this course, from student-based brainstorming to project development, will prepare you for success in your degree pathway and, ultimately, a competitive career. therefore, the use of generative AI tools to complete any aspect of assignments for this course are not permitted and will be treated as plagiarism. if you have questions about what constitutes a violation of this statement, please contact me.\" >> \"this course assumes that work submitted for a grade by students \u2013 all process work, drafts, brainstorming artifacts, final works \u2013 will be generated by the students themselves, working individually or in groups as directed by class assignment instructions. this policy indicates the following constitute violations of academic honesty: a student has another person/entity do the work of any substantive portion of a graded assignment for them, which includes purchasing work from a company, hiring a person or company to complete an assignment or exam, and/or using generative AI tools (such as chatgpt).\" _. generative AI is permitted in specific contexts and with acknowledgment_ >> \"the emergence of generative AI tools (such as chatgpt and dall-e) has sparked interest among many students in our discipline. the use of these tools for brainstorming the materials may be useful for you as you craft responses to class assignments. while there is no substitute for working directly with your instructor, the potential for generative AI tools to provide automatic feedback, assistive technology and language assistance is clearly developing. please feel free to reach out to me well in advance of the due date of assignments for which you may be using generative AI tools and i will be happy to discuss what is acceptable.\" >> \"in this course, students shall give credit to ai tools whenever used, even if only to generate ideas rather than usable text or illustrations. when using ai tools on assignments, add an appendix showing (a) the entire exchange, highlighting the most relevant sections; (b) a description of precisely which ai tools were used (e.g. chatgpt private subscription version or dall-e free version), (c) an explanation of how the ai tools were used (e.g. to generate ideas, turns of phrase, elements of text, long stretches of text, lines of argument, pieces of evidence, maps of the conceptual territory, illustrations of key concepts, etc.); (d) an account of why ai tools were used (e.g. to save time, to surmount writer\u2019s block, to stimulate thinking, to handle mounting stress, to clarify prose, to translate text, to experiment for fun, etc.). students shall not use ai tools during in-class examinations, or assignments unless explicitly permitted and instructed. overall, ai tools should be used wisely and reflectively with an aim to deepen understanding of subject matter. >> \"it is a violation of university policy to misrepresent work that you submit or exchange with your instructor by characterizing it as your own, such as submitting responses to assignments that do not acknowledge the use of generative AI tools. please feel free to reach out to me with any questions you may have about the use of generative AI tools before submitting any content that has been substantially informed by these tools.\" >> \"in this course, we may use generative AI tools (such as chatgpt) to examine the ways in which these kinds of tools may inform our exploration of the topics of the class. you will be informed as to when and how these tools will be used, along with guidance for attribution if/as needed. any use of generative AI tools outside of these parameters constitutes plagiarism and will be treated as such.\" >> \"understanding how and when to use generative AI tools (such as chatgpt, dall-e) is quickly emerging as an important skill for future professions. to that end, you are welcome to use generative AI tools in this class as long as it aligns with the learning outcomes or goals associated with assignments. you are fully responsible for the information you submit based on a generative AI query (such that it does not violate academic honesty standards, intellectual property laws, or standards of non-public research you are conducting through coursework). your use of generative AI tools must be properly documented and cited for any work submitted in this course.\" >> \"to ensure all students have an equal opportunity to succeed and to preserve the integrity of the course, students are not permitted to submit text that is generated by artificial intelligence (ai) systems such as chatgpt, bing chat, claude, , or any other automated assistance for any classwork or assessments. this includes using ai to generate answers to assignments, exams, or projects, or using ai to complete any other course- related tasks. using ai in this way undermines your ability to develop critical thinking, writing, or research skills that are essential for this course and your academic success. students may use ai as part of their research and preparation for assignments, or as a text editor, but text that is submitted must be written by the student. for example, students may use ai to generate ideas, questions, or summaries that they then revise, expand, or cite properly. students should also be aware of the potential benefits and limitations of using ai as a tool for learning and research. ai systems can provide helpful information or suggestions, but they are not always reliable or accurate. students should critically evaluate the sources, methods, and outputs of ai systems. violations of this policy will be treated as academic misconduct. if you have any questions about this policy or if you are unsure whether a particular use of ai is acceptable, please do not hesitate to ask for clarification.\" _. students are encouraged to use generative AI tools in coursework_ >> \"the use of generative AI is encouraged with certain tasks and with attribution: you can choose to use ai tools to help brainstorm assignments or projects or to revise existing work you have written. when you submit your assignment, i expect you to clearly attribute what text was generated by the ai tool (e.g., ai-generated text appears in a different colored font, quoted directly in the text, or use an in-text parenthetical citation).\" >> \"designers commonly use ai-content generation tools in their work. in this course, using ai-content generation tools is permitted and will be a normal and regular part of our creative process when it is used according to the below criteria. in this course, neglecting to follow these requirements may be considered academic dishonesty. () for each assignment, you are required to include a paragraph that explains what ai content- generation tool you used, the dates you used it, and the prompts you used to generate the content according to the mla style guide. () during critique, it is important to describe the precedents you used and how any source content was transformed. when showing or presenting images or other content you generated using an ai-tool, cite that image or content following the mla style guide. if you need help referencing your creative work, contact me to collaborate.\" >> \"students are invited to use ai platforms to help prepare for assignments and projects (e.g., to help with brainstorming or to see what a completed essay might look like). i also welcome you to use ai tools to help revise and edit your work (e.g., to help identify flaws in reasoning, spot confusing or underdeveloped paragraphs, or to simply fix citations). when submitting work, students must clearly identify any writing, text, or media generated by ai. this can be done in a variety of ways. in this course, parts of essays generated by ai should appear in a different colored font, and the relationship between those sections and student contributions should be discussed in cover letters that accompany the essay submission.\" **note on citation** : when thinking about your options, we urge instructors to explore these tools and think carefully about how to cite content from them as well as the role of citation in student work (i.e., brainstorming possibilities, developing arguments from sources, aligning ai tool output and authorship, etc.). considering ut-austin's policy that \" _chatgpt or similar ai tools_ _must not be used to generate output that would be considered non-public_ ,\" it is important to consider the shareable or retrievable nature of any ai-informed work. remind students that these tools cannot be used to create content that could be private (i.e., used for research purposes) or as their intellectual property. the following, most commonly used style guides should be useful in crafting language for your syllabi and assignments: how to cite generative AI output (mla) how to cite generative AI output (apa) how to cite generative AI output (chicago) _acknowledgments:_ _statement on artificial intelligence (ai) tools in )_ _(college of fine arts, ut-austin),_ _[generative AI syllabus statement /tamu-cte_genai-syllabusstatementconsiderations.pdf)_ _(_ _university),_ _[using generative AI in coursework_ _(faculty of computing and data science, boston_ _university),_ _instructional innovation resources_ _(mccombs school of business, ut-austin)_ **contact us** mail code: g austin, tx email us > ut ) [emergency information site policies [web accessibility /web-accessibility-policy) [web privacy /web-privacy-policy) [adobe /reader/) _\u00a9 at austin _ ", "## chatgpt guidance ", "# chatgpt guidance for instructors ", "## hat is c hat ? chat is an **artificial intelligence (ai) tool** that uses natural language processing techniques to respond to user-generated prompts. hile other chatbots are typically limited to pre-programmed responses, chat can produce original responses in real time. chat can generate everything from essays and emails to poems and lesson plans. it can revise text ith improved grammar and spelling or modulate the style or tone of a provided set of text, as requested by the user. chat is just one of many generative AI tools . chat may occasionally incorporate fabricated or incorrect information in its responses. because of the ay it operates, it is difficult to trace the source and provenance of information provided by chat (except hen it is connected to the internet, e.g., bingintegrated ). in addition, because chat as trained on a corpus of text that as originally ritten by humans, chat\u2019s responses may reflect the biases present in the text it as trained on. ", "## t ips for i nstructors - **talk to students about your expectations for academic honesty.** many students who engage in academic dishonesty do so impulsively or without significant reflection on the choice. anticipate this behavior by proactively engaging students in an open discussion about academic honesty in your course, including your expectations regarding chat. remind students that they are required to follow uga\u2019s academic honesty policy and talk to your students about how that policy applies to your course. for example, is chat off-limits, sometimes ok to use, or always encouraged? see below for sample syllabus language related to chat, or explore the growing repository of classroom policies related to generative AI available here . _use of artificial intelligence or word mixing software to write your paper or_ _disguise plagiarized work is considered unauthorized assistance in this_ _course. suspected unauthorized assistance, or other violations of uga\u2019s \u201ca_ _culture of honesty,\u201d will be reported to the office of academic honesty._ _or:_ _we encourage you to use ai tools to explore the field and help you study._ _however, you must take full responsibility for any ai-generated materials you_ _incorporate in your course products. if you include ai-generated materials in_ _your course products, it should be cited like any other reference material. all_ _information incorporated into course products must be verified, ideas must still_ _be attributed, and facts must be true._ - **do not rely solely on ai detector tools** (see the \u201cadditional resources\u201d section at the end of this document for examples) to identify whether an assignment was created using generative AI **.** these tools can return false positives and fail to detect some ai-generated material. if you suspect a piece of work was completed using generative AI, carefully analyze the work. if you believe a violation of your course policies may have occurred, instructors should report the incident to the office of academic honesty. a facilitated discussion will be scheduled for you to talk with the student about their process for completing the assignment and whether a violation occurred. - **consider the limitations of chat when designing course assignments.** as of , chat (v.): `o` cannot access information that is not already included in its corpus. this includes text or internet resources generated after , notes or other specifics from your course. however, and other integrated products do have access to more updated information. `o` cannot dissect or produce non-text-based responses, although other /awesome-generative-ai#image) [/awesome-generative-ai#image) can produce images and art. `o` may fabricate references (including contrived dois) when prompted to produce citations. - instructors might **deliberately ask students to engage with chat,** or [other generative AI tools , as an educational endeavor. for example, students might analyze how chat generates text for different audiences, attempt to find the original sources of text used to generate a particular chat response, compare and contrast chat output in response to various prompts, or improve upon a given chat prompt. if you decide to incorporate use of generative AI tools in your course, inform students how/whether you would like them to **document or cite** **their use of generative AI** . discuss with students the importance of transparency and trustworthiness to the process of generating knowledge, the pursuit of a degree, and to the ideals of higher education. - **if you ask your students to use chat, review the privacy policy and** **provide an opt out.** chat is currently released as a \u201cfree research preview,\u201d meaning that current use of the tool is helping to improve it for future use. openai (the company that designed chat) collects data from its users which may also be shared with third party entities. if you plan to use chat in an educational setting, it is recommended that you review the privacy policy and terms of use with your students, and provide them with the option to opt out (or alternate means to engage with chat output) if they do not feel comfortable having their data collected and shared as stated in these policies. ", "## a dditional r esources the homework =profile&utm_medium=reader) (substack post from ethan mollick, //) [using ai to implement effective teaching strategies in classrooms: five strategies, iluding prompts (doi: ./aarn. , ) teaching: what you need to know about chat (chronicle of higher education newsletter, ) teaching writing in an age of ai (teaching in higher ed podcast with guest , ) chat is not all you need. a state-of-the-art review of large generative AI ) (doi: [./arxiv.. , / / ) the learning with ai initiative (university of maine, ongoing) growing collection of ideas for chat prompts (github, ongoing) chat: understanding the new landscape and short-term /document/d/ercgdylglyoelawrkjfn_mqauenwkzork) (, ongoing) **chat detectors:** zero, openai detector, ai writing check, gltr, turnitin\u2019s ai [writing detection. \u201cchat guidae for instructors\u201d by () is licensed under a cc by . international license, meaning that you can freely use, remix, and share it as long as you give attribution and do not use it for commercial purposes. portions of this work itself are derived from the cc by work \u201c [chat and /presentation/d/vowftpx-rizdwyayob-pqdzknogdgxsntx/mobilepresent%%/l%%slide=id.p) \u201d by torrey trust, . griffeth and courtney cullen, uga office of academic honesty, served as consultants in the creation of this guide. ", "# policy brief: chatgpt and other generative AI systems ", "## about ", "#### the ai asia pacific institute focuses on addressing the social, legal, and ethical risks associated with artificial intelligence in order to unlock its potential for creating a sustainable world. ", "### acknowledgements we are grateful for the insightful expertise provided by , , , and floridi. thank you to (intern of ) for his significant contribution in drafting this document and to (associate professor of law at bond university) for her valuable contribution to the editing process. **copyright** \u00a9 ai asia pacific institute. all rights reserved. no part of this publication may be reproduced or transmitted in any form or by any means, including photocopying and recording, or by any information storage and retrieval system. **important disclaimer** the reader is advised and needs to be aware that the information contained in this publication may be incomplete or unable to be used in any specific situation. no reliance or actions must therefore be made on that information without seeking prior expert professional, scientific and technical advice. to the extent permitted by law, (including its members and advisors) excludes all liability to any person for any consequences, including but not limited to all losses, damages, costs, expenses and any other compensation, arising directly or indirectly from using this publication (in part or in whole) and any information or material contained in it. after engaging in a series of discussions with experts in the field of artificial intelligence (\u2018ai\u2019), previously disseminated a briefing paper that delves into the risks and prospects associated with . building upon the foundation laid by the briefing paper, this policy brief explores nascent methodologies applicable to the regulation of generative AI systems. generative AI systems are models that _generate_ new output\u2014whether text, audio, or visual material\u2014based on data they have been trained on. is one example of a generative AI system. other examples include alibaba\u2019s \u2018tongyi qianwen\u2019, google\u2019s \u2018bard\u2019, and \u2019s \u2018vall-e\u2019. ", "#### an overview of the applicable regulations this part outlines current and proposed regulatory frameworks governing generative AI systems in china, (\u2018eu\u2019) and the united states (\u2018us\u2019), recognising their pioneering role in these advancements. **china** china is a central figure in the development of ai, and is expected to play a leading role in shaping the contours of the \u2018fourth industrial revolution\u2019. china has adopted a top-down approach to ai regulation, characterized by strong government intervention and control. the chinese government has issued comprehensive national strategies and plans for ai development, outlining specific goals, targets, and policy frameworks. in contrast, western countries generally follow a more decentralised approach featuring a combination of government regulations, industry self-regulation, and collaborative initiatives. on a brief comparative analysis, the regulatory developments emerging from china place a greater emphasis on social responsibility and group and community relations, with relatively less focus on individualistic rights. the regulatory framework includes the \u2018measures for the management of generative AI services (draft for comment)\u2019 (\u2018 _draft_ _measures for generative AI services_ \u2019); _provisions on the administration of deep synthesis of_ _internet information services_ (entered into force on ); and the _personal_ _information protection law_ (entered into force on ). an official translation of the _draft measures for generative AI services_ is not available at the time of writing. therefore, this policy brief relies on  translation . crucially, a holistic analysis of china\u2019s high-level regulatory developments requires policymakers to assess the structural, cultural, and political context that shapes its approach to and development of ai. as is the case with all jurisdictions, a nuanced understanding of the domestic and international interests is paramount for policymakers. **** the eu\u2019s regulatory framework includes the general data protection regulation ( _\u2018gdpr_ \u2019) and the proposed \u2018ai act \u2019 (\u2018 _ ai act_ \u2019). under the  may compromise amendments to the _ ai act_ , generative AI systems will be considered \u2018foundation models\u2019, as they are \u2018designed to optimize for generality and versatility of output\u2019 and \u2018trained on a broad range of data sources and large amounts of data\u2019 (para (e)). the explanatory paragraph (g) states that this is intended to subject generative AI systems to specific requirements that distinguish such systems from \u2018high-risk\u2019 ai systems. accordingly, article b requires providers of foundation models to ensure their systems comply with eu regulations prior to becoming available on the market by documenting risk assessment and mitigation; incorporating appropriate data sources and examining for biases. the _ ai act_ has also received criticism from the ai ecosystem on the argument that it imposes excessive regulatory burdens and stifles innovation, contributing to europe\u2019s further disadvantage in ai. the _draft ai act_ is still undergoing review and revision, and it is expected that the final version will address some of the concerns raised during the consultation process. **the united states** the us does not have comprehensive federal regulations specifically focused on ai. however, various initiatives and efforts are underway to address ai-related concerns. this mainly consists of agency guidance: federal agencies such as (\u2018ftc\u2019), (\u2018nist\u2019), and the food and drug administration (\u2018\u2019) have all issued guidance and recommendations related to ai. for instance, the ftc provides guidelines on consumer protection and privacy concerns associated with ai technologies, while nist offers technical standards and best practices to promote trustworthy ai development and deployment and has proposed the ai risk management framework , which is intended to be voluntary. supplementing the agency guidance is the blueprint for an ai bill of rights () (the \u2018blueprint\u2019). the blueprint\u2014which is not binding\u2014 is intended to support the development of policies and practices to protect the civil rights and promote democratic values in the building, deployment, and governance of automated systems. us regulation is lagging relative to china and the eu, with no actual or proposed binding federal legislation to date. there have been ongoing discussions and legislative proposals in the u.s. regarding ai regulation. these efforts seek to establish federal laws that address a wide range of ai-related issues, including privacy, bias, transparency, and accountability. several bills have been introduced, but as of now, no comprehensive federal ai legislation has been enacted. while this absence of federal legislation may be thought to encourage innovation, an alternative possibility is that clarifying the regulatory framework\u2014or lack thereof\u2014can increase investment in ai due to greater legal certainty. ", "#### regulating risks posed by generative AI systems of paramount importance is the proper categorisation of the risks posed by generative AI systems, distinguishing between the short-term and long-term risks. this policy brief focuses on the short-term risks outlined in the briefing paper , which are (i) impersonation and disinformation; (ii) privacy and security; (iii) bias and discrimination; and (iv) intellectual property infringement. the regulatory strategies used, or proposed, to mitigate these risks are discussed in turn. ** impersonation and disinformation** generative AI systems have the capacity to mimic individuals, resulting in the proliferation of advanced disinformation and fraudulent activities. this section considers two epistemic threats. the first threat concerns disinformation created by malicious agents, like phishing messages. **** the second threat concerns factual failures and reasoning errors generated by ai systems, referred to as \u2018hallucinations\u2019. **** these threats can be thought of as human-made disinformation and ai-generated misinformation, respectively. in regard to human-made disinformation, regulations can be imposed on both the providers and users of generative AI systems. the eu\u2019s  strengthened code of practice on disinformation provides a set of guidelines for signatories to better self-regulate. commitment provides that signatories can mitigate human-made disinformation by warning users of the ai systems and proactively detecting such content. this standard mirrors article () of the _ ai act_ , which provides that, unless it is \u2018obvious from the circumstances and the context of use\u2019, providers must inform natural persons they are interacting with their ai systems. to prevent the distribution of manipulative content, article () provides that users of ai systems who create deepfakes **** must disclose that they have been artificially generated. a report by the european parliamentary research service_en.pdf) notes that this labelling obligation \u2018could be a first step towards mitigating potential negative impacts\u2019, but is insufficient to address other issues. the _ ai act_ neither contains guidelines for disclosure nor includes sanctions for non-compliance (article ). further, it is unclear how actors sharing deepfakes anonymously would be held accountable. china\u2019s \u2018 provisions on the administration of deep synthesis of internet-based information services \u2019, which came into force on , are instructive here. **** these provisions prohibit persons from using generative AI systems to produce or disseminate false information (article ); require the authentication of persons using deepfake technologies (article ); and establish mechanisms for refuting rumours created by such systems (article ). policymakers should consider whether different sociopolitical conditions would affect the feasibility of these regulations within their own countries. because chinese internet users have a greater \u2018digital fingerprint\u2019, as they are often required to link their online accounts to their government-id-linked phone numbers , malicious agents may struggle to conceal their identities online. there may be competing policy objectives, as suggested by measure . of the strengthened code of practice on disinformation, which notes that policies to detect and sanction the impermissible use of deepfake technologies must be trustworthy and \u2018respect the rights of end-users\u2019. with respect to ai-generated misinformation, regulators ought to maintain a balanced approach. in a blog post concerning /research/gpt-) , openai acknowledged that \u2018new risk surfaces\u2019 will emerge as models become more powerful and their fields of content expand. it is conceivable that the complete eradication of hallucinations may be an unattainable objective. greater attention is required in the eu to address this issue. as has been [observed -authorities-scrutinize-chatgpt-experts-see-ai-regulation-the-horizon) , the original proposal of the _ ai act_ did not foresee the proliferation of generative AI systems. the _gdpr_ addresses this gap to a limited extent. in circumstances where the hallucination provides false information about a particular individual, a claim may arise under article of the _gdpr_ , which provides that personal data must be accurate, and reasonable steps must be taken to rectify or erase inaccurate data. in addition to the aforementioned scenario, the absence of provisions governing hallucinations presents a potential peril whereby individuals may excessively depend on systems without engaging in discerning assessment of their outputs. it must be noted that the providers of ai systems are not _entirely_ blameworthy for hallucinations in all circumstances. users may unintentionally pose a question in a manner that causes the system to \u2018untether\u2019 from factual training data. for example, when asked to provide \u2018at least five examples, together with quotes from relevant newspaper articles\u2019 of sexual harassment by american law professors, chatgpt falsely listed the (real) university law school professor, [/story/opinion/columnist////chatgpt-misinformation-bias-flaws-ai-chatbot//) . the response (falsely) claimed that turley was a member of , citing a [(non-existent) technology////chatgpt-lies/) [article that supposedly reported the harassment occurred during a class trip to alaska (which turley clarified had never happened before). as indicated within the recommendations section, regulatory measures aimed at mitigating the incidence and associated hazards of hallucinations may necessitate comprehensive coverage of both the development and utilization of generative AI systems. **** **privacy and security** models trained on personal data can generate highly realistic and identifiable information, creating risks for privacy and security. this concern transcends the realm of individual privacy and security, encompassing broader considerations. in ,  banned /-bans-chatgpt-and-other-generative-ai-use-by-staff-after-leak) [employees from using /-bans-chatgpt-and-other-generative-ai-use-by-staff-after-leak) following concerns that internal sensitive code that had been uploaded could be provided to other users. the _gdpr_ is more relevant to privacy and security issues than the _ ai act_ . the gdpr requires consent from individuals before collecting personal data (article ); provides individuals with the rights to access their personal data (article ) and delete it (article ); and contains measures to protect personal data from unauthorised access, use, or disclosure (article ). since [/news/technology-) , openai and data protection authority\u2014 have contested the lawfulness of chatgpt\u2019s data collection processes. this reveals the regulatory challenges that generative AI systems pose to the _gdpr_ . specifically, the garante called for [a range of measures concerning data processing , which sought to resolve four identified breaches of the _gdpr_ . firstly, openai did not initially prevent minors from accessing chatgpt. secondly, chatgpt can generate inaccurate information about people (ie hallucinate). whether the _failure to explain_ how personal data is processed, and _failure to_ _explain_ responses that utilise personal data are, breaches of the _gdpr_ is a contested issue. the \u2018right to explanation\u2019 is not mentioned in the _gdpr_ \u2019s articles, and the relevant recital ( recital  ) has no legal force . nevertheless, article of the _gdpr_ concerns erasure or rectification of inaccurate personal data. thirdly, users were not provided with an explanation as to how their data was being collected. article of the gdpr provides for the \u2018right to be forgotten\u2019 such that an individual can request to have their data removed from the model. it is worth noting that an absolute \u2018right to be forgotten\u2019 may be unattainable. there are concerns that personal [data becomes embedded in generative AI /en/insights/does-chatgpt-comply-with-eu-gdpr-regulations-inves) , making it \u2018nearly impossible to remove all traces of an individual\u2019s personal information\u2019. lastly, the large amounts of personal information being collected to train future iterations of chatgpt could not be justified under any of the six bases in article () of the _gdpr_ . the us blueprint lists \u2018data privacy\u2019 as a guiding principle. the blueprint calls for privacy protection by default, with an ongoing review for privacy risks; minimising data collection by confining it to situations where it is \u2018strictly necessary to [achieve] the [system provider\u2019s] identified goals\u2019; and ensuring best practices are followed to prevent data leaks beyond the consented use case. further, the blueprint outlines rights for the peoples whose data is being collected, including the rights to access that data; know who has access to that data; correct the data where necessary; and request the deletion of their data. certain domains (eg health, employment, education) are identified as deserving of enhanced data protection. this includes an ethical review of sensitive data that may limit opportunities or access to services; auditing data quality to ensure it is not inaccurate; limiting the extent to which sensitive data can be shared, sole or made public; and additional reporting requirements where necessary. china\u2019s _draft measures for generative AI services_ contains similar measures. the consent of data subjects is required for personal data used in the pre-training and optimisation of generative AI systems (article ()). further, providers must \u2018ensure the data\u2019s veracity, accuracy, objectivity, and diversity\u2019 (article ()). once this data is collected, providers have an obligation to protect it and treat it appropriately. pursuant to the __ article , providers must not \u2018illegally preserve input information from which it is possible to deduce the identity of users, \u2026 conduct profiling on the basis of information input by users and their usage details, and \u2026 provide information input by users to others\u2019. last, the \u2018right to be forgotten\u2019 is recognised in article , which provides that providers must \u2018promptly handle individual requests concerning revision, deletion, or masking of their personal information\u2019. ** bias and disinformation** generative AI systems can reflect biases present in their training data, entrenching discriminatory narratives. one of the highlighted issues presented by experts is the importance of improving the transparency of ai systems. however, gaining complete insight into how generative AI systems are trained may be an unattainable objective. the combination of complex training algorithms, proprietary considerations, large-scale data requirements, iterative processes, and the evolving nature of research and development pose challenges that can limit transparency and make it difficult to fully understand the intricacies of the training process. has recently proposed auditing requirements for very large online platforms (\u2018vlops\u2019) and search engines (\u2018vloses\u2019), which would be inserted into the digital services act . the current proposal would impose an obligation on vlops and vloses to provide vetted researchers with privileged access to data; subject themselves to annual independent audits; and publish reports on content moderation, risk assessments and risk mitigation. at the time of writing, chatgpt and other generative AI systems are not included in the list of vlops or vloses. however, paragraph of the proposal indicates that these systems may be subject to requirements if they are used by the listed vlops and vloses. in addition, the newly proposed article b of the _ ai act_ provides that foundation models\u2014which include generative AI systems like chatgpt\u2014must contain \u2018only datasets that are subject to appropriate data governance measures\u2019. providers of such models must therefore take appropriate measures to examine the suitability of the data sources and mitigate possible biases. in china, generative AI systems must \u2018respect social virtue and good public custom\u2019. thus, article () of the _draft measures for generative AI services_ provides that measures must be taken to prevent discrimination \u2018on the basis of race, ethnicity, religious belief, nationality, region, sex, age, or profession\u2019. this must occur throughout the lifespan of the ai system, including during the stages of algorithm design, selecting training data, model generation and optimisation, and service provision. lastly, the us blueprint lists \u2018algorithmic discrimination protections\u2019 as a guiding principle. the blueprint calls for a \u2018proactive assessment of equity\u2019 during a system\u2019s design phase; \u2018representative and robust data\u2019 that mitigates potential biases; proactive testing to guard against discrimination via proxy data; and disparity assessment and mitigation. ** intellectual property infringement** finally, generative AI systems raise questions about intellectual property rights and the implications of generating copyrighted works. providers have already faced liability risks, with class action suits having been brought against companies like github for their code-generating ai and /legal/ai-companies-ask-us-court-dismiss-artists-copyright-lawsuit---/) for their art-generating tool. similar regulations have been proposed across china and the us. in china, article () of the _draft measures for generative AI services_ provides that generative AI systems must \u2018respect intellectual property rights and commercial ethics\u2019. article () accordingly prohibits the use of data that infringes intellectual property rights from being used as pre-training or optimisation material for generative AI systems. in the us, the proposed [ai risk management framework states that training data subject to copyright should align with relevant intellectual property right laws. meanwhile, article b()(c) of the _ ai act_ imposes an obligation on providers of generative AI systems to publicly disclose the training data used that is protected under copyright law. this transparency provision was favoured over a blanket prohibition on the use of copyrighted material as training data. ultimately, this is a balancing act between protecting individuals\u2019 (intellectual property) rights on one hand and fostering innovation on the other. the application of copyright law to machines\u2014as opposed to the human creative process\u2014raises a fundamental question moving forward: should copyright law protect an artist\u2019s creative expression or their style more broadly? this discourse has been further convoluted by the recent position adopted in japan , wherein copyrighted materials incorporated within ai datasets are exempted from the purview of copyright law, except in cases where such utilisation would unreasonably jeopardize the rights of the copyright owner. ", "#### conclusion and recommendations the regulatory framework surrounding ai is characterised by rapid evolution. as of the present writing, the united states government is actively soliciting public input for forthcoming ai regulations, while divergent opinions persist among experts within the ai community regarding the potential suspension of training activities for systems surpassing the capabilities of . this section presents a conclusive overview of the proposed methodologies aimed at regulating the aforementioned risks associated with ai. of paramount importance is the proper categorization of these risks, distinguishing between the short-term and long-term risks posed by generative AI systems. as mentioned already, this policy brief places high emphasis on the short-term risks of the technology. **_short-term risks_** short-term risks pertain to the immediate hazards currently posed by generative AI systems. this policy brief has examined four such risks. **_. impersonation and disinformation_** .. for users, inform them that they are interacting with generative AI systems. .. for users, inform them of the ai system\u2019s limitations, which improves their ability to critically evaluate its output. .. for users, establish platforms where they can refute the validity of harmful generated content. .. for users, require identity verification before enabling access to generative AI systems. .. for providers, require detection procedures to identify malicious generated content. .. for providers, require content produced by generative AI systems to be labelled as generated. .. for providers, require \u2018stress testing\u2019 of models to test the vulnerability to hallucinations. **_. privacy and security_** . for users, enable age-gating to protect the personal data of minors. . for users, provide notice and require their consent to collect and use data for training purposes. . for providers, minimise the amount of personal data collected for training purposes. . for providers, allow users to opt-out of having their personal data used for training purposes. . for providers, establish mechanisms that allow users to delete their personal data from existing datasets. **_. bias and discrimination_** . for providers, establish bias mitigation measures throughout the lifespan of their systems, including the following stages: algorithm design, selecting training data, model generation and optimisation, and service provision. . for providers, exercise enforcement on the disclosure of data training models. . for providers, require regular independent audits and reporting on risk assessment and mitigation measures. **_. intellectual property infringement_** . for providers, prohibit the use of training data that infringes intellectual property law. alternatively, require reporting on copyrighted data that is used for training purposes. **_long-term risks_** the longer-term risk that generative AI systems _may_ pose is in accelerating society\u2019s arrival at artificial general intelligence (\u2018agi\u2019). agi refers to the ability of an ai system to perform a variety of tasks in different contexts and environments. the concept of agi exists in contrast to our current, \u2018narrow\u2019 ai systems, which perform tasks in specified contexts. within the ai community, there exists a division of perspectives regarding the fundamental inquiries surrounding the feasibility of agi and, if indeed attainable, the prospective timeframe for its realization. **** assuming that agi proves viable, apprehensions arise regarding its potential to profoundly and adversely impact humanity, potentially engendering existential perils. these concerns demand equitable recognition and warrant further scrutiny. in this vein, there are recommendations that policymakers increase investment in \u2018 safety and alignment research \u2019 so that our understanding of ai\u2019s long-term risks keep pace with technological developments. nonetheless, it is of utmost significance to uphold the differentiation between short-term and long-term risks, thereby averting potential diversions from the pivotal role that regulation may play in offering remedies to the aforementioned risks. ", "### endnotes one prominent example has been the \u2018hundreds\u2019 of fake profiles of ukrainian president, , that attempt to trick individuals into sending them money: , \u2018there are now hundreds of volodymyr zelenskyy impersonators on social media\u2019, forbes (online, ) <  >. this term has not been universally approved of, largely on the basis that it frames the problem in a manner that appears to anthropomorphize ai systems rather than depict the issue as one of \u2018untethered\u2019 text generation: , \u2018\u201challucination\u201d: when chatbots (and people) see what isn\u2019t there\u2019, (online, ) <  >. deepfakes are ai-generated audio or visual content. they need not be manipulative, and have recognisably beneficial purposes in areas like education and entertainment. however, deepfake technology can be used maliciously. a report by found that the vast majority of deepfake videos (%) were nonconsensual pornography: see , the state of deepfakes (report, ) , . again, there is no official english translation of these regulations, so the translation is relied on: rogier creemers and , \u2018translation: internet information service deep synthesis management provisions (draft for comment) \u2013 \u2019, (online, ) < -/ >. see, eg, toby walsh, \u2018the singularity may never be near\u2019 () () ai magazine . cf s\u00e9bastien bubeck et al, \u2018sparks of artificial general intelligence: early experiments with \u2019 []. ----- ", "### committee on information services _usc academic \u2013 provost joint committee_ _, co-chairs_ ", "# instructor guidelines for student use of generative AI for academic work the university of southern california's academic recommends that all usc schools, academic departments, and instructors adopt the following guidelines regarding student use of generative AI for academic work. _instructors should encourage usc students to explore generative artificial_ _intelligence (ai), using these new tools to create, analyze, and evaluate new_ _concepts and ideas that inspire them to generate their own academic work. in_ _advance of this exploration, instructors should help students recognize that some_ _contemporary ai-generated content may be specifically designed to appear_ _plausible and persuasive but is sometimes factually inaccurate._ _many of the issues that have surfaced with the introduction of chatgpt \u2013_ _questions about academic integrity, authorship and citations, student_ _engagement, misinformation and disinformation \u2013 are issues higher education_ _and society have encountered in the past in response to the need for digital_ _literacy. we suggest that generative AI is simply the newest addition to usc\u2019s_ _digital literacy tools._ _ultimately, this committee leaves instructors to set their own course policies_ _regarding student use of generative AI. whatever any given individual instructor_ _decides should be clearly communicated to students in course materials._ _however, the committee recommends that instructors remind students that the_ _acquisition of academic work in whole or in part from any source (from textbooks_ _and journal articles to web resources to generative AI) and the subsequent_ _presentation of those materials as the student's own work (whether that material_ _is paraphrased or copied in verbatim or near-verbatim form) constitutes an_ _academic integrity violation unless otherwise allowed by the instructor._ _individual assignments and exams may have additional, specific requirements_ _related to original work which should be clearly defined by the instructor._ _because generative AI is a constantly evolving space, the committee encourages_ _usc\u2019s instructors to begin to learn more about generative AI so they can better_ _adjust their pedagogy and evolve as educators._ last updated: ", "# the current state of student use of generative AI for academic work (midfebruary ) ", "## limitations of guidelines our focus in this document is narrow: to highlight the steps that usc\u2019s instructors need to take to identify and to state their expectations with respect to student use of generative AI for academic work. in to come, we expect that usc\u2019s academic community will be asked to participate in broader conversations about generative AI and its place in academe and society. ", "## what is chatgpt and what can it do? it is hard to overstate how much attention chatgpt, a free online artificial (ai) chatbot that generates text in response to prompts, has received since its launch on . one reason it has become so popular so quickly, surpassing million active users to become the fastestgrowing consumer internet application in history , is the ease and speed with which it can generate text on demand. ask chatgpt to \"write a five-paragraph essay on the impact recantation of the wages fund doctrine had on classical economics\" or \"explain what it means when people say, 'knowledge is knowing that frankenstein is not the monster but wisdom is knowing that frankenstein is the monster'\" or \"write a sonnet about clay helton\" and it creates plausible, human-like text responses in a matter of seconds. scholars, researchers, and educators have demonstrated that, given the right prompts, chatgpt can - pass the final exam of an mba-level operations management class at wharton - [(barely) pass questions on a law school exam at ) - [pass all three exams that comprise the united states medical licensing ) - [pass 's coding exams and /-testing-chatgpt-like-chatbot-apprentice-bard-with-employees.html) at the level of an entry-level software engineer with no prior industry experience. ", "## are students already using chatgpt for academic work? yes. students are starting to use chatgpt for their academic work. in a nationwide [survey of , students currently enrolled in us colleges and /nearly--in--college-students-have-used-chatgpt-on-written-assignments/) , nearly one-third of the students said they have already used chatgpt to complete a written college assignment and nearly two-thirds of that group say that they have used it for % or more of their assignments. we expect both percentages to be even higher . ", "## are there other generative AI text tools like chatgpt? yes. **chatgpt is just the first in a wave of generative AI tools that will soon become** **ubiquitous.** generative AI is algorithms and tools that can be used to create new content, including audio, code, images, text, simulations, and videos. recent new breakthroughs in the field have the potential to drastically change the way we approach content creation. ( mckinsey & /featured-insights/mckinsey-explainers/what-is-generative-ai) ) most of these new tools rely on \u2018large language models,\u2019 ai systems that use advanced statistical techniques to analyze and understand natural language data, such as text or speech, and generate human-like responses. , already a aipowered bing search engine and edge browser [major investor in openai (makers of chatgpt), launched a new in and intends to incorporate ai-content generation into office /articles/ghost-writer--looks-to-add-openais-chatbot-technology-to-word-email) like outlook, word, and powerpoint. later in , will release technology that will allow [companies, schools, and governments to create their own custom chatgpt-powered ai text generators . is expected to launch its own chatgpt competitor named bard in early . in of , meta (formerly facebook) released its open pretrained transformer (opt) large language model to developers and researchers. and that is just the beginning (see / for a list of hundreds of new ai tools that be used to generate text, images, audio, and more). considering this, **we suggest that rather than focusing solely on chatgpt, instructors** **should instead focus on what role they would like** **_all_** **generative AI tools to play in their** **classes and in their students' work going forward** **.** ", "## how might instructors approach student use of generative AI? we suggest that there are two ways instructors can approach student use of generative AI: . embrace and enhance . discourage and detect ", "#### embrace and enhance the good news is that many of the proven teaching and assessment techniques that worked in a pre-generative AI world still work in a world where any student with a cell phone and a generative AI account can create walls of academic(-sounding) text. usc's center for excellence in teaching (cet) recently published a guide titled \" using ai /teaching-resources/using-ai-text-image-and-music-generating-tools-in-your-courses/) [image, and music-generating tools in your courses \" that includes helpful ideas for incorporating ai-generators and ai-generated content in your course, including evaluating and critiquing aigenerated content (including interrogating the content for biases) and asking students to create rebuttals. like our recommendation that students should use generative AI to create, analyze, and evaluate new concepts and ideas that inspire them to generate their own academic work, cet recommends having your students use ai generators to brainstorm ideas, formulate and iterate question prompts, and refine responses, adding that you should frame using ai tools as something to build upon. remind students of the best way to use these tools in their discipline, such as for idea generation, essentializing, brainstorming, or gathering information about the typical understanding of a topic. all uses of ai tools should be supplemented with appropriate evidentiary support and reflection. some students may lack the foundational knowledge to understand why or how ai-generated content is inaccurate. this presents an excellent teaching opportunity for you to demonstrate for your students generative AI's strengths and weaknesses. cso offers several suggestions on designing assignments and assessments in the age of ai generators, including - asking more nuanced questions, beyond simple definitions and common comparisons, related to the course text, articles, media, or activities that may be unknown to or beyond the capabilities of current ai generators, - having students complete assignments and assessments during class time, - requiring students to submit drafts of their papers or projects before they submit their finished work, and - augmenting written papers with additional oral presentations, concept maps, group work, or case studies so that students can further demonstrate their understanding of the course objectives. if you are going to allow your students to use generative AI as a source in their academic work, you may want to consider requiring your students to clearly disclose the role generative AI played in formulating their work. openai also has recommended language that you may want to adapt and adopt: the author generated this text in part with gpt-, openai\u2019s large-scale languagegeneration model. upon generating draft language, the author reviewed, edited, and revised the language to their own liking and takes ultimate responsibility for the content of this publication. ", "#### discourage and detect some educators have asked how they can block student use of chatgpt (see new york city department of education and others ). we suggest that that would be akin to standing on the shore hoping to block a rising tide. generative AI is here and is not going away. that said, **if you** **wish to** **_discourage_** **student use of generative AI, let your students know this expectation** **both in your syllabus and in class.** the guidelines listed at the beginning of this document should serve as a good starting point. you may also consider adapting and adopting something like _/content/page/science-journals-editorial-policies#authorship)_ [journals' artificial intelligence (ai) policy : text generated from ai, machine learning, or similar algorithmic tools cannot be used in papers published in science journals, nor can the accompanying figures, images, or graphics be the products of such tools, without explicit permission from the editors. in addition, an ai program cannot be an author of a science journal paper. a violation of this policy constitutes scientific misconduct. another approach is _nature_ journals' large language model guidelines : large language models (llms), such as chatgpt, do not currently satisfy our authorship criteria. notably an attribution of authorship carries with it accountability for the work, which cannot be effectively applied to llms. use of an llm should be properly documented in the methods section (and if a methods section is not available, in a suitable alternative part) of the manuscript. in class, you can discourage student use of generative AI by encouraging students to use other tools and techniques instead. in fact, many of the teaching and assessment techniques recommended by the /teaching-resources/using-ai-text-image-and-music-generating-tools-in-your-courses/) \u2013 ask more nuanced questions, have students complete assignments and assessments during class, require students to submit drafts, augment written papers with other activities that demonstrate students\u2019 content knowledge \u2013 work equally well if you want to embrace and enhance or discourage and detect student use of ai generators. however, we do not consider requiring handwritten assignments to be an effective technique to discourage or detect. students who have academic accommodations may need to use assistive technology in your class. prohibiting student use of technology or requiring that all students handwrite their work may create a situation that singles out students with accommodations if they can use technology while others cannot. as for detecting if students' typed academic work contains ai-generated text, the best way is to honestly grade that work and look for errors. some, if not most, contemporary ai-generated text is [specifically designed to appear plausible and persuasive but is not necessarily accurate . openai cautions that \" chatgpt sometimes writes plausible-sounding but incorrect or nonsensical answers .\" because of this, current generation ai text generators have the propensity to make easily discernable, fundamental mistakes that a subject matter expert or even an 'experienced novice' would never make (see \" cnet's article-writing ai is already /cnet-ai-errors) [very dumb errors \", \" why meta's latest large language model survived online \", \" chatgpt needs some help with math assignments ,\" and \" alphabet shares dive after google ai chatbot bard flubs answer in ad \" for some recent examples). even if students rewrite aigenerated text to avoid detection, the structural and factual errors in current-generation aigenerated text should remain. but those detectable weaknesses may not last forever, especially with future generations of ai text generators. another option is to use a 'similarity detector' (often mistakenly called a 'plagiarism detector') like . , which is available in every usc blackboard course, scans submitted text and highlights any phrases or paragraphs that are identical or closely like other sources known to . since some ai text generators have been known to copy from other sources without attribution \u2013 see \" cnet's ai journalist appears to have committed extensive plagiarism \" \u2013 tools like _may_ detect ai-generated text. or not. has announced that it will roll out additional, built-in ai writing and chatgpt detection features soon. open ai, makers of chatgpt, recently released their own ai text classifier tool at  that \"predicts how likely it is that a piece of text was generated by ai from a variety of sources.\" the tool currently \"r equires a minimum of , characters, which is approximately - words.\" also developed a popular tool named gptzerox at / that \"highlights portions of text that are most likely to be ai generated\" and allows you batch upload files \"in pdf, word, and .txt format.\" one word of caution: students may be able to circumvent these tools. as melissa heikkil\u00e4 noted in an article in the mit technology review in , \"[b]ecause large language models work by predicting the next word in a sentence, they are more likely to use common words like 'the,' 'it,' or 'is' instead of wonky, rare words.\" with this in mind, at the national center for ai in tertiary education found a simple technique to fool many chatgpt detectors , including gptzerox: . have the ai text generator create some text. . then ask the ai generator to \"use the word 'the' less\" we tried this technique and were able to 'fool' both openai\u2019s ai text classifier and tian's gptzerox into claiming that text copied straight from chatgpt was most likely written by a human and not ai. ", "## conclusion the age of ai-generated content is upon us. in , openai\u2019s chatgpt has created a million user market for ai-generated text content that did not exist at scale . and chatgpt is just the first in a wave of generative AI tools that will soon become ubiquitous. because of that, rather than focusing solely on chatgpt, we strongly recommend that instructors instead focus on what role they would like all generative AI tools to play in their classes and in their students' work going forward \u2013 either by embracing and enhancing or discouraging and detecting students\u2019 use of this technology. ", "## additional resources - usc center for excellence in teaching ai generators in the news - educause quickpoll /educause-quickpoll-results-did-chatgpt-write-this-report) - mit technology review \u2013 [artificial intelligence - the register \u2013 artificial intelligence - national centre for ai in tertiary ) - library's [repository of information about the impact of chatgpt on/in higher education ", "# considerations for integrating ai within teaching and learning ", "### purpose this resource provides educators with guidance regarding ways to utilize ai within teaching and learning in ways that are effective, ethical, and equitable and that will empower educators and learners\u2013both traditional and non-traditional learners\u2013alike. these are considerations, not requirements. educators do not _have_ to teach with or about ai, but there\u2019s good reasons to do so, and should someone wish to, here are some things to consider. this document is not and cannot be exhaustive. it concerns a very complex set of ideas with details that not only evolve over time, sometimes very quickly, but also have different meanings in different contexts. this university-level document should begin discussions and decisions made by individual educators and groups of educators (e.g., departments, schools, programs), not end them. ", "### audience this resource and the considerations offered here are primarily intended for ud educators responsible for teaching courses at any level, associates through doctoral. a secondary audience includes leaders of academic units (e.g., deans, department chairs, school directors) who may wish to utilize or adapt these considerations when creating unit- or discipline-specific ai-in-education policy documents for their units. ", "### context: generative AI as a catalyst for educational transformation the center for integrative research in computing and learning sciences defines ai as: \u201ca branch of computer science. ai systems use hardware, algorithms, and data to create \u2018intelligence\u2019 to do things like make decisions, discover patterns, and perform some sort of action. ai is a general term and there are more specific terms used in the field of ai. ai systems can be built in different ways, two of the primary ways are: () through the use of rules provided by a human (rule-based systems); or () with machine learning algorithms. many newer ai systems use machine learning\u2026[employing] an algorithm [that] will identify rules and patterns in the data without a human specifying those rules and patterns. these algorithms build a model for decision making as they go through data. (you will sometimes hear the term machine learning model.) because they discover their own rules in the data they are given, ml systems can perpetuate biases. algorithms used in machine learning require massive amounts of data to be trained to make decisions.\u201d while ai has been a focus of scholarship and development since , recent advances in _generative ai_ have catalyzed great interest, concern, and activity, particularly in regards to education. generative AI refers to \u201cai techniques that learn a representation of artifacts from data and use it to generate unique content (including images, video, music, speech, and text) that preserves a likeness to the original data.\u201d these considerations are offered in response to the unique ethical, practical, and educational challenges arising from generative AI. ", "### scope given that ai is a broad topic, this resource is necessarily limited in scope, specifically to that of the use of ai and automation within teaching and learning. for example, while ai has been leveraged in the application of self-driving cars, that application of ai is outside the scope of this resource. also, the field of ai - including generative AI - is constantly evolving and doing so rapidly. considerations are thus offered without reference to specific ai applications (e.g., chatgpt, dalle), retaining the focus on those considerations that would plausibly generalize to whichever tool or application may be used. finally, as the field of ai advances, new considerations will emerge. thus, this resource is offered as a starting point, meant to begin and not end conversations around this important topic. ", "## reasons to consider ai in teaching and learning ", "### ai can improve education ai can help educators achieve educational priorities in ways that can easily be used with many learners and can be widely accessible. for instance, ai has the potential to provide opportunities for immediate and substantive feedback, appraising growth and progress, and exercising creativity and critical thinkin o\u2019regan, (). history of artificial intelligence. in: a brief history of computin springer, .  generative AI,\u201d information technology glossary, , .  **i** lodge, , , , , , p. (). it\u2019s not like a calculator, so what is the relationship between learners and generative AI? _learning: research and practice, _ (), . /./.. ", "### ai is increasingly prevalent these tools are becoming widely available and used throughout modern society. educators have an obligation to provide opportunities for learners to learn about ai to ensure learners are prepared to use ai and automation systems effectively and ethically within employment and society more generally as engaged and informed citizens. many learners are already using ai tools , and for educators to consider ai in their own classrooms allows them to better set expectations for how learners can and should use ai in their courses. ", "### ai raises a number of concerns and risks although ai is increasingly being used throughout society, there are risks associated with ai. educators have a responsibility of ensuring that learners are cognizant of those risks to ensure that learners use ai safely, ethically, and effectively. in this way, educators may help shape the future of ai in a positive direction. ", "## considerations for integrating ai within teaching and learning university of delaware educators contemplating the use of artificial intelligence (ai) tools and models should weigh and prioritize the following considerations. these considerations are offered with the goal of ensuring that using ai preserves \u2013 even strengthens \u2013 but never diminishes the value and values of a ud education. the integration of ai within teaching and learning should be: ", "### human-centered ", "#### . ai within teaching and learning should be \u201chuman centered\u201d a. to be human-centered means that the goal of implementing ai should be to \u201cincrease human self-efficacy, creativity, responsibility, and social connections\u201d and to \u201camplify human abilities, empowering people in remarkable ways while ensuring human control.\u201d accordingly, the human-centered application of ai within teaching and learning should facilitate educators to focus more on what they are uniquely capable of coffey, lauren. (). learners outrunning faculty in ai use. _inside higher ed,_  ty-ai-use schneiderman, (). [human-centered /permalink/udel_inst/tuoc/alma) . new york, ny. . page . ibid. page . and facilitate learners to engage in higher levels of thinking . importantly, the application of ai should not reduce the energy directed at teaching and learning, rather it should create a productive division of labor, shifting the focus towards new, more innovative, and higher levels of critical engagement. ", "#### . educators should be \u201cin the loop,\u201d remaining responsible for teaching and educational decision making a. while ai can streamline tasks like feedback, assessment creation, grading, and material development, saving time and effort, it's crucial that educators actively supervise and confirm the validity of ai outputs. ultimately, the responsibility for instruction rests solely with the educator; the ai cannot take responsibility. ", "### transparent ", "#### . educators should make their expectations regarding learners' use/non-use of ai explicit a. educators should be explicit about what uses and tools are and are not appropriate. moreover, and perhaps more importantly, educators should not just set those policies but also to teach learners, or direct learners towards resources, the knowledge and skills they need to successfully comply with those policie b. if learners are allowed to use ai tools, educators should ensure that there are clear expectations about how to cite their use, and whether or not learners should submit supplemental artifacts with their work (e.g., the prompt[s] they used to develop and refine their work, revisions made to the original output). c. educators should help learners understand that expectations likely will not generalize from one instructor to the next. special attention should be paid in courses that have multiple sections taught by different instructors to establish some consistency. d. educators are cautioned against using ai detectors as their reliability has shown to be weak, often generating an unacceptable rate of false positives (i.e., human-written text flagged incorrectly as ai generated). lodge, , , , , , p. (). it\u2019s not like a calculator, so what is the relationship between learners and generative AI? _learning: research and practice, _ (), . /./.. elkhatat, a.m., elsaid, , evaluating the efficacy of ai content detection tools in differentiating between human and ai-generated text. _international journal for educational integrity, _ (), (). --- salem, , fiore, , kelly, , & brock, ). _evaluating the effectiveness of \u2019s ai writing indicator_ _mode_ center for the advancement of teaching, temple university.  n%e%%s%ai%writing%indicator%model_.pdf ", "#### . educators should make their own use of ai tools transparent. a. educators should model transparent and ethical behaviors and practices when using ai tools in educational contexts. for example, ai tools used to create or modify educational materials \u2013 syllabi, slides, etc. \u2013 should be appropriately cited or acknowledged. b. educators who are using ai tools that access student data or provide input into decisions about learners (e.g., recommendations about grades) should also be appropriately and ethically transparent about their use of those tools. ", "### ethical ", "#### . educators should consider issues of access, equity, bias, and fairness when using ai within teaching and learning a. educators should ensure that ai tools and models are accessible to learners in every appropriate interpretation of \"accessible\" e.g., financial, technical, cultural. this includes appropriate expectations regarding learners' ai literacy and how that is built and supported. b. educators are encouraged to evaluate the outputs of the ai system given the potential of ai to amplify existing socio-cultural biases. an examination of potential bias should be considered and unpacked in the classroom. c. educators should solicit feedback from learners regarding their perceptions of those outputs, be they scores, feedback, text, images etc., to ascertain whether some groups of learners are systematically experiencing different levels of usability and usefulness with the ai tool. ", "#### . ai use should be aligned with policies and practices protecting learners\u2019 data and privacy a. consistent with existing laws and policies governing data privacy such as ferpa, educators should not submit or encourage learners to submit personally identifiable information or other confidential data to ai systems that do not provide sufficient protections and appropriate assurances of privacy. b. laws concerning generative AI, intellectual property and copyright, especially around fair use, are unsettled at this time. educators should understand how data used in ai tools are stored, used, and protected. for example, educators should not upload copyrighted materials (including most materials accessed through the library). ", "#### . the greater the consequences, the more educator expertise, knowledge, and involvement is necessary a. educators should be appropriately knowledgeable about ai tools they use and the tools they require or encourage students to use. without appropriate knowledge, it will be difficult \u2013 if not impossible \u2013 for educators to remain \u201cin the loop\u201d and provide oversight on the effective uses of ai in their instruction. the level of knowledge should be balanced against the intended use and impact of the tool with more intensive and consequential uses requiring more detailed knowledge on the part of the educator. b. the greater the consequence attached to the outcome/decision, the more important it is to retain human control/autonomy. for example, providing learners with feedback has relatively low stakes. learners may elect to fully adopt, partially adopt, or ignore feedback given to them. in contrast, grading \u2013 especially summative grading where learners are not given opportunities to revise or resubmit \u2013 has higher consequences. ai and automation might be used in both cases, but the latter case would require much greater educator oversight. ", "### educationally effective ", "#### . use of ai within teaching and learning should be aligned with best practices in instruction and theories of how we learn a. ai most productively supports teaching and learning when integrated with modern learning principles: ai tools and models should be employed in alignment with our best understanding of effective teaching and learning, including but not limited to an emphasis on practice and feedback, organization of knowledge, incorporation of prior knowledge and culture, metacognition, and the development of self-regulation and self-direction. b. ai doesn\u2019t change everything. when using ai in the classroom, the basics should still apply: \u201cwhat do i want learners to be able to do as a result of this activity?\u201d ", "#### . effective use of ai requires some explicit instruction in the use of ai a. educators are encouraged to instruct learners in productive ways of using ai tools, developing learners\u2019 knowledge, skills, critical thinking, and ethical awareness of ai to develop their ai literacy. ", "## additional resources - white house: _blueprint for an ai bill of rights_ \u25cb / - us department of education office of educational technology: _artificial intelligence and_ _the future of teaching and learning_ \u25cb ) - unesco: _recommendation on the ethics of artificial intelligence_ \u25cb [ ___________________________________________________________________________ . (). _how people learn: brain, mind, experience, and school: expanded edition._ washington, dc: the national academies press. /./ . ", "# cross-campus approaches to building a generative AI policy esther /esther-brandon-) , [lance eaton , ) and [allison ) [emerging technologies and trends editors' pick min read particularly for new technologies that disrupt long-standing practices and cultural beliefs, the work of carefully and intentionally developing effective policies can pay significant dividends. credit: vinnstock / shutterstock.com \u00a9 policy creation might not be exciting, but it is essential, especially when something new arrives on the scene and an organization does not have an easy or clear means of modifying existing policies to accommodate the new development. one such arrival happened in with generative AI, and , many colleges and universities are still scrambling to figure out an ai policy that works at the institutional, departmental, and course levels. new technologies tend to follow a particular hype cycle, particularly in higher education. however, the possibilities, problems, and paradigms that generative AI tools such as chatgpt, 's bard, and 's ai-powered bing represent are many and can touch every part of the institution and its stakeholders. higher education focuses on building knowledge and investing in the written word, whether it's scholarly research or demonstrations of learning such as essays, research papers, theses, or dissertations. the underlying assumption is that such work could not be significantly faked aside from paying another individual (such as student paper mills) or taking the work of others without attribution. generative AI upends much of that baseline and in fact will challenge many institutions' academic integrity policies because they often prohibit copying from websites or acquiring papers from other individuals. generative AI will also introduce other ethical and procedures considerations throughout the institution. in this article, we provide guidance and recommendations for approaching the development of institutional policy around using generative AI tools in higher education. we aim to help leaders in higher education institutions work more effectively to establish a pathway to a policy that includes various stakeholders and ultimately reduces the risk that members of the institution will take policy matters into their own hands, resulting in problems for the entire institution. this piece evolved from our institutional roles (instructional design, writing support, and research and library support), our individual work at our respective institutions, and a workshop on generative AI policy development that we facilitated for the nercomp annual conference. the workshop included a student panel, followed by focused conversations around several topics related to generative AI: ethics and plagiarism, bias, instructional technology, opportunities, and threats. for the final part of the workshop, we facilitated a mini design sprint for policy development. ", "## the need for policy the number of ways that generative AI tools can be used is part of what has drawn so much attention to them. in higher education, generative AI has been used for press releases about students' deaths, for graduation speeches, and as tutors, to name a few examples. given the nature of knowledge work throughout higher education, institutions need to determine where generative AI tools are appropriate and where they represent ethical or legal challenges. one of the most pressing examples of areas for guidance is the discourse around plagiarism and how to detect it in an era of ai-generated content. institutions are under pressure (whether organic or manufactured) to respond in some manner to the rise of generative AI as a widely available tool. the first wave of awareness seemed to be generated around plagiarism concerns and worker replacement theories (\"students will never write original papers again\" and \"robots are replacing everyone\"). for those in higher education, the drumbeat of fearmongering about plagiarism has succeeded in capturing faculty and administrative attention. early on, some assumed that generative AI work submitted by students could be identified with generative AI plagiarism checkers. 's documentation states, \"our ai writing detector's false positive rate is less than % for documents with % or more ai writing (our tests showed that in cases where we detect less than % of ai writing in a document, there is a higher incidence of false positives).\" however, after the ai detector was used in practice, across million papers, false negative and positive detections are now at a higher risk. and other companies claim to offer greater odds of correct detection than reality seems to bear out. additionally, further research is showing biases in what ai-plagiarism detection tools flag as being ai generated, including an increased likelihood of inaccurately flagging multi-language learners' work as having been generated by ai. beyond the problem of false accusations, this environment also creates an untenable situation for students who must somehow defend themselves against a machine that cannot show its work but is just a projection. additionally, students are using tools such as quillbot, which will paraphrase text and use synonyms, to circumvent ai detection tools. as original student writing becomes increasingly difficult to verify and confirm, developing a policy for ai detection might result in its being outdated just as the policy is implemented. having an agile committee representative of diverse campus needs who can both review these issues and considerations to craft a more useful policy is part of what is needed to both protect students and choose the right tools for navigating the technological changes. this is but one issue that higher education needs to navigate when crafting policy around generative AI. other issues include but are not limited to the following: the role of generative AI in visual and outputs of the institution, be they for marketing, for social media, or in reports how and where faculty can use generative AI in the creation of course content, assignments, and feedback or assessments addressing the embedded biases of the data and outputs the impact and challenge of information literacy the environmental impact of generative AI, including greenhouse gasses and water usage the impact on workers needed to run generative AI ", "## starting with the end in many areas of life, including instructional design, an ideal place to start is with the results\u2014what you want the outcome to be or do. to feel that your\u2014and your collaborators'\u2014time has not been wasted, and to see that you have made progress toward what might still be an abstract version of achievement, codify what success looks like for you, your collaborators, your stakeholders, and the final institutional arbiters. as ai continues to develop at a rapid pace, it is important to pause and do enough research so that you can formulate the questions you ultimately seek to answer. below are some questions to get you started in thinking about this policy: whom is the policy going to focus on? students, faculty, staff, administration, third-party vendors, contractors, etc.? can the same policy apply across the institution, or will different policies be needed for different parts of the organization? will the policy stand on its own, or will there be room for adjustments (for example, will students encounter variations depending on whether instructors\u2014under the notion of academic freedom\u2014want to encourage or discourage certain uses of generative AI for the purposes of teaching)? what can or will be the implications of violating the policy? what methods of accountability with the policy can be created when it may be hard to actually detect generative AI text? will there be differences between institutionally affiliated generative tools and those that are available to anyone? perhaps you are still in the fact-finding and idea-generating stage\u2014you might need to specifically dedicate time to consider what will constitute your goal for the mission. you may decide that success for your group means developing and writing down these measurable goals. that is, you might still be in the phase of brainstorming and research, and you might need to take time to decide what your goals are. ultimately, all involved should agree on specific measurable outcomes that are necessary for your group to have completed your work. it is natural to feel a sense of urgency to take action, and it might be tempting to rush through this step. although this process will not necessarily be easy, it will be helpful in carving out exactly what you are going to do in this phase. one of the trickiest parts about generative AI is that it has continued to change and shift in and will likely continue to do so, especially as other forms of generative AI (image, audio, video, slides, etc.) become increasingly available. therefore, no matter what your goals are, creating a mechanism for revisiting, adjusting, updating will be equally important to name and anticipate early on. in that case, think in terms of not getting it perfect the first time through but having a process to iterate. ", "## identifying stakeholders generative AI has the possibility of hitting every part of the institution. because it is difficult to imagine an area that generative AI won't touch, it's useful to think about all the institutional stakeholders who will need guidance around usage of these new tools. start by considering all the user groups and their iterations at your institution. one approach would be to conduct an audit of your campus; if your institution has an organization chart, that is a great document to use as the foundation. some people and groups are likely not represented, so detective work will come into play. this is a great opportunity to break down institutional silos and examine your own invisible biases about the roles others play on our campuses. identify non-classroom student- and faculty-facing roles, which could include instructional designers, writing specialists, librarians, and academic support services. then move on to people whose work has an impact on the campus experience as a whole. this could include staff working in it (e.g., information security, academic computing, or web services), institutional communications, student life, even alumni relations. be mindful that just because a group is not readily visible to you does not mean that they will not be impacted by or have an impact on your policies. we are a good example of coming together to collaborate on ai policy. the diversity of our professional perspectives has lent itself to not only seeing different viewpoints but also creating the opportunity to truly understand the nuances in just how many ways ai is impacting our institutions. an important early step should be to involve your organization's office for accommodations\u2014that is, the person or people who oversee the institution's support for people with learning, cognitive, and ability differences. historically and even with generative AI, faculty and institutions often look to ban a given technology without genuine consideration of why or how it might actually benefit students with disabilities or be part of a larger strategy involving universal design for learning. keeping an awareness of ada compliance and the ways that generative AI can improve learning can only happen through intentional conversation with accommodation services on your campus. consider, too, your contingent communities, such as part-time educators (adjuncts) and part-time staff. how are they included in the community in general? do they experience regular communication patterns as the full-time employees do, such as being included in campus-wide emails? will you need to set aside time to engage them in discussion separately, and will they need more training and professional development as you enact the policies you create? look for allies who can serve as conduits to get people involved. for instance, adjuncts are often on campus for limited amounts of time during or might work elsewhere during typical business hours. when you are scheduling conversations, be mindful that you will need to create opportunities for those who work nontraditional schedules to be involved. generative AI represents questions for the whole institution, well beyond how it will be treated and used within classrooms. the administrative side of the campus will be affected by generative AI. university, for example, issued an apology after it was discovered that a -word email (sent from the university's peabody office of equity, diversity, and inclusion regarding the , mass shooting at ) was composed using ai. some questions to consider for other entities at your institution may include the following: will the institution's upper management consider using generative AI to surveil employees' work to detect efficiency or generate employee evaluations? should your policymaking efforts account for this scale of institutional use? how will ai be addressed in human resources, especially the recruiting and hiring process? in what ways will the community outside the campus be impacted by your policies? do you have community partnerships in which you offer students an opportunity to put their theoretical learning into practice? do you have an obligation to educate your students on the uses of generative AI as part of that collaboration? will your institution be viewed as being a policy and position leader on the subject of generative AI? what will be reasonable and equitable means of challenging outputs by generative AI? finally, one of the most visible and yet frequently overlooked communities is the students. the value of engaging students in determining this policy cannot be overstated. to craft a policy without their input could result in a policy that feels out of touch and irrelevant to them. at the nercomp workshop, the highlight was hearing at the student panel how they demonstrated their own deep and sophisticated thoughts about generative AI and its roles in their lives. in particular, the conversation should extend beyond plagiarism and also include student perspectives about how other institutional areas should be using it (e.g., faculty, marketing, communications). many students are aware of and interested in how generative AI is currently being employed in a wide variety of industries. students might be reading about the way used generative AI to restore voice to create a \"new\" beatles track, or they may be interested in how generative AI is being used to dramatically improve recycling programs. these interests might be general curiosity (to be encouraged!), but they might also tie into students' future employment goals. the consequences of not including a diverse array of groups in these conversations far outweigh any inconvenience you may experience when trying to find times and ways to gather input throughout the policy development process. our workshop included people from many of the groups mentioned, and a key takeaway was just how much we learned from each other. many realized that while something may seem obviously important to you, it may not even be considered by someone working in a different position. ", "## models for developing policies depending how an institution is structured and how much its leaders want to include different groupings within the organization, any of several models can be deployed to develop policies around generative AI. the following options are useful approaches and, to some degree, can be mixed and matched to meet the institution's needs and structures. ", "### task force model put out a call to action to form an inclusive team representing all aspects of the institution to create a policy task force. alternatively, it could be a smaller, nimbler team that works to engage with different stakeholders across the institution, creating a template policy for generative AI and adjusting and tweaking it for each area of the institution, in conversation and collaboration with relevant stakeholders. for instance, the policy for students and faculty is likely to look different from that of the marketing department, but realistically all of these groups should have ai policies. this might seem self-evident for students, but there are important questions to consider even for marketing, such as the use of generative AI image tools to represent students. would that adhere to the institution's ethos or marketing ethics? those are the kind of questions that would be relevant to marketing that students and faculty may not need to be involved in. ", "### governance model some institutions have governance models in which faculty and staff play pivotal roles in the development and creation of institutional policy, particularly around policies that directly impact the classroom and students. this can be a useful model to gather a range of voices throughout the organization and have a clear pathway and record (e.g., committee notes) of how decisions are made and implemented. yet these processes may encounter challenges in moving at an effective pace to make decisions that are timely and responsive to a changing environment. due to the rate of change in generative AI, committees might create policies for assumptions around generative AI that are no longer valid. ", "### design sprint model commonly used in it and project management fields, the design sprint approach is another successful model. we successfully used this model in our nercomp workshop, and these steps can be adapted for institutional or department use. an effective design sprint includes six steps: understand, define, sketch, decide, prototype, and validate. this format of developing a policy based on feedback from the community is more democratic in nature, allowing staff, students, and faculty to chime in with their ideas, thoughts, and recommendations. . understand: the first step is to understand how generative AI is currently being used (or isn't) at your institution, the concerns of the community, and the ideal state for ai use. this can be achieved through a listening tour, lighting talks, surveys, or structured conversations. . define: next, the policy team should review all the information gathered in the first step to define their main goals and desired outcomes that reflect the needs of the community. . sketch: each individual on the policy committee should sketch out their own draft policy that meets the definitions outlined previously. the larger committee can then review all policy drafts and then narrow down the ideas of each draft into a finalized solution sketch. . decide: the policy committee will then review all solution sketches to decide which version they want to use to move forward with the process. . prototype: the prototype can be considered the first draft of the policy to be shared with the community. . validate: return to the community members from the first phase of the design sprint process, gather feedback based on your policy draft, and make relevant edits. this is the last stage of the design sprint process, which will involve crafting the final version of the policy ready to be shared with your institution. ", "### consultant model some institutions may seek consultants to research, discuss, and implement new policy based on developing industry standards arising across academia. the value of a consultant can be that an external voice with relevant knowledge and experience provides a valuable perspective that helps folks think differently about the challenge. however, it can also have the opposite effect, wherein folks dismiss the consultant because of the costs involved, as well as concerns that an outside entity might not understand the context. ", "### exemplar model another option is to follow the lead of institutions that are publishing their own policies. for instance, and his students have proposed and posted policies for college unbound. starting with one of these policies, the institution can then review, share for input, and adapt as needed. this can save a lot of time in terms of coming up with the initial approach, but it will need to be tailored to the specific needs of the institution and its population. if the policy creation team is reluctant to borrow from another institution, they could use a generative AI tool to draft the initial policy and workshop it across the institution. we used chatgpt to generate several [/document/d/ycnnzvqswuc_ywrxbqwcolhrzprhxselb-ymhxg/edit?usp=sharing) of policies to help get you started crafting your own. ", "## recommendations for gathering voices to create the clearest and most effective policy, all stakeholders' voices must be heard. because recruiting volunteers for their insights in drafting a policy can sound tedious, consider using both formal and informal routes to get their assistance. also important is conveying how each stakeholder may be impacted by such a policy and emphasizing that their experiences and observations are highly valuable to the process. asking for help drafting a policy document can be overwhelming to many. these approaches might make this more engaging: connect with people in mini roundtable discussions or small-group conversations find help through social media\u2014use polling features to generate feedback and locate allies have one-on-one conversations with the people you see as your greatest supporters and greatest challengers in this process. diverse perspectives are necessary to have a policy that works for everyone. allow for enough time in discussions. it can be easy to rush through things, but these discussions will include deep topics and issues that need time to be fully processed. provide collaborative documents for participants to add text, and use the comment feature for questions or additional thoughts. institutional knowledge is both an advantage and a disadvantage in this process. some stakeholders will be obvious, and some people will quickly volunteer. others may be more challenging to reach because of their disinterest or because they don't see the relevance to their work. these are important people to bring into the conversation, rather than making assumptions about their thoughts or possible contributions. ", "## framework for generative AI policy creation below are the relevant sections that a generative AI policy should address to help institutions in their policy development processes. each institution should have its own individual policy based on the needs of its community. policy audience: whom is this policy for? is it for the entire institution, faculty, students, staff, departments, third-party vendors, or others? policy timeline: what is the timeline for implementation? should that timeline include a review and update cycle after initial implementation? policy tools: what counts as ai for this policy? is it focused on all ai or only generative AI? is it focused on all generative AI or just text-generating ai? academic integrity guidelines: if the policy is related to student or faculty work, what are the integrity requirements to make sure academic integrity is upheld? acceptable use: if ai usage is acceptable, are there any limitations on the amount of usage (e.g., a certain percentage must be individually generated in certain contexts) or purposes for which generative AI may be used? transparency: what practices are in place for communicating its usage throughout the institution? security and legal considerations: what concerns need to be addressed concerning privacy, intellectual property, and proprietary knowledge around using external or enterprise generative AI tools? does endorsing the use of generative AI conflict with any laws such as the general data protection regulation? ethical considerations: what concerns or responsibilities does the institution have explicitly or implicitly within its mission that conflict with the environmental, human-exploitation, and bias issues related to generative AI? institutional resources: which areas of the institution will be committed to supporting, responding to, and implementing uses of generative AI? processes for policy violation: if the policy is violated, what are the steps for identifying and addressing it? ", "## conclusion institutional policy development can often be a methodical process that both informs and better unifies an institution's approach to a particular challenge. and yes, it can be tedious. yet many institutions are often unprepared for technological developments, and the delays in catching up have a deep impact on students, faculty, and staff (e.g., the reactive response to the pandemic). although the generative AI cat is out of the bag, there's still an opportunity to meaningfully guide\u2014through a collaborative effort\u2014how it can be best used by all the stakeholders. such an approach will result in a better learning and working environment for students, faculty, and staff. taking an iterative approach to ai policy might feel unnatural for those who operate best with exhaustive policy documents, but it just might be the key to successfully navigating this new technological reality. ", "### notes . , \" is here. but most -here-most-faculty-lack-ai-policies) [lack ai policies,\" \u21a9 . , inside higher ed, . \"'s hype cycle and information system research /science/article/abs/pii/s) international journal of accounting information systems , no. (): ; , [\"what's journal of accounting information systems , no. (): ; , \"what's new in artificial intelligence from the  hype cycle,\" , september , . \u21a9 . miles klee, \"professor flunks all his students after chatgpt falsely claims it wrote their papers,\" rolling stone, . \u21a9 . , \"vanderbilt apologizes for /us-news//feb//vanderbilt-chatgpt-ai-michigan-shooting-email) [chatgpt in email on /feb//vanderbilt-chatgpt-ai-michigan-shooting-email) the guardian, ; josh moody, [\"the chatgpt commencement address,\" inside higher ; lauren coffey, \" taps ai to help teach computer science course,\" inside higher ed, . \u21a9 . , \"new research: 's ai detector shows no statistically significant bias against english language learners,\" support center, . \u21a9 . , \"detecting ai may be impossible. that's a big problem for teachers,\" washington post, . \u21a9 . , \"ai-detectors biased against non- native english writers,\" , . \u21a9 . emily m. bender, timnit gebru, major, and shmargaret shmitchell, \"on the dangers of stochastic parrots: can language models be too big?\" in proceedings of the acm conference on fairness, accountability, and transparency, \u2013, facct ', new york, , . \u21a9 . celeste and , \"how ai can /science.adi) [human /science.adi) science, . \u21a9 . , [\"green intelligence: why data and ai must become more sustainable,\" forbes, . \u21a9 . , \"ai programs consume /articles////ai-programs-consume-large-volumes-scarce-water) [volumes of scarce water,\" uc riverside news, . \u21a9 . and deepa seetharaman, \"cleaning /articles/chatgpt-openai-content-abusive-sexually-explicit-harassment-kenya-workers-on-human-workers-cf) [chatgpt takes heavy toll on human workers,\" wall street journal, . \u21a9 . , \"exclusive: openai used kenyan workers on less than $ per hour to make chatgpt less toxic,\" time, . \u21a9 . , , and , \"chatgpt: bullshit spewer or the end of traditional assessments in higher education?\" journal of applied learning and teaching , no. (, ). \u21a9 . , \"vanderbilt apologizes for using chatgpt in email on michigan shooting.\" \u21a9 . , \"ai used to create new and final beatles song, says /music//jun//ai-used-to-create-new-and-final-beatles-song-says-paul-mccartney) the guardian, june , . \u21a9 . , [\"ai robotics in recycling,\" environmental center, boulder, april , . \u21a9 . see \"design sprint methodology.\" \u21a9 . ibid. \u21a9 . , \"arbiters of effectiveness and efficiency: the frames and strategies of management consulting firms in us higher education ) journal of higher education policy & management , no. (): \u2013 . \u21a9 . see [\"proposal of usage guidelines for ai generative tools at cu.\" \u21a9 esther brandon is manager of learning design & technology adoption at medical school. is director of faculty development & innovation at college unbound. is director of the writing center at dutchess community college. allison papini is assistant director/manager of at bryant university. \u00a9 esther brandon, , , and . the text of this work is licensed under a creative commons by . international license . assessment and evaluation , artificial intelligence (ai)&q=&sortby=publicationdate_search&sortorder=desc) , diversity,&q=&sortby=publicationdate_search&sortorder=desc) equity, and inclusion (dei)&q=&sortby=publicationdate_search&sortorder=desc) , institutional =institutional+management&q=&sortby=publicationdate_search&sortorder=desc) , [instructional design , policy and law , [policy /search?topic_search=policy+development&q=&sortby=publicationdate_search&sortorder=desc) , [risk =risk+management&q=&sortby=publicationdate_search&sortorder=desc) ", "###### an experiment by , elisa farri and gabriele rosani curated by enrico sassoon ", "# generative AI for strategy & innovation ", "## chatgpt\u2019s recommendations to transform management theories and practices ----- introduction ", "#### the infinite potential of generative AI chatgpt has become a topic of conversation for nearly everyone. as a generative artifi\u00ad cial intelligence based on large language models (llms), it is not the only one available , but it is certainly the best-known and most widely used compared to its counter\u00ad parts: dall-e, bard, stable diffusion, midjourney, and others. in the history of technol\u00ad ogies, it currently holds the record for penetration, with million new users in . this record will be broken, as previous ones have been, and it will be fascinating to see who accomplishes this achievement and when. chatgpt is both fascinating and intimidating. the ability for anyone to interact with an interface capable of answering nearly any question, providing millisecond responses in impeccable language, is undeniably exciting. however, despite its remarkable com\u00ad petence, critics caution that it can make errors and even engage in what is technically referred to as \u201challucinations\u201d. regardless, bill gates considers it an epochal step, equal to, if not surpassing, the internet revolution. yet, there is also a worrisome aspect. the creators of chatgpt, such as of openai and others, harbor concerns about their own creation. while they are certain\u00ad ly not contemplating putting the genie back in the bottle, they emphasize the need for caution, the establishment of rules, and the definition of an ethical framework for the creation and utilization of ai. it is unlikely that they wish to stifle the goose that lays the golden eggs; more plausibly, they seek to safeguard themselves against the potential ad\u00ad verse outcomes of their creation. this book utilizes chatgpt not for recreational purposes or generic research and dis\u00ad covery, but to conduct an experiment exploring the tool\u2019s potential in the professional and cognitive domains. the authors of the experiment\u2014, , and gabriele rosani\u2014have immersed chatgpt in the realm of corporate strategy and cul\u00ad ture, investigating how generative AI can enhance the application of key strategic and organizational theories and practices, both in terms of incremental improvements and radical rethinks. the experiment encompassed ten management theories and practices, categorized into two main groups: business strategy and innovation, and organization and culture. a dialogue with ai was constructed using generated and regenerated prompts to obtain meaningful answers pertaining to well-known management theories and practices, such as the blue ocean strategy and agile. these answers were then compared with the pro\u00ad fessional experiences of the authors, who are seasoned consultants and have recently been included in the world ranking of thinkers. the path taken was meticulously prepared and rigorous, aiming to acquire reliable and qualified answers for further scrutiny. in fact, chatgpt was asked to rank the top three elements for each response based on established criteria: business value, speed of ex\u00ad ecution, cost of execution, and feasibility. the ranking provided by the generative AI was not subsequently challenged, although there were instances where the team held differing opinions. the outcome of this concentrated experiment, conducted over a handful of days, is of significant interest, not only because it may be the first of its kind, but also because it allows anyone interested to form their own opinion regarding the tool\u2019s potential. har\u00ad vard business review italia considers this with great attention, as shown by the recent publication of the book \u201cthe revolution of artificial intelligence\u201d. we are merely at the beginning, and the research continues. **enrico sassoon** ", "#### . approach , we conducted a series of experiments with chaptgpt plus (gpt-, and ) to investigate how generative AI can improve the appli\u00ad cation of leading strategic and organizational theories/practices, both in terms of incre\u00ad mental enhancements and radical rethinking. the scope of experiments included the following theories and practices, grouped in two main categories: - \u0007 **business strategy & innovation management:** value innovation; growth planning & experimentation; ; multi-stakeholder co-creation; open innovation. - \u0007 **organization & innovative culture** : leadership behaviors; flexible organi\u00ad zation; agile way of working; empowerment & decision making; employee motivation. the selection was based on two main criteria: i) theories/practices that are popular and globally recognized (such as blue ocean strategy, open innovation, or agile) and ii) on which we are domain experts (because of our extensive application, research and publi\u00ad cations over ). here below we provide more detailed information about our experimental approach: **format of interaction** : human-chatgpt dialogue (like a q&a with an expert). **role of chatgpt** : we asked chatgpt to act as an expert both in generative AI and manage\u00ad ment theories/practices. **context** : for each theory/practice, we input chatgpt with references in terms of: ide\u00ad ator of each theory/practice; articles or books explaining the related approach; exam\u00ad ples; case studies (mainly featured in media or academic publications). **prompting** : after testing various options, we selected a sequence of main prompts (i.e., text query/question) because it delivered the most accurate, creative and detailed answers: . prompt about valuable enhancements that generative AI can bring to the application of a se\u00ad lected theory/practice . prompt about common pitfalls . prompt about how generative AI can help overcoming the common pitfalls . again prompt # . prompt about the main shifts in human role and skills . \u0007 prompt about how generative AI can disrupt and radically rethink the selected theory/ practice . again prompt # . prompt about the ranking of top enhancements and top areas of disruptions ** steps** **to brainstorming** **chatgpt** **on management theories & practices** what is the **ranking** of the top most significant improvements and the top areas of radical rethinking? **criteria** **definition** what **enhancements** can generative AI bring to the application of the selected theory/practice? what are the main changes in the **human role** and related new skills? **peer review** how can generative AI **radically rethink** the selected theory/practice? **start** **input &** **references** what are the most **common pitfalls** that companies usually encounter when **personal** applying this **experience** theory/practice? **** how can generative AI help overcome the most common pitfalls identified? **peer review** legend: = role of the curation team source: , , **regeneration** : we often preferred to rephrase the questions to chatgpt, varying the prompting with additional information and feedback, rather than simply using the \u201cre\u00ad generate\u201d button. **ranking** : once the entire prompting sequence was implemented, we asked chatgpt to consider only the improvement ideas and radical transformations that we selected and reviewed. then we provided chatgpt with four evaluation criteria: business value, ex\u00ad ecution speed, execution cost, and feasibility. based on these specific criteria, chatgpt identified the \u201ctop improvements\u201d and \u201ctop radical transformations\u201d for each the\u00ad ory/practice examined in their respective chapters. the remaining ideas are presented without a defined ranking. we did not question the ranking determined by chatgpt, even though we had different opinions in some cases. chatgpt also provided detailed explanations for each criterion to support its evaluation. this further confirms the future possibilities of interaction and collaboration with chatgpt. **experiment rules & guidelines:** - \u0007 we created a new chatgpt plus account for this experiment. - \u0007 we created separate chats (\u2018verticals\u2019) for each theory and practice. we did not want to mix the topics, but most importantly we wanted to train the language model on select\u00ad ed theories and practice, laying the foundations for an ongoing experimentation. - \u0007 we assigned the theories and practices to the person with the strongest domain exper\u00ad tise (on average, each of us covered areas). - \u0007 we asked chatgpt to provide output in the form of items for each prompt. - \u0007 for prompt # we asked chatgpt to be creative when thinking of potential ideas for disruption. **human curation:** - \u0007 we challenged chatgpt answers based on our hands-on experience (e.g., \u201cbased on our experience, we\u2019d add another pitfall\u2026 or we\u2019d rephrase the last pitfall because of\u2026\u201d). - \u0007 we offered additional input, insights, examples (especially when chatgpt delivered answers we felt too generic). - \u0007 we commented responses to help chatgpt fine-tune and improve the quality of each an\u00ad swer. but also, to make it as much similar as possible to a human-to-human conversation. - \u0007 we peer-reviewed chatgpt\u2019s responses to judge the quality of the generated answers: elimination of least convincing items, sequencing and prioritization of the most in\u00ad sightful items, refinement of the labelling and the text (e.g., cutting some redundant parts of the generated text, or highlighting important parts), identification of criteria for ranking. - \u0007 we identified the criteria for evaluating and ranking the list of ideas proposed by chatgpt. ", "#### . our point of view: what we learned from interacting with chatgpt **an enriching experience.** on one hand, it provided us with valuable on-the-job train\u00ad ing. each interaction served as a learning opportunity, helping us refine our prompt\u00ad ing techniques and foster our critical thinking skills. on the other hand, engaging with chatgpt proved to be an intense mental exercise. it demanded a significant yet gratify\u00ad ing and stimulating effort. we found chatgpt to be an excellent resource, serving as a reliable partner in simulating exceptional, high-quality brainstorming sessions. **challenges and future approach** . concentrating our testing activities within presented its own set of challenges. to address this, we plan to utilize the tool for max hours a day in the future. this approach aligns with the principles of brainstorming among human participants, where the process is often spread out over multiple sessions. additionally, we aim to continue training the language model from a perspective of con\u00ad tinuous learning on each specific theory and practice. **sharing key takeaways for debate and improvement.** with the intention of stim\u00ad ulating constructive debate and inviting other experts and thinkers to join our experi\u00ad ment, we would like to openly share a detailed list of our key takeaways. **prompting** - \u0007 initially, chatgpt may provide generic and superficial responses, but subsequent prompts can be used to improve its accuracy and quality. - \u0007 when utilizing multiple sources such as books and articles, it is more effective to pres\u00ad ent them as a context and then query chatgpt \u201csource by source\u201d before requesting consolidation. - \u0007 certain topics consistently appear throughout various theories/practices, and chatgpt incorporates these recurring themes as part of its default model (e.g. integrating da\u00ad ta-driven insights, simulations, visualization, ethics). - \u0007 occasionally, chatgpt may mix significant insights with less valuable information, so human intervention is necessary to curate and select the most appropriate responses. if i f id d ki f b l i b h l f l - \u0007 to provide updates to chatgpt, specific excerpts from texts such as chapters, articles, or books can be entered. ", "###### we found chatgpt to be an excellent resource, a partner to stimulate high-quality brainstorming sessions **reprompting / regeneration** - \u0007 when interacting with chatgpt, it is important to request specific responses linked to the context of the chapter, avoiding overly generic answers, and encouraging the use of keywords related to the specific topic. there are instances where it is necessary to guide chatgpt to consider certain aspects more thoroughly or refer to specific articles, parts, or more granular details within a broader theory. - \u0007 chatgpt tends to perform better when provided with a well-defined input to work with, such as the \u201csix paths\u201d of the blue ocean strategy or the main steps of the discov\u00ad ery driven planning approach. customizing the response in a timely manner based on such inputs yields better results. - \u0007 while regeneration can help improve the rephrasing of answers, it may be less effective in generating significantly different responses. - \u0007 after some time, chatgpt may start repeating itself, requiring a change in the ap\u00ad proach or prompt structure. for example, explicitly asking for less obvious or intuitive items or exploring different perspectives can be beneficial. - \u0007 it can be useful to provide chatgpt with an \u201cadditive\u201d input, expanding on the initial list or asking it to consider similar things or explore new directions. - \u0007 requesting concrete examples is important, as chatgpt rarely generates them on its own. often, the value of the response lies in the provision of specific, detailed, and tan\u00ad gible examples. **tone/narrative** - \u0007 chatgpt often includes unnecessary pleonastic padding, resulting in the use of two or three sentences when one would suffice. - \u0007 it may be beneficial to ask chatgpt for a more engaging or fitting rephrasing related to the topic, as its default responses can be somewhat flat, repetitive, and uninteresting. - \u0007 the \u201cregenerate\u201d function can be employed to modify specific items, allowing for the rephrasing of answers by shortening, expanding, or making them less verbose through the use of examples - \u0007 creating narrative pieces by initially providing inputs or keywords helps establish the necessary connective structure, which can be further refined through multiple rounds of regeneration and requests for shorter or longer responses. - \u0007 additionally, fine-tuning can be employed to correct the wording in a more targeted manner (by instructing chatgpt on the desired style), followed by the incorporation of personal touches. ", "###### it is important to let chatgpt know what kind of narrative response we would like to obtain (number of words, paragraphs, narrative tone, ...) **creativity** - \u0007 chatgpt demonstrated an impressive level of creativity, in some cases better than many domain experts. - \u0007 when seeking disruptive thinking, encourage chatgpt to explore extremes by re\u00ad questing \u201cwild ideas\u201d that are radically different or unconventional. - \u0007 if after some iterations chatgpt becomes more predictable, it can be helpful to explic\u00ad itly prompt it to be more creative and to look \u201coutside the box\u201d. - \u0007 in first place, for chatgpt the notion of \u201cdisruption\u201d tends to be associated with tech\u00ad nological disruptions (such as ar/vr, blockchain, etc.), therefore prompt it to also ex\u00ad plore ideas that are not necessarily driven by technology. - \u0007 sometimes chatgpt may propose similar patterns/ideas for different theories. when this happens, ask chatgpt to better customize the idea to the specific context, adding concrete examples. ", "###### chatgpt has demonstrated an impressive level of creativity, sometimes surpassing that of many management experts **contents / cognitive bias** - \u0007 in the responses, the logic behind the sequence of the various bullets is often unclear. by applying deliberate pressure and requesting clarification, it is possible to gain a bet\u00ad ter understanding and encourage chatgpt to organize the information in a more log\u00ad ical and coherent manner. - \u0007 chatgpt may not be accurate in the distinction between ai and generative AI and between ai and other technologies, such as blockchain or vr/ar (where an ai component exists). - \u0007 when chatgpt is given a corrective input, it tends to incorporate it explicitly in subse\u00ad quent answers, seemingly aiming to please and satisfy the user. therefore, it is import\u00ad ant to exercise judgment when providing corrective inputs - \u0007 chatgpt sometimes may struggle to \u201cconnect the dots\u201d between different theories and practices. when this happens, it\u2019s useful to explicitly prompt it to look for analogies and connections. - \u0007 chatgpt has not displayed any significant errors or hallucinations that could be con\u00ad sidered major mistakes in its responses. **human judgement** - \u0007 when evaluating responses and selecting generated items, it is crucial to possess strong domain expertise and maintain critical judgement. this is necessary because chatgpt tends to mix valuable insights (\u201cgems\u201d) with less valuable information. - \u0007 assessing the effectiveness of response phrasing also requires experience and familiar\u00ad ity with business . this expertise is essential to determine the appropriateness and relevance of the language used. - \u0007 for individuals with robust domain expertise, chatgpt can serve as an excellent source of inspiration. it can act as an engaging sparring partner, stimulating motivational flow and generating intriguing insights. - \u0007 overall, chatgpt is an amazing tool for generating lists of items and ideas that can be further screened, refined, and evaluated. |col|summary of the key lessons in general, finding the right prompting sequence has required significant effort \u2022 when using multiple sources, it is more effective to query chatgpt source by source \u2022 when chatgpt starts repeating itself, change the prompting and/or ask for specific examples| |contents/ biases|\u2022 in our experiment, we did not notice significant errors or \"hallucinations\" \u2022 chatgpt tends to mix valuable insights (\"gems\") with less valuable information \u2022 when providing a list of responses, chatgpt's ranking logic is unclear, so it is advisable to ask for explanations| |creativity|\u2022 chatgpt showed a remarkable level of creativity (sometimes better than domain experts) \u2022 do not hesitate to encourage chatgpt to be more innovative (focus on extremes, \"wild ideas,\" or radical concepts)| |tone/narrative|\u2022 in general, the language used by chatgpt can be somewhat \"bland\" and requires human intervention \u2022 provide guidance to chatgpt regarding the response format (number of words, paragraphs, etc.) and tone (style, intended audience, etc.)| source: , , ", "#### . guidelines for the reader the chapters in this ebook are grouped into two main categories: i) business strategy and innovation management; ii) organization and innovative culture. while the chapters are organized in a coherent sequence with interconnections between them, they can also be extracted as standalone pieces. depending on your curiosity, do\u00ad main of expertise, or specific business challenge, you can choose the chapters that reso\u00ad nate with you the most. they can be read in sequence or independently, depending on your preference. when you engage with each chapter, it is important not to limit yourself solely to the labels assigned to each bullet point (be it a suggestion for enhancement or potential dis\u00ad ruption). take the time to read the descriptions, as they hold the true value of the con\u00ad tent. as emphasized in the previous chapter about key take aways of this experiment, the labels may sometimes appear generic, but the descriptions and examples contain the essence of the material. from a content perspective, each chapter presents intriguing insights derived from chatgpt. these insights can help you apply frameworks more effectively and efficient\u00ad ly, or even challenge and rethink them in a more radical manner. this book is an experimental project and does not aim to provide definitive answers. instead, it introduces a novel way of interacting with artificial intelligence. the current version serves as a starting point for further exploration and research experiments. with these instructions in mind, we invite you to embark on this experimental journey. embrace the possibilities that emerge from this interaction with chatgpt. may it serve as a catalyst for your own exploration. _let the experiment continue..._ ", "#### . . **value innovation** **chatgpt\u2019s** **choice** powered by ", "### value innovation **main theories and practices** **_blue ocean strategy_** by **_business model canvas_** by **top enhancements** by generative AI **top radical rethinking** by generative AI **ai-enhanced competitive landscape** **analysis** **idea generation and validation** **dynamic and collaborative** **business modeling** **incorporation of exponential tech** **leverage openness and co-creation** **embrace ecosystem thinking** source: chatgpt, , , **theory & practice we selected** innovative business strategies have become essential for organizations seeking to differ\u00ad entiate themselves in the marketplace and create sustainable growth. the leading reference theory and framework is blue ocean strategy ( book and article ) by and . it suggests that companies can achieve re\u00ad markable success by creating new markets instead of competing in existing ones. the theory emphasizes the pursuit of uncontested market spaces, known as \u201cblue oceans\u201d, where competition is irrelevant or non-existent. by identifying customer needs and pain points and offering unique value propositions, companies can create new demand for their offerings. in practice, blue ocean strategy methodology follows some key steps: analysis of the current industry, identification of unmet customer needs; design of a value curve; ex\u00ad ploration of new market spaces; development of a business strategy. blue ocean strategy is part of the broader business model innovation concept, the pro\u00ad cess of creating, modifying, or redefining a company\u2019s business model to achieve superi\u00ad or performance or gain a competitive edge. to this regard, a relevant management tool is the business model canvas , popularized by alexander osterwalder and yves pigneur: it allows organizations to define, visualize, and refine their business models. **our hands-on experience** as long-term partners and contributors of the blue ocean strategy network , we have applied the methodology on dozens of firms across various industries and sectors world\u00ad wide, with established large companies and with smaller ones. we have witnessed the transformative power of blue ocean strategy: simple and effec\u00ad tive framework and visual tools, a clear process to follow, the ability to foster a culture of creativity and innovation within organizations, encouraging employees to think outside the box. during its application we have often observed organizations struggling in terms of: customer understanding: organizations may struggle to fully grasp the needs, prefer\u00ad ences, and behaviors of their target customers. lack of market research, inadequate cus\u00ad tomer feedback channels, or a failure to analyze and interpret customer data can con\u00ad tribute to this challenge. internal biases: organizations can face difficulties in overcoming preconceived notions about their industry, customers, or competition. these biases can prevent the explora\u00ad tion of new opportunities, as decision-makers may be hesitant to deviate from estab\u00ad lished practices. quantification of qualitative insights: translating qualitative insights, such as customer feedback, into quantitative data can be a complex task for organizations. the inability to quantify these insights makes it challenging to prioritize opportunities and make da\u00ad ta-driven decisions. complexity in implementation: organizations often encounter challenges when moving from strategy formulation to implementation. this can be due to various factors, includ\u00ad ing resistance to change, inadequate resource allocation, lack of clear action plans, or insufficient coordination. **enhancements** - what are the most valuable enhancements that generative AI can bring to the application of innovative business strategies theories? **\u00b7 .** \u0007 **ai-enhanced competitive landscape analysis** : generative AI can leverage data analytics to quantify qualitative insights on market dynamics and help identify gaps and dif\u00ad ferentiation opportunities. generative AI can provide evidence-based recommendations for divergent value propositions. **\u00b7 .** \u0007 **idea generation and validation** : generative AI can facilitate idea generation sessions, lever\u00ad aging historical data, market trends, and customer insights; it can also assist in con\u00ad ducting surveys and gathering feedback to validate and refine business ideas before moving to implementation. generative AI can help looking across industry boundaries, stra\u00ad tegic clusters, and other \u201cstrategic paths\u201d described in the blue ocean methodology to spur ideas for strategic reconfiguration. **\u00b7 .** \u0007 **dynamic and collaborative business modeling** : generative AI can enable real-time col\u00ad laboration, version control, and dynamic updates. this capability supports iterative testing, refinement, and adaptation of business models based on new insights and market dynamics. ", "###### generative AI can facilitate idea generation sessions, using historical data, market trends, and customer info. it can also help quickly conduct surveys and gather feedback to validate and refine new strategic ideas additional enhancements include: **\u00b7 \u0007** **explore and unearth value barriers:** regarding customer / user understanding, ge\u00ad nai can facilitate the combination of quantitative data analysis with qualitative research methods and help building a comprehensive and nuanced understanding of customer needs, behaviors, and preferences. **\u00b7 \u0007** **concept exploration and visualization:** generative AI can help visualize different business concepts and models, or prototypes of potential business ideas, allowing to assess and refine them more effectively. this is particularly useful when using tools like the blue ocean value curve or the business model canvas, as generative AI can generate visualizations of various canvas components, such as customer segments, value attributes, value propositions, and revenue streams. **\u00b7 \u0007** **gamification and simulations** : to enhance participant engagement and learning (for instance in a workshop session), gamified activities can encourage creative thinking, problem-solving, and the exploration of alternative business models. simulations could simulate market dynamics, allowing participants to test and refine their strategic choices in a risk-free environment. **\u00b7 \u0007** **exploration of alternative value creation models** : to challenge the traditional notions of value creation and capture, generative AI can help consider alternative models such as the circular economy, access-based models, subscription-based models, or outcome-based models. **\u00b7 \u0007** **scenario planning** : generative AI can assist in simulating different scenarios based on quan\u00ad tified data, helping organizations evaluate the financial viability and feasibility of imple\u00ad menting blue ocean ideas before implementation. **disruptions** - how would generative AI rethink or radically disrupt innovative business strate\u00ad gies theories from within? **\u00b7 \u0007** **.** \u0007 **incorporate exponential technologies** **:** embrace the transformative power of ex\u00ad ponential technologies such as ai, blockchain, internet of things, and augmented reality. explore how these technologies can enable entirely new value propositions, business models, and customer experiences. integrate technology-driven innovation as a core component of the strategy and business model design process. **\u00b7 \u0007** **.** \u0007 **leverage openness and co-creation** **:** embrace the principles of open innovation and co-creation by engaging external stakeholders, including customers, suppliers, and even competitors, in the strategy and business model design process. foster collaboration, crowdsourcing, and open platforms to generate innovative ideas and drive co-creation of value with diverse stakeholders. **\u00b7 \u0007** **.** \u0007 **embrace ecosystem thinking** **:** rather than focusing solely on individual businesses and industries, expand the scope to embrace ecosystem-level thinking. consider how differ\u00ad ent players, technologies, and business models can collaborate and co-create value within interconnected ecosystems. this approach involves identifying new ways to collaborate, leverage partnerships, and create synergies across multiple industries and stakeholders. additional areas of disruptions include: **\u00b7 \u0007** **shift towards purpose-driven strategies:** consider the broader societal and environ\u00ad mental impacts of business decisions. move beyond purely profit-driven strategies and focus on creating shared value for multiple stakeholders. embrace sustainability, social responsibility, and ethical considerations as integral components of strategy formula\u00ad tion and business model design. **human factor** **\u00b7 \u0007** **strategic decision-making:** while generative AI can provide data-driven insights and recom\u00ad mendations, it is up to humans to interpret the information, make judgments, and set the strategic direction for the organization. the human role shifts towards synthesizing ai-generated insights, evaluating trade-offs, and making strategic choices based on a holistic understanding of the business context. **\u00b7 \u0007** **contextual knowledge and expertise** : when formulating new strategies, humans bring deep industry knowledge, experience, and contextual understanding that generative AI may lack. they possess tacit knowledge acquired through of working in specific domains. this expertise enables humans to apply critical thinking and judgment when interpreting generative AI\u2019s outputs, ensuring that ai-generated insights align with the organi\u00ad zation\u2019s unique challenges, goals, and values. **\u00b7 \u0007** **human-ai collaboration and communication:** collaboration between humans and generative AI becomes crucial. human professionals need to effectively communicate their strategic intent, objectives, and priorities to generative AI, enabling it to generate relevant insights. similarly, humans must interpret and communicate ai-generated insights to stakeholders, fostering understanding, buy-in, and alignment within the organization. **\u00b7 \u0007** **ethical standards in strategy formulation:** humans must ensure that the data used is unbiased, representative, and ethically sourced. they are responsible for setting ethical guidelines, reviewing ai-generated recommendations from an ethical standpoint, and making strategic decisions that align with the organization\u2019s values and societal expec\u00ad tations. **\u00b7 \u0007** **continuous learning and adaptation:** as generative AI evolves and brings new capabilities, humans need to stay updated with advancements, understand generative AI limitations, and acquire the skills to effectively collaborate with it. ", "###### the human role shifts towards evaluating trade-offs, and making strategic choices based on a holistic understanding of the business context ", "#### . growth planning & experimentation **chatgpt\u2019s** **choice** powered by ", "### growth planning & experimentation **main theories and practices** **_discovery driven planning_** by **_lean start-up_** by e. ries **top enhancements** by generative AI **top radical rethinking** by generative AI **generate assumptions** **design experiments for validation** **simulate user feedback for validation** **ai as project planner** ** computing for** **assumption generation** **augmented reality assumption testing** source: chatgpt, , , **theory & practice we selected** in \u2019s vuca (volatile, uncertain, complex, ambiguous) world, testing hypotheses and learn in an iterative way is increasingly important in managing growth projects. the reference framework to help managers plan in a vuca world is discovery driven plan\u00ad ning from professor rita mcgrath and ian macmillan (link to book and /a-refresher-on-discovery-driven-planning) ). a similar theory that goes in the same direction of setting and validating key assumptions as cheaply and as fast as possible, is the \u201c [lean start-up \u201d popularized by and steve blank. both frameworks offer a lower-risk way to move a new initiative forward by testing as\u00ad sumptions and learning as much as possible as early as possible. it helps planners think critically, challenge assumptions and pivot when needed. the approach consists of a set of critical questions managers need to answer when developing a new initiative under uncertainties: what is our definition of success? what assumptions need to be true to achieve the desired success? how can the assumptions be validated? how can we adapt the plan as we test and learn? over those dynamic planning methods have become increasingly popular as a disciplined approach to deal with growth projects and initiatives in hyper\u00ad dynamic market environments. **our hands-on experience** over we have introduced the principles and tools in several large corporations, both in bb and bc environment and in different geographical markets. we also pub\u00ad lished our research and experimentation findings to help companies adopt lean think\u00ad ing more effectively , especially in r&d. while the approach brings several benefits, such as early risk identification, iterative learning, efficient resource allocation, and market-responsive decision-making, there are common pitfalls that planners can fall into: - \u0007 poorly defined assumptions: one common pitfall is the lack of clarity and specificity in defining assumptions. if assumptions are vague or ambiguous, it becomes difficult to validate and measure. - \u0007 unrealistic assumptions: planners may sometimes make overly optimistic assumptions about the market, customer behavior, or technology. - \u0007 inadequate validation: planners may rely on their intuition or limited data, without conducting thorough validation experiments or collecting sufficient feedback from customers or stakeholders. - \u0007 insufficient iteration and learning: planners may be resistant to change or may not al\u00ad locate enough time and resources for iterative testing and refinement. this can hinder the ability to adapt and improve the project based on new insights. - \u0007 failure to pivot: some planners may resist changing direction or may not recognize the need to pivot in a timely manner. this can lead to wasted resources and missed oppor\u00ad tunities for corrections. addressing these challenges is crucial for successful implementation. by leveraging generative AI enhancements, planners can overcome these pitfalls and enhance the ef\u00ad fectiveness of the methodology **enhancements** - what are the most valuable enhancements that generative AI can bring to the application of discovery driven planning? - \u0007 **. \u0007** **generate assumptions** **:** ai algorithms can autonomously generate a diverse range of assumptions based on vast amounts of data and insights. planners can then col\u00ad laborate with ai systems like chatgpt to refine and iterate on these assumptions, combining human expertise and ai-generated insights. in addition, generative AI\u2019s can help uncover assumptions that might have been overlooked. - \u0007 **. \u0007** **design experiments for validation** **:** generative AI can provide recommendations for effi\u00ad cient experimental designs that maximize learning and minimize costs. for example, by identifying the most critical assumptions to test first, and the right sequence (also based on sensitivity analysis and scenario simulation). - \u0007 **. \u0007** **simulate user feedback for validation** : traditional validation methods such as in\u00ad terviews and market research can be time consuming. generative AI can simulate feedback from potential users/customers based on the assumptions (planners can describe their target audience and context, and generative AI can generate responses as if it were the user or customer). in addition, ai can help analyze large-scale data sets, customer feedback, online discussions, reviews, and other relevant sources. ", "###### generative AI can simulate user feedback based on assumptions (planners can describe their target audience and context, and generative AI can generate responses as if it were the user or the customer). additional enhancements include: **\u00b7 \u0007** **connect with experts:** planners can describe the specific expertise they are seeking, and generative AI can suggest potential experts to engage with or connect planners with rel\u00ad evant communities or forums. planners can engage with these experts, seeking their perspectives for validating the assumptions. **\u00b7 \u0007** **challenge the assumptions** : ai systems can act as critical \u201cchallenger\u201d, questioning human-generated assumptions. generative AI can provide iterative feedback and challenge the assumptions developed by the planner, stimulating critical thinking or questions that help planners think deeper about the assumptions. it can also simulate different per\u00ad spectives by suggesting alternative viewpoints. **\u00b7 \u0007** **develop metrics:** generative AI can help planners establish measurable milestones and tar\u00ad gets to validate assumptions at specific stages, enabling more structured and action\u00ad able validation. **\u00b7 \u0007** **trigger pivots:** by engaging in discussions and simulations, generative AI can highlight discrep\u00ad ancies between assumptions and evidence, suggest alternative approaches, or identify potential gaps or limitations **disruptions** - how would generative AI rethink or radically disrupt discovery driven planning from within? - \u0007 **. \u0007** **ai as project planner** **:** instead of human project leaders, an ai system takes the lead in driving the discovery process. it generates and tests assumptions autonomously, making decisions based on data analysis and machine learning algorithms. - \u0007 **. \u0007** ** computing for assumption generation** **:** leveraging the power of quan\u00ad tum computing, assumptions are generated by exploring all possible scenarios si\u00ad multaneously, allowing for a more comprehensive and nuanced understanding of potential outcomes. - \u0007 **. \u0007** **augmented reality assumption testing** **:** assumptions are tested in immersive aug\u00ad mented reality environments, where planners can visually experience and interact with simulated scenarios. this experiential approach enhances the validation process and encourages creative problem-solving. ", "###### an artificial intelligence system can take a guiding role in the discovery process. it autonomously generates and tests hypotheses, making decisions based on data analysis additional areas of disruption include: - \u0007 **multi-agent assumption validation** : generative AI can create virtual ecosystems where as\u00ad sumptions are tested through dynamic interactions between virtual entities. this en\u00ad ables planners to understand the complex interdependencies that impact the success of assumptions. - \u0007 **collaborative assumption setting** : ai systems can facilitate collaborative brainstorm\u00ad ing sessions by generating and sharing ideas in real-time. planners can leverage ai\u2019s ability to generate a vast number of ideas, sparking collective creativity and fostering a collaborative ideation process. - \u0007 **ai-facilitated assumption gamification** : ai-powered gamification techniques can turn the assumption validation process into an engaging and interactive experience. planners can compete or collaborate in virtual games that simulate real-world scenari\u00ad os, fostering creativity and enhancing the motivation to validate assumptions. **human factor** - \u0007 **creativity (in prompting):** with ai systems providing insights and suggesting poten\u00ad tial assumptions, humans must think creatively on which deep questions and creative prompting can leverage the full potential of chatgpt. - \u0007 **critical thinking / ability to challenge:** humans must cultivate critical thinking skills, interpret results, assessing the capabilities, accuracy, and reliability of ai models, under\u00ad standing their limitations, and making informed choices. - \u0007 **integration of ai-generated insights** : human planners will need to synthesize ai-gen\u00ad erated insights with their own expertise and industry knowledge to make informed de\u00ad cisions. this requires skills in data interpretation, pattern recognition, and critical anal\u00ad ysis to extract meaningful insights from ai-generated data and integrate them into the planning process. - \u0007 **iterative adaptation and pivoting:** human planners will continue to be responsible for guiding the iterative adaptation and pivoting process. they will need skills in moni\u00ad toring and analyzing feedback, identifying opportunities for course correction, and mak\u00ad ing strategic decisions about when and how to pivot based on a combination of ai-gen\u00ad erated insights, user feedback, and market dynamics. - \u0007 **ethical considerations in ai use:** humans must understand the ethical implications of using generative AI and ensure responsible and unbiased decision-making. skills in ai ethics, governance frameworks, and data privacy become essential. for example, by judging safe and secure methods/data for testing the assumptions. ", "#### . platforms & business ecosystems **chatgpt\u2019s** **choice** powered by ", "### platforms & business ecosystems **main theories and practices** **_platform revolution_** by , choudary **_ecosystem economy_** by **top enhancements** by generative AI **top radical rethinking** by generative AI **data-driven insights on** **market frictions** **enchanced curation** **and recommendation** **collaboration facilitation** **in the ecosystem** **embrace decentralization and blockchain** **ai and ml for platform (autonomous)** **decision making** **user empowerment and data sovereignty** source: chatgpt, , , **theory & practice we selected** main reference is the seminal book \u201cplatform revolution\u201d by geoffrey , mar\u00ad shall , and sangeet ( book and article ); this theory has pro\u00ad vided a comprehensive overview of the platform business model, its key components, strategies, and implications. it has proven to be a valuable resource for understanding the transformative power of platforms in \u2019s digital economy. another key contributor is /faculty-and-research/faculty-profiles/j/jacobides-m-g) ; his work (as this [article ) has provided valuable insights into the role and dynamics of ecosystems in shaping competitive ad\u00ad vantage and innovation. his research emphasizes the need for firms to embrace ecosys\u00ad tem strategies, become effective orchestrators, and navigate the complexities of ecosys\u00ad tem governance to thrive in \u2019s interconnected business landscape. **our hands-on experience** we applied the above theories and thinking in multiple contexts, drawing inspiration also for our publications and speeches/talks. our original thinking was featured in lead\u00ad ing magazines and various books. see for instance how to embrace the power of /embrace-power-platforms/) [forms , or ecosystems: the how factor . we have observed in several projects how the concept and thinking captured in \u201cplat\u00ad form revolution\u201d and in [professor /faculty-and-research/faculty-profiles/j/jacobides-m-g) publications help business leaders in understanding and strategizing the potential of such innovative business models. academic research has clearly highlighted how network effects operate, how they harness the virtuous cycle of growth where more users attract more participants. however, in many cases the application of has turned out to be challenging in several aspects: - \u0007 unfamiliarity with platform logic: most managers are unfamiliar with platform con\u00ad cepts. understanding the nuances of network effects, value sharing, and orchestration is crucial to leverage these theories successfully. - \u0007 na\u00efve approach: some organizations approach network effects, value sharing, and or\u00ad chestration in a simplistic or inexperienced manner. failing to be scientific and rigorous can lead to ineffective implementation and missed opportunities for value creation. - \u0007 organizational inertia: overcoming factors such as organizational inertia, legacy systems, and resistance to change is essential for successful implementation in large organizations **enhancements** - what are the most valuable enhancements that generative AI can bring to the application of ? - **. \u0007** **data-driven insights on market frictions** : generative AI can analyze vast amounts of data to provide actionable insights on ecosystem dynamics, user behavior, and emerging trends. generative AI can help understanding the frictions, the current mismatches between the various platform sides, the needs for curation that do not allow to release full value. - \u0007 **. \u0007** **enhanced curation and recommendations** **:** generative AI can leverage user data to offer personalized recommendations and experiences within platform ecosystems. a stron\u00ad ger user interface (q&a-based) can replace or complement search engines in most plat\u00ad forms. in addition to that, by analyzing user behavior and preferences, generative AI can help businesses tailor their offerings, enhance customer satisfaction, and drive engagement. - \u0007 **. \u0007** **collaboration facilitation** **:** generative AI can provide tools and recommendations to foster collaboration among ecosystem participants. by analyzing data on capabilities, generative AI can help identify potential partners, assess compatibility and complementarities, and facilitate resource sharing. ", "###### a more advanced user interface (based on questions and answers) can replace or integrate search engines in most platforms additional enhancements include: - \u0007 **ecosystem mapping and visualization** : generative AI can assist in visualizing and mapping ecosystems by analyzing data on stakeholders, relationships, and dependencies. this can help businesses gain a holistic view of their ecosystem and understand the dynam\u00ad ics and interdependencies among participants. - \u0007 **quantitative analysis and simulation** : generative AI can assist in quantitative analysis and simulation of platform dynamics, in terms of network effects, side liquidity and match\u00ad ing between sides, complementarities, value sharing mechanisms and incentives. - \u0007 **risk assessment and mitigation:** by analyzing data on security, privacy, regulatory compliance, and market dynamics, generative AI can help businesses proactively address po\u00ad tential risks and ensure the long-term sustainability of their ecosystems. **disruptions** - how would generative AI rethink or radically disrupt platforms & business ecosys\u00ad tems theories from within? - **. \u0007** **embrace decentralization and blockchain technologies** : traditional platform models often rely on centralized control and intermediaries. by embracing decentral\u00ad ized technologies such as blockchain, it is possible to create self-governing ecosys\u00ad tems where participants have more autonomy and control over their data, transac\u00ad tions, and governance. this shift can foster trust, reduce reliance on intermediaries, and enable more equitable value distribution. - **. \u0007** **ai and machine learning for platform (autonomous) decision-making** : by lever\u00ad aging ai and machine learning algorithms, platforms can automate certain aspects of decision-making, such as matching supply and demand, optimizing pricing, or rec\u00ad ommending personalized offerings. this can enhance efficiency, scalability, and user experience within the ecosystem. - **. \u0007** **foster user empowerment and data sovereignty** : shift the power dynamics in favor of users by enabling them to have greater control over their data and privacy. provide users with transparent access to their data, allowing them to manage permis\u00ad sions and decide how their data is utilized within the ecosystem. empowering users can enhance trust and engagement within the ecosystem. additional areas of disruptions include: - \u0007 **embed \u201cby-design\u201d sustainability and social impact:** encourage responsible and ethical practices, promote environmental sustainability, and support social causes with\u00ad in the ecosystem. consider how the platform can contribute to the well-being of society and address broader societal challenges. - \u0007 **embrace circular economy principles** : encourage resource optimization, reduce waste, and promote sustainable practices across the value chain. consider how the plat\u00ad form can facilitate the exchange, reuse, and repurposing of resources, products, and services within the ecosystem. - \u0007 **dynamically upgrade platforms with latest technologies:** continuously scan and experiment with emerging technologies and trends that can disrupt the traditional plat\u00ad form and ecosystem models. this may include exploring technologies like internet of things (iot), augmented reality (ar), virtual reality (vr), or edge computing. **human factor** - \u0007 **sensemaking and context interpretation:** humans play a crucial role in sensemaking by interpreting the insights and recommendations provided by generative AI within the specific context of their organization and ecosystem. a strong domain expertise (on platforms and ecosystems) is needed to interpret the insights and recommendations from generative AI - \u0007 **adaptability and learning agility:** in the rapidly evolving landscape of platform and eco\u00ad system strategies, humans need to be adaptable and quick learners. they must stay updat\u00ad ed on emerging trends, technologies, and market dynamics. this enables them to under\u00ad stand the implications of generative AI\u2019s insights and adapt strategies accordingly. they need to stay informed also about advancements in ai technologies, understand generative AI\u2019s capabilities and limitations, and develop the necessary skills to effectively collaborate with ai systems. - \u0007 **communication, collaborative and relationship-building skills:** humans need to foster relationships, build trust, and engage with ecosystem participants to co-create value. they must leverage their interpersonal and relationship-building skills to forge partnerships and foster a collaborative environment. they need to effectively commu\u00ad nicate the insights, recommendations, and strategic decisions to various stakeholders within the organization and the ecosystem. they must engage and manage stakehold\u00ad ers\u2019 expectations, address concerns, and foster alignment. these skills will be even more critical as they complement the capabilities brought by ai. - \u0007 **ethical decision-making:** humans need to assess the ethical implications of the recom\u00ad mendations provided by generative AI, consider potential biases, and make decisions aligned with ethical standards and social values. think how much privacy, sovereignty, sustain\u00ad ability, circular economy, ecc. are related to the current and future ecosystems. - \u0007 **creativity and innovation:** humans are essential for driving creativity and innovation within platform and ecosystem strategies. they can leverage the insights generated by generative AI to think creatively, identify new opportunities, and design novel approaches and directions for platform design and evolutionary paths. ", "#### . multi-stakeholder co-creation **chatgpt\u2019s** **choice** powered by ", "### multi-stakeholder co-creation **main theories and practices** **_cooperative advantage_** by **_co-creation practices_** by leading companies **top enhancements** by generative AI **top radical rethinking** by generative AI **improved problem framing** **advanced modeling and simulation** **improved insights** **and opportunity generation** **decentralized collaboration** **augemented collaboration (vr/ar)** **real-time sentiment analysis** **and adjustements** source: chatgpt, , , **theory & practice we selected** main reference is the theory of cooperative advantage, as proposed by prieto and simone t.a. phipps in their work \u201c cooperative advantage: rethinking the /article/cooperative-advantage-rethinking-the-companys-purpose/) [ny\u2019s purpose \u201d. according to the authors, companies can create more value and achieve a sustainable competitive advantage by working collaboratively with stakeholders, rather than simply competing against rivals. there are several well-established practices to working collaboratively with stakehold\u00ad ers: co-creation workshops; jamming sessions; stakeholder consultation meetings/sum\u00ad mits; community engagement projects; participatory design / user-centered design. over an increasing number of companies have understood the benefits of multi-stakeholder co-creation and embraced it as a common practice. among the oneers, it is worth mentioning for example: - \u0007  connect + develop program: collaborates with innovators outside the company to identify promising ideas that can be developed and brought to market. - \u0007 philips\u2019 co-creation labs: philips bring together consumers, health professionals, and other stakeholders to collaboratively develop solutions to healthcare challenges. - \u0007  creator space tm : a global co-creation program initiated on th anniver\u00ad sary to harnessing the collective knowledge, creativity, and expertise of various stake\u00ad holders \u2013 including employees, customers, academics, and members of the public sec\u00ad tor. **our hands-on experience** we have applied the above multi-stakeholder collaboration and co-creation methodolo\u00ad gies in various contexts. back in , we directly supported the design and implementa\u00ad tion of creator spacetm, a pioneering initiative, which was then pub\u00ad lished in an hbs case /faculty/pages/item.aspx?num=) . such theories and related practices can be extremely beneficial in terms of cultural change, relationship building with key stakeholders, innovation marketing, and \u2013 in some cases \u2013 also result in successful product and service innovations. however, their application is complex and resource-intensive, especially in the prepara\u00ad tion phase. based on our direct experience, main pitfalls include: - \u0007 lack of alignment on the [problem being addressed: organizations may struggle to es\u00ad tablish a clear understanding and agreement on the specific problem that the collabo\u00ad ration activity aims to solve. - \u0007 selection and engagement of stakeholders: inadequate selection and engagement of stakeholders, characterized by under-representation, biases, or power dynamics, can lead to imbalanced decision-making processes and skewed outcomes. - \u0007 insufficient resources/preparation: inadequate allocation of resources, both financial and human, can hinder the success of collaborative initiatives. - \u0007 lack of proper follow-up: failure to properly follow up on collaboration activities can result in a lack of accountability and progress monitoring. **enhancements** - what are the most valuable enhancements that generative AI can bring to the application of multi-stakeholder collaboration practices? - **. \u0007** **improved problem framing** : generative AI can perform extensive data mining and analysis on existing internal and external data sources to identify relevant trends, customer insights, market dynamics, and emerging opportunities that can help improve the challenge statement definition. - **. \u0007** **advanced modelling and simulation** : generative AI can be used to create complex mod\u00ad els and simulations of different scenarios. this can help stakeholders explore vari\u00ad ous possibilities, understand potential outcomes, and make more informed choices during the co-creation process. - **. \u0007** **improved insight & opportunity generation** : generative AI can analyze large amounts of data to detect patterns, trends, and correlations that may not be easily apparent to humans. this can help stakeholders gain deeper insights, make better decisions, and co-create more effectively. also, generative AI can propose novel concepts, new product fea\u00ad tures, or innovative solutions based on the identified patterns and insights. ", "###### generative AI can perform extensive data collection and analysis to identify relevant trends, customer insights, and market dynamics that can contribute to improving problem definition additional enhancements include: before the co-creation activity (e.g., a co-creation workshop or a jam session) - \u0007 **participant selection and matching** : generative AI can assist in the selection and matching of participants for the co-creation process. by analyzing participant profiles, expertise, and past contributions, generative AI can recommend suitable stakeholders who bring diverse perspectives, relevant skills, and complementary knowledge to the table. - \u0007 **knowledge sharing and content curation** : generative AI can curate and disseminate relevant knowledge, best practices, case studies, and research findings to participants before the co-creation process. this ensures that participants have a shared baseline understand\u00ad ing of the subject matter, accelerates the onboarding process, and promotes a common knowledge foundation. - \u0007 **scheduling and logistics optimization** : generative AI can optimize the scheduling of the co-creation process, considering participants\u2019 availability, time zones, and preferences. it can also assist in coordinating logistics, such as venue selection, travel arrangements, and resource allocation, streamlining the planning phase and ensuring smooth execution. - \u0007 **preparation and pre-work assignments** : generative AI can provide pre-work assignments or activities to participants to prepare them for the co-creation process. this may include pre-reading materials, thought-provoking questions, or small individual or group tasks aimed at priming participants\u2019 thinking and encouraging them to come prepared with initial ideas or insights. during the co-creation activity: - \u0007 **enhanced communication and understanding** : generative AI can use natural language pro\u00ad cessing to understand, generate, and translate language (i.e., voice-to-text transcription, synthesis, semantic analysis and connection mapping). this can improve communica\u00ad tion among diverse stakeholders, facilitate better understanding, and ensure that every\u00ad one\u2019s voices are heard and understood. - \u0007 **personalization** : generative AI can help personalize the co-creation process for each stake\u00ad holder, considering their specific interests, perspectives, and needs. this can enhance stakeholder engagement and satisfaction. - \u0007 **predictive capabilities** : generative AI can predict potential obstacles or challenges that may arise during the co-creation process (e.g., ip topics), allowing stakeholders to proactively address these issues. after the co-creation activity: - \u0007 **consolidation and analysis of workshop output:** generative AI can assist in consolidating the insights, ideas, and outcomes generated, and provide a comprehensive summary of the discussions. - \u0007 **knowledge management and documentation** : generative AI can support the documenta\u00ad tion and management of the co-creation process outcomes. it can create structured re\u00ad positories or knowledge bases that capture the generated ideas, concepts, prototypes, and artifacts. - \u0007 **idea evaluation and prioritization** : generative AI can employ algorithms and models to eval\u00ad uate and prioritize the generated ideas based on predefined criteria or decision frame\u00ad works. - \u0007 **action planning and roadmap development** : generative AI can help in developing action plans and roadmaps. it can analyze dependencies, resource requirements, and poten\u00ad tial risks to facilitate the creation of a realistic and comprehensive plan for implementing the co-created solutions. - \u0007 **monitoring and progress tracking** : generative AI can contribute to ongoing monitoring and progress tracking of the co-creation outcomes. by analyzing relevant data points, met\u00ad rics, or feedback, generative AI can provide insights into the implementation progress, identify potential bottlenecks or areas for improvement, and support continuous optimization of the co-created solutions. **disruptions** - how would generative AI rethink or radically disrupt multi-stakeholder collabora\u00ad tion practices from within? - **. \u0007** **decentralized collaboration** : using blockchain technology could allow for more democratic and secure co-creation processes. each participant would have a trans\u00ad parent record of every change and contribution made during the co-creation process, ensuring accountability, trust, and fair attribution of ideas. - **. \u0007** **augmented collaboration (vr/ar)** : virtual and augmented reality can help create immersive co-creation environments that go beyond traditional meeting or workshop settings. with vr/ar, stakeholders can interact in a fully immersive digital environ\u00ad ment, manipulating ideas and designs in real-time, regardless of their physical loca\u00ad tion. - **. \u0007** **real-time sentiment analysis and adjustment** : employ generative AI to continuously ana\u00ad lyze the sentiment and engagement levels of participants during co-creation sessions and along the overall co-creation process. also, biosensors technology can monitor physiological responses (like heart rate, brainwaves, etc.) and thus provide real-time feedback during collaboration sessions. this data could be used to adjust the process, ensuring optimal engagement and effectiveness. ", "###### virtual reality and augmented reality can help create immersive co-creation environments that go beyond traditional meetings or workshops additional areas of disruptions include: - \u0007 **brain-computer interfaces (bci):** though it may sound like science fiction, bcis could potentially allow for direct communication between the human brain and digital sys\u00ad tems, which could radically disrupt the way we collaborate and co-create. in the future, this could allow for \u201cthought sharing\u201d and immediate translation of ideas into digital formats. - \u0007 **artificial general intelligence (agi) co-creator:** while this is more speculative and future-facing, once agi (ai with human-like understanding and capabilities) is realized, it could serve as another participant in the co-creation process, contributing its own in\u00ad sights and ideas, and even challenging human participants to think differently. **human factor** - \u0007 **advanced literacy:** as collaboration technologies evolve, so too will the need for digital fluency. understanding vr/ar environments, blockchain technology, and brain-computer interfaces will become vital. this includes not only how to use these technologies but also how to leverage them effectively for collaboration and creativity. with more sophisticated technologies, an increased amount of data will be available - from sentiment analysis to neurofeedback. the ability to interpret and utilize this data will become a critical skill. - \u0007 **neuro-technological understanding:** if brain-computer interfaces become a reality, understanding how the human brain functions and how it can interact with technology will be crucial. - \u0007 **ethical considerations and decision-making:** more advanced technology brings more complex ethical dilemmas. skills in ethical decision-making, understanding of privacy implications, and managing the potential misuse of technology (like deepfakes in vr or security issues in blockchain) will become increasingly important. - \u0007 **psychological safety and empathy:** as collaboration becomes more technologically advanced and potentially anonymous (in the case of blockchain), creating an environ\u00ad ment of psychological safety and demonstrating empathy will be vital. this ensures par\u00ad ticipants feel comfortable expressing their ideas and thoughts, despite the impersonal nature of some technologies. - \u0007 **human-ai interaction:** as agi may become a reality, humans will need to learn how to interact with ai not just as a tool, but as a co-creator. for instance, if an agi is partic\u00ad ipating as a co-creator in a workshop, it could propose design ideas based on its vast knowledge base, predict the market response to different designs, or identify potential sustainability issues based on the latest research. importantly, it would be capable of adapting its responses based on the conversation flow, perhaps even challenging hu\u00ad man ideas, or proposing novel solutions. - \u0007 **design and visualization:** with vr/ar, the ability to design and visualize in three di\u00ad mensions becomes crucial. for example, if a multi-stakeholder group is co-designing a new product, they could create a d model of that product in the virtual environment. stakeholders could then \u201cwalk around\u201d the product, viewing it from different angles, even interacting with it as if it were a physical object. changes to the design can be made in real-time, with everyone witnessing and participating in the alterations. ", "###### for example, if a group of stakeholders is co-designing a new product, they could create a d model of that product in the virtual environment. stakeholders could then \u201cwalk around\u201d the product, interacting with it as if it were a physical object ", "#### . open innovation **chatgpt\u2019s** **choice** powered by ", "### open innovation **main theories and practices** **_open innovation_** by **_open innovation archetypes_** **top enhancements** by generative AI **top radical rethinking** by generative AI **partners discovery and selection** **ai-driven open innovation strategy** **ai-based innovation challenges** **open innovation ai marketplace** **intelligent mapping of** **innovation ecosystem** **ai-enhanced serendipity engine** source: chatgpt, , , **theory & practice we selected** open innovation theory, coined by , suggests that organizations can enhance their innovation capabilities by leveraging external ideas and resources. it em\u00ad phasizes the importance of collaboration. originating , with a hbs book and seminal -way-to-innovate) , open innovation has gained widespread adoption across industries. over hbr has published more than [contributions (digital ar\u00ad ticles, podcasts, \u2026) on open innovation, that demonstrates the solidity and continued timeliness of the theory until . open innovation offers several benefits, including access to a broader pool of ideas, in\u00ad creased speed of innovation, reduced costs, and risk mitigation through external col\u00ad laborations. it enables organizations to tap into diverse perspectives, expertise, and re\u00ad sources, fostering a culture of innovation and growth. from an organizational perspective, it has also led to the emergence of various open in\u00ad novation archetypes , such as corporate innovation outposts, corporate garage, venture builders, corporate accelerators, innovation labs, innovation catalysts, venture client. **our hands-on experience** over we have supported several companies in their open innovation journey, considering the tools and practices (like crowdsourcing ) as well as the organiza\u00ad tional and cultural implications for large corporations. in particular, we looked into open innovation archetypes and how to help leaders design innovation units and outposts . more recently we explored the broadening scope of open innovation towards sustain\u00ad ability (as in the case of [enel\u2019s /media/news///insead-case-study-award-innovability) ) and beyond the traditional r&d domain. we have observed the following common pitfalls when large companies embrace open innovation: - \u0007 strategic inconsistency, where innovations may not align with company goals or lack a long-term perspective. - \u0007 organizational siloes result in disconnected open innovation labs, leading to mis\u00ad aligned initiatives and lack of support for scaling. - \u0007 intellectual property and data privacy issues may arise due to sharing ideas externally - \u0007 lack of alignment of central processes such as procurement, finance, legal, it, and hr - \u0007 risk aversion and fear of failure hinder innovative thinking - \u0007 cultural resistance as employees perceive external sourcing as devaluing their contri\u00ad butions or threatening job security. **enhancements** - what are the most valuable enhancements that generative AI can bring to the application of open innovation theories and practices? - **. \u0007** **partners discovery and selection** **:** generative AI can analyze potential partners based on various criteria, such as their innovation track record, compatibility with the compa\u00ad ny\u2019s goals, and financial stability, among others, facilitating the process of partner discovery and selection. - **. \u0007** **ai-driven open innovation strategy** : generative AI can assess and propose open innova\u00ad tion initiatives based on the company\u2019s strategic goals, identifying and flagging those that may not be aligned. it can help ensure strategic alignment, mitigating the risk of wasted resources or conflicts/duplications/silos. generative AI can identify and recommend which business units might be most open to. - **. \u0007** **ai-based innovation challenges** : organize innovation challenges or hackathons where ai algorithms are used to facilitate idea generation, evaluation, and collabo\u00ad ration. ai can provide real-time feedback, suggest improvements, and facilitate the selection of winning ideas. ", "###### generative AI can analyze potential partners based on different criteria, thus facilitating the discovery and selection process additional enhancements include: - \u0007 **patent screening, evaluation, and matching:** generative AI can augment the process of iden\u00ad tifying, screening, evaluating, and selecting patents or startups for collaboration. it can scan databases using specific criteria, analyze and score potential matches, evaluate their depth by predicting their impact or success, and provide data-driven recommen\u00ad dations for selection. - \u0007 **streamlining of central processes** : generative AI can automate and streamline central pro\u00ad cesses, making them more adaptable and responsive to the needs of partners (startups, etc.), reducing the burden and improving efficiency. - \u0007 **ai-powered needs exploration:** generative AI can rapidly analyze large volumes of data, un\u00ad covering hidden trends, patterns, and insights that can drive innovative solutions. generative AI can also help analyze social media data, customer reviews, and other online data to gain a deeper understanding of customer needs and preferences. this could lead to the dis\u00ad covery of new innovative opportunities. - \u0007 **enhanced intellectual property (ip) management:** generative AI can assist in intellectual property management by automatically analyzing patent databases, identifying poten\u00ad tial infringements, and helping organizations navigate complex patent landscapes to protect their innovations. **disruptions** - how would generative AI rethink or radically disrupt open innovation theories and practices from within? - **. \u0007** **open innovation ai marketplace** **:** establish an ai-driven marketplace where orga\u00ad nizations can share their innovation challenges and receive ai-curated solutions from a global network of innovators. the marketplace would use generative AI to match the most relevant ideas with specific challenges, providing a diverse range of creative solutions. - **. \u0007** **intelligent mapping of innovation ecosystem** **:** ai could map the entire innovation ecosystem, including startups, research institutions, and potential partners. it could analyze their expertise, capabilities, and compatibility, helping organizations navigate the complex landscape and identify optimal collaboration opportunities. - **. \u0007** **ai-enhanced serendipity engine** **:** create an ai algorithm that generates unexpected connections and serendipitous ideas by analyzing vast amounts of diverse data. the algorithm would identify unusual patterns, combinations, and associations, leading to groundbreaking innovations by connecting seemingly unrelated concepts. ", "###### the algorithm can identify unusual patterns, combinations, and associations, leading to disrupting innovations by connecting seemingly unrelated concepts additional areas of disruption include: - \u0007 **patent mining for innovation:** develop an ai system that autonomously scans and ana\u00ad lyzes massive patent databases, identifying hidden patterns, cross-industry applications, and potential opportunities for collaboration or acquisition. this system could uncover novel ways of leveraging existing intellectual property for innovative purposes. - \u0007 **open innovation with ai entities:** generative AI could create virtual entities or avatars (\u201csyn\u00ad thetic innovators\u201d with unique characteristics, skills, and perspectives) capable of par\u00ad ticipating in the open innovation process. these ai entities could generate ideas, pro\u00ad vide feedback, and even collaborate with human innovators, bringing a unique blend of ai-generated insights and human creativity. **human factor** - \u0007 **strategic thinking and decision-making:** humans with strong strategic thinking skills play a vital role in assessing ai-generated insights and making informed decisions re\u00ad garding innovation strategies, partnership selection, and resource allocation over the portfolio of oi initiatives. - \u0007 **systems thinking:** open innovation involves complex systems with interconnected elements, and individuals with systems thinking skills can understand the dencies, identify synergies, and navigate the collaborative and dynamic nature of the innovation ecosystem. - \u0007 **inquisitiveness and curiosity:** curiosity drives exploration and discovery, allowing in\u00ad dividuals to uncover novel insights, challenge assumptions, and seek out innovative op\u00ad portunities that may arise from open collaboration and diverse perspectives. - \u0007 **domain expertise:** deep domain expertise allows humans to interpret and validate ai-generated insights, bringing industry-specific knowledge to evaluate the relevance and applicability of ai-generated suggestions in the open innovation process, for exam\u00ad ple providing valuable insights and guidance to startups, helping them refine their ideas and solutions. - \u0007 **human relationship with external and internal partners** while several open inno\u00ad vation tasks can be taken by generative AI, some elements are human specific: building and nurturing relationships with external stakeholders, such as partners, startups, and re\u00ad search institutions, requires strong interpersonal skills (communication, negotiation, \u2026) and the ability to foster trust and collaboration. - \u0007 **open innovation ethics and compliance:** upholding ethical standards, ensuring data privacy, and complying with intellectual property regulations are fundamental in open innovation. humans play a key role in ensuring ethical practices and responsible inno\u00ad ti hil t ti t k h ld \u2019 i t t ", "#### . ----- ", "#### . leadership behaviors **chatgpt\u2019s** **choice** powered by ", "### leadership behaviors **main theories and practices** **_ paradoxes of innovative cultures_** by **_psychological safety_** by **top enhancements** by generative AI **top radical rethinking** by generative AI **improved communication on behaviors** **automated administration and reporting** **behavioral measurement and monitoring** **real-time feedback and coaching** **virtual simulation and experiential learning** **ai-driven behavioral analysis** source: chatgpt, , , **theory & practice we selected** in , extensive literature and academic research confirmed the critical role that leaders play in fostering and sustaining innovation within organizations. in his award-winning on the  paradoxes of innovative cul\u00ad tures , professor emphasizes the crucial role that leaders play in shaping and sustaining innovative cultures, while managing these paradoxes carefully: _paradox # \u2013 tolerance for failure vs. accountability:_ encouraging and supporting exper\u00ad imentation while maintaining clear expectations for individual/team performance and holding individuals accountable. _paradox # \u2013 willingness to experiment vs. clear strategy and discipline:_ promoting and supporting experimentation within the boundaries of the strategic objectives, ensuring that experiments are purposeful, aligned with the organization\u2019s goals, and executed with discipline. _paradox # \u2013 psychological safety (as theorized by professor amy edmondson) vs. candor:_ creating an environment where individuals feel psychologically safe to share ideas and take risks, while also promoting open and honest communication, encouraging con\u00ad structive feedback. _paradox # \u2013 collaboration vs. individual accountability:_ creating structures and process\u00ad es that encourage collaboration and teamwork, promoting a culture of shared goals and collective problem-solving, while also establishing clear expectations for individual ac\u00ad countability, ownership, and delivering on commitments. _paradox # \u2013 flat hierarchy vs. strong leadership:_ fostering a culture of empowerment and distributed decision-making, encouraging individuals at all levels to contribute their ideas and perspectives, while also providing strong leadership that sets the vision, direc\u00ad tion, and guidance. compared to traditional approaches (mainly focused on rhetoric about abstract values), pisano advocates a more concrete approach , where leaders need to embody and demon\u00ad strate a set of desired and observable behaviors themselves. as a measurement tool, pisa\u00ad no designed a quantitative survey to evaluate concrete behaviors related to collaboration, psychological safety, empowerment, attitude toward failure, and experimentation. this data helps identify gaps, improvement areas, and weak spots within the organization. **our hands-on experience** under the supervision and guidance of professor pisano, we developed an innovative practice to help leaders lay the foundation for a successful cultural transformation. our approach follows three main steps: () measure concrete behaviors rather than abstract values (tool: pisano\u2019s survey), () select the desired behaviors (tool: deck of cards, with a mix of positive and negative behaviors, in line with pisano\u2019s paradoxes), and () live the new, desired behaviors in practice (tool: circles of trust). the output is the lead\u00ad ership social contract\u2014a set of actionable behaviors that leaders must commit to either stop doing, start doing or keep doing. we applied our approach to thousands of executives in multiple contexts, mainly in eu\u00ad rope and us. overall, it has helped in creating alignment and commitment to real change. however, in many cases the application has turned out to be challenging because of: - \u0007 failure to embed new behaviors: leaders may struggle to effectively live new behaviors in their tasks and decisions. - \u0007 measurement of behaviors: difficulty in measuring behaviors against a baseline to track progress quantitatively. - \u0007 difficult translation of behaviors into concrete actions: translating abstract values con\u00ad cepts into practical and actionable steps can pose challenges. - \u0007 unclear correlation between cultural change and business impact: the lack of measur\u00ad able link between behavioral shift and tangible business results can make it challeng\u00ad ing to justify the roi of the initiative and sustain support. **enhancements** - what are the most valuable enhancements that generative AI can bring to our leadership behaviors approach? - **. \u0007** **improved communication on behaviors** : generative AI can review and guide communica\u00ad tions to ensure they align with desired behaviors and the organization\u2019s new social contract. it can also provide a consistent messaging across all communication chan\u00ad nels to avoid mixed signals. - **. \u0007** **automated administration and reporting** : generative AI can automate various admin\u00ad istrative tasks, such as conducting surveys, collating, and analyzing data, and gen\u00ad erating reports. this reduces the resource burden and allows for more efficient and effective behavior change initiatives. - **. \u0007** **behavioral measurement & monitoring** : generative AI can use a combination of natural language processing, sentiment analysis, and other machine learning techniques to objectively and quantitively measure behaviors. this could involve analyzing commu\u00ad nication and actions within the organization, tracking progress over time, and provid\u00ad ing real-time feedback to individuals. ", "###### generative AI can use a combination of natural language processing, sentiment analysis, and other machine learning techniques to measure behaviors objectively additional enhancements include: - \u0007 **personalized coaching and guidance** : generative AI could provide personalized suggestions for concrete actions individuals can take to align with desired behaviors. this could be based on an individual\u2019s role, context, and previous behavior. generative AI could also provide real-time coaching to leaders, helping them better embody and promote desired be\u00ad haviors. - \u0007 **in-depth understanding of organizational context** : by analyzing a wide range of data, generative AI can provide valuable insights into the organizational context and how it may influence behavior change efforts. this understanding can help leaders tailor their approaches to their specific organizational context, increasing the chances of success. - \u0007 **interactive & engaging workshops** : generative AI could facilitate more interactive and engag\u00ad ing workshops. for example, it could create virtual scenarios or simulations where the participants can see the impact of their chosen behaviors in real-time. this can provide immediate feedback and allow them to refine their choices. or could provide collabo\u00ad rative tools and platforms that enable participants to contribute ideas, collaborate on documents or visualizations, and provide feedback in real-time. - \u0007 **social network analysis** : generative AI could analyze social network data within the orga\u00ad nization to identify influential individuals or groups who can drive behavior change. it could provide recommendations on how to leverage these influential nodes to cascade desired behaviors throughout the organization more effectively. - \u0007 **continuous behavioral reinforcement:** generative AI can provide ongoing reinforcement of new behaviors, sending reminders or prompts when needed. it can also provide contin\u00ad uous feedback to individuals based on their progress, further promoting the adoption of new behaviors. **disruptions** - how would generative AI rethink or radically disrupt our leadership behaviors approach from within? - **. \u0007** **real-time feedback and coaching** : generative AI could provide instant, personalized feed\u00ad back and coaching to individuals and teams, leveraging its ability to process vast amounts of data and provide immediate insights. this would enable individuals to adjust and course corrections in real-time, enhancing their behavior change efforts. - **. \u0007** **virtual simulation and experiential learning** **:** generative AI could create virtual simulations or immersive experiences where individuals can practice and refine the desired be\u00ad haviors in a safe and controlled environment. this would enable experiential learning, allowing individuals to build their skills and confidence in embodying the behaviors. - **. \u0007** **ai-driven behavioral analysis** : generative AI could utilize advanced algorithms and ma\u00ad chine learning techniques to analyze behaviors at a much deeper level. it could iden\u00ad tify patterns, correlations, and insights that humans may miss, enabling a more com\u00ad prehensive understanding of behaviors and their impact on organizational culture. ", "###### generative AI could identify patterns, correlations, and insights that humans may not grasp, enabling a more comprehensive understanding of behaviors and their impact on organizational culture additional areas of disruption include: - \u0007 **predictive behavior modeling:** generative AI could use advanced analytics to predict potential outcomes of behavior change initiatives. this includes forecasting potential unintended consequences, as well as correlating changes in behavior with key business outcomes. - \u0007 **ethical ai guidance:** generative AI could provide ethical guidelines and considerations to ensure that behavior change initiatives are aligned with ethical standards and avoid potential bi\u00ad ases or unintended consequences. it could continuously monitor the impact of behavior changes on diverse groups within the organization to promote fairness and inclusion. **human factor** - \u0007 **advanced data literacy:** humans need to develop a strong understanding of data analysis, interpretation, and visualization to inform their behaviors. they should be able to derive actionable insights from the data generated by generative AI, effectively lever\u00ad age data to drive behavior changes, and communicate the implications of data to key stakeholders. - \u0007 **change management & enablement:** humans play a crucial leadership role in driv\u00ad ing behavior change initiatives with the support of generative AI. they need to provide vision, set strategic direction, inspire others, and navigate the organizational change process. leadership skills become essential in creating an environment that embraces generative AI and fosters a culture of continuous improvement. - \u0007 **empathy, authenticity and emotional intelligence:** as generative AI becomes an integral part of behavior change initiatives, humans need to maintain and reinforce strong in\u00ad terpersonal skills. empathy, emotional intelligence, and authenticity are vital in under\u00ad standing the human experience, addressing concerns, providing support, and building trust between humans and ai, fostering genuine connections, and ensuring the ticity of interactions in the behavior change process. - \u0007 **ethical awareness and decision-making:** humans must be well-versed in ethical con\u00ad siderations related to the use of generative AI. they should understand the potential biases, privacy concerns, and social implications of using ai in behavior change efforts. ethical decision-making becomes crucial when interpreting generative AI recommendations and en\u00ad suring fairness, transparency, and accountability. - \u0007 **adaptability and agility:** as behavior change initiatives evolve in collaboration with generative AI, humans need to be adaptable and agile. they should be open to new informa\u00ad tion, adjust strategies and approaches based on generative AI insights, and respond quickly to changes or emerging opportunities. ", "###### ethical decision-making becomes crucial in interpreting generative AI recommendations and ensuring fairness, transparency, and accountability ", "#### . fluid & flexible organization **chatgpt\u2019s** **choice** powered by ", "### fluid & flexible organization **main theories and practices** **_adhocracy_** by **_fast forward_** by _holacracy_** by **top enhancements** by generative AI **top radical rethinking** by generative AI **promoting cross-functional** **collaboration** **modeling change in organizational** **structure** **supporting self-organizing teams** **fluid organizational networks** **decentralized decision-making ecosystem** **purpose-driven autonomous cells** source: chatgpt, , , **theory & practice we selected** in \u2019s fast-changing business landscape, traditional hierarchical and bureaucratic models are giving way to innovative theories of organizational design. was one of the first to observe a paradigm shift towards /s---) accompanied by the emergence of the \u201cnetworked firm\u201d inspired by the internet economy. building upon these foundations, and introduced flexibility and informality within organizational structures in the book [fast forward . influential book reinventing organizations presented a compelling vision of self-man\u00ad agement and introduced the concept of teal organizations. more recently the open-source movement, agile methodologies, and the sharing econ\u00ad omy have inspired participative, responsive structures and a range of company-specif\u00ad ic variations on self-organization. for example, a prominent self-organization theory is holacracy , which explicitly defines roles, enables distributed decision-making, and fosters adaptive governance. holacracy encourages autonomy and accountability within teams, promoting a sense of ownership and unleashing collective intelligence. the shift towards these modern theories of organizational design aims to strike a bal\u00ad ance between reliability and adaptability. by embracing flexibility, self-management, and participative structures, organizations create environments that foster collabora\u00ad tion innovation and resilience the experience of few pioneers has offered valuable insights and lessons on potential benefits, as well as on barriers or pitfalls to avoid: ing bank - tribes and squads (extensively studied and researched by professor julian birkinshaw ): ing bank transformation involved restructuring the organization into small, cross-functional teams called \u201csquads\u201d and implementing agile practices such as scrum and , leveraging the organizational model of spotify and other digital native firms. ing bank\u2019s transformation has been widely recognized as a reference case of implementing adaptable organizations at scale within a large, established company. holacracy (analyzed by professors  bernstein , juan pablo vazquez sam\u00ad pere and georges romme ): an online shoe and clothing retailer, embraced self-management and organizational agility. in , they implemented a holacra\u00ad cy-based system called which involves distributing authority across self-organizing teams. this approach encourages employees to take ownership of their work, make de\u00ad cisions autonomously, and adapt to changing circumstances. **our hands-on experience** organizational reinvention is an area we have extensively studied, consulted, and pub\u00ad lished in . as domain experts, we are often engaged in webinars , confer\u00ad ences, and roundtable discussions. in our experience with several companies, we have observed an increasing interest on more fluid and adaptable organizational models. although tempting, copying the org. model of agile champions like spotify or , is challenging and moreover, can bring significant unanticipated complexity. our experience suggests that modernizing tradi\u00ad tional organizational structures, especially for legacy companies, is challenging because: - \u0007 overlooking the specific organizational context: each organization has its unique char\u00ad acteristics. failing to consider these factors when implementing an agile organizational structure can lead to challenges and suboptimal outcomes. - \u0007 lack of clarity in roles and responsibilities: old traditional practices such as raci are no longer effective in fluid, flat organizational archetypes. - \u0007 resistance to continuous change: people are reluctant to give up established hierar\u00ad chies and power dynamics, and even when they transition, they neglect continuous learning and adaptation. - \u0007 inadequate cross-functional collaboration: even if change happens, people keep work\u00ad ing in isolation, inhibiting the flow of information. **enhancements** - what are the most valuable enhancements that generative AI can bring to the application of fluid and flexible organizational models? - **. \u0007** **promoting cross-functional collaboration** : generative AI can identify potential areas of re\u00ad sistance or collaboration gaps by analyzing communication patterns, dependencies, and information flow. it can suggest strategies to promote cross-functional collabo\u00ad ration, such as implementing shared platforms, facilitating knowledge sharing, and fostering a culture of collaboration. - **. \u0007** **modelling change in organizational structure** : generative AI can analyze organization\u00ad al data (such as size, industry, and existing culture), industry benchmarks, and best practices to provide insights and recommendations on the necessary changes to the organizational structure: where fluid/flat model applies and what archetypes fit best. it can offer simulations and modeling capabilities to help visualize the impact of dif\u00ad ferent structural changes, aiding in decision-making. - **. \u0007** **supporting self-organizing teams** **:** generative AI can provide resources and training ma\u00ad terials to support self-organizing teams. it can offer guidance on decision-making frameworks, conflict resolution techniques, and best practices for effective self-orga\u00ad nization. generative AI can also facilitate communication channels for teams to share knowl\u00ad edge and align their efforts. ", "###### generative AI can analyze organizational data (such as size, industry, and existing culture), industry benchmarks, and best practices to provide recommendations on changes to the organizational structure. additional enhancements include: - \u0007 **clear the organizational fog** : generative AI can assist in defining clear roles and responsibil\u00ad ities by analyzing job descriptions, skill sets, and team dynamics. it can provide recom\u00ad mendations on role definitions, accountability frameworks, and optimal composition of teams within a fluid and flexible organizational structure. - \u0007 **performance tracking and organizational improvement** : generative AI can monitor team performance, provide real-time feedback, and help identify areas for improvement within the fluid and flexible organizational structure. it can offer insights, recommend iterative adjustments to the organizational structure, and facilitate ongoing learning and adaptation. - \u0007 **support the shift in management styles** : generative AI can assist in promoting servant lead\u00ad ership and a more empowering management style. it can provide training materials and resources to help leaders transition from command and control to a supportive and facilitative role. in addition, generative AI can provide insights on establishing guidelines, frameworks, and feedback mechanisms to ensure that individuals/teams have the au\u00ad tonomy to make decisions. - \u0007 **addressing resistance to change:** generative AI can help identify sources of resistance to change within the organization by analyzing employee sentiment, conducting surveys, or collecting feedback. it can provide targeted interventions, such as personalized com\u00ad munication, training resources, and change management strategies, to address resis\u00ad tance and foster a positive mindset towards the agile organizational structure. **disruptions** - how would generative AI rethink or radically disrupt fluid and flexible organiza\u00ad tional models from within? - **. \u0007** **fluid organizational networks** : instead of rigid team structures, organizations could embrace a fluid network model. employees would form dynamic networks based on project needs and personal interests, allowing for more agility and flexibility. generative AI can assist in the self-organization of fluid networks by analyzing project needs, indi\u00ad vidual availability, and team dynamics. it can provide recommendations on optimal team compositions, helping teams form and disband as projects evolve. - **. \u0007** **decentralized decision-making ecosystem** : rather than relying on a few designat\u00ad ed leaders or managers, organizations could establish a decentralized decision-mak\u00ad ing ecosystem. at individual level, generative AI can provide decision support tools that offer data-driven insights and recommendations to individuals at all levels. overall, generative AI can help ensure alignment and coordination within a decentralized decision-making ecosystem. it can provide mechanisms for sharing information, tracking decisions, and facilitating collaboration, enabling distributed leadership while maintaining orga\u00ad nizational coherence. - **. \u0007** **purpose-driven autonomous cells** : organizations could transition towards pur\u00ad pose-driven autonomous cells that operate as independent entities. generative AI can assist in resource allocation within cells. it can analyze project requirements, individual capabili\u00ad ties, and resource availability to optimize resource allocation and decision-making with\u00ad in each cell. also, generative AI can facilitate knowledge sharing and collaboration across cells. ", "###### generative AI can analyze project needs, individual capabilities, and resource availability to optimize resource allocation and decision-making additional areas of disruption include: - \u0007 **dynamic performance evaluation and rewards** : moving away from traditional an\u00ad nual performance reviews, organizations could implement dynamic and real-time per\u00ad formance evaluation systems. these systems would provide continuous feedback to individuals and teams based on their contributions, achievements, and alignment with organizational values and goals. generative AI can assist in identifying and recognizing individu\u00ad al and team contributions based on predefined criteria. it can provide recommendations for personalized rewards and recognition, promoting transparency and motivation. - \u0007 **holistic skill sharing platforms** : organizations could develop holistic skill-sharing plat\u00ad forms that go beyond traditional job roles and functions. generative AI can analyze employee profiles, skills, and project requirements to identify potential matches for skill sharing. it can recommend individuals with complementary skills and interests to collaborate with like-minded colleagues or suggest relevant projects based on their skills and interests. **human factor** - \u0007 **flexibility, adaptability & continuous learning:** in fluid and flexible organizational models, individuals may need to take on more adaptive roles that transcend traditional job descriptions. they may need to be flexible and adaptable, assuming multiple re\u00ad sponsibilities based on the needs of the organization or project at hand. this requires a willingness to learn and embrace new challenges, as well as the ability to quickly acquire new skills and knowledge. - \u0007 **collaborative organizational design:** humans actively engage in collaborative design and customization of fluid and flexible archetypes in conjunction with ai systems. they work alongside generative AI to co-create organizational structures that promote agility, collab\u00ad oration, and effective decision-making. humans leverage their domain expertise, con\u00ad textual knowledge, and understanding of team dynamics. ", "###### humans working together with generative AI to co-create organizational structures that promote agility, collaboration, and effective decision-making. - \u0007 **critical thinking and decision-making:** while generative AI provides insights and recommen\u00ad dations, humans must bring their critical thinking skills to the table. they need to eval\u00ad uate and validate the suggestions provided by generative AI, considering the organizational context, human factors, and stakeholder input before making final decisions. - \u0007 **emotional intelligence, trust, and empathy:** despite generative AI\u2019s capabilities, humans remain central to building relationships, trust, and collaboration within teams. emotion\u00ad al intelligence skills, such as self-awareness, empathy, trust, and relationship manage\u00ad ment, are vital for fostering a positive and supportive team culture. - \u0007 **change management and leadership:** as generative AI assists in change management, humans, particularly leaders, need to develop skills in guiding and supporting teams through change. this includes skills in communication, influencing, and empathetic leadership to address resistance, manage transitions, and create a supportive environ\u00ad ment for agile transformations. ", "#### . agile way of working **chatgpt\u2019s** **choice** powered by ", "### agile way of working **main theories and practices** **_the agile manifesto_** **_scrum_** by **_** **top enhancements** by generative AI **top radical rethinking** by generative AI **enhanced project/program** **management** **ai-based skill matching and sourcing** **customized agile career paths** **predictive agile** **artificial scrum master** **new roles in ai agile** source: chatgpt, , , **theory & practice we selected** agile originated as an approach for software development . gradually, ag\u00ad ile principles and practices have expanded \u201c at scale \u201d well beyond it teams and proj\u00ad ects permeating the entire organization , beyond just individual teams or projects. this requires extending the agile mindset to all levels and functions of the business, which can lead to increased flexibility, faster decision-making, and improved responsiveness to customer needs or market changes. the principle underpinning an agile way of working are: decentralized decision-making (teams closest to the work make decisions, enhancing speed and efficiency); cross-func\u00ad tionality (teams possess all required skills to deliver a product or service, encouraging self-organization); alignment and autonomy (teams are guided by strategic goals but have the freedom to decide their path to those objectives); iterative and incremental de\u00ad velopment (regularly reassessing strategies and plans based on feedback). for the successful adoption of an agile way of working it\u2019s important to ensure a re-align\u00ad ment of culture, leadership styles, as well as processes and systems of an organization. **our hands-on experience** over , we have contributed to the debate about enterprise agility with multiple publications: agility inc (thinkers), agile planning (), agile feedback (), /six-business-processes-you-need-to-rethink-for-the-agile-age/) (ebr) and [watch?v=ktvutyfm) (thinkers). based on our research and direct experience with companies undergoing agile transformations we have identified common pitfalls and how to unmask \u201c [fake agile \u201d. in our experience, agile transformations often stumble due to common pitfalls: - \u0007 \u201cagile theater\u201d: while and tools are adopted, the enterprise still operates in the traditional way with no signs of real systemic change (e.g., rigid goal setting and resource allocation, hierarchical authorization mechanisms, unaltered traditional de\u00ad cision-making processes, lack of continuous feedback mechanisms). - \u0007 inadequate leadership behaviors: lack of effective shift in leaders\u2019 actions, failing to concretely support and empower agile teams. - \u0007 burden of legacy systems: existing legacy systems and processes can pose challenges during agile transformations, as they may impede flexibility and responsiveness. - \u0007 overemphasis on tools: placing excessive focus on agile tools rather than the agile mind\u00ad set, collaboration, and adaptive thinking can hinder the success of agile transformations. - \u0007 insufficient training: inadequate training and education on agile principles and practices can limit the understanding and application of agile concepts within the organization. recognizing and addressing these pitfalls is crucial for a true agile transformation. **enhancements** - what are the most valuable enhancements that generative AI can bring to the application of agile way of working theories and practices? - **. \u0007** **enhanced project/program management** : generative AI can support the optimization of project schedules, backlog management and sprint planning. it can facilitate integra\u00ad tion and coordination across different functions, setting okrs, and improve efficiency in communications and alignment within and across agile squads and tribes. - **. \u0007** **ai-based skill matching and sourcing** **:** generative AI can match organizational needs with internal and external talents available. ai algorithms can analyze skill requirements, project demands, and talent profiles to recommend suitable matches. - **. \u0007** **customized agile career paths** **:** generative AI can help identifying skill gaps and generating personalized learning and career plans. this can help organizations build a versatile and multi-skilled workforce, a key attribute of an agile organization. ", "###### artificial intelligence algorithms can analyze skill requirements, project needs, and talent profiles to recommend suitable matches. additional enhancements include: - \u0007 **dynamic planning and resource allocation** : to overcome rigid goal setting and re\u00ad source allocation, generative AI can assess resource flexibility, budget forecasting, team capac\u00ad ity, skill requirements, and market opportunities to recommend efficient and effective resource allocation - \u0007 **promote transformative leadership behaviors:** ai can employ sentiment analysis to understand employees\u2019 perceptions of leadership styles, thereby delivering essential feedback to guide leaders\u2019 development **disruptions** - how would generative AI rethink or radically disrupt agile way of working theories and practices from within? - **. \u0007** **predictive agile** **:** ai could predict the success of an agile project based on the initial requirements, available resources, and past projects. it could use this information to suggest an optimal project structure, team size, sprint length, and more, drastically improving project planning and execution. - **. \u0007** **artificial scrum master** **:** generative AI could potentially take over the role of a scrum mas\u00ad ter. it could automatically assign tasks, monitor progress, identify potential risks, and even suggest improvements based on data from previous iterations. it could facilitate stand-ups, sprint planning, and retrospectives by processing data in real-time and providing valuable insights. - **. \u0007** **new roles in ai-agile** **:** traditional agile roles (like scrum master, product owner) may need to be redefined in the context of generative AI. for instance, teams may need roles focusing on ai ethics, data management, and ai model training and evaluation. ", "###### ai, based on the initial requirements, could use this information to suggest an optimal project structure, team size, sprint duration, dramatically improving project planning and execution additional areas of disruption include: - \u0007 **transforming traditional agile ceremonies.** stand-ups may become unneces\u00ad sary as generative AI provides real-time data and progress tracking. sprint planning can be influenced by ai, which analyzes historical data and dependencies to suggest optimal plans. retrospectives can be streamlined with ai-generated insights and recommenda\u00ad tions for process improvements. - \u0007 **immersive agile training:** generative generative AI could simulate immersive training experi\u00ad ences to develop an agile mindset in team members. ai-powered virtual environments would challenge individuals with realistic agile scenarios, providing instant feedback, coaching, and adaptive learning paths to foster agile thinking and behavior. - \u0007 **generative AI as a team member:** ai could become an active contributor as a team member, working on tasks, writing code, designing solutions, and contributing to discussions. this could completely change the dynamics of agile teams and open the door to / development cycles. ", "###### with ai becoming a prominent part of the team, effective collaboration and communication with ai tools, virtual assistants, and human colleagues are essential **human factor** - \u0007 **strategic ai integration:** teams need the ability to strategically integrate ai tech\u00ad nologies into agile practices. this includes evaluating ai capabilities, identifying areas where ai can enhance agile processes, and aligning ai integration with agile values and principles **.** - \u0007 **human-machine agile collaboration:** with ai becoming a prominent part of the team, effective collaboration and communication with both ai tools, virtual assistants and hu\u00ad man colleagues becomes critical. this involves not just conveying information effective\u00ad ly, but also understanding and interpreting outputs from ai models. - \u0007 **collaborative problem-solving with ai** : agile teams should cultivate the ability to col\u00ad laborate effectively with ai tools and systems in problem-solving activities. this involves leveraging ai-generated suggestions, predictions, and insights as inputs for collabora\u00ad tive discussions and decision-making within the agile team. - \u0007 **understanding ai capabilities and limitations:** although not everyone will need in- depth technical knowledge, a basic understanding of what ai can and cannot do will be important. this includes an appreciation for the strengths, limitations, and appropriate uses of ai tools in agile projects. - \u0007 **ai-based coaching and mentoring:** with generative AI reshaping workflows and responsibil\u00ad ities, the role of managers as coaches and mentors becomes crucial. they will need to guide their team members through changes, helping them develop new skills and adapt to working with ai. - \u0007 **ai ethics and governance in agile** : as generative AI integrates more into agile practices, it\u2019s vital to ensure data privacy, mitigate ai bias, maintain process transparency, and under\u00ad stand the impacts of ai-based decisions within agile projects. ", "#### . empowerment & decision making **chatgpt\u2019s** **choice** powered by ", "### empowerment & decision making **main theories and practices** **_humanocracy_** by **_no rules rules_** by r. hastings **_simple rules_** by **top enhancements** by generative AI **top radical rethinking** by generative AI **context understanding for decisions** **ai-facilitated decision making** **modeling and simulating** **decision outcomes** **ai-powered voting** **ai-augmented collective intelligence** **decentralized decision networks** source: chatgpt, , , **theory & practice we selected** in \u2019s dynamic context, characterized by rapid changes and evolving market con\u00ad ditions, there is a growing need for less rigidity and a greater emphasis on faster, au\u00ad tonomous decision-making processes. empowerment becomes crucial as it allows in\u00ad dividuals at all levels of an organization to have a voice and contribute their expertise. rethinking decision-making practices and criteria, along with control models, becomes necessary to reduce excessive hierarchical bureaucracy. this shift towards employee empowerment helps reduce the bureaucratic burden on in\u00ad dividuals and fosters a culture of innovation. over , noteworthy books such as \u2019s and \u2019s \u201c humanocracy ,\u201d reed hastings and erin meyer\u2019s \u201c no rules rules ,\u201d \u2019s and \u2019s \u201c simple rules for a complex world \u201d, have provided valuable insights and methodologies to reshape decision-making processes in large bureaucratic corporations, emphasizing the impor\u00ad tance of empowerment. various companies have pioneered innovative decision-making practices and empower\u00ad ment, including haier , , netflix, michelin , handelsbanken, southwest airlines, . **our hands-on experience** over , we have further contributed to enhance these theories and practic\u00ad es developing a framework for innovative control models for more decentralized and empowered decision making, and enhancing the concept of debureaucratization. en innovative control models are presented to help achieve these goals: guiding princi\u00ad ples, boundary rules, context setting, sounding board, peer review, social pressure, and post-detection. we advocated \u201ctrust-by-design\u201d as a way to embed trust in processes and decision making criteria (see our article on ibyimd ). introducing empowerment theories and practices in large companies we have observed common pitfalls that organizations need to deal with: - \u0007 resistance from middle management: managers may resist losing their traditional power of control. unlearning the old paradigm and embrace the new one can be chal\u00ad lenging. - \u0007 organizational inertia: existing structures and processes can exhibit inertia, making it difficult to effectively empower people. - \u0007 lack of trust: building trust within the hierarchy and the layers of an organization is crucial for empowering employees and may be a challenge to overcome. - \u0007 employee skill gaps: lack of capability among employees that can hinder their ability to take on additional responsibilities and make independent decisions with autonomous judgement. - \u0007 legal and compliance constraints: formal requirements may limit the actual degree of autonomy that should be granted to employees in empowerment initiatives. - \u0007 technology gaps: monolithic technology infrastructure can impede the effective imple\u00ad mentation of empowerment practices due to rigidity and lack of flexibility and adapt\u00ad ability of systems. the good news is that technology advancement, like generative AI, is changing the game. it can make bureaucracy harmless without necessarily eliminating its control system. on one side it can simply replace low-value tasks and decisions that traditionally were made by frustrated and demotivated humans; on the other side, generative AI tools like chatgpt can augment human judgement to make faster, better and more autonomous decisions. **enhancements** - what are the most valuable enhancements that generative AI can bring to de\u00ad cision making and empowerment theories and practices? - **. \u0007** **context understanding for decisions** **:** generative AI can provide a wide range of infor\u00ad mation to employees, helping them understand the larger context in which they are operating. - **. \u0007** **ai-facilitated decision making** **:** generative AI can provide support by analyzing large data\u00ad sets to offer predictive insights, forecasts, and recommendations (pondering pros and cons of decisions). this helps managers in making decisions faster and more accurately, reducing the time spent on deliberation. - **. \u0007** **modeling and simulating decision outcome** **:** generative AI can model potential outcomes of decision-making scenarios, allowing individuals and teams to experiment with dif\u00ad ferent approaches and see their potential impacts before actual implementation. this encourages a shift from a risk-averse mindset to one that embraces innovation and learns from failures. ", "###### generative AI can provide support by analyzing large datasets to offer forecasts, insights, and recommendations by weighing the pros and cons of decisions additional enhancements include: - \u0007 **streamlining complex rules:** generative AI could help streamline complex rules, turning them into simple, actionable, and understandable guidelines. it could suggest the most essen\u00ad tial rules of a process or a policy. by defining common rules and leveraging ai-generated insights, organizations can reduce variations in adoption and interpretation, promoting consistent practices. - \u0007 **human-machine decision boundaries:** ai can be designed with built-in decision-mak\u00ad ing boundaries, which can be quantitative or rule-based. the ai could make decisions autonomously within these boundaries, while escalating decisions outside the bound\u00ad aries to human oversight. - \u0007 **personalized recommendations:** by analyzing individual preferences, past decisions, and performance data, generative AI can provide personalized recommendations tailored to each employee\u2019s specific profile. - \u0007 **trust-building** : generative AI can help providing transparency. ai tools can track and analyze decision-making processes, ensuring that all decisions are fair, unbiased, and data driv\u00ad en. ai can help ensure that decisions are transparent and traceable, providing an audit trail for accountability. - \u0007 **promoting ethical decision-making:** generative AI can be programmed to consider ethical guidelines in decision-making, helping organizations maintain their standards as they become more decentralized. for example, ai can monitor activity and offer feedback or reminders about ethical guidelines. - \u0007 **decision storytelling and narrative** : generative AI can help decision makers craft compelling narratives to communicate complex information and engage stakeholders. by analyzing data and generating narratives, ai can present decisions in the form of stories, making them more relatable and impactful. - \u0007 **enhanced decision visualization:** generative AI can transform complex data and decision models into intuitive visual representations, making it easier for decision-makers to understand and communicate insights. by providing interactive and visually appealing dashboards, ai enhances decision visualization. - \u0007 **risk management (of decisions):** generative AI systems can be designed to incorporate le\u00ad gal and compliance requirements, ensuring that decisions align with regulatory frame\u00ad works. ai-powered anomaly detection systems can also help identify potential security breaches and mitigate risks proactively. **disruptions** - how would generative AI rethink or radically disrupt the way decision making is conducted? - **. \u0007** **ai-powered voting** : introduce ai-powered platforms that allow employees to directly participate in decision-making processes through voting and consensus mechanisms. generative AI algorithms can aggregate and analyze the collective input, enabling a more inclusive and democratic approach to decision-making. - **. \u0007** **ai-augmented collective intelligence** : generative AI can facilitate collective decision mak\u00ad ing by aggregating and synthesizing diverse perspectives from multiple individuals. through natural language processing and sentiment analysis, ai can extract insights from discussions, forums, and social media, enabling a broader range of input in de\u00ad cision-making processes. - ** \u0007** **decentralized decision networks** : generative AI facilitates the creation of decentralized de\u00ad cision networks, where decision-making authority is distributed among various nodes in the network. each node, represented by ai or human decision-makers, has the au\u00ad tonomy to make decisions within their domain of expertise, enabling faster and more agile decision-making. ", "###### as humans work in collaboration with ai systems, developing metacognitive skills becomes increasingly important. this includes awareness of one\u2019s cognitive biases, assumptions, and limitations, as well as actively monitoring and adapting decision-making strategies additional areas of disruption include: - \u0007 **emotion and sentiment analysis** : generative AI can detect and analyze emotions and senti\u00ad ments expressed in text, voice, or facial expressions. by understanding the emotional context, ai can help decision makers gauge the impact of their choices on stakeholders\u2019 well-being and make more empathetic decisions. - \u0007 **responsible decision navigator:** generative AI acts as a navigator, guiding decision-makers through the complex landscape of sustainability considerations and trade-offs. it helps identify potential risks, evaluate the environmental and social implications, and suggest alternatives that align with sustainable practices. - \u0007 **inclusive decisions:** ai facilitates the integration of stakeholder voices by aggregating and analyzing data from multiple sources. this inclusive approach helps organizations make decisions that balance the interests and needs of different stakeholders, fostering a more inclusive and socially responsible outcome. - \u0007 **intelligent decision routing:** generative AI can intelligently route decision requests to the most suitable individuals or teams based on their expertise, availability, and workload. by optimizing decision routing, ai ensures that decisions are handled by the most qual\u00ad ified and capable individuals, for better outcomes. - \u0007 **multi-agent decision optimization:** generative AI can employ multi-agent systems where dif\u00ad ferent ai agents with specialized expertise collaborate to optimize decisions. each agent contributes unique perspectives, allowing for holistic decision-making that considers a wide range of factors. **human factor** - \u0007 **ability to collaborate with ai** : humans collaborate closely with generative AI tools, working in tandem to achieve optimal outcomes. they leverage ai-generated insights and recom\u00ad mendations, combining them with their domain expertise, creativity, and critical thinking. - \u0007 **probing and critical thinking** : humans ask probing questions, challenge assumptions, and evaluate alternative perspectives to arrive at well-rounded decisions. they assess the reliability and relevance of ai-generated recommendations and ensure that deci\u00ad sions align with organizational goals and values. - \u0007 **ability to train ai** : humans are responsible for training and validating generative AI models. they curate and prepare high-quality data, ensure model accuracy and fairness, and continuously monitor and fine-tune the ai algorithms to improve their decision-making performance and mitigate biases. - \u0007 **ethical reasoning:** while generative AI can process vast amounts of data and generate recom\u00ad mendations, good and fair judgment still requires human intervention. skills related to ethical reasoning, critical thinking, and moral judgment become crucial. - \u0007 **context provision** : managers provide contextual information to employees, guiding them on the strategic context, business objectives, and organizational priorities. they ensure that employees understand how ai-generated insights align with the broader goals of the organization. - \u0007 **domain expertise:** employees bring their domain expertise and deep knowledge of specific areas to the decision-making process. they leverage generative AI tools to augment their expertise, analyze data, and gain insights, combining them with their domain knowledge to make decisions. they are also aware that generative AI\u2019s answers can have lim\u00ad itations and should be carefully reviewed. - \u0007 **metacognition:** as humans work in collaboration with ai systems, developing metacog\u00ad nitive skills becomes increasingly important. metacognition refers to the ability to reflect on and regulate one\u2019s own thinking processes. it involves being aware of one\u2019s own cognitive biases, assumptions, and limitations, and actively monitoring and adjusting decision-making strategies. ", "###### as humans work in collaboration with ai systems, developing metacognitive skills becomes increasingly important. this includes awareness of one\u2019s cognitive biases, assumptions, and limitations, as well as actively monitoring and adapting decision-making strategies ", "#### . employee motivation **chatgpt\u2019s** **choice** powered by ", "### employee motivation **main theories and practices** **_flow theory_** by m. csikszentmihalyi **_drive_** by d. pink **top enhancements** by generative AI **top radical rethinking** by generative AI **gathering actionable insights on people** **motivation** **standardization of motivation analysis** **continuous measurement and** **real-time tracking** **\u00abkind\u00bb ai** **automated sentiment analysis** **and emotion recognition** **personalized feedback** **and improvement plans** source: chatgpt, , , **theory & practice we selected** main references are intrinsic motivation theories by mihaly csikszentmihalyi and daniel pink. csikszentmihalyi\u2019s flow theory focuses on the experience of being in a state of flow, which is characterized by complete immersion, deep focus, and a sense of enjoyment in an activity. csikszentmihalyi identified several factors that contribute to the flow state, such as the match between the challenge level of the activity and an individual\u2019s skill level, clear goals, immediate feedback, and the merging of action and awareness. flow theory emphasizes the intrinsic rewards of engagement and the importance of finding activities that provide an optimal balance between challenge and skill. csikszentmihalyi\u2019s theories served as the foundation and inspiration for daniel pink, who further elaborated on and popularized these ideas in his book /books/drive/) . pink intro\u00ad duced the concepts of autonomy, mastery, and purpose as the key drivers of intrinsic motivation, highlighting their significance in fostering engagement, creativity, and sat\u00ad isfaction in individuals. autonomy refers to having control over one\u2019s work, mastery to the desire to get better at what one does, and purpose to the belief that the work matters. research in the field of organizational psychology and management has demonstrated that intrinsic motivation plays a crucial role in driving employee performance, satisfac\u00ad tion and overall organizational outcomes (lindsay mcgregor and neel doshi in their article \u201c [how company culture shapes employee /how-company-culture-shapes-employee-motivation) \u201d). when employees are intrinsically motivated, they tend to exhibit higher levels of engagement, creativity, and commitment to their work. cases often cited in the management literature include: - \u0007 **best buy** | hubert joly\u2019s human-centered approach (described in his book [) [of /book/) ), leveraging the full potential of best buy employees by ensuring they are well-motivated, adequately trained, and fully engaged in their roles. - \u0007 **** | [responsabilisation (french for \u201cempowerment\u201d) program which aimed at giving employees more responsibility and autonomy in their roles. by doing this, chelin fostered a sense of ownership among employees which led to increased motiva\u00ad tion and productivity. **our hands-on experience** in applying these principles and practices we often observed that they can be very pow\u00ad erful, but their implementation and scale up can pose difficult challenges such as: - \u0007 lack of standardization: without a standardized method to define and measure moti\u00ad vation, the process can become highly subjective. different individuals may have dif\u00ad ferent interpretations of motivation, which can lead to inconsistencies in measurement and interpretation of results. - \u0007 difficulty in deriving actionable insights: surveys can provide valuable data on employ\u00ad ee motivation but converting them into actionable strategies is challenging because of the complex nature of motivation. - \u0007 perception that motivation is qualitative without a business case: numerous studies have shown a strong link between employee motivation and business outcomes such as pro\u00ad ductivity, retention, and customer satisfaction, but this connection is not yet obvious. to help firms overcome these challenges we supported the development of a practical approach called \u201c kindness triangle \u201d. at the base of the triangle are motivation and wellbeing indicators. at its top are business results. every vertex of the triangle has an associated set of indexes, with analytical cor\u00ad relations linking the three vertices. the logic is that a compassionate leadership results in higher rates of trust and engagement in people, which in turn translates into improved company performance. to convincingly show the link between kindness, motivation and business results, anecdotal evidence is not enough. we need analytical measure\u00ad ment, such as the \u201ckindness performance indicators\u201d: employees are surveyed on their motivation with questions around purpose, autonomy, and relationship. results by unit (or sub-unit) are compared with the unit leader\u2019s individual score on the trust behavior\u00ad al index. in the companies and units where we ran the correlation, we found consistent links between kind leaders and motivated employees. **enhancements** - what are the most valuable enhancements that generative AI can bring to the application of intrinsic motivation practices such as kindness performance indicators (kpis)? - **. \u0007** **gathering actionable insights on motivation** **:** generative AI can process survey data and other relevant information to generate actionable insights to harness intrinsic mo\u00ad tivation. by using advanced analytics and machine learning algorithms, generative AI can identify patterns, trends, and relationships that might be missed by human analysis. it can also suggest actions or motivation strategies. - **. \u0007** **standardization of motivation analysis** **:** generative AI can aid in creating an ad-hoc stan\u00ad dardized model of measuring and understanding motivation across the organization. it can process a large amount of data to identify common factors and patterns, which can serve as a standard. the model can be used for individual assessments and com\u00ad parisons across units or the whole organization. - **. \u0007** **continuous measurement and real-time tracking** **:** generative AI can automate the pro\u00ad cess of regular measurement and tracking of kpis. in traditional settings, these would typically be assessed through employee surveys and observations, usually conducted periodically. with the aid of generative AI, this process can be automated, providing real-time insights and analyses. the ai system can be trained to analyze various sources of data to measure indicators of kindness continuously. ", "###### generative AI can process survey data and other relevant information to generate useful insights for unleashing intrinsic motivation additional enhancements include: - \u0007 **demonstrating business case for motivation:** by analyzing historical and real-time data, generative AI can draw clear connections between motivation levels and key business out\u00ad comes. it can provide evidence-based arguments for the impact of motivation on perfor\u00ad mance, helping to establish the business case for investment in motivation strategies. - \u0007 **enhanced qualitative analysis:** while generative AI can analyze quantitative data, it can also process qualitative information, offering a deeper, more nuanced understanding of the qualitative aspects of motivation and kindness, often reflected in unstructured data such as open-ended survey responses, employee feedback, meeting transcripts, emails, and other text data. it can identify recurring themes, detect sentiment (positive, nega\u00ad tive, neutral), and even comprehend subtle emotions (like joy, frustration, etc.). - \u0007 **engaging employees:** with capabilities like chatbots, generative AI can facilitate two-way com\u00ad munication with employees, inviting their input and feedback in a more interactive man\u00ad ner. this can help increase employee engagement in the process. **disruptions** - how would generative AI rethink or radically disrupt application of intrinsic moti\u00ad vation practices such as kindness performance indicators (kpis) from within? - **. \u0007** **\u201ckind\u201d ai** : generative AI systems can be designed to embody kindness in their interactions, serving as a digital exemplar of kindness in the organization. through providing con\u00ad sistently empathetic and supportive responses, these ai systems foster a culture of kindness and provide a touchpoint for guidance. - **. \u0007** **automated sentiment analysis and emotion recognition** : generative AI, especially ad\u00ad vanced natural language processing (nlp) and machine learning algorithms, could process large amounts of text data (like emails, chat transcripts, social media posts) or even voice and video data to understand employees\u2019 emotions, satisfaction, and overall sentiments about their work and the company culture. this could provide real-time in\u00ad sights into motivation and kindness at work beyond traditional survey methods. - **. \u0007** **personalized feedback and improvement plans** **:** using ai, personalized feedback can be provided to each employee, including recommendations for enhancing moti\u00ad vation. these suggestions can be derived from analyzing vast amounts of data on suc\u00ad cessful interactions and patterns of motivation and kindness within the organization or across similar organizations. ", "###### generative AI systems can be designed to embody kindness in their interactions, serving as a digital example of kindness in the organization. other areas of disruption include: - \u0007 **kindness intervention** : through machine learning and data mining, generative AI could forecast potential pitfalls or opportunities related to motivation and kindness in the organization. it could predict how changes in policies or procedures might impact motivation, trust and kindness, or it could foresee which departments or individuals might need extra support. - \u0007 **immersive empathic training:** advanced ai can utilize ar/vr to simulate real-life sce\u00ad narios and help in training employees and leaders to exhibit more kindness in their interactions. - \u0007 **decentralization of motivation and kindness initiatives** : advanced ai technolo\u00ad gies such as blockchain could be used to create a decentralized, transparent record of kindness-related initiatives, actions, and their impacts in the organization. this would democratize the process, giving every employee a chance to contribute to and access kindness-related data, and to certify the quality of data. **human factor** - \u0007 **data interpretation:** as generative AI automates the process of data collection and initial analysis, humans can focus more on interpreting the results, understanding their impli\u00ad cations, and developing strategic responses to foster employee motivation - \u0007 **interactive & kind engagement** : instead of disseminating information about kindness in a one-way manner, humans will play a vital role in engaging with employees interactively and having meaningful conversations, aided by generative AI tools such as chatbots. they\u2019ll focus on fostering relationships, building trust, and promoting a culture of kindness. - \u0007 **anticipatory kindness & motivation management** : leveraging ai insights to proac\u00ad tively detect, address, and capitalize on shifts in motivation and kindness within the organization. - \u0007 **immersive learning skills** : mastery in designing and facilitating immersive, experi\u00ad ential learning experiences (possibly using ar/vr technologies) to enhance the under\u00ad standing and practice of kindness. - \u0007 **authentic & compassionate leadership** : emphasizing the human ability to show em\u00ad pathy, exhibit personal authenticity, and serve as a role model of kindness. interperson\u00ad al connection, understanding, and emotional intelligence are key to complement ai\u2019s analytical capabilities. ", "###### interpersonal connection, understanding, and emotional intelligence are crucial for integrating the analytical capabilities of ai **bios** ", "###### enrico sassoon is the chief editor of . is hbr.org author and member of the thinkers radar class of (the global ranking of up-and-coming thinkers). he co-leads the capgemini invent\u2019s management lab. previously, content coordinator of . ", "# policy on the use of ai text generation ", "## preamble this policy derives from a case study conducted on , by the juniors and seniors in cds ds, \u201cdata, ethics, and society.\u201d the focus of the case study was the use of openai\u2019s chatgpt in university education. the case study involved analyzing ideas such as skill building and cheating, as well as the interests of stakeholders. the challenge posed within the case study was to devise a policy for use in their own class that takes full account of the aims of university education and the perspectives of relevant stakeholders, and can be shared for consideration in other classes. the case study was revisited each class session thereafter until a consensus was achieved. the result was the **generative AI assistance (gaia) policy** . the fundamental concerns of class members included wanting to learn how to use ai text generators skillfully while enhancing rather than damaging their own developing abilities as writers and thinkers, to honor stakeholder interests, and to ensure that grading is fair between people who do not use ai text generators and people who do use them, in a variety of different ways. this introduces new demands on those charged with grading student work. thus, the gaia policy stresses transparency, fairness, and obligations for both students and teachers. ", "## the generative AI assistance (gaia) policy we welcome ai language-generation tools (collectively, large language models, or llms) into the learning process, in a way that preserves fairness, optimizes student skill building, and honors relevant stakeholder perspectives. these include our own perspectives as students eager to learn and build careers, and the perspectives of our families who send us to university, our professors who are charged with teaching us vital skills, our university that has a responsibility to attest to our competency with diplomas, our future employers who invest in us because of our abilities and character, and our colleagues who lack privileged access to valuable resources. to that end, the gaia policy adopts a few commonsense limitations on an otherwise embracing approach to llms. . as students, we should give credit to llms whenever they are used, even if only to generate ideas rather than usable text. . when writing papers or take-home assignments using llms, we should include in an appendix our entire exchange(s) with the llm, highlighting the most relevant sections. we should write a narrative at the beginning of the appendix explaining precisely _how_ we used the llm (to generate ideas, turns of phrase, elements of text, long stretches of text, lines of argument, pieces of evidence, etc.). this narrative should also explain _why_ we used the llm (to save time, to surmount writer\u2019s block, to stimulate our thinking, to handle mounting stress, to clarify prose, to experiment for fun, etc.). . we should not use llms to help with in-class examinations, tests, or assignments, unless they are explicitly organized around an llm (e.g. an in-class assignment might challenge students to elicit from a llm the most profound statement on the future of ai). . if we choose to use an llm, we should use it wisely and intelligently, aiming to deepen our grasp of the subject matter and to support our learning. . our professor should seek to understand how llms work, including their strengths and weaknesses, as well as tools for detecting llm-generated output, in order both to optimize their value for our learning, and to incorporate that awareness into grading procedures. . our professor should: a. treat work submitted by students who declare no use of llms as the baseline for grading. b. use a lower baseline for students who declare use of llms, depending on how extensive the usage, while rewarding creativity, critical nuance, and the correction of factual inaccuracies or superficial interpretations in response to suggestions made by the llm. c. employ ai-text-generated-detection tools to evaluate the degree to which machine- generated text is likely to be present in student work. d. impose a significant penalty for low-energy or unreflective reuse of wording generated by llms, to the point of assigning zero points for merely reproducing llm output. furthermore: - we acknowledge that some may prefer stronger restrictions on the use of llms, and therefore that the gaia policy may make them feel uncomfortable. - we acknowledge that some aspects of this policy are non-enforceable and depend on goodwill, a sense of fairness, and honorable character. - we acknowledge that this policy will need to be revisited when subscription versions of llms become available, which may be affordable for some students but not for others. - we acknowledge that this policy may need to be revised in light of other policies that would supersede it or due to novel technological developments. ", "# generative AI in academic research: perspectives and cultural norms cornell university task force **executive summary** **** **introduction** **** **framework for using generative AI in research** **** **generative AI use across research stages** **** a. research conception and execution stage generative AI for literature review generative AI for research infrastructure generative AI for data collection and generation generative AI for ideation & hypothesis generation b. research dissemination stage c. research translation stage d. research funding & funding agreement compliance stage **perspectives and cultural norms** **** considerations for the cornell research community considerations for cornell leadership **appendix . prompts on generative AI in research (discussion starters or frequently asked questions)** **** a. research ideation and execution stage b. research dissemination stage c. research translation stage d. research funding and funding agreement compliance stage **appendix . existing community publication policies** **** **appendix . references consulted or cited** **** **appendix . task force charge** **** ", "## framework for using generative AI in research the epochal developments of in generative AI have enabled systems to _generate_ complex, recognizable outputs such as text, programming code, images, and voices. ai as a field has been around for , but the output of systems has often been narrow, binary predictions: whether an email is spam, or whether a transaction is likely to be fraudulent. generative AI offers dramatic new capabilities, generating output in response to _prompts_ (i.e., questions, requests, instructions) from the user. see inset: _what are generative uses of ai?_ generative AI provides the user a sense of power in its apparent intellectual assistance on demand, which unsurprisingly also vests the user with a need to take responsibility. academic research groups and projects often include multiple users with different stages of contribution, different degrees of experience and leadership, and different responsibilities to research integrity and translation of research results to societal impact. thus, we begin with the following general framework describing categories of **uses** of generative AI in research and categories of **duties** that researchers may have. there are many levels of potential **uses** in research, ranging from surface level adjustments to applications that blur the boundary of authorship. at one extreme, we might consider systems that simulate a copyeditor, correcting spelling or grammar, which are already integrated in many word processing systems. at the other extreme might be a system that acts as a ghost writer, converting vague descriptions and specifications into polished final **_what are generative uses of ai?_** **_to define what this report considers to_** **_be generative uses of ai tools (genai_** **_tools), a key distinction is whether the_** **_tool produces outputs that contain_** **_concepts and interpretations that the_** **_researcher or author did not supply._** **_under this distinction, neither a spell_** **_checker nor a tool that fixes grammar_** **_and_** **_improves_** **_sentence_** **_syntax_** **_is_** presentations. in between, systems might act **_checker nor a tool that fixes grammar_** more like research assistants, collecting and **_and_** **_improves_** **_sentence_** **_syntax_** **_is_** collating information, writing short computer **_considered generative AI, as long as it does not_** programs, or filling in paragraph bodies from **_alter concepts and interpretations that_** thesis statements. other uses might be more like **_the researcher or author supplied._** reviewers or editors, enabling researchers to **_conversely, a large language model_** \"bounce ideas\" or summarize a passage of text **_(llm) that writes a draft of the related_** to ensure that it reads correctly. **_work section is strongly generative, even_** **_if it received the relevant papers_** these uses imply corresponding **duties** by **_(supplied from the user or scraped from_** researchers. most high-performance generative AI **_the web) as input. similarly, a tool that_** systems are currently available as third-party **_creates an image or diagram in response_** (i.e., company product, not university-managed **_to a prompt should also be thought of as_** resource) cloud (i.e., using remotely located **_generative_** **_if_** **_the_** **_prompt_** **_contains_** computers) applications, so there is a researcher **_substantial ambiguity._** duty of _discretion_ in what data should be uploaded. generative AI, while usually convincing and **_even in this attempt to describe a_** fluent (at least in english), is often factually **_distinction_** **_between_** **_technical_** incorrect or lacking in attribution, so _verification_ **_improvement_** **_and_** **_new_** **_creation,_** **_it_** is another key duty to ensure accuracy and **_becomes clear that the boundary of what_** validity of research outputs. researchers may **_constitutes generative AI cannot be cleanly_** also have a duty to provide transparency and **_delineated. we expect that greater_** _disclosure_ to identify how and where generative AI **_understanding of generative AI tools and their_** contributed. finally, we need clear lines of **_impact_** **_on_** **_research_** **_will_** **_shift_** individual and collective _responsibility_ to ensure **_interpretations of assistance versus_** that the other duties are actually executed. **_creation. note also that this definition_** **_hinges on the use of the tool, not on the_** **_tool itself, implying that the same tool_** for the remainder of this report we will identify **_used in one context may count as_** specific situations in the research process, and **_generative, while it is not generative in_** **_other contexts._** describe how they relate to these _categories of_ _use_ and what duties we believe apply in academic research \u2013 and are consistent with cornell shared values. **in all of these research stages, we consider generative AI to be a useful research** **tool that can and should be explored and used to great scholarly advantage.** as with all tools, the user is responsible for understanding how to use such tools wisely. as with all academic research, the responsibilities are shared, but the research leader \u2013 called principal investigator in some fields and contexts, and lead author, corresponding author, or lead inventor in others \u2013 is considered **_considered generative AI, as long as it does not_** **_alter concepts and interpretations that_** **_the researcher or author supplied._** **_conversely, a large language model_** **_(llm) that writes a draft of the related_** **_work section is strongly generative, even_** **_if it received the relevant papers_** **_(supplied from the user or scraped from_** **_the web) as input. similarly, a tool that_** **_creates an image or diagram in response_** **_to a prompt should also be thought of as_** **_generative_** **_if_** **_the_** **_prompt_** **_contains_** **_substantial ambiguity._** **_even in this attempt to describe a_** **_distinction_** **_between_** **_technical_** **_improvement_** **_and_** **_new_** **_creation,_** **_it_** **_becomes clear that the boundary of what_** **_constitutes generative AI cannot be cleanly_** **_delineated. we expect that greater_** **_understanding of generative AI tools and their_** **_impact_** **_on_** **_research_** **_will_** **_shift_** **_interpretations of assistance versus_** **_creation. note also that this definition_** **_hinges on the use of the tool, not on the_** **_tool itself, implying that the same tool_** **_used in one context may count as_** **_generative, while it is not generative in_** **_other contexts._** responsible for communicating expectations to their research colleagues and students, and ultimately bearing consequences of intentional or incidental errors in tool use. ", "## generative AI use across research stages we considered four stages of research, each of which may receive different emphasis among cornell\u2019s impressive breadth of research and scholarship areas. **figure ** illustrates these four stages where generative AI can be used to great advantage, with appropriate sense of duty by the researcher(s). _of use and duty varying by research stage and by research discipline. while such boundaries across research stages_ **_figure :_** _stages of the academic research life cycle in which uses of generative AI can be envisioned, with considerations_ _are porous, this framing helps distinguish the tradeoffs and responsibilities of use in context. image component_ _attributions: appendix ._ these four stages that can be considered in the life cycle of research include: and execution stage: includes ideation by the individual and research team, prior to any public dissemination of ideas or research results. b. research dissemination stage: includes public sharing of research ideas and results, including peer-reviewed journal publications, manuscripts and books, and other creative works. stage: includes reducing research findings or results to practice, which may be in the form of patented inventions or copyrights, for products or processes or policies. d. research funding and funding agreement compliance stage: includes proposals seeking funding of research plans, as well as compliance with expectations of sponsors or the us government policies relevant to cornell as an institution of higher education and a research university. ", "## a. research conception and execution stage in this tion we discuss uses of generative AI for the \"internal\" research process prior to the preparation of public documents. research conception and execution includes literature review, research infrastructure, research ideation, and hypothesis generation. **generative AI for literature review** the volume of published research literature and data have been expanding exponentially, accelerating with technology advances such as movable type and publishing changes such as electronic journal proliferation and public **what about review articles?** **_in practice, these suggestions on use of_** **_genai_** **_in_** **_literature_** **_review_** **_during_** **_research conception and ideation could_** **_also be applied to those authoring a_** **_review article (i.e., containing no new_** **_research_** **_data_** **_or_** **_findings,_** **_but_** **_summarizing past work and identifying_** **_new_** **_ways_** **_forward_** **_for_** **_the_** **_field)._** **_however, review articles are currently_** **_thought_** **_in_** **_most_** **_communities_** **_to_** **_contribute_** **_an_** **_original_** **_slant_** **_or_** **_perspective of the authors; a \u201cghost_** **_written\u201d review article that is conceived_** **_by generative AI and then simply fact-checked_** **_or copy edited by the authors seems a_** **_distortion of that intent, and this_** **_possibility_** **_should_** **_be_** **_considered_** databases. it is widely assumed that there are **_possibility_** **_should_** **_be_** pockets of information in distinct fields that, if **_carefully by the authors to confirm that it_** combined, could lead to breakthroughs. but despite **_still expresses their own insights._** the volume of published information, those serendipitous connections are infrequent because fields are mutually inaccessible due to technical language, and no one from either field knows to look for the other (e.g., epidemiologists and aerosol physicists). in fact, interdisciplinary research often espouses the mixing of existing information in new ways, implying that generative AI systems which can keep track of vastly more information than any person may find connections that might be missed entirely by humans. acting as \u201cstate-of-the-art information retrieval\u201d systems (extance, ), they go beyond conventional databases, such as google scholar and pubmed, by being able to retrieve, synthesize, visualize, and summarize massive amounts of existing knowledge (e.g., semantic scholar, scopus ai, academic, iris.ai, scite, consensus). as such, they have the potential to help overcome the problem of \u201cundiscovered public knowledge\u201d (, ; davies, ), which may exist within the published literature, and break through disciplinary silos, facilitating the discovery of relevant research across diverse academic disciplines. in this context, suggested practices for using generative AI in the literature review phase of research conception are that: **_carefully by the authors to confirm that it_** **_still expresses their own insights._** - generative AI can be used to triage, organize, summarize, and quickly get directionally oriented, in the context of an exponentially growing base of reported claims and established knowledge. - generative AI can be used to assist with drafting literature reviews, although researchers should fact-check and be aware of incomplete, biased, or even false generative AI outputs. in some cases, it can help to provide generative AI with explicit prompt text to try to guard against the use of fake references (e.g., , ), although it still does not guarantee accurate results. - subject to authorship, citation, and fact-checking considerations, it can be helpful to use generative AI to ideate and iterate on the quality of a literature review. examples include (a) refining the review to include both prior research and its connection to the new research idea, (b) rewriting the style of the literature review, and (c) refining the literature review to emphasize the contribution of the new research, such as is relevant to other gaps in literature, uncertainties, or even market sentiments. _duty of verification._ the reliability and quality of ai-powered literature review tools are limited by the databases they search, which can affect the comprehensiveness and accuracy of the results. therefore, it is advisable to use these tools in conjunction with other methods. another major concern when using these tools is plagiarism, as they can produce verbatim copies of existing work without proper attribution or introduce ideas and results from actual published work but provide incorrect or missing citations. to minimize the risk of unintentional plagiarism, it is best to start with original text and then use generative AI assistance to refine it, in line with the distinction between ai- _assisted_ and ai- _written_ text , bollen, ., ). this will help ensure that ai-generated text is original and reflects the authors\u2019 own work, as also emphasized in journals and professional societies that permit the use of generative AI tools (but note that some journals prohibit the use of generative AI for any part of the research process entirely; see **appendix ** for a summary of existing community publication policies, noting that such policies are subject to change by those communities and publishers). finally, depending on the extent of generative AI assistance with information search and literature review production (specifically, when it is used beyond grammatical polishing of authorwritten text), researchers may have a _duty of disclosure_ for this research stage. **generative AI for research infrastructure** one of the more benign possible uses of ai is in improving workflows and research processes. collecting and processing data often involve custom software, using complicated apis (application programming interface, or software with a specific function) that may be poorly documented. code generation tools such as copilot have become powerful and successful, leading to significant improvements in users' ability to create software to collate and analyze data. other ways might involve using generative AI to help construct or critique survey questions or interview templates. in each case, the ai is not involved in producing or recording data, but in building the infrastructure that is itself used to produce data. a ond category of infrastructure might include code or language generation for presentation of research results. apis for generating figures, such as matplotlib or , are notoriously complicated, with innumerable options for modifying the appearance and layout of graphics. code generation may help in producing programs to generate graphics from data sets, without being directly involved in the construction of data sets themselves. similarly, language models might assist in generating alt-text for image accessibility. _duty of verification._ as with any other use of generative AI, infrastructure-building uses require careful checking to ensure that outputs are correct. there should be clear responsibility for who will do this verification. we see less need to disclose the use of generative AI in these \"back office\" contexts relative to other uses, though still with care for potential implications at later research stages. **generative AI for data collection and generation** a subtle but important distinction is when we move from using _genai to help develop tools that we_ _use in research_ to using _genai as a tool for research_ , specifically for data collection and generation. in principle, the potential for data collection is enormous. generative AI can be used to help construct data sets from unstructured data, such as descriptions of patents, job vacancies, (us urity and exchange commission) filings, banker speeches, etc. generative AI tools can also be used to synthesize information coming from text, or images. they can be employed to self-assess (predict accuracy) and augment which coding tasks are conducted by human iteration. advantages for data collection and generation using generative AI as a tool for research include: - collecting and organizing data. consider the cornell lab of ornithology\u2019s example of ebird as one data-rich source: through this global application platform, birdwatchers have submitted a large amount of bird observations that have already informed development of species distribution models (, ). - generating data out of unstructured information. - summarizing data coming from various sources. data related to human clinical trials or patient outcomes hold different and important data privacy concerns, but the collection and organization/cleaning of such data is a key step in inference for patient-centered health outcomes (waitman ., ). - scaling up data collection with generative AI by conducting faster and less resource-intensive experiments. the challenges of using generative AI tools for data collection and generation primarily relate to the _duties_ _of verification and disclosure:_ \u25aa issues with performance and accuracy: large language models like chatgpt are currently not fundamentally trained to speak accurately or stay faithful to some ground truth. \u25aa the reliance on large amounts of data may be challenging, and the needed data may not always be available. \u25aa bias (king and zenil, ): ai is traditionally trained on data that has been processed by humans. example: in using ml to categorize different types of astronomical images, humans might need to feed the system with a series of images they have already categorized and labeled. this would allow the system to learn the differences between the images. however, those doing the labeling might have different levels of competence, make mistakes and so on. generative AI could be used to detect and to some extent redress such biases. \u25aa attribution: data sources may not always be tracked. there is a need for ensuring correct humans. example: in using ml to categorize different types of astronomical images, humans might need to feed the system with a series of images they have already categorized and labeled. this would allow the system to learn the differences between the images. however, those doing the labeling might have different levels of competence, make mistakes and so on. generative AI could be used to detect and to some extent redress such biases. attribution of data sources. given these challenges, the use of generative AI tools for data generation and collection must be carefully documented and disclosed to facilitate research assessment, transparency, and reproducibility. **generative AI for ideation & hypothesis generation** while the use of generative AI for idea generation is under early consideration by most academic researchers, it is important to weigh its strengths and weaknesses in the early phases of research. if we think of the idea generation process as a creative process (as opposed to fact-checking or verification), then complementing ideation with generative AI can potentially offset human weaknesses, such as comparatively poorer memory recall versus recognition processes and narrower breadth of knowledge bases. in this sense, generative AI can complement individual researchers during the ideageneration process and democratize access to research assistants. on the other hand, scientific knowledge relies on the ability to reason rationally, do abstract modeling and make logical inferences. however, these abilities are handled poorly by statistical machine learning (ml). humans do not need a large amount of data or observations to generate a hypothesis, while statistical ml relies on vast amounts of data. as a consequence, computers are still unable to formulate impactful research questions, design proper experiments, and understand and describe their limitations. furthermore, assessing the scientific value of a hypothesis requires in-depth, domain-specific, and subject-matter expertise. an example is the potential of \u201clanguage based discovery\u201d (lbd) as the possibility to create entirely new, plausible and scientifically non-trivial hypotheses by combining findings or assertions across multiple documents. if one article asserts that \u201ca affects b\u201d and another that \u201cb affects c,\u201d then \u201ca affects c\u201d is a natural hypothesis. the challenge is for lbd to identify which assertions of the type \u201ca affects c\u201d are novel, scientifically plausible, non-trivial and sufficiently interesting that a scientist would find them worthy of study (smalheiser . ). whereas generative AI does well in identifying and retrieving potential data constructs, researcher domain expertise remains critical for determining the quality of output (dowling and lucey, ). while considering the possibilities of generative AI-human collaboration for research ideation, it is essential to emphasize _the duty of discretion_ to prevent the leakage of proprietary, sensitive, and confidential information into public information space. furthermore, since using generative AI tools is an evolving space, academics should learn more about generative AI technologies and stay abreast of potentially useful ways for hypothesis generation. for example, as food for thought, one of the generative AI prompts used by dowling and lucey () for idea generation: \"you [the generative AI tool] created this research idea, and i\u2019d like you to improve it. could you see if there is an additional article that can be added, to improve the research idea. can you also talk about the novel contribution of the idea. please keep it to about words.\u201d moreover, as we humans gain experience and familiarity with new tools, we do well to be observant to the expectation that they can also change how we conduct research and interact with researchers at this ideation and hypothesis generation stage \u2013 in ways that are not always easy to identify _a priori_ . finally, we note that research execution includes expectations of responsible conduct of research, which for some studies and disciplines includes prior approval of data use and management, animal welfare and procedures, and human subjects. use of generative AI in research will likely augment considerations of these approvals per expectations of sponsors or federal agencies through research integrity review processes of the university. those considerations related to research compliance are expanded in tion d. next, we consider the stage where research of any type is disseminated through public disclosure including peer-reviewed publications. ", "## b. research dissemination stage generative AI offers new affordances that support both positive and negative outcomes for research dissemination (nordling, ). on the positive side there is the potential to level the playing field for non-native speakers of english; to provide writing assistance resulting in improved clarity; and for new tools that aid in more equitable discovery of related work (improving on common practices of searching for well-known authors, for example). on the negative side there are serious and reasonable concerns such as erroneous information being disseminated because of inadequate verification; easier plagiarism (either intentional or accidental); lack of appropriate attribution because current llm-based tools are unable to indicate the source of information; bias and ideological influence; and inappropriate use of generative AI as a lazy peer review tool. additionally, we must be aware that careless use of generative AI may entrench biases in scholarly communication and dissemination, such as reinforcing the positions of prominent scholars and preferring sources in english as the dominant language of the initial trained models available to the general public. however, future generative AI tools may also provide new interventions to oppose existing biases that are entrenched in current practice. as such, the following is less focused on specific generative AI tools available , but more on general recommendations for the responsible use of generative AI tools in research dissemination that upholds research integrity as a principal value at cornell. in this section and research stage, we do not discuss questions of copyright, confidentiality or intellectual property (see section c), but instead focus on the conceptual impact that generative AI can have on producing research output. following from the definition of generative AI from above, a key distinction is whether the tool **produces output for dissemination that contains concepts and** **interpretations that the author did not supply** . from this perspective, generative AI tools that fill in concepts or interpretations for the authors can fundamentally change the research methodology, they can provide authors with \u201cshortcuts\u201d that lead to a breakdown of rigor, and they can introduce bias. this makes it imperative that users of generative AI tools are well aware of the limitations of these tools, and that it is clear who is responsible for the integrity of the research and the output that is produced. below we discuss these issues in more detail and provide a minimal set of norms that we recommend across all disciplines. however, we recognize that the methodology and standards are differentially impacted by generative AI across disciplines (e.g., humanities as well as engineering), and that community norms around the use of generative AI may be stricter than what is outlined below. **authorship** : we posit that generative AI tools do not deserve author credit and cannot take on author responsibility. this means that authors of research outputs, not any generative AI tools used in the process, carry the responsibility for checking the correctness of any statements. authors must be aware that generative AI tools can and do produce erroneous results including \u201challucinated\u201d citations. the content will be viewed as statements made by the authors. indeed, there are emerging concerns on impact to scientific publishing with which publishers and ai ethicists are now grappling (conroy ), but the responsibility of authentic authorship is a component of research integrity that will continue to rest with the human authors. **impact on concepts and interpretations** : researchers need to be aware that generative AI tools can have a substantial impact on the research output depending on how they are used to fill in concepts and add interpretations. if the impact is substantial, we recommend that the use of generative AI is disclosed and detailed so that readers are aware of its potential impact. what constitutes substantial impact depends on the type of publication (e.g., journal articles, books, talks, reports, reviews, research proposals) and community norms in the respective discipline. an example that is probably considered to have a substantial impact in any discipline is the use of generative AI to draft a related work section. **impact on methodology** : writing and other dissemination activities typically cannot be separated from conducting the research, and the act of writing is explicitly part of the research methodology in some disciplines. a key concern is that the use of generative AI as a \u201cshortcut\u201d can lead to a degradation of methodological rigor. if the use of generative AI tools can be viewed as part of the research methodology, then we recommend disclosure so that readers can assess the rigor of the methodology. indeed, there may be collective impact on methodology at the scale of the research community\u2019s practices. whether generative AI becomes a tool that sharpens our minds or a blunt instrument that dulls them is a question that cornell (and other communities of research scholars) must address actively over time. historically, human imagination sees most tools as helpful implements to move on to harder problems and more creative discovery and analysis, if one masters the tool instead of the other way around. but we can also recognize from past experiences that zeal for rapid development of exciting new research-enabling capabilities \u2013 especially when these provide competitive advantage over peers that can relate to economic competition or even national security \u2013 can shift even the best intentioned individuals to start to behave collectively as a group that focuses sharply on the benefits without openly discussing the costs and trade-offs. **potential for bias** : just as authors need to be aware of human biases in their sources, authors using generative AI tools need to be aware that these tools have biases and may reflect specific ideologies. it is the authors\u2019 responsibility to counteract or avoid these biases, and authors cannot offload responsibility for bias in their work on the ai system. for example, use of a generative AI tool to create a hospital scene might result in an image in which the nurses are female and the doctors are male. changing the prompt could address this bias. another issue is that generative AI tools may reflect a particular ideology, or they may perpetuate historical biases because generative AI tools are trained on historical data. this may be compounded by particular algorithms such as citation analysis which has an inherent time lag, and might further bias recommendations back in time or towards a dominant group or language. **acceptable use** : there are many different forms and venues of research dissemination: journal articles, books, talks, reports, reviews, research proposals, etc. what is acceptable use of generative AI in one form of communication is not necessarily acceptable in other forms, and authors must adhere to community standards. to take an extreme example, having a generative AI tool draft a peer review from scratch runs counter to the idea of peer review and has an extremely high impact on the review, even if the author checks and edits the review. this is likely unacceptable in most communities. even within communities, different publication venues (e.g., journal, conference) may have different policies, and authors must check and follow these if more stringent than what is outlined here. **ai literacy to support research integrity** : rigorous and ambitious use of generative AI tools requires a good understanding of the strengths and weaknesses of these tools. furthermore, as generative AI has become part of the integrity of research and its dissemination, then research leaders such as principal investigators and faculty supervising student research should now make the appropriate use of generative AI part of their mentoring. in particular, part of their mentoring is to communicate the standards and the norms in their specific fields to the researchers and students they lead \u2013 just as they mentor on other topics of research conduct (e.g., plagiarism, co-authorship, privacy regulations). **regulations** : any use of generative AI tools needs to be compliant with regulations (e.g., copyright law, privacy regulations such as hipaa and ferpa, confidentiality agreements, and intellectual property). in particular, users must be aware that use of generative AI tools may disclose sensitive information to a third party, which may be in violation of regulations and confidentiality norms (lauer . ; conroy ). this extension to implications for subsequent research translation to policies, processes, and products of all types is discussed further in ", "## c. research translation stage the use of generative AI in any stage of the research process may impact the translation, protection and licensing of intellectual property (ip), commercialization of technology, open-source release of software and other uses of the research output downstream. interpretations of laws and new regulations regarding generative AI are major topics for governments in many countries including the us. there may be new government agencies and international organizations created for ai regulation and coordination in the near future. in fact, while recently announced new regulations on artificial intelligence, current understanding is that most of this eu policy effort to create these \u201cfirst rules\u201d preceded widespread use of generative AI ( ). we can draw no immediate conclusions on how the eu\u2019s risk-based approach may impact generative AI development and uses specifically. the nature of the impact of generative AI is still evolving and may change in , with legislation and guidees expected to lag the use of generative AI and its shorter term implications, which may be inadequately addressed under current laws and regulations. the following are important areas for researchers to consider for translation when they use generative AI in their research process: **inventorship and patentability:** recent us case law has held that inventors of patents must be human beings under . documentation of human contribution and disclosure of the nature of generative AI utilization are essential for patent eligibility. key information needs to be carefully documented, such as: - specific generative AI tools used and rationale for their use; - detailed input into and output of the generative AI tool; - whether the outputs lead to any aspects of the conception of the invention; - contributions of individual inventors in the inventive idea, and how they directed and refined the generative AI output; and - for research done in teams, deeate the role of generative AI for each inventor. **copyright and authorship** : under current us copyright law, copyright can protect only material that is the product of human creativity and authors of copyrighted materials must be human beings. when incorporating generative AI-generated content, the authors should: - clearly document the boundary between human-created and generative AI-created content with clear annotations. - according to guidance published by us copyright office, if copyright registration is sought, the nature and extent of the use of generative AI, if containing more than aigenerated material, must be disclosed with clarifications of what part of the work was __ created by the researchers and what part of the work was created by the generative AI. - specifically for computational algorithms and code, where research code can be further translated to wider use through copyright and various licensing types including opensource licensing, considerations attach at a time of active discussion. we note emerging considerations of copyright infringement, not only for creative works such as songs but also for computational code. for example, it is possible that code generated by a llm reflects code reproduced verbatim from the llm training set unbeknownst to the user. when such code is part of a research outcome that may be made available to licensees (even open-source licensees), it is possible but not yet well understood how use of such code, even when unintentionally plagiarized from other original sources, may violate copyright or invalidate licenses. **commercialization and fair use** : for research that leads to commercialization and publications with financial benefits, to mitigate risks of potential infringement claims, the inventors and authors should: - prioritize the use of generative AI tools that are trained using only public domain works, which is a small but growing area of development. for example, the recently announced ai alliance coalition that includes cornell as a founding member and anchored by two forprofit companies, and meta, advocates for development of open-source software tools including those enabg generative AI ( / ; , , ). - understand that the commercial intent can significantly impact fair use considerations. consult with relevant university offices, such as the center for technology licensing or general counsel\u2019s office, when there are questions. - stay informed of ongoing litigation that may influence the use of copyrighted materials in generative AI training data set. there are pending class action copyright suits by authors against entities owning generative AI tools for training without compensation to the authors. **data privacy and protection** : for data that researchers enter into generative AI themselves, it is important that researchers follow cornell policy . on research data retention. note that this is an existing policy and practice, simply extended to generative AI. private, confidential, or proprietary data owned or controlled by cornell may have certain contractual or legal restrictions or limitations, such as those to sponsors or collaborators, that would preclude their use in generative AI research projects, and it is a researcher\u2019s responsibility to verify/determine whether any such data sets have restrictions on such use before inputting them into public-facing generative AI and ensuring compliance with any restrictions mandated by contract, law, or governing body (e.g., irb, iaucc). any use of patient or human derived data should be disclosed to such governing body during the approval process and any such data set should only be used in research projects upon the explicit approval of the relevant governing body on campus. **training** : specific to this stage of research translation, it is recommended that the university provide ongoing workshops on campus or through one platforms, and offer training materials through websites and other distribution channels, on topics related to the use of generative AI and its impact on patent rights, copyrighted materials, commercialization, open-source release and other uses to aid the researchers in understanding their rights, obligations, best practices and landscapes of relevant laws and regulations. indeed, cornell includes faculty and staff experts that can facilitate and codevelop such resources as part of their scholarly practice. ", "## d. research funding & funding agreement compliance stage during the research funding and funding-agreement compliance stage, there are many potential applications of generative AI. for example, these tools can be leveraged to assist in the writing of technical, science-related information for a proposal to a sponsor or a donor, such as the technical scope and anticipated impact. on the non-technical side, they can also be used to draw appropriate data from multiple data sources to develop information for a biosketch, a report of current and pending support, and other documentation relevant at this stage of the research process. work conducted during the research funding and funding agreement compliance stage is poised to benefit from the use of generative AI tools, for example, due to efficiency improvements and reductions in the time taken to produce previously time-consuming work. however, the use of these tools also comes with risks. generative AI may produce outputs that include incorrect or incomplete information. these tools also may lack sufficient security and privacy protections, both in the tools themselves, and in any plug-ins and add-ons to the tools. note that we and many federal agency sponsors refer to the person of primary responsibility in research as the _pi_ , or principal investigator, and pronounced pee-i, for shorthand. we acknowledge that this term is common for research in the sciences and engineering with cultures of team-based research and that other fields have a tradition of independent scholarship and authorship even when enrolled as graduate students. **responsibility:** as with the earlier stages of research, users of generative AI hold some burden of responsibility (or _duty_ ) in the research funding and funding agreement compliance stage. in this stage, however, it is common to attach the primary responsibility of compliance to the leader of the research effort. for example, the accuracy of any information contained in a proposal for funding is ultimately the responsibility of the pi, and so if the pi uses generative AI in the development of materials for that proposal, they must review the information in those materials and correct any omissions, errors, or otherwise inaccurate information. the pi must also understand that although resources (for example, research administration staff professionals in cornell departments, colleges/schools, or research & innovation office units) are available to help them during this stage of the research process, these resources cannot certify to the accuracy of much of the information provided to them, and therefore cannot be expected to identify mistakes in that information, such as those generated by generative AI. the pi must also understand that they are responsible for the activities of students and research personnel working on funded projects under their supervision or mentorship, and for ensuring the appropriate use of generative AI tools by those individuals. see **appendix ** , prompts on generative AI in research for suggested discussion starters. during this stage, individuals may desire to input information into generative AI to assist in the production of their research proposals, reports to sponsors, or even the public dissemination and translation stage documents that may have specific restrictions placed by the sponsors. because some of this information will be highly sensitive, such as unpublished technical information or private funding data, users of generative AI tools must understand their responsibility for protecting the privacy and security of any information they input into these tools, and must seek approval to do so from the owner (such as the pi) of any such information. in fact, even in the peer review of sponsored research proposals (e.g., faculty serving on review panels for nsf or study sections for ), the use of generative AI may not be allowable by the sponsor (nsf notice to research community, ). in this stage of the research process, it is also important for those who are responsible for making decisions regarding the use of sponsored funds to consider whether, and under what circumstances, it is appropriate to charge the use of generative AI tools to a research account, and to ensure their awareness with each sponsor\u2019s requirements. although some sponsors are clear on whether and how funds may be applied to the use of generative AI, others are not. **guidance and training:** the nature of these tools, their potential applications, and the associated benefits and pitfalls will continue to develop and change over time, and thus, so will the appropriate guidance on how to use them. although information and guidance should be shared with users about the risks of the use of generative AI and about which tools to avoid, it is also important to share information and training on how users _can_ make use of these tools, how to navigate security and privacy concerns with confidence, and to provide access to tools that have been vetted and found to be aligned with the university\u2019s expectations for security and privacy. in this context, we suggest the following considerations as resources developed by and for the research community, including staff professionals experienced in research integrity, information systems, and user experience. - broad communications and outreach about **what about re** **search involving** **human participants?** **_applications of generative AI involving human_** **_subjects, including but not limited to_** **_healthcare research, would be expected_** **_to include institutional review board_** **_(irb) review. research in which genai_** **_may be a useful tool may also include_** **_involving patient-related data. it will take_** **_time to consider how ethics and societal_** **_impact can be considered thoughtfully_** **_and reviewed/approved by appropriate_** **_boards when generative AI tools are used or_** **_developed in such proposed studies._** **_this consideration is already an active_** **_area of research for some at cornell (e.g.,_** **_center_** **_for_** **_precision nutrition and_** **_health; see refences cited) and is_** **_connected naturally to the faculty-staff_** **_irbs that serve all of cornell\u2019s campuses_** **_as_** **_part_** **_of_** **_research_** **_integrity and_** **_assurance. part of that research integrity_** **_process connects to existing cornell_** **_policy . on research data retention_** **_(see section: _** **_norms). additional resources will benefit_** **_researchers who propose such research_** **_with_** **_unique_** **_data_** **_protection_** **_and_** generative AI in responsible conduct of research. **_process connects to existing cornell_** these communications should include guidance **_policy . on research data retention_** and resources on the use of generative AI, as well as **_(see section: _** information about training, what tools to use **_norms). additional resources will benefit_** or avoid, and references to offices and units **_researchers who propose such research_** that are available to provide support. when **_with_** **_unique_** **_data_** **_protection_** **_and_** appropriate, this outreach should be shared **_ethical/societal considerations, which_** by central offices and posted to central web **_will continue to meet federal and review_** **_body guidelines._** pages \u2013 such as the recently developed artificial intelligence website hosted by cornell information technology (cit) that links to cornell\u2019s generative AI in education report and other resources \u2013 rather than from individual units or departments, to create consistent understanding and information access across campus. providing this type of outreach from central offices can help ensure that the university as a whole is looking to the same resources; that inquiries and concerns come to the appropriate offices; that approaches, advice, and guidance given are consistent across units; and that gaps in accessibility of information and learning are kept to a minimum. **_ethical/societal considerations, which_** **_will continue to meet federal and review_** **_body guidelines._** as with training on the use of, for example, animals, human participants, or biological agents in research, centralized training should be provided on the use of generative AI. this training should not only focus on risks and concerns, but on how to get the most out of these types of tools, and how to use them better. \u201chackathons as training\u201d should make it enjoyable for researchers to gain new skills, while also contributing to the safe and responsible use of generative AI. - guidance on navigating mistakes made and security breaches should be communicated university-wide. it is important to acknowledge that with these new tools comes some anxiety about making mistakes in using them appropriately or even safely. to an extent, inadvertent mistakes present opportunities for education and training. however, it is also important that any mistakes that lead to security, privacy, or other concerns are handled correctly and in a timely manner. information should be shared university-wide about cornell\u2019s expectations and processes with regard to what to do in the case of a potential security or other risk related to the use of generative AI, and which responsible offices should be notified. - additional tools and resources should be developed to provide guidance. it would be beneficial to researchers and administrative staff alike to develop a generative AI-enabled tool (e.g., a form of a chatbot) that would respond to common inquiries about the use of generative AI in research. for example, \u201ccan i use generative AI to edit my scope of work?\u201d this tool could be populated with responses to common questions, so that consistent answers could be communicated broadly \u2013 even while appreciating that perspectives and cultural norms and even sponsor requirements and expectations may be changing fluidly in . because such a tool would be automated and would provide immediate access to answers to these types of common questions, it would both reduce wait times and delays associated with other means of gathering this information, and reduce administrative workload in responding to these types of common requests. similarly, resources that facilitate awareness of resource use (e.g., estimated carbon dioxide emissions associated with tool use; see section a) can be made available at the artificial intelligence website and/or developed by cornellians whose research and translation focus includes sustainability practices (e.g., cornell atkinson center for sustainability). ", "## perspectives and cultural norms having framed the use of generative AI in research across the stages of research above, we here summarize the perspectives that can inform our cultural norms. the widespread availability of generative AI tools offers new opportunities of creativity and efficiency, and as with any new tool depends on humans for responsible and ethical deployment in research and society. thus, it is important that cornell anticipates that researchers can and should use such tools appropriately, facilitates researcher access to appropriate generative AI tools and to resources to improve researchers\u2019 \u201cai literacy.\u201d it is also important that we develop shared understanding of the limits of appropriate use of specific publicly available and commercial generative AI tools, as well as the tradeoffs or risks involved in their use. while these perspectives and cultural norms will vary reasonably among different research communities, and likely vary over time in , we offer the following summary considerations. these are considerations of both opportunity (ambitious use that may create new knowledge, insights, and impact for the world) and accountability or responsibility (duty grounded in research integrity of individuals, research teams, and institutions including cornell). we consider these to be peer-to-peer guidelines, not a suggestion of any formalized university policy. however, we remind our fellow cornellians that two existing policies naturally extend to use of generative AI tools in research: . as noted in the university privacy statement , cornell strives to honor the privacy /privacy-cornell/privacy-principles-cornell) : notice, choice, accountability for onward transfer, security, data integrity and purpose limitation, access, and recourse. this is noted on cornell\u2019s artificial intelligence website, along with preliminary guidelines of accountability that are discussed in this report in the context of researcher duties and research integrity. . [cornell policy . on research data retention . private, confidential, or proprietary data owned or controlled by cornell _may_ have certain contractual or legal restrictions or limitations, such as those to sponsors or collaborators, that would preclude their use in generative AI research projects. it is the researcher\u2019s responsibility to verify/determine whether any such data sets have restrictions on such use before inputting them into publicfacing generative AI and ensuring governing body compliance (e.g., irb, iaucc). relatedly, any use of patient or human derived data should be disclosed to such governing body during the approval process, and any such data set should only be used in research projects upon the explicit approval of the relevant governing body on campus. ", "#### considerations for the cornell research community we as colleagues encourage faculty, research and administrative staff, and students to help develop the norms, technology, and public reflection on generative AI use in research, to both shape and stay current on these uses and scholarly practices. these five areas of consideration for the cornell research community are summarized below, as part of responsible experimentation. help develop the norms, technology, and public literacy around generative AI. \uf06f actively develop the norms and best practices around the use of generative AI in their disciplines. \uf06f develop generative AI technology that is particularly suited for research (e.g., improved attribution). generative AI development for academic use should not be left solely to for-profit companies. \uf06f engage in generative AI public literacy efforts to foster responsible and ethical use of generative AI tools. using at least one of these tools is enormously helpful to being part of that conversation and process, and many are freely and publicly available with associated caveats on risks of use. **table ** provides examples of currently available generative AI tools that can be accessed (denoted as \u201cfree\u201d to indicate no financial charge to the user). we emphasize user awareness and appropriate caution: only publicly available data should be included, and the user should assume that any entry of information by the user can be absorbed into that tool\u2019s training set and potentially exposed to others. stay up-to-date with generative AI uses and practices \uf06f each research subcommunity (whether a faculty member\u2019s research group, a department, interdisciplinary research center or institute, or college/school as those researchers see fit) gather relevant information on relevant policies by professional associations, journals and funding institutions to stay up-to-date with evolving policies, practices, and requirements in your field **. appendix ** may serve as a discussion starter. in how to use generative AI tools in a safe, effective, and productive manner in research and innovation. develop expertise in the potential limitations and risks of generative AI tools. |free* generative AI tool|how to find it|what it can do| |---|---|---| |chatgpt|go to / in any browser|generates text. the free version of chatgpt uses the openai gpt-. model.| |copilot with bing chat|go to . in the edge browser, you can open up bing chat in a sidebar that gives you additional functionality, by clicking on the icon in the top right corner. for help installing edge you may need to reach out to your it support.|generates text and images. with the sidebar version in edge, allows you to ask questions about specific web pages or pdfs in the browser window. the free version of bing chat that is available now uses the latest openai models, for text and dall-e for images.| |google to / in any browswr.|generates text. it now uses a more powerful model called gemini.| |stable to  in any browser.|generates images using the open stable diffusion xl model.| |runway ml|go to  in any browser.|generates video from text or still images using the runway gen- model.| _table : a sample of free generative AI tools as of , where *free indicates no financial fee charged to_ _the user. none of these tools are endorsed by cornell, and those using these tools should note that these tools_ _are_ **_only for use with public data._** further, when acting as well-informed academic researchers with access to this research tool among others, consider the individual and shared **_duties of verification, disclosure, and discretion_** across the stages of research ideation and execution, public disclosure, translation, and funding expectations: duty of verification \uf06f do verify the accuracy and validity of generative AI outputs. the responsibility for research accuracy remains with researchers. \uf06f do check for unintentional plagiarism. generative AI can produce verbatim copies of existing work, or more subtly, introduce ideas and results from other sources but provide incorrect or missing citations. duty of disclosure \uf06f do keep documentation and provide disclosure of generative AI use in all aspects of a research process, in accordance with the principles of research reproducibility, research transparency, authorship and inventorship. duty of discretion x do not assume that generative AI is private. generative AI systems run on training examples, and user input and behavior are a prime source. even if organizations that provide generative AI tools do not currently claim to use data in this way, there is no guarantee that they may not in the future. x do not share confidential, sensitive, proprietary, and export-controlled information with publicly available generative AI tools. x do not assume that generative AI output is already considered part of the public domain (e.g., not legally encumbered by copyright). generative AI tools can \"memorize\" their training data and repeat it with a level of verbatim accuracy that violates copyright. even material that is not copyrighted may produce liability for corporate partners in sponsored research, if it is derived from data generated by a competitor. ", "#### considerations for cornell leadership we also provide considerations for cornell leadership, particularly for aspects of generative AI preparedness and facilitated use in research and innovation that can be implemented collectively across cornell\u2019s colleges, schools, and campuses. - develop a knowledge base module, perhaps as part of responsible research conduct training resources, for rigorous, ethical and responsible use of generative AI in research and related activities. users of generative AI tools need to understand their strengths and weaknesses, as well as regulations around privacy, special data considerations such as personally identifiable, human subject, or proprietary commercial data, and confidentiality and commercialization. - consider procurement of cornell-licensed generative AI tools with data and privacy protection as facilities for research, as well as for administrative and teaching uses. text generation and chat, program code generation, streamlined processes, and image generation would likely all be of value. - consider development or co-development of generative AI tools that are particularly suited for academic research use cases, including use cases in research administration services. - identify relevant central offices responsible for providing university-wide communications, guidance, outreach, and training to all generative AI users on various aspects of uses. to the extent that it is possible and relevant, information on the use of generative AI should be shared from central locations to encourage consistent access and understanding across the university, and to avoid siloed, inconsistent, or incorrect information. - in support of cornell's public engagement mission, recognize cornell efforts that improve generative AI public literacy beyond the university-affiliated community. - consider periodic updates to cornell guidance, through a task force or other appropriate generative AI public literacy beyond the university-affiliated community. mechanisms, given the rapidly changing landscape of generative AI tools, uses, and considerations in academic research and translation of research outcomes. ", "## a. research ideation and execution stage **_when using a tool such as chatgpt to generate research ideas for a research project sponsored by nsf,_** **_how do the researcher and principal investigator decide on which information and ideas to enter and_** **_\u201cshare\u201d with chatgpt?_** any information entered into public versions of chatgpt involves sending that data to a third-party that is under limited confidentiality and privacy restrictions (if any) with end users and not party to agreements with the nsf via data entry by other users, and the information that is entered can eventually become public. as such, where the use of chatgpt for research idea generation does not currently violate any known general nsf policies, users should also be sure not to violate any other agreements that may exist relative to their funding sponsorship agreements, such as confidentiality, intellectual property, and entity identification clauses (e.g., mentioning nsf in any input data may be discouraged to the extent that it is in conflict with an agreement). **_when using a tool such as chatgpt to brainstorm solutions for research sponsored by a company (e.g.,_** **_, , and , ), how do the researcher and principal investigator_** **_decide what information about the project can be entered and shared?_** again, any information entered into public versions of chatgpt involves sending that data to a third-party that is under limited confidentiality and privacy restrictions (if any) with end users and not party to agreements with corporate sponsors via data entry by other users. furthermore, any information that is entered can eventually become public. as such, where the use of chatgpt for brainstorming solutions does not currently violate any known general policies, users should also be sure not to violate any other agreements that may exist relative to their funding sponsorship agreements, especially including but not limited to, confidentiality and intellectual property clauses. **_when using generative AI tools to summarize the literature for the introduction or discussion of a peerreviewed article, how should the researcher and corresponding author attribute or disclose this section_** **_of a manuscript or thesis?_** in general, authors and/or principal investigators have ultimate responsibility for works (including their accuracy), and furthermore, summaries should not violate plagiarism rules and regulations. citation style guides and support websites (e.g., for , chicago, ) are being updated to reflect proper citations for verbatim output from generative AI and other uses. as a general practice, authors should be transparent and fully disclose uses of generative AI technologies, consistent with publication outlet, department, or area policies. **_what are the conditions, if any, that a researcher should not use generative AI to generate research ideas?_** **_examples may vary among research fields, sources of information included in a prompt including ferpa_** **_or hipaa data, and collaborating or sponsoring organizations._** there are no general rules that prohibit the user of generative AI to generate research ideas. however, because inputs into public generative AI platforms are not confidential and data can also become public, sensitive information and individual data should never be entered for any phase of a research project, pursuant to personal data identification, re-identification, and/or chain of custody ferpa and hipaa requirements. **_in the process of research publication development, can tools such as bard or chatgpt be used: to_** **_summarize responses to online surveys of income level of state residents? to summarize preclinical_** **_research animal model histology? to summarize patients\u2019 blood oxygen levels in a registered study?_** **_how can the differences among these use cases be distinguished in the responsible conduct of research?_** the summary of online survey data and/or other data sets can be assisted by bard or chatgpt to the extent that the researcher ) does not enter confidential or data protected by other laws (e.g., hipaa), ) does not violate a broader agreement (e.g., between researcher, institution, host, ), and ) has responsibility for the accuracy of the summary. ", "## b. research dissemination stage **_when a figure for a publication or presentation or patent disclosure is generated by ai tools (e.g.,_** **_midjourney; deepai), how should the principal investigator (who is typically the corresponding author_** **_or communicating inventor) verify the accuracy and intellectual ownership over the data or content of_** **_that image?_** we see a distinction between cases where the author supplies all semantics and uses a tool for layout and rendering, and when a tool is used to introduce semantics such as organization of ideas or the generation of structure. where the author supplies all semantics the use is akin to powerpoint style suggestions or an automated layout tool, and acknowledgement is generally unnecessary unless publication policies require it. however, when generative AI introduces new semantics then we advise acknowledging its use, and checking the output carefully for accuracy. norms around intellectual ownership are in flux at this time, and we caution authors that this poses a substantial risk. **_can images used in publications and theses be created wholly by generative AI? how does this_** **_expectation change if the generative AI-drafted images are edited by the authors? how does that vary among_** **_research disciplines?_** uses include generation of a cover image for a book or presentation, or images similar to clipart. we advise that authors should generally acknowledge the use of generative AI in this case, and they should carefully check images for bias and accuracy. authors should be aware that, in the us and many other jurisdictions, it is not possible to claim copyright in non-human created works even if any human additions/edits may be copyrightable. there are unresolved legal questions regarding possible copyright infringement both as a result of the training of generative AI programs on works under copyright, and as a result of output that might closely resemble works under copyright (see, for example, , \u201cgenerative AI and copyright law\u201d, updated ,  ). there is also significant variability in the acceptability of generative AI-generated images based on the publication venue. **_when and how should the corresponding author inform a journal of manuscript elements created by_** **_genai, if not explicitly required to disclose by the publisher and when not obviously using or studying_** **_genai? examples may be a proposed cover image, a graphical depiction of a new method, a graph_** **_containing research-generated data, a set of test data, generation of derivative data, etc._** generative AI technology is increasingly being built into services that provide grammar checks, polish language, and proofreading. general purpose tools such as chapgpt are also effective for these tasks. it is not usual to acknowledge the use of checking and suggestion tools. generative AI tools, like human proofreaders who may not understand the subject matter in detail, can suggest changes that change the intended meaning so authors must still verify suggestions with care. commercial checking and suggestion tools are being extended with generative AI features to draft entire sections or articles, or summarize texts, so authors should consider when their use crosses the line into generative use as defined above. **_when and how should research group leaders (e.g., faculty) communicate these expectations of_** **_appropriate/ethical/responsible use of generative AI in research to researchers who are undergraduate_** **_students? graduate students? postdoctoral researchers? other research staff?_** educating about the responsible use of generative AI should become part of the regular training on research methodology and norms of the respective discipline. this includes training that research leaders provide, but it also is a responsibility of cornell to educate faculty and students on the affordances and pitfalls of generative AI tools. ", "## c. research translation stage **_if an invention is reduced to practice in part by use of generative AI, how should the inventors document_** **_and inform others when considering a disclosure of invention or copyright?_** any use of generative AI in the conception and reduction to practice of an invention or generation of copyrighted materials should be carefully documented and disclosed to the center for technology licensing by the inventors/authors. for example, as to the conception and reduction to practice: - what was the generative AI tool used? - what were the inputs to the generative AI? do you have rights to the data used for input? - what were the outputs of the generative AI? - how did the outputs of the generative AI, if at all, lead to the conception of any aspect of the invention? - were there any difficulties encountered in using the generative AI to yield the outputs desired and, if so, which researchers updated use of the generative AI, model and/or data to yield the desired outputs? - which researchers substantively contributed to/controlled the development of the input and output corresponding to the invention? **_if the research outcome is open-source licensable and/or posted on an open-source repository (e.g.,_** **_code or algorithm or app), should and how should the researcher disclose use of generative AI in creation of_** **_the \u201copen source\u201d item?_** disclosure of the use of a specific generative AI tool and possibly even the origins of, and the rights to use, the input data used will likely be viewed as the standard for ethical behavior over time. currently there are no hard and fast rules. **_if the research outcome is a creative work (e.g., book, play, sculpture, musical score, multimedia exhibit)_** **_that used generative AI in the creation of that work, how should the researcher disclose that contribution in_** **_discussions of copyright?_** according to guidance published by usco, if copyright registration is sought, the nature and extent of the use of generative AI, if containing more than _de minimis_ ai-generated material, must be disclosed, and what part of the work was created by the researchers and what part of the work was created by the generative AI. **_how should the researcher inform themselves of the uncompensated contributions of others to the genai_** **_output used in their own creative and/or copyrighted work or invention? how does this responsibility_** **_depend on whether the researcher derives personal financial benefit (e.g., royalties on published book)_** **_from the research outcome?_** there are pending class action copyright suits by authors against entities owning generative AI tools. in those suits, generative AI tools are alleged to utilize existing copyrighted works for training without compensation to the authors. commercial purpose is an important factor in the determination of fair use. for research that leads to commercialization and publications with financial benefits, it will be safer to use generative AI tools that are trained using only public domain works. for data that the researchers put into generative AI themselves, it\u2019s important that they make sure they have the rights to do so regardless of whether they expect financial benefits from the output of generative AI. ", "## d. research funding and funding agreement compliance stage **_if grant proposal information related to science (technical scope) and non-science (biosketch, current &_** **_pending funding) components are generated by generative AI, who is responsible for editing them before_** **_submission to a potential sponsor? who is responsible if there are omissions or errors in those work_** **_products?_** the pi is responsible for the accuracy of information related to the science, as well as for omissions and errors in that information. on the non-science side, the pi is, again, primarily responsible for the information contained in their proposal. there are resources available to help them (such as research administration staff), but those resources cannot certify the accuracy of the information provided to them, or identify mistakes in information provided to them that occurred as a result of the use of generative AI. it is also important for the pi and their less experienced collaborators (mentees, supervised students) to discuss concerns about inputting information into generative AI tools. this information can be highly sensitive (unpublished technical information, for example) or personal to an individual (current & pending funding that must be disclosed to employers and sponsors but not to peers or the general public). to an extent, whether information is considered sensitive may depend on the context of the use of generative AI or of the research field itself. consensus of this task force was that the pi is responsible for the security of his or her research information, but that anyone who intended to input information into generative AI would need to seek approval to do so from the owner of that information (such as the pi). **_should the costs of generative AI be charged to a research account, assuming this is not disallowed by_** **_the corresponding funding agreement (i.e., not disallowed by a research sponsor)?_** the appropriate source of funds for generative AI in research may depend on how the generative AI is being used. if such use is categorized in such a way that other things falling under the same type of use could be charged to a research account (e.g., software services), then it is plausible that the use of generative AI may be acceptable. in some cases, sponsors note definitively whether such charges to sponsored project accounts are allowed, but this is not always the case. **_if a principal investigator becomes aware that her graduate student queried a generative AI tool (e.g.,_** **_chatgpt) with proprietary data obtained appropriately from a company when summarizing research_** **_team meeting notes, what should her next steps be? who is responsible for notifying the company? who_** **_is responsible for remedying the action if the company has grounds to sue for breach of the data use_** **_agreement?_** the pi is responsible for what their students do in the course of their cornell work, and is therefore responsible for ensuring that these individuals use generative AI resources appropriately. that said, mistakes are bound to happen, and they present great opportunities for education and training of both the faculty and of the students. further, in these situations when proprietary information is input into generative AI inappropriately, it is reasonable that the pi may feel compelled to directly report this issue to their technical contact at the company, but doing so may not align with cornell\u2019s processes for resolution. therefore, we should educate faculty about the appropriate way to resolve something like this, which cornell resources are available to them, and what offices \u2013 such as osp or counsel\u2019s office \u2013 are available to help. **_what tools or approaches might cornell researchers find useful for shared awareness of responsible_** **_genai use?_** the use of generative AI comes with significant privacy and security concerns, and it may be important for the university to gain an understanding of the privacy policies of generative AI companies in order to determine whether they are safe to use. also of concern are plug \u2011 ins to generative AI programs, which may come with their own privacy and security issues. although cornell should provide guidance on risks and tools to avoid, it would also be very useful to provide researchers with information about what tools and resources they can or should use, as well as access to those tools, and confirmation that they\u2019ve been vetted and found to be secure. the university could also provide information about the use of generative AI through other means: - creation of a tool \u2013 \u201casking for a friend\u201d \u2013 which could be used to answer questions researchers may have (ex.: \u201ccan i use generative AI to edit my scope of work?\u201d). - training should not only focus on risks and concerns, we should also provide training on how to get the most out of these types of tools, and how to use them better. \u201chackathons as training\u201d \u2013 could make it fun for researchers to gain new skills, while also contributing to the safe and responsible use of generative AI. - the web page is a centralized location that can be used to post preliminary guidelines, general information about generative AI, and what researchers need to know about it. in order to educate researchers on the use of generative AI, communication and outreach are key. we should educate researchers about the central offices that issue training, guidance, etc. that can help them, rather than leaving them to rely on potentially siloed offices in the units that may not provide consistent advice. if the university as a whole is looking to the same resources, and inquiries consistently come to the same/appropriate offices, approaches/advice/guidance given is more likely to be consistent university-wide. finally, much like training on the use of other things in research (animals, human participants, biological agents, etc.), education and training should be provided on how to use generative AI safely. ", "### charge on generative AI in academic research: perspectives and cultural norms ", "#### overview cornell\u2019s leadership recognizes the opportunity and challenge of generative AI (generative AI) on academic research, as well as the communication and translation of research outcomes to research peers and broader society. the vice president for research & innovation charges this task force to discuss and offer guidelines and practices for generative AI in the practice and dissemination of research. the outcome of this ad hoc task force provides clarity in establishing perspectives and cultural norms for cornell researchers and research team leaders, as internal advice, and is not meant to be a set of binding rules. ", "#### charge to task force generative AI is a tool that is now widely available to the research community. such capabilities can provide new efficiencies and insights in research, and can also introduce new quandaries for the responsible conduct of research. faculty and senior research scientists (also called principal investigators of externally funded research) are leaders of research projects, and are thus ultimately responsible for setting and adhering to such norms \u2013 particularly when formal guidelines are nascent or disparate. cornell now has the opportunity to discuss and establish these cultural and professional norms, consistent with our wider institutional values in responsible research across many fields. this group of staff and faculty is charged to consider any guidelines and best practices on appropriate use and attribution of generative AI that should be shared with the cornell research community of students, staff and faculty. this task force should identify the range of cultural norms consistent with cornell values when using this class of tools for research. these recommendations should be communicated in a brief (< pages written), internal advisory report by . the task force should not include extensions to cornell education or admissions or hiring practices or institutional communications; those use cases are under consideration elsewhere. ", "#### task force roster (listed alphabetically by family name) - **natalie bazarova** department of communication, college of agriculture and life sciences - **mich\u00e8le belot** department of economics, school of industrial and labor relations **olivier elemento** department of physiology and biophysics, weill cornell medicine **thorsten joachims** departments of computer science and information science, cornell bowers cis **** cornell center for technology licensing, ovpri **** information science, cornell bowers cis **bridget macrae** office of research integrity assurance, ovpri **alexander (sasha) m. rush** cornell tech and department of computer science, cornell bowers cis **** cornell center for technology licensing, ovpri and weill cornell medicine **stephen shu** dyson school, sc of business **simeon warner** cornell university library **fengqi you** smith school of chemical and biomolecular engineering, college of engineering ", "# generative AI guidance for staff in teaching and learning who is this guide for? any member of staff involved in teaching and learning as it relates to undergraduate, postgraduate and apprenticeship programmes. uea has a generative AI policy which should be read in conjunction with this guidance document. partner institutions can use and adapt this guide as required. ", "## opportunities - developing awareness of and skills around academic integrity. - articulating the attributes of our students which are independent of ai, e.g. critical thinking, self-reflection, tolerance, thought and action. - diversifying assessment to focus on core competencies (however, need to ensure that students have an understanding of the potential uses of ai in their specific disciplines). - providing students with advice and tools that can support/accelerate their learning and achievement of (existing and future) learning outcomes. - providing new opportunities for judgement-free tailored instruction for students from disadvantaged backgrounds or with lower starting skill levels to level up their learning. - speeding up analysis of data. automating repetitive processes. researching into the use of ai. ", "## challenges - understanding the different types of ai which currently exist and monitoring new and evolving developments. - student use of ai inappropriately to generate complete responses to assessment items. this would make it seem that students have achieved more learning that is actually the case. - ensure that assessment is meeting the right learning outcomes to provide our students with skills which are independent of ai, or where ai is not intended to replace. - where developing ai skills are themselves a learning outcome ensure that it is appropriate. - the use of ai may become paid for (advanced features already are) - therefore if the use of ai is a learning outcome there may be financial liability for students and/or the institution. - current language models (that are free of charge) are not % accurate in the content generated or the references provided, and their accuracy may depend on subject. this will improve in time and with premium (paid for) versions. - potential adverse effects from teaching students how to use ai in terms of overreliance on generative AI for assessments. - unequal opportunities for students with disabilities and splds if there is an overreliance on generative AI tools and no support on specialist software such as voice recognition etc. ", "# the technology available machine learning has been in existence for , and it is common in software such as spelling and . however, the rapid and ongoing development of generative AI tools which are able to replicate natural language and generate content has had a disrupting effect in the education sector. generative AI is a sub-group of ai which creates new content, including images and diagrams rather than analysing existing data. examples include generative pre-trained transformers (). it should be noted that s are not strictly ai but represent travel towards it. they work on text based prediction algorithms and are trained on databases and then with human interaction. s still fall under the policy. the output from generative AI can contain errors, bias, misinformation, missing information, and hallucinations (false information). everyone who uses generative AI should always check the content against their own knowledge and understanding. this is an essential part of the development of critical thinking skills. one way to get better information out of the ai tool is to understand more about hallucinations, why they occur and how to mitigate. in this short clip an representative covers hallucinations. generative AI technology continues to develop rapidly. tools such as chat, , wordtune and quilbot are becoming widely known. not all services are free, and some products have premium paid for functionality (freemium). will be launching copilot into its core software (word, powerpoint etc). states that copilot \u201c _combines the power of large language models (llms) with your data in_ _the graph and the apps to turn your words into the most powerful_ _productivity tool on the planet_ .\u201d there is a useful ai tools directory where you can find details of the available tools and a description of how they can be used and whether they are free or freemium. ", "# exploring chatgpt as an example tool chatgpt is probably the tool which has received the most attention since . chatgpt only has access to data up to and does not \u2018scour\u2019 the internet. it cannot access anything which is behind a paywall. experiences of those who have used it to generate answers to essays have shown that it can produce reasonable answers to level and higher education written assessments. however, there are limitations: . the narrative while clear, is often unsophisticated . the question is referred to often within the response . the main ideas lack nuance . the insights are superficial . references are dated, or they are hallucinations (false information) . key references are often missing ", "# detection of ai generated content you can sometimes detect chatgpt generated text by experience of looking at the outputs. there is often a superficial narrative, the essay question is often referred to throughout. often points are made several times but re-worded. references are often false, or key sources for your subject area are often missing. there are detection tools available. you can use zerogpt , there are also tools available from turnitin, but blackboard has recently stopped developing detection tools as they are unreliable. detection tools should be used with caution due to reported inaccuracy and, as with other screening tools, merely one factor in potentially identifying submissions which warrant further investigation. the tool will not be able to differentiate legitimate use of generative AI. by far the best way to limit the inappropriate use of generative AI in your students is training. the library and learning enhancement team have produced a training guide for students , but there are activities you can do to support this. - show chatgpt to students and run question and example assessment though it. - ask the students to criticise the outputs and uncover the flaws - make sure that students know that if they use it within their work, that they must reference the contribution made. - make sure that students know that they cannot copy and paste ai generated content (when it is not part of the assessment design itself). - remind students of the plagiarism and collusion policy which states \u201c _while you are_ _permitted to use artificial intelligence software to help you understand material and_ _how that can be expressed, you are not allowed to use that software to complete the_ _assessment (or any part of it) for you. if you use artificial intelligence software to_ _complete the work for you, that will be plagiarism. in some cases, it will reach the_ _level of contract cheating policy point pg _ \u201d ", "# referencing ai contribution a general overview use declaration (in the submission declaration) in which you explain in general how technology assistance was used e.g. \u201ci have used word processing and spell check as well as the reference sources cited in the reference list and \u2026) specifically, when you would cite a human (for the idea, exact or general wording) then cite the technology: author of ai model used. (year of ai model used). name of ai model used (version of ai model used) [type or description of ai model used]. web address of ai model used \u00a7 e.g., openai. (). (dec version) [large language model]. / and a screenshot of the full thread of the cited ai interactions pasted to an appendix. students might also go to cite them right , which uea has a license for to get further guidance. ", "# staff practice and usage there are a number of \u2018green light\u2019 approaches which can be used by staff. these have been grouped as teaching design, content creation and assessment. ", "# generative AI for teaching design ideas for teaching design often come through speaking with colleagues and investigating the pedagogical literature. generative AI can be used to generate lesson plans, surface new ideas and approaches. an example creation is in box taken from biology. **box ** i asked chatgpt the following question \u201ccreate a discussion scenario for a seminar for higher education students in the area of single cell protein\u201d. **discussion points:** **. understanding single-cell protein:** - what exactly is single-cell protein (scp), and how is it produced? - how does scp compare nutritionally to traditional protein sources like meat, soy, and legumes? - what are the potential environmental benefits of scp production, such as reduced land and water usage? **. technological advancements in scp production:** - how has biotechnology and fermentation played a role in advancing scp production? - are there specific microorganisms that are more efficient at producing high-quality scp? - what are the challenges associated with scaling up scp production to meet global demand? **. food security and scp:** - how can scp contribute to addressing food shortages in regions with limited resources? - are there cultural or social barriers to adopting scp as a protein source in different parts of the world? - what role can scp play in sustainable diets and reducing malnutrition? **. economic and societal impacts:** - what is the economic feasibility of incorporating scp into the food supply chain? - how might the growth of the scp industry impact traditional livestock and agriculture sectors? - are there potential job opportunities and challenges related to scp production and distribution? **. consumer acceptance and perception:** - how can consumers be educated and encouraged to embrace scp as a viable protein source? - what are the psychological factors influencing consumer perceptions of scp? - are there lessons to be learned from the introduction of other alternative protein sources, like plant-based meats? **. regulatory and ethical considerations:** - what regulatory hurdles or standards need to be established for scp production and marketing? - are there ethical concerns regarding the use of microorganisms for mass protein production? - how might scp intersect with debates about genetically modified organisms (gmos) and bioengineering? **. future outlook for single-cell protein:** - what are the potential breakthroughs and innovations that could shape the future of scp? - how can interdisciplinary collaboration drive research and development in this field? - can scp play a pivotal role in achieving sustainable development goals related to food security and sustainability? **my evaluation:** the response was well considered, but it was more a discussion plan, than a scenario. there were interesting questions which i could use to frame a minute discussion, using pair and share techniques or stakeholder role play. ", "# generative AI for content creation generative AI can support you in creating content for teaching. this could involve generating case examples to illustrate concepts or problem-based scenarios which can be discussed in teaching sessions. you could also use it to generate templates, for example letters. diagrams and images can also be created, but the ai tools here are often paid for, and run the risk of copyright issues. there are also tools which will generate online content, but they are not free, and unsupported by uea. ", "# assessment creation generative AI can be used to create assessment questions, e.g. multiple choice questions, but these must be evaluated. an example is shown in box . box i asked the question \u201cwrite a multiple choice question with responses to test knowledge on lichen symbiosis and indicate the correct response\u201d question: lichens are formed through a symbiotic association between fungi and which other type of organism? a) algae b) bacteria c) protozoa d) ferns e) mosses correct response: a) algae **my evaluation** : in this case the multiple choice question was wrong, as lichens can f i ti ith b th l d b t i b t th i id f th l tt it another example: i asked chatgpt to: \u2019write a multiple choice question with responses to test knowledge on role played by the principle of separation of powers in the british constitution and indicate the correct response\u2019 question: what role does the principle of separation of powers play in the british constitution? a) it ensures that the prime minister has absolute authority over the judiciary. b) it prevents the monarch from having any influence over the legislative process. c) it helps maintain a balance of power between the executive, legislative, and judicial branches. d) it grants the power to overrule decisions of . correct response: c) it helps maintain a balance of power between the executive, legislative, and judicial branches. **my evaluation:** this was a fairly straightforward question and the incorrect answers were well chosen. whilst \u2018c\u2019 was the closest to a correct answer it is not wholly accurate as it fails to acknowledge the more nuanced balance of powers or partial separation which exists in the british constitution. so whilst acceptable could also be used as a teaching tool to prompt a more in depth evaluation by the students. i then asked chatgpt the question \u2018to what extent is there separation of powers in the british constitution?\u2019 _the concept of separation of powers, as traditionally seen in other constitutional systems like_ _that of the united states, is not as rigidly defined in the british constitution. the british_ _constitution is characterized by a fusion of powers, where the executive (prime minister and_ _cabinet), legislative (parliament), and judicial (courts) branches are interconnected to some_ _. here's an overview of the extent of separation of powers in the british constitution:_ - **_executive and legislative branches:_** _unlike some systems, the prime minister and_ _cabinet are drawn from the majority party in , which blurs the_ _separation between the executive and legislative branches. this enables the_ _executive to have significant influence and control over the legislative process._ - **_parliamentary sovereignty:_** _the british parliament is and can make or_ _change laws without significant limitations from other branches. while this provides_ _some of separation, it also means that the executive (government) is_ _accountable to the legislature, blurring the lines further._ - **_judiciary and legislature:_** _the british judiciary is independent and can review laws_ _and government actions for their legality and constitutionality. however, the_ _judiciary's role in reviewing legislation passed by parliament is limited compared to_ _systems with a more robust separation of powers._ - **_cabinet members in parliament:_** _members of the cabinet are drawn from the_ _parliament, and this dual role further integrates the executive and legislative_ _branches._ - **_constitutional conventions and royal prerogatives:_** _the crown still possesses_ _certain prerogative powers that are exercised by the executive, which can influence_ _the legislative process. however, many of these powers are now exercised by_ _ministers in the government._ _in summary, while the british constitution lacks the strict separation of powers seen in some_ _other systems, there are mechanisms in place to maintain a balance between the branches._ _the british tradition relies heavily on conventions, practices, and historical arrangements_ _that have evolved over centuries. this fusion of powers is based on a delicate balance that_ _seeks to prevent any one branch from becoming too dominant and to ensure accountability._ my evaluation: this answer was accurate, in so far as it relatively superficially correctly identified key elements of the principle as it operates in the uk. it did not, however, provide any authority or specific examples to support so whilst correct would be insufficiently detailed and too descriptive to obtain a good mark. again, this could work as a discussion exercise or a formative assessment task requiring students to improve upon the starting point provided below. ", "# marking using generative AI staff can use ai to do some aspects of marking for example: - grouping and marking responses to short answer questions or multiple choice where ai functionality is part of a software package used to deliver an assessment and where there remains human oversight. however: - generative AI cannot be used to obtain personalised student feedback on formative and summative assessment. students can be encouraged to seek ongoing feedback on tasks and assignments, but the justification of a mark should be a human judgement. ", "# assessment design there is no going back from this point. ai tools are only going to get better and we cannot outrun the pace of change. we need to re-think assessment design. in the first instance staff should consider using blooms taxonomy within assessment design and use assessment to evidence higher order thinking skills around creation and evaluation where it is harder for ai to respond appropriately at this time. there are two strategies for re-thinking assessment design: . designing out . designing in ", "# designing out ", "## alternative formats for assessment summative assessment which solely focuses on writing down information is the most easily replicated by ai. students could be asked to write podcasts or have assignments which require video or recorded speech. these approaches could be combined together in a multimedia project or portfolio. ", "## oral/in person assessments assessments which have an oral component, for example presentations, vivas, poster sessions and in class competency testing are not as easily replicated by ai. however it should be noted that there are some generative AI tools which do produces images, diagrams and posters. students could be asked to upload video of them talking through a poster or an infographic. viva-voce assessments can be scalable with -- minute slots, feedback can be instant. a detailed marking rubric can be shared with students in advance. the sessions can be recorded and moderated. if you use this approach then you should consider ways to scaffold the approach and train students progressively in this skill. you will also need to be aware of students with reasonable adjustments where a viva could not be an appropriate method of assessment. ", "## object and data reflections students can be asked to critically analyse and reflect on pieces of data, they could interpret physical objects or artefacts. this could be in person, or it could be recorded. ", "## experiential learning students can be asked to work on case studies or problem based learning activities which require the generation of new knowledge, creative design or the development of products or resources. ", "## proctored assessments these are the use of invigilated exams or a test in class. however we would discourage the use of these unless there are strong pedagogical reasons and are delivered as part of a suite of assessments to diversify experience. ", "# designing in this is where we embrace generative AI within assessment tasks. we must prepare our students for when they encounter ai in the workplace. think of a task where students are tasked to use generative AI to obtain a piece of writing on a specific topic then: - get the students to critique the output in terms of structure - ask the students to identify the flaws in the content for examples, hallucinations (false information) and bias - ask the students to assess the content in the light of their own knowledge and understanding - ask the students to follow up the references, see if they are genuine and if they reflect the key sources. you can also obtain answers to example test in class or exam questions to be shared with students to evaluate the strengths and weakness of generative AI content. if you would like more support in assessment design visit the cherpps pebblepad training page . ", "## generative AI as mentor encourage students to get ongoing feedback on assignments and tasks and get them to reflect on the feedback against their own knowledge and understanding and report on the guidance which has been provided and how they may or may not include it in their work. ", "# where generative AI should not be used there are a number of \u2018red light\u2019 activities where staff should not use generative AI - generation of letters to students or other staff including personal data and information. this is because the software will store data and information and potentially use it for other content. - generation of personalised student feedback on formative and summative assessment. students can be encouraged to seek ongoing feedback on tasks and assignments, but the justification of a mark should be a human judgement. ", "# generative AI in research projects our students on taught programmes will be conducting research, especially in of study. . students should not input research data into an ai tool unless it is an agreed part of the research project. . students are required to obtain ethics approval before entering personal data into an ai tool . students will need instruction on the difference between feeding a transcript/observation notes/participant diary into e.g. nvivo, and feeding it into ai which could use it to generate further material. ", "# developing graduate attributes as relates to ai when designing content and assessment we must consider learning outcomes and graduate attributes as they related specifically to the use of ai. critical thinking-thought and action students should be able to take a piece of generative AI text, diagram, image or code and check this against their own knowledge and understanding of a topic or area. they need to critically assess the origins and the authenticity of the content. self reflection support students to explore ways of using generative AI to identify ways that they could improve areas of feedback on previous assignments. students can also use generative AI to provide feedback on their work and identify areas for improvement at the editing stage. digital literacy the use of ai in the workplace is going to expand and we should develop confidence in our students to be able to use ai tools, how to generate input questions to get the best outputs and evaluate what they do well, and where there are limitations. integrity we should discuss with our students the \u2018authorised green light\u2019 activity when it comes to use of ai in assessment. students should be encouraged to look at assessment briefs for specific assignments and engage with discipline specific uses. ethical awareness students should be aware of issues such as job displacement, exploitation, authorship, bias and misinformation. research skills help students develop skills in identifying research questions, and assessing the outputs problem solving. students can generate outlines that are then used as the basis for deeper research and investigation. encourage synthesis of sources by getting students to integrate other sources to support or refute generated output. organisation generative AI can be used to create study and work schedules allowing students to create personalised study plans or group work schedules. ", "# acknowledgements we acknowledge the kind contribution which have made in allowing us to replicate some of the content from their staff guide. ", "# further resources there are plenty of ideas in the community on how to effectively use ai for teaching and learning,  creative ideas to use ai in education-a crowdsourced collection is one example. should ai be used to assess research? chatgpt listed as author on research papers introduction to chatgpt and chatbots ai tools directory trusted research  ? ", "# generative artifici intelligence guidelines |related policy:|academic integrity policy| |---|---| **preamble** **.** **purpose** to support the ethic and responsible use of generative artifici intelligence for the purpose of teaching and learning at holmesglen. generative artifici intelligence (gai) is a typed or artifici intelligence (ai) technology that can produce various types of new content/outputs, including text, imagery, audio, synthetic data and more, based on the data on which they have been trained. in the education setting, gai has the potenti to dramaticly change and shape the future of learning, content development and research practices. considerations such as ethic use, transparency, fairness, and accountability must be addressed to ensure gai is used responsibly. **.** **guidelines for teaching employees** .. educate learners as to the impacts of generative AI use, including relevance to the academic integrity policy. .. educate learners as to potenti impacts on the quity of their output resulting from use of generative AI, including systemic prejudices and biases in training data. .. ensure that the use of ai tools is consistent with the requirements of relevant accrediting bodies (if any) and is consistent with relevant industry expectations. .. understand that detection of use of generative AI is difficult and that existing academic integrity detection tools may not be reliable. .. consider forms of assessment in the context of the availability of generative AI and the implications arising in relation to learning outcomes and authenticity of assessments. consider ternate assessment methods, such as: \u25aa in person observation assessment \u25aa simulation / role play \u25aa or assessment / viva voce \u25aa invigilated assessment including lockdown browser software \u25aa interactive activities \u25aa the inclusion of specific loc context in assessments. .. determine, in relation to each subject, which of the following four options, or combination thereof, is best suited for assessment in that subject, based on the nature of the task and the extent to which it produces evidence of required learning: \u25aa prohibit l use of generative AI for an assessment task \u25aa restrict the types of generative AI tools which can be used for an assessment task \u25aa restrict how generative AI tools can be used for an assessment task \u25aa do not restrict use of generative AI for an assessment task. .. state clearly and consistently, on the holmesglen learning management system and assessment instructions, where appropriate, the conditions applicable to each piece of assessment for use of generative AI, by reference to one of the above stated four categories. the wording used should be consistent with the recommended wording set out in appendix a to this guideline. owner: _manager curriculum management and support_ revision: v .. attach a link to each piece of assessment to any applicable holmesglen guides as to use of generative AI, including any guides as to how use of generative AI should be acknowledged for referencing purposes. .. ensure that the declaration made by the learner for academic integrity purposes on each piece of assessment includes a declaration as to the following, in accordance with the wording set out in appendix b: \u25aa a written acknowledgment as to the use of generative AI \u25aa details as to which ai technology was used \u25aa details as to how that information was generated \u25aa identification of the prompts used \u25aa an explanation as to how the output was used in the assessment task .. ensure that, in addition to the above, learners reference materi generated by ai is cited in the assessment item, in accordance with the citation methods required by holmesglen. .. ensure that, for assessment purposes: \u25aa fin results are determined by a human \u25aa where ai has been employed in communication with learners and/or in the preparation of teaching materi and assessments, teaching employees must verify the currency and accuracy of that documentation. .. consideration should be given to where generative artifici intelligence might be used in the preparatory steps taken prior to the actu writing of the assessment item. for example, is it permissible for learners to use it as a writing prompter? if so, this should be clearly stated on the guidelines for preparation of the assessment item, with an accompanying statement that the learners are required to build their own argument and employ their own skills of critic thinking. .. consideration should be given on a department level, to permitting learners to use generative AI in their study. for example, generative AI can be used to proofread fin drafts, check for spelling and grammatic errors, sentence structure etc. it should so be considered as a tool to explain study materi. .. report l unsanctioned or inappropriate use of generative in assessment in accordance with the academic integrity policy and academic misconduct procedure (learners) . **.** **guidelines for learners** .. only use generative AI as permitted. .. check with teachers or subject coordinators as to permissible use of generative AI. .. where generative AI is used: \u25aa provide a statement in accordance with appendix b \u25aa retain proof of their interactions with generative AI, in the event of a consequent misconduct case. .. where generative AI is used, learners must cite the source in the body of the text and reference list. .. use of generative AI except as permitted in writing and, where use is permitted in full or in part, failure to clearly state the information required in appendix b amounts to academic misconduct. it will be det with in accordance with the academic misconduct procedure (learners) . owner: _manager curriculum management and support_ revision: v **.** **definitions** |term|meaning| |---|---| |ai|artifici intelligence where machines are capable of performing tasks which have previously required human intelligence.| |generative artifici intelligence|a type of artifici intelligence technology that can produce various types of new content/outputs, including text, imagery, audio, synthetic data and more, based on the data on which they have been trained.| **.** **context and/or referenced documents** **intern** code of conduct academic integrity policy academic misconduct procedure (learners) **extern** higher education standards framework (threshold standards)  standards for registered training organisations () higher education support act  education services for overseas students act (cth). **.** **version history** |version number|date|summary of changes| |---|---|---| ||july |new guidelines.| owner: _manager curriculum management and support_ revision: v **appendix a** where l use of generative AI for an assessment task is prohibited: _in this assessment, you must not use generative artifici intelligence in any way whatsoever._ where use of certain types of generative AI tools are restricted: _in this assessment, you are permitted to only use the following generative artifici intelligence (ai) (insert_ _names or types of tools). written detail must be provided as to which tools were used, how output was_ _generated and identification made as to the prompts used. ideas and/or text obtained through this process_ _must be cited._ where certain uses for generative AI tools are restricted: _in this assessment, you are permitted to use generative artifici intelligence (ai) for the following purposes_ _(state purposes). written detail must be provided as to which tools were used, how output was generated and_ _identification made as to the prompts used. ideas and/or text obtained through this process must be cited._ where use of generative AI tools are not restricted: _in this assessment, you are permitted to use generative artifici intelligence (ai). written detail must be_ _provided as to which tools were used, how output was generated and identification made as to the prompts_ _used. ideas and/or text obtained through this process must be cited._ **appendix b** i acknowledge use of (insert details of ai system used, with link to that system) to (list specific use of that ai). i used the following prompts (list prompts used). the output from these prompts was used to (set out uses). owner: _manager curriculum management and support_ revision: v ", "### policy brief: ", "# generative AI **** this report is authored by: **** minderoo centre for technology and democracy **** bennett institute for public policy **about ai@cam** aspires to be a global leader in ai research, an innovator in ai education, and a hub that connects research with business, civil society, and policy, supporting the deployment of ai technologies for wider social and economic benefit. its vision is of ai-enabled innovations that benefit society, created through interdisciplinary research that is deeply connected to real-world needs. ai@cam is flagship mission to deliver this vision, driving a new wave of ai innovation that serves science, citizens, and society. more information: **ai.cam.ac.uk** **about the bennett institute for public policy** the bennett institute for public policy is one of the uk\u2019s leading public policy institutes, achieving significant impact through its high-quality research. our goal is to rethink public policy in an era of turbulence and inequality. our research connects the world-leading work in technology and science at with the economic and political dimensions of policymaking. we are committed to outstanding teaching, policy engagement, and to devising sustainable and long-lasting solutions. more information: **** **about the minderoo centre for technology and democracy** the minderoo centre for technology and democracy is an independent team of academic researchers at , who are radically rethinking the power relationships between digital technologies, society and our planet. more information: **** doi: **doi.org/./cam.** ", "## contents ", "#### foreword executive summary . introduction . generative AI . what is generative AI capable of and how does it work? . generative AI\u2019s limitations . foundation models vs applications . the economics of generative AI . productivity and generative AI . foundation model leadership . real-world applications of foundation models . impediments to developing the uk\u2019s national capabilities in generative AI . risks with generative AI . ethical and responsible generative AI . personal data and privacy concerns . data governance . regulatory capacity . international leadership . recommendations to build capability in generative AI about the authors appendix selected bibliography ", "## foreword **which path should the uk take to build national capability for generative AI?** the rapid rollout of generative AI models, and public attention to open ai\u2019s chatgpt, has raised concerns about ai\u2019s impact on the economy and society. in the uk, policy makers are looking to large language models and other so-called foundation models as ways to potentially improve economic productivity. this policy brief from and outlines which policy levers could support those goals. they argue that the uk should pursue becoming a global leader in applying generative AI to the economy. rather than use public support for building new foundation models, the uk could support the growing ecosystem of startups that develop new applications for these models, creating new products and services. a uk approach to generative AI could leverage the existing national strengths in safe, responsible and ethical ai to put human safety and flourishing at the forefront of innovation. a national approach could achieve these goals by increasing understanding of and access to generative AI tools throughout the economy and society. this policy brief answers three key questions: . what **policy infrastructure and social** **capacity** does the uk need to lead and manage deployment of responsible generative AI (over the long term)? . what **national capability** does the uk need for large-scale ai systems in the short- and medium-term? thanks to and \u2019s extensive research, this policy brief maps out an ethical framework for the governance of generative AI, through the creation of an ai bill. we hope that this policy brief will be useful to a wide range of stakeholders and address how we can use regulatory and legislative power , to ensure that the british public can trust how this technology is used. we are also excited that this policy brief brings together expertise from three groups at the bennett institute for public policy, minderoo centre for technology and democracy and ai@cam. evidenced-based, science-informed research like this brief is what our three organisations do best, and we hope that our insights can help decision-makers navigate public debates and policy choices with more clarity. **professor dame diane coyle** bennett professor of public policy, bennett institute for public policy, **professor gina neff** executive director, minderoo centre for technology and democracy, **professor ** deepmind professor of machine learning, . what **governance capacity** does the uk need to deal with fast moving technologies, in which large uncertainties are a feature, not a bug? ----- ", "## . generative AI **. what is generative AI capable of and how does it work?** generative AI involves running the kind of pattern-matching that machine learning systems do, only **in reverse** . rather than looking at data and finding existing examples that fit a particular pattern, it draws on data to \u2018generate\u2019 new examples of that pattern. generative AI systems can therefore output original high-quality text, images, audio, or video at mindboggling speed and scale. much of the excitement about generative AI has been driven by the runaway popularity of chat, a consumer facing app developed by openai, which reached million users **even faster than the** **app tiktok** . chat is underpinned by a type of generative AI system called a _large_ _language model_ (llm). llms take instructions (or _prompts_ ) from users in natural language, and then output text in response\u2014from stump speeches to shakespearean sonnets and everything in between. they work by predicting what word (or, strictly, _token_ ) ought to come next in a sequence, based on inferences from the vast corpus of data on which they have been _trained_ , together with the user\u2019s instructions. while openai\u2019s is the best-known llm, there are many other examples (see **figure ** ). although image-generation models like midjourney use a different process called _diffusion_ , from the perspective of the user they work in the same way as llms. natural language text prompts can yield **-inspired cover art for** **\u2018stairway to heaven\u2019, in a** **balenciaga puffer jacket** , or more or less anything else than can be imagined and articulated. **glossary** **_diffusion model_** \u2013 an image-generation model developed by corrupting a dataset of images with \u2018noise\u2019, then learning how to \u2018de-noise\u2019 the data and recover the images **_training_** \u2013 the process of teaching an ai system to interpret data **_prompt engineering_** \u2013 the practice of designing prompts with the objective of improving the quality of a generative AI model\u2019s output **_fine-tuning_** \u2013 a training technique used to customise a foundation model for a specific purpose **_plugin_** \u2013 a software add-on that enhances a system\u2019s capabilities. a number of **chat** **plugins** are available. **_foundation model_** \u2013 the generic name for llms, diffusion models and other general-purpose generative AI models which developers can use as the basis for more specialised **_api_** \u2013 short for application programming interface; a way of allowing different software applications to interact with each other **_saas_** \u2013 short for software-as-a-service; software which is accessed over the web, rather than being installed locally **_compute_** \u2013 shorthand for the computational resources generative AI systems use to process data . , benedict. . \u201cchat and the imagenet moment,\u201d benedict < / benedict////chat-imagenet > [accessed september ] . tung, liam. . \u201cchat just became the fastest-growing \u2018app\u2019 of all time,\u201d < / chat-just-became-the-fastest-growing-app-of-all-time/ > [accessed september ] . [n.d.]. prompthero.com <  > [accessed september ]; \u201creddit - dive into anything.\u201d [n.d.]. reddit.com < / /the_pope_drip/ > [accessed september ] **. generative AI\u2019s limitations** at first sight these capabilities can seem miraculous, but it is important to be aware of their limitations. diffusion models are not underpinned by an understanding of the physical world; **they don\u2019t \u2018know\u2019** what text symbols mean, or that human hands usually have five fingers. the results can be comical, nightmarish, or simply wrong. similarly, llms do not function like search engines, reliably retrieving information from a database. rather, llms generate new text probabilistically, meaning that they often invent facts and refer to seemingly plausible but non-existent academic studies and urls (a phenomenon known as \u2018hallucination\u2019). overcoming these limitations requires a combination of _fine-tuning_ , _prompt_ _engineering_ , and _plugins_ . **. foundation models vs applications** both llms and diffusion models are types of _foundation model_ \u2014a term describing models that others could \u2018build on top of\u2019 for many different purposes. this is enabled by giving third-party developers __ , allowing them to incorporate foundation model capabilities into their applications. new startups have been able to develop software-as-a-service ( _saas_ ) products that apply foundation models in specific contexts. for example, **harvey ai** uses openai\u2019s models in products designed to assist lawyers with research, contract drafting, and document review. established tech companies have enhanced their products with generative AI features. for example, the graphic design platform canva introduced a **text to image feature** powered by the dall-e model, and added llm-powered writing and editing features to its **office products** . **. the economics of generative AI** providers of foundation models earn revenue by charging a small fee for each api request. as a result, their business model depends on the volume of api requests from applications being sufficient to offset the massive _compute_ costs involved in developing and operating foundation models. these costs are partly a function of the vast size of training datasets. for example, the text used to train openai\u2019s - model included a ** terabyte** **archive of the web** , , books, and the entirety of wikipedia. processing such large quantities of data requires graphics processing units (gpus). a single gpu designed by market-leader nvidia costs $,; and thousands of gpus are needed to train a single foundation model. further compute costs accrue once models are released and begin processing prompts from users. . mirjalili, seyedali. . \u201cif ai image generators are so smart, why do they struggle to write and count?,\u201d the conversation < - > [accessed september ] . \u201charvey.\u201d [n.d.]. harvey.ai < / > [accessed september ] . [n.d.-b]. canva.com <  > [accessed september ]; stallbaumer, colette. . \u201cintroducing copilot\u2014a whole new way to work,\u201d blog < / en-us/-/blog////introducing---copilot-a-whole-new-way-to-work/ > [accessed september ] . , , , , , , and others. [n.d.]. \u201clanguage models are few-shot learners,\u201d arxiv.org < /. > [accessed september ] **analysts estimate** that chat costs $ million per month to run, and that would need $ billion of compute if its -powered bing chat product responded to all queries from bing\u2019s users. a final nuance to note is that it is not necessary for foundation model developers to own gpus themselves\u2014 they can rent gpu time from cloud providers as a service.currently, most real-world end users of generative AI systems are paying nothing for the privilege, meaning foundation model providers\u2019 revenues are negligible \u2013 openai projects just $ million for . both development and usage of generative AI is therefore currently being funded by venture capital and the balance sheets of big tech companies \u2013 a situation which will clearly not last forever. **glossary** **_gpus_** \u2013 powerful chips originally developed to render d images in video games, now used for training foundation models **__** \u2013 a group of computers containing gpus it seems likely that a small number of dominant foundation model providers will emerge and then increase prices to a level that produces attractive shareholder returns. in the interim, the biggest beneficiaries are likely to be compute providers \u2013 nvidia\u2019s share price, for example, is +% . economics are more benign for application developers, as their foundation model api costs rise and fall in proportion to usage of their products, and they can switch between different model providers easily. **examples** **value drivers** **cost drivers costs** business, public sector and individuals using generative AI-powered tools to fully or partly automate tasks and workflows **_consumer _** - e.g. chat **_saas tools_** - e.g. harvey **_product integrations_** - e.g. copilot **_large language models_** (llms) - e.g. **_diffusion models_** - e.g. midjourney subscription fees paid to \u00a3 app & saas providers **real-** **world** **uses** **application** **layer** **foundation model** **layer** productivity gains subscription fees from users; ad revenue transaction fees from app developers transaction fees paid to model providers \u00a3\u00a3 compute \u00a3\u00a3\u00a3\u00a3\u00a3 costs; r&d \"compute\" energy, **infrastructure** hardware sales; **_cloud platforms_** - e.g. azure ai materials; \u00a3\u00a3\u00a3\u00a3\u00a3 **layer** service fees **_hardware_** - e.g. nvidia gpus r&d \"compute\" **_cloud platforms_** - e.g. azure ai **_hardware_** - e.g. nvidia gpus hardware sales; service fees _figure : a simple schematic of the generative AI \u2018stack\u2019_ . leswing, kif. . \u201cmeet the $, nvidia chip powering the race for a.i,\u201d < //// nvidias-a-is-the--chip-powering-the-race-for-ai-.html > [accessed september ] . all market cap figures are correct as of august . |company|maturity|generative AI activities|financial position| |---|---|---|---| |us|||| |openai|late-stage growth|develops foundation models for text, image, and audio-generation (e.g. , dall-e , whisper); develops consumer (e.g. chat)|valued at ~$bn in april ; has raised $.bn in total| |meta|public|develops open-source llms (e.g. llama)|$bn market cap| ||public|provides compute as a service via the azure ai platform; develops consumer applications (e.g. bing chat) and integrations (e.g. copilot); major investor in openai|$.tn market cap| |nvidia|public|designs chips used in the training of foundation models; investor in infel ction ai and synthesia|$.tn market cap| ||public|develops llms (e.g. palm), consumer (e.g. bard); integrates generative AI into existing products (e.g. gmail); provides compute as a cloud service|$.tn market cap| |anthropic|growth-stage startup|develops llms (e.g. claude)|raised $m at ~$bn valuation in may | |infel ction ai|seed-stage startup|develops llms and consumer (e.g. pi)|raised $.bn at $bn valuation in june | ||growth-stage startup|develops saas tools for copywriting, based on openai llms|raised $m at $.bn valuation in october | _figure : selected generative AI companies, united states (us) and uk_ . singh, jagmeet, and ingrid lunden. . \u201copenai closes m share sale at b-b valuation,\u201d t echcrunch < / > [accessed september ]; \u201copenai.\u201d [n.d.]. crunchbase <  > [accessed september ] . wiggers, . . \u201canthropic raises $m to build next-generative AI assistants,\u201d t echcrunch < . com////anthropic-raises-m-to-build-next-gen-ai-assistants/ > [accessed september ] . \u201c-backed ai startup inflection raises $. billion from nvidia and others.\u201d . reuters < . com/technology/inflection-ai-raises--bln-funding--others---/ > [accessed september ] . rogenmoser, . [n.d.]. \u201c announces m series a funding round, bringing t otal valuation to .b and launches new browser extension,\u201d .ai <  > [accessed september ] |company|maturity|generative AI activities|financial position| |---|---|---|---| |uk|||| |deepmind|acquired|developing a robot command language (rt-) and llm (gemini)|acquired by for ~$m ()| |stability ai|seed-stage startup|develops image-generation models (stable difuf sion) and llms (stablelm)|raised $m at $bn valuation ()| |synthesia|growth-stage startup|develops saas tools enabling users to create corporate training videos with realistic digital avatars, based on proprietary models|raised $m at ~$bn valuation in june | |arm|public|designs chips used in the training of foundation models; developing a platform to power generative AI (tcs)|ipo-ed at ~$bn in september | |graphcore|growth-stage startup|designs chips used in the training of foundation models|has raised $m, but venture capital investor sequoia has written of f its stake| _figure : selected generative AI companies, united states (us) and uk (continued)_ . , . . \u201cdeepmind unveils rt-, a new ai that makes robots smarter,\u201d venturebeat < / > [accessed september ]; knight, will. . \u201c ceo says its next algorithm will eclipse chat,\u201d wired < / story/-deepmind-demis-hassabis-chat/ > [accessed september ] . shu, catherine. . \u201c acquires artificial intelligence startup deepmind for more than $m,\u201d t echcrunch < / > [accessed september ] . wiggers, . . \u201cstability ai, the startup behind stable diffusion, raises $m,\u201d t echcrunch < . com////stability-ai-the-startup-behind-stable-diffusion-raises-m/ > [accessed september ] . e, ryan. . \u201cnvidia-backed platform that turns t ext into a.i.-generated avatars boosts valuation to $ billion,\u201d <  > [accessed september ] . [n.d.]. \u201cnew arm total compute solutions enable a mobile future built on arm,\u201d arm | the architecture for the digital world <  > [accessed september ] . \u201cblow for tech unicorn graphcore as sequoia writes off stake.\u201d [n.d.]. times (london, england: ) (the times) <  > [accessed september ] ----- ", "## . productivity and generative AI **we take the view that generative AI is a very significant technology, of comparable** **importance to the web.** however, it cannot be taken for granted that the adoption of generative AI will inevitably lead to whole-economy productivity growth\u2014indeed, the digital innovations of have had no discernible impact on **measured** **uk productivity** . it must also be acknowledged that there is still a lot of uncertainty about how generative AI will become economically useful. search data suggests the predominant use-cases for chat are currently **job applications and** **homework** , which have little relevance to the economy. meanwhile, most **capital investments** **in generative AI companies** to date have been at the foundation model and infrastructure layers; at the application layer, the majority of venture-backed companies are developing chatbots, virtual customer services assistants, writing tools, and features for video games. while these may reduce operating costs in contact centres and increase copywriters\u2019 output and gamers\u2019 play-e, they are unlikely to have a transformative economic impact. if the uk is to benefit from generative AI, it needs to encourage direct application of the technologies to the productive economy, across multiple sectors. **stability** **.ai: the uk foundation model** **leader?** best known for the open-source image-generation model stable diffusion, stability ai was founded in by former hedge fund manager emad mostaque. in the company raised $ million in a seed round led by lightspeed venture partners and coatue. stable diffusion xl, released in , features the ability to generate words within images (see \u2018generative AI\u2019s limitations\u2019), and has been **favourably compared** by users to midjourney and openai\u2019s image models. a number of controversies surrounding stability ai should be noted. have brought a **lawsuit** from getty images, who claim that copyrighted material was included in stable diffusion\u2019s training data without permission, together with allegations from former partners and employees of **fraud** , financial irregularities and intellectual property **theft** . . [n.d.-c]. parliament.uk < / > [accessed ] . , . . \u201ci find that homework is actually the # application of chat (as measured by us search). there is a higher volume of searches relating to job applications (eg \u2018chat resume\u2019, \u2018chat cover letter\u2019), & a comparable volume for code (per )  ,\u201d twitter < / > [accessed ] . \u201cno title.\u201d [n.d.]. dealroom.co < / > [accessed ] **. foundation model leadership** unlike the us, the uk has no big tech companies with balance sheets large policy discussion has focused on how enough to invest meaningfully in the uk could become a **world leader in** foundation model developers, **the development of novel commercial** and the uk venture capital market is far **foundation models** . smaller ( **$bn** vs **$bn** in ). we doubt that this is realistic, despite the uk benefitting from a worldleading research base in underpinning technologies. training foundation models requires vast amounts of compute, and little compute capacity is available in the uk. the \u00a3m supercomputer announced by the chancellor in march will not be online until , and neither amazon web services, azure, nor cloud have **uk-located gpu clusters** . stability ai trains its foundation models on clusters in the us. however, the idea of sending sensitive data offshore is very unpalatable for all organisations concerned with privacy (including, say, the nhs), and such data transfers are not reconcilable with uk law. a related barrier is the limited availability of investment capital to fund compute. modest government **support for the** **uk chip industry** \u2014which has strategic importance well beyond generative AI\u2014 speaks to constraints on state spending relative to china and the us. traditional startup funding models where companies raise seed capital (~\u00a3m) to develop a minimum viable product, followed by larger and larger amounts of investment once they have gained traction with customers will not work at the scale needed for foundation model development. **other uk generative AI startups** **_criteria: raised >$ million; hq in the uk_** **_polyai_** \u2013 develops voice assistants for enterprise clients that can handle tasks like hotel room bookings, food orders and insurance claims **_papercup_** \u2013 develops software that dubs existing video content into different languages **_lifescore_** \u2013 platform generating endlessly varying music based on original compositions and recordings **_unlikelyai_** \u2013 in stealth mode; founder previously contributed to development of amazon\u2019s virtual assistant alexa **_instadeep_** \u2013 machine-learning platform provider, acquired by biontech for \u00a3 million in . does not describe itself as a generative AI company . department for science, and technology. a. \u201cinitial \u00a3 million for expert taskforce to help uk build and adopt next generation of safe ai,\u201d gov.uk <  > [accessed ] . the economist. . \u201chow to make britain\u2019s ai dreams reality,\u201d economist (london, england: ) (the economist) <  > [accessed ] . , , and . . \u201cuk government unveils long-awaited \u00a3bn semiconductor strategy,\u201d financial es <  > [accessed ] . [n.d.-d]. dealroom.co <  > [accessed ]; [n.d.-d]. dealroom.co <  > [accessed ] the upfront capital requirements to develop foundation models are of a different order of magnitude, making them unsuitable for uk-style startup investing. the foundation model layer is also not the most economically attractive part of the generative AI \u2018stack\u2019. most models have been trained on the e openlyavailable data, rather than proprietary sources, meaning there is limited scope for competitive differentiation and defensible market leadership. it is at least plausible that competition between the likes of openai, , anthropic, and inflection will drive down prices, leading to foundation models becoming increasingly commoditised. \u2019s **open-sourcing of llama ** means that a **powerful** llm is now available for commercial use, without the upfront capital costs associated with building these models, undermining the business model of the closed-source foundation model developers. there remain, however, significant compute costs associated with their use. there are also indications that the **performance of open source models** is progressing at pace. given these market conditions, it is unclear how foundation model leadership would contribute to economic productivity, even if it could be attained. **glossary** **_no-code_** \u2013 an approach to software development which uses intuitive drag-and-drop interfaces to allow people without programming skills to build applications **_web framework_** \u2013 a set of tools and resources designed to make it easier to build web applications **. real-world applications of** **foundation models** rather than building publicly or privately funded competitors to the likes of openai and , **_we see greater_** **_opportunity for the uk in becoming_** **_a leader in how foundation model are_** **_applied in the real world_** . with smaller funding requirements, application layer products which customise foundation model capabilities to specific use-cases are a better fit for the uk venture capital market, and can build on existing strengths in sectors like fintech, healthtech and cybersecurity. a further opportunity could be leveraging the uk\u2019s research capabilities to drive progress in underpinning technologies and to develop products which address specific major challenges at the foundation model and infrastructure layers of generative AI, such as the **detection of ai-generated content** and **cooling of data centres** , as well as ai safety solutions. . facebook company. . \u201c and introduce the next generation of llama,\u201d < -/ > [accessed ]; \u201calpaca eval leaderboard.\u201d [n.d.]. github.io < / > [accessed ] . \u201cai foundation models: initial report.\u201d . gov.uk < / system/uploads/attachment_data/file//full_report_.pdf > [accessed ] . , . . \u201cai model collapse could spell disaster for ai development, say new studies,\u201d verdict < / > [accessed ]; [n.d.-e]. datacentremagazine.com <  > [accessed ] **case study: software development with generative AI** **_ is a london-based technology entrepreneur, whose previous exits_** **_include footwear brand mahabis and adtech platform techlightenment._** \u201ci trained as a barrister and my coding skills are adequate for simple proofs of concept, but i\u2019ve always relied on outsourced developers when building new projects, which is e-consuming and costly. but in generative AI has changed everything. for people like me who want to build websites, , and workflow automations it\u2019s akin to a superpower. \u201cone simple example i really like is **meoweler** \u2013 a light-hearted travel site, ostensibly for cats. it\u2019s beautifully executed and provides a nice snapshot of thousands of cities around the world. but what\u2019s significant is that it **cost only** **$** to build, and the guy who made it is a designer with no formal training in software development. \"he found a freely available database of cities, then wrote and midjourney prompts to generate the content and images for each city in a consistent format and style. then he used the svelte web framework to create urls, page components, and site search. it\u2019s a similar approach to the one we\u2019ve **_generative ai\u2019s primary contribution to_** **_productivity will be in_** **_changing how things_** **_are produced_** **_._** the biggest benefits to productivity will not come from a small number of technologically-sophisticated companies using generative AI to invent new products, or cut their costs. taken to programmatically **reviewing** **insurance products** *, albeit we use a different web framework and are more focused on data quality. \"features that used to take and cost tens of thousands of pounds, i can now build myself in an afternoon with chat. it\u2019s insane. \u201cbut sites and only scratch the surface. what\u2019s exciting me at the moment is systems that use llm capabilities recursively. i love the idea of \u2018teams\u2019 of ai agents that can take a request like \u2018get me some quotes to have a heat-pump installed\u2019 and then automate the whole series of linked tasks needed to fulfil it \u2013 background web research, shortlisting and prioritising suppliers, contacting them for quotes, and so on. my intuition is, it will be scrappy, bedroom-hacker types \u2013 not computer science graduates or corporate it departments \u2013 who get there first.\u201d _* author disclosure: is_ _involved with this project._ rather, generative AI\u2019s promise lies with changing production itself, just as occurred with interchangeable parts (), assembly lines (), just-ine production (), and globalised supply chains (). the best example is software. . , . . \u201cthe promise and peril of generative AI,\u201d social europe (se) < / the-promise-and-peril-of-generative-ai > [accessed ] the **code interpreter plugin** for chat and llm-powered tools like github copilot are already enabling developers to **write code up to % faster** than before, presenting a potential solution to the uk\u2019s chronic **developer labour** **shortage** . even more significant is how generative AI expands the scope of no-code, enabling people without programming knowledge to build increasingly sophisticated software applications. in the past, which systems and automations could be developed was constrained by the availability of workers with skills in programming languages. generative AI tools effectively remove this constraint for some types of development, meaning that the capability to imagine what a system might do and to articulate how it ought to function becomes more valuable than formal computer science training\u2014a paradigm brought to life by the case study on the previous page. when it comes to productivity, in our view **_the most important national capability_** **_is a means of widely disseminating_** **_understanding of and access to_** **_generative ai tools through the_** **_economy and society._** there is good evidence that only a minority of firms are adopting existing digital tools in ways that enhance their productivity and commercial success, pulling ever further ahead of the pack. the gap could grow with the powerful new capabilities afforded by generative AI. the national economic challenge is to spread know-how among businesses and employees. there is a role for government and ai experts to encourage learning about the potential of generative AI, not only through sharing techniques and examples but also through the range of business support tools available. in some ways this runs counter to prevailing trends: many organisations have **banned their employees** from using generative AI applications, reasonably fearing it could lead to data leaks and/or the loss of intellectual property. while understandable, such practices inhibit the bottom-up emergence of productivity opportunities inside organisations. there is also some anecdotal evidence that productivity gains from generative AI are already being realised, but lost to forms of arbitrage. remote workers **secretly use chat** to get more free e or impress their superiors; marketing agencies outsource content writing to llms while leaving their client fees and service-level agreements unchanged. **_incentives must be created_** **_for expert users of generative AI tools_** **_to share their techniques._** . \u201cchat plugins.\u201d [n.d.]. openai.com <  > [accessed ]; dohmke, . . \u201cgithub copilot for business is now available,\u201d the github blog < / > [accessed ]; mcdonald, clare. . \u201caround new software developer jobs advertised ,\u201d computerweekly.com < / news//around--new-software-developer-jobs-advertised-every-day > [accessed ] . milmo, cahal. . \u201cchat limited by amazon and other companies as workers paste confidential data into ai chatbot,\u201d inews < - > [accessed ] . ito, aki. . \u201cemployees are secretly using chat to get ahead at work,\u201d business insider < -- > [accessed ] ----- ", "## . impediments to developing the uk\u2019s national capabilities in generative AI **several impediments may hamper efforts to unlock the full potential of the uk\u2019s** **capabilities for generative AI.** there are economic impediments in terms of lack of investment, and impediments from the challenges of scale of the technical infrastructure, as explained in previous sections. while the uk has not adopted specific legislation to regulate generative AI, there are some restrictions in existing laws, notably concerning personal data protection and intellectual property. further, there is an impediment to the uptake of national capabilities in generative AI in that these technologies are considered unethical and untrustworthy by some. thus, national capability will depend on generative AI tools which are reliable, safe, responsible, and trustworthy. we have identified how generative AI can unlock the uk\u2019s potential for augmented productivity by changing the ways things are produced. however, there are several impediments to uk businesses\u2019 access to and use of generative AI. **figure ** sets out some of the chief legal, regulatory, economic, cultural, and societal impediments to the adoption of generative AI in the uk. this section gives an overview of impediments to the uptake of generative AI in the uk. it specifically addresses risks associated with generative AI and what is meant by ethical and responsible ai. the section also addresses the concerns regarding, personal data, privacy, and data governance, particularly in relation to copyright, that arise from the development and use of generative AI tools. . 'trustworthy ai' is a contested term. independent high-level expert group on artificial intelligence identifies three components of trustworthy ai: () it should be lawful, complying with all applicable laws and regulations; () it should be ethical, ensuring adherence to ethical principles and values; and () it should be robust, both from a technical and social perspective. |impediment|explanation| |---|---| |legal & regulatory (law & regulation can both be a facilitator and an impediment if too restrictive; the absence of law & regulation can also be an impediment)|there is currently no omnibus bill in parliament dedicated solely to regulating ai in the uk. this is in contrast to other jurisdictions, especially ), where stringent legislation is being adopted. while the uk is considering regulating aspects of ai, notably through the online safety bill and particularly through regulators, no legislative initiative specifci ally addresses generative AI or foundation models\u2014as illustrated by the examples below. the uk government has taken steps to regulate ai through a \u2018pro-innovation approach\u2019 by which the government wants to use regulators to encourage business to adopt fvi e ethical principles when using generative AI. the fvi e principles are modelled on the organisation for economic co-operation and development ()\u2019s principles for the regulation of ai. the uk has also signed up through its membership of the unesco recommendations on the ethics of ai. while there is no specifci legislation for generative AI in the uk, the use of these technologies must still conform to existing law, such as the data protection act or intellectual property laws. the uk\u2019s intellectual property ofcfi e is currently working on a draft code for copyright and ai that will address inter alia the contentious issue of text and database mining exceptions, which the government had earlier proposed for the development of ai models and tools. there is a chance that generative AI will be regulated through the regulatory framework being developed by the competition & markets authority based on the regulator\u2019s new statutory powers in the digital markets, competition and consumers bill (dmcc), which is expected to enter into force in . a recent report from the competition & markets authority suggested a collection of principles to guide regulatory intervention in support of competitive generative AI markets, built on ready access to the materials to create foundation models, diversity of business models, choice for businesses in how to use foundation models and fel xibility for consumers in which provides to engage, the prevention of anti-competitive practices, and transparency about the risks and limitations of the foundation model products they are using. a cluster of policy initiatives also seek to set guardrails for ai development, with difef rent levels of implementation. for example, while the uk has set out a data sharing governance framework as part of its national data strategy, it has not adopted specifci legislation to give efef ct to the framework in the private sector. in contrast, the eu is adopting the data act and the data governance act. in contrast to the uk, the eu is adopting the ai act, expected to come into force at . the ai act will regulate ai according to perceived risks: unacceptable risk (banned), high risk (transparency, oversight, and accountability requirements), and low-to-minimal risk (safety and user protection requirements). can has taken a similar approach with its artifci ial intelligence and data act. the eu is also considering specifci ai product safety liability rules for how products are manufactured and how they should be used. see for example proposal for an ai liability directive, or the work of transparency (ecat). while there are numerous initiatives to introduce legislation to regulate ai in the us, the us so far has encouraged voluntary self-regulation based on blueprint for an ai bill of rights, setting out fvi e principles: () safe and efef ctive systems, () algorithmic discrimination protection, () data privacy, () notice and explanation, and () human alternatives, consideration and fallback. has also published a set of eight voluntary commitments pledged by leading companies in the ai industry. in addition, in it was announced that the biden administration is fast-tracking an executive order to address risks associated with ai.| _figure : impediments to the uptake of generative AI in the uk_ |impediment|explanation| |---|---| |legal & regulatory (law & regulation can both be a facilitator and an impediment if too restrictive; the absence of law & regulation can also be an impediment) (continued)|there are also legal and regulatory initiatives on state-level, exemplifei d by the governor of california\u2019s recent executive order n-- on generative AI, and domain-specifci guidance on the application of existing legislative, for example from blog posts by on consumer protections. technology (nist) has also developed a voluntary ai risk management framework (airmf) and senator has developed a safe innovation framework for the regulation of ai. in addition, the us consumer product safety commission published a report on product safety and liability on ai in . numerous issues arise in relation to product liability and ai, including whether existing laws cover the systemic risk of harm or if a precautionary principle approach should be adopted, to whom liability should be assigned, and the resources and levers available to the regulators. the department for business and trade and the ofcfi e for product safety and standards are currently reviewing the uk\u2019s product safety regime post-brexit, which ofef rs an opportunity to also consider the need for national generative AI product safety standards. (tuc) and the minderoo centre for technology and democracy at have set up a taskforce to draft a legislative proposal for the protection of workers and the use of ai. the taskforce will particularly examine risks associated with privacy, insecurity of work, and discrimination from the deployment of ai.| |technical|there are technical limitations to the capabilities generative AI can provide business, particularly when it comes to responsible, transparent, and trustworthy ai. the efef ctiveness of tools for auditing for bias or delivering required levels of explainability continue to be limited. ai \u2018hallucinations\u2019, where a generative AI tool makes up information is a weighty concern about the reliability of these technologies.| |economic|lack of investment as outlined in earlier sections.| |cultural|business may be reticent to make use of generative AI whilst employees may be using these technologies \u2018under the rr\u2019, without the quality or legal assurance, which poses a risk to competitiveness and regulation. there may also be reticence within the labour force to deploy generative AI either for fear that these technologies are not trustworthy, or that they will replace workers, thereby taking away the user\u2019s job. a variety of organisational processes or cultural factors will also inful ence patterns of ai adoption, from , and an executive understanding of the potential of ai, to employer-employee relations. organisational ai readiness will be an important inful ence on overall patterns of adoption.| |societal|there are numerous concerns regarding the ethics of generative AI, which lead to questions of fairness, trustworthiness, transparency, and accountability. without a robust and accountable ethics framework, the public will not trust the use of generative AI. there is also a risk that without a sound compulsory ethical framework, generative AI will perpetuate and advance biases and inequalities within the population, thereby contributing to greater systemic unfairness.| _figure : impediments to the uptake of generative AI in the uk (continued)_ in its **_interim report_** published on , the house of commons science, innovation and technology committee summarised the barriers to implementing safe and effective ai as ai challenges: **.** the bias challenge **.** the privacy challenge **.** the misrepresentation challenge **.** the access to data challenge **.** the access to compute challenge **.** the black box challenge **.** the open source challenge **.** the intellectual property and copyright challenge **.** the liability challenge **.** the employment challenge **.** the international coordination challenge **.** the existential challenge while not negating the importance of ai safety, this policy brief narrowly focuses on how to build uk\u2019s capabilities for productivity using generative AI. we therefore only consider risks that pose impediments to that go there are three chief impediments to building the uk\u2019s capabilities in this regard. first, there is the risk that a lack of trust in generative AI becomes so pervasive that the deployment of these technologies is rejected by businesses and the public. second, there is the risk that generative AI will be subjected to legal and ethical regimes which will be overly restrictive and thus hamper its full potenti third, the issue with ai hallucinations, whereby the generative AI tool makes up information, alongside other technical limitations, poses a challenge to their reliability which again is an impediment to their uptake nationally. **. risks with generative AI** this section briefly examines risks associated with generative AI and the legal and ethical frameworks that are emerging to address these. fundamentally, the british public must be able to trust the use of generative AI. there are many conceptualisations of risks associated with generative AI. the list below is not intended to be read as a complete overview, but rather a list of some of the most prominent concerns related to ai. numerous risks are associated with generative AI, including risks to personal data, privacy, and intellectual property. there are risks that due to lack of transparency or accountability, generative AI may produce unreliable outcomes, or be used for hidden or unacceptable outcomes. key concerns with generative AI applications are the reliability or veracity of the outputs, especially as the capacity of non-technical users to produce deepfake images, audio, and video abounds. scholars have also identified risks of negative environmental consequences, the overrepresentation of hegemonic viewpoints and value-lock in training data, the risk of propagating toxic stereotypes and racist, sexist, and ableist ideologies, marginalising communities, violating personal data, and subjecting people to abusive language, hate speech, microaggressions, derogating language, dehumanising and denigrating content and framing, which could lead to psychological harm. . , on the dangers of stochastic parrots: can language models be too big?, facct\u2019 , march -, acm /./. there are risks that data scraping for training foundation models violates copyright laws, or that the foundation models will reproduce bias, which may produce illegal outcomes, especially when generative AI is used in the context of social services, policing, and education. the cumulative effect of these risks is the erosion of trust in the technology, and of societal trust overall. according to \u201cit is also unlikely that international agreements will be effective in making ai safer and preventing harm, unless they are underpinned by robust domestic regulatory frameworks that can shape corporate incentives and developer behaviour in particular.\u201d (, **regulating ai in the uk** , p. ). **. ethical and responsible generative AI** responsible ai means demonstrating how the ethical principles are adhered to throughout all the stages of the generative AI lifecycle. to do so, there must appropriate accountability, risk mitigation, and liability. in terms of building national capabilities for the workforce, there are particular concerns regarding automated decisionmaking and the role of humans in the loop. numerous voices have expressed concern that generative AI is not responsible or ethic **\u2019s value-based principles for ai:** **\u2022** **_inclusive growth, sustainable development,_** **_and well-being_** **\u2022** **_human-based values and fairness_** **\u2022** **_transparency and explainability_** **\u2022** **_robustness, security, and safety_** **\u2022** **_accountability_** to meet these concerns about the use of ai more broadly, the government has proposed a guiding **principle-based** **framework** . the principles are drawn from the work of the **** and as such build on the emerging international consensus for ethical and responsible ai. this principle-based approach is dependent on regulatory capacity to be effective. the uk\u2019s government\u2019s value-based principles are: **\u2022** safety, security and robustness **\u2022** appropriate transparency and explainability **\u2022** fairness **\u2022** accountability and governance **\u2022** contestability and redress the principles are designed to be futureoriented and flexible, with the intention of promoting growth and innovation. while not legally binding, the government envisions that sector-specific regulators will adopt the principles as fit to their sectors and industries. . ai ethics is a growing academic field with numerous different interpretations of the term. some relevant scholarly articles are and emre kazim, philosophical foundations for digital ethics and ai ethics: a dignitarian approach, ai and ethics () : -; samuele lo piano, ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward, humanities and () -; , , , , , principled artificial intelligence: mapping consensus in ethical and rights-based approaches to principles for ai, berkman klein center for internet & society at , , ibo , embedding values in artificial intelligence (ai) systems, minds and machine :-. . australian government department of industry, science and resources, safe and responsible ai in australia (discussion paper ), pp. -. however, this approach may pose challenges in ensuring that regulators have the incentives, resources, or mandate to do so, especially as many regulators\u2019 remits are constrained by statutory language. thus, the approach has been challenged by **leading** **academics** , pointing to the need for more holistic thinking. it is also problematic that the government\u2019s principles are so vague as to be nearly vacuous. it is, for example, difficult to discern with any certainty whether the principles are focused on outcomes or how those outcomes are to be achieved. however, elsewhere, for example in data protection, the government has suggested that regulation should be based on outcomes; an approach that could potentially be taken for the five valuebased principles as well. (department for digital, culture, , **data:** **a new direction** , september , updated , p. .) as the principles are not legally binding, it is unlikely that businesses will have an adequate incentive to adopt all the principles unless there are compelling competitive advantages to doing so. while the government has provided tools such as the algorithmic transparency recording standard, which aims to support the implementation of ethical ai principles, the extent to which such tools are being implemented in practice is not clear. thus, has noted that: \u201cthe principles will not \u2013 initially \u2013 be placed on a statutory footing, and so regulators will have no legal obligation to take them into account, although the government has said it will consider introducing a \u2018duty to have regard\u2019 to the principles.\u201d ( , _regulating ai in the uk_ , p. .) the **house of commons science,** **innovation and technology committee** has criticised the government\u2019s unwillingness to consider ai-specific legislation, noting that: \u201c[t]here is a growing imperative to ensure governance and regulatory frameworks are not left irretrievably behind the pace of technological innovation.\u201d ( **the** **governance of artificial intelligence;** **interim report** , ninth report of session , p. .). thus, rather than see legislation as an impediment to the development of the uk\u2019s competitiveness in generative AI, we echo the sentiment of the review of the digital technologies, led by sir , that: \u201cwell-designed regulation and standards can have a powerful effect on driving growth and shaping a thriving digital economy.\u201d (hm government, **pro-innovation regulation** **of technologies review: digital** **technologies** (), p. .) while calls for legislation are mounting, it does not mean that the content of ai legislation is self-evident. legal rules that are too specific risk being quickly outdated while principles that are too broad or vague risks being meaningless. the challenge is therefore how to find the regulatory approach that will be robust and future-proof. legislation would also clarify the chain of liability throughout the value-chain and lifecycle of generative AI. for example, the all-party parliamentary group on data analytics (apgda) has noted that: \u201cthere are issues around transparency, explainability, and accountability in relation to third party/outsourced ai system development. . the central digital and data office expounded on these principles in its data ethics framework for the use of digital technologies, including ai, in . however, this guide is only for the public sector and does not have the force of law. for example, attention was drawn to the difficulty of testing for bias in third party systems.\u201d (policy connect, **an ethical ai** **future: catalysts to make** **artificial intelligence a force for good** , , p. .) legislation could clarify the standards and responsibility of testing that would befall uk businesses using third-party generative AI systems.a key issue with applying the law or ethical principles to generative AI is that the outcome is personalised or bespoke, therefore making predictability or comparison difficult. \u201cgenerated content is probabilistically and randomly generated based on certain input (or \u2018prompts\u2019), which are usually written by a human. \"therefore, the output of any given generative AI model is likely to be different for each person prompting the model and may both resemble patterns in the training data or appear to be something completely new.\u201d (forbrukerr\u00e5det, **ghost in** **the machine: addressing the consumer** **harms of generative AI** , , p. .) a **recent review** of foundation models found that none met the compliance requirements set out in the eu\u2019s draft ai act. there is a question of whether generative AI should go through an approval or vetting process before being used, or if redress and contestability should be used as a deterrent for unacceptable practices. accountable principles also means that there must be ways to audit the generative AI systems, which will require access to data for researchers and for regulators. a right to access to data for researchers in relation to the processing of personal data has been proposed included in the **online safety bill** in relation to the online information environment, but this has yet to be adopted by parliament. further there are no legal stipulations for data access in the legislative pipeline with regard to generative AI in the uk. **. personal data and privacy concerns** many of the ethical concerns regarding generative AI are linked to the use of personal data and privacy. these concerns span personal data that is being inputted into generative AI systems, personal data generated by these systems, and uses of generative AI systems for surveillance. some of these fears should be alloyed with the **data protection act (dpa)** and its forthcoming replacement, the **data protection and digital information** **(no. ) bill** . the uk\u2019s data protection framework is based on the eu\u2019s **general** **data protection regulation (gdpr)** , which includes the stipulation that all processing of personal data must adhere to the data processing principles. the data processing principles are: () lawfulness, fairness, and transparency; () purpose limitation; () data minimisation; () accuracy; () storage limitation; () integrity and confidentiality; and () accountability. that means that all uses of personal data by generative AI must respect these principles as a matter of law. as the legislation covers all forms of personal data its remit is broader than processing that concerns privacy. the legal definition of personal data is technologically neutral and comprehensive to ensure that all forms of personal data falls under its scope. the broadness of the definition has implications for the use of generative AI and may pose a considerable impediment from the uptake of these technologies by uk companies. the court of justice of (cjeu) has for example ruled that an **ip address can be personal data** when combined with other factors held by third parties. regardless of where in the process personal data is generated or the sources from which it is harvested, including public domain sources, or provided directly (and voluntarily) by an individual, all the data processing principles still apply in full. there are further restrictions on the use of sensitive data, which poses challenges for companies using generative AI as sensitivity may first become apparent once the system has generated output data. the use of generative AI poses several challenges when it comes to compliance with data protection law. it may not be apparent whether data is personal or not, or the system may generate personal data unbeknown or unintended by the creator of the ai system. however, it must be noted that the dpa is not a privacy statute, and that the objective of the legislation is not to preclude the processing of personal data, but instead to ensure that the processing is leg thus, the dpa does not automatically prevent the generation and use of personal data in generative AI. **article of the dpa defines personal data as:** **_\u201c\u2026any information relating to an identified_** **_or identifiable living individual\u2026 [meaning] a_** **_living individual who can be identified, directly_** **_or indirectly, in particular by reference to: (a)_** **_an identifiers such as a name, an identification_** **_number, location data or an online identifier, or_** **_(b) one or more factors specific to the physical,_** **_physiological, genetic, mental, economic, cultural_** **_or social identity of the individu\u201d_** the uk government clearly recognises the role personal data has in innovation and ai. in its **white paper on data** , , media & sport writes that: \u201cinnovative uses of personal data are at the forefront of driving scientific discovery, and enabling cutting-edge technology, like artificial intelligence (ai)\u2026this means maintaining a clear legal framework overseen by a regulator that takes account of the benefits of data use, while protecting against the harms that can come from using personal data irresponsibly.\u201d (p. ). the objective of the white paper on data is to use \u201cpersonal data responsibly\u201d (p. .), which necessitates an ethical framework. one of the drawbacks in the context of generative AI of the current data protection regime is that it is focussed on the right to data protection of the individuals and as such does not address the potential for systemic risk of bias, discrimination, and inequality arising from the use of personal data at scale. . however, several european data protection authorities are examining whether generative AI tools comply with the gdpr. notably, the italian data protection authority has placed a temporary ban on an openai generative chatbot for failing to provide information as required under the gdpr. the spanish data protection authority is also investigating chatgpt for breaches of gdpr. furthermore, (edpb) has set up a taskforce to examine whether generative AI is compatible with the gdpr. it must, however, also be noted that these concerns regard whether generative AI comport with the data-processing principles for the processing of personal data, not whether they should be banned outright as illeg **. data governance** generative AI needs data and there is therefore considerable concern and interest in the data that goes into the training of foundation models and the data that is input into generative AI systems. there is growing concern that generative AI violates intellectual property rights. legal challenges have been mounted in the us concerning the use of data scraping for training data which could violate **copyright** . generative AI has been front and centre of the recent labour dispute and **strike** by the sag-afra trade unions representing actors in the us. whether any legal dispute will be successful is highly uncertain, however, the broader point is that the labour force of the creative industries is under threat from generative AI, which will have a direct effect on the uk economy as these industries represent **.% of gdp** . as mentioned above, the uk\u2019s intellectual property office is currently drafting a **code for ai and copyright** in an attempt to answer some of these questions. in the meantime, there are signals of a **broader debate** about the societal value and risk associated with absorbing a large portion of human knowledge into large ai models, potentially impinging on fundamental human rights, such as access to culture. as a countermeasure to copyright concerns, there is a chance that companies will hold data in so-called walled gardens. that would give the public even less access to open data and would stifle innovation and productivity. there is still room for clarification of the legal framework in this regard. **. regulatory capacity** the government\u2019s approach to ai regulation would support x\u00bdindividual regulators to develop sector-specific frameworks for the adoption of the value-based principles by uk industry. in many ways, this is a more concrete and pragmatic approach than the approach taken by other jurisdictions, notably the eu, where centralised, overarching principles have been adopted in comprehensive legislation. as such, the uk is showing more willingness to operationalise the principles in ways that will have a direct impact on the development and uptake of generative AI. for example, the competition and markets authority has **proposed a set of** **principles** to regulate the development of ai models. (competition & markets authority, **ai foundation models: initial** **report** , .) . see creative%industries%sector%contributed,the%uk%economy%in%. . the principles are: () ensuring that foundation model developers have access to data and computing power, and that early ai developers do not gain an entrenched advantage; () that both closed and open source models are allowed to develop; () that businesses have a range of options to access ai models \u2013 including developing their own; () that consumers should be able to use multiple ai providers; () that no anticompetitive conduct like 'bundling' ai models into other services take place; () that consumers and businesses are given clear information about use and limitations of ai models. the effectiveness of the approach taken by the government will depend on regulatory capacity and there is a risk that efforts will be unnecessarily duplicated, or that regulatory frameworks will promote contradictory rules. the **sir review** of digital technologies, published in , found more than different regulators of digital technologies. we concur with others who have observed a need for centralised regulatory oversight to coordinate the efforts of the many departments and regulators. this is necessary to ensure that the uk\u2019s value-based principled framework for the governance of generative AI is adopted in a consistent manner across the uk\u2019s industrial sectors. these functions are met by the **office for artificial intelligence** and centre for data ethics and innovation under the department of science, innovation and technology (dsit), and the **digital regulation cooperation** **forum** , which was formed as a membership organisation consisting of four key regulators: the competition & markets authority, ofcom, the information commissioner\u2019s office, and the financial conduct authority. alongside recent internal changes to government\u2019s policy delivery infrastructure, through the establishment of dsit, further changes to the government\u2019s interactions with the external expert community are also expected, which may influence the ability to rapidly identify and respond to emerging technological changes with regulatory implications. **. international leadership** the uk government has repeatedly set forth an ambition of international leadership in ai, both in terms of development and regulation. in , the **sir review** asserted that the uk had a window of to realise that ambition. in relation to the development of regulatory frameworks, the uk is struggling to keep pace, as suggested by **figure ** in an earlier section. while the uk\u2019s government has resisted calls for legislation to allow for growth and innovation in the sector, the lack of ai-specific legal regulation opens the possibility that the safe and responsible deployment of ai solutions and products will depend on the enforcement of rules devised and overseen by other jurisdictions or the international community. the absence of robust legislation poses a serious risk to the safety and trustworthiness of generative AI solutions, especially when these are devised wholly or in part by foreign companies. being first-to-the-post in adopting legislation to regulate ai is not necessarily a desirable objective if that legislation is not robust, balanced, and feasible. however, the uk\u2019s lack of binding regulation means that despite any ambition of the government, the uk is failing to reach its ambition of international leadership in this regard. . the ai council and centre for data ethics and innovation have recently come to the end of their term or been disbanded, with plans for an alternative approach to external engagement in development. ----- ", "## . recommendations to build capability in generative AI **although the** **national ai strategy** **is concerned with the broader ai field** **and pre-dates the latest developments in generative AI, many of the key** **actions it sets out retain their relevance and do not need to be repeated here.** **** we focus instead on innovation and skills policy levers that both support the goal of making the uk a global leader in applying generative AI to the economy, and are not discussed in detail in the national ai strategy. it is worth noting that exactly how these policy levers are used depends on whether the uk pursues **_ai nationalism_** or a more open approach. as noted by the national ai strategy, increased compute capacity is a dependency for the development of most generative AI capabilities. an efficient way of mitigating the uk\u2019s compute deficit would be lobbying **_hyperscalers_** to establish gpu-clusters in the uk. this would allow organisations like the nhs to run fine-tuned foundation models with fewer concerns about data security and privacy. in parallel, subsidies could be increased for companies developing capital-intensive proprietary and/or strategically important generative AI capabilities (e.g. chips; cybersecurity and defence applications). tax incentives like the seed enterprise investment scheme (seis) could be enhanced to increase the supply of early-stage capital to generative AI startups at the application layer. tax credits could be introduced for all businesses to incentivise them to apply generative AI technologies to their existing operations and/or to develop **glossary** **_ai nationalism_** \u2013 coined by to describe an approach to national ai policy which prioritises a country\u2019s strategic interests and/or the economic interests of its citizens **_hyperscaler_** \u2013 a company operating massive cloud computing infrastructure (e.g. amazon web services) new generative AI-powered products and services. challenge prizes could be launched to identify and disseminate effective bottom-up uses of generative AI by teams and individuals inside organisations operating in industries where productivity gaps have been identified. they can also be used to motivate innovation in industries identified as potential growth areas for the uk economy. an ai nationalist approach would imply government acting assertively to steer market outcomes. public sector procurement of generative AI capabilities could positively favour uk suppliers\u2014for example, public funding for supercomputers could be made contingent on the use of chips designed by uk companies like graphcore. acquisitions of major uk generative AI companies by foreign rivals\u2014comparable to the past acquisitions of deepmind by , arm by softbank, or instadeep by biontech\u2014could be challenged. . \u201cnational ai strategy - html version.\u201d [n.d.]. gov.uk <  > [accessed ] by contrast, an open approach might involve designing a regulatory regime encouraging foreign generative AI entrepreneurs to set up in, or relocate their companies to, the uk. in addition to the national ai strategy\u2019s plans to make visas easier to obtain, this might include corporation tax and entrepreneurs\u2019 relief incentives. it would not, however, be compatible with the kind of controls on mergers and acquisitions described above. for generative AI to pervade the economy, school and higher education curriculums would need to be developed to increase both understanding of the technologies and critical thinking about how they are used in practice. computer science education may need to be reformed, or a new discipline established, to teach software development using no-code and llms. these could also be the subject for new **skills bootcamps** , and/or upskilling programmes co-designed with employers and workers. regardless of whether an ai nationalist or open strategy is pursued, our view is that legislation and regulation will be needed to remove impediments to the adoption of generative AI and ensure that the british public can trust organisations\u2019 use of the technology. we favour government adopting a principled approach to introducing legislation that would embed an ethical framework for the governance of generative AI in domestic law in multiple sectors. it should forbid high-risk uses of generative AI, for example in the operation of critical infrastructure, where it could pose a significant threat to human safety or violate fundamental ethical rules. legislation takes a long time to pass. in the interim we recommend the adoption of soft governance models, such as the **ieee standard on transparency** , together with moves to strengthen regulatory capacity. international standards may also be used as frameworks for legislative proposals. we therefore support the all-parliamentary group on data analytics\u2019 (apgda) recommendation for a centralised ai office with a renewed strategic focus to not only oversee and coordinate ai regulation across regulators, as set out in the government\u2019s white paper, but also to ensure that regulators enforce regulation. this could be achieved by, for example, bolstering the remit to the office of artificial intelligence with a strategic focus on work programmes that identify regulatory gaps and empower existing regulators to deliver responsive regulatory interventions in their domains. there continues to be a need for capacity building among regulators. although this is well under way in some domains, as seen from the framework being developed by the competition & markets authority, others will need further support to deliver the government\u2019s current ai white paper proposals. in addition, as is already recognised, regulators need to enhance their existing co-operation to ensure clarity about responsibilities, as the technology will cut across all sectors. this coordinating function may need additional or more active guidance and support than is currently proposed. it is crucial that the regulatory oversight mechanism has sufficient resources and expertise to test and oversee the use of generative AI to build national capabilities for productivity, and be transparent about the oversight in order to inspire public confidence. . \u201cfind a skills bootcamp.\u201d . gov.uk <  > [accessed ] ----- ", "## selted bibliography \u201cai foundation models: initi report.\u201d . gov.uk < / system/uploads/attachment_data/file//full_report_.pdf > [accessed ] \u201cblow for th unicorn graphcore as sequoia writes off stake.\u201d [n.d.]. es (london, england: ) (the es) <  > [accessed september ] \u201c-backed ai startup infltion raises $. billion from nvidia and others.\u201d . reuters < . com/thnology/infltion-ai-raises--bln-funding--others---/ > [accessed september ] \u201cnation ai strategy - html version.\u201d [n.d.]. gov.uk < / nation-ai-strategy-html-version > [accessed ] \u201cresponsible ai uk.\u201d [n.d.]. responsible ai uk < / > [accessed september ] andre charlesworth, , , , and clare torrible, response to the uk\u2019s march white paper \u201ca pro-innovation approach to ai regulation\u201d, centre for glob law and innovation, university of , june , = and the associated press, writers strike: why is such a hot button in hollywood\u2019s labor battle with sag-aftra, fortune, july , //// sag-aftra-writers-strike-explained-artifici-intelligence/ arm ltd. [n.d.]. \u201cnew arm tot compute solutions enable a mobile future built on arm,\u201d arm | the architture for the digit world <  > [accessed september ] artifici intelligence and data act, / artifici-intelligence-and-data-act austrian government department of industry, science and resources, safe and responsible ai in austria (discussion paper june ) bradshaw, , and . . \u201cuk government unveils long-awaited \u00a3bn semiconductor strategy,\u201d financi es <  > [accessed september ] brown, , , , , , and others. [n.d.]. \u201clanguage models are few-shot learners,\u201d arxiv.org < /. > [accessed september ] browne, ryan. . \u201cnvidia-backed platform that turns text into -generated avatars boosts vuation to $ billion,\u201d <  > [accessed september ] c-/ breyer, judgement of the court (sond chamber on ), li:eu::, . europa.eu/juris/liste.jsf?num=c-/ centr digit & data office, data sharing governance framework (guidance), , / government/publications/data-sharing-governance-framework/data-sharing-governance-framework centr digit and data office, data ethics framework (guidance), , updated ,  computer & markets authority, ai foundation models: initi report, september , / government/publications/ai-foundation-models-initi-report cooke, . . \u201cai model collapse could spell disaster for ai development, say new studies,\u201d verdict < / > [accessed ] coyle, . . \u201cthe promise and peril of generative AI,\u201d soci europe (se) < / the-promise-and-peril-of-generative-ai > [accessed ] data prottion act ,  data prottion and digit information (no. ) bill, / , sylvie, data rivers: re-bancing the data osystem that makes generative AI possible (march , ). available at ssrn: = or . department for digit, culture, , data: a new dirtion, , updated june ,  department for science, and thnology. a. \u201ciniti \u00a3 million for expert taskforce to help uk build and adopt next generation of safe ai,\u201d gov.uk <  > [accessed september ] department for science, innovation and thnology and department for digit, culture, , nation data strategy (guidance), , updated ,  department for science, innovation and thnology and office for artifici intelligence, a pro-innovation approach to ai regulation (policy paper), march , / ai-regulation-a-pro-innovation-approach department for science, innovation and thnology, office for artifici intelligence, department for digit, culture, , and department for business, energy & industri strategy, nation ai strategy (guidance), , updated ,  digit markets, competition and consumer bill, / digit regulation cooperation forum,  dohmke, . . \u201cgithub copilot for business is now available,\u201d the github blog < / > [accessed ] emily m. bender et , on the dangers of stochastic parrots: can language models be too big?, , , acm euronews and afp, spain opens an investigation into openai\u2019s chatgpt over a potenti data breach, april ,  european commission, european centre for gorithmic transparency,  european data prottion board, edpb resolves disputes on transfers by meta and creates task force on chatgpt, april ,  evans, benedict. . \u201cchatgpt and the imagenet moment,\u201d benedict evans < / benedictevans////chatgpt-imagenet > [accessed september ] exutive department state of cifornia, exutive order n--, / uploads///ai-eo-no.-_-ggn-signed.pdf forbrukerr\u00e5det, ghost in the machine: addressing the consumer harms of generative AI, june ,  freshfields bruckhaus deringer, itian ban on ai chatbot lifted: updates on data prottion investigation, lexology, march ,  heather stewart, \u2018the chlenges are re\u2019: tuc taskforce to examine ai threat to workers\u2019 rights, the guardian, september ,  hm government, pro-innovation regulation of t hnologies review: digit t hnologies (sir patrick vlance review) (march ),  house of commons science, innovation and thnology committee, the governance of artifici intelligence: interim report, ninth report of session -, august , cmscth//report.html house of lords library, arts and creative industries: the case for a strategy, dember , . parliament.uk/arts-and-creative-industries-the-case-for-a-strategy/#:~:text=the%creative%industries% stor%contributed,the%uk%onomy%in% ibo van de poel, embedding vues in artifici intelligence (ai) systems, minds and machine :- intelltu property office, the governments code of practice on copyright and ai (guidance), june ), % practice%aims,and%rewards%investment%in%creativity. ito, aki. . \u201cemployees are sretly using chatgpt to get ahead at work,\u201d business insider < . businessinsider.com/chatgpt-sret-productivity-work-ai-thnology-ban-employees-coworkers-job-- > [accessed ] , , , , , principled artifici intelligence: mapping consensus in ethic and rights-based approaches to principles for ai, berkman klein center for internet & society at , katyanna quach, judge lets art trio take another crack at suing ai devs over copyright, the register, july , / knight, will. . \u201c ceo says its next gorithm will lipse chatgpt,\u201d wired < / story/-deepmind-demis-hassabis-chatgpt/ > [accessed september ] leswing, kif. . \u201cmeet the $, nvidia chip powering the race for a.i,\u201d < //// nvidias-a-is-the--chip-powering-the-race-for-ai-.html > [accessed september ] matt davies and , regulating ai in the uk, , july , / mcdond, clare. . \u201caround new software developer jobs advertised ,\u201d computerweekly.com <  > [accessed ] , keep your ai claims in chk (blog, feder trade commission february ), / business-guidance/blog///keep-your-ai-claims-chk milmo, cah. . \u201cchatgpt limited by amazon and other companies as workers paste confidenti data into ai chatbot,\u201d inews < - > [accessed ] mirjili, seyedi. . \u201cif ai image generators are so smart, why do they struggle to write and count?,\u201d the conversation < - > [accessed september ] nist, ai risk management framework,  ai policy observatory, ai principles overview,  office of artifici intelligence,  online safety bill, / policy connt, an ethic ai future: catysts to make artifici intelligence a force for good, june , #: ~:text=policy%connt's%inquiry%heard%from,use%of%data%and%ai propos for a dirtive of the european parliament and of the council on adapting non-contractu civil liability rules to artifici intelligence (ai liability dirtive), com// fin, / txt/?uri=celex%apc propos for a regulation of the european parliament and of the council laying down harmonised rules on artifici intelligence (artifici intelligence act) and amending certain union legislation acts, com// fin, . europa.eu/leg-content/en/txt/?uri=celex%apc propos for a regulation of the european parliament and of the council on european data governance (data governance act), com// fin,  propos for a regulation of the european parliament and of the council on harmonised rules on gair access to and use of data (data act), com// fin,  regulation (eu) / of the european parliament and of the council of on the prottion of natur persons with regard to the processing of person data and on the free movement of such data, repeing dirtive // (gener data prottion regulation) (text with eea relevance) oj l ,  risi bommasani, , and , do foundation model providers comply with the draft eu ai act?, centre for research on foundation models, ,  and emre kazim, philosophic foundations for digit ethics and ai ethics: a dignitarian approach, ai and ethics () : - rogenmoser, . [n.d.]. \u201c announces m series a funding round, bringing tot vuation to .b and launches new browser extension,\u201d .ai <  > [accessed september ] samuele lo piano, ethic principles in machine learning and artifici intelligence: cases from the field and possible ways forward, humanities and soci sciences communications () - senator democrats, majority leader schumer delivers remarks to launch safe innovation framework or artifici intelligence at csis, june , / majority-leader-schumer-delivers-remarks-to-launch-safe-innovation-framework-for-artifici-intelligence-at-csis sharma, . . \u201cdeepmind unveils rt-, a new ai that makes robots smarter,\u201d venturebeat < https:// venturebeat.com/ai/deepmind-unveils-rt--a-new-ai-that-makes-robots-smarter/ > [accessed september ] shu, catherine. . \u201c acquires artifici intelligence startup deepmind for more than $m,\u201d thcrunch < / > [accessed september ] singh, jagmeet, and ingrid lunden. . \u201copenai closes m share se at b-b vuation,\u201d thcrunch < / > [accessed september ] stlbaumer, colette. . \u201cintroducing copilot\u2014a whole new way to work,\u201d blog < / > [accessed september ] the onomist. . \u201chow to make britain\u2019s ai dreams reity,\u201d onomist (london, england: ) (the onomist) <  > [accessed september ] the pissarides review into the future of work and wellbeing, briefing paper: what drives the uk to adopt ai and robotics, and what are the consequences for jobs?, september , . com/dfafceacd/aaabc_fin%briefing%-%adoption%of% automation%and%ai%in%the%uk.pdf , a blueprint for an ai bill of rights making automated systems work for the american people, / , voluntary ai commitments,  tung, liam. . \u201cchatgpt just bame the fastest-growing \u2018app\u2019 of l e,\u201d < / chatgpt-just-bame-the-fastest-growing-app-of-l-e/ > [accessed september ] unesco, ethics of artifici intelligence,  united states consumer product safety commission, artifici intelligence and machine learning in consumer products,  wes , ai-generated art cannot be copyrighted, rules a us feder judge, the verge, august ,  wiggers, . . \u201cstability ai, the startup behind stable diffusion, raises $m,\u201d thcrunch < . com////stability-ai-the-startup-behind-stable-diffusion-raises-m/ > [accessed september ] report design by ** printed this** images taken from unsplash courtesy of milad fukurian, and vackground com  ai.cam.ac.uk   ", "# generative AI at work \u02da erik danielle first draft: please see here for latest version **abstract** new ai tools have the potential to change the way workers perform and learn, but little is known about their impacts on the job. in this paper, we study the staggered introduction of a generative AI-based conversational assistant using data from , customer support agents. access to the tool increases productivity, as measured by issues resolved per hour, by % on average, including a % improvement for novice and low-skilled workers but with minimal impact on experienced and highly skilled workers. we provide suggestive evidence that the ai model disseminates the best practices of more able workers and helps newer workers move down the experience curve. in addition, we find that ai assistance improves customer sentiment, increases employee retention, and may lead to worker learning. our results suggest that access to generative AI can increase productivity, with large heterogeneity in effects across workers. **jel classifications** : d, j, m, m, o **keywords** : generative AI, large language models, technology adoption, worker productiv- ity, worker learning, experience of work, organizational design. \u02da correspondence to erikb@stanford.edu, d_li@mit.edu, and lraymond@mit.edu. we are grateful to daron acemoglu, , , , , , , , sendhil mullainathan, emma , , ashesh rambachan, , , , , sebastian thrun, and various seminar participants for helpful comments and suggestions. we thank for providing excellent research assistance and for funding. the content is solely the responsibility of the authors and does not necessarily represent the official views of , mit, or the nber. the emergence of generative AI (ai) has attracted significant attention, but few studies have examined its economic impact. while various generative AI tools have performed well in laboratory settings, excitement about their potential has been tempered by concerns that these tools may be less effective in real-world settings, where they may encounter unfamiliar prob- lems, face organizational resistance, or provide misleading information in a consequential environ- ment ( , ; roose , ). in this paper, we study the adoption of a generative AI tool that provides conversational guidance for customer support agents. this is, to our knowledge, the first study of the impact of generative AI when deployed at scale in the workplace. we find that access to ai assistance increases the productivity of agents by %, as measured by the number of customer issues they are able to resolve per hour. in contrast to studies of prior waves of computerization, we find that these gains accrue disproportionately to less-experienced and lower-skill workers. we argue that this occurs because generative AI systems work by capturing and disseminating the patterns of behavior that characterize the most productive agents, including knowledge that has eluded automation from earlier waves of computerization. computers and software have transformed the economy with their ability to perform certain tasks with far more precision, speed, and consistency than humans. to be effective, these systems typically require explicit and detailed instructions for how to transform inputs into outputs: when engineers write code to perform a task, they are codifying that task. yet because many work- place activities\u2014such as writing emails, analyzing data, or creating presentations\u2014rely on tacit knowledge, they have so far defied automation ( polanyi , ; autor , ). machine learning (ml) algorithms work differently from traditional computer programs: instead of requiring explicit instructions to function, these systems infer instructions from examples. given a training set of images, for instance, ml systems can learn to recognize specific individuals even though one cannot fully explain what physical features characterize a given person\u2019s identity. this ability highlights a key, distinguishing aspect of ml systems: they can learn to perform tasks even a note on terminology. there are many definitions of artificial intelligence and of intelligence itself\u2014 . ( ) list over of them. in this paper, we define \u201cartificial intelligence\u201d (ai) as an umbrella term that refers to a computer system that is capable of sensing, reasoning, or acting like a human. \u201cmachine learning\u201d (ml) is a branch of ai that uses algorithms to learn from data, identify patterns, and make predictions or decisions without being explicitly programmed ( , n.d. ). large language models (llms) and tools built around llms such as chat are an increasingly important application of machine learning. llms generate new content, making them a form of \u201cgenerative AI.\u201d we provide a discussion of this literature at the end of this section. by codify, we mean compiling a process into a formal, ordered routine. tacit knowledge refers to the knowledge and skills that individuals possess but are unable to express explicitly. it is often intuitive and nonverbal, acquired through personal experiences, observations, and practice over time. is deeply ingrained in an individual\u2019s behavior and can be difficult to transfer or convey to others through traditional methods such as training or manuals ( polanyi , ). when no instructions exist\u2014including tasks requiring tacit knowledge that could previously only be gained through lived experience ( polanyi , ; autor , ; and , ). in addition, ml systems are often trained on data from human workers, who naturally differ in their abilities. by seeing many examples of tasks\u2014making sales pitches, driving a truck, or diagnosing a patient, to name a few\u2014performed well and poorly, these models can implicitly learn what specific behaviors and characteristics set high-performing workers apart from their less effective counterparts. that is, not only are generative AI models capable of performing complex tasks, they might also be capable of capturing the skills that distinguish top workers. the use of ml tools may therefore expose lower-skill workers to new skills and lead to differential changes in productivity. we study the impact of generative AI on productivity and worker experience in the customer service sector, an industry with one of the highest rates of ai adoption ( chui et , ). we examine the staggered deployment of a chat assistant using data from , agents working for a fortune software firm that provides business process software. the tool we study is built on a recent version of the generative pre-trained transformer () family of large language models developed by openai ( openai , ). it monitors customer chats and provides agents with real- time suggestions for how to respond. it is designed to augment agents, who remain responsible for the conversation and are free to ignore its suggestions. we have three sets of findings. first, ai assistance increases worker productivity, resulting in a % increase in the number of chats that an agent successfully resolves per hour. this increase reflects shifts in three components of productivity: a decline in the time it takes an agent to handle an individual chat, an increase in the number of chats that an agent handles per hour (agents may handle multiple chats at once), and a small increase in the share of chats that are successfully resolved. the productivity impacts of ai assistance are highly uneven. we find that less-skilled and less-experienced workers improve significantly across all productivity measures we consider, including a % increase in the number of issues they are able to resolve per hour. access to the ai tool helps newer agents move more quickly down the experience curve: treated agents with of tenure perform just as well as untreated agents with of tenure. in contrast, we find minimal impacts on the productivity of more-experienced or more-skilled workers. indeed, we find evidence that ai assistance may decrease the quality of conversations by the most skilled agents. these results contrast, in spirit, with studies that find evidence of skill-biased technical change for earlier waves ) puts it \u201cwhere the software . engineer formally specifies their problem, carefully designs algorithms, composes systems out of subsystems or decomposes complex systems into smaller components, the software as meijer ( . engineer amasses training data and simply feeds it into an ml algorithm...\u201d of computer technology ( autor et , ; acemoglu and restrepo , ; bresnahan et , ; bartel et , ). our second set of results investigates the mechanism underlying our main findings. we show that ai recommendations appear useful to workers: agents who follow recommendations more closely see larger gains in productivity, and adherence rates increase over time for all workers, particularly those who were initially more skeptic we also find that engagement with ai recommendations can generate durable learning. using data on software outages\u2014periods in which the ai software fails to provide any suggestions\u2014we show that workers see productivity gains relative to their pre-ai baseline even when recommendations are unavailable. these outage-period gains are more pronounced for workers who had more prior exposure to ai assistance or who had followed ai recommendations more closely. finally, we analyze the text of agents\u2019 chats and provide suggestive evidence that access to ai drives convergence in communication patterns: low-skill agents begin communicating more like high-skill agents. our third set of results focus on agents\u2019 experience of work. work in contact centers is often difficult. agents are regularly exposed to hostile treatment from upset (and anonymous) customers, and because much work is outsourced, many agents work overnight shifts in order to service us business hours. ai assistance may help agents communicate more effectively but could also increase the likelihood that agents are perceived as mechanical or inauthentic. we show that access to ai assistance markedly improves how customers treat agents, as measured by the sentiment of their chat messages. we also find that customers are less likely to question the competence of agents by requesting to speak to a supervisor. these changes come alongside a substantial decrease in worker attrition, which is driven by the retention of newer workers. our overall findings show that access to generative AI can increase the productivity and retention of individual workers. we emphasize, however, that our paper is not designed to shed light on the aggregate employment or wage effects of generative AI tools. firms may respond to increasing productivity among novice workers by hiring more of them, de-skilling positions, or seeking to develop more powerful ai systems that can replace lower-skill workers entirely. unfortunately, our data do not allow us to observe changes in wages, overall labor demand, or the skill composition of workers hired for the job. our results also highlight the longer-term incentive challenges that ai systems bring. top workers are generally not paid for their contributions to the training data that ai systems use to capture and disseminate their skills. yet, without these contributions, ai systems may be less the term \u201ccontact center\u201d updates the term \u201ccall center,\u201d to reflect the fact that a growing proportion of customer service contacts no longer involve phone calls. effective in learning to resolve new problems. our work therefore raises questions about how workers should be compensated for the data they provide to ai systems. our paper is related to a large literature on the impact of technological adoption on worker productivity and the organization of work (e.g. rosen , ; autor et , ; athey and stern , ; bresnahan et , ; bartel et , ; acemoglu et , ; hoffman et , ; bloom et , ; michaels et , ; garicano and rossi-hansberg , ; acemoglu and restrepo , ; felten et , ). many of these studies, particularly those focused on information tech- nologies, find evidence that it complements higher-skill workers ( akerman et , ; taniguchi and yamada , ). bartel et ( ) shows that firms that adopt it tend to use more skilled labor and increase skill requirements for their workers. acemoglu and restrepo ( ) study the diffusion of robots and find that the negative employment effects of robots are most pronounced for workers in blue collar occupations and those with less than a college education. there have been substantially fewer studies involving ai-based technologies, generative or not. acemoglu et ( ); zolas et ( ); calvino and fontanelli ( ) examine economy-wide data from the us and and show that the adoption of ai tools is concentrated among large, young firms with relatively high productivity. so far, evidence on the productivity impacts of these technologies is mixed: for example, acemoglu et ( ) finds no detectable relationship between investments in ai-specific tools, while babina et ( ) finds evidence of a positive relationship between firms\u2019 ai investments and their subsequent growth and valuations. these studies all caution that the productivity effects of ai technologies may be challenging to identify at the macro-level because ai-adopting firms differ substantially from non-adopters. in this paper, we provide micro-level evidence on the adoption of a generative AI tool across thousands of workers working at a given firm and its subcontractors. our work is more closely related to several other studies examining the impacts of generative AI in lab-like settings. et ( b ) recruit software engineers for a specific coding task (writing an http server in javascript) and show that those given access to github copilot complete this task twice as quickly. similarly, noy and ( ) conduct an online experiment showing that subjects given access to chat complete professional writing tasks more quickly. choi and schwarcz ( ) give law students access to ai assistance on a law school exam. consistent with our findings, noy and ( ), choi and schwarcz ( ) and ( ) find that chat compresses the productivity distribution, with lower-skill workers benefiting the most. our paper, however, is ( ) reports that when surveyed firms are asked directly, % of employers in finance and % in manufacturing reported that ai positively impacted productivity and % of surveyed workers who work with ai report higher job performance. the first to examine longer-term effects in a real-world workplace where we can also track patterns of learning, customer-side effects and changes in the experience of work. ", "## generative AI and large language models in , the rapid pace of ai development and public release tools such as chat, , and dall-e have attracted widespread attention, optimism, and alarm ( the white house , ). these technologies are all examples of \u201cgenerative AI,\u201d a class of machine learning technologies that can generate new content\u2014such as text, images, music, or video\u2014by analyzing patterns in existing data. in this section, we provide background on generative AI as a technology and discuss its potential economic implications. **.** **technical primer** this paper focuses on an important class of generative AI, large language models (llms). llms are neural network models designed to process sequential data ( bubeck et , ). an llm is trained by learning to predict the next word in a sequence, given what has come before, using a large corpus of text (such as wikipedia, digitized books, or portions of the internet). this knowledge of the statistical co-occurrence of words allows it to generate new text that is grammatically correct and semantically meaningful. though \u201clarge language model\u201d implies human language, the same techniques can be used to produce other forms of sequential data (\u201ctext\u201d) such as protein sequences, audio, computer code, or chess moves ( eloundou et , ). recent progress in generative AI has been driven by four factors: computing scale, earlier innovations in model architecture, the ability to \u201cpre-train\u201d using large amounts of unlabeled data and refinements in training techniques. first, the quality of llms is strongly dependent on scale: the amount of computing power used for training, the number of model parameters, and dataset size ( kaplan et , ). firms are increasingly devoting more resources to increasing this scale. the - model included billion parameters, was trained on billion tokens, and generated approximately $ million dollars in computing costs alone; the model, meanwhile, is estimated to include . trillion parameters, trained on trillion tokens, at a rumored computing-only cost of $ million ( li , ; brown et , ; patel and wong , ) for a more detailed technical review of progress, see radford and narasimhan ( ); radford et ( ); ( ); ( ). in terms of model architecture, modern llms use two earlier key innovations: positional en- coding and self-attention. positional encodings keep track of the order in which a word occurs in a given input. meanwhile, self-attention assigns importance weights to each word in the context of the entire input text. together, this approach enables models to capture long-range semantic relationships within an input text, even when that text is broken up into smaller segments and processed in parallel ( vaswani et , ; bahdanau et , ). next, llms can be pre-trained on large amounts of unlabeled data from sources such as reddit or wikipedia. because unlabeled data is much more prevalent than labeled data, llms can learn about natural language on a much larger training corpus ( brown et , ). by seeing, for instance, that the word \u201cyellow\u201d is more likely to be observed with \u201cbanana\u201d or \u201csun\u201d or \u201crubber duckie,\u201d the model can learn about semantic and grammatical relationships even without explicit guidance ( radford and narasimhan , ). the resulting model can be used in multiple applications because its training is not specific to a particular set of tasks. finally, general-purpose llms can be further \u201cfine-tuned\u201d to generate output that matches the priorities of any specific setting ( , ; liu et , ). for example, a model trained to generate social media content would benefit from receiving labeled data that contain not just the content of a post or tweet, but also information on the amount of user engagement it received. similarly, an llm may generate several potential responses to a given query, but some of them may be factually incorrect or contain toxic language. to discipline this model, human evaluators can rank these outputs to train a reward function that prioritizes desirable responses. these types of refinements can significantly improve model quality by making a general-purpose model better suited to its specific application ( , ). together, these innovations have generated meaningful improvements in model performance. the generative pre-trained transformer () family of models, in particular, has attracted con- siderable media attention for their rapidly expanding capabilities. **.** **the economic impacts of generative AI** computers have historically excelled at executing pre-programmed instructions, making them par- ticularly effective at tasks that can be reduced to explicit rules ( autor , ). consequently, com- puterization has disproportionately reduced demand for workers performing \u201croutine\u201d tasks such as data entry, bookkeeping, and assembly line work, reducing wages in these jobs ( acemoglu and autor , ). at the same time, computerization has also increased the demand for workers who for instance, a model would keep track of \u201cthe, \u201d instead of only \u201cthe\u201d (if \u201cthe\u201d was the first word in the sentence). for instance, has recently been shown to outperform humans in taking the us legal bar exam ( liu et , ; bubeck et , ; openai , ). possess complementary skills such as programming, data analysis, and research. together, these changes have contributed to increasing wage inequality in the united states and have been linked to a variety of organizational changes ( and , ; autor et , ; michaels et , ; bresnahan et , ; and hubbard , ; , ). in contrast, generative AI tools do not require explicit instructions to perform tasks. if asked to write an email denying an employee a raise, generative AI tools will likely respond with a professional and conciliatory note. this occurs because the model will have seen many examples of workplace communication in which requests are declined in this manner. importantly, the model produces such an output even though no programmer has explicitly specified what tone would be appropriate for what context, nor even defined what a tone like \u201cprofessional\u201d or \u201cconciliatory\u201d means. indeed, the ability to behave \u201cappropriately\u201d is one that cannot be fully articulated even by those who possess it. rather, people learn to do so from experience and apply unconscious rules in the process. this type of \u201ctacit knowledge\u201d underlies most tasks humans perform, both in and out of the workplace ( polanyi , ; autor , ). the fact that generative AI models display such skills suggests that they can acquire tacit knowledge that is embedded in the training examples they encounter. this ability expands the types of tasks that computers may be capable of performing to include non-routine tasks that rely on judgment and experience. for example, , an ai tool that generates code suggestions for programmers, has achieved impressive performance on technical coding questions and, if asked, can provide natural language explanations of how the code it produces works ( nguyen and nadi , ; zhao , ). meanwhile, \u201cai-assistant\u201d services such as claude can be used to produce convincing business case analyses, including reading and interpreting financial statements and offering strategic assessments. because many of these tasks\u2014coding, financial analysis, etc.\u2014 are currently performed by workers who have either been insulated or benefited from prior waves of technology adoption, the expansion of generative AI has the potential to shift the relationship between technology, labor productivity, and inequality ( , ). generative AI tools can not only expand the types of tasks that machines can perform, they may also reveal valuable information about how the most productive human workers differ from others. this is because the ml models underlying generative AI systems are commonly trained on data generated by human workers and, consequently, encounter many examples of people performing tasks both well and poorly. in learning to predict good outcomes on such data, ml models may implicitly identify characteristics or patterns of behavior that distinguish high and low performers, including subtleties rooted in tacit knowledge. generative AI systems then take this knowledge and use it to produce new behaviors that embody what top performers might do. this ability could be used in different ways: firms may choose to replace lower-skill workers with ai-based tools, such tools could be used to demonstrate best practices to help lower-skill workers improve or help less experienced workers get up to speed more quickly. in either case, generative AI tools may have differential impacts by worker ability, even amongst workers performing the same tasks. despite their potential, generative AI tools face significant challenges in real-world applications. at a technical level, popular llm-based tools, such as chat, have been shown to produce false or misleading information in unpredictable ways, generating concern about their ability to be reliable in high-stakes situations. second, while llm models often perform well on specific tasks in the lab ( openai , ; peng et , b ; noy and zhang , ), the types of problem that workers encounter in real-world settings are likely to be broader and less predictable. this raises concerns both about whether ai tools will be able to provide accurate assistance in every circumstance and\u2014 perhaps more importantly\u2014about whether workers will be able to distinguish cases where ai tools are effective from those where they are not. finally, the efficacy of new technologies is likely to depend on how they interact with existing workplace structures. promising technologies may have more limited effects in practice due to the need for complementary organizational investments, skill development, or business process redesign. because generative AI technologies are only beginning to be used in the workplace, little is currently known about their impacts. ", "## our setting: llms for customer support **.** **customer support and generative AI** we study the impact of generative AI in the customer service industry, an area with one of the high- est surveyed rates of ai adoption. customer support interactions are important for maintaining a company\u2019s reputation and building strong customer relationships, yet, as in many industries, there is substantial variation in worker productivity ( . , ; , ). newer workers are also often less productive and require significant training. at the same time, turnover is high: industry estimates suggest that % of agents in contact centers leave , costing firms $, to $, dollars per agent ( buesing . , ; gretz and jacobson , ). to address these workforce challenges, the average supervisor spends at least hours per week coaching agents with lower performance ( . , ). faced with variable productivity, high turnover, and high training costs, firms are increasingly turning to ai tools ( chui . , ). for instance, of the businesses that report using ai, % use ai in their customer service centers ( chui . , ). at a technical level, customer support is well-suited for current generative AI tools. from an ai\u2019s perspective, customer-agent conversations can be thought of as a series of pattern-matching problems in which one is looking for an optimal sequence of actions. when confronted with an issue such as \u201ci can\u2019t login,\u201d an ai/agent must identify which types of underlying problems are most likely to lead a customer to be unable to log in and think about which solutions typically resolve these problems (\u201ccan you check that caps lock is not on?\u201d). at the same time, they must be attuned to a customer\u2019s emotional response, making sure to use language that increases the likelihood that a customer will respond positively (\u201cthat wasn\u2019t stupid of you at all! i always forget to check that too!\u201d). because customer service conversations are widely recorded and digitized, pre-trained llms can be fine-tuned for customer service using many examples of both successfully and unsuccessfully resolved conversations. customer service is also a setting where there is high variability in the abilities of individual agents. for example, top-performing agents are often more effective at diagnosing the underlying technical issue given a customer\u2019s problem description. these workers often ask more questions before settling on a diagnosis of the problem; this takes longer initially, but reduces the likelihood that agents waste time trying to resolve the wrong problem. such differences in agent behavior can often be inferred from the large amounts of training data that customer-service-specific ai models have access to. as a result, customer service is also a setting in which generative AI models can potentially encode some of the \u201cbest practices\u201d that top-performing agents use. in the remainder of this section, we provide details about the firm we study and the ai tool they adopt. **.** **data firm background** we work with a company that provides ai-based customer service support software (hereafter, the \u201cai firm\u201d) to study the deployment of their tool at one of their client firms, (hereafter, the \u201cdata firm\u201d). our data firm is a fortune enterprise software company that specializes in business process software for small and medium-sized businesses in the united states. it employs a variety of chat-based technical support agents, both directly and through third-party firms. the majority of agents in our sample work from offices located in the philippines, with a smaller group working in the united states and in other countries. across locations, agents are engaged in a fairly uniform job: answering technical support questions from us-based small business owners. chats are randomly assigned, and support sessions are relatively lengthy, averaging minutes, with much of the conversation spent trying to diagnose the underlying technical problem. the job requires a combination of detailed product knowledge, problem solving skills, and the ability to deal with frustrated customers. our firm measures productivity using three metrics that are standard in the customer service industry: \u201caverage handle time,\u201d the average time an agent takes to finish a chat; \u201cresolution rate,\u201d the share of conversations that the agent successfully resolves; and \u201cnet promoter score,\u201d (customer satisfaction), which is calculated by randomly surveying customers after a chat and calculating the percentage of customers who would recommend an agent minus the percentage who would not. a productive agent is able to field customer chats quickly while maintaining a high resolution rate and net promoter score. across locations, agents are organized into teams with a manager who provides feedback and training to agents. once a week, managers hold one-on-one feedback sessions with each agent. for example, a manager might share the solution to a new software bug, explain the implication of a tax change, or suggest how to better manage customer frustration with technical issues. agents work individually, and the quality of their output does not directly affect others. agents are paid an hourly wage and bonuses based on their performance relative to other agents. **.** **ai system design** the ai system we study combines a recent version of with additional ml algorithms specifically fine-tuned to focus on customer service interactions. the system is further trained on a large set of customer-agent conversations that have been labeled with a variety of outcomes and characteristics: whether the call was successfully resolved, how long it took to handle the call, and whether the agent in charge of the call is considered a \u201ctop\u201d by the data firm. the ai firm then uses these data to look for conversational patterns that are most predictive of call resolution and handle time. the ai firm further trains its model using a process similar in spirit to al. ( ) to prioritize agent responses that express empathy, provide appropriate technical documentation, and limit unprofessional language. this additional training mitigates some of the concerns associated with relying on llms to generate text. once deployed, the ai system generates two main types of output: ) real-time suggestions for how agents should respond to customers and ) links to the data firm\u2019s internal documenta- tion for relevant technical issues. in both cases, recommendations are based on a history of the conversation. for example, the correct response when a customer says \u201ci can\u2019t track my employee\u2019s hours during business trips\u201d depends on what version of the data firm\u2019s software the customer uses. suppose that the customer has previously mentioned that they are using the premium version. in that case, they should have access to remote mobile device figure illustrates an example of ai assistance. in the chat window (panel a), , the customer, describes their problem to the agent. here, the ai assistant generates two suggested responses (panel b). in this example, it has learned that phrases like \u201ci can definitely assist you with this!\u201d and \u201chappy to help you get this fixed asap\u201d are associated with positive outcomes. panel a of appendix figure a. shows an example of a technical recommendation from the ai system, which occurs when it recommends a link to the data firm\u2019s internal technical documentation. importantly, the ai system we study is designed to augment, rather than replace, human agents. the output is shown only to the agent, who has full discretion over whether to incorporate (fully or partially) the ai suggestions. this reduces the likelihood that off-topic or incorrect outputs make their way into customer conversations. furthermore, the system does not provide suggestions when it has insufficient training data for that situation. in these situations, the agent must respond on their own. ", "## deployment, data, and empirical strategy **.** **ai model deployment** the ai assistant we study was gradually rolled out at the agent level after an initial randomized pilot featuring agents. the deployment was largely uniform across both the data firm\u2019s own customer service agents and its outsourced agents. appendix figure a. documents the progression of deployment among agents who are eventually treated. the bulk of the adoption occurs between and . **.** **summary statistics** table provides details on sample characteristics, divided into three groups: agents who are never given access to the ai tool during our sample period (\u201cnever treated\u201d), pre-ai observations for those who are eventually given access (\u201ctreated, pre\u201d), and post-ai observations (\u201ctreated, post\u201d). in total, we observe the conversation text and outcomes associated with million chats by , agents. within this, we observe . million chats by , agents in the post-ai period. most agents in our sample, %, are located outside of the united states, primarily in the philippines. for each agent, we observe their assigned manager, tenure, geographic location, and firm information. timekeeping, meaning that the support agents need to diagnose and resolve a technical issue that prevents the software from working. if, however, the customer stated that they are using the standard version, then the correct solution is for the customer to upgrade to the premium version in order to access this feature. for more on context tracking, see, for instance, dunn et ( ). data from the rct is included as part of our primary analysis but is not analyzed separately because of its small sample size. to examine the impacts of this deployment, we construct several key variables, all aggregated to the agent-month level, which is our primary level of analysis. our primary measure of productivity is resolutions per hour (), the number of chats a worker is able to successfully resolve per hour. we consider this measure to be the most effective summary of a worker\u2019s productivity at the firm. an agent\u2019s is determined by several factors: the average time it takes an agent to complete a conversation, the number of conversations they are able to handle per hour (accounting for multiple simultaneous conversations), and the share of conversations that are successfully resolved. we measure these individually as, respectively, average handle time (aht), chats per hour (cph), and resolution rate (rr). in addition, we also observe a measure of customer satisfaction through an agent\u2019s net promoter score (nps), which is collected by the firm from post-call customer surveys. we observe these measures for different numbers of agents. in particular, we are able to recon- struct measures of average handle time and chats per hour from our chat level data. we therefore observe aht and cph measures for all agents in our sample. measures that involve an understand- ing of call quality\u2014resolution rates, and customer satisfaction\u2014are provided at the agent-month level by our data firm. because our data firm outsources most of its customer service functions, it does not have direct control over this information, which is kept by subcontracted firms. as a result, we observe resolution rates and net promoter scores for a subset of agents in our data. this, in turn, means that we only observe our omnibus productivity measure\u2014resolutions per hour\u2014for this smaller subset. figure plots the raw distributions of our outcomes for each of the never, pre-, and post- treatment subgroups. several of our main results are readily visible in these raw data. in panels a through d, we see that post-treatment agents do better along a range of outcomes, relative to both never-treated agents and pre-treatment agents. in panel e, we see no discernible differences in surveyed customer satisfaction among treated and non-treated groups. focusing on our main productivity measure, panel a of figure and table show that never- treated agents resolve an average of . chats per hour, whereas post-treatment agents resolve . chats per hour. some of this difference may be due to differences in the initial section: treated agents have higher resolutions per hour prior to ai model deployment (. chats) relative to never treated agents (.). this same pattern appears for chats per hour (panel c) and resolution rates (panel d): while ever-treated agents appear to be stronger performers at the outset than agents who are never treated, post-treatment agents perform substantially better. when looking instead at average handle times (panel b), we see a starker pattern: pre-treatment and never-treated agents have similar distributions of average handle times, centered at minutes, but post-treatment agents have a lower average handle time of minutes. these figures, of course, reflect raw differences that do not account for potential confounding factors such as differences in agent experience or differences in selection into treatment. in the next section, we will more precisely attribute these raw differences to the impact of ai model deployment. **.** **empirical strategy** we isolate the causal impact of access to ai recommendations using a standard difference-in- differences regression: _y_ _it_ _\u03b4_ _t_ _\u03b1_ _i_ __ _it_ _\u03b3x_ _it_ _\u03f5_ _it_ () \u201c ` ` ` ` our outcome variables _y_ _it_ capture various measures of productivity for agent _i_ in _t_ , as outlined earlier. because workers often work only for a portion of , we include only observations for an agent who is actively employed (e.g. assigned to chats). our main variable of interest is _ai_ _it_ , an indicator equal to one if agent _i_ has access to ai recommendations at time _t_ . all regressions include fixed effects _\u03b4_ _t_ to control for common, time-varying factors such as tax season or the end of the business quarter. in our preferred specification, we also include controls for time-invariant agent-level fixed effects _\u03b1_ _i_ and time-varying agent tenure. standard errors are clustered at the agent level. a rapidly growing literature has shown that two-way fixed effects regressions deliver consistent estimates only with strong assumptions about the homogeneity of treatment effects, and may be biased when treatment effects vary over time or by adoption cohort ( cengiz et , ; de chaise- and d\u2019haultf\u0153uille , ; and , ; goodman-bacon , ; callaway and , ; borusyak et , ). for example, workers may take time to adjust to using the ai system, in which case its impact in may be smaller. alternatively, the onboarding of later cohorts of agents may be smoother, so that their treatment effects may be larger. we study the dynamics of treatment effects using the interaction weighted (iw) estimator pro- posed in and ( ). and ( ) show that this estimator is consistent assuming parallel trends, no anticipatory behavior, and cohort-specific treatment effects that follow the same dynamic profile. in the appendix, we show that both our main differences-in-differences and event study estimates are similar using robust estimators introduced in de chaise and d\u2019haultf\u0153uille ( ), borusyak et ( ), callaway and ( ), and and abra- ham ( ), as well as using traditional two-way fixed effects ols. this last assumption means that treatment effects are allowed to vary over event-time and that average treatment effects can vary across adoption-cohorts (because even if they follow the same event-time profile, we observe different cohorts for different periods of event-time). ", "## main results **.** **productivity metrics** table examines the impact of the deployment of the ai model on our primary measure of produc- tivity, resolutions per hour, using a standard two-way fixed effects model. in column , we show that, controlling for time and location fixed effects, access to ai recommendations increases resolu- tions per hour by . chats, up .% from an average of .. in column , we include fixed effects for individual agents to account for potential differences between treated and untreated agents. in column , we include additional controls for the time-varying agent tenure. as we add controls, our effects fall slightly, so that, with agent and tenure fixed effects, we find that the deployment of ai increases rph by . chats or .%. through produce these same patterns and magnitudes for the log of rph. appendix table a. finds similar results using alternative difference-in-difference estimators in- troduced in callaway and ( ), borusyak et ( ), de chaisemartin and d\u2019haultf\u0153uille ( ), and sun and ( ). unlike traditional ols, these estimators avoid comparing be- tween newly treated and already treated units. in most cases, we find larger effects of ai assistance using these alternatives. figure shows the accompanying iw event study estimates of sun and ( ) for the impact of ai assistance on rph, in levels and logs. for both outcomes, we find a substantial and immediate increase in productivity in of deployment. this effect grows slightly in and remains stable and persistent up to the end of our sample. appendix figure a. shows that this pattern can be seen using alternative event study estimators as well: callaway and ( ), borusyak et ( ), de chaisemartin and d\u2019haultf\u0153uille ( ), and traditional two-way fixed effects. in table , we report additional results using our preferred specification with , agent, and agent tenure fixed effects. column documents a . minute decrease in the average duration of customer chats, a % decline from the baseline mean (shorter handle times are generally considered better). next, column indicates a . unit increase in the number of chats that an agent can handle per hour. relative to a baseline mean of ., this represents an increase of roughly %. unlike average handle time, chats per hour account for the possibility that agents may handle multiple chats simultaneously. the fact that we find a stronger effect on this outcome suggests that ai enables agents to both speed up chats and multitask more effectively. column of table indicates a small . percentage point increase in chat resolution rates, significant at the % level. this effect is economically modest, given a high baseline resolution rate of %; we interpret this as evidence that improvements in chat handling do not come at the expense of problem solving on average. finally, column finds no economically significant change in customer satisfaction, as measured by net promoter scores: the coefficient is -. percentage points and the mean is .%. through report these results for logged outcomes. going forward, we will report our estimates in logs, for ease of interpretation. figure presents the accompanying event studies for additional outcomes. we see immediate impacts on average handle time (panel a) and chats per hour (panel b), and relatively flat patterns for resolution rate (panel c) and customer satisfaction (). we therefore interpret these find- ings as saying that, on average, ai assistance increases productivity without negatively impacting resolution rates and surveyed customer satisfaction. **.** **impacts by agent skill and tenure** there is substantial debate about the distributional consequences of ai-based technologies on worker productivity. an extensive literature suggests earlier waves of information and communication tech- nology (e.g., the internet, computers, network-based communication) have complemented high-skill workers, increasing their productivity and labor demand and widening wage differentials. gen- erative ai tools, however, are based on machine learning tools that rely on looking for patterns associated with success. as discussed earlier, generative AI tools may have a different pattern of productivity consequences relative to earlier waves of technology adoption. in this section, we ex- amine whether access to ai assistance has different impacts along two dimensions: worker skill and worker experience. **..** **pre-treatment worker skill** in panel a of figure , we consider how our estimated productivity effects differ by an agent\u2019s pre-ai productivity. we divide agents into quintiles using a skill index based on their average call efficiency, resolution rate, and surveyed customer satisfaction in prior to the adoption of the ai system. these skill quintiles are defined within . to isolate the impact of worker skill, we also control for worker tenure at ai deployment. in panel a, we show that the productivity impact of ai assistance is most pronounced for workers in the lowest skill quintile (leftmost side), who see a % increase in resolutions per hour. in contrast, ai assistance does not lead to any productivity increase for the most skilled workers (rightmost side). in figure we show that less-skilled agents consistently see the largest gains across our other outcomes. for the highest-skilled workers, we find mixed results: a zero effect on average handle time (panel a), a positive effect for chats per hour (panel b), and, interestingly, a small but statistically significant _decreases_ in resolution rates and customer satisfaction (panels c and d). these results are consistent with the idea that generative AI tools may function by exposing lower-skill workers to the best practices of higher-skill workers. lower-skill workers benefit because ai assistance provides them with new solutions, whereas the best performers may see little benefit from being exposed to their own best practices. indeed, the fact that we find negative effects along measures of chat quality\u2014resolution rate and customer satisfaction\u2014suggests that ai recommendations may distract top performers, or lead them to choose the faster option (following suggestions) rather than taking the time to come up with their own responses. **..** **pre-treatment worker experience** next, we repeat our previous analysis for agent tenure. to do so, we divide agents into five groups based on their tenure at the time the ai model is introduced. some agents have of tenure when they receive ai access, while others have of experience. to isolate the impact of worker tenure, we control for worker skill when given access to the ai. in panel b of figure , we see a clear, monotonic pattern in which the least experienced agents see the greatest gains in resolutions per hour. agents with of tenure improve their resolutions per hour by almost % (relative to agents of the same tenure who do not have access to ai assistance). in contrast, we see no effect for agents with of tenure. in figure , we show the same patterns for other outcomes. in panels a and b, we see that ai assistance generates large gains in call handling efficiency, measured by average handle times and chats per hour, respectively, among the newest workers. in panels c and d, we find positive impacts of ai assistance on chat quality, as measured by resolution rates and customer satisfaction, respectively. for the most experienced workers, we see modest positive effects for average handle time (panel a), positive but statistically insignificant effects on chats per hour (panel b), and small but statistically significant negative effects for measures of call quality and customer satisfaction (panels c and d). **..** **moving down the experience curve** to further explore how ai assistance impacts newer workers, we examine how worker productivity evolves on the job. in figure , we plot productivity variables by agent tenure for three distinct groups: agents who never receive access to the ai model (\u201cnever treated\u201d), those who have access we avoid the term \u201clearning curve\u201d because we cannot distinguish if workers are learning or merely following recommendations. from the time they join the firm (\u201calways treated\u201d), and those who receive access in with the firm (\u201ctreated mo.\u201d). we see that all agents begin with around . resolutions per hour. workers who are never treated (blue line) slowly improve their productivity with experience, reaching approximately . resolutions per hour . in contrast, workers who always have access to ai assistance (red line) increase their productivity to . resolutions per hour after and continue to improve until they are resolving more than chats per hour after of tenure. comparing just these two groups suggests that access to ai recommendations helps workers move more quickly down the experience curve. the final group in panel a tracks workers who begin their tenure with the firm without access to ai assistance, but who receive access after on the job (green line). these workers improve slowly in the same way as never-treated workers for the first of their tenure. starting in , however, these workers gain access and we see their productivity rapidly increase following the same trajectory as the always-treated agents. in appendix figure a. , we plot these curves for other outcomes. we see clear evidence that the experience curve for always- treated agents is steeper for handle time, chats per hour, and resolution rates (panels a through c). follows a similar but noisier pattern for customer satisfaction. together, these results indicate that access to ai helps new agents move more quickly down the experience curve. across many of the outcomes in figure , agents with of tenure and access to ai assistance perform as well as or better than agents with of tenure who do not have access. ", "## adherence, learning, and conversational change in this section, we conduct a variety of analyses aimed at better understanding the mechanisms behind our main results. first, we examine how workers engage with ai recommendations. we show that workers are selective about the recommendations they adopt, following the recommendations % on average. we find that the returns to ai assistance are highest for workers who choose to follow recommen- dations. consistent with a story in which workers find ai recommendations helpful, we show that adherence rates increase over time for all workers, especially among older workers: by the end of our sample, we see similar adherence rates across worker tenure and skill. our sample ends here because we have very few observations after treatment. second, we explore whether ai-assistance helps workers learn. using information on software outages in which ai assistance is temporarily unavailable, we provide evidence that exposure to ai leads to durable changes in worker skills. we find that workers exposed to ai recommendations continue to perform better during outages, and this effect is greater after more exposure and for agents who more closely follow ai recommendations when the software is working. lastly, using text-based analysis of chat records themselves, we provide suggestive evidence that ai assistance changes the content of agents\u2019 communication. we document within-agent changes in communication following ai deployment, with larger changes for lower-skill workers. across- person, we show that these changes increase the similarity of communication patterns between low- and high-skill agents. these results are consistent with ai recommendations leading lower-skill workers to communicate more like high-skill workers. taken together, our results suggest that examining and following ai recommendations helps workers\u2014particularly lower-skilled workers\u2014learn to adopt best practices gathered from higher- skill and more experienced agents. **.** **adherence to ai recommendations** the ai tool we study makes suggestions, but agents are ultimately responsible for what they say to the customer. in our main results, we estimate how access to the ai tool impacts outcomes regardless of how frequently agents follow its recommendations. here, we examine how closely agents adhere to ai recommendations, and document the association between adherence and returns to adoption. we measure \u201cadherence\u201d starting at the chat level, using the share of ai recommendations that each agent follows. our ai firm codes agents as having adhered to a recommendation if they either click to copy the suggested ai text or if they self-input something very similar. we take this chat-level measure and aggregate it to the agent-month level. panel a of figure shows the distribution of average agent-month-level adherence for our post- ai sample, weighted by the log number of ai recommendations provided to that agent in . the average adherence rate is %, with an interquartile range of % to %: agents frequently ignore recommendations. in fact, the share of recommendations followed is similar to the share of other publicly reported numbers for generative AI tools; a study of github copilot reports that individual developers use % to % of code recommendations ( zhao , ). such behavior may be appropriate, given that ai models may make incorrect or irrelevant suggestions. panel b of figure shows that _returns_ to ai model deployment are higher when agents actually follow recommendations. to show this, we divide agents into quintiles based on the percent of ai recommendations they follow in of ai access and separately estimate the impact of ai assistance for each group. these estimates control for and agent fixed effects as in column of table . we find a steady and monotonic increase in returns by agent adherence: among agents in the lowest quintile, we still see a % gain in productivity, but for agents in the highest quintile, the estimated impact is over twice as high, close to %. appendix figure a. shows the results for our other four outcome measures. the positive correlation between adherence and returns holds most strongly for average handle time (panel a) and chats per hour (panel b), and more noisily for resolution rate (panel c) and customer satisfaction (panel d). our results are consistent with there being a treatment effect of following ai recommendations on productivity. we note, however, that this relationship could also be driven by other factors: selection (agents who choose to adhere are more productive for other reasons); or selection on gains (agents who follow recommendations are those with the greatest returns). to further explore this, we consider worker\u2019s revealed preference: do they continue to follow ai recommendations over time? if our results were driven purely by selection, we would expect workers with low adherence to continue having low adherence, since it was optimal for them to do so. figure plots the evolution of ai adherence over time, for various categories of agents. panel a begins by considering agents who differ in their initial ai compliance, which we categorize based on terciles of ai adherence in of model deployment. here, we see that compliance either stays stable or grows over time. the most initially compliant agents continue to comply at the same rates (just above %). less initially compliant agents increase their compliance over time: those in the bottom tercile initially follow recommendations less than % of the time but, by , their compliance rates have increased by over %, to just over half of the time. next, panel b divides workers up by tenure at the time of ai deployment. more senior workers are initially less likely to follow ai recommendations: % for those with of tenure compared to % for those with of tenure. over time, however, all workers increase their adherence, with more senior workers doing so faster so that the groups converge after deployment. in panel c, we show the same analysis by worker skill at ai deployment. here, we see that compliance rates are similar across skill groups, and all groups increase their compliance over time. the results in figure are consistent with agents\u2013particularly those who are initially more skeptical\u2014coming to value ai recommendations over time. an alternative hypothesis, however, is that agents who dislike working with ai assistance exit the firm at higher rates. in appendix figure a. we repeat the analysis above, focusing on within-agent changes in adherence (that is, adherence rates residualized by agent fixed effects). our within-agent results follow a similar pattern: all workers increase adherence over time, and these increases appear largest for workers who were initially the least compliant and workers who were the most senior. this suggests that increases in adherence over time are not driven exclusively by selection. **.** **worker learning** a key question raised by our findings so far is whether these improvements in productivity and changes in communication patterns reflect durable changes in the human capital of workers or simply their growing reliance on ai assistance. to study this, we examine how workers perform during periods in which they are not able to access ai-recommendations due to technical issues at the ai firm. outages occur occasionally in our data and can last anywhere from a few minutes to a few hours. during an outage, the system fails to provide recommendations to some, but not necessarily all, workers. for example, outages may affect agents who log into their computers after the system crashes, but not agents working at the same time who had signed in earlier. they may also affect workers using one physical server but not another. our ai firm tracks the most significant outages in order to perform technical reviews of what went wrong. we compile these system reports to identify periods in which a significant fraction of chats are impacted by outages. appendix figure a. shows an example of such an outage, which occurred on , . the _y_ -axis plots the share of post-treatment chats (e.g. those occurring after the ai system has been deployed for a given agent) for which the ai software does not provide any suggestions, aggregated to the hour level. the _x_ -axis tracks hours in leading up to and following the outage event (hours with fewer than post-treatment chats are plotted as zeros for figure clarity). during non-outage periods, the share of chats without ai recommendations is typically -%. this reflects the fact that the ai system does not generate recommendations in response to all messages, even when it is functioning properly. because many chats are short, it is common to see chats end without the ai system intervening. on the morning of th, however, we see a notable spike in the number of chats without recommendations, increasing to almost %. records from our ai firm indicate that this outage was caused by a software engineer running a load test that crashed the system. figure examines the impact of access to the ai system for chats that occur during and outside these outage periods. whereas our main event study regressions are at the worker-month level, these are at the chat level, in order to more precisely compare conversations that occurred during outage periods, versus those that did not. panel a considers the impact of the introduction of ai assistance on chat duration (shorter is more efficient), using only post-adoption periods in which no outages are reported. consistent with our main results, we see an immediate decline in the duration of individual chats by approximately % to %. in panel b, we use the same pre-treatment observations, but now restrict to post-adoption periods that are impacted by large outages. we first note that our estimates are noisy and their magnitude appears larger than for non-outage periods (% to % declines in chat duration). because ai outages are rare and not necessarily random, this may reflect differences in the types of chats that are seen during outage periods than during non-outage periods. however, focusing on the size of estimated effects over time, an interesting pattern emerges. rather than declining immediately post-adoption and staying largely stable as we see in panel a for non-outage periods, panel b shows that the benefit of exposure to ai assistance increases with time during outage periods. that is, if an outage occurs one month after ai adoption, workers do not handle the chat much more quickly than their pre-adoption baseline. yet, if an outage occurs after of exposure to ai recommendations, workers handle the chat faster\u2014even though they are not receiving direct ai assistance. in figure , we split our main outage event studies by worker\u2019s initial ai adherence, as described in section . . panel a shows that workers with high initial ai adherence see large and fast declines in chat processing times (relative to their pre-adoption baseline), even during outages. panel b, in contrast, shows no such impact for workers who tend to deviate from ai recommendations: they see no improvement in chat times during outage periods, even after of ai access. these findings suggest that workers learn more by actively using ai suggestions. together, these results suggest that generative AI tools can help workers develop durable skills. prior to the deployment of ai-assistance, agents only received training from managers during brief coaching sessions. during these sessions, managers would go through several conversations from and advise the worker on how they might have handled certain conversations better. however, by necessity, managers can only provide feedback on a small fraction of the conversations that an agent conducts. moreover, because managers are often pressed for time and may lack training, they may simply point out weak metrics (\u201cyou need to lower your handle time\u201d) rather than identifying strategies for how an agent could better approach a problem (\u201cyou need to ask more questions at the beginning to diagnose the issue better.\u201d) this type of coaching is ineffective and can be counterproductive for employee engagement ( . , ). in contrast, ai assistance provides workers with specific, actionable suggestions in real time. our findings suggest that this can play a useful role in supplementing existing on-the-job training programs. **.** **conversational change** lastly, we consider how access to ai assistance influences how workers communicate. to capture an overall sense of the content of conversations, we begin by creating embeddings of agent- customer conversations. embeddings take a given body of text and transform it into a high-dimensional vector that represents its \u201ccoordinates\u201d in linguistic space. two pieces of text will have more similar coordinates if they share a common meaning or style. the specific embedding given to a body of text will depend on the embedding model that is used. we form our text embeddings using all-minilm-l-v, an llm that is specifically intended to capture and cluster semantic information to assess similarity across text ( hugging face , ). once we create an embedding for each conversation, we can compare the similarity of conversations by looking at the cosine similarities of their associated vectors; this common approach yields a score of if two pieces of text are semantically orthogonal and a score of if they have the same meaning ( , ). for context, the sentences \u201ccan you help me with logging in?\u201d and \u201cwhy is my login not working?\u201d have a cosine similarity of _._ in our model. using this approach, we first show that ai assistance changes the content of what agents write to customer, rather than just typing the same things faster. second, we explore how these patterns differ for high- and low-skill workers. we are particularly interested in understanding whether ai models can disseminate the behaviors of high performers. if this is the case, then we would expect ai assistance to lead lower-performing agents to write more like high-performers. **..** **within-worker changes in communication** we begin by examining how an agent\u2019s communication evolves over time, before and after access to ai assistance. we begin by examining treated workers and comparing the similarity of their chats in each given event-time week to their chats from before ai deployment (week - to week -). we exclude messages from the customer and focus only on agent-generated language. panel a of figure plots the cosine similarity associated with these comparisons, we find that similarity to the pre-ai window is stable in leading up to the ai roll-out and drops immediately following ai deployment. that is, conversations before deployment are quite similar to conversations before, but conversations after are all less similar. this drop in similarity is broadly inconsistent with the idea that ai assistance merely leads workers to type the same things but faster. if that were the case, we would expect call handle times to drop, but similarity to remain constant. next, panel b of figure compares the magnitude of this pre- versus post-deployment change in content varies by pre-ai worker skill. we find that lower-skill agents (those in the bottom quintile of the pre-ai skill distribution) experience greater change after ai adoption, relative to top performers (those in the top quintile). our results here control for firm- fixed effects, which can account for seasonal changes in topics such as tax or payroll cycles, or new product rollouts. we also control for agent tenure fixed effects, which can account for the possibility that younger workers\u2019 language may evolve more quickly independent of access to the ai model. although we cannot control directly for the chat topic, we note that chat topics are randomly assigned to agents, so we would not expect differences in topics to vary systematically by agent skill. we interpret these results as providing suggestive evidence that ai deployment shifts the communication patterns of low-skill workers more than high-skill workers. **..** **across worker comparisons** figure considers whether individual level changes in communication lead low- and high-skill workers to sound more alike. to examine this, we plot the cosine similarity between high- and low-skill agents at specific moments in calendar time, separately for workers with (blue dots) and without (red diamonds) access to ai assistance. among agents without ai access, we define high- and low-skill agents as those who are in the top or bottom quintile of our skill index for . among agents with ai access, we define high- and low-skill agents based on whether they are in the top or bottom quintile of skill at the time of ai deployment. focusing on the blue dots, we see that the average similarity between high- and low- productivity workers is . among workers who do not have access to ai assistance. this figure is lower than our average within-person text similarity, which makes sense given that within-person changes are likely to be smaller than across-person differences. we see, moreover, that this similarity is stable over time, indicating that high- and low-skill workers do not appear to be trending differently in the absence of ai assistance. turning to the red diamonds, we see that, post-ai adoption, high- and low-skilled workers begin to use language that is more similar. the magnitude of this change\u2014moving from . similarity to . similarity\u2014may appear small, but given that the average within-person similarity for high- skill workers is around ., this result suggests that ai assistance is associated with a substantial narrowing of language gaps. together, the patterns in figures and suggest that low-skill workers are converging toward high-skill workers, rather than the opposite. this finding is consistent with ai models disseminating the behaviors of high-skilled workers to lower-skilled workers. in such a scenario, we would expect low-skill workers to change their communication patterns more following ai-deployment. top per- formers, meanwhile, would change less because the ai model is more likely to suggest language they already use. ", "## effects on the experience of work qualitative studies suggest that working conditions for contact center agents can be unpleasant. the repetitive nature of the job, coupled with regular exposure to challenging and emotionally charged conversations, can contribute to burnout and high turnover rates. additionally, contact center work for us-based businesses is frequently outsourced to lower-income countries such as india and the philippines, meaning that agents often work difficult hours and may face cultural barriers or judgements when speaking with customers. increases in worker productivity may not neccesarily lead workers to be happier with their jobs, especially if workers feel pressured to work faster and faster. in this section, we examine the impact of generative AI on one key aspect of the workplace experience: how agents are treated by customers, as measured by customer sentiment and requests to speak with a manager. we also examine the impact of ai assistance on worker turnover as an overall indicator of worker satisfaction. **.** **customer sentiment** customers often vent their frustrations on anonymous service agents and, in our data, we see regular instances of swearing, verbal abuse, and \u201cyelling\u201d (typing in all caps). service workers are called upon to absorb such customer frustrations while limiting one\u2019s own emotional reaction ( hochschild , ). the stress associated with this type of emotional labor is often cited as a key cause of burnout and attrition among customer service workers ( ). access to ai-assistance may impact how customers treat agents, but the direction and magnitude of these impacts are ambiguous. ai assistance may improve the tenor of conversations by helping agents set customer expectations or resolve their problems more quickly. alternatively, customers may become more frustrated if ai-suggested language feels \u201ccorporate\u201d or insincere. to assess this, we attempt to capture the affective nature of both agent and customer text, using sentiment analysis ( mejova , ). for this analysis, we use siebert, an llm that is fine-tuned for sentiment analysis using a variety of datasets, including product reviews and tweets ( hartmann . , ). sentiment is measured on a scale from \u00b4 to , where \u00b4 indicates negative sentiment and indicates positive. in a given conversation, we compute separate sentiment scores for both agent and customer text. we then aggregate these chat-level variables into a measure of average agent sentiment and average customer sentiment for each agent-. panel a of figure shows the distribution of customer sentiment scores. on average, customer sentiments in our data are mildly positive and normally distributed around a mean of ., except for a mass of very positive and very negative scores. panel b shows the distribution of sentiments associated with agents: agents are unfailingly positive, with a mean sentiment score of .. this reflects the fact that agents are trained to be extremely polite and friendly, even prior to ai access. panels c and d consider how sentiment scores respond following the roll-out of ai assistance. in panel c, we see an immediate and persistent improvement in customer sentiment. this effect is economically large: according to column of table , access to ai improves the mean customer sentiments (averaged over an agent-month) by . points, equivalent to half of a standard deviation. in panel d, we see no detectable effect for agent sentiment, which is already very high at baseline. column of table indicates that agent sentiments increase by only . points or about % of a standard deviation. focusing on customer sentiment, appendix figure a. examines whether access to ai has dif- ferent impacts for across agents. we find that access to ai assistance significantly improves how customers treat agents of all skill and experience levels, with the largest effects for agents in the lower to lower-middle range of both the skill and tenure distributions. consistent with our productivity results, the highest-performing and most-experienced agents see the smallest benefits of ai access. these results suggest that ai recommendations, which were explicitly designed to prioritize more empathetic responses, may improve agents\u2019 demonstrated social skills and have a positive emotional impact on customers. **.** **customer confidence and managerial escalation** changes in individual worker-level productivity may have broader implications for organizational workflows ( garicano , ; athey . , ; athey and stern , ). in most customer service settings, front-line agents attempt to resolve customer problems but can seek the help of supervisors when they are unsure of how to proceed. customers, knowing this, will sometimes attempt to escalate a conversation by asking to speak to a manager. this type of request generally occurs when the customer feels that the current agent is not equipped to address their problem or becomes frustrated. in figure , consider the impact of access to ai-assistance on the frequency of chat escalation. the outcome variable we focus on is the share of an agent\u2019s chats in which a customer requests to speak to a manager or supervisor, aggregated to the level. we focus on requests for escalation rather than actual escalations both because we lack data on actual escalations and because requests are a better measure of customer confidence in an agent\u2019s competence or authority. following the introduction of ai assistance, we see a gradual decline in requests for escalation. relative to a baseline rate of approximately percentage points, these coefficients suggest that ai assistance generates an almost % decline in customer requests to speak to a manager. in appendix figure a. , we consider how these patterns change by the skill and experience of the worker. consistent with our other results, we find that requests for escalation are disproportionately reduced for agents who were less skilled or less experienced at the time of ai adoption. **.** **attrition** the adoption of generative AI tools can have a variety of impacts on workers: their productivity, the amount of stress they encounter on the job, and how they are perceived by customers, to name a few. while we cannot observe all these factors, we can look at turnover patterns to provide one overarching measure of how workers are impacted by ai technology at work. for this analysis, we compare attrition rates among treated agents to those of untreated agents with the same tenure. we drop observations for treated agents before treatment because they do not experience attrition by construction (they must survive to be treated in the future). our analysis also controls for location and time fixed effects. figure plots the impact of ai access on attrition: panel a considers how this varies by agent tenure while panel b considers heterogeneity by agent skill. consistent with our findings so far, panel a shows that access to ai assistance is associated with the strongest reductions in attrition among newer agents, those with of experience. the magnitude of this coefficient, around percentage points, translates into a % decrease relative to a baseline attrition rate in this group of %. in panel b, we examine attrition by worker skill. here, we find a significant decrease in attrition for all skill groups, but no systematic gradient. finally, we note that these results should be taken with more caution relative to our main results because we are unable to include agent fixed effects to control for unobservable differences between agents with and without access to ai assistance. this is because attrition can only occur once for any given individual. our results may overstate the impact of ai access on attrition if, for example, access to the ai tool is more likely to be given to agents whom the firm believes are more likely to stay. ", "## conclusion advancements in ai technologies open up a broad set of economic possibilities. our paper provides the first empirical evidence of the effects of a generative AI tool in a real-world workplace. in our setting, we find that access to ai-generated recommendations increases worker productivity, improves customer sentiment, and is associated with reductions in employee turnover. we hypothesize that part of the effect we document is driven by the ai system\u2019s ability to embody the best practices of high-skill workers in our firm and make it accessible to other work- ers. these practices may have previously been difficult to disseminate because they involve tacit knowledge. consistent with this, we see that ai assistance leads to substantial improvements in problem resolution and customer satisfaction for newer- and less-skilled workers but does not help the highest-skilled or most-experienced workers on these measures. furthermore, agents who have used the system perform somewhat better even when the system is unexpectedly disabled. ana- lyzing the text of agent conversations, we find suggestive evidence that ai recommendations lead low-skill workers to communicate more like high-skill workers. our findings, and their limitations, point to a variety of directions for future research. most importantly, our results do not capture the potential longer-term impacts of generative AI on skill demand, job design, wages, or customer demand. it is unclear, for example, whether improvements in customer service productivity will lead to more or less demand for customer service workers. if the demand for customer support is inelastic, then generative AI tools may reduce demand and wages in this sector in the long run. alternatively, better product support could lead customers to seek out representatives for a wider range of questions; this, in turn, could increase demand for workers or give them new responsibilities, such as collecting customer feedback for the product development team ( . , ; korinek , ). our findings also raise questions about the nature of worker productivity. traditionally, a support agent\u2019s productivity refers to their ability to help the customers they come in contact with. yet, in a setting where customer service conversations are fed into training datasets, a worker\u2019s productivity also includes their ability to provide ml models with examples of successful behaviors that can be shared with others. in our setting, top performers contribute many of the examples used to train the ai system we study, but they see relatively few improvements in their own productivity as a result. under our data firm\u2019s current pay practices, these workers may even see a reduction in their pay because bonuses are calculated relative to other agents\u2019 performance. our results therefore raise questions about how workers, particularly top performers, should be compensated for the data that they provide to ai systems. finally, as a potential general-purpose technology, generative AI can and will be deployed in a variety of ways, and the effects we find may not generalize across all firms and production processes ( eloundou . , ). for example, our setting has a relatively stable product and a set of technical support questions. in areas where the product or environment is changing rapidly, the relative value of ai recommendations may be different: they may be better able to synthesize changing best practices, or they may actually impede learning by promoting outdated practices observed in historical training data. given the early stage of generative AI, these and other questions deserve further scrutiny. ", "### month onboarded notes : this figure shows the share of agents deployed onto the ai system over the study period. agents are deployed onto the ai system after a training session. the firm ran a small randomized control trial in and of . all data are from the firm\u2019s internal software systems. figure a. : event studies, resolutions per hour . . . . . -. -. -. - - - - - - - - - - to/from ai deployment sun- de chaisemartin-d'haultfoeuille callaway-sant'anna borusyak . twfe ols b. log(resolutions per hour) . . . -. - - - - - - - - - - to/from ai deployment sun- de chaisemartin-d'haultfoeuille callaway-sant'anna borusyak . twfe ols notes : this table presents the effect of ai model deployment on our main productivity outcome, resolutions per hour, using a variety of robust dynamic difference-in-differences estimators introduced in borusyak . ( ), callaway and ( ), de chaisemartin and d\u2019haultf\u0153uille ( ) and sun and ( ) and a standard two-way fixed effects regression model. all regressions include agent level, chat-year fixed effects and controls for agent tenure. standard errors are clustered at the agent level. because of the number of post-treatment periods and high turnover of agents in our sample, we can only estimate five of preperiod using borusyak et al. ( ) and de chaisemartin and d\u2019haultf\u0153uille ( ). figure a. : experience curves by deployment cohort, additional outcomes a. average handle time per hour agent tenure, never treated always treated treated - mo. agent tenure, never treated always treated treated - mo. rate d. customer satisfaction agent tenure, never treated always treated treated - mo. agent tenure, never treated always treated treated - mo. notes : these figures plot the experience curves of three groups of agents over their tenure, the x-axis, against five measures of productivity and performance. the red lines plot the performance of always-treated agents, those who are start work in with the ai and always have access to the ai suggestions. the blue line plots agents who are never treated. the green line plots agents who spend their first four of work without the ai model, and gain access to the ai during on the job. all panels include % confidence intervals. figure a. : heterogeneity of ai impact by initial ai adherence, additional outcomes a. log(average handle time) ) . -. -. . . . initial adherence at ai deployment (%) initial adherence at ai deployment (%) ) d. log(customer satisfaction (nps)) . . . . . -. . -. -. initial adherence at ai deployment (%) initial adherence at ai deployment (%) notes : these figures plot the impact of ai model deployment on additional measures of performance by quintile of initial adherence, the share of ai recommendations followed in of treatment. panel a plots the average handle time or the average duration of each technical support chat. panel b graphs chats per hour, or the number of chats an agent can handle per hour (including working on multiple chats simultaneously). panel c plots the resolution rate, the share of chats successfully resolved, and panel d plots nps, or net promoter score, is an average of surveyed customer satisfaction. all specifications include agent and chat , location, and company fixed effects and controls for agent tenure. all data come from the firm\u2019s internal software systems. figure a. : within-agent ai adherence over time a. by adherence at ai model deployment since ai deployment low adherence med adherence high adherence b. by agent tenure at ai model deployment since ai deployment < mos. - mos. > mos c. by agent skill at ai model deployment since ai deployment low skill med skill high skill notes : this figure plots the residualized percentage of ai suggestions followed by agents as a function of the number of each agent has had access to the ai model, after controlling for agent level fixed effects. in panel a, we divide agents into terciles based on their adherence to ai suggestions in . in panel b, we divide agents into groups based on their tenure at the firm at the time of ai model deployment. in panel c, we divide workers into terciles of pre-deployment productivity as defined by our skill index. all data come from the firm\u2019s internal software systems. figure a. : sample ai outage sep :: sep :: sep :: sep :: sep :: chat date notes : this figure plots the share of post-treatment chats with no ai suggestions during a period of a documented software outage. figure a. : heterogeneity in customer sentiment a. by tenure at ai model deployment . . . . . agent tenure at ai deployment b. by productivity at ai model deployment . . . . . agent tenure at ai deployment notes : each panel of this figure plots the impact of ai model deployment on the mean sentiment per conversation. sentiment refers to the emotion or attitude expressed in the text of the customer chat and ranges from \u00b4 to where \u00b4 indicates very negative sentiment and indicates very positive sentiment. panel a plots the effects of ai model deployment on customer sentiment by agent tenure when ai deployed and panel b plots the impacts by agent ex-ante productivity. all data come from the firm\u2019s internal software systems. average sentiment is measured using siebert, a fine-tuned checkpoint of a roberta, an english language transformer model. figure a. : escalation, heterogeneity by worker tenure and skill a. manager assistance, by pre-ai skill . -. -. -. -. agent tenure at ai deployment b. manager assistance, by pre-ai tenure . -. -. agent tenure at ai deployment notes : panels a and b show the effects of ai on customer requests for manager assistance, by pre-ai agent skill and in by pre-ai agent tenure. all robust standard errors are clustered at the agent location level. all data come from the firm\u2019s internal software systems. table a. : main effects: productivity (log(resolutions per hour)), alternative difference-in-difference estimators point standard estimate error lower bound % confidence interval upper bound % confidence interval twfe-ols . . . . borusyak-jaravel-spiess . . . . callaway- . . . . dechaisemartin-d\u2019haultfoeuille . . . . sun- . . . . notes : this table shows the impact of ai model deployment on the log of our main productivity outcome, resolutions per hour, using robust difference-in-differences estimators introduced in borusyak . ( ), callaway and ( ), de chaisemartin and d\u2019haultf\u0153uille ( ) and sun and ( ). all regressions include agent level, chat-year fixed effects and controls for agent tenure. the standard errors are clustered at the agent level. ", "# generative AI: perspectives from ", "###### how do you think generative AI will affect your field and society going forward? ", "### ai\u2019s great inflection point **, sequoia capital** **professor in the computer** **science department; denning** **co-director of hai** , the number of animal species exploded in a very short time period. there are many theories as to what happened, but one has captured my attention: the sudden onset and ensuing evolution of vision. , visual perception is a major sensory system and the human mind can recognize patterns in the world and generate models or concepts based on these patterns. endowing machines with these capabilities, generative capabilities, has been a dream for many generations of ai scientists. there is a long history of algorithmic attempts at generative models with varying degrees of progress. in , researchers at mit developed the \u201c vision project\u201d to effectively construct \u201ca significant part of the visual system\u201d with technology. this was the beginning of the field of computer vision and image generation. recently, due to the profound and interconnected concepts of deep learning and large data, we seem to have reached an inflection point in the ability of machines to generate language, image, audio, and more. while building ai to see what humans can see was the inspiration for computer vision, we should now be looking beyond this to building ai to see what humans can\u2019t see. how can we use generative AI to augment our vision? though the exact figure is disputed, deaths due to medical error in the u.s. is a significant problem. generative AI models could assist healthcare providers in seeing potential issues that they may have otherwise missed. furthermore, if the mistakes are due to minimal exposure to rare situations, generative AI can create simulated versions of this rare data to further train the ai models or the healthcare providers themselves. additionally, before we even start developing new generative tools, we need to focus on what people want from these tools. in a recent project to benchmark robotics tasks by our lab, before even starting the research, the project team did a largescale user study to ask people how much they would benefit if a robot did these certain tasks for them. the winning tasks were the focus of the research. ", "##### endowing machines with these capabilities, generative capabilities, has been a dream for many generations of ai scientists. to fully realize the significant opportunity that generative AI creates, we need to also evaluate the associated risks. joy buolamwini led a study titled \u201cgender shades,\u201d which found ai systems frequently fail to recognize women and people of color. study results were published in . we continue to see similar bias in generative AI models, specifically for underrepresented populations. **generative AI: perspectives** **from stanford hai** ", "### ai\u2019s great inflection point (cont\uf6c3d) the ability to determine whether an image was generated using ai is also essential. our society is built on trust of citizenship and information. if we cannot easily determine whether an image is ai generated, our trust of any information will erode. in this case, we need to pay special attention to vulnerable populations that may be particularly susceptible to adversarial uses of this technology. the progress in a machine\u2019s capability to generate content is very exciting, as is the potential to explore ai\u2019s ability to see what humans are not able. but we need to be attentive to the ways in which these capabilities will disrupt our everyday lives, our communities, and our role as world citizens. **generative AI: perspectives** **from stanford hai** ", "### the potentials of synthetic patients **, professor** **in the school of engineering; professor** **of bioengineering, of genetics, of** **medicine, and of biomedical data** **science; associate director of** **stanford hai** it is often difficult to get large numbers of patients in clinical trials and it is crucial to have a realistic group of patients who do not receive a therapy in order to compare outcomes with those who do. this is one area within biomedical research where generative AI offers great opportunities. generative AI could make clinical trials more efficient by creating \u201csynthetic\u201d control patients (i.e., fake patients) using data from real patients and their underlying attributes (to be compared with the patients who receive the new therapy). it could even generate synthetic outcomes to describe what happens to these patients if they are untreated. biomedical researchers could then use the outcomes of real patients exposed to a new drug with the synthetic statistical outcomes for the synthetic patients. this could make trials potentially smaller, faster, and less expensive, and thus lead to faster progress in delivering new drugs and diagnostics to clinicians and their patients. in the past, we have used \u201chistorical controls\u201d which are patients who did not have the benefit of the new drug or diagnostic \u2013 and compared their outcomes to patients who received the new drug or diagnostic. synthetic patients could match the real patients more realistically; they are created using knowledge of current medications, diagnostic tools, and standards of practice that were likely different in the historical situation. in the setting of medical education, generative AI could allow us to create patients that are very realistic and could allow medical students to learn how to detect diseases. the ability for generative models to create many variations on a theme could allow students to see multiple cases of the same disease and learn the ways in which these patients can vary. this could give them more experience in seeing a disease and provide a nearly unlimited set of cases for them to practice if they find that certain diseases are more challenging for them to recognize and diagnose. these same generative models could also interact with the students and give them practice eliciting signs and symptoms through conversational interaction. ", "##### this could make trials potentially smaller, faster, and less expensive, and thus lead to faster progress in delivering new drugs and diagnostics. with opportunity comes worry. if synthetic patients are generated from data that does not reflect the population of patients receiving the drug, the patients may be biased. more worrisome, however, is that even the real patients receiving the drug will not reflect the full population, and so synthetic controls could just improve the use of the drugs for a subset of patients and not all \u2013 leading to inequity. while generative technologies can be very useful in accelerating scientific discovery and progress, care must be taken in selecting the data used to generate patients and the models must be examined very carefully for biases that may lead to disparate impact. **generative AI: perspectives** **from stanford hai** ", "### upending healthcare, from patient care to billing **curt langlotz, professor of radiology, of biomedical informatics research, and** **of biomedical data science; director of the center for artificial intelligence in** **medicine and imaging (aimi); associate director of hai** one of the benefits of our healthcare system is that patients can see a variety of specialist physicians who are experts in specific medical disciplines. the downside of our system is that these specialists often aren\u2019t acquainted with the patients they are seeing. imagine a world in which a specialist you are seeing for the first time has already read a succinct summary of your healthcare needs, created by generative AI. during the patient visit, a chatbot based on a foundation model could serve as the physician\u2019s assistant to support more accurate diagnosis and tailored therapy selection. a generative model could draft a clinic note in real time based on the physician-patient interaction, leaving more time for face-to-face discussion. in the back office, generative models could optimize clinic scheduling or simplify generation of medical codes for billing, disease surveillance, and automated follow-up reminders. these new capabilities could improve the accuracy and efficiency of patient care while increasing patient engagement and adherence to therapy. recent federal legislation gives patients the right to access their entire medical record in digital form. as a result, patients are increasingly encountering complex clinical documents that contain obscure medical terms. when a patient returns home from a clinic visit, a foundation model could generate tailored patient education materials and explain their care plan at the appropriate reading level. machine learning models in medicine are critically dependent on large medical datasets that contain examples of disease. we have shown how diffusion models, a type of foundation model, can be modified to create realistic clinical images from text prompts. our results demonstrate that synthetic training data produced by these models can augment real training data to increase diagnostic accuracy. this form of synthetic data could help solve machine learning problems for which training data is scarce, such as the detection and treatment of uncommon diseases. ", "##### during the patient visit, a chatbot \u2026 could serve as the physician\u2019s assistant to support more accurate diagnosis and tailored therapy selection. finally, generative AI\u2019s well-reported challenges with factual correctness are particularly problematic in medicine, where inaccuracies can cause serious harm. recent problems in medicine include incorrect differential diagnosis and invalid scientific citations. we are working to improve the factual correctness of medical explanations from these models so they can achieve an accuracy that is suitable for safe clinical use. **generative AI: perspectives** **from stanford hai** ", "### an ai window into nature **surya ganguli, associate** **professor of applied physics;** **associate director of** ** hai** scientific ideas from the study of nature itself, in the form of nonequilibrium thermodynamics and the reversal of the flow of time, lead to the creation at of the first diffusion model, a key kernel of technology that forms the basis of many successful ai generative models . now, in a virtuous cycle, ai generative models are well poised to deliver considerable insights into nature itself, across biological, physical, and mental realms, with broad implications for solving key societal problems. for example, generative models of proteins can allow us to efficiently explore the space of complex threedimensional protein structures, thereby aiding in the search for proteins with novel and useful functions, including new efficacious medicines. generative AI is starting to be explored in the quantum realm, enabling us to efficiently model strongly correlated states of electrons, with the potential of advancing our understanding of materials science and quantum chemistry. these advances could in turn lead to the creation of new materials and catalysts that could play a role in efficient energy capture and storage. simple generative modeling, intertwined with classical numerical solvers, has also made key advances in accurate and fast large scale fluid mechanical simulations, which when scaled up, could aid in climate modeling and weather forecasting, thereby contributing to a deeper understanding of our changing climate and its ramifications. in a beautiful recursion, the generative AI models that we have created can also act as scientific windows, not only into the physical world but also into our own minds. for the first time, we have ai systems that can model high-level cognitive phenomena like natural language and image understanding. many neuroscientists and cognitive scientists have compared the neural representations of both deep networks and ai generative models to neurobiological representations in humans and animals, often finding striking similarities across many brain areas. examples include the retina, the ventral visual stream, motor cortex, entorhinal cortex for navigation, cortical language areas, and neural geometries underlying few shot concept learning. the often similar structure of artificial and biological solutions to generative tasks suggests there may be some common principles governing how intelligent systems, whether biological or artificial, model and generate complex data. ", "##### ai generative models are well poised to deliver considerable insights into nature itself, across biological, physical, and mental realms, with broad implications for solving key societal problems. **generative AI: perspectives** **from stanford hai** ", "### an ai window into nature (cont\uf6c3d) an exceedingly interesting and profound question arises in the forthcoming age of scientific collaboration between humans and ai systems as they work together in a loop to analyze our complex biological, physical, and mental worlds: what does it mean for a human to derive an interpretable understanding of a complex system when an ai provides a substantial part of that understanding through predictive models? issues regarding explainable ai will likely rise to the fore when a fundamentally human scientific endeavor, namely understanding our world, is partially achieved through the use of ai. human scientists will not be content with uninterpretable ai-generated predictions alone. they will desire _human interpretable_ _understanding_ , in addition. nature, and the use of this window to solve societal problems, is full of promise. we certainly do live in interesting times. finally, to dream even bigger, while \u2019s generative AI has access to immense global scale training data spanning images, text, and video from the internet, it does not have direct access to our own thoughts, in the form of neural activity patterns. however, this need not always be the case, given remarkable new capacities to record many neurons from the brains of animals while they view images, as well as to perform meg, eeg, and fmri from humans as they experience the world through rich multimodal sensory experiences. such combined neural and real-world data could then potentially be used to train next generation multimodal foundation models that not only understand the physical world but also understand the direct impact the physical world has on our mental world, in terms of elicited neural activity patterns. what might such hybrid biological-artificial intelligences teach us about ourselves? overall, the future of generative AI as a window into **generative AI: perspectives** **from stanford hai** ", "### the new tools of daily life **, anand rajaraman and venky harinarayan** **professor in the school of engineering and professor of** **computer science; vice director of as we all know, ai is taking the world by storm. we will begin to see many new tools that augment our abilities in professional and personal activities and workflows. imagine a smart tutor that is always patient and understands the level of knowledge the student has at any point in time on any subject. these tutors will not replace teachers, but instead will augment the student learning experience \u2013 giving students a more personalized interaction, focusing in areas where they might be weaker. in design, picture a tool that assists a professional designer by riffing off their initial design ideas and helping them explore more ideas or fill in details on their initial ideas. generative AI will also unleash language-based interfaces, whether written or spoken, as a more common way of interacting with our everyday computing systems, especially when on the go or when our eyes and hands are busy. imagine an alexa, siri, or assistant that can actually understand what you are trying to do rather than just answering simple queries about the weather or music. while generative AI creates many exciting opportunities, we know from past ai deployments there are risks. in , an ai-based software tool used across the country to predict if a criminal defendant was likely to reoffend in the future was shown to be biased against black americans. we need to ensure we are designing these tools to get the most positive outcomes. to do this, we need to deeply design and analyze these systems at the user, the community, and societal levels. at the user level, we need to create new designs that augment people by accounting for their existing workflows and cognitive abilities. but we can\u2019t just design for the user. we need to consider the community that the system impacts: the families, the infrastructure, and the local economy. but, even that is not enough, we need to analyze the impacts to society at large. we need to be able to forecast what happens if the system becomes ubiquitous and from the start design mitigations for possible negative impacts. ", "##### changes that are underpinned by generative AI are only now starting to be imagined by designers and technologists. our user interface to computing has been fairly static over . in , we will see a revolution in human-computer interaction. changes that are underpinned by generative AI are only now starting to be imagined by designers and technologists. now is the time to ensure that we are critically thinking about the user, the community, and the societal impacts. **generative AI: perspectives** **from stanford hai** ", "### poetry will not optimize: creativity in the age of ai **, ** **coe professor in the school of** **humanities and sciences and** **professor of english; associate** **director of in , the professional art world was upended when the renowned auction house sold an aiaugmented work, \u201cportrait of edmond belamy,\u201d for the wildly unexpected sum of $,. that sale, which came with the tacit imprimatur of the established art community, generated much gnashing of teeth and hand-wringing in the arts sector over what artificial intelligence means for the creative industry. since then, the genie has long fled its lamp: generative AI has enabled visual art of every known genre as well as ai-augmented poetry, fiction, film scripts, music and musicals, symphonies, ai-curated art histories, and much more. the furor over the sale may now seem quaint \u2013 it occurred before dall-e, lensa ai, chatgpt, bing, to name just a few \u2013 but it heralded many of \u2019s increasingly ferocious debates over the nature of creativity and the future of work for the creative industry. it anticipated the current hornet\u2019s nest of ethical, political, and aesthetic concerns that generative AI poses for the arts. some of these concerns have been productive: generative AI has encouraged many of those whose livelihoods, and in many cases their identities, depend on their artistic productions to consider anew \u2013 and in new ways \u2013 perennial questions about foundational aesthetic norms and value: what do we identify as \u201cart\u201d? what counts as \u201cgood\u201d art? is artistry defined by human agency or automation? just who or _what_ can make \u201cart\u201d? and who decides? generative AI raises important, thorny questions about authenticity, economic valuation, provenance, creator compensation, and copyright. (the getty images lawsuit against stable diffusion is just the tip of an iceberg.) it also, arguably, normalizes extractive and exploitative approaches to creators and their work; amplifies biases of every kind; exacerbates already urgent educational and national security concerns around deep fakes and plagiarism, especially in the absence of congressional regulation. ", "##### should the principles of efficiency, speed, and so-called blessings of scale apply so unequivocally to creative processes? after all, poetry does not optimize. perhaps the most pressing concern, in terms of national security, is that generative AI might take advantage of the fact that the arts have always shaped \u2013 for good or ill \u2013 the civic imagination, that stories, films, plays, images shape our perception of ourselves, of our physical and social realities. one of the most famous disagreements between and his student aristotle was over the potentially dangerous power of **generative AI: perspectives** **from stanford hai** ", "### poetry will not optimize: creativity in the age of ai (cont\uf6c3d) poesy to influence beliefs and worldviews. this power is why fascist regimes first do away with the artists and intellectuals: because they hold sway over our minds and thus our actions. some claim that generative AI is democratizing access to creative expression to those traditionally barred from it by lack of status or wealth. but do claims to \u201cdemocratization\u201d and \u201caccess\u201d function, in effect, as industry cover for rushing a commercial application \u201cinto the wild\u201d (i.e., to the public) without the timeintensive work of ensuring ethical guardrails? _is_ ai simply a neutral if powerful assistive tool for the arts \u2013 akin to pen, paintbrush, or photography? _is_ it \u201cblitzscaling\u201d creativity, or in emad mostaque\u2019s choice description, relieving our \u201ccreatively constipated\u201d world with ai technologies that can have us all \u201cpooping rainbows\u201d? despite \u2019 worth of opining by poets, philosophers, and pundits of all kinds about the nature of \u201ccreativity,\u201d no settled definition exists. given this, technological claims to expedite that so little-understood phenomenon carry more than a whiff of hubris. interpretive skills required to understand any piece of writing by . her work always invites us to pause, insists we reflect. consider what natural language processing applications informing foundation models make of african american vernacular english, not to mention \u2019s _signifying_ on that language system. just try the experiment of my students, who submitted an excerpt of \u2019s _beloved_ to grammarly, which attempted to correct her exquisite prose for what sociolinguists term \u201cstandard english,\u201d and quickly saw how even deeply rich meaning can be rendered impotent. historically, creative expression \u2013 especially poetry, painting, novels, theater, music \u2013 has always been considered a distinguishing feature of humanity and the pinnacle of human achievement. can generative AI live up to that? maybe. maybe not. definitely not yet. in fact, generative AI may simply automate a highly reductive notion of both the creative process and of the learning process itself. _should_ the principles of efficiency, speed, and so-called blessings of scale apply so unequivocally to creative processes? after all, poetry does not optimize. fiction is not frictionless. consider the slowed-down, recursive reading and **generative AI: perspectives** **from stanford hai** ", "### generative AI and the rule of law **, and professor in** **law at law school and director of the regulation, evaluation,** **and governance lab (reglab); associate director of hai** in , a colombian court was faced with the question of whether an indigent guardian of an autistic minor should be exempted from paying for therapy costs. it might have been an ordinary case. but the judge consulted chatgpt. the prompt: \u201chas the jurisprudence of the constitutional court made favorable decisions in similar cases?\u201d while quick to note that chatgpt was not replacing judicial discretion, the judge noted, generative AI could \u201coptimize the time spent writing judgments.\u201d the colombian case may be the first judicial proceeding incorporating generative AI, and it exemplifies both what is promising, but also terrifying, about generative AI and the rule of law. on the one hand, the united states faces an access to justice problem of tragic proportions. in , president delivered a speech to , admonishing the profession: \u201cwe have the heaviest concentration of lawyers on earth. \u2026 ninety percent of our lawyers serve percent of our population. we are overlawyered and underrepresented.\u201d (\u201cthe situation has not improved,\u201d said in .) veterans wait for the appeals of disability benefits to be decided. the right to counsel with underfunded public defenders has turned into a \u201cmeet \u2019em and plead \u2019em\u201d system. and even though the united states yields one of the highest per capita rates of lawyers, legal representation is out of reach for most. ", "##### relying on chatgpt as a substitute for legal research poses grave problems for professional ethics and, ultimately, the rule of law. therein lies the promise. just as legal databases such as westlaw and lexis revolutionized legal research, there is the potential for generative AI to help individuals prepare legal documents, attorneys in legal research and writing, and judges to improve the accuracy and efficiency of painfully slow forms of adjudication. while the industrial organization of legal search could get in the way, generative AI could help level the legal playing field. but the colombian case also illustrates everything that can be wrong with the use of generative AI. such models can lie, hallucinate, and make up facts, cases, and doctrine. (insert mandatory joke about lawyers lying and cheating too.) relying on chatgpt as a **generative AI: perspectives** **from stanford hai** ", "### generative AI and the rule of law (cont\uf6c3d) _substitute_ for legal research poses grave problems for professional ethics and, ultimately, the rule of law. why is that the case? what the law teaches us is that justice is as much about the process as the outcome. a fair process engenders public trust. and the process for embedding generative AI in legal decision-making is as important as getting the foundation model right. significant technical research will be required to prevent generative AI from making up facts, cases, and doctrine. or better yet: to think like a lawyer. but even if that is solved \u2013 a big if \u2013 we cannot resolve the most contentious disputes that are channeled into law unless humans trust, participate, buy in, and engage in the process. justice delayed is justice denied, but optimizing the time to write judgments is not the right objective either. or, as chatgpt puts it, \u201cjudges should not use chatgpt when ruling on legal cases.\u201d at least not yet. **generative AI: perspectives** **from stanford hai** ", "### the new cambrian era: \u2018scientific excitement, anxiety\u2019 **, associate professor** **of computer science; director of** **stanford center for research on** **foundation models** for almost all of human history, creating novel artifacts (literary works, art, music) was difficult and only accessible to experts. but with recent advances in foundation models, we are witnessing a cambrian explosion of ai that can create anything from videos to proteins to code with uncanny fidelity. this is incredibly enabling, lowering the barrier to entry. it is also terrifying, as it eliminates our ability to determine what is real and what is not, and it will upend the creative industry (artists, musicians, programmers, writers). foundation models are based on deep neural networks and self-supervised learning which has existed for ; however, the amount of data with which these recent models can be trained results in emergent abilities, abilities not present when the models were trained on less data. in , we released a paper detailing the opportunities and risks of foundation models. we discuss how these emergent abilities are a \u201csource of scientific excitement but also anxiety about unanticipated consequences.\u201d along with emergent abilities, we discuss homogenization. in the case of foundation models, \u201cthe same few models are reused as the basis for many applications. this centralization allows us to concentrate and amortize our efforts (e.g., to improve robustness, to reduce bias) on a small collection of models that can be repeatedly applied across applications to reap these benefits (akin to societal infrastructure), but centralization also pinpoints these models as singular points of failure that can radiate harms (e.g., security risks, inequities) to countless downstream applications.\u201d understanding emergent behavior and homogenization in foundation models are just as relevant, if not more, now than just . ", "##### this is incredibly enabling, lowering the barrier to entry. it is also terrifying, as it eliminates our ability to determine what is real and what is not. additionally, it is absolutely critical that we benchmark these foundation models to better understand their capabilities and limitations as well as use these insights to guide policymaking. toward that end, we recently developed (holistic evaluation of language models). benchmarks over prominent language models across a wide range of scenarios (e.g., question answering, summarization) and for a broad range of metrics (e.g., accuracy, robustness, fairness, bias, toxicity) to elucidate their capabilities and risks. there will continue to be new models and associated scenarios and metrics. we welcome the community to contribute to . **generative AI: perspectives** **from stanford hai** ", "### a call to augment \u2013 not automate \u2013 workers **, and akiko yamazaki professor** **at ; director of digital economy lab** over , most uses of computers, including earlier waves of ai, primarily affected workers with less education and training. as a result, income inequality tended to increase in the u.s. and many other developed nations. in contrast, generative AI has the potential to affect many types of work that have primarily been done by well-compensated people including writers, executives, entrepreneurs, scientists, and artists. this may reverse some of the past effects of it and ai when it comes to inequality. so far, there have been speculation and case examples, but not much systematic empirical evidence either way. at digital economy lab, we are cataloging the list of economic activities likely to be affected by generative AI and estimating what share of the economy they represent. generative AI promises to automate or augment many of the thousands of tasks done in the economy that previously could only be done by humans. in particular, writing nonfiction essays, persuasive ad copy, intriguing fiction, evocative poetry, concise summaries, entertaining lyrics, and other forms of text of reasonable quality is an important part of many occupations. so is writing code, generating images, and creating new designs. this will almost surely increase total output, reduce costs, or both. either way, productivity is likely to rise, although some of the benefits (and costs) are not well measured. in cases where generative AI can be a complement to labor, particularly for knowledge workers and the creative class, wages could increase even as output increases. in other cases, the effects may be primarily to substitute for labor, as the technology replaces workers in some tasks. likewise, the technology can be used to concentrate wealth and power, by facilitating winner-take-all dynamics or to decentralize and distribute decision-making and economic power, by lowering barriers to entry and fixed costs, empowering more people to create value. it can create a monoculture of closely related output, or a flourishing of novel creations. ", "##### this will almost surely increase total output, reduce costs, or both\u2026productivity is likely to rise, although some of the benefits (and costs) are not well measured. last but not least, these technologies have the potential to speed up the rate of innovation itself, by facilitating invention, design, and creativity. thus they may not only increase the level of productivity but also accelerate its rate of change. **generative AI: perspectives** **from stanford hai** ", "### a call to augment \u2013 not automate \u2013 workers (cont\uf6c3d) powerful new technologies almost always require significant changes in intangibles like business organization, process, and skills. generative AI is not likely to be an exception. given the rapid advances in the technology, a growing gap is emerging between the technological capabilities and the economic complements needed. this will create tensions and disruptions, but also opportunities for rapid progress. understanding these tensions and opportunities is central to our research agenda. the effects of generative AI are not necessarily predetermined. instead, they depend on choices by technologists, managers, entrepreneurs, policymakers, and many others. **generative AI: perspectives** **from stanford hai** ", "### the reinvention of work **, professor in machine learning** **at the school of engineering; professor of linguistics and of computer** **science; director of ai lab; associate director of hai** imagine a business analyst or data scientist generating a visualization, say, of how changes in voting patterns and economic growth correlate or anti-correlate by county in the u.s. over . at the moment, they\u2019ll typically spend a few hours on the task: searching to find out where the right data lives, writing some sql or python code to grab that data, then spending more time, perhaps in tableau, , or again in python, to turn it into a nice visualization. maybe by , ai will be able to fulfill a longstanding dream: the business analyst will just be able to say, \u201cgenerate a heatmap visualization over a u.s. map showing the correlation between voting patterns and economic growth by county in the u.s. over the .\u201d the generative AI system will do the job in seconds, and to the extent that the first work product isn\u2019t exactly what the person wanted, they\u2019ll be able to continue a back-and-forth dialog to refine the visualization. in our world, built by humans for humans, the major medium for communication is through human language \u2013 whether it is speaking with someone in person, on the phone, or by zoom; or communicating in written form via anything from texts to emails to lengthy reports. because of this, generative language models provide a massive opportunity to reinvent how work is done inside all sorts of companies and industries: marketing, sales, product development, customer support, and even human resources will all change. recent generative AI models are sufficiently good to offer enormous help \u2013 and hence potential cost savings in a business context. in some cases, a large language model\u2013based system might be able to take over a whole interaction, working with a human being to get things done. there is no doubt that a person in marketing and copywriting can get significant creative assistance from these models: a generative language model can suggest better wordings or hip, catchy phrases. given one sample paragraph, it can generate other possibilities, which a person might mine the best parts from, or just use them all to provide a variety of messages. ", "##### these ai models are not going to provide toni morrison\u2013level prose nor her lived experience, but, i believe, they will produce very competent prose. there are many intriguing aspects of this technological future that deserve further thought and comment. we\u2019re still in of figuring out what new models of normal business practice are and aren\u2019t possible. in nearly all cases, the ai system will help humans to get work done. as such, it continues the **generative AI: perspectives** **from stanford hai** ", "### the reinvention of work (cont\uf6c3d) story of new technologies and automation making things easier and improving quality of life. washing machines made washing clothes much easier. for almost the entire history of civilization, whether in the middle east, europe, or china, the ability to write well has been seen as absolutely central and vital to human accomplishment and professionalism, something still reflected in the way universities emphasize developing their students\u2019 writing skills. we will have to reckon with that changing: as notes in her piece, these ai models are not going to provide toni morrison\u2013level prose nor her lived experience, but, i believe, they will produce very competent prose. **generative AI: perspectives** **from stanford hai** ", "### in education, a \u2018disaster in the making\u2019 **rob reich, professor of political** **science; director of mccoy** **family center for ethics in society;** **associate director of hai** the newest revolution in artificial intelligence is powerful new automatic writing tools. in professional settings, these models can augment human performance \u2013 rewrite our client emails in a more professional tone, complete our papers, or generate a report on our company\u2019s performance. however, in educational settings, absent special design considerations, these models could undermine performance and corrode our creative abilities. calculators have proven to promote accuracy, remove some of the more tedious work, and make math more enjoyable for many. chat is not like a calculator. why? the quality of your writing is not just a measure of your ability to communicate; it is a measure of your ability to think. if students lean on chat to write their essays, if they do not learn to express their thoughts in writing in a clear, concise, and cohesive manner, then their thoughts themselves are not clear, concise, or cohesive. the ability to write exercises their thinking; learning to write better is inseparable from learning to think better. becoming a good writer is the same thing as becoming a good thinker. so if text models are doing the writing, then students are not learning to think. initially, the new wave of generative AI (e.g., , dall-e) was treated with caution and concern. openai, the company behind some of these models, restricted their external use and did not release the source code of its most recent model as it was so worried about potential abuse. openai now has a comprehensive policy focused on permissible uses and content moderation but as the race to commercialize the technology has kicked off, those responsible precautions have not been adopted across the industry. in , easy-to-use commercial versions of these powerful ai tools have proliferated, many of them without the barest of limits or restrictions. ", "##### calculators have proven to promote accuracy, remove some of the more tedious work, and make math more enjoyable for many. chatgpt is not like a calculator. so how could we prevent this disaster-in-the-making in education? first, ai developers and policymakers must distinguish between the significance of foundation models in educational versus professional settings. then, they must work together, along with industry players, to develop community norms. this isn\u2019t new ground. look to bioengineering, where the leading researchers, such as , developed norms around the appropriate use of crispr technology. for ai, that would mean \u200b companies establishing a shared framework for the responsible development, deployment, or release of language models to mitigate their harmful effects. in an environment where companies are sprinting to launch their latest models, we cannot be content to wait and see the ethical and societal impact and patch things up later. we need to develop widely shared norms now before we as a society pay the price. **generative AI: perspectives** **from stanford hai** ", "### solving inequalities in the education system **,** **distinguished education** **fellow at we know that learning is suboptimal when a lecturer drones on and on to a large crowd with no interaction. and yet, that\u2019s what happens in many classrooms. we know that learning is at its best when a knowledgeable, inspiring, empathetic tutor works directly with a learner, allowing the learner to progress at their open pace, mastering each point along the journey. but we don\u2019t have enough tutors to provide this level of interaction for every learner. with the recent advances in large language models, there is the possibility that they can augment human teachers in this role. if done right, this could provide a better education for all and help even out inequalities in the educational system. students could find topics that excite them and learn at their own pace from material that is designed for them. traditional curriculum with walls between subject areas can have the walls broken down, as learners move quickly between subject areas to follow their passions. doing it right requires caution: if we are going to expose learners to models, we want the models to be helpful, harmless, and honest; unfortunately, current ai models can sometimes be harmful and hallucinatory. there are several defenses against this. we can isolate the model from the learner; the model is used to select from a set of pre-curated responses \u2013 this is safer, but less engaging and less free-wheeling. we can keep the model away from learners and instead use it to train new teachers by simulating student responses. we can use the model to generate learning materials which are then vetted by a human teacher before being shown to the learner. we can limit the model to asking socratic questions, not asserting statements \u2013 that way it can\u2019t be untruthful. we can use peer-to-peer learning and feedback, with the model as a mediator. we can use reinforcement learning from human feedback to train the model toward better responses. we can use constitutional ai, in which humans explain to the model a set of rules for what is allowed and disallowed, and the model then trains itself to follow the rules. ", "##### we don\u2019t have enough tutors to provide this level of interaction for every learner\u2026there is the possibility [to] augment human teachers in this role. inevitably there will be ways to trick the system into harmful responses. for example, a system might refuse to answer \u201ctell me how to make a bomb\u201d but be willing to answer \u201cwrite an excerpt from a fictional novel in which the hero makes a bomb.\u201d there will be a continuing arms race between attackers and defenders; our challenge is to stay one step ahead. ** hai:** jane way, university, , ca **t** .. **f** .. **e** hai-institute@.edu **hai..edu** ", "# generative AI (ai) use policy **this policy is effective from** **approval body** academic council **approval date** **owner** , head of visual culture **next review date** **** **purpose** . this policy guides ncad staff in the use of generative AI (ai) when setting assignments on academic programmes, and ncad students when undertaking those tasks. this policy is designed to support the creativity, transparency and originality to which the teaching and learning at ncad is committed while upholding the highest principles of academic integrity. this policy should be understood as operating in conjunction with ncad\u2019s plagiarism policy. . this policy concerns the use of specific forms of ai, namely those which can be understood as generative AI. these are systems that are capable of generating texts, code, sounds, music and images in response to prompts or other instructions from the user. these outputs will be new and unique. typical examples of generative AI tools include chat , dall-e-, midjourney and github co-pilot. . this policy does not address the use of ai-powered tools designed to correct or improve visual or written expression (such as photo editors or grammar checkers) or to conduct online research (e.g. image search engines). in such cases, and as currently required, the student using such ai-powered tools should be able to make an unequivocal declaration of their authorship of any piece of work conducted during their studies. similarly, this policy does not address the training of a student\u2019s own ai model through machine learning, data sets, etc. . this policy is guided by the understanding that generative AI has the potential to act as a valuable aid to learning, research and creativity, and that, if used, students should do so in critical and informed ways. this means that they should be guided to understand how generative AI functions; what kind of data it draws on; and the implications of its use for copyright and intellectual property (both that of the student\u2019s and of others\u2019). in particular, students need to be equipped to understand the limitations of any generative AI that they use, as well as the tendency for these tools to exploit the creativity and research of human authors, artists and other creators without acknowledgment. . our approach to the use of generative AI at ncad requires transparency. students should make their own practices as learners evident to those who teach and assess them. in this way, teaching staff are able to provide valuable and effective feedback. . while there is much public discussion about the likely negative impact of generative AI on academic integrity and creativity, it is clear that ai generative tools will continue to develop and be a feature of many future applications of technology. they will be employed in many workplace and professional settings. at the same time, the core skills and understanding that we seek to develop in our students remain of central importance. accordingly, our approach is to support ncad teaching staff to set appropriate limits on the uses of generative AI tools, balancing their utility against the learning needs of our students. without such declared limits, students will reasonably make use of freely available and highly purposeful ai generative tools. it is incumbent on staff to communicate clearly the limits and potential of generative AI tools in relation to any task being set. **** **policy** . teaching staff have the right to prohibit the use of an ai generator by a student when undertaking an assignment. typically, this will be when the learning outcomes of a module require that the student develop and apply particular skills. the development of research skills in the library or sketching skills are incompatible with the use of generative AI, for instance. in such cases, the teaching staff will make it clear in any published course documentation - such as a brief - that use of an ai generator is not permitted. . teaching staff may allow limited use of an ai generator to undertake a specified task which forms part of the work to be undertaken on the course. for instance, an ai generator might be used in an early phase of a project to support ideation or as a critical investigation of particular ai tools. limited use may also include the use of generative AI to check or improve content which has been created by the student. in such cases, the teaching staff will specify the nature and extent of permitted usage of an ai tool. this limited usage will be specified in any published documentation provided to students on the course. staff may require students to declare in written form the nature and the extent of the use of an ai generator when presenting / submitting work for assessment. this may, for instance, take the form of a declaration on a cover sheet, a citation or a caption for images, as required by the teaching staff. . teaching staff may allow uninhibited use of an ai generator to undertake any task which forms part of the work to be undertaken on a course. again, this should be declared in course documentation. and as above, the student will be required to make a full declaration about the way in which the ai generator has been used. . teaching staff have the right to use ai detection tools to test or confirm their use in the production of work by ncad students. staff should not, however, rely on such tools while they have yet to prove their complete accuracy. . in the case where staff have reason to believe that an ai generator has been used in ways that contravene the permitted uses outlined above, the following approach should be taken: .. the student should be required to explain their work processes concerning the use of ai tools by the module coordinator or a nominee. this will typically take the form of an in-person meeting with the student; .. if the student admits to having breached this policy, a judgement should be made - by the module coordinator and the head of programme - about the scale and nature of the offence; .. \u2018first offences\u2019 or minor breaches of the policy will typically result in the student resubmitting the work and a grade penalty can be considered at the point of assessment of the module. if the timing of this assessment point does not permit the resubmission of work, first offices or minor breaches may result in a requirement that the student resits the assessment task; .. more substantial breaches of the policy can be considered a fail and a recommendation be made to the examination board that the student be required to repeat the module; .. if a student denies using an ai generator despite evidence to the contrary or engages in an act of deception, the module coordinator and head of programme may decide that the student is guilty of serious academic misconduct (defined as \u2018any action or attempted action that may result in creating an unfair academic advantage\u2019). in such cases they should request that the head of academic affairs invoke the student discipline procedure as outlined in the ncad student code of conduct. ", "## guidelines for the use of generative AI in teaching, learning and student evaluation _effective from ", "# . definition of generative AI generative AI is a subset of artificial intelligence that utilizes machine learning techniques to generate information. generative AI uses advanced algorithms and models to generate new data similar to the input data it was trained on. this unique ability allows it to create content that did not previously exist or transform existing data into a new format. for instance, generative AI can be used to create realistic images, synthesize voices, generate text, compose music and conduct other tasks. ai tools can offer substantial benefits to academia, helping students and teachers alike in research, writing, exploration of complex topics and other activities. by leveraging these capabilities, ism university aims to enhance the teaching and learning experience, thus pushing the boundaries of conventional education. ", "# . using generative AI in academic activities **. generative AI in teaching** faculty members can choose to use ai tools in their teaching, as long as these tools help meet the goals and requirements of the course and are in line with ism university\u2019s code of ethics. faculty members are encouraged to try out ai tools to make classes more engaging and help students learn better. this can include using ai tools for things like research, improving content made by ai, competing on ai challenges, explaining how to think through problems, and making all-around assignments. faculty members can also use ai tools to help them prepare for teaching and to give students feedback. faculty members should clearly explain students how they should be using ai in the class. they should talk about this in class and put it in the course syllabus. faculty members need to know what are the benefits and drawbacks of the application of ai tools. this includes being aware of any biases in the ai, and any ethical or data privacy issues. faculty members should know the basics of ai working principles. this will help them use ai properly and ethically in their teaching. faulty members are encouraged to have regular training on how to use ai tools. this training should cover not just the technical information but also ethical and legal knowledge of the technology. **. generative AI in learning** students are permitted to use ai tools in their academic activities unless explicitly stated otherwise in a course syllabus or assignment (e.g., exam, test, etc.) description. it is crucial to review course-specific guidelines for ai usage, especially for exams and assignments. **. authorship and accountability for ai-assisted works** generative AI tools should not be acknowledged as authors because they cannot ensure the work\u2019s accuracy, originality, and integrity - all of which are prerequisites for authorship. as a result, students are responsible for all materials created with the assistance of ai technologies. students are encouraged to revise the output, as ai can produce potentially inaccurate, incomplete, or biased content. students must ensure that their paper is free from plagiarism, including in the text and images generated by ai. it is a student\u2019s obligation to provide attribution to all quoted content as per _formatting_ _and citing requirements for student academic papers: apa style sumy (th_ _edition),_ updated on . in cases where assignments contain factual inaccuracies or incorrect citations, the students will be held accountable, even if these errors originate from properly cited ai tools. such circumstances will result in the assignment receiving a lower grade and/or other penalties as per ism university\u2019s code of ethics. unauthorized use of ai tools, where prohibited, will be treated as a violation of academic integrity, resulting in penalties as outlined by ism university\u2019s code of ethics. **. referencing ai-generated content** it is imperative that students provide an appropriate citation for the ai tool used, which involves: . acknowledging the ai tool in references list and in-text citation. . specifying the purpose of ai tools usage. . providing a brief process description. this applies even when the ai-generated content has been edited by the student or student generated content was edited by ai tools. _.. creating references to generative AI models._ references for usage of generative AI should be cited according to the newest apa standards. example: openai. (). chatgpt (jun version) [large language model].  - parenthetical citation: (openai, ) - narrative citation: openai () _.. describing the purpose and process of using generative AI in academic_ _papers_ an explanation of how the ai tool was employed in the research should be provided in the methods section or a comparable part of the academic paper. in specific cases a professor can require to justify human input of ai generated content. for literature reviews, essays, or response and reaction papers, the introduction can serve as a suitable location to describe the usage of the tool. the text should include: . the prompt used and . the corresponding ai-generated text as a response. example: in response to the query \"can music enhance cognitive performance?\", chatgpt produced the following statement: \"research suggests that listening to music can have a positive impact on cognitive performance, such as improving focus and memory retention\" (openai, ). reference openai. (). _chatgpt_ ( version) [large language model].  when dealing with extensive outputs from generative AI, like chatgpt, it is recommended to incorporate the full text into an appendix of the paper or within online supplementary materials. this approach gives readers access to the precise response generated. due to the characteristic of chatgpt which generates unique responses for every interaction, even with the same prompt, it becomes essential to document the exact produced text. if the decision is made to add appendices or online supplementary resources, it is important to ensure that each one is referenced at least once within the core text of the apa style paper. example: in response to a secondary prompt such as \"can you clarify the concept?\", the text produced by chatgpt explained that \"networks of neurons work in tandem to facilitate various mental operations\" and \"the dedicated roles of specific networks can adapt based on experience and environmental contexts\" (openai, ; refer to appendix b for the entire conversation). reference openai. (). _chatgpt_ (version dated ) [large language model].  ", "# . closing remarks ism university is committed to promoting responsible and ethical use of generative AI in teaching, learning, and student evaluations. these guidelines are to be used as a framework for the successful integration of ai into our academic setting. ism university recognizes that advancements in technology or changes in overarching policies may necessitate updates and revisions to this policy. ", "# generative AI tools ", "#### what are generative AI tools? \u00ac generative AI (ai) tools use machine-learning algorithms to create \u201cnew\u201d digital content (text, images, audio, multimedia, computer code, etc.). \u00ac they are not currently capable of evaluating, critically combining or verifying information\u2014instead, they predict and rearrange the most likely outcome based on the requested output, feedback and patterns in the data models they are trained on. \u00ac natural language processing (nlp) is the subset of generative AI tools, such as chatgpt, that allows computers to analyze and then mimic human language. paired with a user-friendly interface, these tools are commonly called \u201cchatbots\u201d and allow users of all skill levels to place requests and interact with the language models in a conversational manner. _example_ a chatbot for a course could answer student questions related to the course subject matter, offer definitions, summarize or identify main ideas in documents or materials, generate review questions, or identify support resources. for the model to learn, it needs to be exposed to relevant data. the chatbots learn what the best answers are and how to deal with questions that don\u2019t fit the framework of the questions asked. ", "#### different tools for text and image generation \u00ac chatbots such as chatgpt, chatsonic, lamda, , jasper, jasper art, midjourney, stable diffusion and bing use nlp and are trained to understand language and respond in a meaningful way. \u00ac some apps such as chatgpt are trained on large amounts of text data from various sources and then the model uses the prompt given, analyzes the data into components, processes the meaning of each part generated and then produces a response. this process is called \u201ctransfer training,\u201d which involves the model being trained on new tasks and data to improve its performance and accuracy (sanchez, ). \u00ac the tools differ in the data models they are trained on and the way in which they were designed for the user to interact with them; for example, the original version of chatgpt is based on data and uses a conversational format, chatsonic is powered by search and utilizes voice commands, jasper remembers conversations, lamda is trained on dialogue and replika is oriented to personal use. other ai apps are conversation-focused and may use rule-based systems that rely on predetermined responses. additional apps are image-based and provide visual explanation such as socratic or dall-e , which can create realistic images from a given description. \u00ac bard (): powered by lamda (language model for dialogue applications); natural language input; can follow up on conversations; can generate responses to open-ended prompts \u00ac bing: uses a conversational ui; delivers a summarized answer; provides sources to each data provided \u00ac grammarly: suggests improvements to spelling, grammar, fluency, style and tone \u00ac chatsonic: conversational ai tool provides updates and factual information aided by \u2019s information network; accesses the internet to generate accurate data on current events and remembers conversations; has a built-in image generator \u00ac jasper: ai writing tools for companies that want to generate high-quality content, templates for blogs and social media; great for short sentences and ad copy \u00ac replika: ai chatbot or companionship; can hold meaningful conversations; has video call options and avatars ", "### enhancing teaching and learning generative AI tools can be used to support the work of teachers, transform students\u2019 learning experiences and create innovations in learning assessment. here are some ideas of how these tools can be integrated in teaching and learning, aligned with good teaching practice. teaching practice\u2014supporting the work of teachers _examples of good practice_ here are some examples of what teachers can generate to support their teaching practice. although the output may not be % correct, it can be a starting point that will save time. |course schedules|prompt learning outcomes, delivery mode, course duration ask to produce a course schedule| |---|---| |lesson plans|prompt learning outcomes, main student characteristics, preferred pedagogical strategies, lesson duration ask to produce a lesson plan| |lesson summaries|prompt learning outcomes, lesson main themes, lecture notes ask to produce a summary highlighting key topics| |learning outcomes|prompt lesson topic, duration and level of lesson (introductory, advanced) ask what learning outcomes should be covered| |feedback & guidance|prompt the subject or the task students need to improve on ask for generation of specific steps/action students can do to improve| |quiz questions|prompt learning outcomes ask to generate different types of closed questions, such as multiple choice and true/false| |images|prompt key aspects of what needs to be illustrated, using a detailed description ask for the creation of the image| _examples of good practice_ here are some examples of what teachers can ask students to generate to improve the learning experience: |discussion prompts|ask students to create an argument, asking the generative AI tool to refute the idea. students use the rebuttal to strengthen their original argument.| |---|---| |student generated summaries|ask students to use generative AI tools to summarize a lesson. request that students share their prompts and explain why they chose them.| |student agency|ask students to use generative AI tools to generate a list of open-ended questions related to a specific topic. request that students self-organize in small groups to respond to the questions.| |image generation|ask students to generate one image to illustrate a given topic. request that they critique the image.| assessment\u2014rethinking student assessment _examples of good practice_ here are some examples of how teachers can rethink assessment of learning to focus on higher-order cognitive skills, such as creating, evaluating and analyzing: _if an assignment is easily done by an automated response system, is it worth asking students_ _to do it?_ |generating assignments with students to use ai to generate their assignment. request that they submit a critical review of the assignment, critiquing the underlying thinking. ask students to use ai to generate at least three assignments. request that students compare each one, critique and grade them, providing a rubric. ask students to use ai to generate a piece or work (essay, code). request that they critique it and provide ideas for optimization, indicating why the idea would improve the piece of work.| |---|---| |generating prompts to create assignments|tell students the end result for an assignment. ask students to generate the prompts they would use to obtain such an assignment.| important! when using generative AI tools for assignment creation, be sure to have students check facts, provide references and add acknowledgements. ethics new artificial intelligence (ai) tools and large language models (llm) (e.g., chat, , bing chat) interact in a conversational way and have many uses, but also present ethical challenges. some key issues for educators related to ai-generated information are: \u00ac explainability and transparency since sources are not identified and accuracy cannot be confirmed \u00ac intellectual property issues due to unclear data ownership, authorship and citation information \u00ac low reliability as inaccurate or biased data may be sourced or fantasy responses provided \u00ac misinformation based on examples and data provided \u00ac lack of accountability since the source of data is unclear \u00ac privacy and security concerns as data could be misused or in breach of privacy requirements \u00ac unethical labour practices\u2014moderations workers are employed in the global south for under $/hour privacy and technology the need to maintain student privacy is essential. check technology signup requirements and terms of use. to maintain privacy (and meet fippa requirements) ensure tools do not collect student data (e.g., phone number, email address, age). tools that do not meet privacy requirements must be voluntary and alternatives provided. using ai in your courses we are not preparing learners for the past but for the future. being able to use ai tools effectively and understand their value and limitations is important to be technically and conceptually prepared for future life and workplace demands. plan for the use of artificial intelligence. prepare by creating a policy, acknowledgement requirements and an assignment. further consider how to make assessments ai-proof and help learners build new skills related to ai use. it is impractical to try to ignore, ban or eradicate ai. instead, the preferred path is to work on developing assessment, teaching and learning in ways that promote responsible engagement with ai. when used thoughtfully, ai tools can be used to support academic practices. the use of generative AI tools highlights existing questions about how we can refine assessment concerning what matters to staff, students, and society more broadly. some course learning outcomes and related activities may benefit from using these tools, while others may not. you can prepare by considering your learning outcomes and, where appropriate, how to make assessments ai-proof or help learners build new skills related to ai use. generative AI tools will continue to impact and influence our teaching and learning practices. what we know about these tools and how we use them will likely change as development and access shift in . policy be clear about expectations. be explicit about what cheating is, with ai tools or not. if it appears a student is submitting ai work, talk with them one-on-one (e.g., did you use any sources or tools you did not cite or acknowledge?). if you allow ai use, then be clear about the limits of such tools and how to credit ai-generated information. within this class, you are welcome to use generative AI tools (chat, , dall-e and others) in a totally unrestricted fashion, for any purpose, at no penalty. however, you should note that all large language models still have a tendency to make up incorrect facts and fake citations and inaccurate outputs, and image-generation models can occasionally come up with highly offensive products. you are responsible for any inaccurate, biased, offensive, or otherwise unethical content you submit regardless of whether it originally comes from you or a foundation model. if you use generative AI tools, you must acknowledge use. undeclared use of the tool/technology are considered a violation of the academic integrity policy. you must document use and the prompts used to generate the results. you must also evaluate the output for accuracy, make the necessary corrections and add citations as required. having said all this, the use of generative AI tools is encouraged, as it may make it possible for you to submit assignments with higher quality, in less time. bcit\u2019s policy on plagiarism still applies to any uncited or improperly cited work by technologies or other human beings, or submission of work by other tools or people as your own. (, ; sfu, ) _sample citation and acknowledgement_ an apa style citation might look like this: \u00ac reference page: openai. (, ). [chat response to a prompt about three prominent themes in bcorp businesses].  \u00ac in text citation: (chat, personal communication, february , ) acknowledgements might look like this: \u00ac i acknowledge the use of chat for generation of three key ideas that i then researched to ensure accuracy and further developed. \u00ac prompts used: ) what are the advantages of... ) how can we improve cost effectiveness when... ) what ethical challenges relate to ... _sample assignment_ consider an assignment in which ai (e.g., chat) acts as a starting point and the student critiques and improves it. ask learners to complete an assignment using an ai tool (e.g., chat). next steps: \u00ac critique the assignment and explain reasoning (e.g., well done because..., poor because...) \u00ac optimize the assignment (e.g., fact check, references, add content, improve writing and format) \u00ac grade the work and explain the grade (mollick and mollick, ) for additional ideas on using an ai tool like chat in a variety of subjects, see trust and maloy . ", "### sustainability please note that, as with any technology, sustainability, ethical practices and use of resources are issues to be aware of. see the resources provided for more information. generative AI tools bisen, ). what ai techniques are used in chatbots: explained with examples. medium.  lund, , w. (, ). chatting about chat: how may ai and impact academia and libraries? pre-print of a manuscript that has been accepted for publication by library hi tech news. retrieved from: chatting about chat: how may ai and impact academia and libraries? | semantic /paper/chatting-about-chat%a-how-may-ai-and--impact-lund-ting/fddbdacaeceaebbfa) montessi, ). chat alternatives for your business. invgate. retrieved from [ sanchez, v.(, ). the origin and evolution of chat : the natural language model that is changing the game. retrieved from -/ enhancing teaching and learning ferlazzo, l. (, ). ways to use chat in your classroom. . // wiley, d. (, january ). ai, instructional design, and oer \u2013 improving learning. opencontent.org. / herfteducator. (n.d.). a teacher\u2019s prompt guide to chat aligned with \u201cwhat works best\u201d [google docs].  academic integrity baker, r. (). foundation model class policy, v..  cc by-sa . mollick, , l. (, . why all our classes suddenly became ai classes. . hbsp.harvard.edu.  simon fraser university (sfu). (). statements. .  trust, , r. (, ). _guide to teaching and learning critical analysis with chat._ smartbrief. - fdbcecbd trust, , r. (n.d.). _critical media literacy guides_ . critical media literacy and civic learning. / mediaandciviclearning/cmlguides#h_xqej. ethics, principles and responsible use of artificial intelligence (ai) . (). _the artificial intelligence (ai) principles_ . .ai.  treasury board of canada. (, ). _responsible use of artificial intelligence (ai)_ . . . html#toc unesco. (). _recommendation on the ethics of artificial intelligence_ . unesco.org.  cc by-nc-sa sustainability crawford, k. (). _atlas of ai_ . . nast, october ). _the generative AI race has a dirty secret_ . wired uk.  perrigo, b. (, ). exclusive: _the $ per hour workers who made chat safer_ . time. / thi k t d b bcit / ed ti s t d i ti d i li d d /licenses/by/./) [ti /licenses/by/./) [att ib ti   ", "# issues posed by generative AI for teaching and learning ", "## missouri online ", "### issue #: course policies - student use of ai ", "#### summary many have said artificial intelligence will disrupt many aspects of society. with generative AI, these disruptions may extend to our ideas and assumptions on academic integrity whatever expectations or policies regarding the use of generative AI a faculty member ultimately adopts and uses in teaching a course, students should come to receive and understand them clearly and early in the course, through explicit syllabus statements and discussions in class. instructors may like to consider inviting students to contribute to the formulation of these expectations and policies. ", "#### academic integrity and policies one of the most dominant concerns regarding generative AI is its effects on academic integrity. with tools like chatgpt able to compose meaningful and clear work that students can submit as their own, many may wonder and worry about whether generative AI may account for much of the content appearing in submissions. [a recent /article/faculty-members-still-arent-sure-what-to-make-of-chatgpt?cid=gen_sign_in) indicates that most institutions and departments have not yet developed guidelines and policies regarding when and how students can use generative AI, if at all (surovell, ). given the widespread lack of institutional guidance, faculty members have faced the task of articulating and describing their own policies. as per [the standard of /programs/ch/._standard_of_conduct) , the university of missouri system has decided to leave to each individual faculty member or their departments the decision of whether students can use generative AI in their coursework. the default policy is that if an instructor does not explicitly allow the use of generative AI, it is forbidden. with this policy, the university of missouri system has decided that each individual instructor is best equipped to judge and decide what role generative AI should play in students\u2019 learning, if any. consider your own teaching context: what policies involving generative AI would ensure students achieve the set learning outcomes and objectives and build skills, such as creativity and communication (vivekanandan, ), while still being realistic and offering opportunities for students to learn new technologies? whatever policy is adopted, a faculty member may like to at least integrate the following two processes into the instruction. these processes will give students explicit guidelines regarding the use of generative AI in their studies: - **syllabus statements:** the syllabus for a class should include a section discussing generative AI and indicate any standards or guidelines for both appropriate and inappropriate use thereof. this section should clearly define the border between the two to ensure students understand what the instructor expects. it is essential to identify and describe the contexts (when, where, how, why, and for what) students can use generative AI in the course. - **a discussion early in the course:** in addition to developing a syllabus statement, instructors should engage students in a conversation about generative AI. rather than lecturing them, invite them to share how they could most effectively use generative AI while maintaining responsibility for and actively participating in their learning. something that you may like to do is use the discussion with students to generate the syllabus statement. in other words, you could collaborate with students in each course you teach to develop the expectations and policies surrounding the use of generative AI. involving students in the process of determining these policies (and perhaps others in the course) \u201cfosters student ownership in the classroom and responsibility among the students for their behaviors\u201d (). ", "#### sample statements as you consider your own policy to include in your , please rest assured: various statements about generative AI have come to exist and become publicly available across higher education ( center for teaching excellence). these statements, which individual faculty members have developed in the absence of institutional mandates, range from the absolute restriction of generative AI to the enthusiastic embrace of it. **no use permitted whatsoever** - \u201cintellectual honesty is vital to an academic community and for my fair evaluation of your work. all work submitted in this course must be your own, completed in accordance with the university\u2019s academic regulations. you may not engage in unauthorized collaboration or make use of chatgpt or other ai composition software\u201d (). - \u201csince writing, analytical, and critical thinking skills are part of the learning outcomes of this course, all writing assignments should be prepared by the student. developing strong competencies in this area will prepare you for a competitive workplace. therefore, ai-generated submissions are not permitted and will be treated as plagiarism\u201d (). **use permitted under certain circumstances and in certain contexts** - \u201cwe recognize that there are a variety of ai programs available to assist writers. ai programs are not a replacement for human creativity, originality, and critical thinking. writing is a craft that you must develop over time to develop your own individual voice as a writer. however, within limited circumstances, and with proper attribution, ai programs may be used as a tool\u201d (bryant university). - \u201cthere are situations and contexts within this course where you will be asked to use ai tools to explore how they can be used. outside of those circumstances, you are discouraged from using ai tools to generate content (text, video, audio, images) that will end up in any student work (assignments, activities, responses, etc) that is part of your evaluation in this course. any student work submitted using ai tools should clearly indicate what work is the student\u2019s work and what part is generated by the ai. in such cases, no more than % of the student work should be generated by ai. if any part of this is confusing or uncertain, please reach out to me for a conversation before submitting your work\u201d (). **broader use accepted within certain guidelines** - \u201cai is allowed with attribution: use of ai tools, including chatgpt, is permitted in this course for students who wish to use them. to adhere to our scholarly values, students must cite any ai-generated material that informed their work (this includes in-text citations and/or use of quotations, and in your reference list). using an ai tool to generate content without proper attribution qualifies as academic dishonesty\u201d ( amherst). - use of ai tools, including chatgpt, is permitted in this course for students who wish to use them. to be consistent with our scholarly values, students must cite any ai-generated material that informed their work and use quotation marks or other appropriate indicators of quoted material when appropriate. students should indicate how ai tools informed their process and the final product, including how you validated any ai-generated citations, which may be invented by the ai. assignment guidelines will provide additional guidance as to how these tools might be part of your process for each assessment this semester and how to provide transparency about their use in your work\u201d () you will find further sample statements from temple /sites/teaching/files/resource/pdf/chat-gpt%%statement%guidance.pdf) and [the , knoxville . for more information about how students could cite generative AI tools, please review this page from the modern language association and this page from the american psychological association . ", "### issue #: plagiarism detection ", "#### summary one of the more common responses to generative AI so far has been to use detection software. however, such tools present issues and challenges. we may need to reconceptualize and transform our ideas about plagiarism and academic honesty in response to generative AI. missouri online offers a sprint , a short asynchronous professional development opportunity for faculty , on academic integrity that considers the causes of cheating and how to prevent it, but here we will primarily consider ai-plagiarism detection software and what it means for learning and teaching. ", "#### ai detection software rather than adopting and implementing clear guidelines for the use of generative AI, faculty members may seek a policy of restricting and forbidding its use. in addition, they may resort to ai detection software (, ). while these tools may offer a seemingly convenient solution to the question of academic integrity in this new age, they also present issues: - such solutions may identify false positives, wrongly imperiling some students\u2019 academic studies (fowler, ). - the formulaic writing style of non-native writers as they develop calp, cognitive academic language proficiency, may resemble the writing style of generative AI, leading to further false positives (, ). - \u201cnew ai language models are more powerful and better at generating even more fluent language, which quickly makes our existing detection tool kit outdated\u201d (heikkil\u00e4, ). [you may learn more about issues with ai detectors /support/solutions/articles/-detecting-artificial-intelligence-ai-plagiarism) . given all this, \u201cthere is little actual scientific evidence to show that ai-generated text can be effectively detected\u201d (eaton, ). with the advent of generative AI and the problems with detecting it, we must perhaps evolve and change our ideas of what constitutes academic integrity and plagiarism. for a long time, academic integrity involved writing original content and citing any other sources used. the expectation with academic writing has been to respect and acknowledge the work of others as distinct while also presenting one\u2019s own insights and conclusions. in other words, academic integrity has generally involved treating ideas with an individualistic attitude: they are the property of a single individual or group of individuals. ", "#### reconsidering plagiarism and academic honesty this definition of academic integrity becomes more problematic once one encounters the chimera that is a student\u2019s work produced with assistance and contributions from generative AI. with the power of generative AI, () describes the possibility of academia needing to transition into a postplagiarism world. below you will find an infographic she produced to describe the six characteristics of a postplagiarism world. _please view the above image in higher resolution here_ _._ as provocative as the idea of a postplagiarism world may seem, it remains clear that we must adjust our approach to and provide more clarification about academic integrity. students are likely more confused than we are about these expectations, in which the slightest and most innocuous use of generative AI (to revise and edit a draft written entirely by the student) could constitute academic misconduct. the conversation needs to change. ", "#### supporting students in this brave new world \u201dwe argue that it is time to shift this narrative in favor of one highlighting a distributed accountability when it comes to academic misconduct\u2014that is, leaders, administrators, educators, and students are to share the responsibility. educational bodies and institutions should therefore allocate adequate resources to support staff and students deal effectively with generative AI-related challenges and optimize opportunities presented by its tools\u201d (lim ., , p. ). regardless of one\u2019s own response to eaton\u2019s six tenets () and the concept of \u201cdistributed accountability\u201d proposed by lim . (), it is clear we must all anticipate and respond to the use of generative AI by our students. whether we approve or disapprove of any use of generative AI and whether we plan to use detection software or not, we must communicate to our students our expectations and policies. ", "#### scenario students have submitted their final research essays for the semester in a course on the economics of globalization. this essay, in which they must present and analyze a positive or negative economic effect of globalization, is one that many students decide to ask chatgpt to outline for them, grammarly to proofread for them, and quillbot to refine for them. however, students still have conducted all the research and thoroughly engaged with the content. once these students submit their work, you receive an alert that their work has been identified as possibly being generated by ai. how do you respond to this information? if you learned of the process they used, would you consider their work plagiarized or not, and why would you take such a position? . **red light (unacceptable):** it is clear students have offloaded much of the \u201cthinking\u201d for this assignment to generative AI. therefore, the work they have submitted does not meet your standards and expectations for their learning. . **yellow light (uncertain/ambiguous):** while you do not mind the use of generative AI for stages later in the writing process (revision and editing, for example), you believe students should still take ownership of and be responsible for higher-order considerations in their work (content and ideas, for example). therefore, you may like to discuss with them appropriate use cases and inappropriate use cases with generative AI. . **green light (acceptable):** students are still \u201clearning\u201d in your eyes: they are engaging with the content and receiving guidance and feedback from a partner in the writing process. though generative AI may play a role in the workflow of students, it is clear they are still achieving the learning outcomes. ", "### issue #: ferpa, privacy, and choice ", "#### summary though such new technologies as chatgpt and claude could play a role in the workflow of both students and the instructor, it is important to keep the law in mind. one specific matter is ensuring that the work of students is not shared with third parties without their consent. as per the family educational rights and privacy act, parties without a legitimate academic interest should not receive access to students\u2019 academic records without approval. therefore, instructors _should not_ : . require students to use third-party generative AI tools. . upload or copy and paste the work of students into generative AI tools without consent from each individual student. if you give students the option to use generative AI as part of their learning, please also design your instruction such that students who decline to use such services can enjoy and benefit from a comparable learning experience. ", "#### background and context under ferpa , or the family educational rights and privacy act, educational institutions receiving federal funding must ensure the privacy of students\u2019 academic records. such institutions of learning \u201cmust have written permission from the\u2026eligible student in order to release any information from a student's education record\u201d ( department of education, n.d.). it is possible that requiring students to use chatgpt may share academic records and other pii, or personal identifying information, with openai and its third-party vendors. the same may also hold true for other generative AI applications. unless the user has disabled chat history with the service (openai, ), any information shared with chatgpt will contribute to its evolving llm (large language model), the corpus of text that it uses to generate responses to human prompts. \u201cwhat we do know is that any information shared with chatgpt or other openai programs in an educational setting can then be shared by that program elsewhere\u201d (turner, ). **principles to keep in mind** in light of the legal requirements of ferpa and the uncertainty surrounding precisely what happens with the data shared with openai or other companies, there are two fundamental principles to keep in mind: - **faculty should refrain from mandating that students use generative AI for** **an activity or assignment.** while you can certainly allow and invite students to use generative AI in your directions, you should not require students to use these services, nor should you penalize them for declining to do so. in addition, you should clearly communicate to and discuss with students the inherent privacy risks associated with using these tools for learning purposes. - **faculty should avoid using any content from, or discussing any specific** **concerns about or communications with, students with generative AI** **without the students\u2019 explicit consent.** it is also important for faculty to remain mindful of and abide by ferpa while using generative AI for teaching purposes. after all, research has found educators use chatgpt more than students do (the walton family foundation, ). faculty may turn to generative AI for a variety of purposes: to give feedback on the results section of a master\u2019s thesis, to compose an email response to an undergraduate student asking for an extension on assignment due to a family emergency, and more. in these situations, **by copying and pasting students\u2019 work or** **communication with you into a separate generative AI tool, you are** **violating ferpa** : you are disclosing students\u2019 academic records and/or pii to a third party to which the student did not consent. it is essential that instructors refrain from importing students\u2019 work or communication into generative AI, from using third-party generative AI tools to analyze and give feedback on students\u2019 work, and from sharing academic records and/or pii about students to expedite their workflow. ", "#### ensuring equity and student choice for students who decline to use generative AI for one reason or another, instructors should ensure equity and universal design in the learning experience. in other words, if students using tools like chat or bard would receive a considerable academic advantage from using generative AI, it is essential you craft and integrate avenues for other students to enjoy similar opportunities. for example, you could teach an art history course and direct students to use dall-e to produce artificially generated artwork and then share them in a discussion forum to review and discuss the characteristics and hallmarks of various movements, such as impressionism or cubism. in this event, you must offer students a similarly effective avenue for reviewing the schools virtually, such as by downloading and sharing images from elsewhere. if you are to ask students to use generative AI as part of their learning, please also consider the pricing associated with some of the services. for example, only the paid version of chat uses the most recent model of , -, while the free version uses an older version. though the paid version may offer access to a more robust and powerful llm, it costs twenty dollars a month, something that can come to constitute a considerable expense for students. given rising concerns about the affordability of a college education, you are advised to refrain from mandating the use of paid tools. please also note that faculty are advised and encouraged to only ask students to use the technology tools vetted and approved by for learning and teaching purposes . should you mandate that students make use of another application or service that has not received approval, you accept the risks and potential liability in the event of a data breach or similar event. with simplified tuition , you may not be able to require students to purchase unauthorized software. ", "#### scenario you teach an introductory computer science course and have directed students to ask chatgpt to generate the html code needed to create, maintain, and update a professional portfolio, which will serve as the final assignment. students will then analyze, critique, and update the code produced before building their own html portfolio. a student privately messages you her concerns about using this service: uncertain what chatgpt does with the data she shares, she worries about the risks. how do you respond to these concerns she has raised? should you inform her she is exaggerating the privacy and safety risks of using chatgpt and expect her to proceed to use the service? should you acknowledge her reservations and offer an alternative activity? what should you do? ", "### issue #: accuracy and biases of output ", "#### summary though many of us may treat and view generative AI as an \u201cexpert\u201d due to the datasets on which it has been trained, it is not: the internet, which often serves as the source of much if not all of a tool\u2019s llm, is not intrinsically an expert on any topic, as we all know. generative AI can only generate content based on patterns it has detected, and it cannot appraise or determine the accuracy or social impact of what it creates. only humans are capable of fully assessing the quality of material and of empathizing with others. only we can understand. therefore, in integrating and using generative AI as part of students\u2019 learning and workflow, you should take the time to encourage and scaffold for students the critical engagement and use of these tools. there are two fundamental and necessary components of such critical engagement and use: . ai literacy skills, which includes prompt engineering . and engagement (to identify biases and prejudices toward various groups) the latter concern does not receive much attention in discussions about teaching students to use generative AI. however, developing this awareness will enable students to not only more effectively and comprehensively assess and judge the output of generative AI but will also foster and invite the development of empathy, something currently in decline (, ) but increasingly needed in our complex and dynamic society. ", "#### accuracy of output generative AI can create text based on what it has learned through its large language model. however, as the case study above demonstrates, it cannot assess the accuracy, validity, and truthfulness of the content it produces. as chatgpt itself observed in discussing what generative AI cannot do, it cannot: - guarantee complete accuracy and reliability in generated content. - distinguish between real and generated content in all cases. generative AI merely uses its llm to produce text relevant to the prompt from users. often that output uses correct and true information borrowed from the web. sometimes, though, that output contains \u201challucinations.\u201d the kennesaw state university school of data science and analytics () states, \u201cfor the most part, when people talk about an ai hallucination, they mean that a generative AI process has responded to their prompt with what appears to be real, valid content, but which is not.\u201d () found that in response to a prompt about teaching with technology in a science class, chatgpt produced six citations, five of which were fake. this pattern of numerous false citations likely persists in the work generative AI may produce for students. though it is possible that generative AI will improve and gain effectiveness against producing hallucinations, for the time being faculty should teach students ai literacy skills. key among these is the ability to analyze and critique the output from generative AI for quality, accuracy, and correctness. if students are working on a research project, such as the legal brief assignment described in the scenario below, it is important to ask and remind students to corroborate and check any citations or studies presented by generative AI. some argue that because of the possibility of hallucinations, students should not exclusively rely on generative AI for sources and citations for an assignment (wellborn, ). instead, students should review and check any citations or summaries created by generative AI for accuracy. though generative AI may provide a basis for the discussion at hand, students should corroborate and expand on it. the technology is rapidly progressing in this area (tay, ). ", "#### biases of output generative AI simply analyzes a prompt and then \u201cparrots\u201d an answer back from its llm (large language model). \u201cthe model (for chatgpt) was trained using text databases from the internet. this included a whopping gb of data obtained from books, webtexts, wikipedia, articles and other pieces of writing on the internet. to be even more exact, billion words were into the system\u201d (hughes, ). if some biased or prejudiced sources are present among the training data and contribute to the construction of the llm, then those biases or prejudices may appear once again in the output from generative AI. it is also important to note that not including substantial content from or with certain perspectives or demographic groups in the training data may also produce biased content. such content \u201ccan manifest in a myriad of ways, ranging from gender bias, racial and ethnic bias, socioeconomic bias, cultural bias, content bias, and ideological bias in terms of political, philosophical, and religious perspectives\u201d (, , p. ). ultimately, generative AI may reinforce and perpetuate social marginalization. the research so far has established two relevant and urgent concerns: - **marginalization of conservative perspectives in the viewpoints generated** **by llms:** \u201cmodels trained on the internone tend to be biased toward less educated, lower income, or conservative points of view. newer models, on the other hand, further refined through curated human feedback tend to be biased toward more liberal, higher educated, and higher income audiences\u201d (myers, ). for example, the latest gpt model () relies on and uses rlhf (reinforcement learning from human feedback) (, ). because of this, conservatives have voiced and raised concerns about the potential bias displayed in the output of generative AI. chatgpt has been found to display a \u201cpro-environmental, left-libertarian ideology\u201d (, ). by asking questions related to the political compass test, rutinowski et () reached a similar conclusion: \u201cchatgpt seems to hold a bias towards progressive views\u201d (p. ). a study by santurkar et () also determined that the perspectives expressed by llms sharply diverged from those held by various demographic groups in the united states. - **dated and dangerous stereotypes based on gender and race, especially in** **images generated by ai:** these concerns about bias also extend to artificially generated images. a bloomberg analysis (, ) found that stable diffusion, an image generator driven by artificial intelligence, placed men with lighter skin tones in higher-paying jobs and women and individuals with darker skin tones in lower-paying or domestic jobs. social stratification in these images was found to be higher than exists in the data from the bureau of labor statistics. in addition, \u201cmore than % of the images generated for the keyword \u2018inmate\u2019 were of people with darker skin, even though people of color make up less than half of the us prison population, according to the eral bureau of prisons \u201d (, ). the research has established that generative AI may create content with bias across multiple modalities. therefore, **faculty should draw students\u2019 attention to these** **issues and invite students to appraise and review generative AI\u2019s output for** **biased viewpoints or inaccurate and harmful stereotypes** . students should approach the content they receive from generative AI with a critical and socially engaged eye. with conservatives often expressing concerns about their views being marginalized on college campuses and with students becoming more diverse and non-traditional as society changes, it is important for us to treat them all with respect and to acknowledge when generative AI may fail them. ", "#### scenario you teach an online course on constitutional law for . you have asked students to select a clause within a constitutional amendment of their choice, generate a hypothetical legal case, and then compose a corresponding legal brief describing the relevant precedents associated with the clause and/or amendment and established by . this legal brief must cite specific decisions, discuss how the \u2019s understanding of the clause and the amendment may have evolved over time, and develop an argument about how this understanding applies to and informs the case at hand. you receive a legal brief from a student about the equal protection clause of the fourteenth amendment, discussing how its role in society has expanded from its passage to . however, as you review the brief, you notice something: in addition to including cases like _ of education_ , _ , and others, the legal brief contains citations for cases you do not recognize at all. you begin doing research and realize these cases do not exist. they never happened. concerned, you confront the student. once you do so, the student admits that she relied on chatgpt to write a good portion of the legal brief and did not bother to check if all the included cases were actually real. you decide that while the student will lose points on the \u201crelevant case law\u201d section of the rubric, this could serve as a learning experience for her and others. what would you like to tell her and her fellow students? _note:_ _[actual /nyregion/avianca-airline-lawsuit-chatgpt.html)_ _inspired this scenario._ ", "### issue #: reinvigoration of your teaching and students\u2019 learning ", "#### summary generative AI will and should challenge all of us to change how we teach and how students learn. with new technologies, the opportunity emerges for us to innovate and experiment, creating fresh and engaging learning experiences for students. if properly designed, structured, and implemented, the use of generative AI by students could potentially contribute to and enrich their learning. as we consider the future of teaching and learning with generative AI, please keep in mind the following: - **our role in the classroom, physical or virtual:** heeding the trite, either/or dichotomy of the \u201cguide on the side\u201d versus the \u201csage on the stage,\u201d we should practice humility, take a both/and approach, and remain open-minded about the role we may come to play in students\u2019 learning experience in this new world filled with ai and its contributions to education. - **the importance of focusing on the journey:** using a process-centered approach to teaching and learning will guarantee that we design potent learning experiences. by concentrating more on the journey, we can offer more structured, meaningful, and active activities and assignments for students that foster metacognition and reflection, encourage students to take ownership of their learning, allow for more formative assessments, and ensure students do not come to depend on generative AI exclusively. ", "#### divergent metaphors of teaching and learning it is among the most pervasive cliches in teaching: we should aspire to serve as a \u201cguide on the side\u201d rather than the \u201csage on the stage.\u201d with the advent of the internet, students could obtain information and knowledge with ease and convenience, and so teachers faced the challenge of moving from delivering knowledge to creating and sustaining learning experiences. now that generative AI has emerged, we must further embrace that role as a guide on the side. after all, generative AI can: - step beyond search engines, which merely present available content and information of relevance to a topic, to synthesize and produce content and information. - offer feedback and clarification on content and information. notwithstanding concerns about accuracy, if correctly guided and prompted, generative AI could effectively teach a student about the causes of the decline of the roman empire or produce an essay about the differences between dark matter and dark energy. it seems that with delivering information, evaluating work, and creating content, generative AI could potentially replace the work of the teacher and student. for this reason, much of the conversation about generative AI approaches learning as a sort of factory in which the teacher offers information and instructions in a top-down manner and students must work in isolation to manufacture a product. however, with the potential of generative AI, we perhaps can no longer view ourselves as experts depositing knowledge in the minds of students, demonstrating and adhering to what paulo freire () calls a \u201cbanking model of education.\u201d instead of conforming to such a model, in which we serve as the \u201csage on the stage,\u201d we should view ourselves as conductors, \u201cguides on the side,\u201d facilitating a symphony of learning, in which students use instruments that include but are not limited to generative AI to create something beautiful and memorable. ", "#### why educators still matter though theoretically valid, concerns about generative AI supplanting the work of teaching and learning ultimately approach students with a limited conceptualization of what takes place in the physical or virtual classroom. generative AI cannot perform certain tasks and cannot accomplish certain hallmarks of good teaching. please review what generative AI cannot do and identify where educators could still play a role in the learning experience of students. unlike (and according to) generative AI, only educators can offer students the following: - **intuition and empathy:** human teachers can establish emotional connections with their students, creating a supportive and empathetic learning environment. they have the capacity to sense and respond to the emotional and social dynamics within a classroom. they can gauge the mood of the students, detect signs of distress, and provide appropriate support. this intuition and empathy are essential for fostering a positive and inclusive learning environment. - **creativity and improvisation:** teachers often need to think on their feet, adjusting their lesson plans or explanations in real-time based on students' reactions and questions. they can employ creative teaching techniques, analogies, and examples to enhance understanding and engagement, tailoring their approach to the specific needs of the students. - **motivation and inspiration:** human teachers can inspire students and instill a passion for learning. through their own enthusiasm, storytelling, and real-life experiences, they can ignite curiosity and encourage students to explore subjects beyond the curriculum. - **mentorship and guidance:** human teachers often serve as mentors and role models for students, offering guidance not only in academics but also in personal growth, career choices, and character development. they can provide valuable advice, share wisdom, and nurture the holistic development of their students. - **social and interpersonal skills:** teaching involves social interactions, and human teachers possess the ability to navigate and facilitate these interactions effectively. they can foster collaboration, communication, and teamwork among students, promoting social skills and emotional intelligence. - **ethical decision-making:** teaching involves making ethical decisions in various situations, such as handling sensitive topics, addressing student behavior, and respecting diverse perspectives. human teachers can exercise judgment, empathy, and moral reasoning to navigate these complexities. in other words, they can engage in critical thinking and reflection (reflection will also play a critical role in how students will learn with generative AI). ", "#### process-centered teaching educators can demonstrate why they matter still in the classroom by taking a process-centered approach, in which we demonstrate an investment in the learning journeys of students. one of the most common concerns with generative AI\u2019s impact on education is that students will rely on it to produce much if not all of the product they submit. if a student is asked to write a research essay or some code to execute a task, he or she may turn to chatgpt or bing for some of the content, only to then expand on and change some of it. with generative AI playing a significant role in the ultimate submission, educators naturally have concerns about the extent to which students have engaged with the assignment and concepts at hand and achieved the learning outcomes set. notice: we are focusing on the ultimate work the student turns in for a grade and nothing that has taken place beforehand. the conversation about generative AI often focuses on the destination. educators express concern that by using generative AI, students will \u201cteleport\u201d to the destination without doing the hard work of actually journeying cognitively toward it. however, underlying and unacknowledged in these worries is that educators may often focus exclusively on the destination in their pedagogy and not guide and facilitate students\u2019 journeys in reaching it. it is a universal cliche: life is about the journey and not the destination. the same applies to learning and the work we would like to see from students. **generative AI may challenge us to focus more on the journey of students. in** **other words, we may adopt a process-centered approach rather than a** **product-centered one in our teaching.** what are the differences between product-centered teaching and process-centered teaching? please review the table below, adapted from white (), that discusses how these approaches diverge from one another in their pedagogy, their epistemology, their curricula, and their power dynamics. **differences between product-centered and process-centered teaching** |product-centered teaching|process-centered teaching| |---|---| |pedagogy: what is the heart of teaching and learning? focus on what is to be learnt emphasis on subject learning directed externally|pedagogy: what is the heart of teaching and learning? focus on how it is learnt emphasis on process learning directed internally and self-fulfliling| |epistemology: where does knowledge come from? knowledge external to the learner knowledge from determination by authority|epistemology: where does knowledge come from? knowledge internal to the learner knowledge from negotiation between learners and where does the content to be learned come from? content from subject matter expert content: gift to learner from teacher or knower|curriculum: where does the content to be learned come from? content from learner content: what the learner brings and wants| |power dynamics: who has power and control over teaching and learning? teacher as decision-maker objectives defni ed in advance assessment by achievement or by mastery doing things to the learner|power dynamics: who has power and control over teaching and learning? learner and teacher as joint decision-makers objectives described afterwards assessment in relationship to learners\u2019 criteria of success doing things for or with the learner| you may notice that adopting a process-centered approach also calls for you to reconceptualize and reinvigorate our role and approach as an educator. however, you may wonder: how exactly may product-centered and process-centered teaching affect how students use generative AI? - **product-centered teaching and generative AI\u2019s ensuing role in learning:** it is important to note here that for many major assignments, the instructor may provide an introduction to it for the class, answer some questions through , and then leave students to work on and complete it in isolation until the due date. focusing primarily on the product that students will submit, this approach neglects to provide students the scaffolding and structure to move forward and thrive with the project. this absence of structured guidance to facilitate movement forward leaves students on their own and the door open to the potentially excessive use of generative AI, impacting students\u2019 learning. after all, generative AI can create the entire product in question with some guided prompting. - **process-centered teaching and generative AI\u2019s ensuing role in learning:** with a more process-centered approach, in which the teacher accompanies, guides, and equips students in their learning, students will engage in more deliberation and contemplation about their work. in addition, students will experience and enjoy numerous activities and interactions that facilitate their progression through their learning and foster metacognition. after all, \u201cprocess is much harder to fake\u201d (dietz & keys, ). though it is likely (and acceptable) that students will turn to generative AI throughout the process, students will not rely on but rather collaborate with tools like chatgpt and duet ai. **instructional strategies for process-centered teaching** some strategies to cultivate a process-centered approach that would accommodate and acknowledge the role generative AI could play, include: - **reflections and discussions** on one\u2019s personal experience with and attitudes toward a topic throughout (before, while, and after working on a project) - **gathering and synthesis of research** on a topic to identify themes and insights that generative AI may lack (annotated bibliography, etc.) \u25cb a tool like powernotes could support and facilitate this process well. please note that powernotes is currently only available for of missouri flagship campus in columbia. - **one-on-one conferences** with students to discuss a project - **critiques of the output from generative AI** for various stages in the process (brainstorming, outlining/planning, drafting, revising, and editing) - **expression across multiple modalities** (outlining or planning through creating a slideshow or infographic, doing peer review through podcasts, etc.) - **other activities (kwls, etc.) and** **classroom assessment techniques** **(cats)** , or formative check-ins (iowa state center for excellence in learning and teaching, n.d.) \u25cb kwls: students identify what they _know_ and what they _want to know_ at the beginning of a unit or project. at the end of the unit or project, students then articulate and describe what they have _learned_ . ", "#### scenario **the problem** throughout your career so far, you may have used a top-down approach to teaching environmental biology: deliver lectures and then assess how well students have learned the content through exams. this approach concentrates on the product (the achievement of the learning outcomes) and not on the process (the students\u2019 engagement with and exploration of contemporary issues at the intersections of biology and sustainability). you have relied on a familiar and comfortable routine for your curriculum for now: deliver content, whether by traditional lecture for face-to-face sections and through video for asynchronous online sections, and ask students to reflect on and discuss the concepts at hand, either through think-pair-shares or discussion forums. you then ask students to complete open-book assessments, such as quizzes or tests, to demonstrate their learning. it has come to your attention that a significant portion of your students are now using chatgpt for assistance during these open-book exams, even though you have told them to rely on the digital textbook and authoritative websites. you believed offering open-book assessments would allow students to focus on higher-order thinking about matters involving biodiversity and sustainability, but it now seems your students may no longer bother to engage with the concepts as deeply or critically as they previously had. instead, students are now merely relying on chatgpt for information about the sixth mass extinction and the anthropocene, information they then build on or modify to answer the essay questions. you begin to wonder: should you change how you teach, and, if so, how? **the solution** you decide to reduce your reliance on traditional, unidirectional teaching practices, such as the lecture, partially. with the cornucopia of information available on the internet and through generative AI, students can locate and find information and ideas about the sixth mass extinction and other topics. approaching your work as a guide on the side rather than the sage on the stage, you create structured opportunities for students to use the internet and generative AI to learn more about, create content regarding, and reflect on these matters in small groups. students can then share their findings, insights, and learning with the remainder of the class through presentations and other strategies. altogether, the change you have implemented is embracing inquiry-based learning: you have changed the class such that it now frequently challenges students to learn about a specific topic or issue, either individually or collaboratively, and then share their findings with the class. students are invited and encouraged not only to use insights from generative AI but also to corroborate and expand on them through finding and integrating relevant academic research. ", "### issue #: cultivation and growth of skills ", "#### summary as we design learning experiences that allow and accommodate the use of generative AI, we must remember to reinforce and build students\u2019 skills in communication and collaboration. we must also encourage and invite creativity and innovation through offering more choices, more modalities, and more open-ended assignments and activities. one last important consideration in this regard is that we should strive to summon students to higher levels of bloom\u2019s taxonomy . with a well-designed curriculum, generative AI could support students\u2019 in learning to communicate more effectively, in stretching their imaginations and creative muscles, and in facilitating higher-order thinking. ", "#### defining, teaching, and assessing skills \u201cto participate effectively in the increasingly complex societies and globalized economy that characterize \u2019s world, students need to think critically, communicate effectively, collaborate with diverse peers, solve complex problems, adopt a global mindset, and engage with information and communications technologies, to name but just a few requirements\u201d (vivekanandan, ). while we may not explicitly account for these skills in developing our learning outcomes and curriculum, we should consider how our teaching will cultivate and contribute to the growth of them. however, the question may naturally and inevitably arise: how can we ensure students grow in these skills and do not offload the work of communication, creation, and thinking critically to tools like chatgpt, claude, or duet ai in full? authentic or alternative assessments and activities can play a substantial role in ensuring students still practice and build these skills while potentially using generative AI. many different authentic or alternative assessments and activities exist and may help with meeting the challenges and answering the pedagogical questions posed by generative AI. in addition, there are some authentic or alternative assessments and activities that can deliberately and conscientiously call for the use of ai. below you will find some suggestions for authentic or alternative assignments and activities that both include the use of generative AI and ensure students remain active in their learning and practice some key skills, including communication/collaboration, creativity/innovation, and critical thinking. after we consider these suggestions, we will relate them to a scenario of teaching an environmental biology course. **communication and collaboration** here are some examples of assignments and activities, suggested by chatgpt. teachers can use these strategies and others to foster and invite communication and collaboration among students, who may leverage generative AI as part of their learning and workflow. - **collaborative writing:** assign students a writing task where they work together to create a piece of written content related to their discipline. they can use generative AI to generate ideas, prompts, or even assist in the writing process, taking turns contributing and editing the content. - **presentation and debate:** assign students a topic or issue within their discipline, and have them prepare and deliver presentations to the class. after each presentation, encourage a debate where students can ask questions, challenge viewpoints, and engage in constructive discussions using generative AI-generated content as reference material. **creativity and innovation** here are some examples of assignments and activities, suggested by chatgpt. teachers can use these strategies and others to cultivate and encourage creativity and innovation among students, who may leverage generative AI as part of their learning and workflow. - **content creation using multimedia:** instead of traditional essays or presentations, encourage students to produce content with multimedia created with generative AI tools. they can incorporate ai-generated text and visuals, interactive elements, and multimedia components to communicate their ideas creatively, capturing the attention and imagination of the audience. you will find a discussion of designer, one tool that would [support this, /design-like-pro-with--designer/) (, ). - **data visualization with ai:** task students with creating dynamic and visually appealing data visualizations using generative AI. they can use ai algorithms to analyze large datasets from their discipline and generate visual representations that communicate complex information in innovative ways. students can explore different visualization techniques, colors, and interactive features to make their data visualizations engaging and creative. **critical thinking** here are some examples of assignments and activities, suggested by chatgpt. teachers can use these strategies and others to call for and bring about critical thinking and problem-solving among students, who may leverage generative AI as part of their learning and workflow. - **argumentation and debate:** assign controversial topics or issues for students to research and develop arguments. encourage them to critically analyze the strengths and weaknesses of different perspectives, fact-checking, comparing, evaluating, synthesizing, and using ai-generated information from various tools to support their claims while also considering its potential limitations. - **reflection and self-assessment:** incorporate regular reflection activities where students can assess their own critical thinking skills, including how effectively they use ai tools. encourage them to identify areas for improvement and develop strategies for enhancing their critical thinking abilities. ", "#### scenario in the environmental biology course you teach, you have decided to accept and embrace the use of generative AI by students as part of their learning. however, how can you ensure students still practice and build skills while making use of tools like chatgpt and bard? below you will find some examples of possible ideas and strategies. **communication and collaboration** you have introduced the hippo acronym that identifies the causes of ongoing defaunation: habitat loss, invasive species, pollution, population growth, and overharvesting. students then join teams, in which they must work together to learn more about their assigned cause from the hippo acronym. as students engage with one another to learn more, they not only rely on chatgpt for common perspectives (and potential misconceptions) but also locate and use peer-reviewed research and other authoritative sources for more accurate and reliable insights and information. after gathering further information, students collaborate on a shared presentation on the graphic design app /creative-services/graphic-design-and-interactives/using-canva-course-design) . they are working together to develop the materials they will share with the class through a [panopto video recording of the aforementioned slideshow. through this activity, students learn to collaborate effectively with others and to use written, oral, and visual communication strategically to convey information and ideas. **creativity and innovation** you have decided to transform your curriculum and design a multigenre ) [project (langstraat, n.d.) that will play a key role in students\u2019 learning this semester. students will select an ongoing issue in environmental biology, such as defaunation. then they will do research on that topic, gathering and analyzing sources, and then use themes or ideas from their sources to create a multigenre research project. this multigenre research project will not explicate but rather render the topic at hand (romano, ): students will not explain it but rather bring it to life through various artifacts, such as first-person diary entries from or podcast interviews with affected species, infographics featuring statistics, or psa videos to hypothetically share on social media. while composing these artifacts, students will use ideas and possibilities produced by generative AI tools but will have to apply and compose them across various genres. being asked to compose these various artifacts, even with input from generative AI, will challenge students to use their imagination. while practicing communication in these various genres, students will also become familiar with the discourse and best practices for each modality. **critical thinking** to conclude the unit on the sixth mass extinction in your environmental biology course, you decide to eliminate the test and replace it with an alternative assessment: a reflective portfolio in which students must keep video diaries for and then reflect on how their actions may contribute to or prevent ongoing defaunation. students cannot rely on chatgpt or other tools for this as much as they would have for a generic essay about the topic, and the assignment forces them to grapple with and analyze how current human systems as a whole cause defaunation. students will engage with higher levels of bloom\u2019s taxonomy (armstrong, ): applying what they have learned about hippo, analyzing and evaluating the environmental impact of their own actions, and synthesizing these observations to identify how they as individuals and human systems altogether could change to better support ecosystems. ", "### issue #: effective prompting through prompt engineering ", "#### summary as students use generative AI for the purposes discussed above, we must provide explicit instruction and structured guidance in crafting and submitting effective prompts. called \u201cprompt engineering,\u201d this process will ensure that when generative AI may play a role in students\u2019 learning, they can use it to achieve desired results. ", "#### four elements of an effective prompt an effectively written prompt should contain the following four elements, though they may do so to varying degrees: - **instruction:** the task assigned to the generative AI tool. some examples include: \u25cb chained prompting: posing follow-up questions or prompts \u25cb self-critiques of output: asking generative AI to review or critique its own previous output - **context:** additional information about the \u201csituation\u201d surrounding the output \u25cb identifying the rhetorical situation: explicitly articulating the purpose, audience, and genre of the output \u25cb being specific and detailed with prompt - **input data:** further information in the input to generative AI - **output indicator:** specification of the output desired output \u25cb indication of preferred writing style (flesh-kincaid reading levels, amount of technicality and , etc.) and length (one paragraph, a five-paragraph essay, etc.) of output \u25cb request for certain presentation format (through tables, lists, outlines, etc.) \u25cb use of a prompt previously created by generative AI (created in response to your asking it for a prompt you will later use) ", "#### some tips for writing prompts what are some simple and effective strategies for creating an effective prompt? here are some tips that you may like to share with students so that they can use them in their workflow with generative AI. . start simple. . break down complex tasks. . use clear instructions. . separate elements. . specify details of output, such as length. . be precise. . focus on what to do. ", "#### scenario you have asked students to use claude, chatgpt, or any program of their choice to compare and contrast various coding languages in your computer science course. however, as you circulate around the room, you find many students consider the responses vague and perhaps even meaningless: the output lacks concrete details, according to many. you decide to bring the class back together to discuss the importance and value of chained prompting, in which students take an iterative approach to achieve the output they desire. in addition, you explain the importance of offering specific contexts as part of the input to generative AI, so that there is a more meaningful situation for claude or chatgpt to consider and discuss. ", "#### conclusion as generative AI comes to play more of a role in the world, it is natural for us to worry and wonder about how it will affect the learning of students. there is understandable concern, anxiety, and frustration on the part of faculty. however, generative AI could amount to less of a threat and more of an opportunity with thoughtful and effective pedagogy. this document is not an absolute and comprehensive guide to navigating the use of generative AI by students in your teaching. instead, it is only a starting point for you to begin to contemplate how to adjust your policies and pedagogy. **as you begin to** **consider how to best integrate generative AI in your teaching, please do not** **hesitate to discuss and brainstorm your ideas and concerns with missouri online.** **you are welcome to reach out to an instructional designer at** **teaching@missouri.edu** **.** ", "# its overview \u2013 generative AI tool usage, _ _ the current wave of generative artifici intelligence (ai) technologies such as: chatgpt, dl-e , bard, midjourney, stable diffusion, musiclm, et has rapidly captured the attention, and imagination of higher education and the gener public ike. these are novel tools, and instructors, administrators, technologists, and students are l experimenting with their use in various settings including academic settings. this overview highlights some key considerations for using this type of ai at from its\u2019s perspective. it does not directly address use of the technology by students for classwork. when using these tools at , please take l of the materi below into consideration. - use of these tools must comply with l existing university policies. - acquisition of new ai software/services, like any other software, is subject to the \u201cgettech\u201d process. ) - faculty considering the use of generative AI themselves, or possible use by students in their classes, should refer to the center for teaching excellence\u2019s page, [/ appropriate use of generative AI - **cite your source(s).** generative AI, as of this writing, is somewhat notorious at not providing proper citations as to where it borrows information from in constructing answers to questions. if you use generative AI, you should cite either the origin sources, if possible, or simply that you used a given generative AI engine on . similarly, if you use ai to generate images, you should cite this in the image label. this is a tradition practice in academia and should be neither a surprise nor an inconvenience, and it is so ethicly appropriate not to claim credit for others\u2019 work, aka plagiarism. - **inspiration and summarization** . using generative AI to draft a document, or to shorten a document from say pages to page, can save significant time. given that the technology is currently prone to errors and biases, you should carefully review any such materi generated by ai \u201cdangers\u2026\u201d (see below) and consider citing your use of the technology if it contributes substantily to the fin product. - **research** . experimenting with this technology as an anytic or research tool, while mindful of the \u201cdangers\u2026\u201d (see below), is immensely important to the university and to society as a whole as we grapple with a very different technology than what most of us are used to. please share what you learn, even if inform, with the rest of the community. materi in this section is reworded for academia from / dangers of artifici intelligence - **privacy** : whenever using or interacting with an ai system, such as when chatting online with chatgpt, or asking an ai system to anyze or summarize data for you, be aware that any information you enter into the system can not only be processed but so retained and used by the ai to give answers to others. this means if you enter any person information about yourself or any confidenti information, that information will be stored and potentily shared with or sold to others. do not share or enter any information that you consider sensitive, person, or is confidenti data or research data. - **gorithmic bias:** has warned that \u201cai is not neutr: ai-based decisions are susceptible to inaccuracies, discriminatory outcomes, embedded or inserted bias.\u201d users of ai must be cognizant of this. - **recreating voice/video** : ai solutions can take a recording of a person\u2019s voice \u2013 your voice for example \u2013 and then use it to create re-time audio that sounds just like you. so, a cyber attacker could create a message that sounds like you, potentily tricking your coworkers into thinking you cled and asked them to take an action. ai can so do this with pictures or video. sometimes cled deep fakes, an ai solution can take an existing picture or video of you and use it to recreate entirely new pictures or videos (including your voice) appearing to show you doing things that you never did. because of this, you should be wary of posting extensive voice or video of yourself on the internet, and so be skeptic of recorded messages of colleagues. finly, do not mis-use the technology to engage in this type of re-creation yourself. - **wrong answers** : regarding the data or answers ai provides, the solutions can be wrong. ai often uses public information from the internet, and its answers may be influenced by the biases of its developers or the data it was \u201ctrained\u201d on. while typic search engines are designed to provide you the \u201cbest\u201d or most correct answer to your queries, solutions like generative AI may be designed to give you the most human-like answer. which approach is better depends on what you are attempting to accomplish. people so give wrong answers, of course. but we ready know this and know to check peoples\u2019 answers \u2013 generative AI answers should so be checked as appropriate. - **privacy** : whenever using or interacting with an ai system, such as when chatting online with chatgpt, or asking an ai system to anyze or summarize data for you, be aware that any information you enter into the system can not only be processed but so retained and used by the ai to give answers to others. this means if you enter any person information about yourself or any confidenti information, that information will be stored and potentily shared with or sold to others. do not share or enter any information that you consider sensitive, person, or is confidenti data or research data. this section is largely adopted, including significant wording, from:  ", "#### generative AI: guidelines for educators ", "##### contents introduction part : recommendations what everyone needs to know what lecturers and other educators need to know and do what programme managers and institutional leaders need to do what students need to know and do part : detailed guidelines what everyone needs to know what lecturers and other educators need to know and can do what programme managers and institutional leaders need to do what students need to know and do part : further reading, links, and resources ----- ----- ", "# ", "### recommendations ", "##### part : recommendations ", "###### what everyone needs to know ) tools which include artificial intelligence (ai) can produce impressive outputs, whether well-structured and fluently written reports, images and graphics, computer code, or mathematical solutions. they have a huge potential range of applications. ) this technology is becoming ubiquitous, embedded within major software suites (such as office, google workspace, etc) and browsers, and has spurred the development of a large number of new apps and tools proffered by a myriad of start-ups and project teams. ) it is crucially important for everyone to be aware that these tools generally are based on mimicry and reproduction of content, style, and genre and are not always optimised to provide factually correct answers. nor should their speed, conversational interface, and apparent quality of their output be taken as evidence of any \u2018intelligence\u2019 or subject expertise. ) there are concerns about how the tools are developed and trained (around copyright, intellectual property, wellbeing of those hired to screen and label content, energy usage, etc) as well as how they may be misused or misapplied. ) it is important that everyone is familiar with their current institutional policy on the use of generative AI, bearing that it is likely to be updated on a regular basis. ", "###### what lecturers and other educators need to know and do ) be familiar with these tools and their availability, and recognise their limitations and affordances. ) as soon as you can, review all your assessments, replacing or modifying any which may be completed satisfactorily by someone using ai without an appropriate level of understanding of the subject, or which are vulnerable to breaches of integrity or security. if you identify a particular appropriate role for generative AI in your courses, then ensure that students are aware of what constitutes authorised and unauthorised use. ) work with colleagues, and within disciplinary communities, to design assessments which have strong validity (i.e., clearly aligned with the learning outcomes and the skills which they are meant to demonstrate) and in which there is an appropriate balance of credit between the process of preparing for and undertaking the assessment and the final product, helping students develop self-efficacy, critical thinking, and a professional disposition. ) take the opportunity, at programme level, to review overall assessment volume, range of assessment types, and alignment with intended programme outcomes across the complete programme and cohorts, identifying any vulnerabilities, over-assessment, and opportunities for enhancement. ) be consistent in your approaches to student training, assessment practice, and in the implementation of institutional academic integrity policies, data protection, and assessment regulations. there must be clear information for students that unauthorised submission of the output of generative AI as their own work constitutes academic misconduct and will be treated accordingly. ) in your partnership with students, emphasise values such as integrity, trust, and truthfulness as being at the heart of learning, knowledge discovery and creativity. ", "###### what programme managers and institutional leaders need to do ) ensure that there is up-to-date and regular training for all staff and students on academic integrity, ai, and assessment, and that appropriate resources are allocated to this area to ensure that all avail of it. ) programme leaders should work with colleagues to plan and undertake a comprehensive review of assessment, focusing on validity, range of types, and volume, with a view to enhancing both the programme design and the student learning experience. ) update, and regularly refresh, policies on academic integrity, including the use of generative AI, and assessment to more effectively reflect and respond to these issues and take the opportunity to reiterate the valuable educational purposes of assessment. ) develop an institutional ethos and culture which emphasises integrity, honesty, trust, and respect, rather than let the conversations be dominated by suspicion, surveillance, and distrust. workshops and training events which promote dialogue and engagement can be valuable in this regard. ", "###### what students need to know and do ) ai tools are appearing everywhere these days: embedded within packages that are used to write text, produce slide-decks; or in new apps and services that get promoted on social media. they can be useful for many types of tasks, but they also have serious limitations and can give unreliable answers whilst appearing confident and convincing. ) it is crucial to be aware of what these tools can and cannot do, as well as recognise the ethical concerns associated with their development and use. ) assessment is meant to provide the student with an opportunity to demonstrate achievement of the intended learning outcomes of the module or programme, to the standard required. lecturers often use assessment tasks as a means of helping students focus on the key knowledge and skills that they need to develop and encourage them to practice and build their confidence. it is important that students bmit work that they have produced and acknowledge the sources used, as well as paying close attention to the requirements of the task and policies on academic integrity. ) in reality, assessment can be stressful, but to maintain integrity (both personal integrity and that of the qualifications), students should resist any attempts to take \u2018shortcuts\u2019 or engage in any form of misconduct (copying, plagiarism, bmitting materials produced largely by generative AI, etc). if a student feels unable to complete the assessment for whatever reason, they should discuss this with their lecturer, counsellor, officer or appropriate person and see what alternative arrangements can be made. ----- ----- ", "# ", "## detailed guidelines ", "##### part : detailed guidelines ", "###### what everyone needs to know () ai is becoming ubiquitous and embedded within more of the tools and software we use in everyday life and in research, learning, and teaching. the pace of change is rapid and it makes sense to anticipate further significant advances over . browsers, word-processing packages, spreadsheets, presentation software, audio, imaging, graphics, and video tools are all increasingly making use of such technologies, including core product suites from and . by default, users of these tools will be presented with \u2018suggestions\u2019 on anything which they write or design. () generative AI tools such as the \u2018large language models\u2019 on which chatgpt, bard, and others are based, are designed to write well in terms of language, style, and syntax, rather than in terms of whether what they write is factually correct or accurate. it is crucially important to understand how such technologies work and be aware of their limitations as well as their apparent strengths. they are not \u2018intelligent\u2019 in any real sense, nor are they experts on topics, but rather largely rely on statistical predictions of word combinations or image features. () there are also concerns about ethical (and environmental/energy use) aspects in how such tools are developed, trained, and deployed and it is important to be aware of these, particularly with regard the lack of transparency on the information that has been used to \u2018train\u2019 the systems and whether copyrighted materials have been used and sources which are heavily biased some moves are being made recent releases of tools built on \u2018generative AI\u2019 have made headlines across the world. at first glance, their capabilities seem impressive: writing fluent text on any subject, eloquently expressed with excellent structure and grammar; producing visually arresting images in any specified genre; constructing (and explaining) computer code for simple or complex tasks; suggesting statistical tests for data sets and producing a range of analyses; solving mathematical and other symbolic manipulation challenges. their speed of response, their conversation-like ability to build on previous prompts and answers, and their (superficially, at least) plausible output, however, runs the risk of anthropomorphism and the presumption that behind the scenes there is a nascent, if not fully enacted, \u2018intelligence\u2019. the implications of these tools for assessment are very significant as they run the risk of increasing intentional and unintentional misconduct. in addition, beyond assessment, in the wider world, they may well contribute to the dissemination of misinformation, false accusations, libel, breach of copyright, insertion of erroneous computer code into systems, and other legal and ethical issues. used well, they could offer benefits for learners, document preparation, media production, and even lead to newer forms of creativity. clearly, a critical digital literacy which addresses the development and deployment of ai is essential for all of us. in these guidelines, however, we will focus on assessment and have grouped together key information and suggested courses of action for staff, students, and higher education institutions in the short-term. internationally to consider potential forms of regulation, although quite what shape these will take is very uncertain. () as technologies develop, appropriate roles in education may be found, but if they are used to bypass rather than support thinking, or used to acquire academic credit which has not been earned via real, intellectual engagement with the subject of study, then they can undermine the educational enterprise. part of the current challenge for educators, learners, and institutions is to determine the range of beneficial applications which might be afforded by such tools. ", "###### what lecturers and other educators need to know and can do () ensure that you are aware of recent and new generative AI tools, including those associated with supporting writing, and others which might be relevant to your particular discipline, such as those which assist the development of computer code, solve mathematical problems, generate graphics, video, and audio content, etc. try to derstand what these tools can and can\u2019t do (including by trying them out on your own assignments or subject content), and, in particular, avoid mistakenly attributing subject expertise, intelligence, or capacity for reflection to such software. it is useful also to be aware of ethical and legal concerns over how such tools are developed and used, as well as the potential inequality of differential access (e.g., on the basis of cost). () increasingly, educators are sharing use cases of where ai tools might be useful in designing courses, lesson planning, assessment design, student feedback, etc. whilst as the technology improves, there is no doubt that generative AI will be more useful in many professions and contexts, we still urge caution, particularly in terms of the accuracy of its outputs and the fact that it is largely based on statistical models and hence reproduces or mimics rather than being capable of generating original content. there are many cases where a traditional search strategy (using a search engine or library tools) is much more effective and has the added benefit of identifying original sources and allowing you to make judgements about accuracy and quality as well as to provide due credit to the original authors. this is a key point that should also be included in any training of students about information gathering and research. () if you are using generative AI tools in your own academic practice, then you should model appropriate use with your students, acknowledge where generative AI has assisted in your work, etc. it is important not to input personal, private, sensitive, or copyrighted materials (including student work) into such tools less you have appropriate levels of legal guarantees. many of the freely available tools at the moment do not have such protections in place. () in designing assessment, it is important to ensure validity, i.e., that assessment should be a means whereby each student demonstrates that they have attained the intended learning outcomes to an appropriate standard and that this should be the basis on which academic credit is awarded. - it is important to clarify and reiterate this point with students and to demonstrate how the assessment fits this intention. - it may be appropriate to revisit your original learning outcomes to ensure that they are aligned with how you teach, the tasks you set students, and the chosen forms of assessment. () if you intend for students to use generative AI or ai-supported tools in any assignment, make this clear. it may not be possible to simply state \u2018do not use ai for this assignment\u2019 given the technology\u2019s ubiquity, so the emphasis should be on what the student actually does to demonstrate their attainment of the intended learning outcome with which the assignment is aligned. if the student constructs a report or essay through clever \u2018prompt engineering\u2019 which could have been done by anyone not taking this module, then this does not provide the basis for an award of marks or credit. where students are expected to use ai tools, ensure there is clarity on how and why they used such, with an appropriate declaration on any submitted assignments. () there will be cases where it is clearly inappropriate to use generative AI and, in those cases, state this clearly in the instructions provided to students and ensure that you are able to make the format of the assessment sufficiently secure and robust. () academic integrity is breached if students submit the products of generative AI as their own work without acknowledgement or without authorisation to use generative AI in fulfilling the task. it is important to ensure that students are informed that this constitutes academic misconduct and that they should only be seeking credit for work which they have produced themselves, and that they are responsible for correctly referencing and acknowledging sources and resources used in their work. () review all assessments and assignments in terms of whether or not they are susceptible to being completed successfully by an ai tool without the student having to engage intellectually, or personally, with the subject. some common types of assessment should be no longer considered to be sufficiently robust to award scores which cot towards official grades. these may still be perfectly valuable for self-assessment and formative practice. these include: - take-home essays, reports, or similar documents focused largely on subject knowledge content and with an \u2018all or nothing\u2019 submission by a single deadline and where marks are based on structure, style, and information; - online mcqs and other similar types of tests delivered online in -invigilated and/or remote contexts, whether \u2018live\u2019 or asynchronous. () the capabilities of current ai systems are expanding rapidly, including the advent of plugins and connections with other tools and resources (search engines, mathematical engines, drawing packages, etc). this means that the range of assessment types that it can be used to support (or subvert) is extensive. tasks such as developing a plan, a strategy, making a case, comparing and contrasting, inventing data for an experiment, plotting graphs, producing a slide deck on a topic, writing code, analysing data in spreadsheets, compiling a list of references, etc, are all within current capabilities. simply trying to substitute one basic assessment type for another will not be sufficient to coter the challenge to assessment integrity. new assessments and assignments should instead focus on demonstration of personal and academic skills, validity and reliability, authenticity, and security. () consider the balance between formative and summative assessment in your modules/courses, and between continuous assessment and examinations. - practice and formative feedback are key aspects of learning which can also help students develop self-efficacy and responsibility for their own learning. an invigilated examination type environment is the option most readily available to you, at least in the short term, but do try also to consider what might be most educationally valuable alternatives and identify what design assistance or other support would be needed for such. () do not rely on generative AI \u2018detection systems\u2019. none of the tools which are currently available are fully capable of detecting the use of generative AI (except in the most obvious cases which may also have been identified by expert reading and scrutiny) and may also lead to \u2018false positives\u2019 (incorrectly concluding that human-written text was ai-generated) and difficult-to-interpret scoring. detection systems cannot be relied upon to detect use of generative AI accurately or consistently. - in addition, there may be serious data protection, privacy, and intellectual property concerns in the use of any such tool, particularly if it has not dergone appropriate approval by institutions. - turnitin\u2019s detection tool is available in some institutions, but users should be aware of concerns about its capabilities in terms of more recent versions of generative AI, a reported high rate of \u2018false positives,\u2019 and some ambiguity on how to interpret its results. it may be that you feel that a shift towards more weighting for assessments dertaken in () consider what scope there is for assessments which: - focus on \u2018process rather than product\u2019. in other words, where credit is associated with the various tasks or stages that the student goes through in order to lead to the final product. this can be done by breaking down assignments into key stages and incorporating student reflection/ reporting on how they fod their sources, what aspects they explored, what challenges they overcame, etc (or whatever is appropriate to the particular assignment) so that there is a developmental journey. - are clear in terms of whether the emphasis is on the development of writing skills (something the ai tools can do very well) or on derstanding of the specific topic and assess each of these with appropriate methods and rubrics. - are reflective and based on personal/ professional experiences and which are authentic to the discipline or profession. note that many of the ai tools will readily invent \u2018reflective\u2019 content if so asked, so try to ensure that the task is genuinely connected to the student, or the specifics of particular aspects discussed in class. - are in different or multiple formats, such as video or audio content, a mix of presentation (with questions and answers) and ancillary materials (e.g., reference list, handouts), etc. ai tools can produce slide decks and write scripts for video/audio content, so, again, be careful about the requirements. - are based on whether the learning outcomes have been achieved by the student, rather than leading to a grade. - use in-class writing assignments or problem-solving tasks. - are based on, or partially include, an oral component in which the students are asked to answer questions arod the topic and how they approached the task. there are many examples where orals have been used successfully, even in large class contexts, and in which there are particular formats (interactive orals for authentic assessment) which align with the discipline or profession. where it isn\u2019t practicable for a very large cohort, at least consider dertaking a number of orals either on the basis of random selection or to clarify any concerns in a particular submission (i.e., this is where the main assignment is an essay, report, video, etc, and the oral is to check on integrity and/or on student derstanding). () work with colleagues to develop an effective strategy for assessment which ideally would address issues of student (and staff) workload, the scheduling of deadlines/due dates, and ensuring that programme level outcomes are being met. - we know that academic misconduct can arise when people inappropriately react to: **\u25e6** **\u0007** pressure and stress caused by too many overlapping deadlines; **\u25e6** **\u0007** an amot of routine assessment that is so large, over the course of the semester, that it loses its perceived learning value to the student; **\u25e6** **\u0007** lack of opportities for resubmission or development of an assignment after feedback; **\u25e6** **\u0007** perceived lack of consequence for such behaviour. () always comply with and follow your institution\u2019s academic integrity policy and report any suspected cases. being consistent in policy implementation is something which will shape students\u2019 perceptions about the seriousness of the issue and that the policy is one which focuses on education and the development of professional values, reducing the potential for repeated misconduct and protecting the reputation of qualifications. ", "###### what programme managers and institutional leaders need to do () ensure that all staff are informed and kept up to date and provide training opportunities for all staff and students on these issues and technologies. () review approaches to assessment across programmes to: - identify and replace any existing practices which may be vulnerable to successful completion via the misuse of generative AI; and assessment, and the overall assessment workload; - develop a clear map of all assessments, assignments, and deadlines for students and staff in the programme or cohort, and seek opportunities for synergies, rationalisation, and scope for enhancing formative feedback and supporting student development; - establish clear rubrics for assessments and aim for consistency of practice (where appropriate) and alignment with programme outcomes. () whilst it might seem that a switch from continuous assessment, coursework, and assignments back to traditional end-of-semester formal examinations is the easiest way to ensure the integrity of assessment this can run counter to the strength of more authentic assessment which aims to develop skills, knowledge in context, and other professional and graduate attributes. a short-term reweighting of assessments may be necessary to respond quickly to these new challenges, but the longer-term goal should be to take a more holistic approach to assessment as/for/of learning. () review policies on academic integrity and assessment to more effectively reflect and respond to these issues and take the opportunity to reiterate the valuable educational purposes of assessment. () ensure that appropriate resourcing is available to support academic integrity. consider the scope for greater focus on programme level outcomes () refresh study/academic skills supports for students to provide clarity on acceptable as well as unacceptable uses of such technologies. () work as a sector on issues regarding technological developments, data protection, protection of ip, and ethics. () engage with qqi and other awarding or accreditation bodies on these issues and ensure that guidelines and regulations are clear to all staff and students. () foster an institutional ethos and culture (reflected in your communications) which emphasises integrity, honesty, trust, and respect, rather than let the conversations be dominated by suspicion, surveillance, and distrust. ", "###### what students need to know and do () ai (including so-called generative AI) tools are becoming widely available and embedded in many of the technologies which we use to write documents, analyse data, design presentations and to support learning. it is crucially important to understand how such technologies work and be aware of their limitations as well as their apparent strengths. they are not \u2018intelligent\u2019 in any real sense, nor are they experts on topics, but rather largely rely on statistical predictions of word combinations or image features. there are also concerns about ethical aspects in how such tools are developed, trained, and deployed and it is important to be aware of these. () ensure that students understand what is required of them for any assignment or assessment, including the extent to which there is any allowable use of such technologies and how this may need to be acknowledged. all assignments and assessments are designed to determine whether students can demonstrate attainment of the specified learning outcomes of their module or programmes. in other words, the credit is awarded for their work not that of others or produced by generative AI systems or obtained from other sources. this means that students need to understand their institution\u2019s academic integrity policy and be able to clearly draw the line between what is permissible and what may constitute misconduct. () learning is about \u2018sense-making\u2019, about juggling ideas, trying to see where they fit or where they contradict, about rethinking what we thought we already knew, about seeing things in new ways. all of this can be difficult, students can feel vulnerable if something doesn\u2019t appear to be immediately obvious to them and they need to put in lots of effort or seek help for things to \u2018click into place\u2019. it is not a weakness or a sign of lack of ability. it\u2019s what university-level education is about, but it should be counter-balanced by the sense of achievement and the new perspectives and skills that students ultimately acquire through this effort. () if a student is struggling, or feels under pressure, advise them to talk to their lecturers, tutors, su officers, counsellors, or whoever is most appropriate. advise them not to take \u2018short-cuts\u2019 with assessments that avoid them properly engaging with the subject, and to resist any the social media and other messages that come in from online \u2018cheating services\u2019 with \u2018promises of assignment support\u2019. students need to be encouraged to reach out and ask for support. () being a student should be a time in which they can develop new perspectives, learn more about themselves and society, find opportunities to express their passions and creativity, identify where they can engage with community and help make the world a better place. central to this is living up to values of trust, cooperation, integrity, and truthfulness, all of which are central to education and society. ----- ", "# ", "## further reading, links, and resources ", "##### part : further reading, links, and resources i n producing these guidelines, we have been informed by a wide range of documents, policies, articles, and other contributions (including webinars, discussions, and conversations) from across the international educational community. some particularly useful further reading which we would recommend include: . \u0007 a generative AI primer, by , for ai, https:// ) [wp////generative-ai-primer/ . \u0007 aain generative AI guidelines, australian academic integrity network (aain) generative AI working group, , / default/files/-/aain-generative-aiguidelines.pdf . \u0007 maintaining quality and standards in the chatgpt era: qaa advice on the opportunities and challenges posed by generative AI, the quality assurance agency for higher education , / docs/qaa/members/maintaining-qualityand-standards-in-the-chatgpt-erpdf . , directorate-general for education, youth, sport and culture, final report of the commission expert group on artificial intelligence and data in education and training \u2013 an executive summary, publications office of , ,  /doi/./ . \u0007 unlocking the power of generative AI models and systems such as and chatgpt for higher education: a guide for students and lecturers, gimpel , , / media/--_whitepaper_chatgpt.pdf . \u0007 turnitin guide for approaching aigenerated text in your classroom, https://  . \u0007 creative ideas to use ai in education, nerantzi, c., abegglen, , m. and mart\u00ednez-arboleda, (eds.) () doi: ./zenodo. . \u0007 five principles for the effective use of generative AI, uts, sydney, . edu.au/collections/artificial-intelligencein-learning-and-teaching/resources/ five-principles-for-effective-ethical-usegenerative-ai/ the nain generative AI guidelines for educators were developed by the working group chair, iain (university of galway) and (griffith college), with contributions from working group members - elva casey (hibernia college), (atu, sligo), naomi jackson (cct college), brid lane (ibat college) and cathy peck (dcu). ----- published by quality & qualifications ireland (qqi), august ( edition) ", "# proposal of usage guidelines for ai generative tools at cu these guidelines were created and reviewed by college unbound students (s. fast, , , , suleima, ) in with the support of , director of faculty development & innovation. for more information about this project, these guidelines, etc, please contact at lance.eaton@collegeunbound.edu . ", "## definition **ai generative tools** : we define \u201cai generative tools\u201d as including (but not necessarily limited to): the use of technologies that rely on machine learning, large language models (llms) and other advanced data-manipulation tools to produce distinct answers or outputs based upon prompts by the user. **usage** : usage of ai generative tools includes engaging with such tools to generate specific content that contributes to the submission of any activity or assignment or work to be evaluated in a course or requisite for graduation (e.g. big , lips), including but not limited to papers, presentations, discussion posts, etc, by students or by faculty, including but not limited to learning content, presentations, assessments, feedback, etc. ", "### student guidelines . each instructor at college unbound may have student usage policies that are different in terms of expectation and approach to using ai generative tools. an instructor\u2019s syllabus policy supersedes these guidelines in terms of appropriate usage, however an instructor cannot require students to create accounts with unaffiliated organizations for the purposes of any assignment. in the absence of a specific course policy, these guidelines stand as the default expectation. . if students choose to use these tools in some capacity that results in content from the generative AI tool making it into submitted student work, they must make clear and evident what portion of the work is generated by the ai tool and which ai tool they used. a. when available, use the appropriate citation format (e.g. mla or apa) as indicated by the instructor or syllabus. b. in absence of a particular citation format, students should use quotation marks around the ai generated-text and include a works cited that includes both the tool that was used (e.g. bard, chatgpt) and the prompts used. c. for visual materials or audio materials, consult your instructor on how they would want them particularly documented. d. in situations where students use generative AI as part of the brainstorming or organizing process, they are not obligated to cite or reference. . students are discouraged from copying entirely the content directly from an ai-generative text tool into their course work. students should edit and revise the ai-generative tool\u2019s output, unless there are significant reasons not to (e.g. the instructor\u2019s guidelines say otherwise). a. use ai tools as a supplement to your learning, not as a replacement for traditional learning methods. whenever possible, make sure the ai tool is accurately guiding your learning. b. with regard to lips, big , and other reflective practices, students may use such tools as a resource for insight and further understanding, but their reflective submissions should be still created by the student entirely. . students who do not adhere to these guidelines (or ones specified within a given course syllabus), will be subject to the process highlighted in the student [handbook\u2019s policy (academic honesty item # on pg /ab////-ecac-ba--a-fadce.pdf) . . students must get documented permission by faculty before putting original faculty content into any ai-generative tool. this might include communications, feedback, learning content, and the like. . if students choose to use these tools in some capacity related to their work, the submitted work should be less than % generated by the ai tool unless otherwise stipulated by the instructor or assignment guideline. . students are responsible for the possible negative outcomes of using ai-generative tools in the submission of their work as they relate to college unbound and its community. these negative outcomes include but may not be limited to: a. the accuracy of the content of an ai-generative tool. i. for example, chatgpt has been known to provide sources that do not exist or links that do not work. integrating these into one\u2019s work fails to meet the standards of appropriately identifying one\u2019s sources of influence in a given work. b. usage that results in inappropriate harm to the wellbeing of others\u2013individually or collectively. i. for example, using material generated by generative AI that results in reinforcing stereotypes (in written, oral, and visual mediums) for assignments or materials related to one\u2019s work at cu. c. usage that violates the privacy or security of other individuals. i. for example, students should not enter names and personal information or writing of other people (students, faculty, staff, etc) to produce an output for any work or activity related to their role at cu. d. usage that undermines the academic integrity of assessments, exams, or others evaluations at college unbound. i. for example, putting students\u2019 work into a generative AI tool for the purposes of checking for plagiarism or generating feedback (without students\u2019 permission). e. any other usage that violates cu\u2019s policies. f. if you are looking to use generative AI in connection with your learning at cu, please consider reaching out to the director of digital pedagogy, if you have questions or concerns about how you are using it and the policy above. ", "### faculty guidelines . faculty may develop their own usage expectations within their courses that are different from this document. however, they would still need adhere to item # in the faculty guidelines and follow the process highlighted in the student [handbook\u2019s policy (academic honesty item # on pg /ab////-ecac-ba--a-fadce.pdf) for students that do not follow expectations. . whenever faculty use generative AI tools to produce anything related to teaching and assessment, faculty must make it evident how much of the content was created by them and how much was generated by the ai-generative tool. a. for example, for written work, faculty should use the discipline\u2019s preferred citation format (e.g. apa, mla) to cite ai generated text or some other method to distinguish it such as using boldface, italics, or highlighting the ai generated text and explaining that the text comes from a specific generative AI tool.. b. for visual materials or audio materials, faculty should include disclaimers about the role of ai-generative tools used to create such material\u2013either as a preamble to the content or embedded within the content. . faculty cannot require students to get an account with any ai-generative tools at this time. if looking for possible opportunities or practices for students to use ai-generative tools, please contact , director of digital pedagogy. . faculty must get documented permission by students before putting original student content into any ai-generative tool. failure to do so may be subject to dismissal or other disciplinary actions. . faculty should be mindful of using these tools and keep a relational balance between what they ask of students in terms of how much ai-generative content can show up in student work and in their own work. a. for example, if students are restricted from submitting work that includes more than % of ai-generative work in their submissions, then the faculty member\u2019s work should also not include more than % ai-generated content. . faculty can use ai generative tools in the following ways: a. **learning materials, evaluation materials, & class preparation** : faculty can use these tools to help create content for their courses whether it is learning materials, assignment guidelines, slides, conversation questions, activities, etc. b. **classroom demonstrations & learning activities** : faculty can use these tools as part of classroom demonstrations and learning activities where the instructor and student can engage with the ai-generative tool for discovery and/or critique purposes. c. **feedback** : faculty can use ai-generative tools to create effective feedback for students. however, they are not allowed to put student-created work into ai-generative tools in order to create effective feedback without explicit permission from students. . faculty are responsible for the possible negative outcomes of using ai-generative tools for any purpose related to their work at college unbound and its community and may be subject to disciplinary action. these negative outcomes include but may not be limited to: a. the accuracy of the content of an ai-generative tool. i. for example, chatgpt has been known to provide sources that do not exist or links that do not work. integrating these into one\u2019s work fails to meet the standards of appropriately identify one\u2019s sources of influence in a given work. b. usage that results in inappropriate harm to the wellbeing of others\u2013individually or collectively. i. for example, using material generated by generative AI that results in reinforcing stereotypes (in written, oral, and visual mediums) for the purposes of teaching and learning. c. usage that violates the privacy or security of other individuals. i. for example, faculty should not create a chat thread on chatgpt for each student, where they update chatgpt about how the student is doing and requests feedback/strategies about that student d. usage that undermines the academic integrity of assessments, exams, or others evaluations at college unbound. i. for example, putting students\u2019 work into a generative AI tool for the purposes of checking for plagiarism or generating feedback (without students\u2019 permission). e. any other usage that violates cu\u2019s policies. f. if you are looking to use generative AI in connection with your course, it is recommended to reach out and talk with the director of digital pedagogy to double check different assumptions about usage. a final note about these policies: because this technology is both new and continuing to change, we recognize that these policies cannot and will not cover every situation. should issues and edge cases arise which fit outside these guidelines, cu representatives will operate from a position of good faith in trying to address each case, which will also be used to help us refine these policies. ", "# reconsidering education policy in the era of generative AI **g policy area:** digital governance, security, and connectivity **authors:** roland hancock (pwc middle east), (pwc middle east), suha azhar (), szabolcs mezei (pwc hungary), (), ) ", "## abstract education systems around the world grapple with persistent issues related to equity, access, and quality, while also navigating the disruptions brought about by new technologies. these technologies, and specifically generative AI, offer a range of powerful applications, and present an opportunity to reimagine our education systems, but generative AI comes with its own set of unique concerns and challenges and its integration in education poses a significant challenge for educators, researchers, and institutions. governments worldwide need to develop robust and comprehensive regulations and policies tailored to the ethical use of ai in education to ensure that, amongst other things, student data privacy and overall well-being are adequately protected. inaction by governments may mean significant consequences for students, educators, and society as a whole. the future will belong to those who can understand and incorporate the use of emerging technologies like generative AI in everyday life. this paper is a call to action for the g and policy makers around the world towards shaping ai use in education in a way that is informed, transparent, and responsible. ", "## education systems continue to face challenges in access, equity and quality access to education remains a significant challenge, particularly in low-income countries and marginalised communities. millions of children are unable to attend school or access education due to a lack of infrastructure, financial barriers, cultural norms and other factors. a unesco report estimates that million children and youth are out of school globally, with low-income countries hardest hit. it is further estimated that children from the poorest % of families are eight times more likely to be out of school as children from the richest % in lower-middle-income countries. while the global out-of-school rate is gradually decreasing, this shift is too slow and large gaps still exist between different regions. equity in education is a different pressing concern, arising when disadvantaged students face significant barriers to educational success. these barriers include disadvantages based on socio-economic background, gender, ethnicity, and disability, as well as unequal access to resources such as well-trained teachers, textbooks, and technology. disadvantaged students are more likely to attend poorly-performing schools, with fewer resources and less experienced teachers, while girls are twice as likely to be out of school than boys. within this context of inequity, some educators, researchers and students have access to cutting-edge digital tools, capable and experienced experts and innovative pedagogical methodologies, while others make do with limited access to even the most basic educational tools, resources and educational delivery techniques. as a result, disadvantaged communities often have lower levels of educational attainment and fewer opportunities for future success. the last focus of concern for this paper is around the provision of high-quality learning experiences that meet the needs of all students. outdated curricula, inadequate teacher training and limited resources can all contribute to low-quality education outcomes. there is often a mismatch between the skills that students learn in school and the skills that are in demand in the labour market, leading to high levels of youth unemployment and underemployment. in classrooms teachers use a mix of digital and non-digital tools for their delivery, with their focus and time split between developing teaching plans and resources, delivering content, creating and grading assessments and coursework, in addition to other administrative tasks. a study conducted by edweek research centre shows that teachers work hour , with only half that time spent in student engagement like instruction, skill development and coaching. this leaves little room for thinking about enhancing and furthering the curriculum, student experience or providing specialised, tailored learning. the quality and appeal of teaching is variable depending on the capabilities of the professionals and the training and resources available to them. further consideration needs to be given to what students are being taught and assessed on, and how much of it relies on memorization of facts versus application of skills, thought processes and capabilities that can be extrapolated to a variety of situations and contexts. ", "## the transformative power of ai can help resolve some of these challenges generative AI technologies can help dramatically shift the landscape to address the gaps outlined above. the capability to ingest, interrogate and build connections within vast amounts of data allows generative AI to produce content such as text, images and sounds presents new opportunities and applications for educators, researchers, students and parents that can enhance their experiences. generative AI can improve the quality of course materials and personalise them based on students' learning styles and specific needs, such as learning challenges and preferences. it can create simulations and virtual environments, resulting in more engaging courses. additionally, ai can assist in creating new teaching materials and research content and produce images with specific modifications that respond to particular academic needs. the use of ai tools for such tasks frees up time for work that can potentially have more impact on the learning experience. given the ongoing speed of technology and societal change, content needs to be continuously refreshed, to remain relevant; generative AI can enhance the quality of outdated or low-quality materials leading to deeper understanding of the content and better outcomes for educators, students and researchers. it can be used to generate personalised learning materials and assessments for students, and it can create personalised assessments for students to test their knowledge and gauge their understanding of a topic. ai can offer virtual tutoring environments through chat bots and tutoring ai platforms, supporting students with real-time feedback and support outside of the classroom. this is especially useful for those who lack access to in-person tutoring or learning resources. ", "## the use of generative AI brings concerns with it despite many powerful applications, and the need to reimagine our education systems in the light of new disruptions, generative AI technologies do come with their own set of unique concerns and challenges. here we outline some of the key issues before offering a perspective on policy changes to address them. ", "### . academic integrity, ethics and code of conduct students and researchers creating content using ai tools and calling it their own work is challenging academic integrity, ethics and code of conduct. educational and research institutions around the world have employed various measures to address these issues, including requiring students and researchers to disclose their use of generative AI tools such as chatgpt. however, this does not provide a clear solution as the outputs generated by ai tools are a combination of the system-generated content, developer inputs, and user edits. this creates a grey area in identifying and defining plagiarism and outlining sensible guidelines on ai use. while tools to detect whether content is created by ai are being developed and deployed, their effectiveness varies and the sophistication of means and mechanisms to get around them will continue to evolve in parallel. ", "### . knowledge ) when skills development focuses on tool usage to access knowledge at the expense of expertise, a student\u2019s ability to think critically and build deep knowledge is impacted. students are not able to assimilate knowledge without spending time with it, applying problem-solving and critical thinking techniques to dissect and analyse it. research on the psychology of learning indicates that this is critical for students to absorb the content and develop crucial thinking strategies. however, the use of generative AI tools can sideline this type of learning, leaving students vulnerable to shallow thinking and lacking in fundamental understanding. it is important for students to predict, explain, and hypothesise to learn, rather than relying on ready-made answers that may only provide basic knowledge but fall short of critical, creative, and innovative thought. while the use of ai technologies will become a skill on its own, understanding how to build appropriate supporting knowledge and skillsets is important. ", "### . bias, inaccuracy and privacy the content produced by generative AI tools is based on the data that was used to train it, which is raising concerns about potential bias, misinformation, lack of global understanding and overestimation of ai capabilities resulting in incorrect output. openai, for example, has currently not disclosed details about the training methods and materials used for chatgpt, making it a black box. although large amounts of data may be used for training, it is essential to question the nature and origin of that data which is reflective of the types of biases and misinformation that could inflict harm. if the training material focuses heavily on certain geographical regions or particular views, this limits the likelihood of reliable, global and inclusive output required to cater to users, especially students in and researchers publishing their findings, across the globe. recently the risk of ai systems being \u2018poisoned\u2019 by actors deliberately feeding them misinformation maliciously has been noted, leading to increased concerns about the accuracy and bias of ai outputs. privacy and transparency concerns have been top of the agenda in , as members of society at all levels increasingly use technologies for day-to-day tasks, and sharing their data. there is not yet a clear view on how generative AI data is stored and handled, and for what purposes. the use of ai needs to be navigated cautiously given the potential involvement of minors and the disclosure of confidential information. ", "### . further risks to access and equity generative AI technology has the potential to increase socio-economic divides due to accessibility and equity factors, which may disadvantage marginalised communities and limit their access to equitable opportunities. communities that struggle with access to digital tools and internet connectivity do not have the same level of access to technologies as better supplied communities. in addition, the data that is used to train the technology may not be representative or inclusive with respect to ethnicity, gender, or disability, making its use detrimental. it is important to recognise these issues and find ways to minimise any potentially negative impact of generative AI on education and society. ", "### . training and development in light of the challenges and concerns surrounding generative AI in education, its integration currently poses a significant challenge for educators, researchers, and institutions. the lack of education, training and guidance available for the responsible and ethical use of these tools, as well as limited understanding of their full capabilities and implications, contribute to this apprehension. generative AI technologies are innovative and disruptive, but it is important to remember that they are not a replacement for the human mind. people working with them need to develop the right capabilities to make best use of them as tools to be used alongside human creativity and critical thinking, while being aware of their risks and acting accordingly. ", "## recommendations to the g and policy makers as of now, there is no single comprehensive policy or regulatory framework in place that specifically addresses the use of ai in education. however, some existing regulations and policies that touch upon it, albeit indirectly, for instance, in the us, the family educational rights and privacy act (ferpa) and children\u2019s online privacy protection act () mandate that student data collected by technology providers should be kept private and secure. likewise, in , (gdpr) provides a legal framework for the protection of personal data. these regulations also apply to the use of ai in education, as they regulate the collection, use, and storage of personal data in any context. moreover, there are some emerging frameworks that aim to guide the ethical use of ai in education; for example, the principles on ai, the unesco recommendation on ai and education, and the aiall program of however, these frameworks are still in their nascent stage, and their effectiveness in regulating ai use in education remains to be seen. governments worldwide can use these as a starting point but need to develop robust and comprehensive regulations and policies tailored to the ethical use of ai in education to ensure that student data privacy and overall well-being are adequately protected. they have a responsibility to promote the development and adoption of generative AI while also addressing the concerns articulated above. as the capabilities of generative AI (and other emerging technologies) continue to expand, policymakers need to develop a nuanced understanding of its benefits and risks, and enact policies that can effectively manage its impact on education systems and society at large. ", "### policy consideration : access and use in the teaching learning process instead of an outright ban (like in the case of italy - subsequently reversed - or saudi arabia) or allowing unrestricted use of generative AI in the classroom, policy makers (and institutions) will need to consider various scenarios in which use of generative AI will benefit students across different age groups and segments ( vs higher education) and provide for inclusion of the technology in the teaching and learning process. some well researched use cases can help provide teachers and students with guidance on how best to implement specific types of tools. this should be supported through the promotion of ai literacy among students and educators, incorporating ai-related topics such as machine learning, natural language processing, and neural networks into existing curricula. policy makers need to ensure that ai led education tools are accessible to students of all backgrounds, emphasising diversity and inclusion in both the study and application of ai. a starting point here might be to shift emphasis from student/teacher content creation towards the evaluation of content to boost and develop critical thinking, for example, teaching students and teachers the importance of effective prompting. ", "### policy consideration : redrafting learning outcomes the use of generative AI in the day-to-day teaching and learning process could hinder the development of key skills like critical thinking and the ability to assimilate and analyse knowledge. students need guidance on how to leverage technologies while retaining fundamental learning and development. the integration of ai tools creates an opportunity for educators and researchers to develop innovative approaches to teaching, assessment, and content development, thus enhancing the state of academia, for example generative AI can help to define tasks to ensure personalized learning for students. it will encourage a move away from less effective or more time-consuming tasks, such as memorization or reviewing large bodies of literature, to a model that promotes higher-order skills for educators, students, and researchers. this can be achieved, for example, by focusing on reflection on or discussion of created content rather than focusing on the creation of content itself. ", "### policy consideration : ethical framework for ai the development of an ethical framework for ai encourages its safe and responsible use, which can be provided through guidelines and standards that govern the design, development and deployment of ai technologies in education systems across schools and universities. the framework should cover aspects such as privacy, transparency, accountability, and fairness. it should support the declaration by ai systems of their design process so that the right systems can be identified which protect the privacy and personal information of students, teachers, and other stakeholders. while it is the responsibility of developers to carry out rigorous testing and validation of ai algorithms and ensure that they adhere to ethical and legal standards, educators also need to be adequately trained and equipped to handle the technologies and ensure that students' welfare is prioritised. any framework should promote transparency and logic, ensuring that ai models and algorithms are easy to understand and interpret, and outline use cases to be supported. it should be highlighted that frameworks for ai \u2013 like former ones for internet usage for example \u2013 cannot be fully enforced, but the objective here is to make students, parents and teachers aware of the guidelines and the implications of not adhering to them. ", "### policy consideration : data privacy and security the sensitive nature of personal information that is shared between students, teachers, and administrators during the learning process makes them vulnerable to cyberattacks and privacy breaches. schools, universities and educational systems must take a proactive approach to address these concerns by instituting robust data privacy and security policies that protect the personal information of students, teachers, and staff. another critical area of concern is data governance. schools and universities need to establish guidelines and protocols for the collection, storage, and sharing of data in ways that align with ethical and legal standards. they must ensure that they comply with applicable regulations such as gdpr (general data protection regulation), ferpa (family educational rights and privacy acts) and others as they evolve to cope with generative AI. a starting point may be to create default privacy and security processes with options for individuals to modify according to his or her preferences. depending on culture as well as national and organizational priorities, there are opt-out and opt-in approaches that can be implemented. ", "### policy consideration : incorporating ai training for educators and students to fully leverage ai potential, educators need to be trained on how to integrate the technology into their teaching effectively. ai training should be included in teacher preparation programs and continued professional development. teachers need to know how to identify appropriate ai tools, how to use them effectively, mitigate risk, and how to evaluate ai-generated content. students should be taught basic ai concepts to be able to participate in the development of ai solutions in the future. educators can incorporate ai training into the curriculum by developing courses and workshops to ensure students have practical experience using ai tools. as ai becomes more integrated into the educational system, it is important to prepare students for the jobs of the future. governments can enable partnerships that provide industry-relevant training programs and provide financial incentives for schools that make ai and other emerging technologies available to underserved communities. ", "### policy consideration : promote transparency and accountability one of the most significant concerns related to the use of generative AI in education systems is the potential for bias and discrimination. to promote transparency, institutions need to be open about their use of generative AI systems, including the algorithms used and the processes followed. institutions should also provide explanations of how the technology works and how decisions are made based on the data collected. this transparency can help build trust between institutions, educators, parents, and students, and will help to ensure that the use of generative AI in education is ethical and unbiased. a mechanism is required to ensure that institutions and educators are responsible for the decisions made by the systems they use. for instance, if a student is penalised for a mistake made by a generative AI system encouraged by the school, that institution must be accountable for the error. educational institutions need to establish clear guidelines, policies, and procedures for the use of these systems, including how they collect and analyse data, identify potential biases and ensure impartial decision making. in addition, institutions should routinely monitor and audit the generative AI system's performance to identify any errors or biases, and take appropriate measures to correct them. an important part of this is identifying the appropriate supervisory body or bodies to be involved, taking into account national and international approaches and guidelines. ", "### policy consideration : public engagement the use of ai in education raises ethical concerns such as privacy, data security, and fairness in decision-making. public engagement, including with industry, allows for and encourages open discussion about these issues and provides an opportunity to address misconceptions and fears surrounding ai in education as well as building awareness which protects against manipulation. public input and feedback can also inform the development of effective policies and guidelines that govern the use of generative AI in education. this helps to create a transparent and accountable framework for the deployment of the technology. engaging the public in the decision-making process helps to build trust between the community and the institutions working with ai. this trust and inclusive attitude are important for the successful adoption and acceptance of ai in education. ", "### policy consideration : education led ai the education sector itself needs to be a leader in the development of its own ai based tools that build on this new technology and open the opportunities it offers to learners at all levels. in this way the sector can gain better control of contractual terms and technical and organisational measures in the application of ai. in addition, it will create a safer space for students to train in and make the institution both safer and more competitive. this does not mean that government or institutions need to become ai developers, but partnerships with ed tech and companies are a good starting point to develop bespoke tools, work through the ethical, behavioural and other challenges that are being raised, which will allow the sector to lead in this field rather than be reactive to what is to come. ", "## g\u2019s role: call to action for governments to take proactive and responsible steps to shape ai use in education generative AI is here to stay and grow exponentially. according to a forbes article published in , generative-relevant use cases already present a significant enterprise opportunity, with an estimated market of $. billion in which is expected to grow at a rate of % until . as with previous disruptive technologies, such as calculators, computers and the internet, generative AI technologies will become another tool in the education ecosystem. we need to rethink how to learn, grow and develop in a world where generative AI is commonplace, be prepared for further transformations and we must do so while being aware of its uses and deficiencies, its strengths and limitations. this ongoing disruption demands proper guardrails in the form of forward-looking policy. the g recognizes the importance of digital technology and its potential to enhance social development and economic growth. the g digital economy ministerial declaration acknowledged the need for policies that support the development and use of ai technologies while also addressing ethical and social considerations. the time is now to act on policy development, especially in education. generative AI has the potential to contribute to the achievement of sustainable development goals (sdgs), particularly the achievement of sdg which focuses on ensuring inclusive and equitable quality education and promoting lifelong learning opportunities for all, provided that the correct steps are taken now to integrate the use of this technology. the g has an important role to play. by recognizing the potential of ai technologies, the g can create viable opportunities for the use of generative AI in education, provide recommendations to governments across the globe which impact policy and regulatory frameworks and help develop a common understanding of key ethical and \u2018human-centric\u2019 guidelines for the use of ai. ", "### risks of inaction the future will belong to those who can understand, learn and incorporate the use of critical emerging technologies like generative AI in everyday life. lack of understanding of ai and its applications will not only make students unqualified to enter the job market in the future, but will also broaden the divide between their skills, knowledge and abilities versus those who are adept at using ai tools. traditional teaching methods and curricula may become outdated and education systems that are not able to integrate emerging technologies like generative AI into their educational systems risk producing graduates without the skills needed to succeed. the digital divide may be exacerbated if governments do not actively invest in providing access to emerging technologies for all learners. students from low-income or disadvantaged backgrounds may fall further behind in acquiring essential digital skills and knowledge. countries that do not prioritise the adoption of new technologies in education may lose their competitive edge in the global market. by not preparing students with the skills needed for the ai-driven economy, these countries risk stunting their economic growth and development. by not investing in emerging technologies, governments may hinder the development of new and effective teaching methods and learning tools. teachers need training and support to effectively use new technologies in the classroom. inaction in this area may lead to a lack of professional development opportunities for educators, making it difficult for them to adopt new tools and techniques. inaction from governments in the appropriate adoption of emerging technologies like generative AI in education can have significant consequences for students, educators, and society as a whole. by embracing, investing in and working on the best uses of these technologies, governments can help create a more equitable, effective, and innovative educational system that prepares students for the future. ", "### note while preparing this policy brief, we asked chatgpt to prepare a similar document as a test. the work above required approximately human hours to complete. the chatgpt version took around hour to complete with almost all that time spent on rephrasing questions to elicit more relevant content. we learned the following: . all readers of both papers picked the human based version as their preference (despite not knowing which was which) . the skills required to prompt chatgpt are a new and rapidly growing discipline which we are learning in real time . the use of chatgpt reduced the amount of learning significantly for the people involved. no reading, research or discussion was required, and no writing up reinforced learning whereas those that spent time on the human written version gained significantly more understanding and retained knowledge. **bibliography:** - holmes, . \u201cai and education. a guidance for policymakers\u201d, miao, , __ , // () - . \u201cinforming progress. insights on personalized learning implementation and effects\u201d, __ , () - , \u201cequity and quality in education: supporting disadvantaged students and schools\u201d, publishing () - . \u201cimpact evaluation in practice, second edition.\u201d , _world bank publications_ , // () - alistair dieppe. \u201cglobal productivity. trends, drivers, and policies\u201d, _ _publications_ , // () - . \u201cthe impact of the pandemic on education.\u201d international evidence from the responses to educational disruption survey (reds), international association for the evaluation of educational achievement, ,  () - jerome beranger. \u201csocietal responsibility of artificial intelligence. towards an ethical and eco-responsible ai\u201d, _ & sons_ , - , jolyon. \u201cregulatory insights on artificial intelligence.\u201d _research for policy, findlay,_ _, publishing_ , - , \u201cworld poverty could be cut in half if all adults completed secondary education .\u201d _.org_ . . ( ts-completed-secondary-education.) - \u201cmonitoring sdg : access to education.\u201d _.org_ , , (). accessed may . - \u200c \u201c\u2019s teachers are deeply disillusioned, survey data confirms.\u201d _education _ _research centre_ , apr. , ( ms.) accessed may . - \u201cworld development report .\u201d _ , , (hdl.handle.net//). \u201cgenerative AI systems in education -uses and misuses.\u201d _centre for democracy &_ _technology_ , mar . wood, , and mary louise kelly. \u201c\u201ceverybody is cheating\u201d: why this teacher has adopted an open chatgpt policy.\u201d __ , jan. , ( -school.) duggan, steven. \u201cai in education: change at the speed of learning.\u201d __ iite, . swiecki, zachari, . \u201cassessment in the age of artificial intelligence.\u201d _computers and_ _education: artificial intelligence_ , vol. , , p. , (...) hmelo-silver, problem-based learning: what and how do students learn?\u201d _educational psychology review_ , vol. , no. , , pp. \u2013, (.) ho, , and chng. \u201cstirring deep thinking and learning through student-designed assessment problems.\u201d _currents in pharmacy teaching and_ _learning_ , , (...). accessed . \u201cai use in assessments: protecting the integrity of qualifications.\u201d _ for_ _qualifications_ , (/.) department for education. \u201cgenerative AI in education departmental statement.\u201d _gov uk_ , . world economic forum. \u201cgenerative AI: a game-changer society needs to be ready for.\u201d _world economic forum_ , jan. , ( nd-society-code-developers/.) future of life institute. \u201cpause giant ai experiments: an open letter.\u201d _future of life_ _institute_ , mar. , (futureoflife.org/open-letter/pause-giant-ai-experiments/.) lim, , . \u201cgenerative AI and the future of education: ragnar\u00f6k or reformation? a paradoxical perspective from management educators.\u201d _the_ _international journal of management education_ , vol. , no. , july , p. , (...) baidoo-anu, , and leticia owusu ansah. \u201ceducation in the era of generative AI (ai): understanding the potential benefits of chatgpt in promoting teaching and learning.\u201d _social science research network,_ jan. , (papers.ssrn.com/sol/papers.cfm?abstract_id=.) dwivedi, , . \u201c\u201cso what if chatgpt wrote it?\u201d multidisciplinary perspectives on opportunities, challenges and implications of generative conversational ai for research, practice and policy.\u201d _international journal of information_ _management_ , vol. , aug. , p. , , (...) openai. technical report. _openai,_ mar. . ", "# group principles on the use of generative AI tools in education _our universities are committed to the ethical and responsible use of generative AI and to preparing_ _our staff and students to be leaders in an increasingly ai-enabled world._ _the rise of generative AI (ai) has the potential for a profound impact on the ways_ _in which we teach, learn, assess, and access education. our universities wish to ensure that_ _generative ai tools can be used for the benefit of students and staff \u2013 enhancing teaching practices_ _and student learning experiences, ensuring students develop skills for the future within an ethical_ _framework, and enabling educators to benefit from efficiencies to develop innovative methods of_ _teaching._ _valuable work undertaken by organisations such as the quality assurance agency for higher_ _education (qaa) and has helped develop the sector\u2019s understanding of the opportunities and_ _considerations of generative ai_ __ _, and the department for education (dfe) has set out its position_ _on the use of generative AI in the pre-university education sector_ __ _. group universities have_ _contributed sector-wide insight and have been proactively working with experts to revise and_ _develop policies that provide guidance to students and staff._ _collaboration, coordination, and consistency on this issue across the education and professional_ _sectors \u2013 including professional bodies, schools, fe colleges and employers \u2013 will be crucial. in_ _recognition of this, group universities have collectively developed the following principles_ _that will guide the approach to generative AI tools across our universities and, we hope, beyond:_ . universities will support students and staff to become ai-literate. . staff should be equipped to support students to use generative AI tools effectively and appropriately in their learning experience. . universities will adapt teaching and assessment to incorporate the ethical use of generative AI and support equal access. . universities will ensure academic rigour and integrity is upheld. . universities will work collaboratively to share best practice as the technology and its application in education evolves. **. universities will support students and staff to become ai-literate.** . generative AI tools are capable of processing vast amounts of information to generate responses but they have significant limitations. it is important that all students and staff understand the opportunities, limitations and ethical issues associated with the use of these tools and can apply what they have learned as the capabilities of generative AI develop. these include: (a) privacy and data considerations: whether a generative AI tool is designed to learn directly from its users\u2019 inputs or not, there are risks to privacy and intellectual property associated with the information that students and staff may enter. (b) potential for bias: generative AI tools produce answers based on information generated by humans which may contain societal biases and stereotypes which, in-turn, may be replicated in the generative AI tool\u2019s response. /   (c) inaccuracy and misinterpretation of information: data and information contained within generative AI tools is garnered from a wide range of sources, including those that are poorly referenced or incorrect. similarly, unclear commands or information may be misinterpreted by generative AI tools and produce incorrect, irrelevant or out-of-date information. this means that accountability for the accuracy of information generated by these tools when transferred to another context lies with the user. (d) ethics codes: users of generative AI tools should be aware that while ethics codes exist, they may not be embedded within all generative AI tools and that their incorporation, or otherwise, may not be something that users can easily verify. (e) plagiarism: generative AI tools re-present information developed by others and so there is the risk of plagiarised content and/or copyright infringement being submitted by a user as their own, and artwork used by image generators may have been included without the creator\u2019s consent or licence. (f) exploitation: the process by which generative AI tools are built can present ethical issues. for example, some developers have outsourced data labelling to low-wage workers in poor conditions . . our universities will provide guidance and training to help students and staff understand how generative AI tools work, where they can add value and personalise learning, as well as their limitations. by increasing ai-literacy, our universities will equip students with the skills needed to use these tools appropriately throughout their studies and future careers, and ensure staff have the necessary skills and knowledge to deploy these tools to support student learning and adapt teaching pedagogies. **. staff should be equipped to support students to use generative AI tools** **effectively and appropriately in their learning experience.** . our universities will develop resources and training opportunities, so that staff are able to provide students with clear guidance on how to use generative AI to support their learning, assignments, and research. . the appropriate uses of generative AI tools are likely to differ between academic disciplines and will be informed by policies and guidance from subject associations, therefore universities will encourage academic departments to apply institution-wide policies within their own context. universities will also be encouraged to consider how these tools might be applied appropriately for different student groups or those with specific learning needs. . engagement and dialogue between academic staff and students will be important to establish a shared understanding of the appropriate use of generative AI tools. ensuring this dialogue is regular and ongoing will be vital given the pace at which generative AI is evolving. **. universities will adapt teaching and assessment to incorporate the ethical use** **of generative AI and support equal access.** . universities continually update and enhance their pedagogies and assessment methods in response to drivers including new research, technological developments and workforce needs \u2013 adapting to the use of generative AI technology is no different. incorporating the use of generative AI tools into teaching methods and assessments has the potential to enhance / the student learning experience, improve critical reasoning skills and prepare students for the real-world applications of the generative AI technologies they will encounter beyond university. . appropriate adaptations to teaching and assessment methods will vary by university and discipline, and protecting this autonomy is vital. all staff who support student learning should be empowered to design teaching sessions, materials and assessments that incorporate the creative use of generative AI tools where appropriate. professional bodies will also have an important role in supporting universities to adapt their practices, particularly in relation to accreditation. . as the technologies develop and new generative tools become available, elements of generative AI used within universities may reside behind paywalls or be restricted to paying subscribers. universities will need to consider how best to respond to a potential proliferation of such subscription tools and attempt to ensure fairness of access so that students and staff can access the generative AI tools and computing resources they need in support of their teaching and learning practices. **. universities will ensure academic rigour and integrity is upheld.** . all group universities have reviewed their academic conduct policies and guidance to reflect the emergence of generative AI. these policies make it clear to students and staff where the use generative AI is inappropriate, and are intended to support them in making informed decisions and to empower them to use these tools appropriately and acknowledge their use where necessary. . such clear and transparent policies are critical to maintaining consistent and high standards of learning, teaching and assessment across group universities. . ensuring academic integrity and the ethical use of generative AI can also be achieved by cultivating an environment where students can ask questions about specific cases of their use and discuss the associated challenges openly and without fear of penalisation. **. universities will work collaboratively to share best practice as the technology** **and its application in education evolves.** . navigating this ever-changing landscape will require collaboration between universities, students, schools, fe colleges, employers, sector and professional bodies, with the ongoing review and evaluation of policies, principles and their practical implementation. . our universities will regularly evaluate policies and guidance for staff and students relating to generative AI tools and their impact on teaching, learning, and assessment practices. this will include monitoring the effectiveness, fairness, and ethical implications of the integration of generative AI tools into academic life, and adapting policies and procedures to ensure they remain valid as generative AI technologies evolve. . fostering relationships between higher education institutions, schools, employers, professional bodies who accredit degrees, ai experts, leading academics and researchers, as well as ensuring an inter-disciplinary approach to addressing emerging challenges and promoting the ethical use of generative AI, will be crucial. group universities recognise the challenges that lie ahead and will continue to value the input of others, along with contributing expertise to the national and international discussions around generative AI and its applications within teaching, learning, assessment and support. ", "# adopting and expanding ethical principles for generative arti fi cial intelgence from mitary to , , yifan , , , , and ,,,, \u2709 yanshan |---|---|---| ||in , the department of defense officially disclosed a set of ethical principles to guide the use of icial intelgence (ai) technologies on future battlefield despite stark differences, there are core similarities between the mitary and medical servic warriors on battlefields often face fe-altering circumstances that require quick decision-making. medical providers experience similar challenges in a rapidly ging environment, such as in the emergency department or during surgery treating a fe-threatening condition. generative AI, an emerging technology designed to efficiently generate valuable ation, holds great promis as computing power becomes more accessible and the abundance of health data, such as electronic health records, electrocardiograms, and medical images, increases, it is inevitable that will be revolutionized by this technology. recently, generative AI has garnered a lot of attention in the medical research community, leading to debates about its appcation in the sector, mainly due to concerns about transparency and related issue meanwhile, questions around the potential exacerbation of health disparities due to modeg biases have raised notable ethical concerns regarding the use of this technology in . however, the ethical principles for generative AI in have been understudied. as a result, there are no clear solutions to address ethical concerns, and decision-makers often neglect to consider the significance of ethical principles before implementing generative AI in cical practic in an attempt to address these issues, we explore ethical principles from the mitary perspective and propose the \u201cgreat plea\u201d ethical principles, namely governabity, reabity, equity, accountabity, traceabity, privacy, lawfulness, empathy, and autonomy for generative AI in . furthermore, we introduce a framework for adopting and expanding these ethical principles in a practical way that has been useful in the mitary and can be apped to for generative AI, based on contrasting their ethical concerns and risk ultimately, we aim to proactively address the ethical dilemmas|| |||| |||| |||| |||| |||| |||| |||| |||| |||| |||| |||| |||| |||| |||| |||| |||| ||and challenges posed by the integration of generative AI into practic|| |||| ||al medicine (): ; || |||| introduction arti fi cial intelgence (ai) plays an ever-increasing role in our daily ves and has in fl uenced fi elds from one advertising to sales and from the mitary to . with the ongoing ai arms race in the russia-ukraine war, it is expected that ai-powered lethal weapon systems will become commonplace in warfare . although ai has shown promise in numerous successful appcations, there remains a pressing need to address ethical concerns associated with these appcation there are dire consequences if an ai system noncombatants or friendly force seeing the rapid emergence of ai selects an incorrect target potentially kilg and its appcations in the mitary, ) disclosed ethical principles for ai in . this document emphasized fi ve core principles, aiming for responsible, equitable, traceable, reable, and governable ai . in addition, the north atlantic treaty () also released principles for the use of ai in mitary, including lawfulness, responsibity and accountabity, explainabity and traceabity, reabity, governabity, and bias mitigation . the success of these ethical principles has also been demonstrated through their abity to adopt and embed ai mindfully, taking into account ai \u2019 s potential dangers, which the is determined to avoid . clearly, prominent mitary s demonstrate a cautious approach toward adopting ai and are actively implementing measures to mitigate the risks associated with its potential macious uses and appcation on the other hand, ai has had a direct impact on the industry, with discussions ranging from the uses of ai as an assistant to medical personnel \u2013 to ai replacing entire cical departments , . the use and impact of ai in cical natural language processing (nlp) in the context of electronic health records (ehrs) have been profound \u2013 . similar to mitary s, (who) has also released a document discussing the and governance of ai for health . generative AI, as the name suggests, ers to ai techniques that can be used to create or produce various types of new contents, including text, images, audio, and video the rate of development of generative AI has been staggering, with many industries and researchers fi nding its use in fi elds such as fi nance , collaborative writing , email communication , and cyber threat intelgence . generative AI has also become an active area of research in the domain , , with department of health ation management, , pittsburgh, pa, us department of population health ences, ll cornell medicine, new york, ny, us division of pulmonary, allergy, critical care & sp medicine, , pittsburgh, pa, us center for mitary medicine research, , pittsburgh, pa, us telemedicine & advanced technology research center, us army, fort detrick, frederick, md, us department of surgery, uniformed services university, bethesda, md, us virtual medical center, brooke army medical center, san antonio, . intelgent systems program, , pittsburgh, pa, us department of biomedical atics, , pittsburgh, pa, us cical and translational ence institute, , pittsburgh, pa, us medical center, pittsburgh, pa, us \u2709 email: yanshan.@pitedu . the relationship between general ml and modern generative a the fi gure provides an overview of ml sub fi elds, estabshes relationships among these sub fi elds, and shows the path to generative a appcations such as cical documentation and evidence-based medicine summarization . despite many successful and promising ai appcations, has been one of the more controversial subjects of discussion in the ai community, with diverging views and a plethora of opinions , . deals with how one decides what is morally right or wrong and is one of the pivotal aspects that we, as the ai research community, have to consider caully. given the recent emergence of generative AI models and their initial enthusiasm in , our community must seriously consider ethical principles before integrating these techniques into practical us the mitary and are notably similar in many ways, such as al structure, high levels of stress and risk, decisionmaking processes, reance on protocols, and dominion over fe and death. given these parallels, successful implementation of ethical principles in mitary appcations, and the lack of speci fi c solutions to generative AI in , we propose to adopt and expand ethical principles, from mitary to , to govern the appcation of generative AI in appcation what is generative icial intelgence? generative AI ers to ai that is used primarily for generating data, often in the form of audio, text, and image however, in this manuscript, we choose not to follow such a general de fi nition and instead, focus on a particular type of generative a in this section, we describe \u201c modern \u201d generative AI, discuss why it is important, and compare it to the term that has become so popular \u2014\u201c a \u201d modern ai is dominated by machine learning (ml) methods, which leverage statistical algorithms and large amounts of data to gradually improve model performanc ml methods could roughly be classi ed into supervised, unsupervised, and reinforcement learning (. fi ). supervised ml rees on labeled input (supervision), while unsupervised learning needs no human supervision. reinforcement learning takes a different approach and, instead, attempts to design intelgent agents by rewarding desired behaviors and punishing undesired one popular generative AI models are typically pre-trained in an unsupervised manner. the pre-trained generative AI models could generate novel and diverse outputs, including, but not mited to, text, images, audio, or video recently, the most popular generative AI model for language generation is chat , which was reported to have an estimated milon active users in january . the model architectures for chat, previously known as -. , and more recent , are built upon the design principles of its (generative pre-trained transformer) predecessors, and - . many state-of-the-art generative AI models, also known as large language models (llms), share a similar transformer-based architecture . the well-known generative AI models used for image generation from text prompts, such as stable diffusion and dall-e , employ a combination of the diffusion process and a transformer-based architecture similar to the one used in model all of the models are acterized by unsupervised training on very large datasets . the same is true of models that generate video most of these generative AI models also rely on a method called prompting , which lets users input a natural language description of a task and uses it as a context to generate useful ation. this process is also sometimes erred to as in-context learning. when erring to \u201c modern \u201d generative AI or simply generative AI, we are describing a transformer-based machine learning model trained in an unsupervised manner on extensive datasets and speci fi cally optimized for generating valuable data through prompt this description also agns harmoniously with existing research and studies \u2013 . while generative AI shows promising results, dangerous outcomes in can arise from a number of issues, including: algorithmic bias , hallucination , poor commonsense reasoning , lack of generally agreed model evaluation metrics , all of these issues are common for generative AI in general, but more so in the domain, where algorithmic bias may result in the mistreatment of patients , hallucination may carry misation , poor commonsense reasoning can result in confusing interactions , and lack of general and domain-speci fi c metrics can make it dif fi cult to vadate the robustness of the ai system . furthermore, in the context of , there are concerns about leaking protected health ation (phi) as well as lacking empathy to patients . such concerns can also be present in other forms of ai, but given the practical differences present in generative AI, the risks become elevated. first, due to the interactive nature of generative AI, often paired with the abity to hold human-ke dialogs (g., chat), it can make misation sound convincing. second, since generative AI models combine various sources of large-scale data , the risk of training on biased data sources increase third, the standard evaluation metrics, such as precision, recall, and f score, become dif fi cult to use and are less kely to re fl ect human judgment . finally, due to its ease of use, generative AI can be widely adopted in many fi elds and domains of , which naturally increases the aforementioned risk overall, the importance of ethical considerations for generative AI in cannot be understated. from the human-centered perspective, the ultimate goal of generative AI is to enhance and augment human \u2019 s creativity, productivity, and problem-solving capabities, which is well agned with the goal of in improving patient car if the generative AI system is not used ethically and does not re fl ect our values, its role as a tool for improving the ves of people will greatly diminish. ai appcations in mitary v with the increasing prevalence of ai, it has been in the best interest of mitary s to understand and integrate ai into their operations and strategies to be at the cutting edge of security and technology in con fl ict or emergency. various mitary ai technologies for generative purposes have also been developed, including intelgent decision support systems (idsss) and aided target recognition (aitc), which assist in decision-making, target recognition, and casualty care in the fi eld \u2013 . each of these uses of ai in mitary operations reduces the mental load of operators in the fi eld and helps them take action more quickly. just as mitary uses of ai can save ves on the battle fi eld, ai can help save ves by assisting cicians in diagnosing diseases and reducing risks to patient safety \u2013 . uses of generative AI in help improve the ef fi ciency of professionals caring for patient appcations of generative AI in include medical chatbots, disease prediction, ct image reconstruction, and cical decision support tools \u2013 . the bene fi ts of such uses are two-fold, in that they can help professionals dever a higher level of care to their patients, as well as improve the workload within cics and hospital people may question that developing ai models for mitary and purposes hinges on distinct ideological underpinnings re fl ecting unique prioritie in the mitary context, ai models are primarily designed to enhance the ef fi ciency, precision, and strategic capabities of both defensive and offensive operation the focus is on appcations such as surveillance, target recognition, cyber defense, autonomous weaponry, and battle fi . potential future uses of ai for offensive actions such as coordinating drone attacks may oppose any principle, yet is vital for the mitary strategy. the fundamental ideological perspective here is the protection of national security interests, force multipcation, and minimizing human risk in con fl ict zone on the other hand, the use of ai in is driven by the principles of enhancing patient care, improving health outcomes, and optimizing the ef ciency of system the development of ai models in this sector aims to personaze treatments, fi improve diagnostic accuracy, predict disease progression, and streame administrative tasks, among other use the central ideology is the betterment of human health and well-being. while we acknowledge the different ideological foundations in mitary and due to the contrasting objectives, we argue that both mitary and sectors illustrate a compelg convergence of priorities for the appcations of a speci fi cally, their shared focus on appcation vadity, attention to practical implementation, and prioritization of a humancentered approach have emerged as signi fi cant commonatie first, concerning appcation vadity, both fi elds recognize the crucial importance of robust, reable ai system these systems need to function accurately and rapidly under diverse, often challenging, conditions to ful fi ll their designated tasks, whether it identi fi es potential security threats in a complex battle fi eld or detects subtle abnormaties in medical image second, there is an evident emphasis on implementation. beyond the theoretical development of ai models, the critical question for both sectors centers around how these models can be effectively incorporated into real-world systems, often involving multiple human and technological stakeholder finally, a human-centered perspective is paramoun this means ensuring that ai technologies augment, rather than replace, human decision-making capacities and are employed in ways minimizing potential harm. in , this involves developing ai appcations that can improve patient outcomes and experience while supporting providers in their work. thus, these three factors represent key shared priorities in the utization of ai across mitary and context ai has been seamlessly woven into the mitary \u2019 s technology fabric for , serving as the backbone for various advancements ranging from autonomous drone weapons to intelgent cruise missiles , . the track record of robust results and reable outcomes in complex and high-risk environments impcitly engage with foundational ethical principle the ethical guidees estabshed from mitary ai implementations have provided a road map for the incorporation of ai in scenario however, the integration of ai is relatively new to the sector, lone generative AI, and ethical principles are neither widely implemented nor speci fi cally designed for generative a while has begun to adopt generative AI technologies more recently , there are immense opportunities for this fi eld to glean ethical insights from the history of mitary appcation. identifying ethical concerns and risks a study raised various concerns about the use of ai in warfare, shown in ure . of the research report . these concerns fall into the following categories: increasing risk of war, increased errors, and misplaced faith in a although ai can allow personnel to make decisions and strategies more quickly, some experts consider this a downside, as actions taken without proper consideration could have serious repercussions, ke increasing the risk of war . international standards for warfare ke the law of armed con fl ict (loac) and geneva conventions lay out guidees for target identi fi cation specifying that attacks must fi rst distinguish between combatant and noncombatant targets before taking action to minimize harm to civians , . because combatants are not always identi fi able visually, some claim that reading body language to differentiate a civian from a combatant necessitates a human-in-the-loop (hitl) decision-making process . maintaining data privacy for users of generative AI technologies is critical, as both patient data and mitary data are highly sensitive, and would be damaging if leaked . if an ai implementation collects phi, it should be secure against breaches, and any disclosures of this protected data must comply with health insurance portabity and accountabity act (hipaa) guidees . these implementations must experience few errors as is a safety-critical domain where the patient harm is unacceptable , and errors in these systems or algorithms could cause more harm than any physician would be capable of, as many hospitals and cics would be using the same systems and experiencing the same errors . additional concerns present in the mitary and are trust between humans and ai and the lack of accountabity. when there exists human-and-ai collaboration to perform a task, trust must be optimal, as shown in . . too much trust in ai systems can lead to overuse of the ai when it is not in the best interest of gure depicts the relationship between trust and capabity. too much trust in ai systems can . optimization of trust in a the fi lead to overuse of the ai when it is not in the best interest of patients or operators, and too ttle trust can lead to underuse of the system when it would be better to use i patients or operators , and too ttle trust can lead to underuse of the system when it would be better to use it . in both situations, the root cause is operators not knowing the capabities and mitations of the systems they interact with . misuse can lead to non-typical errors, such as fratricide in the mitary or patient harm in a hospital , . while the ai must be transparent in its decisionmaking, the use of ai must be accompanied by fi cient education on the use and mitations of ai systems so that operators are less kely to make dangerous error a lack of accountabity can possibly arise in mitary or use of generative AI because mitary operators or cicians do not have direct control over the actions determined by the a in the same research report by , authors showed (ures ., . in the report) that the general pubc views autonomous systems taking mitary action with human authorization favorably while strongly disagreeing with combat action without human authorization. the parallel can be drawn with , where patients express concerns over the use of ai for medical purposes without human (g., physician, nurse, etc.) involvement . these results could be due to the perceived lack of accountabity, which is considered something that could entirely negate the value of ai, as a fully autonomous system that makes its own decisions distances mitary operators or cicians from the responsibity of the system \u2019 s actions . in , it is critical that the systems are transparent due to their proximity to human ves and that patients understand how cicians use these recommendation the burden of accountabity in the sector falls to both the cicians and the developers of the ai systems, as the decisions made are a product of the algorithm, and the use of these recommendations falls to the cicians . finally, ethical concerns of equity, autonomy, and privacy regarding the use of generative AI must also be considered. in settings, biased algorithms or biased practices can lead to certain patient groups receiving lower levels of care . biased outcomes could be due to biased algorithms, poor data collection, or a lack of diversity . there must be minimal bias in developing ai systems in , both in the algorithm and the data used for training. furthermore, if known, the sources of bias must also be disclosed to ensure transparency and prevent inappropriate us the issue of human autonomy when developing generative AI is especially pertinent in , as both patient and cician autonomy must be respected . it is crucial that a framework is accepted to prevent any data breaches and ensure security measures are up to date and robus these risks and ethical concerns surrounding generative AI in mitary and appcations necessitate principles for the ethical use of a one of the earest sets of principles pubshed for responsible development and use of ai comes from , who did so in response to their employees petitioning their ceo as they disagreed with working with the dod on project maven to assist in identifying objects in drone images , in . these principles oute how will develop ai responsibly and state what technologies they will not create, ke those that cause harm or injure people, provide surveillance that violates international pocies, and any technologies that go against international law and human rights . by examining the differences and similarities between risks and ethical concerns in mitary and appcations of generative AI, we can estabsh guiding principles for the responsible development and use of generative AI in . great plea ethical principles for generative AI in as ai usage has spread throughout the mitary and other fi elds, many s have recognized the necessity of articulating their ethical principles and outing the responsibities associated with applying ai to their operation there are several ethical principles for ai pubshed by various s, including the department of defense , , the american medical association (ama) , (who) , and the coation for health ai (chai) . the ai ethical principles for dod and are similar, with having an added focus on adherence to international law. for the development of ai for , the who has pubshed its own ethical principles, including protecting human autonomy, human well-being and safety, transparency and explainabity, responsibity and accountabity, inclusiveness, and responsive developmen similarly, the ama promotes ai systems that should be user-centered, transparent, reproducible, avoid exacerbating disparities, and safeguard the privacy interests of patients and other individual finally, there is the blueprint for an ai bill of rights pubshed by the of fi ce of ence and technology pocy (ostp) , which has provisions for ai systems to be safe and effective, protected against algorithmic discrimination, protect user data, have accessible documentation, and offer human alternative among the various sets of principles, we see common themes such as accountabity and human presenc the dod and both emphasize the importance of integrating human responsibity into the development and fe cycle of an ai system, as well as ensuring these systems are governable to address errors that may arise during us the ama and who pocies both highght a human-centered design philosophy protecting human autonomy and expcitly mention the need for inclusiveness and equity in the use of ai to prevent care disparity. these principles each provide unique perspectives for developing ai for us however, no set of principles encompasses all ethical concerns that providers or patients may have . adopting the principles of the dod and is advantageous due to each principle \u2019 s practical de fi nition. these principles are outed with a focus on what actions can be taken by personnel developing ai systems, and how end-users would interact with the system the existing principles estabsh a good foundation for and utization of ai in . however, . adoption and expansion of existing ethical principles from mitary to . the fi gure illustrates the commonaties and differences in ethical principles between mitary and . in our assessment, traceabity, reabity, lawfulness, accountabity, governabity, and equity are the ethical principles that both fi elds have in common. at the same time, ethical principles, such as empathy and privacy, are emphasized in , whereas ethical principles, such as national security and defense, are emphasized in the mitary. action must be taken to tailor these principles for generative a by examining the risks and concerns surrounding the use of generative AI in , comparing them to the risks and concerns of generative AI in the mitary, and by expanding these principles, we can have a set of principles that ful fi ll our needs theore, we use dod and guidees as the starting point for the set of ethical principles, and expand them to meet the needs in . the expansion is done by incorporating principles that support the betterment of mankind rather than defeating adversarie ure shows the framework that we used for adopting and expanding ethical principles, estabshed by various s, for the appcations of a where similarities are present in the concerns between mitary and use of generative AI, it is possible to adopt principles for use, such as traceabity, reabity, lawfulness, accountabity, governabity, and equity. in instances when has unique circumstances or requires additional nuance, the principles related to those matters must be expanded to fi t into the world of medicine, such as empathy, autonomy, and privacy. there are many concerns speci fi c to the mitary that are unsuitable for forming ethical principles in , such as national security and defense, mission humanmachine teaming, rules of engagement, rapid deployment and effectiveness, operational security, adversarial ai , adaptation, and proferation and arms rac ure also shows some of these concerns (a non-exhaustive st), which we included to highght that the adoption or expansion of principles must be based on shared concern furthermore, we want to emphasize the need for having safeguards and methods to detect and mitigate mitary-speci fi c properties of ai deployed in settings, by including governabity, accountabity, and traceabity. a detailed mapping of the proposed ethical principles to those used by dod, , and who guidees is shown in table . as shown in the table, all principles, except for privacy, empathy, and autonomy, directly agn with either dod or guidee in cases where the principle indirectly agns with our proposed principles, table uses a star ( - ) pre fi x. as for privacy, empathy, and autonomy, despite not being related to the ethical principles in mitary s (, dod and ), who guidees directly or indirectly agn with all thre their inclusion was also due to the quaty of betterment of mankind and mitigation of concerns speci fi c to . in summary, we propose the \u201c great plea \u201d ethical principles for generative AI in , namely governabity, reabity, equity, accountabity, traceabity, privacy, lawfulness, empathy, and autonomy. the great plea ethical principles demonstrate our great plea for the community to prioritize these ethical principles when implementing and utizing generative AI in practical setting . shows the summary cards for the great plea ethical principle in the following, we will delve into a comprehensive explanation of each individual principl governabity governabity is the abity of a system to integrate processes and tools which promote and maintain its capabity and ensure meaningful human control . standards for the governabity of ai systems, as estabshed by the dod and , emphasize the importance of ensuring that while ai systems ful fi ll their intended functions, humans must retain the abity to identify and prevent unintended consequence in the event of any unintended behavior, human intervention to disengage or deactivate the deployed ai system should be possibl these standards can be adopted for the use of generative AI in . due to the potential of widespread implementation of generative AI systems, where numerous hospitals may be using the same systems, these standards must be considered . suppose a generative AI system, deployed across multiple cics, poses a risk of harm to a patien in that case, it is crucial to recognize that numerous patients across cics could be vulnerable to the same error. risk to patients amp fi es as expands to patient homes with remote patient monitoring or with one tools outside the cic. ideally, humans, whether they develop or implement the system, should possess the capabity to deactivate it without disrupting the regular patient care activities in the cic there must be expcit guidees for monitoring generative AI systems for potential errors, deactivation to prevent more damage when an error occurs, remedying errors, and interaction to reduce operator error with these guidees in place, personnel in ge of the table . agnment of great plea ethical principles with dod, , and who guidee principle dod who governabity governable governabity *promote ai that is responsive and sustainable reabity reable reabity *promote human well-being, human safety, and the pubc interest equity equitable bias mitigation ensure inclusiveness and equity accountabity - responsible responsibity and accountabity foster responsibity and accountabity traceabity traceable explainabity and traceabity ensure transparency, explainabity, and intelgibity privacy none none *ensure transparency, explainabity, and intelgibity lawfulness none lawfulness *promote ai that is responsive and sustainable empathy none none *promote human well-being, human safety, and the pubc interest autonomy none none protect autonomy - mark: indirectly agned principle system can quickly be noti fi ed of any unintended behavior and respond quickly and appropriately. reabity reabity is the abity of a system or component to function under stated conditions for a speci fi ed period of time . the proximity of generative AI to patient well-being necessitates standards for reabity to minimize potential errors that could lead to accidents . the generative AI models should have expcit and well-de fi ned cical use case a generative AI model designed for disease prediction needs to have a clear de fi nition of the use situation and patient criteri in addition, such generative AI models should be safe, secure, and effective throughout their fe cycle generative AI models should be demonstrated to be at least as safe as human decision making alone and not cause undue harm. existing generative AI models fer from hallucination and output variations, undermining their abity to produce reable output these shortcomings can adversely affect the trust between physicians and generative AI system adopting the dod \u2019 s principle for reabity can estabsh use cases for ai appcations and monitor them during development and deployment to fi x system failures and deterioration. having a thorough evaluation and testing protocol against speci fi c use cases will ensure the development of resient and robust ai systems, and help minimize system failures as well as the time needed to respond to these error equity equity is the state in which everyone has a fair and just opportunity to attain their highest level of health . due to the importance of health equity and the rami fi cations of algorithmic bias in , we call for adjustments to this principl there already exists inequity in . the generative AI models, that naturally have elevated data bias risks due to their pretraining on massive datasets, should not exacerbate this inequity for marginazed, under-represented, socioeconomically disadvantaged, low education, or low health teracy groups , but rather incorporate their unique social situations into future ai models to insure equity. generative AI must be developed with efforts to mitigate bias by accounting for existing health disparitie without this consideration, generative AI systems could erroneously recommend treatments for different patients . expansion of the principle for equity must set standards for evaluation metrics of algorithmic fairness so that deployed ai systems will not reinforce disparity. accountabity accountabity is the property of being able to trace activities on a system to individuals who may then be held responsible for their actions . to ensure accountabity and human involvement with ai in , the principle of responsibity and accountabity outed by states that they will develop ai appcations mindfully and integrate human responsibity to estabsh human accountabity for actions taken by or with the appcation. a study of patient attitudes toward ai showed the importance of accountabity in gaining patient trust when using ai in . this assurance of accountabity is crucial when a cician is using generative AI to help treat a patient, as without proper measures for human accountabity, the patient may feel that the cician is not invested in the care they are devering . we can adopt this principle for the ethical use of generative AI in , and ensure that human involvement is maintained when more powerful generative AI systems, such as chat or generative AI-based cical decision support systems, are used in patient car traceabity traceabity is tracking and documenting data, processes, and acts related to a system or model for transparent development . addressing the issue of optimizing trust between professionals and the ai they interact with can be done by adopting the principle of traceabity. this way, the personnel working with ai will understand its capabities, developmental process, methodologies, data sources, and documentation. furthermore, providing personnel with the understanding of an ai system capabities and the processes behind its actions, will also improve system reproducibity, allowing for seamless deployment across system t his is important for generative AI systems in because of their nature of being a black box system. this high-level understanding will help optimize trust, as operators will be aware of the capabities and mitations of the ai systems they work with and know the appropriate settings for use . with generative AI becoming more prevalent in , proper documentation is required to ensure all end users are properly educated on the capabities and mitations of the systems they interact with. the generation process of generative AI models should be transparen the erences or facts should be provided together with answers and suggestions for cicians and patient data sources used to train these models and the design procedures of these models should be transparent too. furthermore, the implementation, deployment, and operation of these models need to be auditable, under the control of stakeholders in the setting. . great plea cards for ethical principle we propose the \u201c great plea \u201d ethical principles for generative AI in , namely governabity, reabity, equity, accountabity, traceabity, privacy, lawfulness, empathy, and autonomy. the great plea ethical principles demonstrate our great plea for the community to prioritize these ethical principles when implementing and utizing generative AI in practical setting privacy privacy is an assurance that the con fi dentiaty of, and access to, certain ation about an entity is protected . privacy is necessary in most mitary and medical appcations of due to their con fi dential natur generative AI systems in must be hipaa compant for data disclosures, and secure to prevent breaches and developers should be advised how data should train systems for deploymen hipaa compance requires a regular risk assessment to determine how vulnerable patient data is . , thus a cic utizing generative AI systems in would have to determine if these systems are weak points in their technology network. for example, the utization of generative AI models presents potential privacy breach risks, including prompt injection , where macious actions could be conducted by overriding an original prompt, and jailbreak , where training data could be divulged by eciting generated conten furthermore, the capabities of generative AI to process personal data and generate sensitive ation make it crucial for these systems to be secure against data breaches and cyberattack ensuring these systems are developed with data privacy and security in mind will assist in keeping protected patient ation secur having these robust measures in place to maintain the privacy of the sensitive data collected and made by ai systems is crucial for the well-being of patients and for building trust with patient lawfulness lawfulness is the adherence to national and international law, including international humanitarian law and human rights law, as appcable . this can be adopted for the use of generative AI in . the laws that must be adhered to are not laws of con fl ict, but rather those related to . different states in the may estabsh different laws for ai systems that must be heeded for deployment in those areas . generative AI systems in also face legal challenges surrounding safety and effectiveness, abity, data privacy, cybersecurity, and intellectual property law . a legal foundation must be estabshed for the abity of action taken and recommended by these systems, as well as considerations for how they interact with cybersecurity and data privacy requirements of provider generative AI for must be developed with these legal challenges in mind to protect patients, cicians, and ai developers from any unintended consequence empathy empathy is the abity to understand the personal experiences and emotions of another, without extensive bonding . a principle for empathy is not directly erenced in any guidees by the dod or . however, by emphasizing the need for human involvement in the treatment of patients, it is possible to create a framework for human involvement in generative AI appcations to prevent gaps in accountabity and ensure patients receive care that is empathetic and helpful . there have been notable concerns about arti fi cial empathy of chatbots, such as chat, reinforcing the need for a principle de fi ning empathy for generative AI in . an empathetic relationship between provider and patient brings several bene fi ts to both the patient and the cic treating them, such as better patient outcomes, fewer disputes with providers, higher patient satisfaction, and higher reimbursement . autonomy autonomy is the matter of control over one \u2019 s self and requires both freedom from controlg in fl uences and the capacity for action for it to be maintained , . the more powerful ai systems become, the more concerns arise that humans do not control systems and care decisions . generative AI has seen staggering progress in , and hence, the protection of autonomy needs to be ensured when using generative AI in . protecting human autonomy means that patients receive care according to their perences and values and that cicians can dever treatment in the manner they want, without being encroached upon by the generative AI system. if autonomy in decision-making is not patient-focused, the potential for adverse events and poor cical outcomes will surely follow . by including provisions for protecting autonomy in using generative AI in , doctor-patient relations improve, and care quaty is ultimately improved . conclusion generative AI has great potential to enhance and make highquaty more accessible to all, leading to a fundamental transformation in its devery. challenges posed by ai in often mirror those encountered in mitary. we propose the great plea ethical principles, encompassing nine ethical principles, in the hope of addressing the ethical concerns of generative AI in , as well as the distinction between generative AI and \u201c general \u201d a this will be achieved by addressing the elevated risks mentioned previously in the paper. generative AI necessitates guidees that account for the risk of misation, rami fi cations of bias, and dif fi culty of using general evaluation metric considering the widespread nature of generative AI and its risks, these ethical principles can protect patients and cicians from unforeseen consequence following these principles, generative AI can be continuously evaluated for errors, bias, and other concerns that patients or caregivers may have about their relationship with ai in their fi eld. the present moment urges us to embrace these principles, foster a closer collaboration between humans and technology, and effect a radical enhancement in the system. these principles can be enforced through cooperation with lawmakers and the estabshment of standards for developers and users, as well as a partnership with recognized governing bodies within the sector, such as the who or am we note that the enforcement of the proposed ethical principles, be it via evaluation approaches (g., kert scale, , , prompting, or semantic similarity-based approaches for empathy ) or through other means, is out of the scope of this effor as such, we acknowledge the lack of detailed enforcement procedures as the mitation of the work. at the same time, implementing ai metrics or enforcement methods for great plea ethical principles can also be the potential future avenue for exploration. received: may ; accepted: november ; pubshed one: december erences . , ai weapons: russia \u2019 s war in ukraine shows why the world must enact a ban. nature --- (). . department of defens principles for arti cial intelgence fi  fi cial-intelgence/ (). . the north atlantic treaty . summary of the arti fi cial intelgence strategy  fi cial_texts_.htm (). . , k. what the thinks about arti fi cial intelgenc potico https://  . fi . , a comparison of arti fi cial intelgence and human doctors for the purpose of triage and diagnosi front . intell. , (). . , , machine learning end the viabity of radiology as a thriving medical specialty? br. . , (). . , impact of arti fi cial intelgence on pathologists \u2019 decisions: an experimen . med. . assoc. , \u2013 (). . , arti fi cial intelgence replace radiologists? radiol. . intell. , e (). . cacciamani, is arti fi cial intelgence replacing our radiology stars? not yet! eur. urol. open , \u2013 (). . yang, x. et a large language model for electronic health record . med. , (). . , ., , , chiang, , appcations of arti fi cial intelgence to electronic health record data in ophthalmology. transl. vi technol. , \u2013 (). . , , , medical terature for section prediction in electronic health record in proceedings of the conference on empirical methods in natural language processing and the th international joint (association for computational guistics, hong kong, china, ). conference on natural language processing (emnlp-ijcnlp) , \u2013 . singhal, large language models encode cical knowledg nature , \u2013 (). . , and governance of arti fi cial intelgence for health / (). . dowg, , chat for ( nance) research: the bananarama conjectur finance re . , (). fi . , m., , : designing a human-ai collaborative writing dataset for exploring language model capabitie in proceedings of the (association for computing machinery, new york, , ). chi conference on human factors in computing systems / , chi \u2019 ./. . . thiergart, , huber, & \u00fcbellacker, understanding emails and drafting responses \u2014 an approach using - (). preprint at / . . . ranade, p., piplai, , mittal, , joshi, & finin, generating fake cyber threat intelgence using transformer-based model in international joint conference on neural networks () , \u2013 (). . , differentiate chat-generated and human-written medical texts (). preprint at /. . . , , , n., amatriain, , medically aware - as a data generator for medical dialogue summarization. in proceedings of the second workshop on natural language processing for medical conversations , (eds shivade, ) \u2013 (association for computational guistics, one, ). -. . . , evaluating on impressions generation in radiology report radiology , e (). . , , f., shortffe, , generated text may have a role in evidence-based medicin na med . (). . , k., brozek, , beyond bias and compance: towards individual agency and pluraty of in ai (). preprint at https:// arxiv.org/abs/. . . , the forgotten margins of ai ethic in acm conference on fairness, accountabity, and transparency (acm, ). . opena introducing chat  (). . hu, k. chat sets record for fastest-growing user base - analyst not reuters ---/ . . opena model index for researchers  . . opena technical report (). preprint at / . . . , , narasimhan, k., , & sutskever, improving language understanding by generative pre-training. / language-unsupervised (). . , language models are unsupervised multitask learners (). . , et language models are few-shot learner in advances in neural ation processing systems , vol. (eds larochelle, h., , m., hadsell, r., balcan, m. & , h.) \u2013 (, ). https:// proceedingneuripcc/paper_ fi les/paper// fi le/cdbfcbbfb acfa-paper.pdf . . vaswani, attention is all you need. in advances in neural ation processing systems , vol. (eds guyon, ) (, ).  fi les/paper// fi le/feedeef bdccaaa-paper.pdf . . rombach, r., , , lorenz, d., esser, , high-resolution image synthesis with latent diffusion model in ieee/cvf conference on computer vision and pattern recognition (cvpr) , \u2013 (ieee computer society, los alamitos, ca, usa, ). / ./cvpr.. . . ramesh, , dhariwal, p., nichol, , chu, c. & , m. hierarchical textconditional image generation with cp latents (). preprint at https:// arxiv.org/abs/. . . , c. understanding diffusion models: a uni fi ed perspective (). preprint at /. . . , a survey of large language models (). preprint at https:// arxiv.org/abs/. . . , p. et pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing. acm compu surv . / ./ (). . , n., , n., foersch, & truhn, d. medical domain knowledge in domain-agnostic generative a . med. , (). . zhang, a complete survey on generative AI (aigc): is chat from to - all you need? (). preprint at /. . . zhang, text-to-image diffusion models in generative AI: a survey (). preprint at /. . . ferrara, should chat be biased? challenges and risks of bias in large language models (). preprint at /. . . , , franke, , endendyk, , dormuth, , m. the selfperception and potical biases of chat (). preprint at / ) . . ji, survey of hallucination in natural language generation. acm compu surv. , \u2013 (). . bang, . a multitask, multigual, multimodal evaluation of chat on reasoning, hallucination, and interactivity (). preprint at [/ abs/. . . bian, chat is a knowledgeable but inexperienced solver: an investigation of commonsense problem in large language models (). preprint at /. . . , metrics for deep generative model in proceedings of the twentyfirst international conference on arti fi cial intelgence and statistics , vol. of proceedings of machine learning research , (eds storkey, & perez-cruz, f.) \u2013 (pmlr, ).  . . , r. et lamda: language models for dialog appcations (). preprint at /. . . gloria, k., rastogi, , bias impact analysis of ai in consumer mobile health technologies: legal, technical, and pocy (). preprint at https:// arxiv.org/abs/. . . , a study of generative large language model for medical research and (). preprint at /. . . , chain of thought prompting ecits reasoning in large language model in advances in neural ation processing systems (eds oh, h., agarwal, , belgrave, , k.) ? id = _/forum?id=_vjqlmesb_j) (). . leiter, towards explainable evaluation metrics for natural language generation (). preprint at [/. . . priyanshu, , vijay, , kumar, , , , f. are chatbots ready for privacy-sensitive appcations? an investigation into input regurgitation and prompt-induced sanitization (). preprint at / . . . ayers, comparing physician and arti fi cial intelgence chatbot responses to patient questions posted to a pubc social media forum. . med. (). . donovan - ai-powered decision-making for defens scale / donovan (). . advanced targeting and lethaty aided system (atlas). covar / case-study/atlas/ (). . doctrinair covar / (). . choudhury, & , o. role of arti cial intelgence in patient safety outcomes: systematic terature review. . . fi , e (). . bahl, high-risk breast lesions: a machine learning model to predict pathologic upgrade and reduce unnecessary surgical excision. radiology , (). . dalal, systems engineering and human factors support of a system of novel ehr-integrated tools to prevent harm in the hospit . med. . assoc. , \u2013 (). . intercom for / . . prediction and early identi fi cation of disease through ai \u2014  ciatelgence-in-/ai-to-help-predict-disease . fi . willemink, m. ai for ct image reconstruction - a great opportunity. ai blog / (). . bajgain, , lorenzetti, d., , & sauro, of implementing arti fi cial intelgence-based cical decision support tools in : a scoping review protocol. bmj open , e (). . , targeting and lethaty automated system archive breaking / defense . . , development and modeg of intelgent control system of cruise missile based on fuzzy logic. in th international conference on electronics computer and computation (icecco) , \u2013 (). . bohr, & memarzadeh, - the rise of arti fi cial intelgence in appcation in arti fi cial intelgence in , (eds bohr, & memarzadeh, k.) \u2013 (academic press, ). . , mitary appcations of arti fi cial intelgence: ethical concerns in an uncertain world (, santa monica, ca, ). . introduction to the law of armed con fl ict (loac)  fl icpdf . . rule . the principle of distinction between civians and combatant ihl  . . docherty, losing humanity. human rights watch / ///losing-humanity/case-against-killer-robots (). . generative arti fi cial intelgence and data privacy: a primer - crs reports https:// crsreportcongresgov/product/pdf/r/r . . , , data, and arti fi cial intelgenc hipaa https://  fi cial-intelgence/ (). . , , , g. & kaufman, cognitive atics for biomedicine: human computer interaction in (springer, ). . ii, and remedies for arti fi cial intelgence in health car brookings  ciatelgence-in-health-care/ (). fi . lyons, & stokes, human reance in the context of automation. hum. factors , \u2013 (). . , o., bayrak, , arti fi cial intelgence and human trust in : focus on cicians (preprint) (). . lewis, m., , p. the role of trust in human \u2013 robot interaction , \u2013 (springer international pubshing, ). . , k. looking back at years of manprint on patriot: observations and lessons (). . , r. , ober, , regulation of predictive analytics in medicin ence , \u2013 (). . , p. et patient apprehensions about the use of arti cial intelgence in . . med. , (). fi . christian, r. mind the gap the lack of accountabity for killer robot human rights  watch (). . hab, , & porter, fi cial intelgence in health care: accountabity and safety. . world health organ. , \u2013 (). . ober, , powers, , voge, , dissecting racial bias in an algorithm used to manage the health of population ence , \u2013 (). . n, o. et addressing racial and ethnic inequities in data-driven health technologies \u2013 (). . , d. , , , d. implementing machine learning in health care \u2014 addressing ethical challenge . med. , \u2013 (). . frisk, what is project maven? the ai project employees want out of - -nation global news (). / /--ai-project-maven/ . . shane, & wakabayashi, d. the business of war \u2019 : employees protest work for the . /// /technology/-er-ceo--projechtml (). . our principle ai  . . augmented intelgence in health care* - american medical association https:// les/-/augmented-intelgence-pocyreporpdf / . fi . blueprint for trustworthy ai implementation guidance and assurance for  . . blueprint for an ai bill of rights -ostp. https:// / (). . naik, legal and ethical consideration in arti fi cial intelgence in : who takes responsibity? fron surg. (). . pifer, r. \"hurtg into the future \u201d : the potential and thorny of generative AI in . dive / generative-ai---potential// (). . rosenberg, , shabtai, , elovici, , l. adversarial machine learning attacks and defense methods in the cyber security domain. acm compu surv /./ (). . sigfrids, , , , salo-p\u00f6ntinen, , human-centricity in ai governance: a systemic approach. fron . intell. /articles/./fra.) [. (). . developing cyber-resient systems: a systems security engineering approach  . . centers for disease control and prevention / whatis/ (). . , y. practical, epistemic and normative impcations of algorithmic bias in arti fi cial intelgence: a quatative study of multidipary expert perspective med. (). . , , trawalter, , axt, r. & over, bias in pain assessment and treatment recommendations, and false beefs about biological differences between blacks and white proc. natl acad. , \u2013 (). . oldehoeft, foundations of a security pocy for use of the national research and educational network / nistir.pdf . . , diverse patients \u2019 attitudes towards arti fi cial intelgence (ai) in diagnosi plos digital health . . . hab, , & porter, fi cial intelgence in health care: accountabity and safety. . world health org. , \u2013 (). . mora-cantallops, m., s\u00e1nchez-alonso, , garc\u00eda-barriocanal, , m.- traceabity for trustworthy ai: a review of models and tool big data cogn. compu /-/// (). . , et trustworthy ai: from principles to practice acm compu surv . /./ (). . , , , branstad, khani, a framework for designing cryptographic key management systems / detail/sp/-/ fi nal . . (ocr), on risk analysi hhgov / for-professionals/security/guidance/guidance-risk-analysis/ (). . , ignore previous prompt: attack techniques for language model in ? id = qiaro_zmug (). . , . jailbreaking chat via prompt engineering: an empirical study (). preprint at /. . . , & christie, h. an arti fi cial intelgence strategy for cial-intelgencestrategy-for-/  . fi . team, f. state of cafornia endorses asilomar ai principle future fe ins  iforg/recent-news/state-of-cafornia-endorses-asilomar-aiprinciples/ (). fl . moudatsou, m., stavropoulou, , philathis, & koukou, the role of empathy in health and social care professional , (). . zhu, q. & , toward arti cial empathy for human-centered design: a framework (). preprint at /. fi . . , d. an interview with chat about health car cat non issue content (). . holm, principles of biomedical , th edn. med. eth. , \u2013 (). . ama of , \u2013 (). . app, & fischer, m. new technologies and mixed-use convergence: how humans and algorithms are adapting to each other (). . human rights and biomedicine  . . svikhnushina, & pu, p. approximating one human evaluation of social chatbots with prompting. in proceedings of the th meeting of the special interest group on discourse and dialogue , (eds schlangen, d. et ) \u2013 (association for computational guistics, ). / .sigdial-. . . , & yang, : a review of current advances, gaps, and opportunities (). preprint at / abs/. . acknowledgements y.w. would ke to acknowledge support from the momentum funds, cical and translational ence institute exploring existing data resources pilot awards, the school of health and rehabitation ences dean \u2019 s research and development award, and the national institutes of health through grants , utr, and rlm. y.p. would ke to acknowledge support from the national institutes of health through grants , rlm, and the national ence foundation through grant . the sponsors had no role in study design; in the collection, analysis, and interpretation of data; in the writing of the report; and in the decision to submit the paper for pubcation. author contributions d.o. conceptuazed, designed, and organized this study, analyzed the results, and wrote, reviewed, and revised the paper. h. analyzed the results, and wrote, reviewed, and revised the paper. r.k.p., c.p., g.l.l., and y.p. wrote, reviewed, and revised the paper. y.w. conceptuazed, designed, and directed this study, wrote, reviewed, and revised the paper. competing interests y.w. consults for and has ownership/equity interests in bona fi denlp, llc. all other authors declare no competing interest additional ation correspondence and requests for materials should be addressed to yanshan . reprints and permission ation is available at / reprints pubsher \u2019 s note springer nature remains neutral with regard to jurisdictional claims in pubshed maps and institutional af fi ation open access this article is censed under a creative commons attribution . international cense, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a k to the creative commons cense, and indicate if ges were mad the images or other third party material in this article are included in the article \u2019 s creative commons cense, unless indicated otherwise in a credit e to the materi if material is not included in the article \u2019 s creative commons cense and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. to view a copy of this cense, visit http:// creativecommonorg/censes/by/./ . \u00a9 the author(s) ", "## course policies on generative AI use _updated on_ _, _ **table of contents** **tips for setting your course approach to ai use** **template syllabus statements for generative AI use** **additional resources** _this resource is part of our suite on teaching and ai. see also_ _teaching in the ai era_ _and_ _starting small with ai in the_ _classroom_ _._ ", "##### tips for setting your course approach to ai use ** instructors may set course policies regarding generative AI use as they choose** , according to guidance from the board on conduct affairs . the guidance recommends that such policies are stated in the course syllabus and communicated clearly to students. **consider your learning goals** to help guide how you encourage and/or limit students\u2019 ai use, such as on which types of coursework or which portions of assignments ai use is permitted and in what ways. **explain limitations on ai use to students** , perhaps by connecting to the learning goals of the course, how assignment expectations mirror exam or quiz expectations, industry standards (e.g., publication standards), or of . if you allow or encourage ai tool use, **assign coursework or offer alternatives that all students may complete** **effectively if they are unable or choose not to use ai tools.** does not yet support any generative AI tools for use. learn more **looking for information about ai detectors?** if you choose to use them, we recommend a high degree of caution. see more under our faqs for reducing unpermitted use of ai tools . **for more guidance on developing your course policy on ai** , see teaching commons\u2019 resource on creating your course policy on ai . ", "##### template syllabus statements for generative AI use adapt the template syllabus statements below to fit your course. ", "## \uf058 **ai tools permitted freely** in this course, you may use generative AI tools for all coursework according to the following data privacy guidelines. be sure to review and follow the guidelines provided in it\u2019s resource on responsible ai at  . uit has advised the community to **avoid inputting information that should not be made public** when using a generative AI tool. this includes personal or confidential information of your own or that others share with you, as well as proprietary or copyrighted materials ( _include relevant material types for your course:_ e.g., case studies, data sets, assignment prompts] ) that may be included in your coursework. information you enter into a generative AI tool may be shared with third parties, and the tool may use your prompts or questions to inform content generated for other users. ", "#### \uf12a **ai usage permitted with limitations** in this course, you may use generative AI tools according to the following guidelines. any use of ai-generated material in student work outside of these guidelines will be considered a violation of the honor code and subject to consequences. guidelines for use: be sure to review and follow the guidelines provided in it\u2019s resource on responsible ai at  . uit has advised the community to **avoid inputting information that should not be made public** when using a generative AI tool. this includes personal or confidential information of your own or that others share with you, as well as proprietary or copyrighted materials ( _include relevant material types for your course:_ e.g., case studies, data sets, assignment prompts] ) that may be included in your coursework. information you enter into a generative AI tool may be shared with third parties, and the tool may use your prompts or questions to inform content generated for other users. [ **_optional_** _: select one or more additional guidelines for use from the list below, according to what applies for your_ _course. highlighted text should be edited to fit your course policies._ ] **use generative AI tools only according to the specific guidelines given for the assignment.** review the instructions for each assignment for more details. it is also acceptable to not use generative AI tools for an assignment that allows you to do so. ai tools in your learning such that you are unable to master the course goals, which [always/sometimes] require you to complete tasks and demonstrate skills without the use of ai tool assistance. _may explain additional_ _allowances for using ai tools, e.g.,_ you may use ai tools during the brainstorming or editing phases but not the drafting process of a writing assignment / you may use ai tools to help you understand and digest challenging readings but not in assignments, which test and enhance your understanding by asking you to apply those concepts to new contexts.] **all ideas, reflections, and analyses you present in your coursework must be your own.** ai tools are only permitted in this course to help you brainstorm starting points, develop prototypes and placeholders, and revise your work. _may include additional guidelines, e.g.,_ use ai tools only in the ways you might get help from a classmate, ta, or tutor \u2014 to brainstorm suggestions or practice skills, but not to generate ideas or arguments or to create final products. if you use ai tools to enhance your learning, make sure you are learning in a way that allows you to complete assignments or assessments without ai tools, if required.] **the use of ai tools during class time is not permitted** [ , _may include rationale, e.g.,_ so that we can continue to get the most out of our in-person interactions] . **cite all ai-generated material and/or explain how you have drawn on ai-generated material in your work.** please cite ai-generated materials using [ mla style apa style chicago style / / ] formatting _or explain your_ _preferred method of citing content, e.g.,_ include a short paragraph with each assignment explaining how you used generative AI tools / attach a copy of the chatbot conversation or other prompting that helped you produce assignment material] . **be prepared to fact-check and critically evaluate all ai-generated information.** [ _may include additional_ _explanation, e.g.,_ most ai chatbots aren\u2019t designed to write sentences that are true \u2014 they are designed to write sentences that are plausible. many ai tools get their training sets and information from the internet and can\u2019t make judgements about the information they draw on.] generative AI tools can provide false information (called \u2018hallucinations\u2019), perpetuate biases and/or stereotypes, or draw on copyrighted information without proper attribution, and such problematic information is often presented very convincingly. the materials these tools generate does not necessarily meet the standards of this course. ", "## \uf057 **no ai usage permitted\u200b** in this course, students may not use generative AI tools to complete any part of their assignments or assessments. this includes using ai tools that generate written, visual, or audio content, even if you revise or recreate the content before submitting. _may explain why ai tools are not allowed, e.g.,_ this course is designed to challenge your creative, analytic, and critical thinking skills, and using generative AI tools can undermine your learning of these skills. this is true even in cases where generative AI tools may be used to replicate portions of assignments or assessments we are asking you to complete.] therefore, generative AI tools are considered \u201cunpermitted aid\u201d according to the stanford honor code for all student work in this course, and their use will be considered plagiarism. ", "##### additional resources teaching in the ai era , gsb teaching and learning hub starting small with ai in the classroom , gsb teaching and learning hub creating your course policy on /teaching-guides/artificial-intelligence-teaching-guide/creating-your-course-policy-ai) , teaching commons [responsible ai at  , uit \uf129 **important note:** technology is changing at a rapid pace. while we make every attempt to ensure our content is updated to reflect changes to the interface and functionality, we can only guarantee the accuracy of the content on this resource page when it was written or recorded. please be sure to check the software developer's website for the latest updates and release notes for the most up to date information. if you have questions or concerns, or need additional support, please contact us. **unless otherwise noted, you may copy and redistribute this resource in its unmodified form under the terms of the creative commons by . international license (/licenses/by/./)** **[non-commercial, no-derivatives).** ", "# teaching and learning hub \uf099 \uf09a \uf16d \uf167 \uf08c ** graduate school of business** knight way , ca **companies, organizations & recruiters** ** community** **newsroom** **jobs** **library** **mygsb** **dashboard** **contact gsb** **visit campus** **stay in touch** \u00a9  graduate school of business non-discrimination policy privacy policy accessibility terms of use  university mobile ", "# the shortcomings of generative AI detection: how schools should approach declining teacher trust in students generative AI \u2013 systems that use machine learning to produce new content (e.g., text or images) in response to user prompts \u2013 has infiltrated the education system and fundamentally shifted the relationships between teachers and their students. across the country, educators have expressed high levels of anxiety about students using generative AI tools, like chatgpt, to cheat on assignments, exams, and essays in addition to fears of students losing critical thinking skills. one professor even described it as having \u201cinfected [the education system] like a deathwatch beetle, hollowing out sound structures from the inside until the imminent collapse.\u201d in response to these fears, school districts, like new york city and los angeles, quickly imposed bans on its use by both educators and students. schools have turned to tools like generative AI detectors to attempt to restore educator control and trust; however, detection efforts have fallen short in both their implementation and efficacy. ", "## cdt research affirms declining trust\u2026 one significant finding from our polling research of teachers, parents, and students is that teacher perception of widespread generative AI use for cheating appears to be largely unfounded. forty percent of teachers who say that their students have used generative AI for school think their students have used it to write and submit a paper. but only ** percent** of students who report having used generative AI say they have used it to write and submit a paper \u2013 a finding that is supported by other survey research . even despite the reality that a large majority of students are not using generative AI for nefarious academic purposes, teachers have still become more mistrustful of students\u2019 work \u2013 perhaps due to the widespread, fear-stoking coverage of cheating instances. **sixty two percent** of teachers agreed with the statement that \u201c[g]enerative ai has made me more distrustful of whether my students\u2019 work is actually theirs.\u201d and this mistrust is bleeding into certain groups of students being disciplined at disproportionate rates for using or being accused of using generative AI \u2013 title i and licensed special education teachers report higher rates of disciplinary actions for generative AI use among their students. these high levels of mistrust among teachers and subsequent disciplinary action have led to [frustration among students and /technology////prove-false-positive-ai-detection-turnitin-gptzero/) about erroneous accusations of cheating, which can cause an even further rift between teachers and students. this erosion of trust is potentially damaging to school communities where strong relationships between educators and their students are imperative in providing a safe, quality learning environment. ", "## \u2026and insufficient detection tools and training tools designed to detect when generative AI was used to produce content are the only technological solutions currently available to help teachers attempt to combat generative aibased cheating; however, they fall short of solving existing trust issues. to begin, school policies on content detection tool use is spotty \u2013 only ** percent** of teachers say that their school provides a content detection tool as part of its larger technology platform, and ** percent** say their school recommends their use, but leaves it up to the educator to choose one and implement it. without strong guidance on the use and implementation of content detection tools, teachers appear uneasy about utilizing them as a defense mechanism for cheating. only ** percent** of teachers report using a generative AI content detection tool regularly, and just ** percent** of teachers strongly agree that these tools \u201care an accurate and effective way to determine whether a student is using ai-generated content.\u201d teachers\u2019 lack of confidence is well-founded as, at least at this point, these tools are not consistently ) at [differentiating between ai-generated and human-written text. beyond using tools for detection, teacher confidence in their own effectiveness at detecting generative AI created writing is low \u2013 ** percent** say they are very effective and ** percent** say they are somewhat effective. this is particularly concerning given that most teachers have not received guidance on how to detect cheating. only ** percent** of teachers who have received training on their schools\u2019 policies and procedures regarding generative AI have gotten guidance on how to detect student use of chatgpt (or another generative AI tool) when submitting school assignments. ", "## how should schools approach declining teacher trust? given our research and what we know about generative AI content detection tools, they are not the answer, at least for now. these tools suffer from accuracy issues, and may /machine-learning////ai-detection-tools-falsely-accuse-international-students-of-cheating) [flag non-native /insights/brief-late-applications-disproportionate-effects-of-generative-ai-detectors-on-english-learners/) . instead, schools need to: - **offer teacher training on how to assess student work in light of generative** **ai.** to help teachers feel like they have more control over academic integrity in the classroom, schools must properly equip them to deal with the new reality of generative AI. this means providing them with training on the limitations of detectors and how to respond if they reasonably suspect that a student is cheating. - **craft and implement clear policies about which uses are allowed and prohibited.** our polling from shows that schools are failing to provide guidance on what is defined as \u201cimproper use\u201d of generative AI, with ** percent** of teachers reporting that their school has no policy or they are not sure if there is a policy in place on generative AI. it is imperative for both teachers and students to know this, so that everyone is on the same page about responsible generative AI use. - **encourage teachers to modify assignments to minimize the effectiveness of** **generative AI.** understanding what generative AI systems are _not_ good at can help teachers design assignments where using generative AI will not be helpful to students. for instance, generative AI systems are often ineffective at providing accurate sources for their claims. requiring students to provide citations for any claims they make will likely require students to go far beyond a generated response. _this is one in a series of information sheets designed by cdt\u2019s equity in civic technology team to give practitioners inside_ _public agencies clear, actionable guidance on how to most responsibly use technology in support of the communities_ _they serve. more info:_ [ _._ ", "# th closed session of the global privacy assembly resolution on generative AI systems sponsors: \u2022 european data protection supervisor (edps); co-sponsors: \u2022 acceso a la informaci\u00f3n p\u00fablica (aaip, argentina); \u2022 defensor\u00eda del pueblo de la ciudad de buenos aires (argentina) \u2022 der bundesbeauftragte und die informationsfreiheit (bfdi, germany); \u2022 der landesbeauftragte und die informationsfreiheit rheinland-pfalz (drlp, germany); \u2022 commission for the control and the protection of personal data (cndp, morocco); \u2022 commission nationale de l'informatique et des libert\u00e9s (cnil, france); (coe); \u2022 federal data protection and information commissioner (fdpic, switzerland); \u2022 garante per la protezione dei dati personali (gpdp, italy); \u2022 information commissioner\u2019s office (ico, united kingdom) for transparency, access to information, and personal data protection of m\u00e9xico (inai, mexico); \u2022 office of the information and data protection commissioner of malta (idpc, malta); ", "# \u2022 office of the information and privacy commissioner of ); \u2022 office of the privacy commissioner of canada (opc, canada); \u2022 office of the privacy commissioner for personal data (hong kong, china); \u2022 personal information protection commission (ppc, japan); \u2022 personal information protection commission (pipc, korea); \u2022 privacy protection authority of israel (ppa, israel); \u2022 unidad reguladora y de control de datos personales (agesic, uruguay) ", "# the th closed session of the global privacy assembly : _acknowledging_ the rapid development of artificial intelligence (ai) technologies, which often process personal data on a large scale; _noting_ the widespread deployment of generative AI technologies and applications and their increasing adoption across various domains as well as the widespread proliferation of uses around the world; _acknowledging_ the various concerns expressed in the public debate regarding the ethical and legal implications of generative AI technologies, including their impact on fundamental rights and freedoms, notably in relation to the fundamental right to privacy and protection of personal data; _concerned_ by the release - often with insufficient pre-deployment assessment - of generative AI systems to the wider public, which may present risks and potential harms to data protection, privacy and other fundamental human rights if not properly developed and regulated; _concerned_ about the indiscriminate collection of personal data from publicly accessible areas and sources to be into such technologies without legal authority; _recognising_ about the environmental impact of developing and deploying generative AI models that dedicates substantial computational resources to process large amounts of data; _recalling_ that data protection and privacy principles and current laws, including data protection and privacy laws, bills, statutes and regulations, apply to generative AI products and services, even as different jurisdictions continue to develop ai-specific laws and policies; _acknowledging_ the ongoing policy making, investigative and enforcement actions taken by various data protection authorities in relation to services using generative AI, in particular with regard to the processing of personal data and transparency for data subjects, including minors; _welcoming_ the roundtable of g data protection and privacy authorities (dpas) statement on generative AI which draws specific attention to key areas where privacy and data protection risks may arise and data protection and privacy principles apply to the development and use of generative AI tools; _acknowledging_ that continuous global discussion and collaboration is needed on promoting common values in the context of generative AI, not only from a legal perspective but also from an ethical, social and technical one;  . _stressing_ that public entities, including dpas, around the world have an essential role to play to ensure that the foundation models giving origin to generative AI tools are built in full respect for the individual\u2019s rights and freedoms, including data protection and privacy, as well as preventing unfair, unethical or discriminatory treatment contrary to human rights law; _recognizing_ the unique risks and potential harms of generative AI systems in the context of automated decision-making or in high-risk usages, particularly on vulnerable populations and children; _recalling_ the th global privacy assembly\u2019s _declaration on ethics and data protection in_ _artificial intelligence_ call for an \u201cethics by design\u201d approach, where artificial intelligence systems should be designed and developed applying the principles of privacy by design and privacy by default _;_ _reaffirming_ the st global privacy assembly\u2019s _international resolution on privacy as a_ _fundamental human right and precondition for exercising other fundamental rights_ that to build trust in our digital society, accelerate innovation, and protect human dignity, generative AI be human centric, based on democratic values, and should recognize privacy as a fundamental human right, vital to the protection of other rights and freedoms. the **th global privacy assembly emphasises** that: as any other ai systems, generative AI must be designed, developed and deployed in a manner that is responsible and trustworthy, based on the principles of data protection, privacy, human control, transparency and democratic values; developers, providers and deployers of generative AI systems should embed data protection and privacy in the conception, design, operation and management of new products and services using generative AI systems, based on the principles of data protection and privacy by design and document their choices and analyses in a data protection and privacy impact assessment; moreover, developers, providers and deployers of generative AI systems should understand the risks, harms, and potential impact on affected individuals and society at large as the basis to develop ethical, trustworthy and responsible generative AI; in addition, developers, providers and deployers of generative AI systems should also put in place measures to ensure compliance with data protection and privacy obligations. these stakeholders should cooperate to ensure that individuals whose data are processed by generative AI systems have the ability to exercise their data protection and privacy rights and; close attention should be paid by developers, providers and deployers of generative AI systems to the legal requirements and guidance from dpas on how to interpret such legal requirements. where appropriate, close communication with dpas can contribute to the responsible design, development and deployment of products and services based on generative AI systems. in this regard, the **th global privacy assembly** **endorses** the existing data protection and privacy principles as core elements for the development, operation, and deployment of generative AI systems: **.** **lawful basis for processing** generative AI systems must have a legal basis and be lawful in accordance with applicable legislation even when personal data is publicly accessible. developers must establish that generative AI systems are both legal and safe before the systems are launched. where required under relevant legislation, developers, providers and deployers of generative AI systems must identify at the outset the legal basis for the processing of personal data related to: a) collection of data used to develop generative AI systems; b) training, validation and testing datasets used to develop or improve generative AI systems; c) individuals\u2019 interactions with generative AI systems; d) content generated by generative AI systems. **.** **purpose specification and use limitation** developers, providers and deployers of generative AI systems shall ensure that they process personal data for specific, explicit and legitimate purpose(s) and not process them further for incompatible purpose(s) or beyond the affected individuals\u2019 reasonable expectations. these purpose(s) must be appropriate, reasonable or legitimate in the circumstances. developers, providers and deployers of generative AI systems must neither develop nor put into operation generative AI, the use of which is illegal or has a considerable potential to lead to unfair, unethical or discriminatory treatment, particularly where this would lead to significant violations of fundamental rights and freedoms. this is even more fundamental where ai systems are used to make or assist in decision-making about individuals. developers, providers and deployers of generative AI systems should carefully evaluate the compatibility \u2014ethical, legal, social, and technical\u2014with the purpose for which the personal data used in their development were collected. **.** **data minimisation** developers, providers and deployers of generative AI systems should limit the collection, sharing, aggregation, retention and further processing of personal data only to what is necessary to fulfil the legitimate identified purpose(s). personal data should not be collected and processed indiscriminately. in addition, inclusion of personal data in training sets poses privacy and other risks to individuals , including, inter alia, that information in training data could foreseeably be produced as part of a generative AI system's output. therefore, personal data must only be used as training data if required to achieve the intended purpose(s) of the generative AI system and only after a data protection and privacy impact assessment has been carried out. developers, providers and deployers of generative AI systems should aim to support environmental objectives by developing computational targets that reduce energy consumption, through tactics like data minimization, more efficient computational methods, and architectures that are less reliant on data growth. **.** **accuracy** in their development stage, generative AI systems often use vast amounts of training, testing and validation data, including personal data. the accuracy of the output of generative AI systems highly depends on the quality and representativeness of such large datasets. to safeguard affected individuals from discriminatory, unlawful or otherwise detrimental consequences, it is paramount that developers, providers and deployers of generative AI systems rely on accurate, reliable and representative data . developers, providers, and deployers must take measures to review and filter the content of the data to exclude information that is false or misleading. in addition, developers must refrain from making unsupported or premature claims related to the accuracy of their systems. even when trained with representative high quality data, the content generated by generative AI systems may contain inaccurate or false information including personal data, commonly known as \u201challucinations.\u201d to mitigate the risks posed by the potential lack of accuracy of generative AI systems, developers, providers and deployers of generative AI systems should implement appropriate data governance procedures (e.g. recording of training dataset sources) and technical safeguards (e.g. use of filters in input and output data). moreover, once deployed, it is essential to ensure adequate cooperation to monitor the behaviour and responses of generative AI systems and finetune the behaviour of generative AI systems to produce accurate responses. **.** **transparency** lack of transparency as to training data used has already fuelled concerns over the impact on individuals\u2019 data protection and privacy. deployers of generative AI systems must implement adequate transparency measures ensuring the openness of generative AI tools, including information on how, when, and why personal data is collected and used in the process of training generative AI systems. providers who put generative AI systems on the market or in operation must inform deployers about the potential data protection and privacy risks for using such systems and how providers address these issues through adequate policies and practices. these risks and policies must be clear, easy to understand, and readily available to deployers, both before and during use of the system. if a generative AI system is being used to make or assist in decision-making, developers, providers and deployers must clearly communicate these practices to the affected parties. developers, providers and deployers of generative AI systems should provide transparent documentation about their datasets, including the sources of the datasets, the legal authority and licenses of the datasets, and any modification, filtering or other curation practices on the datasets. **.** **security** in the design, conception and operation of generative AI systems, developers, providers and deployers must put in place effective security measures, especially where the system has access to external data sources. in particular, these measures should aim at: - integrating traditional cybersecurity controls with specific security controls tailored to generative AI system vulnerabilities (e.g. indirect prompt injection attacks); - preventing model inversion attacks that could allow an attacker to extract and reproduce personal data included in the datasets used to train the model; - ensuring that the safeguards put in place to foster compliance with data protection and privacy requirements are not undermined. developers, providers and deployers of generative AI systems should assess and mitigate the risk of misuse of their systems, such as creating deep fakes or generating text for phishing attacks. priority should be given to identifying and mitigating the root cause of these risks in order to prevent future harm. **.** **privacy by design and default** the capacities and limitations of generative AI systems are evolving rapidly. for example, certain generative AI systems that previously accepted just text, images or sound as input recently have been expanded to become multimodal and accept different types of input. new risks will arise as a result of these evolutions in the technology. in line with the privacy by design and by default principle, developers, providers and deployers of generative AI systems should conduct a data protection and privacy impact assessment to identify, assess and address the risks posed by these systems at every stage of their life cycle. privacy by design and by default aims at protecting data throughout the entire life cycle of data processing, starting from the design stage. by complying with this principle, based on a riskoriented approach, the threats and risks that ai may create can be minimised by considering them sufficiently in advance. developers, providers and deployers of ai systems need to carefully assess the envisaged processing activities, the risks they may pose for the data subjects, the possible measures available to ensure compliance with data protection principles and the protection of individual rights. privacy-oriented approaches should be favoured at all stages, including in particular through strong privacy by-default options and user-friendly options and controls. any major change to the functionality of generative AI systems represents a \u2018stage\u2019 in their lifecycle and would warrant a data protection and privacy impact assessment. **.** **rights of data subjects** developers, providers and deployers of generative AI systems must ensure that individuals are granted the right to be informed about the collection and use of their personal data, particularly where such data is obtained from a variety of sources and when personal data is being used to make or assist in decisions. in addition, developers, providers and deployers of generative AI systems shall implement appropriate technical and organisational measures in order to ensure that affected individuals are able to exercise their rights, where provided by law, including: - the right to access their personal data\u037e - the right to rectify any inaccurate personal data; - the right to erase their personal data and\u037e - the right not to be subject to automated decisions that result in a significant effect for the individuals. the capacity of affected individuals to exercise their rights is especially relevant when generative AI systems process special categories of data or personal data of minors. **.** **accountability** developers, providers and deployers of generative AI systems shall be responsible for and must be able to demonstrate compliance with applicable national legislation and international agreements. the principle of accountability requires responsibility to be clearly identified and respected among the various actors involved in the generative AI model supply chain. such compliance should be demonstrated by making available technical documentation throughout the lifecycle of systems in order to enable data protection and privacy authorities to assess compliance of generative AI tools with data protection and privacy requirements. developers, providers and deployers of generative AI systems should include in their documentation how their models work, what data was used to train their models, and the potential data protection and privacy impacts before putting their services on the market or in operation. developers, providers and deployers of generative AI systems should also allow for external audits that can independently assess how a model works, test outputs for inaccuracies and biases, and recommend effective measures to mitigate potential risks. accountability also requires developers, providers and deployers of generative AI systems to implement sound data governance procedures and tools. ", "## the th global privacy assembly therefore resolves to: - commit to ensure the application and enforcement of data protection and privacy legislation in the context of generative AI technologies, including the applicable principles and rights set out in this resolution; - commit to collaborate on ensuring personal data protection and privacy within the context of generative AI from an ethical, legal, social, and technical perspective; - commit to sharing ongoing developments within jurisdictions regarding the data protection and privacy risks of generative AI systems within the ethics and data protection in artificial intelligence working group; - call on developers, providers and deployers of generative AI systems to recognise data protection and privacy as a fundamental human right and to build responsible and trustworthy generative AI technologies that protects data protection, privacy, human dignity and other fundamental rights and freedoms; - encourage developers, providers and deployers of generative AI systems to provide training to employees and personnel to understand development and deployment of the generative AI systems regarding data protection, privacy and the rights of data subjects; - encourage members to raise awareness of the risks to data protection, privacy and other human rights as well as the applicable legal obligations and principles of data protection and privacy in the context of the generative AI systems; - continue monitoring emerging risks and potential harms to fundamental rights and freedoms as they arise in the context of generative AI; - aim to advocate and advise on ongoing and forthcoming legislative and regulatory initiatives and approaches; - call on members to coordinate their enforcement efforts on generative AI systems; - consider presenting, at the th global privacy assembly, an interim report on the work conducted by the aiwg members on generative AI systems, and further consider additional policy documents or resolutions to be presented at the th global privacy assembly. ", "## framework of an acceptable use policy for external generative AI ", "#### illustrative for adaptation ", "# contents ", "##### data provided to generative AI systems **confidentiality** currently, most external generative AI systems use queries for future training (although some systems allow opt-outs). the service may preserve the queries, which hackers could breach and release. queries with sensitive data put companies at significant risk. **policy guidance** **permissive** **stringent** employees must take care to preserve the confidentiality of the company\u2019s work products above any uses of generative AI systems. employees must adhere to this and all company policies and standards. employees must consider: > the impact, importance, or uniqueness of the company\u2019s intellectual property (ip) before sharing it. consider gener icizing and stripping any company employees must respect the confidentiality of the company\u2019s work products above any uses of generative AI systems. employees must adhere to this and all company policies and standards. employees must not share: > the company\u2019s internal ip , especially proprietary, copyrighted, or related ip > any data having personally identifiable | framework of an acceptable use policy for external generative AI **fs-isac** | references, especially if the data is proprietary or copyrighted > limiting or obfuscating the data if it has personally identifiable informa tion (pii), nonpublic personal information (npi), or other data under the purview of reg- ulators or similar entities > repurposing or reducing extraneous information that if exposed publicly: > might tarnish the reputation of the company > could open the company to regulatory or legal action information, nonpublic personal infor mation, or other data under the purview of regulators or similar entities. > any information that if exposed pub licly might tarnish the reputation of the company, or information that would open the company to regulatory or legal action > any information that someone may use to reverse engineer or give access to ip or systems > any information that if exposed publicly could reveal the company\u2019s strategy and/or would be in violation of safe harbor statements > may allow reverse engineering > may give access to ip or systems > a reminder to not share (in generative AI or any form externally) any infor mation that, if exposed publicly, could reveal the company\u2019s strategy and/or would be in violation of safe harbor statements _. this can be adjusted if, through contractual agree_ _ments, the firm has the keys to their data vault and_ _can protect the data held at the service._ | framework of an acceptable use policy for external generative AI **fs-isac** | **responsibility** although generative AI has the power to increase cyber crime through convincing mimicking of existing communications, excellent translation capabilities, deep fake images, audio, and video, ease of finding code vulnerabilities, and much more, the kinds of threats still are the same as when using other third-party systems. for instance, phishing emails may become more personalized with generative AI, but the way these enter the organization still is the same. the responsibility to safeguard against malicious activity when using generative AI is therefore same as general internet usage to protect ip and other concerns such as compliance. **policy guidance** **permissive** **stringent** generative AI systems are no different from any third-party system. they bring massive benefits, if used responsibly. they can do harm too, so employees need to take care of the queries and inputs to these systems. employees should consider the following as part of that responsible use: > that the accuracy of these systems is still suspect; they have been known to \u201challucinate\u201d (see \u201caccuracy\u201d section below) > remove references to ip , npi, pii > whether the firm\u2019s name needs mentioning > if sharing code, genericize any variable names > genericize the request, making it harder to attribute back to the firm > not share any of the aspects men tioned in the confidentiality section acceptable use of these systems is still unclear, given the accuracy of the output (see \u201caccuracy\u201d section below). to use them responsibly, at a minimum, employees must genericize the queries or inputs and remove any reference to the com pany or its ip , akin to asking a question on communities such as stack overflow or discord. if allowed to access these systems in a limited way, employees should: > remove any references to ip , npi, pii > remove any reference to the firm > if sharing code, genericize any variable names > genericize the request to be as abstract as possible > not share any of the aspects men tioned in the confidentiality section _. other policies may prohibit the use of stack_ _overflow and related systems though, and if so,_ _those prohibited use cases should also apply to_ _generative ai systems._ | framework of an acceptable use policy for external generative AI **fs-isac** | **access** this section elucidates the range of options for controlling access to generative AI systems, including guidance for which staff and from what devices they can access, as well as whether to use corporate identities when using them, given that it is possible that such queries become public. also, firms should publish a list of approved generative AI systems, based on its assessment of the vendor\u2019s compliance with laws, rules, and regulations. (fs-isac ai risk vendor risk subgroup is working on a questionnaire to aid this assessment.) **policy guidance** **permissive** **stringent** all employees can access approved external generative AI systems from desktops, mobile phones, and similar corporate devices. firms must limit access to gen erative ai systems from production servers when not part of a service or application workflow. employees must not access generative AI services from any corporate device or server. employees must not use their corporate identity (email or related) as a login to these systems. employees can use their corporate iden tity (email or related) as a login to these systems. | framework of an acceptable use policy for external generative AI **fs-isac** | **monitoring** monitoring is a common section in acceptable use policies, trusting but verifying compliance with the policy. firms need to consider what they intercept, monitor, limit, etc. **policy guidance** **permissive** **stringent** the company has the right to monitor the use of these systems per applicable laws and regulations. management may occasionally verify that the use of these systems adheres to the directives outlined in this document. users should inform their management at once if the use of these systems may have infringed on the standards in this policy for acceptable use. the company will monitor the use of these systems per applicable laws and regula tions. management will ensure that the use of these systems adheres to the directives outlined in this document. users should inform their management at once if the use of these systems may have infringed on the standards in this policy for acceptable use. ", "##### data received from generative AI systems **accuracy** generative AI systems are far from perfect, especially with fact-based output. these systems may \u201challucinate\u201d when their answers appear convincing but are completely wrong. users should not rely on their accuracy. incorrect answers can cause severe issues for companies. for example, inaccurate instructions for it administrators may lead to data loss or other system damage. distortion of statistics or other facts may lead to employees making public claims or key decisions based on erroneous information. other considerations: > since generative AI may not be current on legislation, answers on accounting, tax, or other legal considerations may be inaccurate > generative AI cannot know organizational culture or intricacies of industries, leading to suggestions that may do more harm than good. | framework of an acceptable use policy for external generative AI **fs-isac** | > depending on how users ask the questions, generative AI may not apply gdpr or other applicable laws to the answers given. > employees can use these systems for nefarious purposes, such as proxy avoidance, unapproved network uses, or manipulating financial services transactions for personal gain **policy guidance** **permissive** **stringent** given that the accuracy of generative AI is imperfect, the firm strongly encourages employees to manually verify the output before use. employees should ensure the output does not lead to: > fraudulent, destructive, and/or inap propriate system usage > poor, biased, and/or unethical business practices or decisions > reputational and/or financial harm of the company the firm also recommends employees: > ensure compliance with applicable regulations, laws, and acceptable fair use of others\u2019 copyright protections > avoid circumventing or bypassing this or other company policies akin to any other third-party solution, if the generative AI system results seem suspect, it is best to verify and consider alternative sources. employees must assume the output accuracy of generative AI systems are imperfect, and therefore must manually check the accuracy of the output (espe cially with regards to fact-based queries). employees must check that the output does not lead to: > fraudulent, destructive, and/or inap propriate system usage > poor, biased, and/or unethical business practices or decisions > reputational and/or financial harm of the company employees must also: > ensure compliance with applicable reg ulations, laws, and acceptable fair use of others\u2019 copyright protections. > not circumvent or bypass this or other company policies when there is doubt around the accuracy, completeness, or copyright protections of the output from a generative AI system, the employee must not use the output and, instead, rely on other sources of information. | framework of an acceptable use policy for external generative AI **fs-isac** | **representation as the employee or company** external generative AI systems often require users to give attribution to the system for any output, for example, in the open ai\u2019s terms of use. knowing this stipulation, it could: > invalidate some uses of the output for proprietary or copyrighted work > open users to copyright violations > open users to conflicts with other firms potentially using the same or similar output as generative AI becomes increasingly powerful, organizations will need to reevaluate what they consider \u201cacceptable\u201d use of such systems. no policy document, permissive or stringent, can cover all situations. for example, a manager short on time uses a generative AI system to write an employee appraisal. that employee does not like their appraisal and files a complaint. since an actual human did not write the appraisal, there is good reason to believe that the employee's grievances would be upheld. the onus is on the user to attribute the output correctly. **policy guidance** **permissive** **stringent** there are considerations for employees before they use generative AI output as their own: > in internal documents on behalf of the employee (emails, hr docu ments, et cetera.), employees must remember that the output stands for them. employees must take care to remove sensitive, proprietary, or confidential/secret company infor mation. employees should also check whether the output is in the desired tone and language employees must not use the output of gen erative ai systems to stand for activity they undertook. employees must specifically not use the output of generative AI to: > write any internal documents on behalf of the employee (emails, hr documents, et cetera.), especially those having sensitive, proprietary, or confidential/secret company infor mation > write any external communication > employees must note that there is greater attribution, legal, ethical, and copyright concerns in external com munications and perform stronger reviews in those uses | framework of an acceptable use policy for external generative AI **fs-isac** | **attribution** several commercial generative AI tools require attribution in their terms of use. given that users often do not attribute output to ai, firms may be liable for violations of these terms. consumers of these systems cannot (typically) treat the output as their proprietary ip , so use of this output can only advise and guide users. specific for programming code uses of generative AI, the input to the base of many of these sys tems is open-source software (oss) code found in common repositories. some firms limit the open-source licenses used in their products and need to verify that the output comes from an oss license they approved. while there are tools that try to detect if a generative AI system developed a specific output, they are not (yet) dependable enough to find whether an employee\u2019s work is original or not. this document assumes you cannot use such tools, but that may change. **policy guidance** **permissive** **stringent** any output from generative AI systems must follow the policies of the various external systems, specifically where they require supplying attribution to those systems. employees should take care that the use of generative AI systems does not com promise the firm\u2019s external reputation, even when supplying attribution. additionally, employees must respect and honor any applicable open-source licenses. any output from generative AI systems must follow the policies of the various external systems, specifically where they require supplying attribution to those systems. the firm will block or limit the use of systems that require attribution. employees must not engage in any use of generative AI systems that could compro mise the firm\u2019s external reputation, even when supplying attribution. additionally, employees must strictly follow any applicable open-source licenses. | framework of an acceptable use policy for external generative AI **fs-isac** | ", "# generative AI for organizational use: internal policy checklist ", "#### , future of privacy forum, ", "### generative AI for organizational use: internal policy checklist **introduction** generative AI is a category of artificial intelligence that \u201cgenerate[s] new outputs based on the data they have been trained on.\u201d large language models (llms) are a popular type of generative AI that generates responses to natural language queries. examples include bard and open ai\u2019s chat (chatbots), \u2019s ai-powered bing (search engine), midjourney\u2019s midjourney and open ai\u2019s dall-e (image generators). generative AI tools can draft emails or computer code, outline reports or blog posts, provide biographic information, perform customer service functions, generate images, and write scripts for popular television shows. as their general popularity increases, so does workplace use of generative AI and llms. workers are using generative AI tools in every field, across specialties, and at all levels of employment; there are few jobs in which llms are not relevant in at least one application. accordingly, organizations must grapple with the legal and social risks, benefits, and long-term consequences of organizational support and use of generative AI. organizations are rapidly revisiting internal policies and procedures to ensure responsible, legal, and ethical use. workers should be properly trained on the organization\u2019s policies and processes for acquiring and using these tools to ensure a proper understanding of how the tools work (or do not work), risks to the organization if they are not properly acquired or used, and their limitations. the future of privacy forum\u2019s checklist provides guidance regarding: - use in compliance with existing laws and policies for data protection & security; - employee training and education; - employee use disclosure; and - outputs of generative AI . \u201cwhat is generative AI? an ai explains,\u201d world economic forum (),  . generative AI can be used in a variety of contexts, to include creating images, text, videos, code, audio, etc. s _ee generally_ \u201cthe privacy expert\u2019s guide to artificial intelligence and machine learning,\u201d (),  . _see, e.g.,_ -. annie lowrey, \u201chow chat will destabilize white-collar work,\u201d _the atlantic_ (), // **checklist:** **policy** consulted with leaders across business sectors to learn more about how organizations are using generative AI across teams and in different contexts. we held a series of conversations that included more than experts on technology, law, and policy to understand the most pressing issues and how experts are accounting for generative AI tools in policy and training guidance. the below checklist, which provides a catalog of considerations for the use of generative AI within organizations, is a result of these conversations. this is a living document; new issues associated with the use of generative AI or llms are routinely discovered and refined. when use of generative AI tools within an organization is imminent or already occurring, time may be of the essence, and a comprehensive training program may not be feasible. in such cases, it is critical for key units and individuals to collaborate with all employees to understand how and why different teams may want to use these tools and, at a minimum, form a cross-functional team (e.g. privacy and compliance, human resources, legal, etc.) to compile and clearly communicate a survey of acceptable and prohibited uses, a designated contact point for any uses that are not specifically accounted for, and a timeline for any future actions that may provide greater detail or clarity. this full checklist should be considered as a starting point for this cross-functional team, or any other system an organization chooses, for more advanced conversations, as well as a gateway to address additional issues unique to a particular organization or field. risk management within the context of generative AI models is also an area of ongoing exploration, as some companies have already highlighted the potential risks of their generative AI systems. **note** : we use the term \u201cemployees\u201d as inclusive of, but not limited to: full-time staff, part-time staff, contractors, interns, or any others providing services for any form of compensation. organizations should adapt these recommendations to be most useful for their area or sector and different employees, and should be read in the context of those factors. **use in compliance with existing laws and policies for data protection and security** designated teams or individuals should revisit internal policies and procedures, including privacy policies, data use policies, information classification and management policies, and terms of service, to ensure that they account for planned or permitted uses of generative AI. _see_ \u201c system card,\u201d _open ai_ (),  **checklist:** **policy** individuals or teams responsible for procurement and/or enterprise risk management should collaborate to develop criteria to assess and approve new or updated third party software and services that integrate with generative AI apis or offer generative AI features. internal reviewers should consider the data sets used to create the outputs, as not all tools raise the same risks. reviewers should also consider whether the organization should provide transparency to the public or impacted individuals regarding the organization\u2019s generative AI use. sharing data with vendors must be subject to requirements that ensure compliance with relevant us state laws regulating sharing or sale of data. review contractual terms to ensure that any uses of data by vendors reflect mandatory state contractual language, or are subject to approved exceptions. if use of data by a vendor is deemed sharing or sale, ensure appropriate consumer notices are in place and ensure the organization and vendors comply with relevant consumer requests such as \u201cdo not sell\u201d requests. ensure vendors will support any required access and deletion requests. managers should remind all employees that relevant current or pending legal obligations will continue to apply to the use of new tools, particularly in regard to internal policies as well as applicable laws and regulations related to privacy and data protection, automated-decision making, data use, bias and discrimination, intellectual property, or other legal or policy frameworks of particular interest to the organization. as necessary, specific training may be useful as to how to mitigate legal liability in the use of generative AI. uses with heightened risks may warrant prior review, including legal review. if an organization is part of a regulated industry, it should pay extra care to understanding and communicating any specialized legal obligations or liability. rules should be considered for employees to ensure that they are not intentionally exposing their organization to liability. the organization should review guidance, where it exists, from relevant regulatory agencies on the use of generative AI, and incorporate that information into their internal policies and protocols. employees should be advised to avoid inputting sensitive or confidential information into a generative AI prompt unless data is processed locally and/or subject to appropriate controls regarding access or use. employees should not prompt generative AI tools to output sensitive or confidential information unless data is processed locally and/or _see_ \u201cgenerative AI: eight questions that developers and users need to ask,\u201d _information commissioner\u2019s_ _office_ (apr. ),  -need-to-ask/ **checklist:** **policy** subject to appropriate controls regarding access or use. sensitive or confidential information may include corporate trade secret information or data about users, competitors, clients, customers, employees, subscribers, or other individuals. special care should be taken when handling children\u2019s data, education data, hiring or workplace data that could lead to claims of discrimination or harassment, and other regulated forms of data. when using generative AI applications on work-issued devices, employees should be advised as to recommended settings or permissions associated with the llm or generative AI to ensure that data on that device is protected against unwanted access by the application. employees should be reminded of prior data protection and security training to ensure that their devices and networks are secure in order to prevent unauthorized access to data. **employee training and education** organizations should inform employees about the implications and consequences of using generative AI tools in the workplace. organizations should review and understand the generative AI system\u2019s terms of use and other relevant materials, including privacy policies, to understand how personal data is handled, processed, and protected. if there are specific generative AI tools that the organization wishes to recommend, discourage use of, or issue special warnings for, be sure to communicate that clearly and affirmatively. organizations must identify risks of using generative AI in context, including legal, regulatory, or ethical obligations, as well as potential liabilities associated with the use of generative AI tools. organizations should provide employees with new or existing resources that advise about the responsible use of any automated processing tool. existing educational resources should be updated where possible to expressly address generative AI tools. relevant training and workshops may include, but are not limited to, training on ethics, bias, data inaccuracy, security concerns, intellectual property rights, confidential information, and data minimization. software developers and data scientists accessing generative AI models through apis or building applications that use these models should be trained on ethics, bias, data inaccuracy, security concerns, intellectual property impacts, trade secrets, and data minimization. a system should be established to regularly remind individuals of legal restrictions on profiling and automated decision-making, as well as key data protection principles such **checklist:** **policy** as data minimization, purpose limitation, limitations on sale of personal data, and privacy by design and by default. given the speed at which generative AI technologies are developing, leadership at organizations should designate personnel responsible for staying abreast of regulatory and technical developments and ensure that company policies and employee practices reflect such changes. the contact information for these personnel should be available to all employees, and employees should be reminded of the appropriate points of contact for the organization's privacy and/or data protection policies (e.g. data protection officers) should they have any questions or concerns about the use of generative AI tools. **employee use disclosure** organizations should establish policies for how employees should sign up to use generative AI tools that require account creation, including whether the organization requires or prohibits the use of organizational email accounts for particular ai services or uses. employees should only use generative AI tools or systems that have been approved by the organization. accountability for the use of generative AI may require that employees have access to a system to document their use of these tools for business purposes. such tools should be easy to use, enable employees to add context around any use, and provide a method to indicate how that use fits into the organizations\u2019 policies. for example, organizations may require employees to download and retain chat transcripts and prompts. organizations should communicate when and how the organization will require employees to disclose whether work product was created in whole or part by generative AI tools. organizations should recognize the creative approaches that many employees will take to professional use of generative AI tools. typically, organizations should not create blanket bans on use by job title (e.g. hr employees), but rather provide employees with clear guidance on how they can or cannot use generative AI tools to perform their essential job functions (e.g. restricting or prohibiting hr employees from inputting employee names, addresses, social security numbers, etc. into chat). organizations should update internal documentation, including employee handbooks and related policies, to reflect policies regarding generative AI use. **checklist:** **policy** **outputs of generative AI** employees should be regularly reminded that: generative AI outputs can be incorrect, out-of-date, biased, or misleading. individuals are responsible for the content they create, regardless of the assistance of generative AI tools, and employees are encouraged to independently verify the accuracy of any outputs. verification is particularly important when employees use ai in situations that require legal certification of accuracy, e.g. financial reports, court filings, and due diligence documents. employees should be advised that content from generative AI tools may be subject to copyright protections or implicate holders of intellectual property. depending on the circumstance, organizational leadership may also advise employees to refrain from using ai-generated content if there is a question about intellectual property rights. the organization should decide whether, to what extent, and in what situations, it is determined that compensation should be provided to those whose intellectual property is implicated by the output of a generative AI, including if there is direct use, derivative use, or when it is clear that the material was a source for the output. coding outputs by generative AI should be checked and validated for security vulnerabilities. **checklist:** **policy** **resources** . regulation of ai a. ftc guidance regarding generative AI. note in particular the commission\u2019s warnings about representations of accuracy. i. chatbots, deepfakes, and voice clones: ai deception for sale ii. the luring test: ai and the engineering of consumer trust iii. keep your ai claims in check b. , gdpr, ai act: how (not) to regulate \u201cgenerative AI?\u201d ( law, , ) . understanding generative AI a. exploring generative AI and law: chat, midjourney, and other innovations | pre-conference primer (professor , siln flatirons) . managing risk a. managing the risks of generative AI - a playbook for risk executives \u2013 beginning with /generativeai?_pfses=dnscbpnqmwzxpyxtc#page=) () . emerging although this document is primarily intended for a us audience, emerging guidance from eu regulators is useful for us and global audiences. [generative AI: eight questions that developers and users need to /about-the-/media-centre/blog-generative-ai-eight-questions-that-developers-and-users-need-to-ask/) (, april ) for more information please contact policy counsel amber ezzell at [aezzell@.org or info@.org .       / blog-generative-ai-eight-questions-that-developers-and-users-need-to-ask/ **checklist:** **policy** **checklist:** **policy** ", "# guidelines on generative AI generative AI is predicted to become a transformational technology and may be an increasingly useful and valuable tool for public relations professionals in to come. the responsible use of ai in public relations will enhance our ability to serve our clients and advance the public interest. however, the responsible use of ai must always be subject to human judgment and oversight to avoid bias, misuse, and inadvertent risks of harm. this technology is rapidly evolving, and many agencies, professionals and organizations are exploring the potential of generative AI, current issues, and longer-term implications. the following is guidance on the use of generative AI in our work for clients and our agencies based on and principles. the strongly encourages agencies and their teams to actively engage in internal testing and learning relative to generative AI within a proper ethical and legal framework. following these guidelines will help ensure that the use of generative AI aligns with our members\u2019 core commitment to the highest level of professionalism, decision making, and ethical conduct. while these guidelines have been created with the input of a group of leaders across our membership and reviewed by our legal partners at , we encourage leaders to consult with their legal counsel as they tailor these guidelines and implement specific policies and training most appropriate for their clients, employees and vendors. **.** **we protect the integrity of client information.** - use caution when putting confidential client information into a generative AI tool or platform. for example, do not use it to create the first draft of a press release about a new product or to draft internal memos for staff. other examples of confidential information include, but are not limited to: `o` client business plans, `o` client or prospect ppts or documents, `o` paid or confidential analyst reports that you would like summarized, `o` paid market insights to detail key findings, `o` confidential research data, and `o` text related to sensitive internal employee communications. \u25aa why? many different types of generative AI tools and platforms exist, and some tools may use the information you enter as prompts for written or visual content to train future iterations of their model and be incorporated into future output it generates. unless specifically stated or identified as a closed tool or platform, anything entered as a query may enter the public sphere and release information and intellectual property into someone else\u2019s database not under your control . - do not use generative AI images as final creative for a client campaign. the aigenerated work may be at risk of copyright infringement and the work itself cannot be entirely protected under current u.s. copyright laws (since humans did not create it), according to current court rulings and u.s. copyright office policies. moreover, certain generative AI tools may limit the user\u2019s ownership rights in the work the platform generates. - note: the above guidelines also apply to confidential, internal agency information. **.** **we honor our role in society.** - do not use generative AI to create or spread deepfakes, nor misinformation or disinformation. **.** **we are committed to accuracy.** - always check and source the data generative AI tools provide. always validate the claims with your own search of the source. just because the tool says it came from a source does not mean it did, as some generative AI chat tools are exceptionally good at convincingly fabricating information. - always check for inadvertent plagiarism, copyright infringement, or trademark infringement in ai-generated output. - ask vendors about how they use the ai in their tools (such as sentiment analysis) and work to eliminate biases and improve accuracy. ask vendors to provide transparency around their prompts and inputs used to generate desired output, to help mitigate the risk of inadvertent infringement of third-party rights. **.** **we believe that our clients and the public are best served when third-party** **relationships with spokespeople, bloggers, partners, and allies are open and** **transparent.** we recommend disclosure to clients if generative AI tools are used in any part of the creative process. `o` flexibility can be applied to determining how and when to disclose. we recommend agencies include wording as part of their contract and scope of work if this is a common occurrence. if generative AI is being used infrequently, agencies should call out its use on individual pieces of work in which it played a substantive role. we encourage agency leaders to set policies on what requires written disclosure versus verbal. `o` why? the encourages transparency. additionally, most of our members have contracts that state that all materials we produce on behalf of clients are \u201cwork for hire\u201d meaning we assign the ownership rights of those materials to our clients. however, that is currently impossible to do with solely ai-generated materials which could put us in violation of our contracts. we would also be exposed to increased legal risks due to dual indemnification clauses, which are common in most agency contracts. clarify with your staff when disclosure needs to be in writing and when verbal disclosure is sufficient, - as an employee, you should disclose to your manager if you use generative AI tools as part of the drafting or creation process. - influencers should disclose if they use generative AI tools as part of their content creation on behalf of your clients and in their posts. the disclosure should be on every sponsored post they create. influencers should be transparent with the agency about how ai-generated content was developed and should be responsible to the agency and client if the content results in a legal claim. - voice/music generating ai tools should never be used to mimic the voice or style of a real person. if there is a need to correct a voiceover and it is mutually agreed upon with the talent that ai can be used for such correction, then that will require a signed agreement before proceeding. if the voiceover talent is a union member, or if the agency or client are signatories to a union contract, additional requirements may apply as well. - respect the rights of other creators and do not prompt generative AI to develop creative content similar to that of a specific artist. **.** **we value diversity and inclusion in our profession.** - beware of biases incorporated in ai-generated output, both in writing and in developing imagery for a campaign. some key questions to ask when evaluating an ai platform or tool to better understand potential bias can be found below. - do not rely on generative AI tools to translate or transcreate documents into other languages. the quality of the transcreation or translation might not be accurate. the quality of the transcreation or translation might not be accurate. - do not use generative AI as a replacement for diverse experiences, insight, or engagement. - utilize diverse perspectives within the agency to review content created by generative AI tools to ensure no bias is accidentally overlooked or shared externally. - do not use generative AI tools to create imagery, likenesses, or avatars that create the appearance of diversity instead of working with diverse talent. **: ai bias questions to ask** - how was the data used to train the ai tool collected? - was the training data representative of the cultural identities and intersections of the real-world demographic population? - do the systems and processes used to collect the data have a process to interrupt inherent biases towards demographic groups? - what is the demographic makeup of the people who are using the ai tool? - what bias is the team introducing in its queries or uses of the tool ? specifically, where might the team have inherent blind spots in the process? - what biases can we identify in results generated by the ai platform? - was the ai tool tested on a diverse set of data to evaluate its performance across different demographics? - how can we mitigate the risk of bias in the ai tool? - how do we connect the work of recognizing and reducing opportunities for bias in our use of ai platforms, with ongoing dei work in our agencies to help identify and reduce bias in all aspects of our work and relationships? **.** **we are committed to agency practices that increase society\u2019s confidence in the** **practice of public relations.** - agencies should establish clear guidance and conduct regular, firm-wide training on best practices and the proper ethical and legal use of ai to protect their brands and their clients\u2019 brands. training should focus on the following, to avoid ethical and legal risks: `o` best practices for using ai in workflows, `o` avoiding or mitigating potential algorithmic biases, `o` enhancing client and stakeholder transparency, `o` proper and full sourcing, `o` how to identify inaccurate results, and `o` maintaining the integrity of intellectual property. - agencies should establish or expand their internal reporting frameworks to clearly define how staff can raise concerns. - since generative AI and its uses are evolving rapidly, agency leadership should update guidelines, training and discussion at least . will support members by providing regular updates and trainings. ", "# # # released on "]